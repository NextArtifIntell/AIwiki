<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>ISCI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="isci---1310">ISCI - 1310</h2>
<ul>
<li><details>
<summary>
(2021). Incomplete-view oriented kernel learning method with
generalization error bound. <em>ISCI</em>, <em>581</em>, 951–977. (<a
href="https://doi.org/10.1016/j.ins.2021.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning (MVL) is a promising direction and most MVL methods work under the assumption that data are complete in all views. However, this assumption is often violated in practice due to the difficulties of high cost, equipment failure, and so on. Besides, the amount of data with missing views is particularly huge. Therefore, it is challenging yet valuable to fully leverage the large-scale incomplete-view data. Enlightened by the reduced support vector machine (RSVM) and multi-view privileged support vector machine (PSVM-2V), this paper proposes an efficient kernel method called reduced PSVM-2V (RPSVM-2V). It can not only provide a novel solution to process incomplete-view data, but also can be adjusted to address large-scale complete-view learning problem efficiently. In addition, the idea of replacing the full kernel with a smaller rectangular reduced kernel is extended to develop another two MVL methods, i.e., reduced SVM-2K (RSVM-2K) and reduced multiple kernel learning method (RMKL). Furthermore, we analyze the generalization error bounds of RPSVM-2V and two extensions by using Rademacher complexity. The comprehensive experiments demonstrate that our proposed models can achieve comparable performance with less time and memory cost. The spectral analysis has further verified the effectiveness of the reduced kernel used in our models.},
  archive      = {J_ISCI},
  author       = {Yingjie Tian and Saiji Fu and Jingjing Tang},
  doi          = {10.1016/j.ins.2021.10.011},
  journal      = {Information Sciences},
  pages        = {951-977},
  shortjournal = {Inf. Sci.},
  title        = {Incomplete-view oriented kernel learning method with generalization error bound},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring graph capsual network for graph classification.
<em>ISCI</em>, <em>581</em>, 932–950. (<a
href="https://doi.org/10.1016/j.ins.2021.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Network (GNN) has received tremendous attention due to their power in learning graph representations by modeling the topological structure and aggregating feature information. However, the scalar node representations learned from GNN may not be sufficient to effectively preserve the attributes of the node/graph features, resulting in sub-optimal graph representation. Repeated averaging gathers too much noise, which makes the features of nodes in different classes over-mixed and leads to the problem of over smoothing. Inspired by the concept of capsule network proposed by Hinton, we propose a new framework for graph classification, named CapsualGNN, which takes full advantage of Graph Neural Network and Capsule Network. Specifically, we firstly represent nodes as groups of capsules, in which each capsule extracts distinctive features of its corresponding node. Then, we exploit routing mechanism to capture important information and properties at the graph level by the generated multiple embeddings for each graph, and utilize attention mechanism to focus on important features. Finally, to solve the problem of over smoothing, we introduce class residual connection for GCN . In addition, we also introduce parameter for distinguishing self-connected nodes and other nodes. We evaluate the framework by using six graph datasets on biological information and social networks, and demonstrate that CapsualGNN outperforms other SOTA techniques on the task of graph classification.},
  archive      = {J_ISCI},
  author       = {Ying Wang and Hongji Wang and Hui Jin and Xinrui Huang and Xin Wang},
  doi          = {10.1016/j.ins.2021.10.001},
  journal      = {Information Sciences},
  pages        = {932-950},
  shortjournal = {Inf. Sci.},
  title        = {Exploring graph capsual network for graph classification},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective evolutionary optimization based on online
perceiving pareto front characteristics. <em>ISCI</em>, <em>581</em>,
912–931. (<a href="https://doi.org/10.1016/j.ins.2021.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving multi-objective optimization problems with complex Pareto fronts characteristics, previous work generally ignores the information related to Pareto fronts provided by the population during the evolution, which is detrimental to efficiently tackle them. In order to taking full advantage of information associated with a population evolution, a multi-objective evolutionary optimization method based on online perceiving Pareto front characteristics is proposed in this study. To this end, the information associated with the Pareto front of an optimization problem is first extracted from the population. Following that, the characteristics of the Pareto front in concavity/convexity and continuity are perceived online. For the purpose of each sub-front containing only one characteristic, a Pareto front is divided based on the concavity/convexity and continuity. According to the characteristic of each sub-front, different reference points are selected to refine the distribution of reference vectors. Finally, a multi-objective evolutionary algorithm is designed targeting the characteristics of the Pareto front. The performance of the proposed method is evaluated by comparing it with 8 state-of-the-art optimizers on 31 test problems. Further, the experimental results demonstrate that the proposed method is competitive in handling multi-objective optimization problems with irregular Pareto fronts.},
  archive      = {J_ISCI},
  author       = {Wenqing Feng and Dunwei Gong and Zekuan Yu},
  doi          = {10.1016/j.ins.2021.10.007},
  journal      = {Information Sciences},
  pages        = {912-931},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective evolutionary optimization based on online perceiving pareto front characteristics},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic interaction feature selection based on fuzzy rough
set. <em>ISCI</em>, <em>581</em>, 891–911. (<a
href="https://doi.org/10.1016/j.ins.2021.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important data preprocessing approach that continues to be concerned in data mining . It has been extensively used to construct learning models and reduce storage and computing requirements. Fuzzy rough set is a useful theoretical tool for dealing with the mixed data with fuzziness and inconsistency. Hence, feature selection based on fuzzy rough sets has attracted much attention. However, most of the existing studies ignore the interaction between features, which leads to the loss of useful information. Motivated by this issue, we devise a Dynamic Interaction Feature Selection method based on Fuzzy Rough Set (DIFS_FRS). The method simultaneously considers the interactive relation between features, the relation between conditional features and decision classes, and the dynamic change of feature weights with the variation of feature subset. Firstly, the single-level dependency relevancy between features and classes is defined by the fuzzy dependency degree. Secondly, the multi-level joint interaction between features about classes is investigated. Correspondingly, the correlation evaluation index of features is constructed. Thereafter, a dynamic updating-feedback mechanism is established for a novel feature evaluation function. Finally, compared with the other six representative algorithms on eighteen data sets, the DIFS_FRS algorithm is demonstrated to have better performance.},
  archive      = {J_ISCI},
  author       = {Jihong Wan and Hongmei Chen and Tianrui Li and Xiaoling Yang and Binbin Sang},
  doi          = {10.1016/j.ins.2021.10.026},
  journal      = {Information Sciences},
  pages        = {891-911},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic interaction feature selection based on fuzzy rough set},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). HCTree+: A workload-guided index for approximate kNN
search. <em>ISCI</em>, <em>581</em>, 876–890. (<a
href="https://doi.org/10.1016/j.ins.2021.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of approximate k k -nearest neighbor search in high-dimensional space is a fundamental problem in many applications. We have observed that most existing approaches are unable to leverage the query results to improve the search performance. To address this limitation, we present a new index, called HCTree+, that aims to improve the query performance based on incoming queries and their results. First, we adopt a simple yet effective index to support efficient search. Second, incoming queries and their results are used to optimize the index dynamically for future queries . The experimental study shows that HCTree+ outperforms the state-of-the-art algorithms in terms of accuracy while achieving the desired efficiency.},
  archive      = {J_ISCI},
  author       = {Lingli Li and Jie Xu and Yu Li and Jingwen Cai},
  doi          = {10.1016/j.ins.2021.10.027},
  journal      = {Information Sciences},
  pages        = {876-890},
  shortjournal = {Inf. Sci.},
  title        = {HCTree+: A workload-guided index for approximate kNN search},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generation of admissible orders on n-dimensional fuzzy set
ln([0,1]). <em>ISCI</em>, <em>581</em>, 856–875. (<a
href="https://doi.org/10.1016/j.ins.2021.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {n-Dimensional fuzzy sets are a type of fuzzy sets where the membership degrees are n-dimensional intervals, i.e., ordered vector of dimension n n on [ 0 , 1 ] [0,1] . A fundamental aspect for aggregation function in types of fuzzy sets is establish the order on the membership valued which be consider. The natural order for n-dimensional intervals is the product order. Nevertheless, in some applications it is necessary to consider admissible orders, i.e., total orders which refines the product order. In this work we introduce three methods for generating admissible orders on n-dimensional fuzzy set. Some results and constructions obtained for the case 1-dimensional are generalized for the case n-dimensional. The concept of (OnmF)-graphs is introduced and a method to determine the best (OnmF)-path with respect to an admissible order was proposed.},
  archive      = {J_ISCI},
  author       = {Thadeu Milfont and Benjamín Bedregal and Ivan Mezzomo},
  doi          = {10.1016/j.ins.2021.10.017},
  journal      = {Information Sciences},
  pages        = {856-875},
  shortjournal = {Inf. Sci.},
  title        = {Generation of admissible orders on n-dimensional fuzzy set ln([0,1])},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised label distribution learning via projection
graph embedding. <em>ISCI</em>, <em>581</em>, 840–855. (<a
href="https://doi.org/10.1016/j.ins.2021.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label distribution learning (LDL) is a new machine learning paradigm that addresses label ambiguity by emphasizing the relevance of each label to a particular instance. In supervised learning, many LDL algorithms have been proposed, which often require a large amount of well-annotated training data to achieve good performance. However, annotating a label distribution is more complicated and expensive than annotating a single label or multiple labels with logical values of 0 and 1. Thus, we propose a projection graph embedding algorithm for semi-supervised label distribution learning (PGE-SLDL). Specifically, we seek a potential space by orthogonal neighborhood preserving projections, named capture space. This capture space is used to select more valuable features and construct a graph that contains more accurate data structure information. We utilize the sample correlation information contained between graph nodes to recover the unknown label distribution. In addition, compared with fixed graphs in traditional semi-supervised learning, we carry out projection and graph construction simultaneously to obtain a self-updating projection graph, which is more helpful to learn label distribution. The experimental results validate the effectiveness of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Xiuyi Jia and Tao Wen and Weiping Ding and Huaxiong Li and Weiwei Li},
  doi          = {10.1016/j.ins.2021.10.009},
  journal      = {Information Sciences},
  pages        = {840-855},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised label distribution learning via projection graph embedding},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-universe model of three-way decision with ranking and
reference tuple. <em>ISCI</em>, <em>581</em>, 808–839. (<a
href="https://doi.org/10.1016/j.ins.2021.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of three-way decision, introduced for the needs of explaining the three regions of rough sets, has developed into a more general theory of three regions in recent years. For different types of problems, we should have different types of intentions of trisecting, and only by considering the specific intentions of trisecting can we get the most accurate three regions. This is the starting point of this article. From a new perspective of trisecting, we propose two concepts on two universes, namely rankings of a set of attributes and reference tuples. These two concepts are combined together to express the original intention of trisecting in a new general meaning. At the same time, an evaluation of matching degree is proposed to formulate the trisecting. Based on the above two concepts and one evaluation method, we construct a two-universe model of three-way decision with concrete formulations, and show that the rough-set-based model proposed by Yan et al. is only equivalent to one of the eight cases of our model, with the eight cases corresponding to eight different types of intentions and hence to eight different types of problems. Therefore, the present paper extends classical rough-set-based models to a more general level on two universes. Two algorithms are provided to compute the three regions of our model, with the second one also computing the ordering of objects and hence the optimal ones.},
  archive      = {J_ISCI},
  author       = {Wenyan Xu and Bing Jia and Xiaonan Li},
  doi          = {10.1016/j.ins.2021.10.019},
  journal      = {Information Sciences},
  pages        = {808-839},
  shortjournal = {Inf. Sci.},
  title        = {A two-universe model of three-way decision with ranking and reference tuple},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preventing translation quality deterioration caused by beam
search decoding in neural machine translation using statistical machine
translation. <em>ISCI</em>, <em>581</em>, 791–807. (<a
href="https://doi.org/10.1016/j.ins.2021.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decoding is an important part of machine translation systems, and the most popular inference algorithm used here is beam search . Beam search algorithm improves translation by allowing a larger search space to be traversed than greedy search. However, as the beam width increases, the translation performance declines after a certain point in neural machine translation (NMT). This problem is usually not observed in statistical machine translation (SMT) due to the decoding method. This paper proposes a hybrid system-based method that uses SMT predictions to prevent quality deterioration in the beam search algorithm used in NMT decoding. Our approach is based on the reranking n-best list of NMT according to the SMT system translation sentence. We propose two different algorithms for reranking NMT n-best lists. The first algorithm uses the length information of the SMT outputs. In contrast, the second uses a word-based similarity approach with the Jaccard Index, the Dice’s Coefficient, and the Overlap Coefficient. Experiments on three different language pairs show that the method we propose prevents the decrease in translation quality and produces a gain of 1.3 BLEU and 1.6 METEOR for different beam sizes and 1.8 BLEU and 2.1 METEOR average scores compared to the baseline results.},
  archive      = {J_ISCI},
  author       = {Emre Satir and Hasan Bulut},
  doi          = {10.1016/j.ins.2021.10.006},
  journal      = {Information Sciences},
  pages        = {791-807},
  shortjournal = {Inf. Sci.},
  title        = {Preventing translation quality deterioration caused by beam search decoding in neural machine translation using statistical machine translation},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive operator selection with reinforcement learning.
<em>ISCI</em>, <em>581</em>, 773–790. (<a
href="https://doi.org/10.1016/j.ins.2021.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Operator selection plays a crucial role in the efficiency of heuristic-based problem solving algorithms, especially, when a pool of operators is used to let algorithms dynamically select operators to produce new candidate solutions. A sequence of selected operators forms up throughout the search which impacts the success of the algorithms. Successive operators in a bespoke sequence can be complementary and therefore diversify the search while randomly selected operators are not expected to behave in this way. State of art adaptive selection schemes have been proposed to select the best next operator without considering the problem state in the process. In this study, a reinforcement learning algorithm is proposed to embed in a standard artificial bee colony algorithm for taking the problem state on board in operator selection process. The proposed approach implies mapping the problem states to the best fitting operators in the pool so as to achieve higher diversity and shape up an optimum operator sequence throughout the search process. The experimental study successfully demonstrates that the proposed idea works towards higher efficiency. The state of art approaches are outperformed with respect to the quality of solution in solving Set Union Knapsack problem over 30 benchmarking instances.},
  archive      = {J_ISCI},
  author       = {Rafet Durgut and Mehmet Emin Aydin and Ibrahim Atli},
  doi          = {10.1016/j.ins.2021.10.025},
  journal      = {Information Sciences},
  pages        = {773-790},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive operator selection with reinforcement learning},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive output feedback tracking for time-delay nonlinear
systems with unknown control coefficient and application to chemical
reactors. <em>ISCI</em>, <em>581</em>, 755–772. (<a
href="https://doi.org/10.1016/j.ins.2021.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of global adaptive output feedback tracking is considered for a class of highly nonlinear time-delay systems with unknown control coefficient and relaxed lower-triangular growth constraints. Based on the non-separation principle, a non-identifier-based adaptive output feedback controller is proposed by designing a novel update law of the dynamic gain in observer and controller. The novel gain can simultaneously compensate the uncertain parameters, the output-polynomial growth rate and the unknown time-varying delay. The proposed controller is well universal attributed to using the non-identification adaptive mechanism, and all design parameters are easy to get by simple calculation. With the help of Lyapunov–Krasovskii functionals and Barbalat’s lemma, it is shown that the solutions of the resulting closed-loop system are globally uniformly ultimately bounded by improving the backstepping design and dynamic high-gain scaling approach; the adaptive tracking is achieved under any small pre-given tracking error. Finally, the effectiveness of the proposed controller is illustrated by two examples.},
  archive      = {J_ISCI},
  author       = {Xianglei Jia and Shengyuan Xu and Xiaocheng Shi and Baozhu Du and Zhengqiang Zhang},
  doi          = {10.1016/j.ins.2021.10.015},
  journal      = {Information Sciences},
  pages        = {755-772},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive output feedback tracking for time-delay nonlinear systems with unknown control coefficient and application to chemical reactors},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuro-inspired edge feature fusion using choquet integrals.
<em>ISCI</em>, <em>581</em>, 740–754. (<a
href="https://doi.org/10.1016/j.ins.2021.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that the human visual system performs a hierarchical information process in which early vision cues (or primitives) are fused in the visual cortex to compose complex shapes and descriptors. While different aspects of the process have been extensively studied, such as lens adaptation or feature detection, some other aspects, such as feature fusion , have been mostly left aside. In this work, we elaborate on the fusion of early vision primitives using generalizations of the Choquet integral , and novel aggregation operators that have been extensively studied in recent years. We propose to use generalizations of the Choquet integral to sensibly fuse elementary edge cues, in an attempt to model the behaviour of neurons in the early visual cortex. Our proposal leads to a fully-framed edge detection algorithm whose performance is put to the test in state-of-the-art edge detection datasets.},
  archive      = {J_ISCI},
  author       = {Cedric Marco-Detchart and Giancarlo Lucca and Carlos Lopez-Molina and Laura De Miguel and Graçaliz Pereira Dimuro and Humberto Bustince},
  doi          = {10.1016/j.ins.2021.10.016},
  journal      = {Information Sciences},
  pages        = {740-754},
  shortjournal = {Inf. Sci.},
  title        = {Neuro-inspired edge feature fusion using choquet integrals},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TWD-r: A three-way decision approach based on regret theory
in multi-scale decision information systems. <em>ISCI</em>,
<em>581</em>, 711–739. (<a
href="https://doi.org/10.1016/j.ins.2021.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a highly prevalent disease, the liver disease is usually diagnosed by testing with several aspects. Due to different accuracies of tests, the obtained results may be different, which may lead to potential errors in diagnosis results. Meanwhile, the psychological behavior and the psychological preference of a decision maker (DM) have a significant influence on decision-making results. Thus, we aim to propose a three-way decision (TWD) approach based on the regret theory (RT) in a multi-scale decision information system (MSDIS), which is named a TWD-R approach. First, by defining a dominating relation and a dominated relation based on the regret-rejoice value of each alternative under each attribute, a novel conditional probability calculation approach is proposed. Second, an objective approach for calculating relative utility functions is proposed to avoid the influence originated from the subjectivity. Third, the key steps and the algorithm of the TWD-R approach are summed up. Finally, the rationality, validity and superiority of the proposed approach are investigated by two cases and some experimental analyses.},
  archive      = {J_ISCI},
  author       = {Xianfeng Huang and Jianming Zhan},
  doi          = {10.1016/j.ins.2021.10.014},
  journal      = {Information Sciences},
  pages        = {711-739},
  shortjournal = {Inf. Sci.},
  title        = {TWD-R: A three-way decision approach based on regret theory in multi-scale decision information systems},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-triggered finite-time h∞ control for markov jump
systems with multiple frequency ranges performance. <em>ISCI</em>,
<em>581</em>, 694–710. (<a
href="https://doi.org/10.1016/j.ins.2021.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present study, a self-triggered finite-time control policy is investigated for Markov jump systems (MJSs) under multiple frequency ranges restrictions. A self-triggered scheme is developed to realize the system in a resource-aware pattern which will fully analyze the effect of transition probability on the characteristics of the finite frequency range. The developed scheme updates the control input of the system through the history of measurements. Then, taking into account several factors such as transient performance, frequency domain specification, and computational burden, a self-triggered finite-time controller is constructed. The developed controller concurrently ensures the predefined disturbance suppression level and the finite-time boundedness of the considered system while decreasing the computational and communication cost. The simulation example of a cart-spring system illustrates the effectiveness and superiority of the proposed approach over existing methods.},
  archive      = {J_ISCI},
  author       = {Haiying Wan and Hamid Reza Karimi and Xiaoli Luan and Fei Liu},
  doi          = {10.1016/j.ins.2021.10.002},
  journal      = {Information Sciences},
  pages        = {694-710},
  shortjournal = {Inf. Sci.},
  title        = {Self-triggered finite-time h∞ control for markov jump systems with multiple frequency ranges performance},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online distributed dual averaging algorithm for multi-agent
bandit optimization over time-varying general directed networks.
<em>ISCI</em>, <em>581</em>, 678–693. (<a
href="https://doi.org/10.1016/j.ins.2021.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with online distributed convex optimization over a multi-agent network, where a swarm of agents attempts to minimize coordinately a sequence of time-changing global loss functions. At per time slot, the global loss function is decomposed into a sum of several local loss functions, each of which is available sequentially and held privately by one agent over the network, and individual agent does not possess prior knowledge of the future global loss function. We are interested in a bandit setting, where only the values of local loss functions at queried points are disclosed to individual agent. Meanwhile, we consider a general multi-agent network where the agents’ communication is represented as a sequence of time-changing unbalanced digraphs and the corresponding weight matrices are only row stochastic. We investigate two bandit scenarios including one- and two-point bandit feedback, and then design two corresponding online distributed bandit algorithms for such a class of problems by exploiting the classical dual averaging method. We show that both algorithms can achieve the sub-linear expected dynamic regret provided that the accumulative variation of the benchmark sequence grows sub-linearly with time. In particular, the bounds of the expected static regret obtained in this paper can reduce the relevant results when restricted to the centralized bandit online convex optimization . In contrast to existing algorithms with gradient feedback, numerical tests verify the competitive performances of the proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Jueyou Li and Xiaomei Zhu and Zhiyou Wu and Tingwen Huang},
  doi          = {10.1016/j.ins.2021.10.003},
  journal      = {Information Sciences},
  pages        = {678-693},
  shortjournal = {Inf. Sci.},
  title        = {Online distributed dual averaging algorithm for multi-agent bandit optimization over time-varying general directed networks},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Y-net: Learning domain robust feature representation for
ground camera image and large-scale image-based point cloud
registration. <em>ISCI</em>, <em>581</em>, 655–677. (<a
href="https://doi.org/10.1016/j.ins.2021.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Registering the 2D images (2D space) with the 3D model of the environment (3D space) provides a promising solution to outdoor Augmented Reality (AR) virtual-real registration. In this work, we use the position and orientation of the ground camera image to synthesize a corresponding rendered image from the outdoor large-scale 3D image-based point cloud. To achieve the virtual-real registration, we indirectly establish the spatial relationship between 2D and 3D space by matching the above two kinds (2D/3D space) of cross-domain images. However, matching cross-domain images goes beyond the capability of handcrafted descriptors and existing deep neural networks . To address this issue, we propose an end-to-end network, Y-Net, to learn Domain Robust Feature Representations (DRFRs) for the cross-domain images. Besides, we introduce a cross-domain-constrained loss function that balances the loss in image content and cross-domain consistency of the feature representations. Experimental results show that the DRFRs simultaneously preserve the representation of image content and suppress the influence of independent domains. Furthermore, Y-Net outperforms the existing algorithms on extracting feature representations and achieves state-of-the-art performance in cross-domain image retrieval . Finally, we validate the Y-Net-based registration approach on campus to demonstrate its possible applicability.},
  archive      = {J_ISCI},
  author       = {Weiquan Liu and Cheng Wang and Shuting Chen and Xuesheng Bian and Baiqi Lai and Xuelun Shen and Ming Cheng and Shang-Hong Lai and Dongdong Weng and Jonathan Li},
  doi          = {10.1016/j.ins.2021.10.022},
  journal      = {Information Sciences},
  pages        = {655-677},
  shortjournal = {Inf. Sci.},
  title        = {Y-net: Learning domain robust feature representation for ground camera image and large-scale image-based point cloud registration},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). User behavior prediction via heterogeneous information in
social networks. <em>ISCI</em>, <em>581</em>, 637–654. (<a
href="https://doi.org/10.1016/j.ins.2021.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of online social networks , user behavior prediction based on the data collected from these social networks has attracted increasing attention. In heterogeneous social networks, a node usually has several heterogeneous attributes to describe itself from different angles. However, most existing methods only utilize an attribute of each node and neglect other heterogeneous attributes. Therefore, this paper proposes a new user heterogeneous information embedding method, called user heterogeneous information embedding (UHIE). This method utilizes the attention mechanism to aggregate the heterogeneous attribute information of each neighbor to obtain their low-dimension representation. Then, the graph neural network is employed to aggregate the multi-relational information from neighbors to obtain the low-dimension representation of nodes. Furthermore, a new soft thresholding method is proposed to eliminate the unimportant information, called multi-head self-attention soft thresholding (MSST), which employs the multi-head self-attention mechanism to calculate an importance threshold for each feature. Based on UHIE and MSST, a new user behavior prediction model is proposed, called Heterogeneous Residual Self-Attention Shrinkage Network (HRSN). This model utilizes UHIE to aggregate heterogeneous information including all heterogeneous attribute information of nodes, and employs MSST to eliminate unimportant information. The experimental results on three real-world datasets show the superiority of the proposed model.},
  archive      = {J_ISCI},
  author       = {Xiangbo Tian and Liqing Qiu and Jianyi Zhang},
  doi          = {10.1016/j.ins.2021.10.018},
  journal      = {Information Sciences},
  pages        = {637-654},
  shortjournal = {Inf. Sci.},
  title        = {User behavior prediction via heterogeneous information in social networks},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Are cluster validity measures (in) valid? <em>ISCI</em>,
<em>581</em>, 620–636. (<a
href="https://doi.org/10.1016/j.ins.2021.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internal cluster validity measures (such as the Calinski–Harabasz, Dunn, or Davies–Bouldin indices) are frequently used for selecting the appropriate number of partitions a dataset should be split into. In this paper we consider what happens if we treat such indices as objective functions in unsupervised learning activities. Is the optimal grouping with regards to, say, the Silhouette index really meaningful? It turns out that many cluster (in)validity indices promote clusterings that match expert knowledge quite poorly. We also introduce a new, well-performing variant of the Dunn index that is built upon OWA operators and the near-neighbour graph so that subspaces of higher density, regardless of their shapes, can be separated from each other better.},
  archive      = {J_ISCI},
  author       = {Marek Gagolewski and Maciej Bartoszuk and Anna Cena},
  doi          = {10.1016/j.ins.2021.10.004},
  journal      = {Information Sciences},
  pages        = {620-636},
  shortjournal = {Inf. Sci.},
  title        = {Are cluster validity measures (in) valid?},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Destroying robust steganography in online social networks.
<em>ISCI</em>, <em>581</em>, 605–619. (<a
href="https://doi.org/10.1016/j.ins.2021.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, some robust steganography approaches for covert transmission in online social networks (OSNs) have been proposed. Some existing image algorithms, such as watermarking removal methods, have been developed to remove the hidden messages that might exist in an uploaded image. However, these methods may result in poor image quality after processing, which is not practical for OSN platforms. In this paper, we propose a general method for destroying robust steganography in OSNs that is able to preserve the image quality. In particular, we design a deep learning network including an attack module and an optimization module, and a new loss function is proposed to consider both. The experimental results indicate that the proposed method can be universally applied tocounter multiple robust steganography algorithms. Furthermore, the resulting processed image can be good quality, and the time cost is sufficiently low to meet most real-time requirements.},
  archive      = {J_ISCI},
  author       = {Zhiying Zhu and Sheng Li and Zhenxing Qian and Xinpeng Zhang},
  doi          = {10.1016/j.ins.2021.10.023},
  journal      = {Information Sciences},
  pages        = {605-619},
  shortjournal = {Inf. Sci.},
  title        = {Destroying robust steganography in online social networks},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution outside the box. <em>ISCI</em>,
<em>581</em>, 587–604. (<a
href="https://doi.org/10.1016/j.ins.2021.09.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates how often the popular configurations of Differential Evolution generate solutions outside the feasible domain. Following previous publications in the field, we argue that what the algorithm does with such solutions and how often this has to happen is important for the overall performance of the algorithm and interpretation of results. Based on observations therein, we conclude that significantly more solutions than what is usually assumed by practitioners need to undergo some sort of ‘correction’ to conform with the definition of the problem’s search domain. A wide range of popular Differential Evolution configurations is considered in this study. Conclusions are made regarding the effect the Differential Evolution components and parameter settings have on the distribution of proportions of infeasible solutions generated in a series of independent runs. Results shown in this study suggest strong dependencies between proportions of generated infeasible solutions and every aspect mentioned above. Further investigation of the distribution of proportions of generated infeasible solutions is required.},
  archive      = {J_ISCI},
  author       = {Anna V. Kononova and Fabio Caraffini and Thomas Bäck},
  doi          = {10.1016/j.ins.2021.09.058},
  journal      = {Information Sciences},
  pages        = {587-604},
  shortjournal = {Inf. Sci.},
  title        = {Differential evolution outside the box},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new interval type-2 fuzzy reasoning method for
classification systems based on normal forms of a possibility-based
fuzzy measure. <em>ISCI</em>, <em>581</em>, 567–586. (<a
href="https://doi.org/10.1016/j.ins.2021.09.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deal with two sources of uncertainty, cluster centers and reasoning aggregation operators, in the inference engine, this paper represents a new fuzzy reasoning method for an interval type-2 fuzzy classification system including cluster-based rules. In the reasoning, a new Possibility-based fuzzy measure is introduced to consider the uncertainty of cluster centers determined by the iterative clustering algorithms (because of the NP-Hardness of clustering models) in an interval type-2 fuzzy rule-based classification system (IT2 FRBCS). Then, the diversity of aggregation operators which are generally applied in reasoning process to combine the matching degrees of a test or unseen pattern with all clusters of an output class is regarded as the other source of reasoning uncertainty extending the crisp matching degrees into the intervals. The disjunctive and conjunctive normal forms of the OR operator for presented fuzzy measure are used as the lower and upper bounds of this interval, respectively. To evaluate the performance of the proposed system, a comparison against some other systems is conducted for 10 data sets. Further, it is applied to a practical problem of classification of generation units’ bidding behavior in the Iranian wholesale electricity market. Experimental results display the superior performance of the proposed system.},
  archive      = {J_ISCI},
  author       = {M. Rostam Niakan Kalhori and M.H. FazelZarandi},
  doi          = {10.1016/j.ins.2021.09.060},
  journal      = {Information Sciences},
  pages        = {567-586},
  shortjournal = {Inf. Sci.},
  title        = {A new interval type-2 fuzzy reasoning method for classification systems based on normal forms of a possibility-based fuzzy measure},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive fuzzy control for uncertain nonlinear systems
subject to full state constraints and actuator faults. <em>ISCI</em>,
<em>581</em>, 553–566. (<a
href="https://doi.org/10.1016/j.ins.2021.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper investigates a theoretical and practical problem of handling a class of uncertain nonlinear systems carrying with full state constrains and actuators failure , where commonly occurs on marine vessel or aircraft. The knowledge of fuzzy logic systems (FLS), barrier Lyapunov functions (BLF) and backstepping technique are fusing to overcome this difficult issue. Fuzzy logic systems for approximating are used to allow more general of the considered systems, while the fuzzy compact set can be easily determined by preset constraints without any prior knowledge. Based on the fuzzy parametrization-like transformed systems, a novel backstepping control scheme is then proposed via constructing a series of barrier Lyapunov functions to finally ensure all the state constraints are not violated and compensate the possible actuator failures. It can be rigorously proved that all the closed-loop signals are globally bounded and the tracking error is guaranteed within a preserved compact set. Simulation results verify the established theoretical conclusion and show the effectiveness of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Xiaohang Su and C.L. Philip Chen and Zhi Liu},
  doi          = {10.1016/j.ins.2021.09.055},
  journal      = {Information Sciences},
  pages        = {553-566},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy control for uncertain nonlinear systems subject to full state constraints and actuator faults},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical classification of data with long-tailed
distributions via global and local granulation. <em>ISCI</em>,
<em>581</em>, 536–552. (<a
href="https://doi.org/10.1016/j.ins.2021.09.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated learning from datasets with a long-tailed distribution has gradually become a research hotspot due to the increasing complexity of large-scale real-world datasets. Existing solutions to long-tailed data classification usually involve re-balancing strategies for global optimization, which can achieve satisfactory results. However, re-balancing strategies tend to alter the original data. In this paper, we propose a knowledge granulation method based on global and local granulation to assist the hierarchical classification of long-tailed data without altering the original data. Firstly, a global classifier is constructed based on the WordNet knowledge organization’s hierarchical structure, which is used to granulate the global data from coarse to fine. Secondly, a local hierarchical classifier adapted to tail data is constructed for tail classes that contain few samples. The hierarchical structure of this local classifier is obtained by granulating the data via spectral clustering rather than by using the semantic hierarchy of classes. Finally, the global classifier is used to preliminarily classify samples, then uncertain samples are further classified by the tail local classifier. Experimental results show that the proposed method outperforms several state-of-the-art models designed for the hierarchical classification of long-tailed data.},
  archive      = {J_ISCI},
  author       = {Hong Zhao and Shunxin Guo and Yaojin Lin},
  doi          = {10.1016/j.ins.2021.09.059},
  journal      = {Information Sciences},
  pages        = {536-552},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical classification of data with long-tailed distributions via global and local granulation},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple histogram based adaptive pairwise prediction-error
modification for efficient reversible image watermarking. <em>ISCI</em>,
<em>581</em>, 515–535. (<a
href="https://doi.org/10.1016/j.ins.2021.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction-error expansion (PEE) based reversible data hiding (RDH) methods mainly contain two steps: prediction-error histogram (PEH) generation and PEH modification . Multiple histograms modification (MHM) and pairwise PEE are two efficient methods used in PEH modification, which can greatly reduce the distortion to the cover image under given payloads. However, these two effective methods are not used together for their conflict on causality and large computational complexity . To address the above two problems, in this paper, a group of non-causal predictors with a specially designed complexity metric are proposed so that the conflict on causality is resolved. Then, the original optimization problem to determine the parameters of MHM and pairwise PEE is decomposed into two easier ones, which are addressed by a step-by-step optimization. Several efficient constraints are used to narrow the search range for the optimal parameters while minimizing the performance degradation . As a result, the proposed method can obtain high quality on the embedded images, that is, the average PSNR of the 8 standard 512 × 512 sized grayscale images from the USC-SIPI image database can reach 60.43 dB for the payload of 10,000 bits, while the running time for the proposed algorithm is acceptable. Experimental results show that the proposed method outperforms many kinds of RDH schemes , and achieves an obvious increment in fidelity over a series of state-of-the-art RDH schemes.},
  archive      = {J_ISCI},
  author       = {Guojun Fan and Zhibin Pan and Quan Zhou and Xinyi Gao and Xiaoran Zhang},
  doi          = {10.1016/j.ins.2021.09.019},
  journal      = {Information Sciences},
  pages        = {515-535},
  shortjournal = {Inf. Sci.},
  title        = {Multiple histogram based adaptive pairwise prediction-error modification for efficient reversible image watermarking},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive hybrid system using deep learning for wind speed
forecasting. <em>ISCI</em>, <em>581</em>, 495–514. (<a
href="https://doi.org/10.1016/j.ins.2021.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The integration of wind power with traditional electricity grids is challenging because of the volatile and intermittent nature of wind speed. Consequently, wind speed forecasting is an essential tool in the energy system because it supports economic, regulation, and operational efficiency issues decisions. The development of systems for accurate wind speed forecasting is a difficult task because it presents linear and nonlinear temporal patterns, and is differently influenced by climate and environmental variables. In this paper, we propose a method to search for the best combination of linear, nonlinear forecasts, and exogenous variables , aiming to increase the accuracy of wind speed forecasting. The proposed method performs: (i) the choice of the linear statistical model to forecast the time series; (ii) the error series modeling using a Long Short-Term Memory model; and (iii) the evolutionary search for the most suitable nonlinear combination of linear and nonlinear forecasts with exogenous variables . The proposed method is assessed using hourly and monthly time series of three stations located in northeast Brazil . The evaluation of the results using two traditional measures shows that the proposed method has a better performance than statistical techniques, Machine Learning models, and state-of-the-art hybrid systems in most series.},
  archive      = {J_ISCI},
  author       = {Paulo S.G. de Mattos Neto and João F.L. de Oliveira and Domingos S. de O. Santos Júnior and Hugo Valadares Siqueira and Manoel H.N. Marinho and Francisco Madeiro},
  doi          = {10.1016/j.ins.2021.09.054},
  journal      = {Information Sciences},
  pages        = {495-514},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive hybrid system using deep learning for wind speed forecasting},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multilingual handwritten numeral recognition using a robust
deep network joint with transfer learning. <em>ISCI</em>, <em>581</em>,
479–494. (<a href="https://doi.org/10.1016/j.ins.2021.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numeral recognition plays a crucial role in creating automated systems such as posting address sorting and license plate recognition . Nowadays, numeral recognition systems which have the capability of recognising multiple languages are highly beneficial due to growing international correspondence and transactions, especially in multilingual countries where several languages are used simultaneously. Therefore, handwritten numeral recognition is more challenging than printed numeral recognition due to having different and complex handwriting styles. Hence, developing a multilingual handwritten system is considered as an important and debatable issue. We address this issue by proposing a language-independent model based on a robust CNN . Our proposed model is composed of language recognition and digit recognition, which aims to handle the recognition of multi-script images. We used transfer-learning in the proposed system to enhance the image quality and consequently the recognition performance. Extensive experiments were conducted to verify the effectiveness of both language and digit recognition procedures. The proposed system was tested with six different languages. The results showed an average accuracy of up to 99.8\% for recognising various languages and the associated digits. The robustness and design procedure of the proposed model created a cost-effective extension for recognition of handwritten numerals in other languages.},
  archive      = {J_ISCI},
  author       = {Amirreza Fateh and Mansoor Fateh and Vahid Abolghasemi},
  doi          = {10.1016/j.ins.2021.09.051},
  journal      = {Information Sciences},
  pages        = {479-494},
  shortjournal = {Inf. Sci.},
  title        = {Multilingual handwritten numeral recognition using a robust deep network joint with transfer learning},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convolution-based linear discriminant analysis for
functional data classification. <em>ISCI</em>, <em>581</em>, 469–478.
(<a href="https://doi.org/10.1016/j.ins.2021.09.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technological advances have allowed for the rise in more reliable and less expensive sensors to collect data over time (e.g., on temperature, heartbeat, and neural activity). Consequently, mathematical methods to examine these time series data have become necessary. One topic of intensive research in time series analysis is supervised classification . For example, biomedical researchers are interested in classifying controls versus people with heart disorders based on electrocardiograms. Several works have adapted Fisher’s linear discriminant analysis (LDA) to work with functional data. However, they have poor performance when a multiplicative random effect model generates the time series; they do not exploit the periodicity of the data. To solve this problem, we propose convolution-based linear discriminant analysis (cLDA). Different from the standard LDA that projects the data into a lower space, cLDA obtains filters. To show the performance of cLDA, we compared it to state-of-the-art methods in simulated and 12 12 empirical datasets. cLDA obtained the lowest classification error rate on average. It showed the ability to classify real-world time series.},
  archive      = {J_ISCI},
  author       = {Grover E. Castro Guzman and Andre Fujita},
  doi          = {10.1016/j.ins.2021.09.057},
  journal      = {Information Sciences},
  pages        = {469-478},
  shortjournal = {Inf. Sci.},
  title        = {Convolution-based linear discriminant analysis for functional data classification},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neural network architecture optimizer based on DARTS and
generative adversarial learning. <em>ISCI</em>, <em>581</em>, 448–468.
(<a href="https://doi.org/10.1016/j.ins.2021.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural network architecture search automatically configures a set of network architectures according to the targeted rules. Thus, it relieves the human-dependent effort and repetitive resources consumption for designing neural network architectures and makes the task of finding the optimum network architecture with better performance much more accessible. Network architecture search methods based on differentiable architecture search (DARTS), however, introduces parameter redundancy . To address this issue, this work presents a novel method for optimizing network architectures that combines DARTS with generative adversarial learning (GAL). We first find the module structures utilizing the DARTS algorithm. Afterwards, the retrieved modules are stacked to derive the initial neural network architecture. Next, the GAL is used to prune some branches of the initial neural network, thereby obtaining the final neural network architecture. The proposed DARTS-GAL method re-optimizes the network architecture searched by DARTS to simplify the network connection and reduce network parameters without compromising network performance. Experimental results on benchmark datasets, i.e., Mixed National Institute of Standards and Technology (MNIST), FashionMNIST, Canadian Institute for Advanced Research10 (CIFAR10), Canadian Institute for Advanced Research100 (CIAFR100), Cats vs Dogs, and voiceprint recognition datasets, indicate that the test accuracies of the DARTS-GAL are higher than those of the DARTS in the majority of the cases. In particular, the proposed solution exhibits an improvement in accuracy by 7.35\% on CIFAR10 compared with DARTS, attaining the state-of-the-art result of 99.60\%. Additionally, the number of network parameters derived by the DARTS-GAL is significantly lower than that by the DARTS method, with a pruning rate of 62.3\% at the highest case.},
  archive      = {J_ISCI},
  author       = {Ting Zhang and Muhammad Waqas and Hao Shen and Zhaoying Liu and Xiangyu Zhang and Yujian Li and Zahid Halim and Sheng Chen},
  doi          = {10.1016/j.ins.2021.09.041},
  journal      = {Information Sciences},
  pages        = {448-468},
  shortjournal = {Inf. Sci.},
  title        = {A neural network architecture optimizer based on DARTS and generative adversarial learning},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient pareto-based feature selection algorithm for
multi-label classification. <em>ISCI</em>, <em>581</em>, 428–447. (<a
href="https://doi.org/10.1016/j.ins.2021.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning algorithms have significant challenges due to high-dimensional feature space and noises in multi-label datasets. Feature selection methods are effective techniques to deal with these problems. ParetoCluster is an effective multi-label feature selection algorithm based on Pareto dominance and cluster analysis concepts which considers each label an objective function. This algorithm loses its effectiveness to differentiate features when dealing with high labeled datasets and makes most features incomparable (e.g., when most features fall into the first layer). Thus, a cluster analysis criterion in ParetoCluster will play a decisive role in determining the most relevant features. Bearing this in mind, in this paper, we have modeled the multi-label feature selection problem into a bi-objective optimization problem regarding the relevancy and redundancy degree of the features. We then handle it using Pareto dominance in this bi-objective domain. To illustrate the optimality and efficiency of the proposed method, we have compared our approach against some similar techniques.},
  archive      = {J_ISCI},
  author       = {Amin Hashemi and Mohammad Bagher Dowlatshahi and Hossein Nezamabadi-pour},
  doi          = {10.1016/j.ins.2021.09.052},
  journal      = {Information Sciences},
  pages        = {428-447},
  shortjournal = {Inf. Sci.},
  title        = {An efficient pareto-based feature selection algorithm for multi-label classification},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QuickDSC: Clustering by quick density subgraph estimation.
<em>ISCI</em>, <em>581</em>, 403–427. (<a
href="https://doi.org/10.1016/j.ins.2021.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density-based clustering is a traditional research topic with the capability of determining clusters of arbitrary shapes. Besides, through the Density Estimator (DE), density-based methods such as MeanShift, and QuickShift can find the local density maximums as Modes that are excellent representatives of the clusters. However, concentrating on the modes only may suffer from the over-segmentation problem. On the other hand, most density-based methods cannot satisfy the scenario requiring partitioning the data samples into exactly K clusters. To overcome these issues, QuickDSC: a novel and efficient clustering algorithm that groups the samples through the Quick Density Subgraph Estimation, is proposed in this work. It firstly identifies the high-density-connected samples as the Density Subgraphs (DSs). And then, the importance of DSs is estimated from two aspects: density and geometric weight. The top- K important DSs are selected as the cluster centers and based on which the cluster memberships of remaining samples are determined. QuickDSC incorporates three crucial clustering attributes: (1) the cluster centroids are modes (as in density-based methods); (2) able to efficiently return results by utilizing the underlying density structure (as in hierarchical clustering methods); and (3) it explicitly returns K clusters (e.g., K -Means, K -Modes). In addition, QuickDSC is theoretically and empirically efficient. It is only slightly slower than classical clustering methods such as K -Means and DBSCAN. Experiments on artificial and real-world datasets demonstrate the advantages of the proposed method, and the clustering quality outperforms the state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Xichen Zheng and Chengsen Ren and Yiyang Yang and Zhiguo Gong and Xiang Chen and Zhifeng Hao},
  doi          = {10.1016/j.ins.2021.09.048},
  journal      = {Information Sciences},
  pages        = {403-427},
  shortjournal = {Inf. Sci.},
  title        = {QuickDSC: Clustering by quick density subgraph estimation},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal attack strategy against fault detectors for linear
cyber-physical systems. <em>ISCI</em>, <em>581</em>, 390–402. (<a
href="https://doi.org/10.1016/j.ins.2021.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the design of false data injection attacks (FDIAs) against fault detectors (FD) for linear cyber-physical systems (CPSs). The purpose of the attacker is to design an stealthy attack scheme such that the defenders cannot detect the faults in time or fail to detect the faults, and at the same time the robustness of the CPS is deteriorated. Unlike the existing optimal attack strategies (OASs) that are established based on sufficient conditions, necessary and sufficient conditions (NASCs) are established to maximize the degradation of the FD performance and robustness of CPS while maintaining stealth. Subsequently, an OAS is constructed by solving coupled backward recursive Riccati difference equations (RDEs). Finally, two simulation examples are employed to show the effectiveness of the designed attack scheme.},
  archive      = {J_ISCI},
  author       = {Xiao-Lei Wang},
  doi          = {10.1016/j.ins.2021.09.042},
  journal      = {Information Sciences},
  pages        = {390-402},
  shortjournal = {Inf. Sci.},
  title        = {Optimal attack strategy against fault detectors for linear cyber-physical systems},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aggregation of fuzzy quasi-metrics. <em>ISCI</em>,
<em>581</em>, 362–389. (<a
href="https://doi.org/10.1016/j.ins.2020.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last years fuzzy (quasi-) metrics and indistinguishability operators have been used as a mathematical tool in order to develop appropriate models useful in applied sciences as, for instance, image processing , clustering analysis and multi-criteria decision making. The both aforesaid similarities allow us to fuzzify the crisp notion of equivalence relation when a certain degree of similarity can be only provided between the compared objects. However, the applicability of fuzzy (quasi-) metrics is reduced because the difficulty of generating examples. One technique to generate new fuzzy binary relations is based on merging a collection of them into a new one by means of the use of a function. Inspired, in part, by the preceding fact, this paper is devoted to study which functions allow us to merge a collection of fuzzy (quasi-) metrics into a single one. We present a characterization of such functions in terms of ∗ ∗ -triangular triplets and also in terms of isotonicity and ∗ ∗ -supmultiplicativity, where ∗ ∗ is a t-norm. We also show that this characterization does not depend on the symmetry of the fuzzy quasi-metrics. The same problem for stationary fuzzy (quasi-) metrics is studied and, as a consequence, characterizations of those functions aggregating fuzzy preorders and indistinguishability operators are obtained.},
  archive      = {J_ISCI},
  author       = {Tatiana Pedraza and Jesús Rodríguez-López and Óscar Valero},
  doi          = {10.1016/j.ins.2020.08.045},
  journal      = {Information Sciences},
  pages        = {362-389},
  shortjournal = {Inf. Sci.},
  title        = {Aggregation of fuzzy quasi-metrics},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive neural control for uncertain switched nonlinear
systems with a switched filter-contained hysteretic quantizer.
<em>ISCI</em>, <em>581</em>, 345–361. (<a
href="https://doi.org/10.1016/j.ins.2021.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper demonstrates an adaptive neural control strategy for the uncertain nonlinear switched systems with dwell time. The unknown nonlinear functions , hysteresis nonlinear and external disturbances are taken into account in this system. A filter-contained hysteretic quantizer is introduced to filter out the high frequency components , leading to a durable solution for the conflict between hysteresis actuator and quantization, that is the hysteresis loop deforms when the input signal goes beyond the boundary. In addition, the adaptive neural network control strategy is developed using backstepping techniques to eliminate external disturbances and unknown nonlinear function. This strategy can guarantee that the tracking error converges to an adjustable field near zero.},
  archive      = {J_ISCI},
  author       = {Licheng Zheng and Zhi Liu and C.L. Philip Chen and Yun Zhang},
  doi          = {10.1016/j.ins.2021.07.023},
  journal      = {Information Sciences},
  pages        = {345-361},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive neural control for uncertain switched nonlinear systems with a switched filter-contained hysteretic quantizer},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel kernel density estimator based on ensemble unbiased
cross-validation. <em>ISCI</em>, <em>581</em>, 327–344. (<a
href="https://doi.org/10.1016/j.ins.2021.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unbiased cross-validation (UCV) is a commonly-used method to calculate the optimal bandwidth for the kernel density estimator (KDE), which estimates the underlying probability density function (PDF) for a given data set. Since the UCV method was proposed, there have been few studies that have pointed out its instability when determining the KDE bandwidth. Following the principle of stability improvement, this paper presents a novel ensemble UCV based KDE (EUCV-KDE), which determines the expectation of an estimated PDF using an ensemble of data-block based UCVs rather than a single data-point based UCV. To derive the optimal bandwidth, a novel objective function is designed for EUCV-KDE by considering the empirical and structural risk of KDE together. We validate the rationality and effectiveness of EUCV-KDE on 10 probability distributions. The experimental results show that EUCV-KDE is convergent as the number of data-block based UCVs increases and can obtain a more stable and better prediction performance than the classical UCV-KDE and the revisited cross-validation (RCV) based KDE (RCV-KDE). In addition, a real-world application based on UK climate data is provided to further validate the effectiveness of EUCV-KDE by determining the optimal bandwidth for Nadaraya-Watson kernel regression estimator .},
  archive      = {J_ISCI},
  author       = {Yu-Lin He and Xuan Ye and De-Fa Huang and Joshua Zhexue Huang and Jun-Hai Zhai},
  doi          = {10.1016/j.ins.2021.09.045},
  journal      = {Information Sciences},
  pages        = {327-344},
  shortjournal = {Inf. Sci.},
  title        = {Novel kernel density estimator based on ensemble unbiased cross-validation},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A cluster-based immune-inspired algorithm using manifold
learning for multimodal multi-objective optimization. <em>ISCI</em>,
<em>581</em>, 304–326. (<a
href="https://doi.org/10.1016/j.ins.2021.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both problem characteristics in multimodality and multi-objective are involved in multimodal multi-objective optimization problems (MMOPs). How to locate diverse Pareto sets and approximate Pareto front simultaneously is a challenging research topic. To address this issue, a cluster-based immune-inspired algorithm using manifold learning is proposed in this paper for solving MMOPs. First of all, the population is partitioned into multiple subpopulations, and each of them is expected to find equivalent Pareto solutions in different regions. Subsequently, the immune-inspired algorithm with proportional cloning and hypermutation is developed for improving the diversity of the population and obtaining high-quality Pareto solutions in the decision space. Additionally, principal component analysis is adopted to learn the manifold of the Pareto set, further improve the convergence, and enhance interaction among subpopulations. The proposed algorithm is compared with six state-of-the-art algorithms. Experimental results demonstrate that the proposed algorithm is capable of locating equivalent Pareto optimal solutions in the decision space and maintaining the diversity and convergence of solutions in both decision space and objective space, simultaneously.},
  archive      = {J_ISCI},
  author       = {Weiwei Zhang and Ningjun Zhang and Weizheng Zhang and Gary G. Yen and Guoqing Li},
  doi          = {10.1016/j.ins.2021.09.043},
  journal      = {Information Sciences},
  pages        = {304-326},
  shortjournal = {Inf. Sci.},
  title        = {A cluster-based immune-inspired algorithm using manifold learning for multimodal multi-objective optimization},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relationships between symmetry-based graph measures.
<em>ISCI</em>, <em>581</em>, 291–303. (<a
href="https://doi.org/10.1016/j.ins.2021.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of comparing different measures of graph symmetry. Two measures, each based on the number and respective sizes of the vertex orbits of the automorphism group or a graph, are compared. A real valued distance measure is used to compare the symmetry measures by establishing the limiting value of the distances for several well known classes of graphs.},
  archive      = {J_ISCI},
  author       = {Yuede Ma and Matthias Dehmer and Urs-Martin Künzi and Abbe Mowshowitz and Shailesh Tripathi and Modjtaba Ghorbani and Frank Emmert-Streib},
  doi          = {10.1016/j.ins.2021.09.029},
  journal      = {Information Sciences},
  pages        = {291-303},
  shortjournal = {Inf. Sci.},
  title        = {Relationships between symmetry-based graph measures},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task learning for spatial events prediction from
social data. <em>ISCI</em>, <em>581</em>, 278–290. (<a
href="https://doi.org/10.1016/j.ins.2021.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning is becoming more popular and is being applied in a variety of applications. It improves the accuracy of prediction by simultaneously learning related tasks and saves cost through shared structures. In particular, the prediction of event type from social data is also an area where multi-task learning can be utilized. In this paper, we present a novel deep learning framework called S patial E vents P rediction ( SEP ) based on multi-task learning to predict the types of events that happen at a specific location from social data. The proposed model focuses on predicting the attribute types of an event, which is referred to as subtypes. Specifically, an event type-specific attention mechanism is introduced to extract the representations of social data and to identify their important components. The proposed attention mechanism is based on a two-level attention, which measures the importance of words and sentences to the subtypes of an event. We also propose a representation sharing method using semantic and spatial relationships between locations to alleviate the sparsity and incompleteness of data. The proposed representation sharing preserves the spatial heterogeneity between locations and significantly improves the accuracy of the overall framework. Experiments with real-world datasets confirm the effectiveness and efficiency of the proposed method.},
  archive      = {J_ISCI},
  author       = {Sungkwang Eom and Byungkook Oh and Sangjin Shin and Kyong-Ho Lee},
  doi          = {10.1016/j.ins.2021.09.049},
  journal      = {Information Sciences},
  pages        = {278-290},
  shortjournal = {Inf. Sci.},
  title        = {Multi-task learning for spatial events prediction from social data},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A gaussian mixture model based virtual sample generation
approach for small datasets in industrial processes. <em>ISCI</em>,
<em>581</em>, 262–277. (<a
href="https://doi.org/10.1016/j.ins.2021.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to small-quantity and often imbalance of labeled samples, it is challenging to establish a robust and accurate prediction model through data-driven methods. To deal with the small dataset problem, new virtual samples may be generated via virtual sample generation (VSG) methods based on the trend of the original small raw dataset, thereby improving modeling performance. Effective VSG is desirable, but also challenging. Conventional VSG usually assumes that the raw sample set contains only a single operating mode. Taking multi-mode into account will improve the VSG based modeling performance since actual processes are often multi-mode. To this end, an information expansion function considering sample density and amount (IEDA) is first developed to expand the domain range of the attributes in this paper. Then, virtual samples under the multiple operating mode condition are generated by proposing a Gaussian mixture model based virtual sample generation (GMMVSG) method. Applications of GMMVSG on Tennessee Eastman benchmark process and an industrial hydrocracking process show significant improvement of modeling and predictions over other conventional VSG methods.},
  archive      = {J_ISCI},
  author       = {Ling Li and Seshu Kumar Damarla and Yalin Wang and Biao Huang},
  doi          = {10.1016/j.ins.2021.09.014},
  journal      = {Information Sciences},
  pages        = {262-277},
  shortjournal = {Inf. Sci.},
  title        = {A gaussian mixture model based virtual sample generation approach for small datasets in industrial processes},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalization bottleneck in deep metric learning.
<em>ISCI</em>, <em>581</em>, 249–261. (<a
href="https://doi.org/10.1016/j.ins.2021.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep metric learning aims to learn a non-linear function that maps raw-data to a discriminative lower-dimensional embedding space, where semantically similar samples have larger similarity than dissimilar ones. Most existing approaches process each raw-data in two steps, by mapping the raw-data to a higher-dimensional feature space via a fixed backbone, followed by mapping the higher-dimensional feature space to a lower-dimensional embedding space via a linear layer. This paradigm, however, inevitably leads to a Generalization Bottleneck (GB) problem. Specifically, GB refers to a limitation that the generalization capacity of lower-dimensional embedding space is inferior to the higher-dimensional feature space in the test stage. To mitigate the capacity gap between feature space and embedding space, we propose to introduce a fully-learnable module, dubbed Relational Knowledge Preserving (RKP), that improves the generalization capacity of lower-dimensional embedding space by transferring the mutual similarity of instances. Our proposed RKP module can be integrated into a general deep metric learning approach. And, experiments conducted on different benchmarks show that it can significantly improve the performance of original model.},
  archive      = {J_ISCI},
  author       = {Zhanxuan Hu and Danyang Wu and Feiping Nie and Rong Wang},
  doi          = {10.1016/j.ins.2021.09.023},
  journal      = {Information Sciences},
  pages        = {249-261},
  shortjournal = {Inf. Sci.},
  title        = {Generalization bottleneck in deep metric learning},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective evolutionary 3D face reconstruction based on
improved encoder–decoder network. <em>ISCI</em>, <em>581</em>, 233–248.
(<a href="https://doi.org/10.1016/j.ins.2021.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) face application has attracted significant attention the field of multimedia and image processing . However, the end-to-end 3D face reconstruction method is still immature, and there are some problems, such as overfitting caused by too few training sets and unacceptable 3D face texture alignment performance. Therefore, we design a novel approach to construct a 3D face, named multi-objective evolutionary 3D face reconstruction based on improved encoder–decoder network (MoEDN). This study introduces a regularization algorithm named feature map distortion (Disout); whose purpose is to strengthen the network generalization ability . Based on this, we construct a multi-objective evolutionary 3D face reconstruction model, in which decision variables are distortion probability , distorted block size, distorted intensity, probability step, and learning rate ; and objective functions are loss and structural similarity (SSIM). We use four multi-objective evolutionary algorithms (NSGA-II, AGEII, NSLS, and MOEA/D) to optimize the proposed model. Experimental results demonstrate that NSLS has the best performance. In addition, compared with position map regression network (PRNet), 2D-assisted self-supervised learning (2DASL) and other state-of-the-art, the proposed model achieves better loss values and NME values. Therefore, the proposed multi-objective evolutionary 3D face reconstruction model has outstanding 3D facial reconstruction performance in large poses and face expression.},
  archive      = {J_ISCI},
  author       = {Xingjuan Cai and Yihao Cao and Yeqing Ren and Zhihua Cui and Wensheng Zhang},
  doi          = {10.1016/j.ins.2021.09.024},
  journal      = {Information Sciences},
  pages        = {233-248},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective evolutionary 3D face reconstruction based on improved encoder–decoder network},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Serial-EMD: Fast empirical mode decomposition method for
multi-dimensional signals based on serialization. <em>ISCI</em>,
<em>581</em>, 215–232. (<a
href="https://doi.org/10.1016/j.ins.2021.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Empirical mode decomposition (EMD) has developed into a prominent tool for adaptive, scale-based signal analysis in various fields like robotics, security and biomedical engineering. Since the dramatic increase in amount of data puts forward higher requirements for the capability of real-time signal analysis, it is difficult for existing EMD and its variants to trade off the growth of data dimension and the speed of signal analysis. In order to decompose multi-dimensional signals at a faster speed, we present a novel signal-serialization method (serial-EMD), which concatenates multi-variate or multi-dimensional signals into a one-dimensional signal and uses various one-dimensional EMD algorithms to decompose it. To verify the effects of the proposed method, synthetic multi-variate time series, artificial 2D images with various textures and real-world facial images are tested. Compared with existing multi-EMD algorithms, the decomposition time becomes significantly reduced. In addition, the results of facial recognition with Intrinsic Mode Functions (IMFs) extracted using our method can achieve a higher accuracy than those obtained by existing multi-EMD algorithms, which demonstrates the superior performance of our method in terms of the quality of IMFs. Furthermore, this method can provide a new perspective to optimize the existing EMD algorithms, that is, transforming the structure of the input signal rather than being constrained by developing envelope computation techniques or signal decomposition methods. In summary, the study suggests that the serial-EMD technique is a highly competitive and fast alternative for multi-dimensional signal analysis.},
  archive      = {J_ISCI},
  author       = {Jin Zhang and Fan Feng and Pere Marti-Puig and Cesar F. Caiafa and Zhe Sun and Feng Duan and Jordi Solé-Casals},
  doi          = {10.1016/j.ins.2021.09.033},
  journal      = {Information Sciences},
  pages        = {215-232},
  shortjournal = {Inf. Sci.},
  title        = {Serial-EMD: Fast empirical mode decomposition method for multi-dimensional signals based on serialization},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent machine learning in self-organizing systems.
<em>ISCI</em>, <em>581</em>, 194–214. (<a
href="https://doi.org/10.1016/j.ins.2021.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a novel insight and procedure that includes a variety of algorithms for finding the best solution in a structured multi-agent system with internal communications and a global purpose. In other words, it finds the optimal communication structure among agents and the optimal policy in this structure. First, a unique reinforcement learning algorithm is proposed to find the optimal policy of each agent in a fixed structure with non-linear function approximators like artificial neural networks (ANN) and with eligibility traces. Secondly, a mechanism is presented to perform self-organization based on the information of the learned policy. Finally, an algorithm that can discover an appropriate inter-structure mapping and then can transfer the previous knowledge to the new structure is developed, which increases the speed of the learning in this new environment after self-organization. This paper is one of the first works that analyzes the problem fully theoretically and devises some algorithms to find the best solution. We use a simplified version of the distributed task allocation problem (DTAP) as our case study. The experimental results verify the stability of our approach and show the high speed of finding the optimal solution as a result of using transfer learning .},
  archive      = {J_ISCI},
  author       = {Ehsan Hejazi},
  doi          = {10.1016/j.ins.2021.09.013},
  journal      = {Information Sciences},
  pages        = {194-214},
  shortjournal = {Inf. Sci.},
  title        = {Multi-agent machine learning in self-organizing systems},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint extraction of entities and relations via an entity
correlated attention neural model. <em>ISCI</em>, <em>581</em>, 179–193.
(<a href="https://doi.org/10.1016/j.ins.2021.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition and relation extraction are crucial tasks in natural language processing . As the traditional pipelined manners may suffer from the error propagation issue and ignore underlying interactions, joint extraction of entities and relations has become the dominant trend. However, the performance of existing joint extraction models needs improvement. This paper presents a two-stage tagging scheme that separately labels candidate head entities and multiple tail entities in specific relations. Next, it proposes a novel lightweight joint extraction neural model based on the entity-first labeling strategy. In the proposed model, the BiLSTM-based encoder combines the hidden state and global context features and feeds them as input for the next two entity labeling tasks. Further, with the input of the mixed context representation, the candidate-head-entity recognition module is adopted to identify the candidate head entity, while the multiple-tail-entities recognition module is equipped with an entity-correlated attention mechanism to identify the corresponding tail entity under a specific head entity. Comprehensive experiments on two widely used English datasets and one self-constructed Chinese dataset were performed. The experimental results showed that the proposed model outperformed the baseline approaches in the relation extraction task and achieved a competitive entity recognition effect via a lightweight architecture.},
  archive      = {J_ISCI},
  author       = {Ren Li and Dong Li and Jianxi Yang and Fangyue Xiang and Hao Ren and Shixin Jiang and Luyi Zhang},
  doi          = {10.1016/j.ins.2021.09.028},
  journal      = {Information Sciences},
  pages        = {179-193},
  shortjournal = {Inf. Sci.},
  title        = {Joint extraction of entities and relations via an entity correlated attention neural model},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair clustering with fair correspondence distribution.
<em>ISCI</em>, <em>581</em>, 155–178. (<a
href="https://doi.org/10.1016/j.ins.2021.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the issue of fairness has become important in the field of machine learning . In clustering problems , fairness is defined in terms of consistency in that the balance ratio of data with different sensitive attribute values remains constant for each cluster. Fairness problems are important in real-world applications, for example, when the recommendation system provides targeted advertisements or job offers based on the clustering result of candidates, the minority group may not get the same level of opportunity as the majority group if the clustering result is unfair. In this study, we propose a novel distribution-based fair clustering approach . Considering a distribution in which the sample is biased by society, we try to find clusters from a fair correspondence distribution. Our method uses the support vector method and a dynamical system to comprehensively divide the entire data space into atomic cells before reassembling them fairly to form the clusters. Theoretical results derive the upper bound of the generalization error of the corresponding clustering function in the fair correspondence distribution when atomic cells are connected fairly, allowing us to present an algorithm to achieve fairness. Experimental results show that our algorithm beneficially increases fairness while reducing computation time for various datasets.},
  archive      = {J_ISCI},
  author       = {Woojin Lee and Hyungjin Ko and Junyoung Byun and Taeho Yoon and Jaewook Lee},
  doi          = {10.1016/j.ins.2021.09.010},
  journal      = {Information Sciences},
  pages        = {155-178},
  shortjournal = {Inf. Sci.},
  title        = {Fair clustering with fair correspondence distribution},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise-robust deep cross-modal hashing. <em>ISCI</em>,
<em>581</em>, 136–154. (<a
href="https://doi.org/10.1016/j.ins.2021.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal hashing has been intensively studied to efficiently retrieve multi-modal data across modalities. Supervised cross-modal hashing methods leverage the labels of training data to improve the retrieval performance. However, most of these methods still assume that the semantic labels of training data are ideally complete and noise-free. This assumption is too optimistic for real multi-modal data, whose label annotations are, in essence, error-prone. To achieve effective cross-modal hashing on multi-modal data with noisy labels, we introduce an end-to-end solution called Noise-robust Deep Cross-modal Hashing (NrDCMH). NrDCMH contains two main components: a noise instance detection module and a hash code learning module. In the noise detection module, NrDCMH firstly detects noisy training instance pairs based on the margin between the label similarity and feature similarity, and specifies weights to pairs using the margin. In the hash learning module, NrDCMH incorporates the weights into a likelihood loss function to reduce the impact of instances with noisy labels and to learn compatible deep features by applying different neural networks on multi-modality data in a unified end-to-end framework. Experimental results on multi-modal benchmark datasets demonstrate that NrDCMH performs significantly better than competitive methods with noisy label annotations. NrDCMH also achieves competitive results in ‘noise-free’ scenarios.},
  archive      = {J_ISCI},
  author       = {Runmin Wang and Guoxian Yu and Hong Zhang and Maozu Guo and Lizhen Cui and Xiangliang Zhang},
  doi          = {10.1016/j.ins.2021.09.030},
  journal      = {Information Sciences},
  pages        = {136-154},
  shortjournal = {Inf. Sci.},
  title        = {Noise-robust deep cross-modal hashing},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach of three-way decisions with information
interaction strategy for intelligent decision making under uncertainty.
<em>ISCI</em>, <em>581</em>, 106–135. (<a
href="https://doi.org/10.1016/j.ins.2021.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective tool to deal with uncertain decision-making, three-way decisions (TWD) have gained wide attention in many applications. Decision-theoretic rough sets (DTRSs) as a classic model of TWD contain two key elements, i.e., conditional probability and loss functions. In this paper, we study the determination of these two elements in depth via the information interaction and modification strategy, and further propose a novel model of TWD. First, fuzzy c-means (FCM) is used to cluster the condition attribute information and loss function information, respectively. Considering the interaction of two types of information, we design the corresponding fusion tactic of these clustering results to get equivalent classes and develop a new calculation method of conditional probability . Then, we use probabilistic hesitant fuzzy sets (P-HFSs) to aggregate the loss functions of different members of the same equivalence class and get the probabilistic hesitant fuzzy elements (P-HFEs) loss functions. In this case, P-HFSs not only reflect the hesitant situation of decision-makers, but also depict the proportion of different opinions. Regarding P-HFEs loss functions, we also investigate the modification methods of its outliers in detail. Moreover, based on the P-HFEs loss functions, we propose TWD with probabilistic hesitant fuzzy decision-theoretic rough sets (P-HFDTRSs). Finally, in order to verify the effectiveness of our proposed method, we develop a series of comparative experiments and discuss the decision results on six UCI datasets.},
  archive      = {J_ISCI},
  author       = {Decui Liang and Mingwei Wang and Zeshui Xu},
  doi          = {10.1016/j.ins.2021.09.037},
  journal      = {Information Sciences},
  pages        = {106-135},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach of three-way decisions with information interaction strategy for intelligent decision making under uncertainty},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance-aware optimization model for influential nodes
identification in social networks with independent cascade diffusion.
<em>ISCI</em>, <em>581</em>, 88–105. (<a
href="https://doi.org/10.1016/j.ins.2021.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence maximization (IM) is a challenge in social networks, which depends on the spreader selection. We propose a quadratic programming model to identify a fixed number of initial spreaders to affect the maximum nodes within the minimum diffusion time . We solve this model using a new Distance Aware Spreader Finding (DASF) algorithm independent of the community detection problem. On large-scale social networks, DASF selects anchor nodes by a novel threshold. Then a social distance is defined between anchor nodes via random walk processes . This distance is regularized by the neighborhood degree. Our model finds influential spreaders under the Independent Cascade (IC) diffusion model . It implicitly maximizes the local coverage of spreaders and minimizes the global overlap. We extract the solution of this bi-objective model by finding the principal eigenvector of the regularized distance matrix . Comparing DASF with nine algorithms on various large-scale social networks indicates that DASF performs well based on the influence spread and diffusion rate criteria. The robustness of DASF is also acceptable dealing with different noisy scenarios.},
  archive      = {J_ISCI},
  author       = {Neda Binesh and Mehdi Ghatee},
  doi          = {10.1016/j.ins.2021.09.017},
  journal      = {Information Sciences},
  pages        = {88-105},
  shortjournal = {Inf. Sci.},
  title        = {Distance-aware optimization model for influential nodes identification in social networks with independent cascade diffusion},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evolving concept in the identification of an interval
fuzzy model of wiener-hammerstein nonlinear dynamic systems.
<em>ISCI</em>, <em>581</em>, 73–87. (<a
href="https://doi.org/10.1016/j.ins.2021.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new approach for identifying interval fuzzy models, which enables estimating fuzzy model structures, parameters, and upper and lower bounds simultaneously and online. It is based on a filtered recursive least squares method combined with an incrementally evolving Gaussian clustering. The proposed method generates interval fuzzy models online, on the fly, and in an evolving manner. This means that the algorithm starts with no a priori information , evolves the structure of the model, adjusts the model parameters simultaneously, and computes the upper and lower intervals simultaneously. The fuzzy partitioning of the input–output data space is based on the eGauss + method; the parameters of the local linear models, which together form the fuzzy model, are determined using a recursive least squares method. The interval fuzzy model, used in a predictive manner as a single or multi-level predictor, can be successfully applied in on-line monitoring, fault detection , and the control of dynamic systems. The proposed identification procedure was used to identify the fuzzy interval model of two different processes: a simplified Hammerstein-type nonlinear dynamic process and a realistic industrial continuously stirred tank reactor. The main contribution and advantage of the proposed new method is the identification of an interval fuzzy model in an online manner, which means that the structural and parametric identification of nonlinear systems is done simultaneously and from the data stream. The structural and parametric uncertainties are modeled and integrated into the upper and lower fuzzy models, which form the fuzzy interval in which the measured data samples of the process output are located with a certain probability . The approach is limited to processes that have Wiener-Hammerstein structures.},
  archive      = {J_ISCI},
  author       = {Igor Škrjanc},
  doi          = {10.1016/j.ins.2021.09.004},
  journal      = {Information Sciences},
  pages        = {73-87},
  shortjournal = {Inf. Sci.},
  title        = {An evolving concept in the identification of an interval fuzzy model of wiener-hammerstein nonlinear dynamic systems},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-aware seq2seq translation model for sequential
recommendation. <em>ISCI</em>, <em>581</em>, 60–72. (<a
href="https://doi.org/10.1016/j.ins.2021.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context information, such as product category, plays a vital role in sequential recommendations. Recently, there has been a growing interest in context-aware sequential recommender systems . However, in previous studies, contexts have often been treated as auxiliary information without the consideration of the inter-sequence dependency between the item sequence and the context sequence . Such a dependency provides valuable details for predicting a user’s future behavior. For example, a user may buy electronic accessories after buying an electronic product. In this paper, we propose a context-aware seq2seq translation model to capture the inter-sequence dependency for sequential recommendations. The key component in our model is a tripled seq2seq translation architecture with an injected variational autoencoder (VAE). The tripled architecture, consisting of forward and backward translation, naturally encodes bi-directional inter-sequence dependency. Moreover, the injected VAE enables the translation process to redress the semantic imbalance between context and item. We conduct extensive experiments on four real-world datasets. The results show the superior performance of our model over the state-of-the-art baselines. The code and datasets are available at https://github.com/NLPWM-WHU/CAST .},
  archive      = {J_ISCI},
  author       = {Ke Sun and Tieyun Qian and Xu Chen and Ming Zhong},
  doi          = {10.1016/j.ins.2021.09.001},
  journal      = {Information Sciences},
  pages        = {60-72},
  shortjournal = {Inf. Sci.},
  title        = {Context-aware seq2seq translation model for sequential recommendation},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive ECG annotation: An artificial intelligence
method for smart ECG manipulation. <em>ISCI</em>, <em>581</em>, 42–59.
(<a href="https://doi.org/10.1016/j.ins.2021.08.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An electrocardiogram (ECG) consists of complex segments, such as P-QRS-T waves. Manual ECG annotation is challenging and time-consuming, even for specialist physicians. The shortage of labelled ECG data is one of the essential factors that affect ECG intelligent analysis&#39;s long-term development. This study proposes an intelligent ECG-assisted annotation system, that not only supplements labelled data, but also significantly reduces the workload compared with manual annotation. Since beat annotation is the most basic and important part, a GAN-based generation model that can generate 14 types of simulation beats and a CNN-based beat pre-annotation model are proposed. The experimental results show that the simulation beat has high similarity to real beat and the accuracy of the pre-annotation model on the test set of 14 classes of beats is 99.28\%. The proposed ECG intelligent annotation system&#39;s self-learning mechanism could improve pre-annotation performance and annotation efficiency by generating more labelled data. The proposed annotation system can also be extended to other data annotation applications.},
  archive      = {J_ISCI},
  author       = {Haiyan Wang and Yanjie Zhou and Bing Zhou and Xiangdong Niu and Hua Zhang and Zongmin Wang},
  doi          = {10.1016/j.ins.2021.08.095},
  journal      = {Information Sciences},
  pages        = {42-59},
  shortjournal = {Inf. Sci.},
  title        = {Interactive ECG annotation: An artificial intelligence method for smart ECG manipulation},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The dynamics and control of 2I2SR rumor spreading models in
multilingual online social networks. <em>ISCI</em>, <em>581</em>, 18–41.
(<a href="https://doi.org/10.1016/j.ins.2021.08.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks (OSNs), as multilingual communication platforms, provide great convenience for rumor spreading. However, a great deal of negative impacts on individuals, society and economy will be caused during the spread of rumor. In order to explore the rules of rumor propagation on online social networks and formulate the corresponding control strategies, in this paper, we propose new 2I2SR rumor propagation models with and without time-delay based on multilingual environment. Firstly, we calculate the basic reproduction number which completely determines the local and global stability of the rumor free equilibrium . Secondly, our theoretical analysis reveals the existence and stability of the rumor equilibria, and some critical conditions are obtained for the existence of Hopf bifurcation by selecting critical parameters and delay as bifurcation parameters . Furthermore, by using Pontryagin’s Maximum principle, a real-time optimization method that minimizes the cost of restraining rumor is proposed to eliminate the rumor within an expected time period. Finally, some numerical simulations and a practical application are given to prove the correctness of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Shuzhen Yu and Zhiyong Yu and Haijun Jiang and Shuai Yang},
  doi          = {10.1016/j.ins.2021.08.096},
  journal      = {Information Sciences},
  pages        = {18-41},
  shortjournal = {Inf. Sci.},
  title        = {The dynamics and control of 2I2SR rumor spreading models in multilingual online social networks},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relative entropy of z-numbers. <em>ISCI</em>, <em>581</em>,
1–17. (<a href="https://doi.org/10.1016/j.ins.2021.08.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world information is characterized by uncertainty and partial reliability. In order to model this information, Zadeh introduced the concept of Z-numbers. It has been a challenge to construct a mathematical model to handle Z-number-based information similar to probability theory . One of the basic concepts in probability theory is relative entropy , also known as Kullback–Leibler divergence and information divergence, which is directed divergence between two probability distributions. In this work, we propose an approach for the development of the concept of relative entropy of Z-numbers. It is based on the essence of Z-numbers, maximum entropy method and the relative entropy of probability distributions. Based on the proposed relative entropy, we construct a novel Technique for Order of Preference by Similarity to Ideal Solution based on the Z-numbers (Z-TOPSIS) method, which directly calculates Z-numbers instead of converting them to fuzzy numbers. A case study of supplier selection is then used to illustrate the effectiveness of our proposed Z-TOPSIS method.},
  archive      = {J_ISCI},
  author       = {Yangxue Li and Danilo Pelusi and Yong Deng and Kang Hao Cheong},
  doi          = {10.1016/j.ins.2021.08.077},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Relative entropy of Z-numbers},
  volume       = {581},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Investigation on stability of delayed t-s fuzzy
interconnected systems via decentralized memory-based sampled-data
control and validation through interconnected power systems with
DFIG-based wind turbines. <em>ISCI</em>, <em>580</em>, 934–952. (<a
href="https://doi.org/10.1016/j.ins.2021.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the stability of nonlinear interconnected systems (ISs) with time-delays by designing a decentralized memory-based sampled-data control and it’s an application to power system with doubly fed induction generator (DFIG)-based wind turbines (WTs). Initially, a nonlinear delayed IS is expressed as a delayed Takagi-Sugeno fuzzy ISs based on fuzzy IF-THEN membership rules. Following that, a decentralized sampled-data controller with a memory parameter is designed to ensure the stabilization of the considered ISs. Through constructing Lyapunov-Krasovskii functional by involving the information about the time-delays and sampling periods, delay-dependent stability and stabilization conditions are derived in terms of linear matrix inequalities . The sufficient conditions are guaranteed the asymptotic stability of the closed-loop ISs under a prescribed level of H ∞ performance via a decentralized controller. To validate the derived theoretical sufficient conditions, a nonlinear interconnected power systems with DFIG-based WTs is modeled in which a time-delay is considered in the area control error (ACE). Finally, simulation results of the two area ISs are provided to illustrate the effectiveness of the derived theoretical conditions under the designed controller.},
  archive      = {J_ISCI},
  author       = {Lakshmanan Shanmugam and Young Hoon Joo},
  doi          = {10.1016/j.ins.2021.10.020},
  journal      = {Information Sciences},
  pages        = {934-952},
  shortjournal = {Inf. Sci.},
  title        = {Investigation on stability of delayed T-S fuzzy interconnected systems via decentralized memory-based sampled-data control and validation through interconnected power systems with DFIG-based wind turbines},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-models and dual-sampling periods quality prediction
with time-dimensional k-means and state transition-LSTM network.
<em>ISCI</em>, <em>580</em>, 917–933. (<a
href="https://doi.org/10.1016/j.ins.2021.09.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In most of industrial processes, there are mainly two issues: 1. working models will be different at different time (multi-models); 2. different variables have different sampling periods (dual-sampling periods), in which the sampling period of the difficult-to-measure variable is larger than the easy-to-measure variable in most cases. Typically, the K-means and the long short-term memory (LSTM) network can be used to solve these two issues. However, the K-means only considers the spatial-dimensional distance, and most existing works based on the LSTM network mainly focus on the single sampling period quality prediction, in which all variables have a same sampling period. To overcome these shortcomings and improve the predicted accuracy and flexibility, a novel soft sensor: state transition-long short-term memory network with time-dimensional K-means (ST-LSTM with TK-means) is proposed. In the TK-means, a new nonlinear time-dimensional distance is added to make the clustering result more reasonable. Then, in the ST-LSTM network, the idea of the state transition model is introduced. Therefore, the ST-LSTM network can solve the issue of dual-sampling periods quality prediction. By comparing with several state-of-the-art methods, it is shown that the proposed ST-LSTM with TK-means can make a great improvement in the aspects of predicted accuracy and flexibility.},
  archive      = {J_ISCI},
  author       = {Xiongtao Shi and Yonggang Li and Yanhua Yang and Bei Sun and Fang Qi},
  doi          = {10.1016/j.ins.2021.09.056},
  journal      = {Information Sciences},
  pages        = {917-933},
  shortjournal = {Inf. Sci.},
  title        = {Multi-models and dual-sampling periods quality prediction with time-dimensional K-means and state transition-LSTM network},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An approach for enforcing a class of GMECs on time petri
nets with uncontrollable transitions. <em>ISCI</em>, <em>580</em>,
897–916. (<a href="https://doi.org/10.1016/j.ins.2021.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time control is of great significance for practical plants such as intelligent manufacturing systems and transportation systems, and timing information should be integrated in their discrete models. The existing specifications expressed by generalized mutual exclusion constraints (GMECs) do not consider timing specifications in the control design of these models, which would be restrictive for the control specifications of a timed system. In the framework of time Petri net (TPN) models, this paper introduces a class of GMECs, called time GMECs (TGMECs), in which each GMEC is associated with a restricted time interval . By restricting the firing intervals of controllable transitions, an efficient method based on control functions is proposed to implement TGMECs on a TPN system in presence of uncontrollable transitions. The core of the reported method is to employ the transitions-related timing constraints in a partial modified state class graph (PMSCG) to solve mathematical programming problems. Such a PMSCG is a graph recently introduced to enhance the supervisor permissiveness for a TPN system with GMECs. In particular, the terminal condition for the construction of a PMSCG is modified. By taking advantage of the PMSCG, an online control procedure is presented to implement the supervision for TGMECs in a maximally permissive way.},
  archive      = {J_ISCI},
  author       = {Liang Li and Zhiwu Li and Jipeng Wang},
  doi          = {10.1016/j.ins.2021.09.047},
  journal      = {Information Sciences},
  pages        = {897-916},
  shortjournal = {Inf. Sci.},
  title        = {An approach for enforcing a class of GMECs on time petri nets with uncontrollable transitions},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary multi-task optimization with hybrid knowledge
transfer strategy. <em>ISCI</em>, <em>580</em>, 874–896. (<a
href="https://doi.org/10.1016/j.ins.2021.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging research paradigm in the field of evolutionary computation, evolutionary multi-task optimization (EMTO) has received an increasing amount of attention due to its capability in concurrently solving multiple related optimization tasks. In EMTO , without any prior knowledge about the complementarity between different tasks, the task relatedness is mainly captured dynamically through the evolving population. However, how to transfer the knowledge across tasks in accordance with different degrees of relatedness as the search proceeds has received little visibility. To address this issue and further enhance the performance of EMTOs, this paper proposes a hybrid knowledge transfer (HKT) strategy. In HKT, a population distribution-based measurement (PDM) technique is designed to evaluate the task relatedness based on the distribution characteristics of the evolving population, and then a multi-knowledge transfer (MKT) mechanism is employed to conduct multiple strategies of knowledge transfer according to the degree of relatedness between tasks. By incorporating the HKT strategy into EMTO, the resultant algorithmic framework, termed EMTO–HKT, is presented. The experimental results on the single-objective multi-task optimization test suite demonstrate the superiority of EMTO–HKT compared with other state-of-the-art EMTO algorithms.},
  archive      = {J_ISCI},
  author       = {Yiqiao Cai and Deming Peng and Peizhong Liu and Jing-Ming Guo},
  doi          = {10.1016/j.ins.2021.09.021},
  journal      = {Information Sciences},
  pages        = {874-896},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary multi-task optimization with hybrid knowledge transfer strategy},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and analysis of rumor propagation in social
networks. <em>ISCI</em>, <em>580</em>, 857–873. (<a
href="https://doi.org/10.1016/j.ins.2021.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors affect a variety of human affairs, which may cause a serious social disorder. In order to accurately simulate the propagation dynamics of rumors in real social networks and effectively ameliorate the harm of rumors to society, a new rumor propagation model is proposed in this paper. The model considers the influence of discussants, and divides the total population into four groups: ignorances, discussants, spreaders, and removers. The equilibria and basic reproduction number of the model are calculated, and the local and global asymptotic stability and the transcritical bifurcation of the equilibria are analyzed and proved. The theoretical analysis reveals the dynamic behavior and mechanism of rumor propagation. The parameters of the model are estimated by least-squares fitting, and the rumor spreading process is predicted according to the fitted parameters. The model is verified by using a rumor actual dataset. Simulation results show that the R-squared is 0.9544, which means that the proposed model can accurately simulate the rumor propagation in real social networks. By comparing the proposed model and the existing ones, the outcome indicates that discussants have an important impact on the rumor propagation process.},
  archive      = {J_ISCI},
  author       = {Zhenhua Yu and Si Lu and Dan Wang and Zhiwu Li},
  doi          = {10.1016/j.ins.2021.09.012},
  journal      = {Information Sciences},
  pages        = {857-873},
  shortjournal = {Inf. Sci.},
  title        = {Modeling and analysis of rumor propagation in social networks},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Atomic cross-chain settlement model for central banks
digital currency. <em>ISCI</em>, <em>580</em>, 838–856. (<a
href="https://doi.org/10.1016/j.ins.2021.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current securities settlement systems employ various strategies to manage risks in settlement effectively. However, exchanging and verifying information between the market participants and intermediaries is time consuming.In addition, the back office and coordination costs are very high. To address such challenges, blockchain technology has attracted the attention of researchers due to its potential as a new settlement system. In this study, we propose a blockchain-based settlement system using cross-chain atomic swaps that can be implemented for the central banks digital currency (CBDC). The proposed model adds an administrator ledger to the system to remove settlement failure and improve efficiency in market management. Along with our settlement system, we also propose a new lattice-based sequential aggregate signature scheme generally known for its advantage on resisting future quantum attacks. Proof-of-concept experiments with the proposed system were conducted to analyze the effect of numerous variables in the blockchain ecosystem on the settlement system.},
  archive      = {J_ISCI},
  author       = {Yunyoung Lee and Bumho Son and Huisu Jang and Junyoung Byun and Taeho Yoon and Jaewook Lee},
  doi          = {10.1016/j.ins.2021.09.040},
  journal      = {Information Sciences},
  pages        = {838-856},
  shortjournal = {Inf. Sci.},
  title        = {Atomic cross-chain settlement model for central banks digital currency},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outlier detection from multiple data sources. <em>ISCI</em>,
<em>580</em>, 819–837. (<a
href="https://doi.org/10.1016/j.ins.2021.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preparation of a dataset by merging multiple data sources using the data fusion method may lead to the loss of vital information from each multi-source dataset and a certain amount of correlative information among the multiple data sources. Based on the extensive analysis of “the unique characteristics” of multi-source outliers, we propose multi-source outlier detection techniques to reliably identify outliers in multiple datasets. Several real-world examples are considered to classify multi-source outliers into three types ( Type I-III ) depending on the correlation among datasets. We design a baseline algorithm, which is an intuitive solution, and an optimal algorithm known as multiple-data-sources oriented outlier detection ( MOD ) to obtain high-score outliers. In addition, we build the MOD+ method to speed up the outlier detection process. A new density metric combining k NN and RNN is introduced to evaluate the deviation degrees of multi-source outliers. The new outlier are applied to develop three outlier-join operators. MOD and MOD+ are adept at (1) mining outlier information from each one of multi-source datasets and (2) sensing correlative outlier information among these multiple datasets. We implement and evaluate the three outlier detection algorithms by using synthetic and real-world datasets. The experimental results demonstrate that the proposed methods are promising and practical in the context of detecting outliers from multi-source datasets.},
  archive      = {J_ISCI},
  author       = {Yang Ma and Xujun Zhao and Chaowei Zhang and Jifu Zhang and Xiao Qin},
  doi          = {10.1016/j.ins.2021.09.053},
  journal      = {Information Sciences},
  pages        = {819-837},
  shortjournal = {Inf. Sci.},
  title        = {Outlier detection from multiple data sources},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kernelized distance learning for zero-shot recognition.
<em>ISCI</em>, <em>580</em>, 801–818. (<a
href="https://doi.org/10.1016/j.ins.2021.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Shot Learning (ZSL) has gained growing attention over the past few years mostly because it provides a significant scalability to recognition models for classifying instances from new unobserved classes. This scalability is achieved by providing semantic information about new classes, which could be obtained remarkably easier with lower cost, compared to collecting a new training set. Because seen and unseen classes are completely disjoint, ZSL methods often suffer from domain shift problem that occurs in transferring the knowledge of seen classes to unseen ones. Moreover, hubness problem that usually arises in high-dimensional space is another challenge in most ZSL methods due to applying nearest neighbor search for classification. To address these issues, a kernelized distance function is learned in order to discriminate the classes with a customized large-margin loss function. Furthermore, a simple theoretical-based prototype learning approach is provided by defining a non-linear mapping function to learn the visual prototype of each class from associated semantic information. For classification task , the learned distance function is utilized to measure the distance between instances and class-related prototypes. The evaluation on five benchmarks demonstrates the superiority of the proposed method over the state-of-the-art approaches in both zero-shot and generalized zero-shot learning problems.},
  archive      = {J_ISCI},
  author       = {Mohammad Reza Zarei and Mohammad Taheri and Yang Long},
  doi          = {10.1016/j.ins.2021.09.032},
  journal      = {Information Sciences},
  pages        = {801-818},
  shortjournal = {Inf. Sci.},
  title        = {Kernelized distance learning for zero-shot recognition},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time passivity and synchronization of coupled
complex-valued memristive neural networks. <em>ISCI</em>, <em>580</em>,
775–800. (<a href="https://doi.org/10.1016/j.ins.2021.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite-time passivity and finite-time synchronization issues for two categories of coupled complex-valued memristive neural networks with and without time-varying delay are discussed. First, by selecting a suitable control scheme and exploiting some inequality techniques, several finite-time passivity conditions are proposed for coupled complex-valued memristive neural networks without time-varying delay. Based on the obtained finite-time passivity condition, a criterion for finite-time synchronization for the considered network is also established. Furthermore, for coupled complex-valued memristive neural networks with time-varying delay, some criteria are established to guarantee that the considered network is finite-time passive and finite-time synchronized by developing an appropriate controller and deploying the Lyapunov functional method. Finally, two numerical examples with simulations substantiate the correctness and validity of the results.},
  archive      = {J_ISCI},
  author       = {Yanli Huang and Fang Wu},
  doi          = {10.1016/j.ins.2021.09.050},
  journal      = {Information Sciences},
  pages        = {775-800},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time passivity and synchronization of coupled complex-valued memristive neural networks},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Sliding-mode surface-based adaptive actor-critic optimal
control for switched nonlinear systems with average dwell time.
<em>ISCI</em>, <em>580</em>, 756–774. (<a
href="https://doi.org/10.1016/j.ins.2021.08.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of sliding-mode surface (SMS)-based adaptive optimal control for a class of continuous-time switched nonlinear systems with average dwell time (ADT) via using an actor-critic (AC) reinforcement learning (RL) strategy. By developing a specific cost function related to SMS, the original control problem is equivalently transformed into the problem of finding a series of optimal control policies. Then, the error terms separated from the Hamilton-Jacobi-Bellman (HJB) equation are integrated into a function, which effectively reduces the influence of some repeated magnifications caused by approximation errors. Besides, the solution to the HJB equation is identified by the SMS-based AC neural networks (NNs), where the actor and critic NNs are developed to carry out the RL strategy simultaneously. The actor updating law is to implement control actions based on the system output, while the critic updating law is required to assess the current control action and feedback to the actor. Based on the Lyapunov stability theory , the applicability of the proposed adaptive AC optimal control method is verified to guarantee the boundedness of all signals in the considered closed-loop switched nonlinear systems . Finally, a simulation examples is given to illustrate the effectiveness of the proposed adaptive optimal control method.},
  archive      = {J_ISCI},
  author       = {Haoyan Zhang and Huanqing Wang and Ben Niu and Liang Zhang and Adil M. Ahmad},
  doi          = {10.1016/j.ins.2021.08.062},
  journal      = {Information Sciences},
  pages        = {756-774},
  shortjournal = {Inf. Sci.},
  title        = {Sliding-mode surface-based adaptive actor-critic optimal control for switched nonlinear systems with average dwell time},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online multi-criteria portfolio analysis through compromise
programming models built on the underlying principles of fuzzy
outranking. <em>ISCI</em>, <em>580</em>, 734–755. (<a
href="https://doi.org/10.1016/j.ins.2021.08.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an interactive approach to support multi-criteria decision analysis of project portfolios. In high-scale strategic decision domains, scientific studies suggest that the Decision Maker (DM) can find help by using many-objective optimisation methods, which are supposed to provide values in the decision variables that generate high-quality solutions. Even so, DMs usually wish to explore the possibility of reaching some levels of benefits in some objectives. Consequently, they should repeatedly run the optimisation method. However, this approach cannot perform well – in an interactive way – for large instances under the presence of many objective functions. We present a mathematical model that is based on compromise programming and fuzzy outranking to aid DMs in analysing multi-criteria project portfolios on the fly. This approach allows relaxing the problem of rapidly optimising portfolios while preserving the beneficial properties of the DM’s preferences expressed by outranking relations. Our model supports the decision analysis on two instance benchmarks: for the first one, a better compromise solution was generated 84\% of the runs; for the second one, this ranged from 93\% to 97\%. Our model was also applied to a real-world problem involving social projects, obtaining satisfactory results.},
  archive      = {J_ISCI},
  author       = {Gilberto Rivera and Rogelio Florencia and Mario Guerrero and Raúl Porras and J. Patricia Sánchez-Solís},
  doi          = {10.1016/j.ins.2021.08.087},
  journal      = {Information Sciences},
  pages        = {734-755},
  shortjournal = {Inf. Sci.},
  title        = {Online multi-criteria portfolio analysis through compromise programming models built on the underlying principles of fuzzy outranking},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptively and spatially constrained dual-level trimap
generation from sparse inputs. <em>ISCI</em>, <em>580</em>, 720–733. (<a
href="https://doi.org/10.1016/j.ins.2021.08.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trimap generation is currently playing an important role in the field of image matting. The current trimap generation methods cannot adaptively adjust the classification thresholds, and ignore the nonlocal correlations between pixels. Besides, they also need finely provided trimaps. This paper raises a dual-level trimap generation approach which requires sparse user inputs. The first level introduces a unary data term from adaptive learned thresholds combined with local spatial constraints to effectively overcome the drawback of fixed threshold methods. The second level introduces a smoothness term from a nonlocal affinity for foreground probability estimation, and a pixel correlation constraint is computed and added to the data term. The foreground probability is finally solved in a closed form solution and truncated to generate the final trimap. In the experiments, firstly, this approach raises a novel trimap evaluation criterion according to the two classic terms of missing and false classifications. Based on this criterion, the final trimaps generated by our approach are better than those generated by other methods. Secondly, in the final matting process from four typical matting algorithms, the matting results from the trimaps by our approach are still better than those from the trimaps by other trimap generation methods.},
  archive      = {J_ISCI},
  author       = {Guilin Yao and Xiaodong Su and Haitao Xin and Jianming Sun},
  doi          = {10.1016/j.ins.2021.08.058},
  journal      = {Information Sciences},
  pages        = {720-733},
  shortjournal = {Inf. Sci.},
  title        = {Adaptively and spatially constrained dual-level trimap generation from sparse inputs},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel survival functions based on conditional aggregation
operators. <em>ISCI</em>, <em>580</em>, 705–719. (<a
href="https://doi.org/10.1016/j.ins.2020.12.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we define a novel survival function motivated by real life problems, which generalizes the super level measure introduced by Do and Thiele (2015). This concept is based on conditional aggregation operators extending the definition of aggregation operators introduced by Calvo et al. (2002) for all bounded measurable functions and not only for finite sequences. Some basic properties and several examples of conditional aggregation operators are presented. Using the novel survival function , the Choquet-Stieltjes functional is introduced and the conditions are indicated under which this functional can be called an integral. The new functional generalizes several known integrals including the Choquet-Stieltjes integral as well as Choquet integral with respect to level dependent capacity introduced by Greco et al. (2011).},
  archive      = {J_ISCI},
  author       = {Michał Boczek and Lenka Halčinová and Ondrej Hutník and Marek Kaluszka},
  doi          = {10.1016/j.ins.2020.12.049},
  journal      = {Information Sciences},
  pages        = {705-719},
  shortjournal = {Inf. Sci.},
  title        = {Novel survival functions based on conditional aggregation operators},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On using dynamic programming for time warping in pattern
recognition. <em>ISCI</em>, <em>580</em>, 684–704. (<a
href="https://doi.org/10.1016/j.ins.2021.08.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic programming is a mathematical optimization algorithm relied upon by time warping procedures. In general, its use is straightforward and early time warping publications are indeed correct and efficient. However, in sophisticated use of this technique considerable art is required. We discuss here some published sophisticated time warping procedures which are incorrect or inefficient. Since small example problems are sufficient to show incorrectness or inefficiency we restrict our attention to such. While doing so, we try to educate the reader toward the artful use of dynamic programming.},
  archive      = {J_ISCI},
  author       = {Eiji Mizutani and Stuart Dreyfus},
  doi          = {10.1016/j.ins.2021.08.075},
  journal      = {Information Sciences},
  pages        = {684-704},
  shortjournal = {Inf. Sci.},
  title        = {On using dynamic programming for time warping in pattern recognition},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Type inference for hierarchical multiset structures in
rule-based systems. <em>ISCI</em>, <em>580</em>, 673–683. (<a
href="https://doi.org/10.1016/j.ins.2021.08.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this paper is the resource evolution in rule-based systems with some specific restrictions imposed; specifically, some resources are bounded between certain lower and upper thresholds. Such a system is proved to be correct with respect to a type system.We define types over hierarchical multiset structures, and consider well-typing with respect to a specific relation aiming to guarantee an appropriate use of resources. The dynamics of the system is given by an operational semantics ; well-typedness remains invariant under the semantic transition rules. According to a typed semantics, each rule of the system can be applied only if the left-hand side of the rule is well-typed. A type inference is introduced to deduce the type of each hierarchical multiset structure. Soundness and completeness are proved for this type inference.},
  archive      = {J_ISCI},
  author       = {Bogdan Aman and Gabriel Ciobanu},
  doi          = {10.1016/j.ins.2021.08.079},
  journal      = {Information Sciences},
  pages        = {673-683},
  shortjournal = {Inf. Sci.},
  title        = {Type inference for hierarchical multiset structures in rule-based systems},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A graph-based approach for positive and unlabeled learning.
<em>ISCI</em>, <em>580</em>, 655–672. (<a
href="https://doi.org/10.1016/j.ins.2021.08.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive and Unlabeled Learning (PUL) uses unlabeled documents and a few positive documents for retrieving a set of “interest” documents from a text collection. Usually, PUL approaches are based on the vector space model . However, when dealing with semi-supervised learning for text classification or information retrieval, graph-based approaches have been proved to outperform vector space model-based approaches. So, in this article, a graph-based approach for PUL is proposed: Label Propagation for Positive and Unlabeled Learning (LP-PUL). The proposed framework consists of three steps: (i) building a similarity graph, (ii) identifying reliable negative documents, and (iii) performing label propagation to classify the remaining unlabeled documents as positive or negative. We carried out experiments to measure the impact of the different choices in each step of the proposed framework. We also demonstrated that the proposal surpasses the classification performance of other PUL (RC-SVM, PU-LP, and PE-PUC) or one-class learning ( k k -NN-based, k k -Means-based, and Dense Autoencoder) algorithms in terms of F 1 F1 . Considering the best results of any algorithm used in the experimental evaluation, PU-PUL can improve the classification performance from 2\% 2\% , when using only 1 1 labeled document, to 28\% 28\% , when 30 30 labeled documents are employed.},
  archive      = {J_ISCI},
  author       = {Julio César Carnevali and Rafael Geraldeli Rossi and Evangelos Milios and Alneu de Andrade Lopes},
  doi          = {10.1016/j.ins.2021.08.099},
  journal      = {Information Sciences},
  pages        = {655-672},
  shortjournal = {Inf. Sci.},
  title        = {A graph-based approach for positive and unlabeled learning},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dissipativity analysis for singular markovian jump systems
with time-varying delays via improved state decomposition technique.
<em>ISCI</em>, <em>580</em>, 643–654. (<a
href="https://doi.org/10.1016/j.ins.2021.08.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the issue of dissipativity analysis for singular Markovian jump systems (SMJSs) with time-varying delays via improved state decomposition technique. Toward this aim, based on the decomposed state vectors, an improved mode-dependent augmented Lyapunov–Krasovskii functional (LKF) is established for SMJSs after decomposing SJMSs into subsystems. And the constructed augmented LKF relieves the limitation of state decomposition method by adding some single integral functionals. Then, combining the limited Bessel-Legendre integral inequality and the generalized reciprocally convex combination lemma, a less conservative condition that ensures the SMJSs to be stochastically admissible and dissipative is obtained. Finally, the advantages of the derived criterion are verified by two numerical examples.},
  archive      = {J_ISCI},
  author       = {Yang Li and Yong He},
  doi          = {10.1016/j.ins.2021.08.092},
  journal      = {Information Sciences},
  pages        = {643-654},
  shortjournal = {Inf. Sci.},
  title        = {Dissipativity analysis for singular markovian jump systems with time-varying delays via improved state decomposition technique},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient anomaly detection method for uncertain data
based on minimal rare patterns with the consideration of anti-monotonic
constraints. <em>ISCI</em>, <em>580</em>, 620–642. (<a
href="https://doi.org/10.1016/j.ins.2021.08.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pattern-based anomaly detection method has obtained more attention since it was proposed. This is due to its ability to fully identify anomalies by considering two key features, including appearing rarely and deviating from most data elements. Although most pattern-based anomaly detection methods identify the anomalies from full data space, the process involved in performing this functionality is very time-consuming. Therefore, to solve this problem, this paper introduces a novel method, namely m inimal r are p attern-based anomaly detection method through considering a nti-monotonic c onstraints (MRPAC), for identifying anomalies in uncertain data. MRPAC detects the anomalies from a small scale of uncertain data that satisfy preset anti-monotonic constraints by mining constrained minimal rare patterns, thus, the time efficiency is increased. In addition, MRPAC also defines multiple deviation factors to compute the anomaly score for all transactions, to accurately discover potential anomalies through sorting their anomaly scores. Extensive experimental outcomes indicate that the MRPAC significantly outperforms five state-of-the-art pattern-based anomaly methods in terms of detection accuracy and time efficiency, and obtains good scalability.},
  archive      = {J_ISCI},
  author       = {Saihua Cai and Jinfu Chen and Haibo Chen and Chi Zhang and Qian Li and Rexford Nii Ayitey Sosu and Shang Yin},
  doi          = {10.1016/j.ins.2021.08.097},
  journal      = {Information Sciences},
  pages        = {620-642},
  shortjournal = {Inf. Sci.},
  title        = {An efficient anomaly detection method for uncertain data based on minimal rare patterns with the consideration of anti-monotonic constraints},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An instance-oriented performance measure for classification.
<em>ISCI</em>, <em>580</em>, 598–619. (<a
href="https://doi.org/10.1016/j.ins.2021.08.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance evaluation is significant in data classification. The existing evaluation methods ignore the characteristics (such as classification difficulty) of each instance. In practice, it is necessary to measure classification performance from the perspective of instances. In this paper, an instance-oriented classification performance metric is proposed based on the classification difficulty of each instance, named degree of credibility ( Cr ). Cr conforms to the natural cognition that the lower the probability of misclassifying relatively easy instances, the more credible the classifier. It focuses on the credibility of each instance’s prediction, which opens up a new way for classifier evaluation . Moreover, several important properties of Cr are identified, laying solid theoretical foundation for classifier evaluation. Also, the concept of acceptable classifier is proposed to judge whether the trained model and its parameter set reach excellent ranks at the current technology level instead of relying entirely on human experience. The experimental results of twelve classifiers on twelve datasets indicate the physical significance and good statistical consistency and discriminatory ability of Cr , as well as the feasibility of acceptable classifiers for model selection and training. Furthermore, the proposal of approximate difficulty greatly improves the computation efficiency of instance difficulty.},
  archive      = {J_ISCI},
  author       = {Shuang Yu and Xiongfei Li and Yuncong Feng and Xiaoli Zhang and Shiping Chen},
  doi          = {10.1016/j.ins.2021.08.094},
  journal      = {Information Sciences},
  pages        = {598-619},
  shortjournal = {Inf. Sci.},
  title        = {An instance-oriented performance measure for classification},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real time surveillance for low resolution and limited data
scenarios: An image set classification approach. <em>ISCI</em>,
<em>580</em>, 578–597. (<a
href="https://doi.org/10.1016/j.ins.2021.08.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel image set classification technique based on the concept of linear regression. Unlike most other approaches, the proposed technique does not require any training. We represent the gallery image sets as subspaces in a high dimensional space. Class specific gallery subspaces are used to estimate regression models for each image in the test image set. Images of the test set are then projected onto the gallery subspaces. The residuals, calculated using the Euclidean distance between the original and the projected test images, are used as the distance metric. Three different strategies are devised to decide on the final class of the test image set. We extensively evaluated the proposed technique using both low resolution and noisy images and with less gallery data to assess the suitability of our technique for the tasks of surveillance and video-based face recognition. The experiments show that the proposed technique achieves superior classification accuracy and has a faster execution time compared with existing techniques, especially under the challenging conditions of low resolution and a limited amount of gallery and test data.},
  archive      = {J_ISCI},
  author       = {Uzair Nadeem and Syed Afaq Ali Shah and Mohammed Bennamoun and Roberto Togneri and Ferdous Sohel},
  doi          = {10.1016/j.ins.2021.08.093},
  journal      = {Information Sciences},
  pages        = {578-597},
  shortjournal = {Inf. Sci.},
  title        = {Real time surveillance for low resolution and limited data scenarios: An image set classification approach},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). New uncertainty measurement for categorical data based on
fuzzy information structures: An application in attribute reduction.
<em>ISCI</em>, <em>580</em>, 541–577. (<a
href="https://doi.org/10.1016/j.ins.2021.08.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorical data is a significant kind of data in machine learning .Generally, rough set theory ( RS -theory) deals with categorical data in the following way.First, an equivalence relation based on the equality of attribute values of categorical data is established.Then, information granules ( I -granules) based on equivalence classes are obtained.Finally, information structures ( I -structures) consisting of I -granules are formed.However, an equivalence relation is too strict, and there are some limitations in the I -structure of a categorical information system (CIS) that may result in filtering out potentially useful information.This paper investigates fuzzy information structures ( FI -structures) and new uncertainty measurements for categorical data from the perspective that “the equality of attribute values is fed back to the attribute set”.First, a fuzzy symmetry relation based on the number of attributes with equal attribute values is established. Then, fuzzy information granules ( FI -granules) based on the fuzzy symmetry relation are obtained. Next, FI -structures consisting of FI -granules are formed.Finally, some concepts related to FI -structures in a CIS are given.The set vector is used to denote FI -structures, and the inclusion degree is used to study the dependence between FI -structures.In addition, four new uncertainty measurements based on FI -structures in a CIS are proposed, including fuzzy information granulation ( G f ), fuzzy information entropy ( H f ), fuzzy rough entropy ( E r f ) and fuzzy information amount ( E f ).Moreover, numerical experiments and statistical tests to evaluate the performance of the proposed new measurements are carried out.The results of the paired t -test show that the performance of the four new measurements based on FI -structures is better than that of the corresponding four measurements based on I -structures.Finally, attribute reduction algorithms based on G f and H f are presented, and clustering analysis is conducted on the reduced CIS. The experimental results show that the proposed algorithms are effective and perform well on attribute reduction according to three evaluation indicators of clustering performance.},
  archive      = {J_ISCI},
  author       = {Qinli Zhang and Yiying Chen and Gangqiang Zhang and Zhaowen Li and Lijun Chen and Ching-Feng Wen},
  doi          = {10.1016/j.ins.2021.08.089},
  journal      = {Information Sciences},
  pages        = {541-577},
  shortjournal = {Inf. Sci.},
  title        = {New uncertainty measurement for categorical data based on fuzzy information structures: An application in attribute reduction},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SCIPS: A serious game using a guidance mechanic to scaffold
effective training for cyber security. <em>ISCI</em>, <em>580</em>,
524–540. (<a href="https://doi.org/10.1016/j.ins.2021.08.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training effective simulation scenarios presents numerous challenges from a pedagogical point of view. Through application of the Conceptual Framework for e-Learning and Training (COFELET) as a pattern for designing serious games, we propose the use of the Simulated Critical Infrastructure Protection Scenarios (SCIPS) platform as a prospective tool for supporting the process of providing effective cyber security training. The SCIPS platform is designed to run different scenarios, such as examples in financial forecasting and business infrastructures, with an initial scenario developed in collaboration with industrial partners focusing on an electricity generation plant. Focus groups from these sources were conducted to identify design and developmental considerations for the platform. As an extension from the COFELET framework, we propose an intelligence scaffolding practice as a guidance mechanic taking the form of an agent within the scenario. The agent represents a major innovation in the system and we envisage a deep learning-based augmentation to further adapt towards the behavioural aspects of learners.},
  archive      = {J_ISCI},
  author       = {Stuart O’Connor and Salim Hasshu and James Bielby and Simon Colreavy-Donnelly and Stefan Kuhn and Fabio Caraffini and Richard Smith},
  doi          = {10.1016/j.ins.2021.08.098},
  journal      = {Information Sciences},
  pages        = {524-540},
  shortjournal = {Inf. Sci.},
  title        = {SCIPS: A serious game using a guidance mechanic to scaffold effective training for cyber security},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). JKT: A joint graph convolutional network based deep
knowledge tracing. <em>ISCI</em>, <em>580</em>, 510–523. (<a
href="https://doi.org/10.1016/j.ins.2021.08.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Tracing (KT) aims to trace the student’s state of evolutionary mastery for a particular knowledge or concept based on the student’s historical learning interactions with the corresponding exercises. Taking the “exercise-to-concept” relationships as input, several existing methods have been developed to trace and model students’ mastery states. However, these studies face two major shortcomings in KT: 1) they only consider “exercise-to-concept” relationships; 2) the multi-hot embeddings lack interpretability . In order to address the above issues, we propose a J oint graph convolutional network based deep K nowledge T racing ( JKT ) framework to model the multi-dimensional relationships of “exercise-to-exercise” , and “concept-to-concept” into graph and fuse them with “exercise-to-concept” relationships. In JKT, it is not only possible to establish connections between exercises under cross-concepts, but also to help capture high-level semantic information and increase the model’s interpretability . In addition, sufficient experiments conducted on four real-world datasets have demonstrated that JKT performs better than the other baseline models . We further illustrate a case study to demonstrate its interpretability for learning analysis},
  archive      = {J_ISCI},
  author       = {Xiangyu Song and Jianxin Li and Yifu Tang and Taige Zhao and Yunliang Chen and Ziyu Guan},
  doi          = {10.1016/j.ins.2021.08.100},
  journal      = {Information Sciences},
  pages        = {510-523},
  shortjournal = {Inf. Sci.},
  title        = {JKT: A joint graph convolutional network based deep knowledge tracing},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view group representation learning for location-aware
group recommendation. <em>ISCI</em>, <em>580</em>, 495–509. (<a
href="https://doi.org/10.1016/j.ins.2021.08.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of location-based services (LBS), many location-based social sites like Foursquare and Plancast have emerged. People can organize and participate in group activities on those sites. Therefore, recommending venues for group activities is of practical value. However, the group decision making process is complicated, requiring trade-offs among group members. And the data sparsity and cold-start problems make it difficult to make effective group recommendation. In this manuscript, we propose a Multi-view Group Representation Learning (MGPL) framework for location-aware group recommendation. The proposed multi-view group representation learning framework can leverage multiple types of information for deep representation learning of group preferences and incorporate the spatial attributes of locations to further capture the group mobility preferences. Experiments on two real datasets Foursqaure and Plancast show that our method significantly outperforms the-state-of-art approaches.},
  archive      = {J_ISCI},
  author       = {Ziyu Lyu and Min Yang and Hui Li},
  doi          = {10.1016/j.ins.2021.08.086},
  journal      = {Information Sciences},
  pages        = {495-509},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view group representation learning for location-aware group recommendation},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep truth discovery for pattern-based fact extraction.
<em>ISCI</em>, <em>580</em>, 478–494. (<a
href="https://doi.org/10.1016/j.ins.2021.08.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fact extraction, which aims to extract (entity, attribute, value)-tuples from massive text corpora, is crucial in the area of text data mining . Recent approaches have focused on extracting facts by mining textual patterns with semantic types, where the quality of a pattern is evaluated based on content-based criteria, such as frequency. However, these approaches overlook the dimension of pattern reliability , which reflects how likely the extracted facts are correct. As a result, a pattern of good content-quality (e.g., high frequency) may still extract incorrect facts. In this study, we consider both pattern reliability and fact trustworthiness in addressing the pattern-based fact extraction problem. To learn the complex relationship between pattern reliability and fact trustworthiness, we propose a novel deep learning model using a hybrid of the CNN and LSTM architecture. For fact embedding, we adopt CNN to extract a fix-sized representation of each component, i.e., entity, attribute, and value, of the fact. For pattern embedding, we represent the pattern as a semantic composition of its extracted fact representations. To de-emphasis the noisy facts, we consider the fact trustworthiness and frequency during the process of pattern embedding, where the features of the tuple trustworthiness information are extracted by a long short-term memory (LSTM) model. To learn the pattern-fact relational dependency, we train the model with both pattern and tuple labels. Extensive experiments involving three real-world datasets demonstrated that the proposed model significantly improves the quality of the patterns and the extracted facts in the pattern-based information extraction.},
  archive      = {J_ISCI},
  author       = {Chen Ye and Hongzhi Wang and Wenbo Lu and Jing Gao and Guojun Dai},
  doi          = {10.1016/j.ins.2021.08.084},
  journal      = {Information Sciences},
  pages        = {478-494},
  shortjournal = {Inf. Sci.},
  title        = {Deep truth discovery for pattern-based fact extraction},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A generic bayesian-based framework for enhancing top-n
recommender algorithms. <em>ISCI</em>, <em>580</em>, 460–477. (<a
href="https://doi.org/10.1016/j.ins.2021.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized top-N recommender algorithms have been investigated widely in decades. The core task of different recommender algorithms is to estimate user-item preference scores and then to suggest, for each user, top-N items that have high preference scores. However, little attention was paid to the recommendation of items with low preference scores. In this work, we use the bayesian estimation theory to build the relationship between the estimated preference scores and the actual recommendation accuracy. We then propose a novel metric RNR ( R ecall-to- N oise R atio) to recommend items with low estimated preference scores. An interesting counterintuitive phenomenon is found that user-item links with low preference scores may achieve higher accuracy than high preference score ones in the recommendation. Based on RNR, we design a generic framework that could recommend user-item links that have low preference scores without the loss of recommendation accuracy. The effectiveness of the proposed framework is illustrated by both theoretical analysis and empirical experiments.},
  archive      = {J_ISCI},
  author       = {Ming-yang Zhou and Rong-qin Xu and Zi-ming Wang and Hao Liao},
  doi          = {10.1016/j.ins.2021.08.048},
  journal      = {Information Sciences},
  pages        = {460-477},
  shortjournal = {Inf. Sci.},
  title        = {A generic bayesian-based framework for enhancing top-N recommender algorithms},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Type-based outlier removal framework for point clouds.
<em>ISCI</em>, <em>580</em>, 436–459. (<a
href="https://doi.org/10.1016/j.ins.2021.08.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds from scanners or stereo vision inevitably contain outliers which have negative effects on subsequent procedures. Previous works classify outliers according to their characteristics, which guide the design of targeted outlier removal methods. Thus, outlier classification is critical to the corresponding method and outlier removal effect. The proposed type-based outlier removal framework (TBORF) aims to classify outliers more elaborately by considering both the characteristics of the underlying point cloud and the outliers. Therefore, the designed outlier removal methods can be more targeted. To this end, the framework first quantifies the characteristics of the input point cloud using three proposed metrics. According to this quantitative result, the input point clouds are classified into four types. Meanwhile, three new single-criterion methods are proposed to improve the effect on specific types of outlier removal. Based on the point cloud classification and the proposed single-criterion methods, an appropriate combined method is carefully designed for each type of point cloud. Performance evaluations on both outdoor and indoor point cloud datasets demonstrate that TBORF can effectively remove various outliers, facilitating subsequent digital geometry processing operations.},
  archive      = {J_ISCI},
  author       = {Linlin Ge and Jieqing Feng},
  doi          = {10.1016/j.ins.2021.08.090},
  journal      = {Information Sciences},
  pages        = {436-459},
  shortjournal = {Inf. Sci.},
  title        = {Type-based outlier removal framework for point clouds},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and control of heterogeneous field robots under
partial observation. <em>ISCI</em>, <em>580</em>, 419–435. (<a
href="https://doi.org/10.1016/j.ins.2021.08.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of large-scale dynamic systems, such as field robots, requires a more modular and scalable approach than traditional control theory. Recently, we designed modular supervisory controllers for field robots in agricultural applications based on a hybrid system that combines continuous-time and discrete-event systems. We verified that the developed hybrid system could control field robots and observe all the events while meeting the behavioral specifications. In contrast, all possible events cannot be monitored by a supervisor in a real-field robot system because of the presence of sensors, noise, disturbances, and failure. Therefore, in this study, we expanded the modular supervisor presented in previous studies by considering partial observations. Specifically, we proposed a process for designing an appropriate modular supervisor by considering the observability . The experimental results demonstrated that only observable events could cause state changes, verified by dynamic simulations representing a natural field environment. The effects of the proposed hybrid system-based modeling and control methodology are discussed in light of our systematic results.},
  archive      = {J_ISCI},
  author       = {Chanyoung Ju and Hyoung Il Son},
  doi          = {10.1016/j.ins.2021.08.071},
  journal      = {Information Sciences},
  pages        = {419-435},
  shortjournal = {Inf. Sci.},
  title        = {Modeling and control of heterogeneous field robots under partial observation},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conflicting evidence combination from the perspective of
networks. <em>ISCI</em>, <em>580</em>, 408–418. (<a
href="https://doi.org/10.1016/j.ins.2021.08.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer evidence theory is widely used in the field of information fusion especially when confronting with uncertainties. However, Dempster’s rule of combination may lead to counter-intuitive results when dealing with highly conflicting bodies of evidence (BOEs). Numerous methods were proposed to address this problem. Enlightened by the research of interaction among nodes in complex networks, this paper study the combination of evidences from the perspective of networks: BOEs are regarded as nodes, the conflicting degree between BOEs is considered as one possible interaction between nodes. The direct and indirect interactions among nodes in networks are considered together to determine the weights of the BOEs. After process of weighted average, the modified BOEs can be efficiently combined by Dempster’s rule of combination. A numerical example is illustrated to show the use and better performance of the proposed method.},
  archive      = {J_ISCI},
  author       = {Leihui Xiong and Xiaoyan Su and Hong Qian},
  doi          = {10.1016/j.ins.2021.08.088},
  journal      = {Information Sciences},
  pages        = {408-418},
  shortjournal = {Inf. Sci.},
  title        = {Conflicting evidence combination from the perspective of networks},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved belief structure satisfaction to uncertain
target values by considering the overlapping degree between events.
<em>ISCI</em>, <em>580</em>, 398–407. (<a
href="https://doi.org/10.1016/j.ins.2021.08.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of evidence theory , the processing of uncertain information is a very important research orientation, which has been receiving widespread attention in academic community. Recently, Yager and Alajlan proposed a method to evaluate the belief structure satisfaction to uncertain target values. However, this method ignored the effect of the overlapping degree between events. In this paper, a new method used to calculate the belief structure satisfaction is proposed. With different overlapping degrees between events considered, this new method effectively quantifies the evaluation interval of the belief structure satisfaction. The validity of the proposed belief structure satisfaction is verified in an illustrative application for multi-criteria decision-making through a combination of evidential axiomatic design process.},
  archive      = {J_ISCI},
  author       = {Xinyang Deng and Yebi Cui},
  doi          = {10.1016/j.ins.2021.08.083},
  journal      = {Information Sciences},
  pages        = {398-407},
  shortjournal = {Inf. Sci.},
  title        = {An improved belief structure satisfaction to uncertain target values by considering the overlapping degree between events},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning decomposed hierarchical feature for better
transferability of deep models. <em>ISCI</em>, <em>580</em>, 385–397.
(<a href="https://doi.org/10.1016/j.ins.2021.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep models have achieved prominent results in pattern recognition tasks, especially computer vision and natural language processing . However, the dataset bias caused by the distribution discrepancy between the training and testing data hinders the generalization ability of deep models. Though many domain adaptation approaches have been proposed to mitigate such negative effect, most of them improve the transferability of features by aligning global distributions of deep models. Few researchers pay attention to the versatility of deep features which can play a vital role in cross-domain recognition. In this paper, we propose to enrich the classic deep learning models by capturing high-low-frequency information and multi-scale features, which deal with the domain shift that cannot be easily addressed by merely feature-level alignment. The Hierarchical Transfer Network (HTN) leverages octave convolution , pyramid features, and self-attention mechanism for revamping the classic models, which can be further integrated with any domain alignment approaches by replacing the feature extractor with the proposed HTN. Extensive experiments have been conducted on three public domain adaptation benchmarks. The results show that the proposed HTN can effectively improve adversarial-based, statistics-based, and norm-based domain adaptation approaches, achieving competitive performance without involving model complexity.},
  archive      = {J_ISCI},
  author       = {Jianfei Yang and Hanjie Qian and Han Zou and Lihua Xie},
  doi          = {10.1016/j.ins.2021.08.046},
  journal      = {Information Sciences},
  pages        = {385-397},
  shortjournal = {Inf. Sci.},
  title        = {Learning decomposed hierarchical feature for better transferability of deep models},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PD control of positive interval continuous-time systems with
time-varying delay. <em>ISCI</em>, <em>580</em>, 371–384. (<a
href="https://doi.org/10.1016/j.ins.2021.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to design proportional-derivative (PD) controllers for interval positive linear systems in the continuous-time domain, which still remains a widely-discussed open problem in positive systems theory. The specific objective is to design a PD controller for the system with interval uncertain parameters and time-varying delay, which simultaneously ensures closed-loop system stability and preserves positivity. The work proposes a systematic framework, with the aim of finding PD controller gains for positive robust stabilization. The methodology and algorithm are presented first in the study, and the performance of such methods is instantiated by numerical examples.},
  archive      = {J_ISCI},
  author       = {Jason J.R. Liu and Maoqi Zhang and James Lam and Baozhu Du and Ka-Wai Kwok},
  doi          = {10.1016/j.ins.2021.08.034},
  journal      = {Information Sciences},
  pages        = {371-384},
  shortjournal = {Inf. Sci.},
  title        = {PD control of positive interval continuous-time systems with time-varying delay},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rumor knowledge embedding based data augmentation for
imbalanced rumor detection. <em>ISCI</em>, <em>580</em>, 352–370. (<a
href="https://doi.org/10.1016/j.ins.2021.08.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumor detection aims to detect rumors in a timely manner to prevent malicious rumors from misleading the public and disrupting social order. However, rumor detection suffers from the problem of imbalanced data . Existing methods of text generation and imbalanced learning are insufficient in addressing this imbalance because they are not specialized in rumor tasks. We propose a knowledge graph-based rumor data augmentation method: Graph Embedding-based Rumor Data Augmentation (GERDA), which simulates the generation process of rumor from the perspective of knowledge. To model the generation process of false information, we introduce knowledge representation in the process of text generation. To better learn the graph structured rumor data, we propose a graph-based rumor text generative model G2S-AT-GAN, which uses an attention-based graph convolutional neural network and a generative adversarial network for rumor text generation. Experiments show that our method is able to generate high-quality rumors of diverse topics and the generated rumors can further address rumor data imbalance for better performance in rumor detection.},
  archive      = {J_ISCI},
  author       = {Xiangyan Chen and Duoduo Zhu and Dazhen Lin and Donglin Cao},
  doi          = {10.1016/j.ins.2021.08.059},
  journal      = {Information Sciences},
  pages        = {352-370},
  shortjournal = {Inf. Sci.},
  title        = {Rumor knowledge embedding based data augmentation for imbalanced rumor detection},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new prediction strategy for dynamic multi-objective
optimization using gaussian mixture model. <em>ISCI</em>, <em>580</em>,
331–351. (<a href="https://doi.org/10.1016/j.ins.2021.08.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems (DMOPs), in which the environments change over time, have attracted many researchers’ attention in recent years. Since the Pareto set (PS) or the Pareto front (PF) can change over time, how to track the movement of the PS or PF is a challenging problem in DMOPs. Over the past few years, lots of methods have been proposed, and the prediction based strategy has been considered the most effective way to track the new PS. However, the performance of most existing prediction strategies depends greatly on the quantity and quality of the historical information and will deteriorate due to non-linear changes, leading to poor results. In this paper, we propose a new prediction method, named MOEA/D-GMM, which incorporates the Gaussian Mixture Model (GMM) into the MOEA/D framework for the prediction of the new PS when changes occur. Since GMM is a powerful non-linear model to accurately fit various data distributions, it can effectively generate solutions with better quality according to the distributions. In the proposed algorithm, a change type detection strategy is first designed to estimate an approximate PS according to different change types. Then, GMM is employed to make a more accurate prediction by training it with the approximate PS. To overcome the shortcoming of a lack of training solutions for GMM, the Empirical Cumulative Distribution Function (ECDF) method is used to resample more training solutions before GMM training. Experimental results on various benchmark test problems and a classical real-world problem show that, compared with some state-of-the-art dynamic optimization algorithms , MOEA/D-GMM outperforms others in most cases.},
  archive      = {J_ISCI},
  author       = {Feng Wang and Fanshu Liao and Yixuan Li and Hui Wang},
  doi          = {10.1016/j.ins.2021.08.065},
  journal      = {Information Sciences},
  pages        = {331-351},
  shortjournal = {Inf. Sci.},
  title        = {A new prediction strategy for dynamic multi-objective optimization using gaussian mixture model},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gradient temporal-difference learning for off-policy
evaluation using emphatic weightings. <em>ISCI</em>, <em>580</em>,
311–330. (<a href="https://doi.org/10.1016/j.ins.2021.08.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of off-policy evaluation (OPE) has long been advocated as one of the foremost challenges in reinforcement learning . Gradient-based and emphasis-based temporal-difference (TD) learning algorithms comprise the major part of off-policy TD learning methods. In this work, we investigate the derivation of efficient OPE algorithms from a novel perspective based on the advantages of these two categories. The gradient-based framework is adopted, and the emphatic approach is used to improve convergence performance. We begin by proposing a new analogue of the on-policy objective, called the distribution-correction-based mean square projected Bellman error (DC-MSPBE). The key to the construction of DC-MSPBE is the use of emphatic weightings on the representable subspace of the original MSPBE. Based on this objective function, the emphatic TD with lower-variance gradient correction (ETD-LVC) algorithm is proposed. Under standard off-policy and stochastic approximation conditions, we provide the convergence analysis of the ETD-LVC algorithm in the case of linear function approximation. Further, we generalize the algorithm to nonlinear smooth function approximation. Finally, we empirically demonstrate the improved performance of our ETD-LVC algorithm on off-policy benchmarks. Taken together, we hope that our work can guide the future discovery of a better alternative in the off-policy TD learning algorithm family.},
  archive      = {J_ISCI},
  author       = {Jiaqing Cao and Quan Liu and Fei Zhu and Qiming Fu and Shan Zhong},
  doi          = {10.1016/j.ins.2021.08.082},
  journal      = {Information Sciences},
  pages        = {311-330},
  shortjournal = {Inf. Sci.},
  title        = {Gradient temporal-difference learning for off-policy evaluation using emphatic weightings},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Axiomatic characterizations of l-valued rough sets using a
single axiom. <em>ISCI</em>, <em>580</em>, 283–310. (<a
href="https://doi.org/10.1016/j.ins.2021.08.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough approximation operators are the underlying concepts in fuzzy rough set theory . There are at least two approaches to develop these primary concepts, i.e., the constructive approach and the axiomatic approach . Single axiomatic characterizations of fuzzy rough approximation operators have got tons of attention. In this paper, considering L L being a GL-quantale, we will develop the theory of L L -valued rough sets with an L L -set as the basic universe of defining L L -valued rough approximation operators. Adopting the idea of single axiomatic characterizations of fuzzy rough sets , we will present the axiomatic characterizations of L L -valued upper and lower rough approximation operators on an L L -set with respect to reflexive, symmetric, transitive L L -valued relations on an L L -set as well as their compositions. Choosing an L L -set as the universe will break the rules that adopting Zadeh’s fuzzy sets as the universe. By these results, we will further provide a new framework of axiomatic research of fuzzy rough set theory .},
  archive      = {J_ISCI},
  author       = {Xiaowei Wei and Bin Pang and Ju-Sheng Mi},
  doi          = {10.1016/j.ins.2021.08.078},
  journal      = {Information Sciences},
  pages        = {283-310},
  shortjournal = {Inf. Sci.},
  title        = {Axiomatic characterizations of L-valued rough sets using a single axiom},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving the performance of bagging ensembles for data
streams through mini-batching. <em>ISCI</em>, <em>580</em>, 260–282. (<a
href="https://doi.org/10.1016/j.ins.2021.08.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Often, machine learning applications have to cope with dynamic environments where data are collected in the form of continuous data streams with potentially infinite length and transient behavior . Compared to traditional (batch) data mining , stream processing algorithms have additional requirements regarding computational resources and adaptability to data evolution. They must process instances incrementally because the data’s continuous flow prohibits storing data for multiple passes. Ensemble learning achieved remarkable predictive performance in this scenario. Implemented as a set of (several) individual classifiers, ensembles are naturally amendable for task parallelism . However, the incremental learning and dynamic data structures used to capture the concept drift increase the cache misses and hinder the benefit of parallelism . This paper proposes a mini-batching strategy that can improve memory access locality and performance of several ensemble algorithms for stream mining in multi-core environments. With the aid of a formal framework, we demonstrate that mini-batching can significantly decrease the reuse distance (and the number of cache misses). Experiments on six different state-of-the-art ensemble algorithms applying four benchmark datasets with varied characteristics show speedups of up to 5X on 8-core processors. These benefits come at the expense of a small reduction in predictive performance .},
  archive      = {J_ISCI},
  author       = {Guilherme Cassales and Heitor Gomes and Albert Bifet and Bernhard Pfahringer and Hermes Senger},
  doi          = {10.1016/j.ins.2021.08.085},
  journal      = {Information Sciences},
  pages        = {260-282},
  shortjournal = {Inf. Sci.},
  title        = {Improving the performance of bagging ensembles for data streams through mini-batching},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mean square exponential stability of discrete-time markov
switched stochastic neural networks with partially unstable subsystems
and mixed delays. <em>ISCI</em>, <em>580</em>, 243–259. (<a
href="https://doi.org/10.1016/j.ins.2021.08.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the mean square exponential stability of discrete-time stochastic neural networks with partially unstable subsystems and mixed delays. The mixed delays under consideration involve discrete delay and distributed delay. Moreover, the discrete delay term satisfies the Bernoulli distribution . Different from the deterministic switching, we consider Markov switching and our system has partially unstable subsystems. By constructing a novel Lyapunov–Krasovskii functional and using the stationary distribution of Markov chain , we give sufficient conditions for the mean square exponential stability of the suggested system. Finally, two numerical examples are given to check the theory results.},
  archive      = {J_ISCI},
  author       = {Lina Fan and Quanxin Zhu},
  doi          = {10.1016/j.ins.2021.08.068},
  journal      = {Information Sciences},
  pages        = {243-259},
  shortjournal = {Inf. Sci.},
  title        = {Mean square exponential stability of discrete-time markov switched stochastic neural networks with partially unstable subsystems and mixed delays},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OCEAn: Ordinal classification with an ensemble approach.
<em>ISCI</em>, <em>580</em>, 221–242. (<a
href="https://doi.org/10.1016/j.ins.2021.08.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, classification problems catalog instances according to their target variable without considering the relation among the different labels. However, there are real problems in which the different values of the class are related to each other. Because of interest in this type of problem, several solutions have been proposed, such as cost-sensitive classifiers. Ensembles have proven to be very effective for classification tasks ; however, as far as we know, there are no proposals that use a genetic-based methodology as the metaheuristic to create the models. In this paper, we present OCEAn, an ordinal classification algorithm based on an ensemble approach, which makes a final prediction according to a weighted vote system. This weighted voting takes into account weights obtained by a genetic algorithm that tries to minimize the cost of classification. To test the performance of this approach, we compared our proposal with ordinal classification algorithms in the literature and demonstrated that, indeed, our approach improves on previous results.},
  archive      = {J_ISCI},
  author       = {Belén Vega-Márquez and Isabel A. Nepomuceno-Chamorro and Cristina Rubio-Escudero and José C. Riquelme},
  doi          = {10.1016/j.ins.2021.08.081},
  journal      = {Information Sciences},
  pages        = {221-242},
  shortjournal = {Inf. Sci.},
  title        = {OCEAn: Ordinal classification with an ensemble approach},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A rank-based framework through manifold learning for
improved clustering tasks. <em>ISCI</em>, <em>580</em>, 202–220. (<a
href="https://doi.org/10.1016/j.ins.2021.08.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relevance of diversified data preprocessing approaches for improving clustering tasks is remarkable. Once the effectiveness is direct impacted by feature representation and similarity definition, considerable attention from the research community has been drawn to this direction. More recently, rank-based manifold learning methods have been successfully explored in unsupervised similarity learning for retrieval scenarios. Such methods consider the underlying dataset manifold to compute a new similarity measure, which increases the separability of data from distinct classes. In this paper, a rank-based framework for clustering tasks is proposed based on contemporary manifold learning methods. A flexible model is employed, where ranking structures are the representation of similarity information among data samples. Subsequently, is made the exploration of unsupervised similarity learning. It is also possible to compute more effective similarity measures and clustering results. To assess the effectiveness of the proposed framework was conducted a comprehensive experimental evaluation. The tests involved various public image datasets, considering different manifold learning and clustering methods . The quantitative experiments take into consideration comparisons with traditional and recent state-of-the-art clustering approaches.},
  archive      = {J_ISCI},
  author       = {Bionda Rozin and Vanessa Helena Pereira-Ferrero and Leonardo Tadeu Lopes and Daniel Carlos Guimarães Pedronette},
  doi          = {10.1016/j.ins.2021.08.080},
  journal      = {Information Sciences},
  pages        = {202-220},
  shortjournal = {Inf. Sci.},
  title        = {A rank-based framework through manifold learning for improved clustering tasks},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using m-ary decomposition and virtual bits for visually
meaningful image encryption. <em>ISCI</em>, <em>580</em>, 174–201. (<a
href="https://doi.org/10.1016/j.ins.2021.08.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A visually meaningful image encryption algorithm is presented. More specifically, a strategy of M-ary decomposition is first presented to be used to represent a positive integer in multi base. Then the concept of virtual bits is presented and the relationship between it and the M-ary decomposition is discussed. Based on the M-ary decomposition strategy, a non-standard image pre-encryption algorithm is proposed where each pixel value of the pre-encrypted image is limited to a specified range thus saving a small amount of virtual bits which can also be used to improve the visual quality of cipher images. A Generalized Embedding Model is proposed, where the Generalized-LSB (G-LSB) method is used to embed virtual bits into the host domain and an error-correcting strategy is also presented. The optimal static virtual embedded bits (SVEB) are found and a set of rules for dynamic virtual embedded bits (DVEB) are constructed. Experimental simulations show that the visual quality of cipher images is better than that using existing visually meaningful image encryption algorithms.},
  archive      = {J_ISCI},
  author       = {Yu-Guang Yang and Bao-Pu Wang and Shuai-Kang Pei and Yi-Hua Zhou and Wei-Min Shi and Xin Liao},
  doi          = {10.1016/j.ins.2021.08.073},
  journal      = {Information Sciences},
  pages        = {174-201},
  shortjournal = {Inf. Sci.},
  title        = {Using M-ary decomposition and virtual bits for visually meaningful image encryption},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). Risk spillover network structure learning for correlated
financial assets: A directed acyclic graph approach. <em>ISCI</em>,
<em>580</em>, 152–173. (<a
href="https://doi.org/10.1016/j.ins.2021.08.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using cross-asset return data in global financial markets, we propose a novel empirical framework to identify the causal structure of the asset risk spillover network. The joint return distribution of the global financial system can be characterized using a directed acyclic graph approach. However, since assets tend to be highly correlated during market turbulence, when adopting a nodewise penalized regression approach for neighborhood estimation, parameter estimates will receive large standard errors, and edges cannot be reliably estimated. In this work, we propose a two-stage approach for directed acyclic graph skeleton estimation for highly correlated variables. In the first stage, a variable screening ensemble is incorporated into the sparse partial least squares regression method to both reduce the size of the active variables set and impose an adaptive penalization on the weight vectors . In the second stage, a modified PC algorithm based on Gram-Schmidt orthogonalization is applied to remove the false positive edges. Simulation studies are conducted to demonstrate the effectiveness of the proposed method. Finally, we apply our method to analyze the asset risk spillover channels for international financial assets during the COVID-19 pandemic.},
  archive      = {J_ISCI},
  author       = {Xiaokang Wang and Huiwen Wang and Zhichao Wang and Shan Lu and Ying Fan},
  doi          = {10.1016/j.ins.2021.08.072},
  journal      = {Information Sciences},
  pages        = {152-173},
  shortjournal = {Inf. Sci.},
  title        = {Risk spillover network structure learning for correlated financial assets: A directed acyclic graph approach},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supporting features updating of apps by analyzing similar
products in app stores. <em>ISCI</em>, <em>580</em>, 129–151. (<a
href="https://doi.org/10.1016/j.ins.2021.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facing the increasingly fierce competition, app developers have to update features of their products continually. In this process, developers need to not only consider users’ demands but also pay attention to what other similar apps do so that they can stay one step ahead in the competition. App stores provide large-scale useable data for achieving this goal while how to use them efficiently becomes a new challenge for developers. In this paper, we aim at helping developers make feature updating strategies of their apps by analyzing data of similar products in App stores. Firstly, we identify similar apps by using texts in app descriptions and UI. Then, we gain and integrate the information of updated features in these apps from their release texts. Furthermore, we match reviews with the related updated features, which helps developers predict the payback if they adopt a similar updating strategy. To validate the proposed approach, we conducted a series of experiments based on Google Play. The results show that our approach can analyze the data reasonably and provide useful information for developers making feature updating strategy in the evolution of their own products.},
  archive      = {J_ISCI},
  author       = {Huaxiao Liu and Yihui Wang and Yuzhou Liu and Shanquan Gao},
  doi          = {10.1016/j.ins.2021.08.050},
  journal      = {Information Sciences},
  pages        = {129-151},
  shortjournal = {Inf. Sci.},
  title        = {Supporting features updating of apps by analyzing similar products in app stores},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Granular-conditional-entropy-based attribute reduction for
partially labeled data with proxy labels. <em>ISCI</em>, <em>580</em>,
111–128. (<a href="https://doi.org/10.1016/j.ins.2021.08.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction is attracting considerable attention in the theory of rough sets, and thus many rough-set-based attribute reduction methods have been presented. However, most of them are specifically designed for either labeled or unlabeled data , whereas many real-world applications involve partial supervision. In this paper, we propose a rough-set-based semi-supervised attribute reduction method for partially labeled data. Specifically, using prior class-distribution information, we first develop a simple yet effective strategy to produce proxy labels for unlabeled data. Then, the concept of information granularity is integrated into an information-theoretic measure, based on which, a novel granular conditional entropy measure is proposed, and its monotonicity is theoretically proved. Furthermore, a fast heuristic algorithm is provided to generate the optimal reduct of partially labeled data, which could accelerate the process of attribute reduction by removing irrelevant examples and simultaneously excluding redundant attributes. Extensive experiments conducted on UCI data sets demonstrate that the proposed semi-supervised attribute reduction method is promising and, in terms of classification performance, it even compares favorably with supervised methods on labeled and unlabeled data with true labels (Our code and experimental data are released at Mendeley Data https://doi.org/10.17632/v3byhx2v8s.1).},
  archive      = {J_ISCI},
  author       = {Can Gao and Jie Zhou and Duoqian Miao and Xiaodong Yue and Jun Wan},
  doi          = {10.1016/j.ins.2021.08.067},
  journal      = {Information Sciences},
  pages        = {111-128},
  shortjournal = {Inf. Sci.},
  title        = {Granular-conditional-entropy-based attribute reduction for partially labeled data with proxy labels},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The breaking of additively reciprocal property of fuzzy
preference relations and its implication to decision making under
uncertainty. <em>ISCI</em>, <em>580</em>, 92–110. (<a
href="https://doi.org/10.1016/j.ins.2021.08.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing works usually assume that fuzzy preference relations (FPRs) exhibit additively reciprocal property. In this study, we investigate the situation that FPRs have no additively reciprocal property and address its implication to decision making under uncertainty. First, the considered situation is captured by proposing the novel concept of additively reciprocal property breaking (ARPB) for FPRs. It is proved that FPRs with ARPB, interval additive reciprocal preference relations (IARPRs) and intuitionistic fuzzy preference relations (IFPRs) are transformed each other. Second, the equivalence between FPRs with ARPR and additive reciprocal matrices (ARMs) is defined by keeping the inconsistency level unchanged. An optimization model is proposed to adjust an FPR without weak transitivity to an ARM with weak transitivity. Third, a novel decision making model is developed by considering weak transitivity of FPRs as the minimum requirement of rational choices. A new algorithm is elaborated on where decision information could be expressed as FPRs with ARPR, IARPRs and IFPRs, respectively. Finally, numerical results are reported to show the advantages of the developed model by comparing with the existing ones. The observations reveal that the concept of ARPB offers a novel understanding for uncertainty in decision information.},
  archive      = {J_ISCI},
  author       = {Fang Liu and Qi-Rui You and Yuan-Kai Hu and Wei-Guo Zhang},
  doi          = {10.1016/j.ins.2021.08.066},
  journal      = {Information Sciences},
  pages        = {92-110},
  shortjournal = {Inf. Sci.},
  title        = {The breaking of additively reciprocal property of fuzzy preference relations and its implication to decision making under uncertainty},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inconsistency guided robust attribute reduction.
<em>ISCI</em>, <em>580</em>, 69–91. (<a
href="https://doi.org/10.1016/j.ins.2021.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction (AR) plays an important role in reducing irrelevant and redundant domain attributes, while maintaining the underlying semantics of retained ones. Based on Earth Mover’s Distance (EMD), this paper presents a robust AR algorithm from the perspective of minimising the inconsistency between the discernibility of the reduct and the entire original attribute set. Due to the susceptibility of the inconsistency gauger to noisy information, a strategy for instance denoising is also proposed by detecting abnormal local class distributions with regard to the global class distribution. With such a pretreatment process for AR, the robustness of the reduct found is significantly improved, as testified by systematic experimental investigations. The experimental results demonstrate that the reduct gained by the proposed approach generally outperforms those attained by the application of popular, state-of-the-art AR techniques, in terms of both the size of attribute reduction and the classification results using the reduced attributes.},
  archive      = {J_ISCI},
  author       = {Yanpeng Qu and Zheng Xu and Changjing Shang and Xiaolong Ge and Ansheng Deng and Qiang Shen},
  doi          = {10.1016/j.ins.2021.08.049},
  journal      = {Information Sciences},
  pages        = {69-91},
  shortjournal = {Inf. Sci.},
  title        = {Inconsistency guided robust attribute reduction},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimized data manipulation methods for intensive hesitant
fuzzy set with applications to decision making. <em>ISCI</em>,
<em>580</em>, 55–68. (<a
href="https://doi.org/10.1016/j.ins.2021.08.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of large amounts of hesitant fuzzy data brings more opportunities and challenges for optimal decision-making results. The granularity of the hesitant fuzzy set has been significantly improved, but the potential for more inconsistent data also increases. Due to high computational complexity and low efficiency, the existing data aggregation methods cannot handle the intensive hesitant fuzzy data. To solve this problem, we first propose the optimization strategy for the intensive hesitant fuzzy data. Then the data redundancy elimination method and the data aggregation method are proposed. The extensions of hesitant fuzzy set and normal-type hesitant fuzzy set are proposed for intensive hesitant fuzzy data manipulations. The aggregation methods and the data structure estimation methods of the extensions are also discussed. Finally, a practical application to the wine quality determination is provided, and some comparative analyses are conducted to demonstrate the effectiveness of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Zhinan Hao and Zeshui Xu and Hua Zhao and Zhan Su},
  doi          = {10.1016/j.ins.2021.08.063},
  journal      = {Information Sciences},
  pages        = {55-68},
  shortjournal = {Inf. Sci.},
  title        = {Optimized data manipulation methods for intensive hesitant fuzzy set with applications to decision making},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facial expression recognition with grid-wise attention and
visual transformer. <em>ISCI</em>, <em>580</em>, 35–54. (<a
href="https://doi.org/10.1016/j.ins.2021.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {F acial E xpression R ecognition (FER) has achieved remarkable progress as a result of using C onvolutional N eural N etworks (CNN). Relying on the spatial locality , convolutional filters in CNN, however, fail to learn long-range inductive biases between different facial regions in most neural layers. As such, the performance of a CNN-based model for FER is still limited. To address this problem, this paper introduces a novel FER framework with two attention mechanisms for CNN-based models, and these two attention mechanisms are used for the low-level feature learning the high-level semantic representation , respectively. In particular, in the low-level feature learning , a grid-wise attention mechanism is proposed to capture the dependencies of different regions from a facial expression image such that the parameter update of convolutional filters in low-level feature learning is regularized. In the high-level semantic representation , a visual transformer attention mechanism uses a sequence of visual semantic tokens (generated from pyramid features of high convolutional layer blocks) to learn the global representation. Extensive experiments have been conducted on three public facial expression datasets, CK+, FER+, and RAF-DB. The results show that our FER-VT has achieved state-of-the-art performance on these datasets, especially with a 100\% accuracy on CK + datasets without any extra training data.},
  archive      = {J_ISCI},
  author       = {Qionghao Huang and Changqin Huang and Xizhe Wang and Fan Jiang},
  doi          = {10.1016/j.ins.2021.08.043},
  journal      = {Information Sciences},
  pages        = {35-54},
  shortjournal = {Inf. Sci.},
  title        = {Facial expression recognition with grid-wise attention and visual transformer},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Item-side ranking regularized distillation for recommender
system. <em>ISCI</em>, <em>580</em>, 15–34. (<a
href="https://doi.org/10.1016/j.ins.2021.08.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent recommender system (RS) have adopted large and sophisticated model architecture to better understand the complex user-item relationships, and accordingly, the size of the recommender is continuously increasing. To reduce the high inference costs of the large recommender, knowledge distillation (KD), which is a model compression technique from a large pre-trained model (teacher) to a small model (student), has been actively studied for RS. The state-of-the-art method is based on the ranking distillation approach, which makes the student preserve the ranking orders among items predicted by the teacher. In this work, we propose a new regularization method designed to maximize the effect of the ranking distillation in RS. We first point out an important limitation and a room for improvement of the state-of-the-art ranking distillation method based on our in-depth analysis.Then, we introduce the item-side ranking regularization , which can effectively prevent the student with limited capacity from being overfitted and enables the student to more accurately learn the teacher’s prediction results. We validate the superiority of the proposed method by extensive experiments on real-world datasets.},
  archive      = {J_ISCI},
  author       = {SeongKu Kang and Junyoung Hwang and Wonbin Kweon and Hwanjo Yu},
  doi          = {10.1016/j.ins.2021.08.060},
  journal      = {Information Sciences},
  pages        = {15-34},
  shortjournal = {Inf. Sci.},
  title        = {Item-side ranking regularized distillation for recommender system},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GLIMG: Global and local item graphs for top-n recommender
systems. <em>ISCI</em>, <em>580</em>, 1–14. (<a
href="https://doi.org/10.1016/j.ins.2021.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based recommendation models work well for top-N recommender systems due to their capability to capture the potential relationships between entities. However, most of the existing methods only construct a single global item graph shared by all the users and regrettably ignore the diverse tastes between different user groups. Inspired by the success of local models for recommendation tasks, this paper provides the first attempt to investigate multiple local item graphs along with a global item graph for graph-based recommendation models. We argue that recommendation on global and local graphs outperforms that on a single global graph or multiple local graphs. Specifically, we propose a novel graph-based recommendation model named GLIMG ( G lobal and L ocal I te M G raphs), which simultaneously captures both the global and local user tastes. By integrating the global and local graphs into an adapted semi-supervised learning model, users’ preferences on items are propagated globally and locally. Extensive experimental results on real-world datasets show that our proposed method consistently outperforms the state-of-the-art counterparts on the top-N recommendation task.},
  archive      = {J_ISCI},
  author       = {Zhuoyi Lin and Lei Feng and Rui Yin and Chi Xu and Chee Keong Kwoh},
  doi          = {10.1016/j.ins.2021.08.018},
  journal      = {Information Sciences},
  pages        = {1-14},
  shortjournal = {Inf. Sci.},
  title        = {GLIMG: Global and local item graphs for top-N recommender systems},
  volume       = {580},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Almost sure exponential stability of two-strategy
evolutionary games with multiplicative noise. <em>ISCI</em>,
<em>579</em>, 888–903. (<a
href="https://doi.org/10.1016/j.ins.2021.08.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, stochastic two-strategy evolutionary games in which the players are interfered by multiplicative noise are studied. We propose a stochastic replicator dynamic model to investigate the almost sure exponential stability (ASES) of general two-strategy games. Compared with the deterministic games and stochastic games with additive noise , our most interesting results concern the impact of multiplicative noise on the cooperation behavior in large well-mixed populations. We establish sufficient conditions on stochastic noise which can ensure the stable equilibrium points of general two-strategy games are indeed ASES. The stochastic Lyapunov framework is used to prove the stochastic stability, where finding the suitable Lyapunov function is the key and challenging in our case. Three different types of two-strategy game models (snowdrift games, hunt stag games and prisoner’s dilemmas) are simulated to verify our theoretical results.},
  archive      = {J_ISCI},
  author       = {Haili Liang and Ying Cui and Xiaoqiang Ren and Xiaofan Wang},
  doi          = {10.1016/j.ins.2021.08.091},
  journal      = {Information Sciences},
  pages        = {888-903},
  shortjournal = {Inf. Sci.},
  title        = {Almost sure exponential stability of two-strategy evolutionary games with multiplicative noise},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple attribute decision making using beta distribution
of intervals, expected values of intervals, and new score function of
interval-valued intuitionistic fuzzy values. <em>ISCI</em>,
<em>579</em>, 863–887. (<a
href="https://doi.org/10.1016/j.ins.2021.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new multiple attribute decision making (MADM) method using the Beta distribution of intervals, the expected values of intervals, and the proposed new score function of interval-valued intuitionistic fuzzy values (IVIFVs). Firstly, it transformed each IVIFV in the decision matrix (DM) into three intervals to get the transformed matrix (TM). Then, it calculates the expected values of the obtained three intervals for each triplet in the TM, respectively, and then uses the proposed new score function to calculate the score value of each IVIFV in the DM to obtain the score matrix. Then, it transforms the interval-valued intuitionistic fuzzy (IVIF) weight of each attribute into three intervals and calculates the expected values of the obtained three intervals, respectively. Then, it uses the proposed new score function to calculate the score value of the IVIF weight of each attribute to obtain the normalized optimal weight of each attribute. Finally, based on the obtained score matrix and the obtained optimal weight of each attribute, it computes the weighted score of each alternative to get the preference order of alternatives. The proposed MADM method can overcome the drawbacks of the existing MADM methods in IVIF environments.},
  archive      = {J_ISCI},
  author       = {Shyi-Ming Chen and Wei-Ting Liao},
  doi          = {10.1016/j.ins.2021.04.028},
  journal      = {Information Sciences},
  pages        = {863-887},
  shortjournal = {Inf. Sci.},
  title        = {Multiple attribute decision making using beta distribution of intervals, expected values of intervals, and new score function of interval-valued intuitionistic fuzzy values},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling uncertainty in declarative artifact-centric process
models using fuzzy logic. <em>ISCI</em>, <em>579</em>, 845–862. (<a
href="https://doi.org/10.1016/j.ins.2021.07.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many business processes, knowledge workers collect information and make decisions about business entities. Artifact-centric process (ACP) models have been proposed to represent such knowledge-intensive processes. Declarative ACP models use precise business rules to define flexible process executions. However, in many business situations knowledge experts have to deal with uncertainty and vagueness. Currently, how to deal with such situations cannot be expressed in declarative ACP models. We propose to use the fuzzy logic framework to model uncertainty in such models. Using Guard-Stage-Milestone (GSM) schemas as declarative ACP notation, we show how GSM schemas can be adapted for modeling gradual progress of real-life knowledge-intensive processes via a fuzzy logic interface. We evaluate the proposed fuzzy GSM schemas in real-life scenarios of airport ground operations and healthcare services .},
  archive      = {J_ISCI},
  author       = {Rik Eshuis and Murat Firat and Uzay Kaymak},
  doi          = {10.1016/j.ins.2021.07.075},
  journal      = {Information Sciences},
  pages        = {845-862},
  shortjournal = {Inf. Sci.},
  title        = {Modeling uncertainty in declarative artifact-centric process models using fuzzy logic},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-dimensional relation model for dimensional sentiment
analysis. <em>ISCI</em>, <em>579</em>, 832–844. (<a
href="https://doi.org/10.1016/j.ins.2021.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensional sentiment analysis has received considerable attention because it can represent affective states as continuous numerical values on multiple dimensions such as valence (positive–negative) and arousal (excited–calm). Compared to the categorical approach, which represents affective states as several discrete classes (e.g., positive and negative), the dimensional approach can provide more fine-grained (real-valued) sentiment analysis. Traditional approaches to predicting dimensional sentiment scores typically treat each dimension independently without consideration of relations between dimensions. In fact, different dimensions may correlate with each other. For example, expressions with a higher valence score usually have a higher arousal score, And higher irony expressions usually have a lower valence score. Such relations between dimensions are useful for dimension score prediction. To this end, this study proposes a multi-dimensional relation model to incorporate relations between dimensions into deep neural networks for dimension score prediction. The proposed method has two modes: internal and external. The internal mode incorporates the relations between dimensions into sentence representations before prediction, whereas the external mode builds a linear regression model that can capture the relations between dimensions to refine the predicted scores after prediction. To evaluate the proposed method, we created a Chinese three-dimensional corpus with valence-arousal-irony (VAI) ratings. Experiments using various neural network architectures demonstrate that the proposed multi-dimensional relation model outperformed those that treat each dimension independently. In addition, the internal mode outperformed the external mode, and a combination of the two modes achieved the best performance.},
  archive      = {J_ISCI},
  author       = {Housheng Xie and Wei Lin and Shuying Lin and Jin Wang and Liang-Chih Yu},
  doi          = {10.1016/j.ins.2021.08.052},
  journal      = {Information Sciences},
  pages        = {832-844},
  shortjournal = {Inf. Sci.},
  title        = {A multi-dimensional relation model for dimensional sentiment analysis},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intrusion detection on internet of vehicles via combining
log-ratio oversampling, outlier detection and metric learning.
<em>ISCI</em>, <em>579</em>, 814–831. (<a
href="https://doi.org/10.1016/j.ins.2021.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Internet of vehicles (IoV) technology becomes a research hotspot. However, it also becomes a hotbed for malicious attacks . In the IoV, frequent data transmission and complex connections among numerous different nodes increase the complexity and diversity of malicious attacks . In order to realize the accurate and rapid detection of malicious attacks in the IoV environment, in this paper, an intrusion detection method is proposed by combining oversampling, outlier detection and metric learning. The proposed approach improves intrusion detection effect in three main ways: 1) it oversamples the minority classes based on a novel strategy, 2) it introduces a new feature with basis of imbalance ratio , and 3) it reduces the outliers and rescales original samples actively to make the decision boundary clearer by combining outlier detection and distance metric learning . Furthermore, genetic algorithm is used to extract the optimal subset of features. The experimental results show that the proposed method can achieve 98.51\% accuracy and maintain 0.82\% false alarm rate on UNSW-NB15 dataset. Also, it outperforms the existing methods on ROAD, Car-Hacking and CAN-intrusion dataset for in-vehicle communications.},
  archive      = {J_ISCI},
  author       = {Fusheng Jin and Mengnan Chen and Weiwei Zhang and Ye Yuan and Shuliang Wang},
  doi          = {10.1016/j.ins.2021.08.010},
  journal      = {Information Sciences},
  pages        = {814-831},
  shortjournal = {Inf. Sci.},
  title        = {Intrusion detection on internet of vehicles via combining log-ratio oversampling, outlier detection and metric learning},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A multi-objective differential evolution algorithm based on
domination and constraint-handling switching. <em>ISCI</em>,
<em>579</em>, 796–813. (<a
href="https://doi.org/10.1016/j.ins.2021.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many domination-based multi-objective evolutionary algorithms (MOEAs) are designed for constrained multi-objective optimization problems (CMOPs). However, they still face the challenge of balancing the feasibility, convergence and distribution. This paper tackles this issue by proposing a multi-objective differential evolution algorithm based on domination and a mechanism of constraint-handling switching (MODE-CHS). In constraint-handling switching, if there are no feasible solutions in the population, the population evolves by constraint-handling; otherwise, the population evolves without handling constraints. This mechanism enhances the rate of population convergence to the maximum while obtaining the feasible solutions. Furthermore, in MODE-CHS, the feasible solutions are saved to an external archive and evolve together with the population to explore the feasible region. Meanwhile, to enhance the distribution, the offspring of the external archive also participates in the individual-update procedure of the population. 27 bench-mark test problems and two real-world problems are used for the performance comparison of the proposed algorithm with other five state-of-the-art algorithms. In the experiment, the proposed algorithm, MODE-CHS, is shown to produce satisfactory solutions for most of the tested functions, where other five MOEAs perform relatively worse. The experiment results demonstrate MODE-CHS is very competitive for solving CMOPs.},
  archive      = {J_ISCI},
  author       = {Yongkuan Yang and Jianchang Liu and Shubin Tan and Yuanchao Liu},
  doi          = {10.1016/j.ins.2021.08.038},
  journal      = {Information Sciences},
  pages        = {796-813},
  shortjournal = {Inf. Sci.},
  title        = {A multi-objective differential evolution algorithm based on domination and constraint-handling switching},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the stopping time problem of interval-valued differential
equations under generalized hukuhara differentiability. <em>ISCI</em>,
<em>579</em>, 776–795. (<a
href="https://doi.org/10.1016/j.ins.2021.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the definitions of stopping time , forward and backward solutions to interval-valued differential equations under generalized Hukuhara differentiability , which could be applied to discuss the evolution of dynamical systems with practical backgrounds. By using these definitions, we study stopping time problems for the Malthusian population model and the logistic model in details. Then, some general conclusions about stopping time problems for interval-valued differential equations are considered and the results are shown to be feasible by providing some examples.},
  archive      = {J_ISCI},
  author       = {Hongzhou Wang and Rosana Rodríguez-López and Alireza Khastan},
  doi          = {10.1016/j.ins.2021.08.012},
  journal      = {Information Sciences},
  pages        = {776-795},
  shortjournal = {Inf. Sci.},
  title        = {On the stopping time problem of interval-valued differential equations under generalized hukuhara differentiability},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel quantile-guided dual prediction strategies for
dynamic multi-objective optimization. <em>ISCI</em>, <em>579</em>,
751–775. (<a href="https://doi.org/10.1016/j.ins.2021.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-objective optimization problems (DMOPs) require evolutionary algorithms (EAs) to accurately track the Pareto-optimal Front (PF) and generate the solutions along the PF in the constantly changing environment. In order to solve the DMOPs, a novel quantile-guided dual prediction strategies evolutionary algorithm (NQDPEA) is proposed in this paper. Quantiles are often employed to characterize data in statistics . In NQDPEA, the evolution of the population is guided by the quantile , which is to predict the position of the quantile in a new environment through historical quantile information. Then, a new solution set is expanded according to the location of the new quantile. Moreover, its prediction strategies not only predict Pareto-optimal set (PS) by quantile in the decision space but also predict the PF by quantile in objective space and then mapping back to decision space. Through the adaptive combination strategy, the proportion of the new solutions produced by each prediction strategy changes adaptively. To prove the performance of NQDPEA, it is compared with four powerful EAs on 13 test instances. Experimental results show that NQDPEA can effectively generate high quality solutions uniformly along PF.},
  archive      = {J_ISCI},
  author       = {Hao Sun and Anran Cao and Ziyu Hu and Xiaxia Li and Zhiwei Zhao},
  doi          = {10.1016/j.ins.2021.08.027},
  journal      = {Information Sciences},
  pages        = {751-775},
  shortjournal = {Inf. Sci.},
  title        = {A novel quantile-guided dual prediction strategies for dynamic multi-objective optimization},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Novel three-way generative classifier with weighted scoring
distribution. <em>ISCI</em>, <em>579</em>, 732–750. (<a
href="https://doi.org/10.1016/j.ins.2021.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Naive Bayes classifier (NBC) is a classical binary generative classifier that has been extensively researched and developed for use in various applications owing to its simplicity and high efficiency. However, in practice, the distinct advantages of the NBC are often challenged by the conditional independence assumption among attributes and the zero-count problem. Moreover, the NBC strictly assigns a certain label to every object and lacks a classification mechanism to handle boundary objects ; this may deteriorate the classification performances. Compared with binary classifiers , three-way classifiers provide a delayed decision for boundary objects . However, most existing three-way classifiers have been developed based on rough sets, which have high time complexity and decision conflict. In this study, based on the advantages of the NBC and three-way classifier, a novel three-way generative classifier with a weighted scoring distribution (3WGC-WSD) is proposed to improve the classification performances. First, to calculate the scores of an object under different classes, a scoring function that makes the best use of the advantages of parameter estimation in the NBC is defined. Second, a self-adaptive attribute weighted algorithm is designed to relax the attribute conditional independence assumption by attribute weighted and attribute reduction . Third, a non-parametric binary generative classifier with a weighted scoring function (2GC-WSF) is designed based on the scoring function and attribute weighted algorithm. Finally, inspired by the three-way decision, 3WGC-WSD is extended on 2GC-WSF to improve classification performances by providing delay decision for boundary objects. Experiments and comparisons on 15 widely-used UCI benchmark datasets demonstrate that 3WGC-WSD outperforms three state-of-the-art classifiers and three classical classifiers in terms of four indexes. Furthermore, the efficiency of 3WGC-WSD and 2GC-WSF is demonstrated in comparison with three classifiers on 10 datasets.},
  archive      = {J_ISCI},
  author       = {Chengying Wu and Qinghua Zhang and Yunlong Cheng and Mao Gao and Guoyin Wang},
  doi          = {10.1016/j.ins.2021.08.025},
  journal      = {Information Sciences},
  pages        = {732-750},
  shortjournal = {Inf. Sci.},
  title        = {Novel three-way generative classifier with weighted scoring distribution},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Formal concept analysis for the generation of plural
referring expressions. <em>ISCI</em>, <em>579</em>, 717–731. (<a
href="https://doi.org/10.1016/j.ins.2021.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Referring Expression Generation (REG) is one of the most relevant and complex tasks in Natural Language Generation . Plural referring expressions are linguistic expressions that intend to identify a set of objects in a certain context. In this paper we formulate for the first time plural referring expressions and the elements of the associated REG problem in terms of the well known Formal Concept Analysis (FCA) mathematical framework. We provide theoretical results and general algorithms for computing the whole collection of referable sets in the context under analysis, as well as a condensed representation of all referring expressions for each referable set.},
  archive      = {J_ISCI},
  author       = {Nicolás Marín and Gustavo Rivas-Gervilla and M. Dolores Ruiz and Daniel Sánchez},
  doi          = {10.1016/j.ins.2021.08.024},
  journal      = {Information Sciences},
  pages        = {717-731},
  shortjournal = {Inf. Sci.},
  title        = {Formal concept analysis for the generation of plural referring expressions},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Learning unsupervised node representation from multi-view
network. <em>ISCI</em>, <em>579</em>, 700–716. (<a
href="https://doi.org/10.1016/j.ins.2021.07.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of learning node representations for networks with multiple views, which aims to infer robust node representations by simultaneously considering multiple views during the representations learning process. We propose an effective method for this task, named as Multi-View Representation Learning (MVRL). The new method extends the matrix factorization model for node representation learning of multi-view network in unsupervised representation learning scenario, which simultaneously learns a set of view weights to identify the quality of each view, and the network representations as matrix factorization of the weighted combination of multiple views. An efficient optimization method with linear complexity is proposed to solve the new model, and a simple yet efficient method is proposed for fast updating of the new node’s vector representation without updating the whole nodes’ representation vectors. We have evaluated the performance of our proposed approach on five real-world multi-view network datasets. Experimental results on the node classification task demonstrated the superior performance and efficiency of our proposed method.},
  archive      = {J_ISCI},
  author       = {Chen Wang and Xiaojun Chen and Bingkun Chen and Feiping Nie and Bo Wang and Zhong Ming},
  doi          = {10.1016/j.ins.2021.07.087},
  journal      = {Information Sciences},
  pages        = {700-716},
  shortjournal = {Inf. Sci.},
  title        = {Learning unsupervised node representation from multi-view network},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fusing framework of shortcut convolutional neural
networks. <em>ISCI</em>, <em>579</em>, 685–699. (<a
href="https://doi.org/10.1016/j.ins.2021.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have proven to be very successful in learning task-specific computer vision features. To integrate features from different layers in standard CNNs, we present a fusing framework of shortcut convolutional neural networks (S-CNNs). This framework can fuse arbitrary scale features by adding weighted shortcut connections to the standard CNNs. Besides the framework, we propose a shortcut indicator (SI) of binary string to stand for a specific S-CNN shortcut style. Additionally, we design a learning algorithm for the proposed S-CNNs. Comprehensive experiments are conducted to compare its performances with standard CNNs on multiple benchmark datasets for different visual tasks. Empirical results show that if we choose an appropriate fusing style of shortcut connections with learnable weights, S-CNNs can perform better than standard CNNs regarding accuracy and stability in different activation functions and pooling schemes initializations, and occlusions. Moreover, S-CNNs are competitive with ResNets and can outperform GoogLeNet, DenseNets, Multi-scale CNN, and DeepID.},
  archive      = {J_ISCI},
  author       = {Ting Zhang and Muhammad Waqas and Zhaoying Liu and Shanshan Tu and Zahid Halim and Sadaqat Ur Rehman and Yujian Li and Zhu Han},
  doi          = {10.1016/j.ins.2021.08.030},
  journal      = {Information Sciences},
  pages        = {685-699},
  shortjournal = {Inf. Sci.},
  title        = {A fusing framework of shortcut convolutional neural networks},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asymptotic stability of probabilistic logical networks with
random impulsive effects. <em>ISCI</em>, <em>579</em>, 667–684. (<a
href="https://doi.org/10.1016/j.ins.2021.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the asymptotic set stability of probabilistic logical networks (PLNs) with random impulsive disturbances. A hybrid index model is applied to describe the impulsive PLN. Both the sequence of switching signals and the sequence of impulsive intervals are assumed to be independent and identically distributed (i.i.d.). Some novel methods are proposed to reduce the complexity of calculating invariant subsets and verifying the convergence of homogeneous Markov chains (HMCs). By sampling at impulsive instants, an HMC is obtained from the impulsive PLN, whose initial distribution and transition probability matrix (TPM) are approximately calculated. Based on the obtained HMC, the necessary and sufficient conditions for the asymptotic set stability of the impulsive PLN in hybrid domain and time domain are presented, respectively. Finally, examples are given to illustrate the main results.},
  archive      = {J_ISCI},
  author       = {Bingquan Chen and Jinde Cao and Jie Zhong and Lianglin Xiong},
  doi          = {10.1016/j.ins.2021.08.017},
  journal      = {Information Sciences},
  pages        = {667-684},
  shortjournal = {Inf. Sci.},
  title        = {Asymptotic stability of probabilistic logical networks with random impulsive effects},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Localization in wireless sensor networks with mobile anchor
node path planning mechanism. <em>ISCI</em>, <em>579</em>, 648–666. (<a
href="https://doi.org/10.1016/j.ins.2021.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the accurate locations of randomly deployed sensors in a given geographical region is a critical problem in the field of Wireless Sensor Networks . Various approaches have been proposed in the past to tackle this problem. Most of the existing techniques rely on the use of a beacon node which traverses throughout the region with limited power sources. Sensors use the beacon node positions for self localization . The trajectory of the beacon node has an influence on the accuracy, time and efficiency of the localization algorithm. In this paper, we propose Cosine Rule based Localization (CRL) algorithm for static trajectories of the mobile beacon node. Existing schemes use trilateration for position estimation of sensor nodes . The proposed method uses the Cosine rule on received beacon positions and distances obtained from RSSI in such a way that lines representing distances intersect at one point for the application of the Cosine rule. Simulation results reveal that CRL enables the unknown sensors to locate themselves with better accuracy in comparison with the existing trilateration technique for all the trajectories.},
  archive      = {J_ISCI},
  author       = {Ketan Sabale and S. Mini},
  doi          = {10.1016/j.ins.2021.08.004},
  journal      = {Information Sciences},
  pages        = {648-666},
  shortjournal = {Inf. Sci.},
  title        = {Localization in wireless sensor networks with mobile anchor node path planning mechanism},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A self-adaptive fuzzy learning system for streaming data
prediction. <em>ISCI</em>, <em>579</em>, 623–647. (<a
href="https://doi.org/10.1016/j.ins.2021.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel self-adaptive fuzzy learning (SAFL) system is proposed for streaming data prediction. SAFL self-learns from data streams a predictive model composed of a set of prototype-based fuzzy rules, with each of which representing a certain local data distribution, and continuously self-evolves to follow the changing data patterns in non-stationary environments. Unlike conventional evolving fuzzy systems, both the fuzzy inference and consequent parameter learning schemes utilised by SAFL are simplified so that only a small number of selected fuzzy rules within the rule base are involved in system output generation and parameter updating during a learning cycle. Such simplification not only significantly reduces the system’s computational complexity but also increases its prediction precision. In addition, both theoretical and empirical investigations guarantee the stability of the resulting SAFL. Comparative experimental studies on a wide variety of benchmark and real-world problems demonstrate that SAFL is able to learn from streaming data in a highly efficient manner and to make predictions with a great accuracy, revealing the effectiveness and validity of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Xiaowei Gu and Qiang Shen},
  doi          = {10.1016/j.ins.2021.08.023},
  journal      = {Information Sciences},
  pages        = {623-647},
  shortjournal = {Inf. Sci.},
  title        = {A self-adaptive fuzzy learning system for streaming data prediction},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep dynamic imputation of clinical time series for
mortality prediction. <em>ISCI</em>, <em>579</em>, 607–622. (<a
href="https://doi.org/10.1016/j.ins.2021.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing values in clinical time-series data are pervasive and inevitable; they not only increase the complexity and difficulty of analyzing the data but also lead to biased results. To tackle these two problems, researchers have been exploring recurrent neural network (RNN)-based methods for detecting how well missing values are addressed with the aim of achieving state-of-the-art performance. However, these methods have two practical drawbacks. 1) Handling time-series data with multiple, irregular, abnormal values is difficult. 2) The patterns that may be present in the missing clinical data are not thoroughly considered. Moreover, to the best of our knowledge, none of these methods have been explicitly designed to dynamically optimize the imputation quality for better performance in the realm of clinical time-series analytics. By considering the quality of imputed values , we propose a 2-step integrated imputation-prediction model based on gated recurrent units (GRUs) for medical prediction tasks. In the first step, the missing values are imputed using a sophisticated model based on a replenished GRU with a hidden state decay mechanism (RGRU-D), which is followed by evaluation through two additional layers. In the second step, the optimized imputed values are used to predict the risk of mortality in critical patients. Our model effectively supplies missing values for the masking , time interval , bursty , and cumulative missing rate variables within an integrated deep architecture. Extensive experiments on a real-world ICU dataset demonstrate that our model performs better than the compared methods in terms of the imputation quality and prediction accuracy.},
  archive      = {J_ISCI},
  author       = {Zhenkun Shi and Sen Wang and Lin Yue and Lixin Pang and Xianglin Zuo and Wanli Zuo and Xue Li},
  doi          = {10.1016/j.ins.2021.08.016},
  journal      = {Information Sciences},
  pages        = {607-622},
  shortjournal = {Inf. Sci.},
  title        = {Deep dynamic imputation of clinical time series for mortality prediction},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved stabilization criteria for takagi–sugeno fuzzy
systems with variable delays. <em>ISCI</em>, <em>579</em>, 591–606. (<a
href="https://doi.org/10.1016/j.ins.2021.07.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present research, the stability analysis and stabilization of nonlinear processes characterized by the Takagi–Sugeno (T–S) fuzzy model with variable time delays have been investigated. The state’s delay is presumed to belong to a given interval, ensuring that the delay lower limit is not constrained to zero. First, a new and improved integral inequality (II) lemma is proposed to deal with the cross-product terms in the derivative of the constructed delay-product-type (DPT) augmented Lyapunov–Krasovskii functional (LKF). Second, a novel delay-range-dependent (DRD) stability condition and parallel distributed compensation (PDC) technique-based stabilization condition is then achieved in terms of linear matrix inequalities (LMIs). Finally, to illustrate the superiority of the proposed stability criterion and controller design approach over existing ones, three numerical examples are given.},
  archive      = {J_ISCI},
  author       = {Rupak Datta and Ramasamy Saravanakumar and Rajeeb Dey and Baby Bhattacharya and Choon Ki Ahn},
  doi          = {10.1016/j.ins.2021.07.089},
  journal      = {Information Sciences},
  pages        = {591-606},
  shortjournal = {Inf. Sci.},
  title        = {Improved stabilization criteria for Takagi–Sugeno fuzzy systems with variable delays},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). APAL: Adjacency propagation algorithm for overlapping
community detection in biological networks. <em>ISCI</em>, <em>579</em>,
574–590. (<a href="https://doi.org/10.1016/j.ins.2021.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel method called Adjacency Propagation Algorithm (APAL) which considers the notion that the adjacent vertices are the best candidates for detecting overlapping communities in an undirected, unweighted, nontrivial graph. This is a compact algorithm with a single threshold parameter used to filter the detected communities according to their intraconnectivity property. In this study, APAL was tested rigorously using synthetic generators, such as the widely accepted LFR benchmark, as well as real data sets of yeast and human protein interactions networks . It was compared against the foremost algorithms in the field; the Clique Percolation Method (CPM), Community Overlap Propagation Algorithm (COPRA) and Neighbourhood-Inflated Seed Expansion (NISE). The results show that APAL outperforms its competitors for networks with increases in the number of memberships of the overlapping vertices. Such conditions are often found in biological networks , where a particular protein subunit may form part of several complexes. We believe that this shows the value of the implementation of APAL for protein interaction and other biological networks.},
  archive      = {J_ISCI},
  author       = {Osman Doluca and Kaya Oğuz},
  doi          = {10.1016/j.ins.2021.08.031},
  journal      = {Information Sciences},
  pages        = {574-590},
  shortjournal = {Inf. Sci.},
  title        = {APAL: Adjacency propagation algorithm for overlapping community detection in biological networks},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Make a difference, open the door: The energy-efficient
multi-layer thermal comfort control system based on a graph airflow
model with doors and windows. <em>ISCI</em>, <em>579</em>, 553–573. (<a
href="https://doi.org/10.1016/j.ins.2021.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classical approach to thermal comfort control utilizes fully automatic controllers for temperature, humidity, and other variables. Although commonly used, such systems may need much energy. If speed is not the priority, natural airflow may be considered for the control process. However, this would require a model including airflow changes caused by the opening of windows and doors, which has not been found in the literature yet. This article presents a novel multi-layer control system for thermal comfort control that uses an original graph-based representation of opening and closing doors and windows. It allowed us to model airflow dynamics. The system has two essential advantages. Firstly, the natural airflow between adjacent zones may help the automatic controllers achieve their goals and save energy. Secondly, including the windows and doors into the model lets the human play an active role in an eco-aware control process, which corresponds with the “human-in-the-loop” trends. The concept has been illustrated with an example house with four types of thermal comfort zones. The optimization approach based on finding the optimal subgraph of opened windows and doors between chosen zones led up to 5\% 5\% energy savings of the electric actuators , compared with the classical fully automated structure.},
  archive      = {J_ISCI},
  author       = {Inez Okulska and Maciej Ławryńczuk},
  doi          = {10.1016/j.ins.2021.08.029},
  journal      = {Information Sciences},
  pages        = {553-573},
  shortjournal = {Inf. Sci.},
  title        = {Make a difference, open the door: The energy-efficient multi-layer thermal comfort control system based on a graph airflow model with doors and windows},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to hash based on angularly discriminative
embedding. <em>ISCI</em>, <em>579</em>, 541–552. (<a
href="https://doi.org/10.1016/j.ins.2021.07.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing, a widely-studied tool to the approximate nearest neighbor search, aims to embed samples as compact binary representations . Current approaches to this issue generally seek a low-dimensional Hamming Space where representations are discrete and have smaller intra-class distance and larger inter-class distance. As a result, the performance is often limited by the discrete constraint. In this work, we propose to seek an angularly discriminative Embedding Space where representations are continuous and have smaller intra-class angular margin and larger inter-class angular margin. For our goal is to learn continuous representations rather than discrete hash codes, the problems caused by discrete constraint can be avoided. Besides, in order to further reduce the gap between Embedding Space and Hamming Space, we introduce an additional coordinate-constraint for representations. Our method is simple yet effective. Extensive experiments on the image retrieval task show that it achieves encouraging results on four benchmark datasets. Furthermore, the success of our proposed method demonstrates that leveraging the progress made in representation learning to improve hashing is promising in future.},
  archive      = {J_ISCI},
  author       = {Zhanxuan Hu and Shuzheng Hao and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.ins.2021.07.047},
  journal      = {Information Sciences},
  pages        = {541-552},
  shortjournal = {Inf. Sci.},
  title        = {Learning to hash based on angularly discriminative embedding},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Threshold reusable fuzzy extractor and an application to
joint access control via biometric information. <em>ISCI</em>,
<em>579</em>, 525–540. (<a
href="https://doi.org/10.1016/j.ins.2021.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy extractor can be used to convert the reading of a noisy non-uniform source into a reliably reproducible and almost uniform string, while reusable fuzzy extractor allows multiple extractions of the same source. In this paper, we propose multi-party fuzzy extractor, called threshold reusable fuzzy extractor, whose execution requires a threshold number of members. New definition and efficient construction are given with security proofs and experimental implementations. It preserves the inherent properties of fuzzy extractor with expanded use in multi-party scenarios. Based on the proposed threshold reusable fuzzy extractor, an application in privacy protection is given to store and share sensitive data by smart contract on blockchain , achieving joint access control via biometric information.},
  archive      = {J_ISCI},
  author       = {Jie Ma and Bin Qi and Kewei Lv},
  doi          = {10.1016/j.ins.2021.08.021},
  journal      = {Information Sciences},
  pages        = {525-540},
  shortjournal = {Inf. Sci.},
  title        = {Threshold reusable fuzzy extractor and an application to joint access control via biometric information},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beyond global and local multi-target learning.
<em>ISCI</em>, <em>579</em>, 508–524. (<a
href="https://doi.org/10.1016/j.ins.2021.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-target prediction, an instance has to be classified along multiple target variables at the same time, where each target represents a category or numerical value. There are several strategies to tackle multi-target prediction problems: the local strategy learns a separate model for each target variable independently, while the global strategy learns a single model for all target variables together. Previous studies suggested that the global strategy should be preferred because (1) learning is more efficient, (2) the learned models are more compact, and (3) it overfits much less than the local strategy, as it is harder to overfit on several targets at the same time than on one target. However, it is not clear whether the global strategy exploits correlations between the targets optimally. In this paper, we investigate whether better results can be obtained by learning multiple multi-target models on several partitions of the targets. To answer this question, we first determined alternative partitions using an exhaustive search strategy and a strategy based on a genetic algorithm, and then compared the results of the global and local strategies against these. We used decision trees and random forests as base models. The results show that it is possible to outperform global and local approaches, but finding a good partition without incurring in overfitting remains a challenging task.},
  archive      = {J_ISCI},
  author       = {Márcio Basgalupp and Ricardo Cerri and Leander Schietgat and Isaac Triguero and Celine Vens},
  doi          = {10.1016/j.ins.2021.08.022},
  journal      = {Information Sciences},
  pages        = {508-524},
  shortjournal = {Inf. Sci.},
  title        = {Beyond global and local multi-target learning},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed fault detection and isolation for uncertain
linear discrete time-varying heterogeneous multi-agent systems.
<em>ISCI</em>, <em>579</em>, 483–507. (<a
href="https://doi.org/10.1016/j.ins.2021.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed fault detection and isolation of linear discrete time-varying multi-agent systems subject to heterogeneous dynamics and norm bounded model uncertainties is investigated. By combining the model uncertainties and external disturbances into a new generalized disturbance, a distributed closed-loop residual generator is constructed based on the estimate of the generalized disturbance. Then, the concerned fault detection is transformed into an indefinite quadratic minimum problem by using the finite-horizon robust H ∞ H∞ filtering method, for which necessary and sufficient minimum conditions are provided by the Krein-space theory. Afterwards, a computationally efficient recursive algorithm is further developed to determine the residual for individual agent. Based on the resulting residuals, the fault occurrence can be alerted by devising a novel distributed fault detection scheme, which is then applied for the fault isolation by some appropriate transformation of the output measurements. Finally, both numerical and practical simulations are proposed to verify the effectiveness of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Ping Wang and Peilu Zou and Chengpu Yu and Jian Sun},
  doi          = {10.1016/j.ins.2021.08.033},
  journal      = {Information Sciences},
  pages        = {483-507},
  shortjournal = {Inf. Sci.},
  title        = {Distributed fault detection and isolation for uncertain linear discrete time-varying heterogeneous multi-agent systems},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure fusion approach for the internet of things in smart
autonomous multi-robot systems. <em>ISCI</em>, <em>579</em>, 468–482.
(<a href="https://doi.org/10.1016/j.ins.2021.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of smart autonomous multi-robot systems has received increasing attention and dramatically developed, and this situation greatly promotes the development of the Internet of Things (IoT) and brings the IoT into a new stage. However, the IoT has some emerging issues, such as security and privacy; among many concerns, trusted identity authentication and consensus protocols are the main ones. To address these issues, this study proposes a novel scheme for the identity authentication and consensus algorithm . In the proposed scheme, an identity-based authentication model is designed, and all communication nodes utilize this model to establish connection and conduct data exchange. Meanwhile, a hash pool-based joint consensus algorithm is constructed. All transmission data are strictly protected by permuting hash functions from hash pool and utilizing the generated random number. This feature greatly enhances the security for the IoT. Analysis and experimental results demonstrate that the proposed scheme provides enhanced security and reliability for the IoT. Furthermore, the time efficiency is encouraging, and the communication and storage cost is promising.},
  archive      = {J_ISCI},
  author       = {Wei Liang and Zuoting Ning and Songyou Xie and Yupeng Hu and Shaofei Lu and Dafang Zhang},
  doi          = {10.1016/j.ins.2021.08.035},
  journal      = {Information Sciences},
  pages        = {468-482},
  shortjournal = {Inf. Sci.},
  title        = {Secure fusion approach for the internet of things in smart autonomous multi-robot systems},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning with joint cross-document information via
multi-task learning for named entity recognition. <em>ISCI</em>,
<em>579</em>, 454–467. (<a
href="https://doi.org/10.1016/j.ins.2021.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In information extraction, named entity recognition (NER) aims to locate named entities in unstructured text and classify them into predefined categories. Most existing methods for NER are sentence-level approaches, which only leverage the context information within a sentence and may cause inconsistent entity prediction. Several researchers have identified latent relationships between sentences in a document and therefore present numerous document-level frameworks that utilize the context information in a document. However, these frameworks cannot establish the correlation between sentences in different documents. To address this problem, we present a cross-document NER model that builds internal relationships for each token among all its multiple occurrences in different documents. A cross-document attention module is designed to calculate the cross-document representations. Furthermore, we add a multiclassification auxiliary task to utilize the coarse-grained entity information. The multi-objective optimization is employed through weighted summation and an autonomous approach utilizing the homoscedastic uncertainty of each task. Extensive experimental results on various data sets clearly demonstrate the effectiveness of our proposed approach, and our model achieves better results than the sentence-level and document-level NER models.},
  archive      = {J_ISCI},
  author       = {Dongsheng Wang and Hongjie Fan and Junfei Liu},
  doi          = {10.1016/j.ins.2021.08.015},
  journal      = {Information Sciences},
  pages        = {454-467},
  shortjournal = {Inf. Sci.},
  title        = {Learning with joint cross-document information via multi-task learning for named entity recognition},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Command-filtered backstepping robust adaptive emotional
control of strict-feedback nonlinear systems with mismatched
uncertainties. <em>ISCI</em>, <em>579</em>, 434–453. (<a
href="https://doi.org/10.1016/j.ins.2021.07.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotional models have recently gained increasing attention in the design of intelligent control systems because of their desirable properties , such as universal approximation and fast response. However, stable emotional controllers have generally been for full-state feedback linearizable systems with only matched uncertainties. They also require knowing the reference signal and its higher derivatives. In contrast, we propose here a command-filtered backstepping H ∞ robust adaptive emotional controller (CFBRAEC) for strict-feedback nonlinear systems with mismatched uncertainties. Our approach applies command filters to address the “explosion of complexity” in backstepping control and introduces a compensating filter consistent with the H ∞ -based design to deal with the approximation errors of command filters. The command-filtered backstepping approach handles matched/mismatched uncertainties and disturbances while requiring only the reference signal and its first derivative to be known and continuous. Accordingly, CFBRAEC is more suitable for practical applications and applicable to a broader group of dynamic systems. The boundedness of the tracking error and other closed-loop signals are established based on Lyapunov theory . The effectiveness of CFBRAEC is shown through simulations in the presence of measurement noise and matched/mismatched disturbances with unknown bounds on two different uncertain nonlinear systems : an inverted pendulum and an electromechanical motor.},
  archive      = {J_ISCI},
  author       = {P. Parsa and M.-R. Akbarzadeh-T and F. Baghbani},
  doi          = {10.1016/j.ins.2021.07.090},
  journal      = {Information Sciences},
  pages        = {434-453},
  shortjournal = {Inf. Sci.},
  title        = {Command-filtered backstepping robust adaptive emotional control of strict-feedback nonlinear systems with mismatched uncertainties},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep active learning for object detection. <em>ISCI</em>,
<em>579</em>, 418–433. (<a
href="https://doi.org/10.1016/j.ins.2021.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning (AL) for object detection (OD) aims to reduce labeling costs by selecting the most valuable samples that enhance the detection network from the unlabeled pool. Due to the complexity of OD compared with image classification , more consideration should be given when designing the selection strategies. Previous works have studied aggregating information of multiple outputs (especially the location information) and aggregating information of batch boxes, all of which indicate improved performances. However, the evaluation index—mean average precision (mAP) has not been considered seriously, although improving it is the goal of AL. Moreover, the background class is far more than other classes (15:1 or more) in each batch of samples, leading to a class imbalance problem . Therefore, AL strategies for OD, which take mAP and class imbalance in batch into consideration, may perform better. In this paper, WBetGS is proposed, which not only considers aggregating information of multiple outputs and batch boxes but also aims to mAP improvement and to address the class imbalance in batch. A weighted algorithm is introduced to promote the mAP more effectively. Besides, WBetGS eliminates the impact of class imbalance between background and object categories by extracting class-balanced information. Moreover, a diversity and uncertainty based sampling algorithm is introduced for batch mode active learning in object detection. The experimental results demonstrate that our method performs better than basic methods, saving up 100\% of the labeling efforts while reaching the same performance in an actual industrial application.},
  archive      = {J_ISCI},
  author       = {Ying Li and Binbin Fan and Weiping Zhang and Weiping Ding and Jianwei Yin},
  doi          = {10.1016/j.ins.2021.08.019},
  journal      = {Information Sciences},
  pages        = {418-433},
  shortjournal = {Inf. Sci.},
  title        = {Deep active learning for object detection},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the relationship between PageRank and automorphisms of a
graph. <em>ISCI</em>, <em>579</em>, 401–417. (<a
href="https://doi.org/10.1016/j.ins.2021.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PageRank is an algorithm used in Internet search to score the importance of web pages. The aim of this paper is demonstrate some new results concerning the relationship between the concept of PageRank and automorphisms of a graph. In particular, we show that if vertices u and v are similar in a graph G (i.e., there is an automorphism mapping u to v ), then u and v have the same PageRank score. More generally, we prove that if the PageRanks of all vertices in G are distinct, then the automorphism group of G consists of the identity alone. Finally, the PageRank entropy measure of several kinds of real-world networks and all trees of orders 10–13 and 22 is investigated.},
  archive      = {J_ISCI},
  author       = {Modjtaba Ghorbani and Matthias Dehmer and Abdullah Lotfi and Najaf Amraei and Abbe Mowshowitz and Frank Emmert-Streib},
  doi          = {10.1016/j.ins.2021.08.013},
  journal      = {Information Sciences},
  pages        = {401-417},
  shortjournal = {Inf. Sci.},
  title        = {On the relationship between PageRank and automorphisms of a graph},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple instance classification: Bag noise filtering for
negative instance noise cleaning. <em>ISCI</em>, <em>579</em>, 388–400.
(<a href="https://doi.org/10.1016/j.ins.2021.07.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data in the real world is far from being perfect. The appearance of noise is a common issue that arises from the limitations of data acquisition mechanisms and human knowledge. In classification, label noise will hinder the performance of almost all classifiers, inducing a bias in the built model. While label noise has recently attracted researchers’ attention in standard classification, it has only recently begun to be studied in multiple instance classification. In this work, we propose the usage of filtering algorithms for multiple instance classification that are able to reduce the impact of negative instances within the bags. In order to do so, we decompose the bags to form a standard classification problem that can be efficiently treated by a specialized noise filter. Such a decomposition is tackled in different ways, with the aim of exploiting the knowledge offered by the examples from opposite bags. The bags are then rebuilt, without the identified noise instances. In our experiments, we show that by applying our approach we can diminish the impact of noise and even obtain better results at 0\% noise level for several classifiers. Our approach sets out a promising approach to dealing with noise in the bags of multiple instance datasets and further improve the classification rate of the built models.},
  archive      = {J_ISCI},
  author       = {Julián Luengo and Dánel Sánchez-Tarragó and Ronaldo C. Prati and Francisco Herrera},
  doi          = {10.1016/j.ins.2021.07.076},
  journal      = {Information Sciences},
  pages        = {388-400},
  shortjournal = {Inf. Sci.},
  title        = {Multiple instance classification: Bag noise filtering for negative instance noise cleaning},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How to process local and global consensus? A large-scale
group decision making model based on social network analysis with
probabilistic linguistic information. <em>ISCI</em>, <em>579</em>,
368–387. (<a href="https://doi.org/10.1016/j.ins.2021.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of societal and technological paradigms, large-scale group decision making becomes an emerging topic. In conventional group decision making methods , it is often assumed that all experts are independent. However, with the expansion of social media, experts usually have some relationships and get together for some reasons such as the academic relationship, working relationship or common interests. In these cases, experts are no longer independent individuals. To address the issue, this study introduces a large-scale group decision making model based on the social network analysis . In this model, experts can provide trust values on other experts. Due to the scale and complexity of the large-scale group decision making problems, the dimensional reduction , which uses community detection to classify experts into local communities, is deemed essential. Based on this process, the whole group can be divided into two layers. The first layer is the global network containing all communities, and the second layer is the local network within a community. This study develops a model to address large-scale group decision-making problems considering the local and global consensus in two layers simultaneously. This model allows experts to use probabilistic linguistic preference relations to express their cognitive complex evaluation information. An illustrative example is presented to show the usefulness of the proposed model.},
  archive      = {J_ISCI},
  author       = {Huchang Liao and Xiaofang Li and Ming Tang},
  doi          = {10.1016/j.ins.2021.08.014},
  journal      = {Information Sciences},
  pages        = {368-387},
  shortjournal = {Inf. Sci.},
  title        = {How to process local and global consensus? a large-scale group decision making model based on social network analysis with probabilistic linguistic information},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-way decision and conformal prediction: Isomorphisms,
differences and theoretical properties of cautious learning approaches.
<em>ISCI</em>, <em>579</em>, 347–367. (<a
href="https://doi.org/10.1016/j.ins.2021.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this article is to study the relationship between two popular Cautious Learning approaches, namely: Three-way decision (TWD) and conformal prediction (CP). Based on the novel proposal of a technique to transform three-way decision classifiers into conformal predictors, and vice versa, we provide conditions for the equivalence between TWD and CP. These theoretical results provide error-bound guarantees for TWD, together with a formal construction to define cost-sensitive cautious classifiers based on CP. The proposed techniques are then applied and evaluated on a collection of benchmark and real-world datasets. The results of the experiments show that the proposed techniques can be used to obtain cautious learning classifiers that are competitive with, and often out-perform, state-of-the-art approaches. Further, through a qualitative medical case study we discuss the usefulness of cautious learning in the development of robust Machine Learning.},
  archive      = {J_ISCI},
  author       = {Andrea Campagner and Federico Cabitza and Pedro Berjano and Davide Ciucci},
  doi          = {10.1016/j.ins.2021.08.009},
  journal      = {Information Sciences},
  pages        = {347-367},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision and conformal prediction: Isomorphisms, differences and theoretical properties of cautious learning approaches},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy synchronization of fractional-order chaotic systems
using finite-time command filter. <em>ISCI</em>, <em>579</em>, 325–346.
(<a href="https://doi.org/10.1016/j.ins.2021.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For conventional backstepping control, the analytical calculation of certain virtual controller is required in each step, so when system order increases, the computational burden also increases. An adaptive command filtered fuzzy synchronization approach is implemented for strict feedback fractional-order chaotic systems (FCSs) in this paper. The computational explosion in the backstepping is solved through a fractional-order command filter (FCF). The filtering approximation errors arising from the FCF are overcame by a error compensation mechanism (ECM). In every step, a fuzzy system is introduced to process system uncertainties. The stability of synchronization errors of a strict feedback FCS is ensured based on fractional Lyapunov stability criteria. Finally, numerical simulation examples illustrate the effectiveness of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Madini O. Alassafi and Shumin Ha and Fawaz E. Alsaadi and Adil M. Ahmad and Jinde Cao},
  doi          = {10.1016/j.ins.2021.08.005},
  journal      = {Information Sciences},
  pages        = {325-346},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy synchronization of fractional-order chaotic systems using finite-time command filter},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble ellipse fitting by spatial median consensus.
<em>ISCI</em>, <em>579</em>, 310–324. (<a
href="https://doi.org/10.1016/j.ins.2021.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ellipses are among the most frequently used geometric models in visual pattern recognition and digital image analysis. This work aims to combine the outputs of an ensemble of ellipse fitting methods, so that the deleterious effect of suboptimal fits is alleviated. Therefore, the accuracy of the combined ellipse fit is higher than the accuracy of the individual methods. Three characterizations of the ellipse have been considered by different researchers: algebraic, geometric, and natural. In this paper, the natural characterization has been employed in our method due to its superior performance. Furthermore, five ellipse fitting methods have been chosen to be combined by the proposed consensus method. The experiments include comparisons of our proposal with the original methods and additional ones. Several tests with synthetic and bitmap image datasets demonstrate its great potential with noisy data and the presence of occlusion. The proposed consensus algorithm is the only one that ranks among the first positions for all the tests that were carried out. This demonstrates the suitability of our proposal for practical applications with high occlusion or noise.},
  archive      = {J_ISCI},
  author       = {Karl Thurnhofer-Hemsi and Ezequiel López-Rubio and Elidia Beatriz Blázquez-Parra and M. Carmen Ladrón-de-Guevara-Muñoz and Óscar David de-Cózar-Macías},
  doi          = {10.1016/j.ins.2021.08.011},
  journal      = {Information Sciences},
  pages        = {310-324},
  shortjournal = {Inf. Sci.},
  title        = {Ensemble ellipse fitting by spatial median consensus},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time energy-to-peak fuzzy filtering for persistent
dwell-time switched nonlinear systems with unreliable links.
<em>ISCI</em>, <em>579</em>, 293–309. (<a
href="https://doi.org/10.1016/j.ins.2021.07.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work investigates the finite-time filtering problem of discrete-time switched nonlinear systems with unreliable links, where the persistent dwell-time switching mechanism is introduced to describe the changes of system mode and the fuzzy set theory is adopted to construct the model of nonlinear systems . Moreover, unreliable links including random nonlinearity and disturbance are employed to transmit data between the plant and the filter. The main intention of this study is to develop a desired full-order filter such that the resulting filtering error system is finite-time bounded with a fixed energy-to-peak performance index. Afterwards, based on the finite-time bounded theory, and through constructing appropriate Lyapunov–Krasovskii functionals, sufficient conditions for the stability with corresponding performance of the filtering error system are established. Then, by solving a set of convex optimization problems , the specific gains of the desired filter are computed. Finally, a numerical example and a single link robot arm model are provided to expound the correctness and practicability of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Hao Shen and Xinmiao Liu and Jianwei Xia and Xiangyong Chen and Jing Wang},
  doi          = {10.1016/j.ins.2021.07.081},
  journal      = {Information Sciences},
  pages        = {293-309},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time energy-to-peak fuzzy filtering for persistent dwell-time switched nonlinear systems with unreliable links},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Archetypal analysis for ordinal data. <em>ISCI</em>,
<em>579</em>, 281–292. (<a
href="https://doi.org/10.1016/j.ins.2021.07.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Archetypoid analysis (ADA) is an exploratory approach that explains a set of continuous observations as mixtures of pure (extreme) patterns. Those patterns (archetypoids) are actual observations of the sample which makes the results of this technique easily interpretable, even for non-experts. Note that the observations are approximated as a convex combination of the archetypoids. Archetypoid analysis, in its current form, cannot be applied directly to ordinal data. We propose and describe a two-step method for applying ADA to ordinal responses based on the ordered stereotype model. One of the main advantages of this model is that it allows us to convert the ordinal data to numerical values, using a new data-driven spacing that better reflects the ordinal patterns of the data, and this numerical conversion then enables us to apply ADA straightforwardly. The results of the novel method are presented for two behavioural science applications. Finally, the proposed method is also compared with other unsupervised statistical learning methods.},
  archive      = {J_ISCI},
  author       = {Daniel Fernández and Irene Epifanio and Louise Fastier McMillan},
  doi          = {10.1016/j.ins.2021.07.095},
  journal      = {Information Sciences},
  pages        = {281-292},
  shortjournal = {Inf. Sci.},
  title        = {Archetypal analysis for ordinal data},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Structure preservation adversarial network for visual domain
adaptation. <em>ISCI</em>, <em>579</em>, 266–280. (<a
href="https://doi.org/10.1016/j.ins.2021.07.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation has attracted attention by leveraging knowledge from well-labeled source data to facilitate unlabeled target learning tasks. Numerous research efforts have been devoted to extracting effective features by incorporating the pseudolabels of target data. However, the transferable knowledge reflected by intradomain structure, interdomain correlation and label supervision has scarcely been considered simultaneously. In this paper, we propose a novel structure preservation adversarial network with target reweighting (SPTR) for unsupervised domain adaptation , in which local structure consistencies and category-level semantic alignment are simultaneously considered in the adversarial learning framework. Based on the labeled and pseudolabeled samples, we attempt to align both global and category-level domain statistics from different domains and simultaneously enforce structural consistency from feature space to label space in the source and target domains. Furthermore, to suppress the influence of falsely labeled target samples, a novel and generalized sample reweighting strategy is developed to assign target samples with different levels of confidence, which fully explores the knowledge of the target distribution to benefit the semantic transfer process. The experimental results in three transfer learning scenarios demonstrate the superiority of our proposed method over other state-of-the-art domain adaptation algorithms.},
  archive      = {J_ISCI},
  author       = {Min Meng and Qiguang Chen and Jigang Wu},
  doi          = {10.1016/j.ins.2021.07.085},
  journal      = {Information Sciences},
  pages        = {266-280},
  shortjournal = {Inf. Sci.},
  title        = {Structure preservation adversarial network for visual domain adaptation},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-performance implementation of evolutionary
privacy-preserving algorithm for big data using GPU platform.
<em>ISCI</em>, <em>579</em>, 251–265. (<a
href="https://doi.org/10.1016/j.ins.2021.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy protection has become a predominant concern in big data analysis. Privacy-Preserving Association Rule Mining (PPARM) is a process in which original data is transformed into a sanitized version to remove sensitive patterns. Although evolutionary PPARM approaches were developed, they are inefficient because the fitness function is overwhelmingly expensive. In this paper, an efficient algorithm, GPU-based Evolutionary Privacy-Preserving (GEPP), for improving the performance of PPARM is presented. We introduce two strategies for this reason: the first one is to develop a parallel indexing machine to generate retrieval index lists by parallelizing dataset scanning between GPU blocks, and the second strategy is the parallelization of the index lists for fitness function computation using CPU/GPU platform. In the second strategy, search mechanism and fitness function steps are performed on CPU and GPU, respectively. The scalability of GEPP is evaluated in terms of GPU characteristics, e.g., blocks and threads, data characteristics, e.g., the number of transactions, items, and density ratio, and patterns characteristics, e.g., the ratio of sensitive patterns and support thresholds. Experimental results show that our parallel implementation of the proposed approach obtains a speedup up to 36.6x, on average, compared to the CPU implementation using real and synthetic large-scale transaction datasets.},
  archive      = {J_ISCI},
  author       = {Akbar Telikani and Asadollah Shahbahrami and Amir H. Gandomi},
  doi          = {10.1016/j.ins.2021.08.006},
  journal      = {Information Sciences},
  pages        = {251-265},
  shortjournal = {Inf. Sci.},
  title        = {High-performance implementation of evolutionary privacy-preserving algorithm for big data using GPU platform},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel hybrid particle swarm optimization using adaptive
strategy. <em>ISCI</em>, <em>579</em>, 231–250. (<a
href="https://doi.org/10.1016/j.ins.2021.07.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) has been employed to solve numerous real-world problems because of its strong optimization ability and easy implementation. However, PSO still has some shortcomings in solving complicated optimization problems , such as premature convergence and poor balance between global exploration and local exploitation. A novel hybrid particle swarm optimization using adaptive strategy (ASPSO) is developed to address associated difficulties. The contribution of ASPSO is threefold: (1) a chaotic map and an adaptive position updating strategy to balance exploration behavior and exploitation nature in the search progress; (2) elite and dimensional learning strategies to enhance the diversity of the population effectively; (3) a competitive substitution mechanism to improve the accuracy of solutions. Based on various functions from CEC 2017, the numerical experiment results demonstrate that ASPSO is significantly better than the other 16 optimization algorithms . Furthermore, we apply ASPSO to a typical industrial problem, the optimization of melt spinning progress, where the results indicate that ASPSO performs better than other algorithms.},
  archive      = {J_ISCI},
  author       = {Rui Wang and Kuangrong Hao and Lei Chen and Tong Wang and Chunli Jiang},
  doi          = {10.1016/j.ins.2021.07.093},
  journal      = {Information Sciences},
  pages        = {231-250},
  shortjournal = {Inf. Sci.},
  title        = {A novel hybrid particle swarm optimization using adaptive strategy},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jointly evolving and compressing fuzzy system for feature
reduction and classification. <em>ISCI</em>, <em>579</em>, 218–230. (<a
href="https://doi.org/10.1016/j.ins.2021.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolving fuzzy systems (EFSs) are a type of adaptive fuzzy rule-based systems which can self-adapt both their structures and parameters simultaneously. However, the existing EFSs suffer from two drawbacks: 1) classical EFSs usually use all input features to model systems, resulting in lengthy fuzzy rules; 2) some redundant information in fuzzy rules may hinder high generalization. To address these two issues, a promising method is proposed in this paper by combining very sparse random projection (VSRP) with a class of EFSs based-on data clouds, called VSRP-AnYa-EFS. The proposed method introduces: 1) a random sparse-Bernoulli (RSB) matrix based-on VSRP is utilized to compress the lengthy antecedent part into a tighter form, triggering a feature-reduction mechanism. By employing VSRP in RSB matrix, some redundant information in fuzzy rules can be filtered; 2) Local learning is used for consequent parameter optimization to suit decoupled behavior of rules after redundant information between rules is deleted. By adopting VSRP and local learning, the proposed VSRP-AnYa-EFS owns a compact structure and fast learning speed. Numerical examples presented in this paper demonstrate that the proposed method can significantly reduce training time from hours to minutes while the accuracy can be improved up to 5\%.},
  archive      = {J_ISCI},
  author       = {Hui Huang and Hai-Jun Rong and Zhao-Xu Yang and Chi-Man Vong},
  doi          = {10.1016/j.ins.2021.08.003},
  journal      = {Information Sciences},
  pages        = {218-230},
  shortjournal = {Inf. Sci.},
  title        = {Jointly evolving and compressing fuzzy system for feature reduction and classification},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial training regularization for negative sampling
based network embedding. <em>ISCI</em>, <em>579</em>, 199–217. (<a
href="https://doi.org/10.1016/j.ins.2021.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of network embedding is to learn compact node representations. This has been shown to be effective in various downstream learning tasks, such as link prediction and node classification . Most methods focus on preserving different network structures and properties, ignoring the fact that networks are usually noisy and incomplete, thus such methods potentially lack robustness and suffer from the overfitting issue. Recently, generative adversarial networks based methods have been exploited to impose a prior distribution on node embeddings to encourage a global smoothness, but their model architecture is very complicated and they suffer from the non-convergence problem. Here, we propose adversarial training (AdvT), a more succinct and effective local regularization method, for negative-sampling-based network embedding to improve model robustness and generalization ability . Specifically, we first define the adversarial perturbations in the embedding space instead of in the discrete graph domain to circumvent the challenge of generating discrete adversarial examples . Then, to enable more effective regularization , we design the adaptive l 2 l2 norm constraints on adversarial perturbations that depend upon the connectivity pattern of node pairs. We integrate AdvT into several famous models including D eep W alk , LINE and node2vec, and conduct extensive experiments on benchmark datasets to verify its effectiveness.},
  archive      = {J_ISCI},
  author       = {Quanyu Dai and Xiao Shen and Zimu Zheng and Liang Zhang and Qiang Li and Dan Wang},
  doi          = {10.1016/j.ins.2021.07.018},
  journal      = {Information Sciences},
  pages        = {199-217},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial training regularization for negative sampling based network embedding},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CJC-net: A cyclical training method with joint loss and
co-teaching strategy net for deep learning under noisy labels.
<em>ISCI</em>, <em>579</em>, 186–198. (<a
href="https://doi.org/10.1016/j.ins.2021.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent success of deep convolutional neural networks (CNNs) is mostly due to the availability of large-scale datasets with accurate annotations. However, the collection of such large datasets with clean annotations is time-consuming and not always feasible. In this paper, we propose a novel framework for learning with noisy labels, called the Cyclical training method with Joint loss and Co-teaching strategy net (CJC-net), where the net means our method is insensitive to the structures of the CNN. CJC-net pretrains two networks simultaneously and then performs the cyclical training strategy under an improved co-teaching method based on the two pretrained networks. During the training process, we adjust the learning rates of the two networks to make the network states periodically transfer from overfitting to underfitting. The cumulative loss of each sample under two networks is recorded; and the higher the cumulative loss of a sample is, the higher the probability of identifying it as a noisy label or a hard label. Then, we remove those samples with a high loss and fine-tune the two networks using the remaining data. The experimental results on several datasets demonstrate that CJC-net is superior to many state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Qian Zhang and Feifei Lee and Ya-gang Wang and Damin Ding and Shuai Yang and Chaowei Lin and Qiu Chen},
  doi          = {10.1016/j.ins.2021.08.008},
  journal      = {Information Sciences},
  pages        = {186-198},
  shortjournal = {Inf. Sci.},
  title        = {CJC-net: A cyclical training method with joint loss and co-teaching strategy net for deep learning under noisy labels},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). WSHE: User feedback-based weighted signed heterogeneous
information network embedding. <em>ISCI</em>, <em>579</em>, 167–185. (<a
href="https://doi.org/10.1016/j.ins.2021.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous information networks (HINs), which have rich semantic relations, can flexibly model multisource heterogeneous data in recommendation systems. Learning more comprehensive features of users based on HINs is a way to improve recommendation performance. User feedback can truly reflect user preferences. Most meta-path-based HIN embedding methods measure the similarity among users by counting the number of meta-paths and cannot fully learn the polar similarity of user preferences. In this work, we proposed a user feedback-based weighted signed HIN embedding method to learn more comprehensive embeddings of users and items. First, we defined a similarity measure using the weighted meta-path to measure the polar similarities of users. Second, we designed a weighted signed network embedding method based on the weighted sampling random walk. The embeddings of different meta-paths were deeply fused guided by an attention mechanism. The fused embeddings were further fused with attribute information using a pooling operation to capture their interactions. Finally, we utilized the rating prediction task to optimize the model and obtain the final embeddings of users and items. Extensive experiments performed on four datasets demonstrated the effectiveness of the model. In addition, we analyzed the importance of the different semantic meta-paths in the rating prediction task based on the interpretability of the attention mechanism.},
  archive      = {J_ISCI},
  author       = {Baofang Hu and Hong Wang and Lutong Wang},
  doi          = {10.1016/j.ins.2021.08.002},
  journal      = {Information Sciences},
  pages        = {167-185},
  shortjournal = {Inf. Sci.},
  title        = {WSHE: User feedback-based weighted signed heterogeneous information network embedding},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SolGuard: Preventing external call issues in smart
contract-based multi-agent robotic systems. <em>ISCI</em>, <em>579</em>,
150–166. (<a href="https://doi.org/10.1016/j.ins.2021.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the new era of blockchain-based multi-agent robotic systems , smart contract programs perform an influential role in implementing decentralized applications with required task allocations. Smart contract programs are developed using script-type of programming languages, and they have already deployed several vulnerable patterns without proper testing and audit. We studied Solidity smart contracts running on the Ethereum platform and identified that they had been exploited because of several programming issues, especially using low-level external calls to malicious sources. Since smart contracts are immutable after their deployment to autonomous multi-robot systems, they should be tested to fix possible development phase issues. We implemented a prototype plugin called SolGuard by extending the solhint linter to prevent three critical issues related to Solidity smart contract programs’ usage of external calls. The SolGuard plugin checks state variable order in the smart contracts, participation of delegatecall invocations, address type parameters in the smart contract’s constructor, and denial of service patterns. We empirically evaluate the SolGuard plugin with existing popular static analysis tools. Our results indicate that SolGuard outperformed the baseline tools in terms of efficiency and accuracy.},
  archive      = {J_ISCI},
  author       = {Purathani Praitheeshan and Lei Pan and Xi Zheng and Alireza Jolfaei and Robin Doss},
  doi          = {10.1016/j.ins.2021.08.007},
  journal      = {Information Sciences},
  pages        = {150-166},
  shortjournal = {Inf. Sci.},
  title        = {SolGuard: Preventing external call issues in smart contract-based multi-agent robotic systems},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An image encryption algorithm based on new chaos and
diffusion values of a truth table. <em>ISCI</em>, <em>579</em>, 128–149.
(<a href="https://doi.org/10.1016/j.ins.2021.07.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new chaotic system based on two parameters. The proposed chaotic system has good chaotic characteristics, and it can be shown that the chaotic system is suitable for image encryption through a variety of simulation experiments. Based on this system, we propose a new image encryption algorithm. The algorithm uses nonlinear chaotic sequences for row, column, and diagonal scrambling and diffusion in two directions. When scrambling, the diffusion matrix generated by the chaotic system is dynamically upset, and the image scrambling direction is determined by the relative coordinates of multiple chaotic systems. When diffusing, two matrices are used to change the pixel value: one is the matrix processed by scrambling, and the other is the matrix generated by the truth table. The resulting encrypted image is affected by both the chaotic system and the truth table rules. Theoretical analysis and experimental results show that the image encrypted by this algorithm has high security.},
  archive      = {J_ISCI},
  author       = {Xingyuan Wang and Maozhen Zhang},
  doi          = {10.1016/j.ins.2021.07.096},
  journal      = {Information Sciences},
  pages        = {128-149},
  shortjournal = {Inf. Sci.},
  title        = {An image encryption algorithm based on new chaos and diffusion values of a truth table},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A decision-theoretic fuzzy rough set in hesitant fuzzy
information systems and its application in multi-attribute
decision-making. <em>ISCI</em>, <em>579</em>, 103–127. (<a
href="https://doi.org/10.1016/j.ins.2021.07.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-theoretic rough sets (DTRSs) as a classic model of three-way decisions have been widely applied in the field of risk decision-making. Considering situations where experts hesitate among several evaluation values, hesitant fuzzy sets , as a new generalization of fuzzy sets, can describe uncertain information flexibly in the decision-making process. In this paper, we propose a decision-theoretic fuzzy rough set (DTFRS) model in hesitant fuzzy information systems and discuss its application in multi-attribute decision-making (MADM). More specifically, we first define a novel fuzzy binary relation between two objects by using the hesitant fuzzy distance function. Then, we study the calculations of the fuzzy similarity class and the conditional probability . At the same time, based on the connection between the loss functions and the attribute values, we develop a data-driven calculation method of the relative loss functions. With these discussions, we construct a DTFRS model in hesitant fuzzy information systems and explore the related decision-making mechanism. Furthermore, a three-way decision method based on the proposed DTFRS model is established to handle MADM problems in the context of a hesitant fuzzy environment. The established method not only takes the decision risk into consideration, but also instructs us how to choose the action for each alternative and gives its corresponding semantic explanation. An illustrative example of the stock investment problem is presented to verify the efficacy of our method. Finally, we take a sensitivity analysis and a comparison analysis to show the established method’s performance and characteristics.},
  archive      = {J_ISCI},
  author       = {Haibo Jiang and Bao Qing Hu},
  doi          = {10.1016/j.ins.2021.07.094},
  journal      = {Information Sciences},
  pages        = {103-127},
  shortjournal = {Inf. Sci.},
  title        = {A decision-theoretic fuzzy rough set in hesitant fuzzy information systems and its application in multi-attribute decision-making},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dual-population algorithm based on alternative evolution
and degeneration for solving constrained multi-objective optimization
problems. <em>ISCI</em>, <em>579</em>, 89–102. (<a
href="https://doi.org/10.1016/j.ins.2021.07.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to solve constrained multi-objective optimization problems (CMOPs). Different from the traditional multi-objective optimization problem, the feasibility, convergence, and diversity of the population must be considered in the optimization process of a CMOP. How these factors are balanced will affect the performance of the constrained multi-objective optimization algorithm. To solve this problem, we propose a dual-population multi-objective optimization evolutionary algorithm. The proposed algorithm can make good use of its secondary population and alternative between evolution and degeneration according to the state of the secondary population to provide better information for the main population. The test results of three benchmark constrained multi-objective optimization problem suites, and four real-world constrained multi-objective optimization problems show that the algorithm is better than existing dual-population multi-objective optimization, especially when there is a distance between the unconstrained PF and the constrained PF.},
  archive      = {J_ISCI},
  author       = {Juan Zou and Ruiqing Sun and Shengxiang Yang and Jinhua Zheng},
  doi          = {10.1016/j.ins.2021.07.078},
  journal      = {Information Sciences},
  pages        = {89-102},
  shortjournal = {Inf. Sci.},
  title        = {A dual-population algorithm based on alternative evolution and degeneration for solving constrained multi-objective optimization problems},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Likelihood-constrained coupled space learning for motion
synthesis. <em>ISCI</em>, <em>579</em>, 72–88. (<a
href="https://doi.org/10.1016/j.ins.2021.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When considering the human skeleton as a hierarchical structure ( i.e. an upside-down tree structure), human motion can be treated as the rotation movements of joints around their parent joints , such that a motion sequence can be represented by the joint angle changing processes (referred to as motion patterns) of the joints between its start and end frames. With this motion representation mode, we convert motion synthesis to a motion pattern generation task, given a start-end frame pair. Conforming to such a motion synthesis scheme, we propose a coupled space learning model within which we enforce the sparse representation of the start-end frame pair on the motion frame dictionary to reconstruct its corresponding motion patterns well with a motion pattern dictionary. In addition, as motion naturalness is an important evaluation metric of motions, we propose to use the likelihood of a motion with a pre-estimated motion probability distribution to measure its naturalness and add the motion naturalness measurement into the coupled space learning model to constrain the generated motion patterns to reconstruct highly natural motions. The superior performances of both accuracy and naturalness of the synthesized motions demonstrate the effectiveness of the coupled space learning with the motion likelihood constraint.},
  archive      = {J_ISCI},
  author       = {Guiyu Xia and Peng Xue and Du Zhang and Qingshan Liu},
  doi          = {10.1016/j.ins.2021.08.001},
  journal      = {Information Sciences},
  pages        = {72-88},
  shortjournal = {Inf. Sci.},
  title        = {Likelihood-constrained coupled space learning for motion synthesis},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Leveraging implicit relations for recommender systems.
<em>ISCI</em>, <em>579</em>, 55–71. (<a
href="https://doi.org/10.1016/j.ins.2021.07.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative filtering (CF) is one of the dominant techniques used in recommender systems . Most CF-based methods treat every user (or item) as an isolated existence, without explicitly modeling potential mutual relations among users (or items), which are latent in user-item interactions. In this paper, we design a novel strategy to mine user-user and item-item implicit relations and propose a natural way of utilizing the implicit relations for recommendation. Specifically, our method contains two major phases: neighbor construction and recommendation framework. The first phase constructs an implicit neighbor set for each user and item according to historical user-item interaction. In the second phase, based on the constructed neighbor sets, we propose a deep framework to generate recommendations. We conduct extensive experiments with four datasets on the movie, business, book, and restaurant recommendations and compare our methods with seven baselines, e.g., feature-based, neighborhood-based, and graph-based models. The experiment results demonstrate that our method achieves superior performance in rating prediction and top- k k recommendation.},
  archive      = {J_ISCI},
  author       = {Anchen Li and Bo Yang and Huan Huo and Farookh Khadeer Hussain},
  doi          = {10.1016/j.ins.2021.07.084},
  journal      = {Information Sciences},
  pages        = {55-71},
  shortjournal = {Inf. Sci.},
  title        = {Leveraging implicit relations for recommender systems},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NFDDE: A novelty-hybrid-fitness driving differential
evolution algorithm. <em>ISCI</em>, <em>579</em>, 33–54. (<a
href="https://doi.org/10.1016/j.ins.2021.07.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In differential evolution algorithm (DE), it is a widely accepted method that selecting individuals with higher fitness to generate a mutant vector. In this case, the population evolution is under a fitness-based driving force. Although the driving force is beneficial for the exploitation, it sacrifices performance on the exploration. In this paper, a n ovelty-hybrid- f itness d riving force is introduced to trade off contradictions between the exploration and the exploitation of DE. In the new proposed DE, named as NFDDE, both fitness and novelty values of individuals are considered when choosing individuals to create mutant vectors. In addition, two adaptive scaling factors are proposed to adjust the weights of the fitness-based driving force and the novelty-based driving force, respectively, and then distinct properties of the two driving forces can be effectively utilized. At last, to save computational resources, some individuals with lower novelty are deleted when the population has converged to a certain extent. The comprehensive performance of NFDDE is extensively evaluated by comparisons between it and other 9 state-of-art DE variants based on CEC2017 test suite. In addition, distinct properties of the newly introduced strategies and involved parameters are further confirmed by a set of experiments.},
  archive      = {J_ISCI},
  author       = {Xuewen Xia and Lei Tong and Yinglong Zhang and Xing Xu and Honghe Yang and Ling Gui and Yuanxiang Li and Kangshun Li},
  doi          = {10.1016/j.ins.2021.07.082},
  journal      = {Information Sciences},
  pages        = {33-54},
  shortjournal = {Inf. Sci.},
  title        = {NFDDE: A novelty-hybrid-fitness driving differential evolution algorithm},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TWD-SFNN: Three-way decisions with a single hidden layer
feedforward neural network. <em>ISCI</em>, <em>579</em>, 15–32. (<a
href="https://doi.org/10.1016/j.ins.2021.07.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks have a strong self-learning ability and a wide range of applications. The current neural network models mainly determine the number of hidden layer nodes using empirical formulas, which lack theoretical guidance and can easily lead to poor learning performance. To improve the performance of the neural network model, inspired by the three-way decisions method, this paper proposes a model called three-way decisions with a single hidden layer feedforward neural network (TWD-SFNN). TWD-SFNN adopts three-way decisions to find the number of hidden layer nodes for a neural network in a dynamic way. TWD-SFNN has three key issues: discretizing the datasets, adjusting the learning process of the network, and evaluating the learning results of the network. TWD-SFNN adopts the k-means++ algorithm to discretize the datasets, employs the Adam algorithm to adjust the learning process of the network, and uses a confusion matrix to evaluate the learning results of the network. Therefore, the topological structure of the neural network is obtained. The experimental results verify that the network structure of TWD-SFNN is more compact than those of the SFNN models that use empirical formulas to determine the number of hidden layer nodes, and the generalization ability of TWD-SFNN is better than the state-of-the-art classification models .},
  archive      = {J_ISCI},
  author       = {Shuhui Cheng and Youxi Wu and Yan Li and Fang Yao and Fan Min},
  doi          = {10.1016/j.ins.2021.07.091},
  journal      = {Information Sciences},
  pages        = {15-32},
  shortjournal = {Inf. Sci.},
  title        = {TWD-SFNN: Three-way decisions with a single hidden layer feedforward neural network},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved matrix factorization based model for
many-objective optimization recommendation. <em>ISCI</em>, <em>579</em>,
1–14. (<a href="https://doi.org/10.1016/j.ins.2021.07.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the application scenarios of recommendation algorithms are becoming increasingly complex, the efficiency of traditional recommendation algorithm based on accuracy is no longer satisfied. To solve this problem, an improved matrix factorization based model for many-objective optimization recommendation is proposed to simultaneously optimize the four recommendation objectives of novelty, diversity, accuracy, and recall. As a novel double-layer recommendation model, two improved algorithms are composed: 1) For the bottom layer, an improved matrix factorization algorithm with additional regularization constraints is used to predict unknown item ratings; 2) For the top layer, the recommendation list is optimized by a many-objective evolutionary algorithm . Comprehensive experiments demonstrate that the proposed model can effectively improve the four recommended evaluation metrics . And a recommended list with novel and diverse items is provided for users in a more efficient way while maintaining accuracy.},
  archive      = {J_ISCI},
  author       = {Zhihua Cui and Peng Zhao and Zhaoming Hu and Xingjuan Cai and Wensheng Zhang and Jinjun Chen},
  doi          = {10.1016/j.ins.2021.07.077},
  journal      = {Information Sciences},
  pages        = {1-14},
  shortjournal = {Inf. Sci.},
  title        = {An improved matrix factorization based model for many-objective optimization recommendation},
  volume       = {579},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary multi and many-objective optimization via
clustering for environmental selection. <em>ISCI</em>, <em>578</em>,
930–949. (<a href="https://doi.org/10.1016/j.ins.2021.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, multi and many-objective evolutionary algorithms (MOEAs) embedded with clustering techniques to enhance their environmental selection show promising performance for tackling multi and many-objective optimization problems (MOPs) with irregular Pareto fronts (PFs). However, the similarity metric used for clustering cannot reflect the diversity of solutions fairly when it is measured based on the direction distances of solutions to an ideal point. Consequently, it may mislead the environmental selection when solving MOPs with convex PFs. To alleviate this issue, this paper suggests an MOEA using clustering with a flexible similarity metric to run the environmental selection. In our approach, we first use a simple yet effective method to roughly predict the concavity or convexity of the target problem. Then, a flexible reference point is set to define the direction distances of solutions, which can properly measure the similarity between solutions and fairly show their diversity for solving MOPs with various PF shapes. After that, we use a hierarchical clustering method with this flexible similarity metric to run the environmental selection on all solutions, which will properly classify them into N clusters ( N is the population size). Finally, in each cluster, one solution with the best convergence value will survive to compose the new population. When compared to twenty-seven competitive MOEAs in solving nineteen benchmark MOPs and sixteen real-world engineering MOPs with various PF shapes, the experimental results demonstrate that the proposed algorithm has significant advantages.},
  archive      = {J_ISCI},
  author       = {Songbai Liu and Junhao Zheng and Qiuzhen Lin and Kay Chen Tan},
  doi          = {10.1016/j.ins.2021.08.054},
  journal      = {Information Sciences},
  pages        = {930-949},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary multi and many-objective optimization via clustering for environmental selection},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BALFA: A brain storm optimization-based adaptive latent
factor analysis model. <em>ISCI</em>, <em>578</em>, 913–929. (<a
href="https://doi.org/10.1016/j.ins.2021.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information overload in recent years has tremendously sparked recommender systems (RSs). An RSs usually recommends valuable information for users based on historical experience high-dimensional and incomplete (HDI) data. Since each user cannot mark whole items, extracting latent factors (LF) learned by the stochastic gradient descent (SGD) optimization method is frequently used. However, interference from the adjustment of parameters induces an inferior convergence rate and low efficiency. To address this issue, the paper proposes a b rain storm optimization (BSO)-based a daptative l atent f actor a nalysis (BALFA) model consisting of the following three essential ideas: 1) divergent mechanism to avoid premature convergence, 2) particle retention technique to prevent invalid search, and 3) self-adaptive multidimensional leaning rate for more efficient application on varying data. Moreover, the convergence of the modified BSO used in BALFA is proofed based on the Markov chain . Comparison experiments on six HDI datasets in the SGD-based LF model indicate that the BALFA achieves state-of-art convergence rate and computational efficiency for HDI data analysis.},
  archive      = {J_ISCI},
  author       = {Qing Li and Mingsheng Shang},
  doi          = {10.1016/j.ins.2021.08.057},
  journal      = {Information Sciences},
  pages        = {913-929},
  shortjournal = {Inf. Sci.},
  title        = {BALFA: A brain storm optimization-based adaptive latent factor analysis model},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection using fisher score and multilabel
neighborhood rough sets for multilabel classification. <em>ISCI</em>,
<em>578</em>, 887–912. (<a
href="https://doi.org/10.1016/j.ins.2021.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, feature selection for multilabel classification has attracted attention in machine learning and data mining . However, some feature selection methods ignore the correlations among labels, resulting in low performance, and most of them face challenges in determining an appropriate neighborhood radius for neighborhood systems and suffer from expensive time cost. To overcome the issues, we propose a novel feature selection method using Fisher score and multilabel neighborhood rough sets (MNRS) in multilabel neighborhood decision systems. First, to identify the correlations between labels under a binary distribution, two types of new mutual information between labels are considered, and their balance coefficients are defined. By enhancing strong correlations and weakening weak correlations between labels, a mutual information-based Fisher score model with a second-order correlation between labels is designed to fit multilabel data. Second, to address the problem of automatically choosing a neighborhood radius , a subset of heterogeneous and homogeneous samples is employed to develop a new classification margin as a neighborhood radius, and some concepts of neighborhood, neighborhood class, and upper and lower approximations are formulated for multilabel neighborhood decision systems. The weight and dependency degree are presented to effectively measure the uncertainty of samples in multilabel neighborhood decision systems. Thus, we further present a new classification margin-based MNRS model. Finally, a filter-wrapper preprocessing algorithm for feature selection using the improved Fisher score model is proposed to decrease the spatiotemporal complexity of multilabel data, and a heuristic feature selection algorithm is designed for improve classification performance on multilabel datasets. Experimental results on thirteen multilabel datasets show that the proposed algorithm is effective in selecting significant features, demonstrating its excellent classification ability in multilabel datasets.},
  archive      = {J_ISCI},
  author       = {Lin Sun and Tianxiang Wang and Weiping Ding and Jiucheng Xu and Yaojin Lin},
  doi          = {10.1016/j.ins.2021.08.032},
  journal      = {Information Sciences},
  pages        = {887-912},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection using fisher score and multilabel neighborhood rough sets for multilabel classification},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast local representation learning via adaptive anchor graph
for image retrieval. <em>ISCI</em>, <em>578</em>, 870–886. (<a
href="https://doi.org/10.1016/j.ins.2021.07.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear Discriminant Analysis (LDA) is one of most important methods in dimensionality reduction domain, which is limited with Gaussian assumption . Because of the complexity of real data, data often presents non-Gaussian distribution that points in same class can be divided into several sub-clusters and center point is not enough to describe the distribution of data. In order to solve non-Gaussian data, LDA-based methods consider local structure information through measuring each pairwise distance of full connection graph. However, the strategy of establishing fully-connected graph is at expense of high computational complexity and limits it practical and industrial applications. We propose a Fast Local Representation Learning (FLRL) method which leverages anchor points to establish anchor-based graph and uses similarity matrix to depict the relationships of each pairwise connections . Notably, to avoid the affect of noises and redundant features in original space, anchor points and similarity matrix are updated alternately in subspace that local structure of data will be more precise to learn. Extensive pattern classification and image retrieval experiments on several synthetic datasets , well-known datasets and deep features datasets demonstrate the advantages of our method over the state-of-the-art methods. Our source code available on : https://github.com/superzcy/FLRL .},
  archive      = {J_ISCI},
  author       = {Canyu Zhang and Feiping Nie and Zheng Wang and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.ins.2021.07.088},
  journal      = {Information Sciences},
  pages        = {870-886},
  shortjournal = {Inf. Sci.},
  title        = {Fast local representation learning via adaptive anchor graph for image retrieval},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained attribute weighted inverted specific-class
distance measure for nominal attributes. <em>ISCI</em>, <em>578</em>,
848–869. (<a href="https://doi.org/10.1016/j.ins.2021.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverted specific-class distance measure (ISCDM) ranks first in the list of distance metrics that deal solely with nominal attributes, especially when values are missing and noise exists in non-class attributes. However, the attribute independence assumption still inevitably exists, which is almost untenable in many real-world applications with sophisticated attribute dependencies. Many improved versions based on different attribute weighting schemes have been proposed to relax this unrealistic assumption and circumvent its damage to measuring performance. However, existing attribute weighting schemes are limited to assigning a weight corresponding to each attribute; they ignore the more fine-grained dependence relationships between attributes and classes. Thus, in this study, we derive a novel fine-grained attribute weighting scheme, which first calculates the initial fine-grained attribute weights according to different attribute values and class labels and then uses random walk with restart to optimize them. We titled our improved measure fine-grained attribute-weighted ISCDM (FAWISCDM). Extensive experimental results on 66 datasets from a machine learning repository, collected by the University of California at Irvine illustrate that the FAWISCDM is notably superior to the original ISCDM and some other state-of-the-art competing methods, in terms of the negative conditional log likelihood and root relative squared error.},
  archive      = {J_ISCI},
  author       = {Fang Gong and Xin Wang and Liangxiao Jiang and Seyyed Mohammadreza Rahimi and Dianhong Wang},
  doi          = {10.1016/j.ins.2021.08.041},
  journal      = {Information Sciences},
  pages        = {848-869},
  shortjournal = {Inf. Sci.},
  title        = {Fine-grained attribute weighted inverted specific-class distance measure for nominal attributes},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Zero-shot learning via the fusion of generation and
embedding for image recognition. <em>ISCI</em>, <em>578</em>, 831–847.
(<a href="https://doi.org/10.1016/j.ins.2021.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional image recognition methods require abundant labelled images to learn robust recognition models, and only the images from the classes that appear in the training set (also called seen classes) can be recognized. Thus, determining how to recognize an image from a novel class (also called unseen class) is very challenging. Zero-Shot Learning (ZSL) is proposed to address the above issue. In this paper, we present a novel ZSL model called ZSL based on class prototype and dual latent subspace learning with reconstruction (ZSL-CPLSR). Aiming at the problems of domain shift and information loss, ZSL-CPLSR integrates generation and embedding into a unified framework in the inductive setting, which takes full advantage of the semantic information of unseen classes to alleviate the domain shift and learns more discriminative information with less effective information loss. We conduct comprehensive experiments on four benchmark datasets widely adopted in ZSL. The experimental results show the superiority of ZSL-CPLSR to the state-of-the-art ZSL methods, validating the effectiveness of ZSL-CPLSR.},
  archive      = {J_ISCI},
  author       = {Peng Zhao and Siying Zhang and Jinhui Liu and Huiting Liu},
  doi          = {10.1016/j.ins.2021.08.061},
  journal      = {Information Sciences},
  pages        = {831-847},
  shortjournal = {Inf. Sci.},
  title        = {Zero-shot learning via the fusion of generation and embedding for image recognition},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic output feedback control for networked systems with
limited communication based on deadband event-triggered mechanism.
<em>ISCI</em>, <em>578</em>, 817–830. (<a
href="https://doi.org/10.1016/j.ins.2021.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a deadband event-triggered mechanism is used to reduce the transmission data of the network channel to improve the performance of networked control systems (NCSs) with limited communication. In view of the unmeasurable state signal in the actual network system, the dynamic output feedback control problem for the NCSs is studied. When network-induced delays, time-varying sampling intervals and signal transmission deadbands are considered simultaneously, the model of NCSs under the deadband event-triggered mechanism is constructed, and a sufficient condition for the stability of NCSs is given. Furthermore, the design method of the dynamic output feedback controller of NCSs under deadband event-triggered mechanism is proposed. Two simulation examples are used to show that the proposed approach can obtain the dynamic output feedback controller for NCSs with the deadband event-triggered mechanism, and also illustrate the deadband event-triggered mechanism can reduce the signal transmission in the network channel to obtain better system performance.},
  archive      = {J_ISCI},
  author       = {Ying-Ying Liu and Wei-Wei Che and Chao Deng},
  doi          = {10.1016/j.ins.2021.08.047},
  journal      = {Information Sciences},
  pages        = {817-830},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic output feedback control for networked systems with limited communication based on deadband event-triggered mechanism},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Eigenproblem driven triangular fuzzy analytic hierarchy
process. <em>ISCI</em>, <em>578</em>, 795–816. (<a
href="https://doi.org/10.1016/j.ins.2021.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The eigenproblem plays a crucial role on checking acceptability of decision-makers’ pairwise comparison results and deriving priorities from preference relation matrices in the analytic hierarchy process (AHP). This paper analyzes two recent fuzzy eigenvector methods and illustrates their deficiencies. Two frameworks of additively normalized triangular fuzzy priorities (ANTFPs) are introduced to characterize a cluster of equivalent fuzzy priority vectors. Based on the approximation relationship between triangular fuzzy multiplicative preference relation matrices and their most appropriate ANTFPs, three eigenproblems with positive real matrices are established and an eigenvector based linear program is developed to obtain support interval based ANTFPs from fuzzy multiplicative preference relation matrices. The largest eigenvalue weighting consistency index and consistency ratio are defined and an acceptability checking method is then proposed by both examining acceptable consistency of fuzzy multiplicative preference relation matrices and acceptable vagueness of eigenvector based ANTFPs. Afterwards, an eigenproblem driven triangular fuzzy AHP is devised in detail. A numerical illustration including four fuzzy multiplicative preference relation matrices is provided and a comparative study is carried out to demonstrate the superiority and effectiveness of the presented models. Meanwhile, a multi-criteria graduate job selection problem is used to show the application of the proposed triangular fuzzy AHP.},
  archive      = {J_ISCI},
  author       = {Zhou-Jing Wang},
  doi          = {10.1016/j.ins.2021.08.051},
  journal      = {Information Sciences},
  pages        = {795-816},
  shortjournal = {Inf. Sci.},
  title        = {Eigenproblem driven triangular fuzzy analytic hierarchy process},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Turing instability induced by complex networks in a
reaction–diffusion information propagation model. <em>ISCI</em>,
<em>578</em>, 762–794. (<a
href="https://doi.org/10.1016/j.ins.2021.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dynamics of rumor spreading in the information environment is a valuable way to study information management and public opinion monitoring. In this paper, the spreading of rumors and the behavior of crowd diffusion on network structure are studied by establishing a Suspicious-Infected ( SI SI ) reaction–diffusion model of rumor spreading with Allee effect. Especially, the necessary conditions for Turing pattern to appear in space are studied. Then, Monte Carlo simulation was used to prove the validity of the model. Furthermore, extensive numerical evaluation of the system is carried out under different networks, whose results show that the diffusion coefficient can change the patterns significantly. Then, on the lattice network and the cellular network , the spatial instability will cause the same pattern type, while the density distributions of S S and I I are no longer consistent on WS networks and BA networks. In addition, the change of the network structure and the introduction of the periodicity of diffusion coefficient will make the instability of the original system disappear in space. These works have certain guiding value to the prediction of rumor spreading scope.},
  archive      = {J_ISCI},
  author       = {Le He and Linhe Zhu and Zhengdi Zhang},
  doi          = {10.1016/j.ins.2021.08.037},
  journal      = {Information Sciences},
  pages        = {762-794},
  shortjournal = {Inf. Sci.},
  title        = {Turing instability induced by complex networks in a reaction–diffusion information propagation model},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Adversarial strategy for transductive zero-shot learning.
<em>ISCI</em>, <em>578</em>, 750–761. (<a
href="https://doi.org/10.1016/j.ins.2021.06.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) realizes unseen object recognition by transferring knowledge from seen classes to unseen classes under common semantic space assumption, such as attribute space and semantic word vector space. Previous works used seen image feature and semantic representation but ignored unseen test image features to learn a projection from visual space to semantic space, which may lead to the domain shift problem, i.e., due to disjoint seen and unseen classes, the projection learnt from auxiliary dataset is biased when applied directly to the target dataset. In this paper, adversarial strategy is proposed with an instantiation to deal with domain shift problem. It is described as a two-player game in which player 1 is projector while player 2 is classifier. Projector expects to learn a projection from visual space to semantic space with good semantic preservation property while classifier expects to achieve high accuracy. The adversarial meaning comes from the design of parallel structure between loss function on training samples and that on test samples, semantic compatibility of these two loss functions and loss function in classifier, and distribution alignment. A theoretical analysis is provided and experiments are performed on benchmark datasets to ascertain the effectiveness of adversarial strategy .},
  archive      = {J_ISCI},
  author       = {Youfa Liu and Bo Du and Fuchuan Ni},
  doi          = {10.1016/j.ins.2021.06.085},
  journal      = {Information Sciences},
  pages        = {750-761},
  shortjournal = {Inf. Sci.},
  title        = {Adversarial strategy for transductive zero-shot learning},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The identification of crucial spreaders in complex networks
by effective gravity model. <em>ISCI</em>, <em>578</em>, 725–749. (<a
href="https://doi.org/10.1016/j.ins.2021.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex network is a network that has the characteristics of small world, clustering, and power-law distribution. The discovery of crucial spreaders, as one of the significant research directions in complex networks, is mainly used to identify nodes that play a key role in the structure and function of the network. The gravity model is a special method in identifying influencers. However, it involves an open issue that is how to determine the range of interaction. In addition, the mass is merely represented by degree of nodes in traditional methods, which is also a thought-provoking question. For the sake of solving the above two problems, this paper presents an effective gravity model which is based on the precise radius and value information. The rough truncation radius is accurately calculated. And the value information, which represents the dissemination ability of the node, is modified to mass. In short, the node’s influence range and value score are calculated according to the attributes of each node and the interaction of neighbor’s nodes in the network. Compared with other similar methods and state-of-the-art measures, the rationality and superiority of our approach are demonstrated through six experiments on eleven real-world networks.},
  archive      = {J_ISCI},
  author       = {Shuyu Li and Fuyuan Xiao},
  doi          = {10.1016/j.ins.2021.08.026},
  journal      = {Information Sciences},
  pages        = {725-749},
  shortjournal = {Inf. Sci.},
  title        = {The identification of crucial spreaders in complex networks by effective gravity model},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal soccer highlight identification using a sparse
subset of frames integrating long-term sliding windows. <em>ISCI</em>,
<em>578</em>, 702–724. (<a
href="https://doi.org/10.1016/j.ins.2021.07.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive growth of audiences eager for sport content has substantially increased workers’ demand in this profitable segment. Highlight identification is vital for summarizing football matches. Decision support tools can significantly reduce the number of company employees required to tackle such a task, widely benefiting workforce resource allocation. This paper discusses the development of an automatic football highlight detector. The proposed system exploits discriminative low-level audio and video features extracted from a compact set of irregularly time–spaced frames that integrate a long-term sliding window. A new mixed wrapper-probabilistic algorithm leverages a cost-effective selection of the most significant frames submitted to a robust multi-frame consensus classification scheme . By considering a comprehensive database integrating 30 full matches, the proposed approach achieves a highlight identification rate of 100\% (including all annotated goals), conjugated with a match-time compression rate of about 94\%, when employing a Random Forest classifier .},
  archive      = {J_ISCI},
  author       = {Carolina L. Bez and João B.O. Souza Filho and Luiz G.L.B.M. de Vasconcelos and Thiago Frensch and Eduardo A.B. da Silva and Sergio L. Netto},
  doi          = {10.1016/j.ins.2021.07.066},
  journal      = {Information Sciences},
  pages        = {702-724},
  shortjournal = {Inf. Sci.},
  title        = {Multimodal soccer highlight identification using a sparse subset of frames integrating long-term sliding windows},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ready for emerging threats to recommender systems? A graph
convolution-based generative shilling attack. <em>ISCI</em>,
<em>578</em>, 683–701. (<a
href="https://doi.org/10.1016/j.ins.2021.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explore the robustness of recommender systems , researchers have proposed various shilling attack models and analyzed their adverse effects. Primitive attacks are highly feasible but less effective due to simplistic handcrafted rules, while upgraded attacks are more powerful but costly and difficult to deploy because they require more knowledge from recommendations. In this paper, we explore a novel shilling attack called Graph cOnvolution-based generative shilling ATtack (GOAT) to balance the attacks’ feasibility and effectiveness. GOAT adopts the primitive attacks’ paradigm that assigns items for fake users by sampling and the upgraded attacks’ paradigm that generates fake ratings by a deep learning-based model. It deploys a generative adversarial network (GAN) that learns the real rating distribution to generate fake ratings. Additionally, the generator combines a tailored graph convolution structure that leverages the correlations between co-rated items to smoothen the fake ratings and enhance their authenticity. The extensive experiments on two public datasets evaluate GOAT’s performance from multiple perspectives. Our study of the GOAT demonstrates technical feasibility for building a more powerful and intelligent attack model with a much-reduced cost, enables analysis the threat of such an attack and guides for investigating necessary prevention measures.},
  archive      = {J_ISCI},
  author       = {Fan Wu and Min Gao and Junliang Yu and Zongwei Wang and Kecheng Liu and Xu Wang},
  doi          = {10.1016/j.ins.2021.07.041},
  journal      = {Information Sciences},
  pages        = {683-701},
  shortjournal = {Inf. Sci.},
  title        = {Ready for emerging threats to recommender systems? a graph convolution-based generative shilling attack},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Class imbalance learning using fuzzy ART and intuitionistic
fuzzy twin support vector machines. <em>ISCI</em>, <em>578</em>,
659–682. (<a href="https://doi.org/10.1016/j.ins.2021.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification in imbalanced datasets is one of the main problems for machine learning techniques . Support vector machine (SVM) is biased to the majority class samples, and the minority class samples may incorrectly be considered as noise. Therefore, SVM has poor predictive accuracy for imbalanced datasets and generates inaccurate classification models . Existing class imbalance learning (CIL) techniques can make SVM less sensitive to class imbalance, but these methods suffer from issues related to noise and outliers. Moreover, despite the solid theoretical basis and good classification performance, SVM is not appropriate for the classification of large-scale datasets because the training complexity of SVM is closely related to the dataset size. Class imbalance learning (CIL) using Fuzzy adaptive resonance theory (ART) and intuitionistic fuzzy twin SVM (CIL-FART-IFTSVM), which can be applied to address the class imbalance issue in the presence of noise and outliers and large scale datasets, is proposed to overcome these substantial difficulties. In this method, we modify the distribution of the datasets using fuzzy adaptive resonance theory (Fuzzy ART) as a clustering method to overcome the imbalance problem. Then, after data reduction, IFTSVM is utilized to find excellent non-parallel hyperplanes in the generated data points. Finally, a coordinate descent system with shrinking by an active set is applied to reduce the computational complexity . Forty-five imbalanced datasets are considered to validate the performance of the proposed CIL-FART-IFTSVM method. The Friedman test and the bootstrap technique with 95\%\% confidence intervals are applied to quantify the results statistically. The experimental results indicate that the method proposed in this paper has a better performance compared with other methods, and the training time is significantly better than that of other classifiers for large-scale datasets.},
  archive      = {J_ISCI},
  author       = {Salim Rezvani and Xizhao Wang},
  doi          = {10.1016/j.ins.2021.07.010},
  journal      = {Information Sciences},
  pages        = {659-682},
  shortjournal = {Inf. Sci.},
  title        = {Class imbalance learning using fuzzy ART and intuitionistic fuzzy twin support vector machines},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning feature-based setpoint generation and optimal
control for flotation processes. <em>ISCI</em>, <em>578</em>, 644–658.
(<a href="https://doi.org/10.1016/j.ins.2021.07.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision-based control is a nonintrusive, cost-effective, and reliable technique for flotation process control. It is known that deep learning features can depict the complex behavior of the froth surface more comprehensively and accurately than handcrafted features. However, few studies have tried to use additional information to improve flotation performance through optimal control . To this end, we have attempted to develop a novel deep learning feature-based two-layer optimal control scheme. The first layer is proposed for setpoint generation of high-dimensional features using improved fuzzy association rule reasoning. Then, an offline conservative double Q-learning control layer that can learn from historical industrial records by mitigating bootstrapping error in action value functions is developed. The proposed method can adapt the setpoint to the change in process feeds. Meanwhile, in contrast to traditional approximate dynamic programming methods that need to interact with real/simulated process systems, this controller can work without any further interactions, which makes it possible to transfer the success of reinforcement learning algorithms to complex industrial process control where opportunities to explore are missing. Experiments demonstrate that the proposed method is effective and promising for practical flotation process control.},
  archive      = {J_ISCI},
  author       = {Mingxi Ai and Yongfang Xie and Zhaohui Tang and Jin Zhang and Weihua Gui},
  doi          = {10.1016/j.ins.2021.07.060},
  journal      = {Information Sciences},
  pages        = {644-658},
  shortjournal = {Inf. Sci.},
  title        = {Deep learning feature-based setpoint generation and optimal control for flotation processes},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous estimation and modeling of nonlinear,
non-gaussian state-space systems. <em>ISCI</em>, <em>578</em>, 621–643.
(<a href="https://doi.org/10.1016/j.ins.2021.06.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a framework for simultaneous estimation and modeling of nonlinear, non-Gaussian state-space systems. In the proposed approach, uncertainty in motion model parameters is incorporated to avoid overconfidence in state prediction and better account for modeling inaccuracies. The additional original contribution of a model correction stage improves nonlinear model parameter estimates in order to enhance the accuracy of state estimation. The presented nonlinear/non-Gaussian Simultaneous Estimation And Modeling (SEAM) approach was compared with contemporary estimation techniques using a Monte-Carlo simulation study. This study showed that the proposed method successfully reduces estimation error relative to existing approaches even when substantial model parameter uncertainty and multi-modal sensor noise are present. The framework has potential use in a wide range of applications where state-space estimation is employed, including robotics, signal processing, and controls.},
  archive      = {J_ISCI},
  author       = {J. Josiah Steckenrider and Tomonari Furukawa},
  doi          = {10.1016/j.ins.2021.06.097},
  journal      = {Information Sciences},
  pages        = {621-643},
  shortjournal = {Inf. Sci.},
  title        = {Simultaneous estimation and modeling of nonlinear, non-gaussian state-space systems},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On formal concepts of random formal contexts. <em>ISCI</em>,
<em>578</em>, 615–620. (<a
href="https://doi.org/10.1016/j.ins.2021.07.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In formal concept analysis, it is well-known that the number of formal concepts is exponential in the worst case. To analyze the average case, we introduce a probabilistic model for random formal contexts and prove that the average number of formal concepts is superpolynomial.},
  archive      = {J_ISCI},
  author       = {Taro Sakurai},
  doi          = {10.1016/j.ins.2021.07.065},
  journal      = {Information Sciences},
  pages        = {615-620},
  shortjournal = {Inf. Sci.},
  title        = {On formal concepts of random formal contexts},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-type weight adjustments in MOEA/d for highly constrained
many-objective optimization. <em>ISCI</em>, <em>578</em>, 592–614. (<a
href="https://doi.org/10.1016/j.ins.2021.07.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key issue in evolutionary constrained optimization is how to achieve a balance between feasible and infeasible solutions. The quality of generated solutions in decomposition-based multi-objective evolutionary algorithms (MOEAs) depends strongly on the weights’ setting. To fully utilize both the promising feasible and infeasible solutions, this paper proposes two-type weight adjustments based on MOEA/D for solving highly constrained many-objective optimization problems (CMaOPs). During the course of the search, the number of infeasible weights is dynamically reduced, to guide infeasible solutions with better convergence to cross the infeasible barrier, and also to lead infeasible solutions with better diversity to locate multiple feasible subregions . Feasible weights are evenly distributed and keep unchanged throughout the evolution process, which aims to guide the population to search Pareto optimal solutions . The effectiveness of the proposed algorithm is verified by comparing it against six state-of-the-art CMaOEAs on three sets of benchmark problems. Experimental results show that the proposed algorithm outperforms compared algorithms on majority problems, especially on highly constrained optimization problems. Besides, the effectiveness of the proposed algorithm has also been verified on an antenna array synthesis problem .},
  archive      = {J_ISCI},
  author       = {Ruwang Jiao and Sanyou Zeng and Changhe Li and Yew-Soon Ong},
  doi          = {10.1016/j.ins.2021.07.048},
  journal      = {Information Sciences},
  pages        = {592-614},
  shortjournal = {Inf. Sci.},
  title        = {Two-type weight adjustments in MOEA/D for highly constrained many-objective optimization},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterative rank-one matrix completion via singular value
decomposition and nuclear norm regularization. <em>ISCI</em>,
<em>578</em>, 574–591. (<a
href="https://doi.org/10.1016/j.ins.2021.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix completion is widely used in many fields. In existing matrix completion methods, such as rank minimization and matrix factorization , the hyperparameters must be learned. However, hyperparameter tuning is a time-consuming and tedious process. In this paper, we propose a novel matrix completion method called IMC, i.e., iterative rank-one matrix completion via singular value decomposition (SVD) and nuclear norm regularization . First, we construct a rank-one matrix completion model using nuclear norm regularization . Then, the variables to be optimized in the model are divided into several blocks. Finally, the blocks are iteratively optimized one by one until convergence. For the optimization of each block, we propose an efficient solution scheme based on SVD, in which only the maximum singular value and leading singular vectors of a sparse matrix must be calculated. Further, a nonparametric singular value penalty function is designed to ensure a low-rank completion matrix. In addition, the optimization of each block uses only the values inside the observed entries; hence, no errors are accumulated. Test results shows that the proposed method converges rapidly and outperforms some state-of-the-art methods when applied to grayscale image restoration, recommendation systems, and vote networks.},
  archive      = {J_ISCI},
  author       = {Kai Xu and Ying Zhang and Zhi Xiong},
  doi          = {10.1016/j.ins.2021.07.035},
  journal      = {Information Sciences},
  pages        = {574-591},
  shortjournal = {Inf. Sci.},
  title        = {Iterative rank-one matrix completion via singular value decomposition and nuclear norm regularization},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RCTE: A reliable and consistent temporal-ensembling
framework for semi-supervised segmentation of COVID-19 lesions.
<em>ISCI</em>, <em>578</em>, 559–573. (<a
href="https://doi.org/10.1016/j.ins.2021.07.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The segmentation of COVID-19 lesions from computed tomography (CT) scans is crucial to develop an efficient automated diagnosis system. Deep learning (DL) has shown success in different segmentation tasks . However, an efficient DL approach requires a large amount of accurately annotated data, which is difficult to aggregate owing to the urgent situation of COVID-19. Inaccurate annotation can easily occur without experts, and segmentation performance is substantially worsened by noisy annotations. Therefore, this study presents a reliable and consistent temporal-ensembling (RCTE) framework for semi-supervised lesion segmentation . A segmentation network is integrated into a teacher-student architecture to segment infection regions from a limited number of annotated CT scans and a large number of unannotated CT scans. The network generates reliable and unreliable targets, and to evenly handle these targets potentially degrades performance. To address this, a reliable teacher-student architecture is introduced, where a reliable teacher network is the exponential moving average (EMA) of a reliable student network that is reliably renovated by restraining the student involvement to EMA when its loss is larger. We also present a noise-aware loss based on improvements to generalized cross-entropy loss to lead the segmentation performance toward noisy annotations. Comprehensive analysis validates the robustness of RCTE over recent cutting-edge semi-supervised segmentation techniques , with a 65.87\% Dice score.},
  archive      = {J_ISCI},
  author       = {Weiping Ding and Mohamed Abdel-Basset and Hossam Hawash},
  doi          = {10.1016/j.ins.2021.07.059},
  journal      = {Information Sciences},
  pages        = {559-573},
  shortjournal = {Inf. Sci.},
  title        = {RCTE: A reliable and consistent temporal-ensembling framework for semi-supervised segmentation of COVID-19 lesions},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subgraph matching on temporal graphs. <em>ISCI</em>,
<em>578</em>, 539–558. (<a
href="https://doi.org/10.1016/j.ins.2021.07.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Temporal graphs are graphs whose edges are associated with timestamps. Subgraph matching on temporal graphs retrieves temporal subgraphs whose edge timestamps satisfy user-specified temporal orders. In this paper, a temporal query pattern is composed of a query graph with an arbitrary structure and a partial order on the edge set of the query graph. Moreover, the time span between the minimum and the maximum edge timestamps in a matching is required to be less than or equal to a specified threshold. This paper proposes a temporal subgraph matching algorithm based on two key techniques. First, a memory-efficient index structure called TO-tree is designed to compactly store all necessary information required for finding all temporal subgraph matchings. The TO-tree constructed for a temporal query pattern is much smaller than the temporal graph because unnecessary information is mostly excluded from the TO-tree by three powerful filters. The second technique is a temporal subgraph matching enumeration method that runs on the TO-tree instead of on the temporal graph. This enumeration method expands temporal subgraph matchings in an edge-by-edge manner. Since the TO-tree can fit into the main memory, the enumeration method runs very fast on the TO-tree. An extensive experimental evaluation has been carried out. The experimental results show that the TO-tree index structure is memory-efficient, which in turn enables a fast temporal subgraph matching enumeration. Overall, our algorithm is at least 3X faster than the baseline algorithm adapted from the state-of-the-art non-temporal subgraph matching algorithm CECI and is at least 4X faster than the temporal subgraph matching algorithm HASSE .},
  archive      = {J_ISCI},
  author       = {Faming Li and Zhaonian Zou},
  doi          = {10.1016/j.ins.2021.07.071},
  journal      = {Information Sciences},
  pages        = {539-558},
  shortjournal = {Inf. Sci.},
  title        = {Subgraph matching on temporal graphs},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid-attention guided network with multiple resolution
features for person re-identification. <em>ISCI</em>, <em>578</em>,
525–538. (<a href="https://doi.org/10.1016/j.ins.2021.07.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting effective and discriminative features is highly important for addressing the challenges of person re-identification (re-ID). At present, deep convolutional neural networks typically use high-level features to identify pedestrians. However, some essential spatial information contained in low-level features will be lost during the learning of high-level feature. Most existing person re-ID methods rely primarily on hand-crafted bounding boxes , in which person images are precisely aligned. However, these approaches are unrealistic in practical applications due to the inaccuracy of automatic detection algorithms . To address these problems, we propose a hybrid-attention guided network with multiple resolution features for person re-ID. First, we construct a multi-resolution fusion strategy to ensure that multi-resolution features can be spatially aligned during feature fusion , while at the same time ensuring the discriminability of features after fusion. We then introduce an attention mechanism and multi-granularity operation to reduce the impact of irregular bounding boxes by gently expanding the size of feature maps. In addition, a new multi-pool feature extractor is designed to obtain different types of information by using two different pools, enabling the feature representation capability to be further improved. Extensive experiments demonstrate the superiority of our approach. Our code is available at https://github.com/libraflower/MutipleFeature-for-PRID.},
  archive      = {J_ISCI},
  author       = {Guoqing Zhang and Junchuan Yang and Yuhui Zheng and Ye Wang and Yi Wu and Shengyong Chen},
  doi          = {10.1016/j.ins.2021.07.058},
  journal      = {Information Sciences},
  pages        = {525-538},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid-attention guided network with multiple resolution features for person re-identification},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust discriminative feature subspace analysis for kinship
verification. <em>ISCI</em>, <em>578</em>, 507–524. (<a
href="https://doi.org/10.1016/j.ins.2021.07.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Kinship verification using single image of a person is a challenging task for real-world applications. In this paper, we propose a novel robust discriminative feature subspace analysis (RDFSA) method to address single sample per person (SSPP) problem in kinship verification. The proposed RDFSA method takes advantages of facial symmetry and patch-based analysis to extract discriminative features for kinship verification. Each face image is firstly divided into two halves about bilateral symmetry axis, and each halved face is then partitioned into equal sized non-overlapping patches. Multiple image-sets are formed by grouping these patches according to their positions at each halved face. Then, an SSPP is formulated as an RDFSA problem and a feature subspace is learned by maximizing inter-class separation and minimizing intra-class variance for different patches in each image-set. For a given test image pair, similarity is computed for each feature subspace and majority voting strategy is employed to determine if a given image pair is kin related or not. Proposed RDFSA method is extensively evaluated on different publicly available kinship datasets to validate kinship accuracy. Experimental results show that RDFSA achieves competitive accuracy on all kinship datasets while performing kinship verification under unconstrained environment.},
  archive      = {J_ISCI},
  author       = {Aarti Goyal and Toshanlal Meenpal},
  doi          = {10.1016/j.ins.2021.07.046},
  journal      = {Information Sciences},
  pages        = {507-524},
  shortjournal = {Inf. Sci.},
  title        = {Robust discriminative feature subspace analysis for kinship verification},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel three-way decision approach under hesitant fuzzy
information. <em>ISCI</em>, <em>578</em>, 482–506. (<a
href="https://doi.org/10.1016/j.ins.2021.07.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper explores a novel way to solve the multi-attribute decision-making issues under the hesitant fuzzy environment (HF-MADM) with three-way decision (3WD) theory. Firstly, according to the nature of the relative loss function (RLF), the RLF under the hesitant fuzzy (HF) environment is defined. Then, according to the practical significance of the loss function, this paper establishes the relationship between the loss function and the evaluation value. At the same time, considering that the HF-MADM has multiple attributes and multiple evaluation values, we provide an aggregated loss function via the hesitant fuzzy weight average (HFWA) operator to reflect the overall loss of the alternative. We establish the mixed information table (HF-MADMRLF) based on the overall loss function. Secondly, based on an outranking function and a distance from the positive ideal (PI) solution, this paper defines an estimation on the conditional probability method. Finally, we utilize the presented method to solve actual medical diagnosis of pneumonia (MDP) issue, and prove the validity and applicability of the method through comparison with several representative methods and experimental evaluations.},
  archive      = {J_ISCI},
  author       = {Jiajia Wang and Xueling Ma and Jianhua Dai and Jianming Zhan},
  doi          = {10.1016/j.ins.2021.07.054},
  journal      = {Information Sciences},
  pages        = {482-506},
  shortjournal = {Inf. Sci.},
  title        = {A novel three-way decision approach under hesitant fuzzy information},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-adaptive two roles hybrid learning strategies-based
particle swarm optimization. <em>ISCI</em>, <em>578</em>, 457–481. (<a
href="https://doi.org/10.1016/j.ins.2021.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle Swarm Optimization (PSO) is a simple yet efficient population based evolutionary algorithm, which has been widely applied to solve global optimization problems. Similar to other evolutionary algorithms (EAs), PSO algorithm still suffers from loss of diversity and slow convergence caused by the contradiction between exploration and exploitation abilities. In order to address the drawbacks, we propose Self-Adaptive two roles hybrid learning strategies-based particle swarm optimization (SAHLPSO) to improve optimization performance by using exploration-role and exploitation-role learning strategies with self-adaptively updating parameters manner. The exploration-role learning strategies with external archive adopt comprehensive learning to generate the learning exemplars, which can effectively maintain population diversity and thus avoid premature. On the other hand, the exploitation-role learning strategies utilize elitism learning to generate the learning exemplars so as to improve convergence performance. Considering that the performance improvement of PSO depends on not only the adaptation of different learning strategies but also the reasonable parameter settings, we also develop a self-adaptive parameter updating manner based on success history information. This manner can automatically update the learning parameters to appropriate values and avoid a user’s prior knowledge about the relationship between the parameter settings and the characteristics of optimization problems. In addition, the usage of the linear population size reduction is also helpful to well balance the exploration and exploitation along with the process of evolution. Simulation results on some classical and CEC2013 benchmark functions show that LSAHLPSO is better than other PSO variants or at least comparable to other state-of-the-art evolutionary algorithms.},
  archive      = {J_ISCI},
  author       = {Xinmin Tao and Xiangke Li and Wei Chen and Tian Liang and Yetong Li and Jie Guo and Lin Qi},
  doi          = {10.1016/j.ins.2021.07.008},
  journal      = {Information Sciences},
  pages        = {457-481},
  shortjournal = {Inf. Sci.},
  title        = {Self-adaptive two roles hybrid learning strategies-based particle swarm optimization},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperspectral image classification based on spatial and
spectral kernels generation network. <em>ISCI</em>, <em>578</em>,
435–456. (<a href="https://doi.org/10.1016/j.ins.2021.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread use of deep learning methods, more and more classification models based on hyperspectral images (HSI) have been continuously proposed. However, due to the characteristics of high dimensionality and low resolution of HSI, the traditional convolutional neural network (CNN) model cannot effectively process it. In this paper, we propose a classification network, called spatial and spectral kernels generation network (SSKNet), to generate spatial and spectral convolution kernels based on image characteristics, and use them to replace the traditional initialization convolution kernels. We can obtain representative kernels with stronger spatial correlation with the region segmentation, clustering, and mapping operations of the spatial kernels generation module (SaKG Module). Simultaneously, we also propose a spectral kernels generation module (SeKG module), which integrates the multi-scale correlation characteristics of different bands into the spectral attention mechanism , making the generated spectral kernels more accurate. Combining the spatial and spectral kernels allows the network to extract salient features and achieve feature fusion efficiently. Experimental results based on multiple HSI data sets show that the proposed method has better classification accuracy and generalization performance than existing methods.},
  archive      = {J_ISCI},
  author       = {Wenping Ma and Haoxiang Ma and Hao Zhu and Yating Li and Longwei Li and Licheng Jiao and Biao Hou},
  doi          = {10.1016/j.ins.2021.07.043},
  journal      = {Information Sciences},
  pages        = {435-456},
  shortjournal = {Inf. Sci.},
  title        = {Hyperspectral image classification based on spatial and spectral kernels generation network},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decentralized algorithm for distributed ensemble
clustering. <em>ISCI</em>, <em>578</em>, 417–434. (<a
href="https://doi.org/10.1016/j.ins.2021.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the problem of distributed unsupervised learning where data to be clustered are partitioned over a set of agents having limited connectivity. In order to solve this problem, we consider a novel and extended ensemble clustering procedure in order to make it suitable to a fully distributed scenario. The proposed algorithm can deal with the case where each agent has a local and different dataset. Additionally, to reduce the total amount of exchanged information, only the local prototypes of clusters are forwarded among the neighbors. Cluster similarity indexes are adopted to solve conflicts among agents and to achieve a common structure at the end of the communication process. The experimental results prove the feasibility of this approach, which is able to reach an optimal performance when compared to a fully centralized implementation, that is where data is collected beforehand on a single clustering agent.},
  archive      = {J_ISCI},
  author       = {Antonello Rosato and Rosa Altilio and Massimo Panella},
  doi          = {10.1016/j.ins.2021.07.028},
  journal      = {Information Sciences},
  pages        = {417-434},
  shortjournal = {Inf. Sci.},
  title        = {A decentralized algorithm for distributed ensemble clustering},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic graph convolutional network for long-term traffic
flow prediction with reinforcement learning. <em>ISCI</em>,
<em>578</em>, 401–416. (<a
href="https://doi.org/10.1016/j.ins.2021.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting deep learning techniques for traffic flow prediction has become increasingly widespread. Most existing studies combine CNN or GCN with recurrent neural network to extract the spatio-temporal features in traffic networks. The traffic networks can be naturally modeled as graphs which are effective to capture the topology and spatial correlations among road links. The issue is that the traffic network is dynamic due to the continuous changing of the traffic environment. Compared with the static graph, the dynamic graph can better reflect the spatio-temporal features of the traffic network. However, in practical applications, due to the limited accuracy and timeliness of data, it is hard to generate graph structures through frequent statistical data. Therefore, it is necessary to design a method to overcome data defects in traffic flow prediction . In this paper, we propose a long-term traffic flow prediction method based on dynamic graphs. The traffic network is modeled by dynamic traffic flow probability graphs, and graph convolution is performed on the dynamic graphs to learn spatial features , which are then combined with LSTM units to learn temporal features. In particular, we further propose to use graph convolutional policy network based on reinforcement learning to generate dynamic graphs when the dynamic graphs are incomplete due to the data sparsity i sue. By testing our method on city-bike data in New York City, it demonstrates that our model can achieve stable and effective long-term predictions of traffic flow, and can reduce the impact of data defects on prediction results.},
  archive      = {J_ISCI},
  author       = {Hao Peng and Bowen Du and Mingsheng Liu and Mingzhe Liu and Shumei Ji and Senzhang Wang and Xu Zhang and Lifang He},
  doi          = {10.1016/j.ins.2021.07.007},
  journal      = {Information Sciences},
  pages        = {401-416},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic graph convolutional network for long-term traffic flow prediction with reinforcement learning},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evidential reasoning based ensemble classifier for uncertain
imbalanced data. <em>ISCI</em>, <em>578</em>, 378–400. (<a
href="https://doi.org/10.1016/j.ins.2021.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various studies have focused on the classification of uncertain or imbalanced data . However, previous studies rarely consider the classification for uncertain imbalanced data. To address this research gap, this study proposes an evidential reasoning (ER) based ensemble classifier (EREC). In the proposed method, an affinity propagation based oversampling method is developed to obtain the balanced class distributions of the training datasets for individual classifiers. Using the balanced training datasets, ER-based classifiers are constructed as individual classifiers to handle data uncertainty, in which attribute weights are learned from the similarity between the values of attributes and labels. With trained individual classifiers, final results are generated by combining the results of individual classifiers using the ER algorithm, in which the weights of individual classifiers are determined according to the classification performance on out-of-bag data. The proposed EREC is applied to the diagnosis of thyroid nodules using the datasets of five radiologists, obtained from a tertiary hospital located in Hefei, Anhui, China. Using real datasets and UCI datasets, the EREC is compared with 12 representative ensemble classifiers and other oversampling methods based ensemble classifiers to highlight its high performance.},
  archive      = {J_ISCI},
  author       = {Chao Fu and Qianshan Zhan and Weiyong Liu},
  doi          = {10.1016/j.ins.2021.07.027},
  journal      = {Information Sciences},
  pages        = {378-400},
  shortjournal = {Inf. Sci.},
  title        = {Evidential reasoning based ensemble classifier for uncertain imbalanced data},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting influential news in online communities: An
approach based on hexagons of opposition generated by three-way
decisions and probabilistic rough sets. <em>ISCI</em>, <em>578</em>,
364–377. (<a href="https://doi.org/10.1016/j.ins.2021.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work proposes a new method to detect influential news in online communities. Influential news are articles that induce shifts in users’ opinions or, in general, lead to a polarization of opinions or change like-mindedness of users. The method aims at supporting online platform managers and editors in understanding the impact that social content and news can have on the dynamics of opinions. The influential news detection is conduced by using the Three-Way Decisions approach based on Probabilistic Rough Sets to perform a tri-partitioning of online users. The three parts are then mapped onto a structure, namely Hexagons of Opposition, allowing to reason on opinions, related to a given set of news, of specific communities. More in detail, several hexagons of opposition are constructed along the timeline, as recent news are considered, and compared to detect which news contribute to change opinions of the considered communities. Moreover, two indicators have been introduced to measure the impact of the news. The proposed method has been experimented on real data derived from existing datasets and the promising results have been discussed by using a qualitative approach.},
  archive      = {J_ISCI},
  author       = {Roberto Abbruzzese and Angelo Gaeta and Vincenzo Loia and Luigi Lomasto and Francesco Orciuoli},
  doi          = {10.1016/j.ins.2021.07.014},
  journal      = {Information Sciences},
  pages        = {364-377},
  shortjournal = {Inf. Sci.},
  title        = {Detecting influential news in online communities: An approach based on hexagons of opposition generated by three-way decisions and probabilistic rough sets},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward hierarchical classification of imbalanced data using
random resampling algorithms. <em>ISCI</em>, <em>578</em>, 344–363. (<a
href="https://doi.org/10.1016/j.ins.2021.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the class imbalance issue affects hierarchical datasets, the literature has few studies that deal with it, especially when it comes to methods to pre-process the training dataset as a whole. In this study, we present novel resampling algorithms to deal with imbalance in hierarchical datasets. To be able to process the imbalanced data , we first propose methods to retrieve the set of majority and minority label paths. The resampling algorithms were designed with respect to the depth of the label path prediction and may be used for hierarchical classification problems with single- and multiple-path labels. We propose two oversampling and two undersampling algorithms: HROS-FD/PD – Random Oversampling for Full/Partial Depth Hierarchical problems, and HRUS-PD/FD – Random Undersampling for Full/Partial Depth Hierarchical problems. While the resampling algorithms for full-depth problems deal with the data by simply processing the set of majority/minority paths, the partial depth approaches process the data in a leaf-node order way, recalculating the set of majority/minority paths at each step until reaching the root label. The experimental evaluation with 23 hierarchical datasets across different domains and characteristics, supported by statistical analysis, showed that the proposed resampling algorithms significantly improve the classification performance.},
  archive      = {J_ISCI},
  author       = {Rodolfo M. Pereira and Yandre M.G. Costa and Carlos N. Silla Jr.},
  doi          = {10.1016/j.ins.2021.07.033},
  journal      = {Information Sciences},
  pages        = {344-363},
  shortjournal = {Inf. Sci.},
  title        = {Toward hierarchical classification of imbalanced data using random resampling algorithms},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated granule discovery in continuous data for feature
selection. <em>ISCI</em>, <em>578</em>, 323–343. (<a
href="https://doi.org/10.1016/j.ins.2021.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world database applications possess massive data collections with different data formats such as continuous, discrete or nominal. Continuous data makes the analysis process more complex as the data can take any value within a particular range and so granule mining has been used recently with techniques such as neighbourhood rough sets to discover granules in continuous data. This approach is yet to address the granule resolution design concepts, so this paper presents a novel method, Hierarchical Clustering-based Granulation (HCluG) to improve the granule identification of continuous data by combining hierarchical clustering with neighborhood rough sets, reducing user involvement in granule resolution parameters tuning and introducing an automated granule discovery method. HCluG comprises a feature selection method to evaluate the quality of the granules generated with the proposed granule approximations . Experimental results show HCluG reduces the number of selected features while improving the classification performance. HCluG outperforms the rough sets-based feature selection baselines when used with K-Nearest Neighbours and Radial Basis Function Support Vector Machine on average and performs better on average than using the complete feature set. This method can be used in data analysis to achieve high classification performance with a fewer number of features and less user involvement.},
  archive      = {J_ISCI},
  author       = {M.A.N.D. Sewwandi and Yuefeng Li and Jinglan Zhang},
  doi          = {10.1016/j.ins.2021.07.042},
  journal      = {Information Sciences},
  pages        = {323-343},
  shortjournal = {Inf. Sci.},
  title        = {Automated granule discovery in continuous data for feature selection},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). GT2-CFC: General type-2 collaborative fuzzy clustering
method. <em>ISCI</em>, <em>578</em>, 297–322. (<a
href="https://doi.org/10.1016/j.ins.2021.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new algorithm called general type-2 collaborative fuzzy clustering (GT2-CFC), which focuses on uncertainty associated with the structures discovered for the same data stored in multiple data sites in different feature spaces while maintaining data-sharing restrictions. The uncertainty of membership degrees is directly controlled by using the available data rather than by reinforcing the lower-order fuzzy model through general type-2 fuzzy sets (GT2FS) including primary and secondary memberships. Primary membership degrees show the obtained membership without the knowledge gained from other data sites, and secondary membership degrees indicate the belonging degree to the data in the presence of external knowledge. In addition to the ability of GT2FS in uncertainty modeling, due to the lack of any type reduction and defuzzification during the proposed clustering process, there is no data loss, and time complexity becomes is reduced leading to more powerful uncertainty modeling. Finally, a new validity index is proposed to evaluate the quality of collaboration using the relative entropy-based global consistency. The superiority and efficiency of the proposed method are illustrated with several experiments.},
  archive      = {J_ISCI},
  author       = {Fariba Salehi and Mohammad Reza Keyvanpour and Arash Sharifi},
  doi          = {10.1016/j.ins.2021.07.037},
  journal      = {Information Sciences},
  pages        = {297-322},
  shortjournal = {Inf. Sci.},
  title        = {GT2-CFC: General type-2 collaborative fuzzy clustering method},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-domain sentiment classification via parameter
transferring and attention sharing mechanism. <em>ISCI</em>,
<em>578</em>, 281–296. (<a
href="https://doi.org/10.1016/j.ins.2021.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training data in a specific domain are often insufficient in the area of text sentiment classifications. Cross-domain sentiment classification (CDSC) is usually utilized to extend the application scope of transfer learning in text-based social media and effectively solve the problem of insufficient data marking in specific domains. Hence, this paper aims to propose a CDSC method via parameter transferring and attention sharing mechanism (PTASM), and the presented architecture includes the source domain network (SDN) and the target domain network (TDN). First, hierarchical attentional network with pre-training language model on training data, such as global vectors for word representation and bidirectional encoder representations from transformers (BERT), are constructed. The word and sentence levels of parameter transferring mechanisms are introduced in the model transfer. Then, parameter transfer and fine-tuning techniques are adopted to transfer network parameters from SDN to TDN. Moreover, sentiment attention can serve as a bridge for sentiment transfer across different domains. Finally, word and sentence level attention mechanisms are introduced, and sentiment attention is shared from the two levels across domains. Extensive experiments show that the PTASM-BERT method achieves state-of-the-art results on Amazon review cross-domain datasets.},
  archive      = {J_ISCI},
  author       = {Chuanjun Zhao and Suge Wang and Deyu Li and Xianzhi Liu and Xinyi Yang and Jinfeng Liu},
  doi          = {10.1016/j.ins.2021.07.001},
  journal      = {Information Sciences},
  pages        = {281-296},
  shortjournal = {Inf. Sci.},
  title        = {Cross-domain sentiment classification via parameter transferring and attention sharing mechanism},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incremental construction of three-way concept lattice for
knowledge discovery in social networks. <em>ISCI</em>, <em>578</em>,
257–280. (<a href="https://doi.org/10.1016/j.ins.2021.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way concept analysis (3WCA), a combination of three-way decision and formal concept analysis, is widely used in the field of knowledge discovery. Generally, constructing three-way concept lattices requires the original formal context and its complement context simultaneously. Additionally, the existing three-way concept lattice construction algorithms focus on the static formal context, and cannot cope with the dynamic formal context that is an essential representation in social networks. Toward this end, this paper pioneers a novel problem and method for the incremental construction of three-way concept lattice for knowledge discovery in social networks. Aiming to facilitate the construction efficiency, this paper firstly investigates the three-way concept lattice construction for attribute-incremental/object-incremental formal contexts, respectively. Then, the dynamic formal context of a social network can be viewed as a special formal context with both attribute-increment and object-increment. Further, we develop the AE/OE concept lattice incremental construction algorithms, called SNS-AE and SNS-OE. Extensive experiments are conducted on various formal contexts to evaluate the effectiveness of our incremental algorithms. The experimental results demonstrate that our proposed incremental algorithms can significantly decrease the construction time of three-way concept lattice compared to the non-incremental algorithm.},
  archive      = {J_ISCI},
  author       = {Fei Hao and Yixuan Yang and Geyong Min and Vincenzo Loia},
  doi          = {10.1016/j.ins.2021.07.031},
  journal      = {Information Sciences},
  pages        = {257-280},
  shortjournal = {Inf. Sci.},
  title        = {Incremental construction of three-way concept lattice for knowledge discovery in social networks},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel algorithmic construction for deductions of
categorical polysyllogisms by carroll’s diagrams. <em>ISCI</em>,
<em>578</em>, 236–256. (<a
href="https://doi.org/10.1016/j.ins.2021.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, with the help of a calculus system syllogistic logic with Carroll’s diagrams (SLCD), we construct a useful algorithm for the possible deductions of polysyllogisms (soriteses). This algorithm makes a general deduction in categorical syllogisms with the help of diagrams to depict each proposition of polysyllogisms. The developed calculus system PolySLCD (PSLCD) is used to allow a formal deduction from premises set by comprising synchronically biliteral and triliteral diagrammatical appearance and simple algorithmic nature. This algorithm can be used to deduce new conclusions, step by step, through recursive conclusion sets that are obtained from premises of categorical polysyllogisms. The fundamental contributions of this paper are accurately deducing conclusions from sets corresponding to given premises as exact human reasoning using a single algorithm and designing this algorithm based on SLCD. Therefore, it is more suitable for computer-aided solution. Since the algorithm is set-based, it is a novel algorithm in the literature and it can easily contribute to the researchers using polysyllogisms in different scientific branches, such as computer science, decision-making systems and artificial intelligence .},
  archive      = {J_ISCI},
  author       = {Ibrahim Senturk and Necla Kircali Gursoy and Tahsin Oner and Arif Gursoy},
  doi          = {10.1016/j.ins.2021.07.029},
  journal      = {Information Sciences},
  pages        = {236-256},
  shortjournal = {Inf. Sci.},
  title        = {A novel algorithmic construction for deductions of categorical polysyllogisms by carroll’s diagrams},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving maximum quasi-clique problem by a hybrid artificial
bee colony approach. <em>ISCI</em>, <em>578</em>, 214–235. (<a
href="https://doi.org/10.1016/j.ins.2021.06.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a graph and a threshold ( γ ), the maximum quasi-clique (MQC) problem is to find a maximum cardinality subset of vertices in the graph such that the edge density of a corresponding induced subgraph is not less than γ . This problem istended version of the famous maximum clique problem, which arises in a various application domains and is known as NP-hard. In this study, we propose a heuristic method called the hybrid artificial bee colony (HABC) algorithm to address the MQC problem by incorporating several dedicated strategies into the artificial bee colony framework, which starts with an opposition-based initialization phase and then repeatedly alternates between an employed bees phase, an onlooker bees phase and a scout bees phase to perform the search. The employed bees phase and onlooker bees phase employ a decent local search and solution-based tabu search to locate the local optima and intensify the search,whereas the scout bees phase employs an opposition-based mechanism to reconstruct the best-found solutions to escape from the local optima and diversify the search. Experimental results indicate that our proposed HABC algorithm can improve the best-known solutions for 46 out of 112 problem instances and match the best-known solutions for 63 instances. Comparisons with the state-of-the-art heuristics and exact methods demonstrate the merits of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Bo Peng and Lifan Wu and Yang Wang and Qinghua Wu},
  doi          = {10.1016/j.ins.2021.06.094},
  journal      = {Information Sciences},
  pages        = {214-235},
  shortjournal = {Inf. Sci.},
  title        = {Solving maximum quasi-clique problem by a hybrid artificial bee colony approach},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic multi-channel metric network for joint pose-aware
and identity-invariant facial expression recognition. <em>ISCI</em>,
<em>578</em>, 195–213. (<a
href="https://doi.org/10.1016/j.ins.2021.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) is challenging because the appearance of an expression varies significantly depending on head pose and inter-subject characteristics. With existing techniques, it is often difficult to learn both pose-aware and identity-invariant representations of facial expressions effectively due to the complex distribution of intra-class variation and similarity caused by these two factors. In this study, we propose a dynamic multi-channel metric learning network for pose-aware and identity-invariant FER, called DML-Net, which can reduce the effects of pose and identity for robust FER performance. Specifically, DML-Net uses three parallel multi-channel convolutional networks to learn fused global and local features from different facial regions. Then it uses joint embedded feature learning to explore identity-invariant and pose-aware expression representations from fused region-based features in an embedding space. DML-Net is end-to-end trainable by minimizing deep multiple metric losses, FER loss, and pose estimation loss with dynamically learned loss weights, thereby suppressing overfitting and significantly improving recognition. We evaluate DML-Net on three widely-used multi-view facial expression datasets, namely, KDEF, BU-3DFE, and Multi-PIE, as well as a wild dataset SFEW2.0. Extensive experiments demonstrate that our approach outperforms several other popular methods with accuracies of 88.2\% on KDEF, 83.5\% on BU-3DFE, 93.5\% on Multi-PIE, and 54.36\% on SFEW.},
  archive      = {J_ISCI},
  author       = {Yuanyuan Liu and Wei Dai and Fang Fang and Yongquan Chen and Rui Huang and Run Wang and Bo Wan},
  doi          = {10.1016/j.ins.2021.07.034},
  journal      = {Information Sciences},
  pages        = {195-213},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic multi-channel metric network for joint pose-aware and identity-invariant facial expression recognition},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Make complex CAPTCHAs simple: A fast text captcha solver
based on a small number of samples. <em>ISCI</em>, <em>578</em>,
181–194. (<a href="https://doi.org/10.1016/j.ins.2021.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-based captchas are still widely used by many websites such as Wikipedia and Microsoft despite the emergence of many alternative captchas. Recently, the design of text-based captchas has become more and more complex to resist attacks from automatic cracking programs. However, most of the existing captcha solving methods have certain shortcomings, such as insufficient accuracy, poor generalization performance, and the need for a large number of labeled samples. This study proposes a fast captcha solver that can effectively break text-based captchas with complex security features using a small amount of labeled data. The solver was achieved by constructing a captcha transformation model based on generative adversarial networks to simplify the captcha images before character segmentation and recognition. Results showed that the proposed captcha solver achieved a high success rate of over 96\% character accuracy and 74\% captcha accuracy for all evaluated schemes. Moreover, the average time to process a single captcha image using a laptop GPU was only 4–8 ms. The effectiveness of this work may encourage captcha designers to reconsider a more secure human–machine distinction mechanism.},
  archive      = {J_ISCI},
  author       = {Yao Wang and Yuliang Wei and Mingjin Zhang and Yang Liu and Bailing Wang},
  doi          = {10.1016/j.ins.2021.07.040},
  journal      = {Information Sciences},
  pages        = {181-194},
  shortjournal = {Inf. Sci.},
  title        = {Make complex CAPTCHAs simple: A fast text captcha solver based on a small number of samples},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixing the inconsistencies in fuzzy spatiotemporal RDF
graph. <em>ISCI</em>, <em>578</em>, 166–180. (<a
href="https://doi.org/10.1016/j.ins.2021.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since an increasing number of applications have urgent requirements for the management of fuzzy spatiotemporal information, it is challenging to model fuzzy spatiotemporal data . On the other hand, because Resource Description Framework (RDF) benefits greatly from web data, linked data , and knowledge graph, it has been widely accepted and has rapidly become a new choice to model and represent data in many application domains. The advent of RDF seems to provide an opportunity for dealing with fuzzy spatiotemporal data . However, RDF data is subject to continuously changing operations so that they may violate the integrity constraints and cause inconsistencies. In order to solve these problems, we propose an extended RDF model that can represent fuzzy spatiotemporal data, and then present the structure of fuzzy spatiotemporal data in RDF graph. After studying the constraint conditions of fuzzy spatiotemporal data in RDF graph, we propose the corresponding fixing rules and algorithms to detect and repair the fuzzy spatiotemporal RDF graph. Finally, the experimental results demonstrate the effectiveness of our approach which can significantly solve the inconsistency problem of fuzzy spatiotemporal RDF graphs.},
  archive      = {J_ISCI},
  author       = {Luyi Bai and Jinyao Wang and Xiaofeng Di and Nan Li},
  doi          = {10.1016/j.ins.2021.07.038},
  journal      = {Information Sciences},
  pages        = {166-180},
  shortjournal = {Inf. Sci.},
  title        = {Fixing the inconsistencies in fuzzy spatiotemporal RDF graph},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discriminative visual tracking via spatially smooth and
steep correlation filters. <em>ISCI</em>, <em>578</em>, 147–165. (<a
href="https://doi.org/10.1016/j.ins.2021.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many discriminative correlation filter (DCF)-basedapproaches have been developed to alleviate the undesired boundary effects of traditional DCF-based methods. However, these approaches either focus on the target area by suppressing the background information or exploit a spatial regularisation term to penalise filter coefficients far from the target centre, where real negative samples are exceedingly rare and irrelevant information is integrated into filters. Based on the observation that the tracking model is strongly dependent on the quality of training samples, this paper proposes a novel DCF-based tracker to precisely process the training set through a smooth and steeply decreasing function in two respects. On the one hand, the surrounding information is suitably incorporated into the target. On the other hand, every real background patch is collected as a negative sample. In addition, the target appearance model is adaptively updated by achieving an appropriate trade-off between current and historical models according to their reliability. Experimental results show that our method outperforms other state-of-the-art trackers in terms of accuracy and efficiency. In particular, compared with the baseline tracker, our method achieves gains of 7.4\% and 9.9\% in terms of the area under the curve (AUC) on the OTB-100 and LaSOT datasets, respectively.},
  archive      = {J_ISCI},
  author       = {Wuwei Wang and Ke Zhang and Meibo Lv and Jingyu Wang},
  doi          = {10.1016/j.ins.2021.07.030},
  journal      = {Information Sciences},
  pages        = {147-165},
  shortjournal = {Inf. Sci.},
  title        = {Discriminative visual tracking via spatially smooth and steep correlation filters},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A gradient-based search method for multi-objective
optimization problems. <em>ISCI</em>, <em>578</em>, 129–146. (<a
href="https://doi.org/10.1016/j.ins.2021.07.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A gradient-based search method (GBSM) is developed to solve multi-objective optimization problems. It uses the multi-objective gradient information to construct descent directions, i.e., Pareto descent directions (PDDs), to accelerate the convergence. In addition, a multi-objective evolutionary algorithm based on decomposition is adopted to improve the diversity. The comparisons between GBSM with several selected multi-objective evolutionary algorithms and gradient based algorithms on benchmark functions indicate that the proposed method performs competitively and effectively.},
  archive      = {J_ISCI},
  author       = {Weifeng Gao and Yiming Wang and Lingling Liu and Lingling Huang},
  doi          = {10.1016/j.ins.2021.07.051},
  journal      = {Information Sciences},
  pages        = {129-146},
  shortjournal = {Inf. Sci.},
  title        = {A gradient-based search method for multi-objective optimization problems},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study of interrelationships between rough set model
accuracy and granule cover refinement processes. <em>ISCI</em>,
<em>578</em>, 116–128. (<a
href="https://doi.org/10.1016/j.ins.2021.07.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set model accuracy varies when granules change. Refinement is one way to characterize granule evolutions, but it has not been formally defined in rough set theory so far. Topologically, a granule cover W is called a refinement of another granule cover F if there exists some F W ∈ F such that W ⊆ F W for each W ∈ W . In this article, we show that the concept refinement in topology is too abstract to describe the variability of the rough set model along with the change in granules. By abstracting from some important granule refinements, such as reductions and minimal descriptions, we propose two novel granule cover refinements named base-type refinements and base-preserving refinements, which combine both point-set topology and rough set theory. We analyze the accuracy relationships of some typical approximation operators between granule covers and their base-type or base-preserving refinements. We also show that higher accuracy implies finer granule covers for some approximation operators. These are promising results for rough set model accuracy comparisons. Furthermore, the results hint at how to avoid exponentially increased computation complexity on rough set model accuracy comparisons by checking refinement relationships of granule covers directly instead of computing on them using approximation operators.},
  archive      = {J_ISCI},
  author       = {Zuoming Yu and Dongqiang Wang and Pei Wang},
  doi          = {10.1016/j.ins.2021.07.049},
  journal      = {Information Sciences},
  pages        = {116-128},
  shortjournal = {Inf. Sci.},
  title        = {A study of interrelationships between rough set model accuracy and granule cover refinement processes},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph embedding via multi-scale graph representations.
<em>ISCI</em>, <em>578</em>, 102–115. (<a
href="https://doi.org/10.1016/j.ins.2021.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph embedding provides an effective way to encode graph nodes as continuous vector representations in a low-dimensional space. The high-order proximities based graph embedding methods can preserve global structures, but the high-order proximities based objectives typically imply non-convex optimization and high computational complexity . In contrast, the low-order proximities based graph embedding methods evade the definition and optimization of complex high-order proximities based objectives, but cannot capture global structures. Furthermore, numerous graph embedding methods that only consider the proximity relationships among nodes ignore to capture global structure from the perspective of subgraphs. Motivated by this, we propose a novel graph embedding framework via multi-scale graph representations , named MSGE. MSGE first determines multiple subgraphs of different scales based on random walk. At each scale, MSGE generates a new graph by creating edges among the subgraphs which are treated as supernodes . Thus, the generated multi-scale graphs can approximate rich global structure of the original graph. MSGE then employs any existing graph embedding method as a black box to learn subgraph (i.e., supernode) embeddings on each generated graph. Subsequently, a first-order proximity based embedding fusion method is devised to yield node embeddings of the original graph via the learned multi-scale subgraph embeddings. Finally, we apply MSGE on four classical graph embedding methods and extensive experimental results demonstrate that our framework can generate embeddings of better quality and significantly outperform the original graph embedding methods on visualization, node classification and community detection tasks.},
  archive      = {J_ISCI},
  author       = {Yu Xie and Cheng Chen and Maoguo Gong and Deyu Li and A.K. Qin},
  doi          = {10.1016/j.ins.2021.07.026},
  journal      = {Information Sciences},
  pages        = {102-115},
  shortjournal = {Inf. Sci.},
  title        = {Graph embedding via multi-scale graph representations},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph regularized residual subspace clustering network for
hyperspectral image clustering. <em>ISCI</em>, <em>578</em>, 85–101. (<a
href="https://doi.org/10.1016/j.ins.2021.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral image (HSI) clustering is a challenging task due to the high complexity of HSI data. Subspace clustering methods have achieved promising clustering performance in HSI clustering. However, the existing subspace clustering methods calculate linear affinity rather than nonlinear relationships between data points and often ignore high-level feature extraction, resulting in low clustering accuracy. To address these issues, this paper proposes a Graph Regularized Residual Subspace Clustering Network (GR-RSCNet) that jointly learns deep spectral-spatial representation and robust nonlinear affinity via a deep neural network. Technically, we recast a graph regularized subspace clustering model as a special self-expressive (SE) layer that is integrated into a deep residual convolutional autoencoder. Benefitting from the residual structure, GR-RSCNet can be easily trained from scratch by optimizing a joint loss function consisting of reconstruction error, global manifold regularization term, and self-representation loss. We extensively evaluate the proposed GR-RSCNet for four popular HSI datasets, demonstrating that the GR-RSCNet can achieve state-of-the-art clustering results that significantly outperform many prior arts.},
  archive      = {J_ISCI},
  author       = {Yaoming Cai and Meng Zeng and Zhihua Cai and Xiaobo Liu and Zijia Zhang},
  doi          = {10.1016/j.ins.2021.07.003},
  journal      = {Information Sciences},
  pages        = {85-101},
  shortjournal = {Inf. Sci.},
  title        = {Graph regularized residual subspace clustering network for hyperspectral image clustering},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust stability analysis of an energy-efficient control in
a networked control system with application to unmanned ground vehicles.
<em>ISCI</em>, <em>578</em>, 64–84. (<a
href="https://doi.org/10.1016/j.ins.2021.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the robust stability and disturbance rejection performance analysis of an energy-efficient control is addressed in the framework of Networked Control System (NCS). The control scheme under study integrates periodic event-triggered control, packet-based control, time-varying Kalman filter, dual-rate control and prediction techniques, whose design is aimed at reducing energy consumption and bandwidth usage. The robust stability against time-varying model uncertainties is analyzed by means of a sufficient condition based on Linear Matrix Inequalities (LMI). Finally, the effectiveness of the proposed approach is experimentally validated in a tracking control for an Unmanned Ground Vehicle (UGV), which is a battery-constrained mobile device with limited computation capacities.},
  archive      = {J_ISCI},
  author       = {Antonio González and Ángel Cuenca and Julián Salt and Jelle Jacobs},
  doi          = {10.1016/j.ins.2021.07.016},
  journal      = {Information Sciences},
  pages        = {64-84},
  shortjournal = {Inf. Sci.},
  title        = {Robust stability analysis of an energy-efficient control in a networked control system with application to unmanned ground vehicles},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On a clustering-based mining approach with labeled semantics
for significant place discovery. <em>ISCI</em>, <em>578</em>, 37–63. (<a
href="https://doi.org/10.1016/j.ins.2021.07.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid increase in GPS data collection through pervasive use of mobile devices , it has become an important problem to discover significant places of moving objects from complex spatial and temporal trajectories. This problem is challenging mainly because such trajectory data suffer from several issues including incompleteness, low quality, high redundancy, and oftentimes trajectory points do not follow Gaussian distribution . We propose a clustering-based method with temporal and spatial semantics, referred to as Stops and Moves of Trajectories using Attribute Selection (SMoTAS), whose technical advantages are multifold. Firstly, it improves data availability by using a self-adaptive algorithm to correct the deviation in traditional speed-based methods. Secondly, it improves place mining accuracy by filtering multi-label clustering results when there is a lack of detailed geographic data. Thirdly, it employs feature selection to exploit the core attributes of clustering and simplify the clustering results with Grubbs criterion. Experimental results on real-life datasets show that SMoTAS not only achieves substantial improvement of accuracy over existing methods in discovering significant places, but also exhibits superior adaptability to different trajectories and application scenarios.},
  archive      = {J_ISCI},
  author       = {Xinzheng Niu and Shimin Wang and Chase Q. Wu and Yuran Li and Peng Wu and Jiahui Zhu},
  doi          = {10.1016/j.ins.2021.07.050},
  journal      = {Information Sciences},
  pages        = {37-63},
  shortjournal = {Inf. Sci.},
  title        = {On a clustering-based mining approach with labeled semantics for significant place discovery},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Choquet integral optimisation with constraints and the
buoyancy property for fuzzy measures. <em>ISCI</em>, <em>578</em>,
22–36. (<a href="https://doi.org/10.1016/j.ins.2021.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work concerns solving optimisation problems where the objective function is expressed as a Choquet integral . This objective generalises a linear objective function (with positive weights) and allows for interaction to be modeled between coalitions of the decision variables. We leverage results from optimising the ordered weighted averaging (OWA) operator and propose efficient solution approaches for the asymmetric objectives both for the simplest case of a single constraint and then for multiple comonotone constraints. To solve problems with a large number of variables, we rely on the so-called antibuoyancy property, previously applied to OWA weights, and which we extend to general fuzzy measures. This characterisation not only facilitates a restriction of the domain on which the solution lies but also allows us to relate the Choquet integral’s behavior in such cases to the Pigou-Dalton progressive transfers principle . We characterise the Choquet integrals consistent with the Pigou-Dalton principle. Theoretical results are supported by numerical experiments, which illustrate significant gains in performance. Our results offer opportunities for scalability to a much higher number of variables.},
  archive      = {J_ISCI},
  author       = {Gleb Beliakov and Simon James},
  doi          = {10.1016/j.ins.2021.07.032},
  journal      = {Information Sciences},
  pages        = {22-36},
  shortjournal = {Inf. Sci.},
  title        = {Choquet integral optimisation with constraints and the buoyancy property for fuzzy measures},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visualizations for decision support in scenario-based
multiobjective optimization. <em>ISCI</em>, <em>578</em>, 1–21. (<a
href="https://doi.org/10.1016/j.ins.2021.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address challenges of decision problems when managers need to optimize several conflicting objectives simultaneously under uncertainty. We propose visualization tools to support the solution of such scenario-based multiobjective optimization problems. Suitable graphical visualizations are necessary to support managers in understanding, evaluating, and comparing the performances of management decisions according to all objectives in all plausible scenarios. To date, no appropriate visualization has been suggested. This paper fills this gap by proposing two visualization methods: a novel extension of empirical attainment functions for scenarios and an adapted version of heatmaps. They help a decision-maker in gaining insight into realizations of trade-offs and comparisons between objective functions in different scenarios. Some fundamental questions that a decision-maker may wish to answer with the help of visualizations are also identified. Several examples are utilized to illustrate how the proposed visualizations support a decision-maker in evaluating and comparing solutions to be able to make a robust decision by answering the questions. Finally, we validate the usefulness of the proposed visualizations in a real-world problem with a real decision-maker. We conclude with guidelines regarding which of the proposed visualizations are best suited for different problem classes.},
  archive      = {J_ISCI},
  author       = {Babooshka Shavazipour and Manuel López-Ibáñez and Kaisa Miettinen},
  doi          = {10.1016/j.ins.2021.07.025},
  journal      = {Information Sciences},
  pages        = {1-21},
  shortjournal = {Inf. Sci.},
  title        = {Visualizations for decision support in scenario-based multiobjective optimization},
  volume       = {578},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on hybrid data and knowledge driven decision
making under uncertainty (hybrid DK for DM). <em>ISCI</em>,
<em>577</em>, 899–901. (<a
href="https://doi.org/10.1016/j.ins.2021.07.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Jun Liu and Tianrui Li and Javier Montero},
  doi          = {10.1016/j.ins.2021.07.092},
  journal      = {Information Sciences},
  pages        = {899-901},
  shortjournal = {Inf. Sci.},
  title        = {Special issue on hybrid data and knowledge driven decision making under uncertainty (Hybrid DK for DM)},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A goal-reference-point decision-making method based on
normal cloud model and its application in distribution network planning
evaluation. <em>ISCI</em>, <em>577</em>, 883–898. (<a
href="https://doi.org/10.1016/j.ins.2021.08.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific experiments show that specific and difficult goals can lead to higher performance than do vague and simple goals. Therefore, we study a goal-reference-point decision-making method that considers multiple expert-reference-points and the difficulty grade in a single-stage decision-making problem. First, based on the prior information set, an optimization model is built to obtain the distance range between the attribute value and the goal-reference-point. Next, based on the principle of minimizing the distance between the attribute value and its difficulty grade, an optimization model is built to divide the difficulty grades into several distance ranges. Moreover, based on the principle of maximum entropy , an optimization model that considers the given difficulty grade is built to obtain the weights of experts. Afterward, the ranking values of alternatives are calculated according to the goal-reference-point and prospect theory. Finally, a real-world case of the distribution network planning evaluation and a method comparison illustrate the feasibility and validity of the proposed method.},
  archive      = {J_ISCI},
  author       = {Wen Song and Jianjun Zhu},
  doi          = {10.1016/j.ins.2021.08.064},
  journal      = {Information Sciences},
  pages        = {883-898},
  shortjournal = {Inf. Sci.},
  title        = {A goal-reference-point decision-making method based on normal cloud model and its application in distribution network planning evaluation},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interval nonlinear initial-valued problem using constraint
intervals: Theory and an application to the sars-cov-2 outbreak.
<em>ISCI</em>, <em>577</em>, 871–882. (<a
href="https://doi.org/10.1016/j.ins.2021.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article discusses the theory of constraint interval solutions to interval nonlinear initial value problems and applies the notion of constraint interval solutions to analyze the asymptotic behavior of a susceptible-infected-recovered (SIR) epidemiological nonlinear differential equation model, specifically the covid pandemic, in the presence of interval uncertainty to illustrate the efficacy of this approach. Furthermore, constraint interval solutions are used to estimate the intervals for the parameters by fitting solutions to the Brazilian’s Sars-Cov-2 pandemic official data. Simulations and graphical solutions incorporating constraint interval uncertainties are presented to help in the visualization of the pandemic’s behavior.},
  archive      = {J_ISCI},
  author       = {M.S. Cecconello and M.T. Mizukoshi and W. Lodwick},
  doi          = {10.1016/j.ins.2021.08.045},
  journal      = {Information Sciences},
  pages        = {871-882},
  shortjournal = {Inf. Sci.},
  title        = {Interval nonlinear initial-valued problem using constraint intervals: Theory and an application to the sars-cov-2 outbreak},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting dynamic spatio-temporal correlations for citywide
traffic flow prediction using attention based neural networks.
<em>ISCI</em>, <em>577</em>, 852–870. (<a
href="https://doi.org/10.1016/j.ins.2021.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For intelligent transportation systems (ITS), predicting urban traffic crowd flows is of great importance. However, it is challenging to represent various complex spatial relationships across distinct regions, as well as dynamic temporal relations among various time periods. To overcome this challenge, we propose DHSTNet, a novel deep Spatio-temporal neural network for predicting traffic crowd flows. Our proposed approach consists of four components: (i) the closeness component considers spontaneous changes of the traffic crowd flows; (ii) the period influence component frequently characterizes variations of daily flows; (iii) the weekly influence component characterizes the weekly arrangements of crowd flows; and (iv) the external branch component identifies various external influences. Our model applies diverse weights to individual branches. Then, it fuses the outcomes of the four features. Extensive experiments on two real-world datasets demonstrate the advantage of the proposed model over the compared baseline methods. Moreover, to verify the generalization of the proposed model, we apply the proposed attention-based mechanism with a previously proposed model, resulting in a hybrid approach known as Att-DHSTNet, to forecast short-term crowd flows. Experimental results also confirm improved performance.},
  archive      = {J_ISCI},
  author       = {Ahmad Ali and Yanmin Zhu and Muhammad Zakarya},
  doi          = {10.1016/j.ins.2021.08.042},
  journal      = {Information Sciences},
  pages        = {852-870},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting dynamic spatio-temporal correlations for citywide traffic flow prediction using attention based neural networks},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic selection of clustering algorithms using
supervised graph embedding. <em>ISCI</em>, <em>577</em>, 824–851. (<a
href="https://doi.org/10.1016/j.ins.2021.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widespread adoption of machine learning (ML) techniques and the extensive expertise required to apply them have led to increased interest in automated ML solutions that reduce the need for human intervention. One of the main challenges in applying ML to previously unseen problems is algorithm selection – the identification of high-performing algorithm(s) for a given dataset, task, and evaluation measure. This study addresses the algorithm selection challenge for data clustering , a fundamental task in data mining that is aimed at grouping similar objects. We present MARCO-GE, a novel meta-learning approach for the automated recommendation of clustering algorithms. MARCO-GE first transforms datasets into graphs and then utilizes a graph convolutional neural network technique to extract their latent representation. Using the embedding representations obtained, MARCO-GE trains a ranking meta-model capable of accurately recommending top-performing algorithms for a new dataset and clustering evaluation measure. An extensive evaluation on 210 datasets, 17 clustering algorithms, and 10 clustering measures demonstrates the effectiveness of our approach and its superiority in terms of predictive and generalization performance over state-of-the-art clustering meta-learning approaches.},
  archive      = {J_ISCI},
  author       = {Noy Cohen-Shapira and Lior Rokach},
  doi          = {10.1016/j.ins.2021.08.028},
  journal      = {Information Sciences},
  pages        = {824-851},
  shortjournal = {Inf. Sci.},
  title        = {Automatic selection of clustering algorithms using supervised graph embedding},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level and relevance-based parallel clustering of
massive data streams in smart manufacturing. <em>ISCI</em>,
<em>577</em>, 805–823. (<a
href="https://doi.org/10.1016/j.ins.2021.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Parallel implementations of incremental clustering have been provided to increase performances of data stream processing in smart factories, to enable real-time anomaly detection, remote diagnosis, condition-based monitoring of Cyber-Physical Systems. Incremental clustering algorithms iteratively extract and update over time clusters of data points (often denoted as micro-clusters) whose maximum number is bounded. However, the capability of controlling costs derived from the exploitation of computational resources on the distributed architecture is challenging to enable a sustainable processing of massive data streams. In this paper, we present a multi-level parallelization approach for clustering massive data streams based on an horizontal scaling platform for Big Data processing. In particular, the following levels are considered: (i) a first parallelization level is based on a multi-dimensional model with exploration facets used to perform a first, coarse-grained partition of data streams, according to a divide-and-conquer strategy; (ii) a second parallelization level is based on a buffering mechanism, that splits the data stream into portions of data points on which processing is performed in parallel; (iii) the third level of parallelization is defined over the set of micro-clusters that are generated and change over time. The approach is conceived for anomaly detection in smart manufacturing, where the concept of data relevance, defined in terms of distance from critical conditions of monitored systems, is used in order to force a stronger parallelization (and therefore higher resource usage) only when necessary, that is, when approaching to critical conditions. The scalability and efficiency of the approach are evaluated using a real dataset in a smart factory scenario. In particular, experiments demonstrated that when the maximum number of allowed micro-clusters decreases and the buffer size increases, parallelization based on buffering does not ensure good scalability. Additionally, as the number of features (that is, the complexity of data stream) increases, the parallelization based on buffering may present scalability issues. This paves the way to the advantages of tuning different parallelization levels according to the approach proposed in this paper.},
  archive      = {J_ISCI},
  author       = {Ada Bagozi and Devis Bianchini and Valeria De Antonellis},
  doi          = {10.1016/j.ins.2021.08.039},
  journal      = {Information Sciences},
  pages        = {805-823},
  shortjournal = {Inf. Sci.},
  title        = {Multi-level and relevance-based parallel clustering of massive data streams in smart manufacturing},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Density peak clustering using global and local consistency
adjustable manifold distance. <em>ISCI</em>, <em>577</em>, 769–804. (<a
href="https://doi.org/10.1016/j.ins.2021.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel density-based clustering algorithm , called Density Peak Clustering (DPC), has recently received great attention due to its efficiency in clustering performance and simplicity in implementation. However, empirical studies have demonstrated that the commonly used distance measures in DPC cannot simultaneously consider global and local consistency, which can cause the estimated local densities based on it incapable of capturing the ground-truth data structure and thus produce poor clustering results , especially when the clusters existing in datasets exhibit multi-density manifold structures characteristics with different sizes. In order to address those limitations, we propose a novel density peak clustering algorithm using global and local consistency adjustable manifold distance in this paper. In the proposed algorithm, a novel manifold distance with exponential term and scaling factor is introduced to estimate local densities of all data points. By modifying its exponential term and scaling factor, we can flexibly adjust the ratio of the distance between the data within the same manifold to the distance between the data across different manifolds. This flexible adjustment is beneficial to the estimated local densities more accurately reflecting the global and local consistency of data structures. In addition, to effectively deal with clusters with different densities and sizes, a compensation strategy for distance from nearest point with larger density, called local-scale tuning distance, is developed for our proposed approach. By the developed local-scale tuning distance, underlying cluster centers of clusters with different densities and sizes, especially the clusters with low densities or small sizes can remarkably stand out from the decision graph so that the proposed method can accurately identify the number of underlying clusters in the decision graph and thus obtain satisfactory clustering results . In the experimental part, the effect of the scaling factor on the performance of the proposed technique is discussed and some suggestions about the determination of the parameters are given. Theoretical analysis and experimental results on several synthetic datasets and read-world datasets demonstrate that the proposed approach is superior to other existing clustering techniques in terms of three evaluation metrics with statistical significance.},
  archive      = {J_ISCI},
  author       = {Xinmin Tao and Wenjie Guo and Chao Ren and Qing Li and Qing He and Rui Liu and Junrong Zou},
  doi          = {10.1016/j.ins.2021.08.036},
  journal      = {Information Sciences},
  pages        = {769-804},
  shortjournal = {Inf. Sci.},
  title        = {Density peak clustering using global and local consistency adjustable manifold distance},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Multiattribute decision making using novel score function
of interval-valued intuitionistic fuzzy values and the means and the
variances of score matrices. <em>ISCI</em>, <em>577</em>, 748–768. (<a
href="https://doi.org/10.1016/j.ins.2021.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new multiattribute decision making (MADM) method based on the proposed score function of interval-valued intuitionistic fuzzy values (IVIFVs) and the means and the variances of score matrices , where the proposed score function can conquer the shortcomings of the existing score functions. Firstly, it computes the score value of each IVIFV in the decision matrix based on the proposed score function to construct the score matrix. Then, it calculates the mean and the variance of the obtained score matrix. Then, it builds the standard score matrix based on the obtained score matrix. Then, it converts the interval-valued intuitionistic fuzzy (IVIF) weight of each attribute into a crisp weight based on the proposed score function. Finally, based on the obtained standard score matrix and the obtained converted IVIF weights, it calculates the weighted score of each alternative to rank the alternatives. The larger the weighted score of an alternative, the better the preference order (PO) of the alternative. The proposed MADM method can conquer the shortcomings of the existing MADM methods. It offers us a very useful way for MADM in IVIF environments.},
  archive      = {J_ISCI},
  author       = {Shyi-Ming Chen and Cheng-An Tsai},
  doi          = {10.1016/j.ins.2021.07.055},
  journal      = {Information Sciences},
  pages        = {748-768},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making using novel score function of interval-valued intuitionistic fuzzy values and the means and the variances of score matrices},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework for group decision making with multiplicative
trapezoidal fuzzy preference relations. <em>ISCI</em>, <em>577</em>,
722–747. (<a href="https://doi.org/10.1016/j.ins.2021.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trapezoidal fuzzy numbers are efficient to represent the quantitative vagueness and ambiguity of decision makers (DMs). Preference relations are powerful to express pairwise judgments of DMs with respect to alternatives. Combining their advantages, this paper focuses on group decision making (GDM) with multiplicative trapezoidal fuzzy preference relations (MTrFPRs) and proposes a new consistency-consensus based GDM method . To achieve this goal, a new consistency concept for MTrFPRs is proposed by analyzing the drawbacks of the previous ones. By utilizing this concept, optimal models for judging the consistency of MTrFPRs are built. Meanwhile, a consistency index is proposed to measure the consistency level of any given MTrFPR. After that, an algorithm for ranking alternatives from acceptable consistent MTrFPRs is proposed. For GDM, a central-derivation model for determining the fuzzy measure on a set of DMs is proposed. Furthermore, an optimal model for reaching the consensus threshold is constructed. Finally, a GDM method with MTrFPRs is proposed and an application example is utilized to show the efficiency of the proposed GDM method and to compare with the existing GDM methods. The proposed GDM method outperforms the existing GDM methods. It provides us with a very useful way for GDM based on MTrFPRs.},
  archive      = {J_ISCI},
  author       = {Fanyong Meng and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2021.07.045},
  journal      = {Information Sciences},
  pages        = {722-747},
  shortjournal = {Inf. Sci.},
  title        = {A framework for group decision making with multiplicative trapezoidal fuzzy preference relations},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A mixed data clustering algorithm with noise-filtered
distribution centroid and iterative weight adjustment strategy.
<em>ISCI</em>, <em>577</em>, 697–721. (<a
href="https://doi.org/10.1016/j.ins.2021.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an important technology for data analysis. Cluster analysis for mixed data remains challenging. This paper proposes a mixed data clustering algorithm with noise-filtered distribution centroid and iterative weight adjustment strategy. The proposed algorithm defines noise-filtered distribution centroid for categorical attributes. We combine both mean and noise-filtered distribution centroid to represent the cluster center with mixed attributes, the noise-filtered distribution centroid records the frequency of occurrences for each possible value of the categorical attributes in a cluster more accurately. Furthermore, because the “noise values” are filtered, the measure to calculate the dissimilarity between data objects and cluster centers could be improved. In addition, the algorithm introduces an iterative weight adjustment strategy with combined intra-cluster and inter-cluster information. The unified weight measurement method is used for refining numeric attributes and categorical attributes. Then attributes with higher intra-cluster homogeneity and inter-clusters heterogeneity are considered as attributes with higher priority. They tend to be assigned with relatively heavier weights during clustering. Experimental results on different datasets from the UCI repository show that the MCFCIW algorithm outperforms the existing partition-based clustering algorithm and clustering algorithm based on data conversion for mixed data on both cluster validity indices and convergence speed.},
  archive      = {J_ISCI},
  author       = {Xiangjun Li and Zijie Wu and Zhibin Zhao and Feng Ding and Daojing He},
  doi          = {10.1016/j.ins.2021.07.039},
  journal      = {Information Sciences},
  pages        = {697-721},
  shortjournal = {Inf. Sci.},
  title        = {A mixed data clustering algorithm with noise-filtered distribution centroid and iterative weight adjustment strategy},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CS-DE: Cooperative strategy based differential evolution
with population diversity enhancement. <em>ISCI</em>, <em>577</em>,
663–696. (<a href="https://doi.org/10.1016/j.ins.2021.07.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential Evolution (DE) is one of the most effective approaches in Evolutionary Computation to tackling complex black-box optimization, however, the overall performance of a DE variant is heavily dependent on its mutation strategy and the associated parameter control schemes. According to the “No free Lunch theorem”, every mutation strategy has its own fatal defect, therefore, DE variant with a single mutation strategy can not tackle all optimization problems . Furthermore, DE variant with ensemble of mutation strategies usually needs more parameter control schemes, which inevitably decreases the practicality of it. Here in this paper, a novel Cooperative Strategy based DE (CS-DE) with population diversity enhancement is proposed, and the CS-DE algorithm has the following contributions: First, a cooperative strategy pool containing two similar mutation strategies is advanced in the algorithm, and the two mutation strategies share the same parameter control. Second, a novel grouping strategy is proposed, then the two mutation strategies can be chosen in an adaptive manner by different individuals in generating trial vectors during the evolution. Third, novel adaptation schemes for the three control parameters F , CR F,CR and PS as well as a stagnation based re-initialization mechanism are also proposed in our CS-DE algorithm. 58 benchmarks from the CEC2013 and CEC2014 test suites are employed in algorithm validation, and experiment results show the competitiveness of the CS-DE algorithm with several state-of-the-art DE variants.},
  archive      = {J_ISCI},
  author       = {Zhenyu Meng and Yuxin Zhong and Cheng Yang},
  doi          = {10.1016/j.ins.2021.07.080},
  journal      = {Information Sciences},
  pages        = {663-696},
  shortjournal = {Inf. Sci.},
  title        = {CS-DE: Cooperative strategy based differential evolution with population diversity enhancement},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accurate and efficient image segmentation and bias
correction model based on entropy function and level sets.
<em>ISCI</em>, <em>577</em>, 638–662. (<a
href="https://doi.org/10.1016/j.ins.2021.07.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of society, image segmentation plays a pivotal role in real-world life. However, the images we obtain are often distorted or contaminated by noise and shade, causing low construct and weak boundaries. In this paper, we propose a new model suitable for segmenting and correcting images with inhomogeneous intensity simultaneously. According to the characteristics of the entropy function, we use it as the coefficient of the global and local terms of the energy functional, related to the intensity of the image. Most importantly, the compression function is added to control the global item and the local item in the same range, reducing parameters to be tuned. In addition, our model can be extended to the multi-objective model and the colour model to deal with a more difficult situation. Furthermore, by utilizing the split Bregman method to solve the energy functional, we reduce computational cost and maintain the convergence of the algorithm. A large number of experimental results demonstrate the superiority of our model over previous models. Our model has promising performance for the segmentation and correction of inhomogeneous medical images and colour images.},
  archive      = {J_ISCI},
  author       = {Yunyun Yang and Xiaoyan Hou and Huilin Ren},
  doi          = {10.1016/j.ins.2021.07.069},
  journal      = {Information Sciences},
  pages        = {638-662},
  shortjournal = {Inf. Sci.},
  title        = {Accurate and efficient image segmentation and bias correction model based on entropy function and level sets},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resilient leader tracking for networked lagrangian systems
under DoS attacks. <em>ISCI</em>, <em>577</em>, 622–637. (<a
href="https://doi.org/10.1016/j.ins.2021.07.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the leader tracking problem of a directed networked Lagrangian systems under denial-of-service (DoS) attacks on communication links. To this end, a new adaptive distributed resilient control scheme is proposed to resist the influence of the DoS attacks. Under the proposed control framework, the local controllers are allowed to update their control signals aperiodically and asynchronously. The resulting system is analyzed based on an improved multidimensional small gain approach. Under the derived sufficient conditions, which significantly relax the existing convergence conditions that depend on the duration and frequency of DoS attacks for linear systems, the proposed control scheme can almost ensure the resilient leader tracking under arbitrary DoS attacks with bounded durations and frequencies.},
  archive      = {J_ISCI},
  author       = {Xiaolei Li and Changyun Wen and Jiange Wang and Ci Chen and Chao Deng},
  doi          = {10.1016/j.ins.2021.07.057},
  journal      = {Information Sciences},
  pages        = {622-637},
  shortjournal = {Inf. Sci.},
  title        = {Resilient leader tracking for networked lagrangian systems under DoS attacks},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-dimensional rotation-symmetric number-conserving
cellular automata. <em>ISCI</em>, <em>577</em>, 599–621. (<a
href="https://doi.org/10.1016/j.ins.2021.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel method to study two-dimensional rotation-symmetric number-conserving multi-state cellular automata with the von Neumann neighborhood with radius one. This method enables a succinct and easy enumeration in all cases examined so far in literature, i.e. , cellular automata with at most five states. Moreover, it allows to find all such cellular automata with six and seven states, while so far, even enumerating six-state rules was beyond the reach of computing machines. Such enumeration allows us to revisit some unresolved questions in the field. Furthermore, we give some rough estimates of the asymptotic growth of the number of such cellular automata with n states, as n tends to infinity. The results are obtained for finite square grids with periodic boundary conditions , but they are also valid in the case of the infinite square grid.},
  archive      = {J_ISCI},
  author       = {Adam Dzedzej and Barbara Wolnik and Anna Nenca and Jan M. Baetens and Bernard De Baets},
  doi          = {10.1016/j.ins.2021.06.041},
  journal      = {Information Sciences},
  pages        = {599-621},
  shortjournal = {Inf. Sci.},
  title        = {Two-dimensional rotation-symmetric number-conserving cellular automata},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient and decision boundary aware instance selection for
support vector machines. <em>ISCI</em>, <em>577</em>, 579–598. (<a
href="https://doi.org/10.1016/j.ins.2021.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support vector machines (SVMs) are powerful classifiers that have high computational complexity in the training phase, which can limit their applicability to large datasets. An effective approach to address this limitation is to select a small subset of the most representative training samples such that desirable results can be obtained. In this study, a novel instance selection method called border point extraction based on locality-sensitive hashing ( BPLSH ) is designed. BPLSH preserves instances that are near the decision boundaries and eliminates nonessential ones. The performance of BPLSH is benchmarked against four approaches on different classification problems. The experimental results indicate that BPLSH outperforms the other methods in terms of classification accuracy, preservation rate, and execution time. The source code of BPLSH can be found in https://github.com/mohaslani/BPLSH .},
  archive      = {J_ISCI},
  author       = {Mohammad Aslani and Stefan Seipel},
  doi          = {10.1016/j.ins.2021.07.015},
  journal      = {Information Sciences},
  pages        = {579-598},
  shortjournal = {Inf. Sci.},
  title        = {Efficient and decision boundary aware instance selection for support vector machines},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparsity of weighted networks: Measures and applications.
<em>ISCI</em>, <em>577</em>, 557–578. (<a
href="https://doi.org/10.1016/j.ins.2021.06.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A majority of real life networks are weighted and sparse. The present article aims at characterization of weighted networks based on sparsity , as an indicator of inherent diversity of different network parameters. The measure called s parsity index defined on ordered degree sequence of simple networks is extended and new properties of this index are derived. The range of possible values of sparsity index of any connected network, with edge-count in specific intervals, is worked out analytically in terms of node-count and a pattern is uncovered in corresponding degree sequences. Given the edge-weight frequency distribution of a network, an expression of the sparsity index of edge-weights is formulated. Its properties are analyzed under different distributions of edge-weights. For example, the upper and lower bounds of sparsity index of edge-weights of a network, with all distinct edge-weights, is determined in terms of its node-count and edge-density. The article highlights that this summary index with low computational cost, computed on different network parameters, is useful to reveal different structural and organizational aspects of networks for performing analysis. An application of this index is demonstrated through devising a new overlapping community detection method. The results validated on artificial and real-world networks show its efficacy.},
  archive      = {J_ISCI},
  author       = {Swati Goswami and Asit K. Das and Subhas C. Nandy},
  doi          = {10.1016/j.ins.2021.06.090},
  journal      = {Information Sciences},
  pages        = {557-578},
  shortjournal = {Inf. Sci.},
  title        = {Sparsity of weighted networks: Measures and applications},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered resilient control for cyber-physical systems
under periodic DoS jamming attacks. <em>ISCI</em>, <em>577</em>,
541–556. (<a href="https://doi.org/10.1016/j.ins.2021.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the event-triggered resilient control problem for cyber-physical systems against periodic denial-of-service (DoS) attacks. Firstly, a novel event-triggered scheme without Zeno behaviors is presented to save network resources and eliminate the occurrence of invalid events during periodic DoS attacks. Subsequently, by constructing a predictor-based event-triggered control framework, the upper bound of the prediction error related to periodic DoS attack parameters is given. Furthermore, sufficient conditions related to periodic DoS attack parameters are established to ensure the input-to-state stability. It is shown that the proposed design method can achieve better system performances than the existing ones when the system suffers the same degree of periodic DoS attacks. Finally, the theoretical research results are validated through a batch reactor system model.},
  archive      = {J_ISCI},
  author       = {Peng-Biao Wang and Xue-Mei Ren and Dong-Dong Zheng},
  doi          = {10.1016/j.ins.2021.07.002},
  journal      = {Information Sciences},
  pages        = {541-556},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered resilient control for cyber-physical systems under periodic DoS jamming attacks},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handling multimodal multi-objective problems through
self-organizing quantum-inspired particle swarm optimization.
<em>ISCI</em>, <em>577</em>, 510–540. (<a
href="https://doi.org/10.1016/j.ins.2021.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal multi-objective optimization problems (MMOPs) involve locating equivalent Pareto optimal solutions in decision space with the same objective values. The key to handling MMOPs is finding all equivalent Pareto optimal solutions and maintaining a promising balance between the convergence and diversity of solutions in both decision space and objective space. To tackle this issue, a self-organizing quantum-inspired particle swarm optimization algorithm (MMO_SO_QPSO) is proposed in this paper for handling MMOPs. In the proposed MMO_SO_QPSO, a self-organizing map is used to find the best neighbor leader of particles. With the aid of neighbor leader particles, a special zone searching method is adopted to update the position of particles and locate equivalent Pareto optimal solutions in decision space. To maintain diversity and convergence of Pareto optimal solutions, a special archive mechanism that relies on the maximum-minimum distance among solutions is introduced into MMO_SO_QPSO. And some outstanding Pareto optimal solutions are maintained in the special archive. In addition, a new performance indicator is developed to estimate properly the similarity between obtained Pareto optimal solutions and true Pareto optimal solutions. The performance of the proposed MMO_SO_QPSO is compared with six state-of-the-art multimodal multi-objective evolutionary algorithms on two well-known benchmark problems. Experimental results demonstrate the superior performance of MMO_SO_QPSO for solving MMOPs. The effectiveness of several strategies is also discussed.},
  archive      = {J_ISCI},
  author       = {Guoqing Li and Wanliang Wang and Weiwei Zhang and Wenbo You and Fei Wu and Hangyao Tu},
  doi          = {10.1016/j.ins.2021.07.011},
  journal      = {Information Sciences},
  pages        = {510-540},
  shortjournal = {Inf. Sci.},
  title        = {Handling multimodal multi-objective problems through self-organizing quantum-inspired particle swarm optimization},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-based structural difference analysis for video
summarization. <em>ISCI</em>, <em>577</em>, 483–509. (<a
href="https://doi.org/10.1016/j.ins.2021.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Keyframe extraction is an effective way to achieve video summarization. More recent studies using deep learning networks are heavily dependent on massive historical datasets for training. For practicality in real applications, we focus more on unsupervised online analysis and present a novel graph-based structural difference analysis method for this purpose. Unlike traditional methods of video representation based on raw features, undirected weighted graphs are constructed from the resulting features to represent video frames. The detailed structural changes between graphs are more consistent with the actual changes between video frames than raw features, thus making the newly proposed method robust for detecting various types of shot transitions, such as hard cuts, dissolves, wipes, and fade-ins/fade-outs. Then, considering the local influence between successive frames, a structural difference analysis of graphs is performed to detect the video shot boundaries. Finally, the median graph of each shot is obtained to extract the corresponding keyframe. Extensive experiments are conducted on three video summarization benchmark datasets. Quantitative and qualitative comparisons are made between the proposed method and other state-of-the-art methods, with the proposed method yielding remarkable improvements from 1.9\% to 3.1\% in terms of the F-score on the three datasets.},
  archive      = {J_ISCI},
  author       = {Chunlei Chai and Guoliang Lu and Ruyun Wang and Chen Lyu and Lei Lyu and Peng Zhang and Hong Liu},
  doi          = {10.1016/j.ins.2021.07.012},
  journal      = {Information Sciences},
  pages        = {483-509},
  shortjournal = {Inf. Sci.},
  title        = {Graph-based structural difference analysis for video summarization},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust visual object tracking using context-based spatial
variation via multi-feature fusion. <em>ISCI</em>, <em>577</em>,
467–482. (<a href="https://doi.org/10.1016/j.ins.2021.06.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of camera technology, visual tracking has witnessed great attention in the field of computer vision . For instance, numerous discriminative correlation filter (DCF) methods are broadly used in tracking, nevertheless, most of them fail to efficiently find the target in challenging situations which leads to tracking failure throughout the sequences. In order to handle these issues, we propose contextual information based spatial variation with a multi-feature fusion method (CSVMF) for robust object tracking . This work incorporates the contextual information of the target to determine the location of the target accurately, which utilizes the relationship between the target and its surroundings to increase the efficiency of the tracker. In addition, we integrate the spatial variation information which measures the second-order difference of the filter to avoid the over-fitting problem caused by the changes in filter coefficient . Furthermore, we adopt multi-feature fusion strategy to enhance the target appearance by using different metrics. The tracking results from different features are fused by employing peak-to-sidelobe ratio (PSR) which measures the peak strength of the response. Finally, we conduct extensive experiments on TC128, DTB70, UAV123@10fps, and UAV123 datasets to demonstrate that the proposed method achieves a favorable performance over the existing ones.},
  archive      = {J_ISCI},
  author       = {Dinesh Elayaperumal and Young Hoon Joo},
  doi          = {10.1016/j.ins.2021.06.084},
  journal      = {Information Sciences},
  pages        = {467-482},
  shortjournal = {Inf. Sci.},
  title        = {Robust visual object tracking using context-based spatial variation via multi-feature fusion},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). Distributed cooperative optimization for multiple
heterogeneous euler-lagrangian systems under global equality and
inequality constraints. <em>ISCI</em>, <em>577</em>, 449–466. (<a
href="https://doi.org/10.1016/j.ins.2021.06.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the distributed cooperative optimization problem with globally equality and inequality constraints for a multi-agent system, where each agent is modeled by Euler-Lagrangian (EL) dynamics. The optimized function can be represented by the sum of all local cost functions corresponding to each individual agent. Two continuous-time algorithms are proposed to solve such the problem in a distributed manner. In virtue of geometric graph theory, convex analysis , and Lyapunov stability theory , it is proved that all agents achieve consensus on the Lagrangian multipliers associated with constraints while the proposed algorithms converge exponentially to the optimal solution of the problem given in the case that the parameters of EL agents are known, and converge asymptotically to the optimal solution of the problem in the case that the parameters of EL agents are unknown, respectively. Finally, an example is provided to demonstrate the effectiveness of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Zhu Wang and Jiaxun Liu and Dong Wang and Wei Wang},
  doi          = {10.1016/j.ins.2021.06.080},
  journal      = {Information Sciences},
  pages        = {449-466},
  shortjournal = {Inf. Sci.},
  title        = {Distributed cooperative optimization for multiple heterogeneous euler-lagrangian systems under global equality and inequality constraints},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Document image layout analysis via explicit edge embedding
network. <em>ISCI</em>, <em>577</em>, 436–448. (<a
href="https://doi.org/10.1016/j.ins.2021.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Layout analysis from a document image plays an important role in document content understanding and information extraction systems. While many existing methods focus on learning knowledge with convolutional networks directly from color channels, we argue the importance of high-frequency structures in document images, especially edge information. In this paper, we present a novel document layout analysis framework with the Explicit Edge Embedding Network ( E 3 Net ). Specifically, the proposed network contains the edge embedding block and dynamic skip connection block to produce detailed features, as well as a lightweight fully convolutional subnet as the backbone for the effectiveness of the framework. The edge embedding block is designed to explicitly incorporate the edge information from the document images. The dynamic skip connection block aims to learn both color and edge representations with learnable weights. In contrast to the previous methods, we harness the model by using a synthetic document approach to overcome data scarcity. The combination of data augmentation and edge embedding is important toward a more compact representation than directly using the training images with only color channels. We conduct experiments using the proposed framework on three document layout analysis benchmarks and demonstrate its superiority in terms of effectiveness and efficiency over previous approaches.},
  archive      = {J_ISCI},
  author       = {Xingjiao Wu and Yingbin Zheng and Tianlong Ma and Hao Ye and Liang He},
  doi          = {10.1016/j.ins.2021.07.020},
  journal      = {Information Sciences},
  pages        = {436-448},
  shortjournal = {Inf. Sci.},
  title        = {Document image layout analysis via explicit edge embedding network},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Random generation of capacities and its application in
comprehensive decision aiding. <em>ISCI</em>, <em>577</em>, 424–435. (<a
href="https://doi.org/10.1016/j.ins.2021.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacities and the Choquet integral are powerful tools to represent decision problems with dependencies and aggregate correlated decision criteria. Random generation of suitable capacities is a vital and challenging task in this decision model because of an exponential number of the involved parameters as well as the associated monotonicity restrictions. In this paper we present various approaches to representing decision makers’ preferences on aggregation through linear constraints , random generation of capacities from the selected polytope , testing the uniformity of the resulting distribution, and constructing the dominance relations between the alternatives, which are subsequently used to get the most credible ranking of the alternatives.},
  archive      = {J_ISCI},
  author       = {Gleb Beliakov and Jian-Zhang Wu},
  doi          = {10.1016/j.ins.2021.07.017},
  journal      = {Information Sciences},
  pages        = {424-435},
  shortjournal = {Inf. Sci.},
  title        = {Random generation of capacities and its application in comprehensive decision aiding},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Geodesic simplex based multiobjective endmember extraction
for nonlinear hyperspectral mixtures. <em>ISCI</em>, <em>577</em>,
398–423. (<a href="https://doi.org/10.1016/j.ins.2021.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel multiobjective endmember extraction approach for nonlinear hyperspectral mixtures by assuming that the distribution of mixtures conforms to a nonlinear manifold and the endmembers correspond to its extreme points. To identify the endmembers, the approach aims to seek a set of pixels which define a simplex with the maximum volume along the manifold. Meanwhile, several obstacles are properly settled to make it a good performance. First, calculating a simplex’s volume along the manifold needs to calculate the geodesic distance (i.e., the shortest path) between its vertices on the k -nearest neighbor ( kNN kNN ) graph of the manifold data, but it is time-consuming to go through all the manifold points to search the desired simplex. Therefore, a boundary detection technique is proposed to restrict the identification of endmembers within the boundary points of the manifold to improve the time efficiency. Second, the volume of the geodesic distance based simplex is sensitive to the deviations in the geodesic distance caused by noise. To settle this issue, the multiple regression based noise estimation method is applied due to the high correlation among hundreds of spectral bands . Therefore, the spectral noise can be removed before the calculation of geodesic distance. Third, the number of endmembers is of crucial importance but hard to determine, so it is usually specified beforehand in most unmixing approaches. The proposed approach can instinctively obtain a set of simplices with the maximum volume corresponding to different numbers of endmembers, thus providing more insight for determining the optimal combination of endmembers. In addition, the proposed method is a population based optimization method which is less likely to get trapped into the local optimum. The experiments on synthetic as well as real data sets demonstrate the validity and superiority of the proposed method as compared with the methods of the same type.},
  archive      = {J_ISCI},
  author       = {Xiangming Jiang and Maoguo Gong and Tao Zhan and Hao Li},
  doi          = {10.1016/j.ins.2021.07.009},
  journal      = {Information Sciences},
  pages        = {398-423},
  shortjournal = {Inf. Sci.},
  title        = {Geodesic simplex based multiobjective endmember extraction for nonlinear hyperspectral mixtures},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intermittent delay stabilization of complex-valued
stochastic complex network. <em>ISCI</em>, <em>577</em>, 379–397. (<a
href="https://doi.org/10.1016/j.ins.2021.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stabilization issue for complex-valued stochastic Markovian switching complex network with time delay and time-varying coupling structure (CSMNDC) is investigated via intermittent delay feedback control . Different from intermittent control based on current state in previous work, a class of intermittent control on the basis of past state is designed for the first time, by combining with the advantages of aperiodically intermittent control and delay feedback control . Then, some sufficient conditions are derived to guarantee the exponential stability in mean square of CSMNDC based on Lyapunov method , graph theory as well as some techniques of inequalities. In particular, the stabilization of networks is studied on complex space directly without splitting their real and imaginary parts by using complex generalized Itô’s formula. Additionally, both delay feedback control and aperiodically intermittent control are employed to solve the stabilization issue for CSMNDC here. Whereafter, the stabilization issue of complex-valued stochastic Markovian switching Cohen-Grossberg neural network with time delay and time-varying coupling structure is researched as a practical application of our theoretical results. Ultimately, a numerical example is presented to verify the validity and effectiveness of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Hui Zhou and Mengfan Luo and Wenxue Li},
  doi          = {10.1016/j.ins.2021.07.004},
  journal      = {Information Sciences},
  pages        = {379-397},
  shortjournal = {Inf. Sci.},
  title        = {Intermittent delay stabilization of complex-valued stochastic complex network},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BARF: A new direct and cross-based binary residual feature
fusion with uncertainty-aware module for medical image classification.
<em>ISCI</em>, <em>577</em>, 353–378. (<a
href="https://doi.org/10.1016/j.ins.2021.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic medical image analysis ( e.g. , medical image classification) is widely used in the early diagnosis of various diseases. The computer-aided diagnosis (CAD) systems enable accurate disease detection and treatment. Nowadays, deep learning (DL)-based CAD systems have been able to achieve promising results in most of the healthcare applications. Also, uncertainty quantification in the existing DL methods have not gained enough attention in the field of medical research. To fill this gap, we propose a novel, simple and effective fusion model with uncertainty-aware module for medical image classification called Binary Residual Feature fusion (BARF). To deal with uncertainty, we applied the Monte Carlo (MC) dropout during inference to obtain the mean and standard deviation of the predictions. The proposed model has two main strategies: direct and cross validated using four different medical image datasets. Our experimental results demonstrate that the proposed model is efficient for medical image classification in real clinical settings.},
  archive      = {J_ISCI},
  author       = {Moloud Abdar and Mohammad Amin Fahami and Satarupa Chakrabarti and Abbas Khosravi and Paweł Pławiak and U. Rajendra Acharya and Ryszard Tadeusiewicz and Saeid Nahavandi},
  doi          = {10.1016/j.ins.2021.07.024},
  journal      = {Information Sciences},
  pages        = {353-378},
  shortjournal = {Inf. Sci.},
  title        = {BARF: A new direct and cross-based binary residual feature fusion with uncertainty-aware module for medical image classification},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantized event-triggered communication based multi-agent
system for distributed resource allocation optimization. <em>ISCI</em>,
<em>577</em>, 336–352. (<a
href="https://doi.org/10.1016/j.ins.2021.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a multi-agent system with quantized event-triggered communication mechanisms to reduce the communication expenditure. The event-triggered communication mechanism is proposed to reduce the utilization of communication bandwidth , which lowers the communication expenditure in communication frequency. The quantized communication mechanism quantizes the communication information in the multi-agent system with limited communication capacity. First, a quantized periodic communication mechanism system is proposed, which provides a lower bound of the communication interval for the quantized event-triggered communication system to avoid the Zeno behavior. Then the system with quantized event-triggered communication is proved to be convergent to an optimal solution of distributed constraint optimization . With the quantized communication mechanism, the system can reduce the communication cost in the frequency of communication and the amount of transmission data. The proposed method has a tradeoff between energy saving and precision. Finally, the simulation results with comparisons verify the convergence of the system and exhibit the accuracy with different quantizer densities.},
  archive      = {J_ISCI},
  author       = {Kaixuan Li and Qingshan Liu and Zhigang Zeng},
  doi          = {10.1016/j.ins.2021.07.022},
  journal      = {Information Sciences},
  pages        = {336-352},
  shortjournal = {Inf. Sci.},
  title        = {Quantized event-triggered communication based multi-agent system for distributed resource allocation optimization},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An interpretable neural fuzzy hammerstein-wiener network for
stock price prediction. <em>ISCI</em>, <em>577</em>, 324–335. (<a
href="https://doi.org/10.1016/j.ins.2021.06.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An interpretable regression model is proposed in this paper for stock price prediction. Conventional offline neuro-fuzzy systems are only able to generate implications based on fuzzy rules induced during training, which requires the training data to be able to adequately represent all system behaviors. However, the distributions of test and training data could be significantly different, e.g., due to drastic data shifts. We address this problem through a novel approach that integrates a neuro-fuzzy system with the Hammerstein-Wiener model forming an indivisible five-layer network, where the implication of the neuro-fuzzy system is realized by the linear dynamic computation of the Hammerstein-Wiener model. The input and output nonlinearities of the Hammerstein-Wiener model are replaced by the nonlinear fuzzification and defuzzification processes of the fuzzy system so that the fuzzy linguistic rules, induced from the linear dynamic computation, can be used to interpret the inference processes. The effectiveness of the proposed model is evaluated on three financial stock datasets. Experimental results showed that the proposed Neural Fuzzy Hammerstein-Wiener ( NFHW ) outperforms other neuro-fuzzy systems and the conventional Hammerstein-Wiener model on these three datasets.},
  archive      = {J_ISCI},
  author       = {Chen Xie and Deepu Rajan and Quek Chai},
  doi          = {10.1016/j.ins.2021.06.076},
  journal      = {Information Sciences},
  pages        = {324-335},
  shortjournal = {Inf. Sci.},
  title        = {An interpretable neural fuzzy hammerstein-wiener network for stock price prediction},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-technique diversity-based particle-swarm optimization.
<em>ISCI</em>, <em>577</em>, 298–323. (<a
href="https://doi.org/10.1016/j.ins.2021.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is a population-based random-search optimization technique that has become an increasingly important branch of swarm intelligence studies. Population diversity is an effective measurement that shows the distribution of particles in a search space. In this paper, we propose a diversity-based PSO algorithm that is combined with multiple techniques, and population diversity is used as a search-strategy selection criterion for particles. When diversity is high, we suggest implementing a search strategy that has a strong exploration ability. When diversity is low, we suggest implementing a search strategy that has a strong exploitation ability. In addition to our diversity-based method, we introduce a gradient-based local-search technique, multi-crossover operation, and disturbance strategy to help improve the performance of the proposed algorithm. In the experiments, we compare the proposed algorithm with 10 advanced PSO variants based on 40 widely used benchmark functions , including the CEC2017 benchmark. The results indicate that the proposed algorithm yields a better solution accuracy and convergence speed than those of other PSO variants.},
  archive      = {J_ISCI},
  author       = {Zhao-Guang Liu and Xiu-Hua Ji and Yang Yang and Hong-Tan Cheng},
  doi          = {10.1016/j.ins.2021.07.006},
  journal      = {Information Sciences},
  pages        = {298-323},
  shortjournal = {Inf. Sci.},
  title        = {Multi-technique diversity-based particle-swarm optimization},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ontology learning from relational databases. <em>ISCI</em>,
<em>577</em>, 280–297. (<a
href="https://doi.org/10.1016/j.ins.2021.06.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An ontology is a formal, explicit specification of a shared conceptualization. Ontologies are used in many fields, such as software engineering , information extraction, semantic search , knowledge management , recommender systems , etcetera. Since manual ontology building is a very costly, time-consuming, and error-prone task, automating the process of ontology building, or in other words, learning ontology from existing resources, is a good option. Nowadays, a large amount of data on the web is stored in relational databases , but databases cannot be used directly in the semantic web. Hence, in this paper, we have proposed a new approach to automatically creating an OWL ontology from a relational database. We have defined a set of rules to analyze all database components and convert them to corresponding ontology components. The core contribution of our work is the set of rules which can analyze and extract ontology elements from stored procedures, user-defined functions, views, multiple inheritance, the specific representation of single inheritance , common attributes, and the constraints on tables and their columns. The proposed approach has been compared with existing approaches using three frameworks.},
  archive      = {J_ISCI},
  author       = {Batool Lakzaei and Mehrnoush Shamsfard},
  doi          = {10.1016/j.ins.2021.06.074},
  journal      = {Information Sciences},
  pages        = {280-297},
  shortjournal = {Inf. Sci.},
  title        = {Ontology learning from relational databases},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fuzzy association rule-based classifier for imbalanced
classification problems. <em>ISCI</em>, <em>577</em>, 265–279. (<a
href="https://doi.org/10.1016/j.ins.2021.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced classification problems are attracting the attention of the research community because they are prevalent in real-world problems and they impose extra difficulties for learning methods. Fuzzy rule-based classification systems have been applied to cope with these problems, mostly together with sampling techniques. In this paper, we define a new fuzzy association rule-based classifier, named FARCI, to tackle directly imbalanced classification problems. Our new proposal belongs to the algorithm modification category, since it is constructed on the basis of the state-of-the-art fuzzy classifier FARC–HD. Specifically, we modify its three learning stages, aiming at boosting the number of fuzzy rules of the minority class as well as simplifying them and, for the sake of handling unequal fuzzy rule lengths, we also change the matching degree computation, which is a key step of the inference process and it is also involved in the learning process. In the experimental study, we analyze the effectiveness of each one of the new components in terms of performance, F - score F-score , and rule base size. Moreover, we also show the superiority of the new method when compared versus FARC–HD alongside sampling techniques, another algorithm modification approach, two cost-sensitive methods and an ensemble.},
  archive      = {J_ISCI},
  author       = {J. Sanz and M. Sesma-Sara and H. Bustince},
  doi          = {10.1016/j.ins.2021.07.019},
  journal      = {Information Sciences},
  pages        = {265-279},
  shortjournal = {Inf. Sci.},
  title        = {A fuzzy association rule-based classifier for imbalanced classification problems},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generalized approach to solve perfect bayesian nash
equilibrium for practical network attack and defense. <em>ISCI</em>,
<em>577</em>, 245–264. (<a
href="https://doi.org/10.1016/j.ins.2021.06.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the incomplete information dynamic network attack and defense game in practice, this paper proposes a generalized approach to solve for perfect Bayesian Nash equilibrium (BNE) for practical network attack and defense. To consider “role-shifting” in the practical network attack and defense environment, the proposed approach substitutes solving the Nash equilibrium (NE) problem with a payoff (reward) maximization problem via a profound combination between the subgame perfect NE of the complete information dynamic game and the BNE of the incomplete information static game. Furthermore, to evaluate the effectiveness of the proposed approach, a representative signaling game with specific values is examined from a theoretical perspective. Finally, a real penetration test case targeting a web server is implemented to substantiate the effectiveness of the proposed approach from a practical perspective with some visual verifications and crucial penetration codes, where the attacker successfully obtains the ROOT authority (the highest authority) of the target web server.},
  archive      = {J_ISCI},
  author       = {Liang Liu and Lei Zhang and Shan Liao and Jiayong Liu and Zhenxue Wang},
  doi          = {10.1016/j.ins.2021.06.078},
  journal      = {Information Sciences},
  pages        = {245-264},
  shortjournal = {Inf. Sci.},
  title        = {A generalized approach to solve perfect bayesian nash equilibrium for practical network attack and defense},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parameter discrepancy hypothesis: Adversarial attack for
graph data. <em>ISCI</em>, <em>577</em>, 234–244. (<a
href="https://doi.org/10.1016/j.ins.2021.06.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks are vulnerable to adversarial attacks . Therefore, this paper generalizes existing graph neural network adversarial attacks as a contradictory data hypothesis. Attack methods based on this hypothesis add perturbations to the training data, making it difficult to fit the training data and hence disturbing training. The contradictory data hypothesis cannot fit such cases well, causing the model to overfit the training set and be unable to generalize to the test set. This paper proposes a parameter discrepancy hypothesis for adversarial attacks against graph data, and shows that model training parameters differ significantly before and after the attack. A new attack model is consequently established using Cook distance. Extensive experiments verified the parameter discrepancy hypothesis rationality, Cook distance effectiveness, and the proposed attack method.},
  archive      = {J_ISCI},
  author       = {Yiteng Wu and Wei Liu and Xinbang Hu and Xuqiao Yu},
  doi          = {10.1016/j.ins.2021.06.086},
  journal      = {Information Sciences},
  pages        = {234-244},
  shortjournal = {Inf. Sci.},
  title        = {Parameter discrepancy hypothesis: Adversarial attack for graph data},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Non-fragile h∞ memory sampled-data state-feedback control
for continuous-time nonlinear markovian jump fuzzy systems with
time-varying delay. <em>ISCI</em>, <em>577</em>, 214–233. (<a
href="https://doi.org/10.1016/j.ins.2021.06.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, non-fragile control is studied for time-varying delay Markovian jump systems described by T-S model on the basis of aperiodic memory sampled-data control. The consideration of both non-fragility and signal input delay in a sampled-data control for fuzzy Markovian jump system (FMJS) has not been well documented. An improved time-delay-dependent Lyapunov–Krasovskii functional (LKF) is proposed, which covers as much the sampling interval and the time-delay information in the system and controller as possible. On this basis, we use the advanced technique of treating integral inequality to estimate the derivative term of Lyapunov–Krasovskii functional. The weighted matrix is introduced in the integral inequality makes our results more flexible, which will be illustrated in the practical examples in the last section. Using the linear matrix inequalities (LMIs) method, a set of sufficient conditions is established to guarantee the system to be stochastically stable and satisfy the performance index. Finally, two examples are given to illustrate the effectiveness and superiority of the results.},
  archive      = {J_ISCI},
  author       = {Jun Zhang and Deyou Liu and Yuechao Ma and Peng Yu},
  doi          = {10.1016/j.ins.2021.06.081},
  journal      = {Information Sciences},
  pages        = {214-233},
  shortjournal = {Inf. Sci.},
  title        = {Non-fragile h∞ memory sampled-data state-feedback control for continuous-time nonlinear markovian jump fuzzy systems with time-varying delay},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QHSL: A quantum hue, saturation, and lightness color model.
<em>ISCI</em>, <em>577</em>, 196–213. (<a
href="https://doi.org/10.1016/j.ins.2021.06.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing with any potential quantum computing hardware requires a quantum color model capable of capturing and manipulating color information in images. In this study, a quantum hue, saturation, and lightness (QHSL) model is proposed as a first attempt to encode perceptually relevant triplet color components using the properties of quantum mechanics (i.e., entanglement and parallelism). The proposed color model was used to define a representation of two-dimensional QHSL images for storage and transformation with fewer computing resources. The configuration of color-assignment attributes within this QHSL representation offer useful applications for image analysis. Specifically, a pseudocolor technique with flexible gray depth divisions is presented for highlighting fine visual details.},
  archive      = {J_ISCI},
  author       = {Fei Yan and Nianqiao Li and Kaoru Hirota},
  doi          = {10.1016/j.ins.2021.06.077},
  journal      = {Information Sciences},
  pages        = {196-213},
  shortjournal = {Inf. Sci.},
  title        = {QHSL: A quantum hue, saturation, and lightness color model},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reduced-order-asynchronous-based control for nonlinear jump
networked systems with attacks. <em>ISCI</em>, <em>577</em>, 180–195.
(<a href="https://doi.org/10.1016/j.ins.2021.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the widespread application of communication networks in industrial control systems , cyber-attacks bring a huge threat to the networked control system . In this paper, the issue of secure control of nonlinear jump networked systems with false data inject (FDI) attacks is investigated. In order to against the malicious attacks , a reduced-order-asynchronous sliding-mode control (SMC) strategy is proposed. Firstly, in order to damp the effect of nonlinear term and FDI attacks, an asynchronous sliding-mode function is designed, and the resultant sliding-mode dynamics is generated by using the reduced-order method. Then, the stability conditions for the reduced-order sliding-mode dynamics are given, and the sliding-mode parameters are solved by linear matrix inequality technology. Furthermore, the sliding-mode controllers are designed under the situation of the parameters is known or unknown, respectively, and the reachability of the sliding-mode motion is certificated. Finally, two examples are implemented to illustrate the potential of the presented control strategy.},
  archive      = {J_ISCI},
  author       = {Meng Li and Yong Chen and Jiangming Ma and Yuezhi Liu},
  doi          = {10.1016/j.ins.2021.07.013},
  journal      = {Information Sciences},
  pages        = {180-195},
  shortjournal = {Inf. Sci.},
  title        = {Reduced-order-asynchronous-based control for nonlinear jump networked systems with attacks},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying influential nodes in complex networks: Effective
distance gravity model. <em>ISCI</em>, <em>577</em>, 162–179. (<a
href="https://doi.org/10.1016/j.ins.2021.01.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of important nodes in complex networks is an area of exciting growth due to its applications across various disciplines like disease control, data mining and network system control. Many measures have been proposed to date, but they are either based on the locality of nodes or the global nature of the network. These measures typically use the traditional Euclidean Distance , which only focuses on local static geographic distance between nodes but ignores the dynamic interaction between nodes in real-world networks. Both the static and dynamic information should be considered for the purpose of identifying influential nodes . In order to address this problem, we have proposed an original and novel gravity model with effective distance for identifying influential nodes based on information fusion and multi-level processing. Our method is able to comprehensively consider the global and local information of complex networks, and also utilizes the effective distance to incorporate static and dynamic information. Moreover, the proposed method can help us mine for hidden topological structure of real-world networks for more accurate results. The susceptible infected model, Kendall correlation coefficient and eight existing identification methods are utilized to carry out simulations on twelve different real networks.},
  archive      = {J_ISCI},
  author       = {Qiuyan Shang and Yong Deng and Kang Hao Cheong},
  doi          = {10.1016/j.ins.2021.01.053},
  journal      = {Information Sciences},
  pages        = {162-179},
  shortjournal = {Inf. Sci.},
  title        = {Identifying influential nodes in complex networks: Effective distance gravity model},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic online convex optimization with long-term
constraints via virtual queue. <em>ISCI</em>, <em>577</em>, 140–161. (<a
href="https://doi.org/10.1016/j.ins.2021.06.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the online convex optimization (OCO) with long-term constraints which is widely used in various resource allocations and recommendation systems. Different from the most existing works, our work adopts a dynamic benchmark to analyze the optimization performance since the dynamic benchmark is more common than the static benchmark in practical applications. Moreover, compared with many constrained OCO works ignoring the Slater condition, we study the effect of the Slater condition on the constraint violation bounds and obtain the better performance of the constraint violations when the Slater condition holds. More importantly, we propose a novel iterative optimization algorithm based on the virtual queues to achieve sublinear regret and constraint violations. Finally, we apply our dynamic OCO model to a resource allocation problem in cloud computing and the results of the experiments validate the effectiveness of our algorithm.},
  archive      = {J_ISCI},
  author       = {Xiaofeng Ding and Lin Chen and Pan Zhou and Zichuan Xu and Shiping Wen and John C.S. Lui and Hai Jin},
  doi          = {10.1016/j.ins.2021.06.072},
  journal      = {Information Sciences},
  pages        = {140-161},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic online convex optimization with long-term constraints via virtual queue},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep field relation neural network for click-through rate
prediction. <em>ISCI</em>, <em>577</em>, 128–139. (<a
href="https://doi.org/10.1016/j.ins.2021.06.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-Through Rate (CTR) prediction is crucial in calculating advertisements and recommendation systems. To effectively predict CTR, it is important to properly model the interaction among features of data. This work tends to fully utilise the interaction information among features while employing deep neural networks for CTR prediction. To this end, we propose a Deep Field Relation Neural Network (DFRNN), which models feature interaction via a 3-dimensional relation tensor. The proposed method is evaluated on real data sets and compared with related methods. The results demonstrate that our method could be used to derive significant information contained in feature interaction and achieve an accurate CTR prediction.},
  archive      = {J_ISCI},
  author       = {Dafang Zou and Zidong Wang and Leimin Zhang and Jinting Zou and Qi Li and Yun Chen and Weiguo Sheng},
  doi          = {10.1016/j.ins.2021.06.079},
  journal      = {Information Sciences},
  pages        = {128-139},
  shortjournal = {Inf. Sci.},
  title        = {Deep field relation neural network for click-through rate prediction},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel cascade hybrid many-objective recommendation
algorithm incorporating multistakeholder concerns. <em>ISCI</em>,
<em>577</em>, 105–127. (<a
href="https://doi.org/10.1016/j.ins.2021.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most previous studies of recommender systems (RSs) have particularly focused on optimizing user experience; however, users are not the only stakeholders of an RS. A pure concentration of users limits the ability to incorporate the perspectives of other stakeholders, such as providers. Furthermore, because users&#39; preferences and providers&#39; objectives may conflict, considering only users&#39; views degrades the recommendation methods&#39; utility. Therefore, we propose a cascade hybrid many-objective recommendation method (CHMAOR) to balance four objectives for two different stakeholders. CHMAOR combines provider coverage (PC), user reach coverage (URC), and provider entropy (PE) to create a new provider visibility model (PCRE). The many-objective optimization (MOP) stage includes a novel multiparent probabilistic heuristic genetic algorithm (MPPHX) that heuristically considers both parents&#39; gene frequency and recommendation list features. Extensive experiments demonstrate the following. 1) CHMAOR effectively balances user and provider objectives in terms of accuracy, diversity, novelty, and provider visibility according to the baseline algorithms. 2) The PCRE model considers not only provider coverage but also provider appearance frequency and provider diversity while effectively changing imbalanced provider recommendations. Furthermore, PCRE dramatically reduces the complexity of high-dimensional many-objective recommendations. 3) Our MPPHX achieves better convergence and diversity solutions than the competing MOP algorithms.},
  archive      = {J_ISCI},
  author       = {Dandan Wang and Yan Chen},
  doi          = {10.1016/j.ins.2021.07.005},
  journal      = {Information Sciences},
  pages        = {105-127},
  shortjournal = {Inf. Sci.},
  title        = {A novel cascade hybrid many-objective recommendation algorithm incorporating multistakeholder concerns},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information-theoretic measures of uncertainty for
interval-set decision tables. <em>ISCI</em>, <em>577</em>, 81–104. (<a
href="https://doi.org/10.1016/j.ins.2021.06.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty measurement is considered as a vital quantitative way for analyzing and mining potential characteristic features in different types of decision tables. However, considering the equivalent relation is not suitable for evaluating the relationships of objects, few studies focused on the interval-set decision tables. In this paper, we address the uncertainty measurement problem in interval-set decision tables. Firstly, a similarity relation is induced by the similarity degree. Based on the similarity relation, a notion of granular structure is defined and the corresponding properties are investigated in interval-set decision tables. Secondly, we extend the accuracy and the roughness, called the interval approximation accuracy and the interval approximation roughness, to measure the uncertainty under the granular structures. By the analysis of the two extended measures, they can effectively evaluate the uncertainty caused by the approximations in the rough set model. Considering that the size of similarity classes can also affect the uncertainty, an alternative uncertainty measure based on the conditional information entropy, called the interval-decision entropy, is proposed. Moreover, a definition of reduct based on our proposed measure is provided and a heuristic attribute reduction algorithm is designed. Finally, numerical experiments demonstrate that the proposed uncertainty measures are effective and suitable for interval-set decision tables.},
  archive      = {J_ISCI},
  author       = {Yimeng Zhang and Xiuyi Jia and Zhenmin Tang},
  doi          = {10.1016/j.ins.2021.06.092},
  journal      = {Information Sciences},
  pages        = {81-104},
  shortjournal = {Inf. Sci.},
  title        = {Information-theoretic measures of uncertainty for interval-set decision tables},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image retrieval based on aggregated deep features weighted
by regional significance and channel sensitivity. <em>ISCI</em>,
<em>577</em>, 69–80. (<a
href="https://doi.org/10.1016/j.ins.2021.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (CNN) have demonstrated a very powerful approach for extracting discriminative local descriptors for image description. Many related works suggest that an effective aggregation representation for deep convolutional features is particularly important in forming robust and compact image representations. In this paper, a new robust global descriptor for image retrieval is proposed by creating an effective method for aggregating local deep convolutional features weighted by regional significance and channel sensitivity through sum-pooling on multiple regions. The proposed aggregation method effectively takes advantage of multiple scales, and considers both the varied significance of regional visual content and the sparsity and intensity of response values in the channel. This can improve the ability of deep features to be described and discerned. The experimental results on six benchmark datasets demonstrate that our method can achieve retrieval results comparable to those of some popular approaches for deep feature aggregation but without fine-tuning strategies and multiple image inputs.},
  archive      = {J_ISCI},
  author       = {Juxiang Zhou and Jianhou Gan and Wei Gao and Antoni Liang},
  doi          = {10.1016/j.ins.2021.06.002},
  journal      = {Information Sciences},
  pages        = {69-80},
  shortjournal = {Inf. Sci.},
  title        = {Image retrieval based on aggregated deep features weighted by regional significance and channel sensitivity},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TOMATE: A heuristic-based approach to extract data from HTML
tables. <em>ISCI</em>, <em>577</em>, 49–68. (<a
href="https://doi.org/10.1016/j.ins.2021.04.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting data from user-friendly HTML tables is difficult because of their different layouts, formats, and encoding problems. In this article, we present a new proposal that first applies several pre-processing heuristics to clean the tables, then performs functional analysis , and finally applies some post-processing heuristics to produce the output. Our most important contribution is regarding functional analysis , which we address by projecting the cells onto a high-dimensional feature space in which a standard clustering technique is used to make the meta-data cells apart from the data cells. We experimented with two large repositories of real-world HTML tables and our results confirm that our proposal can extract data from them with an F 1 F1 score of 89.50\% 89.50\% in just 0.09 0.09 CPU seconds per table. We confronted our proposal with several competitors and the statistical analysis confirmed its superiority in terms of effectiveness, while it keeps very competitive in terms of efficiency.},
  archive      = {J_ISCI},
  author       = {Juan C. Roldán and Patricia Jiménez and Pedro Szekely and Rafael Corchuelo},
  doi          = {10.1016/j.ins.2021.04.087},
  journal      = {Information Sciences},
  pages        = {49-68},
  shortjournal = {Inf. Sci.},
  title        = {TOMATE: A heuristic-based approach to extract data from HTML tables},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A three-way decision method based on fuzzy rough set models
under incomplete environments. <em>ISCI</em>, <em>577</em>, 22–48. (<a
href="https://doi.org/10.1016/j.ins.2021.06.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper primarily explores the applicability of three-way decision (TWD) to multi-attribute decision-making (MADM), and establishes a new three-way multi-attribute decision-making (TW-MADM) method under an incomplete environment. For the sake of making rational decisions for MADM problems with fuzzy values, fuzzy rough set models are first utilized to investigate a new TWD model. By taking into account the hesitation degree of each evaluation value, a data-driven method to determine the relative loss functions is presented. Moreover, a new conditional probability calculation method is put forth via the information granularity of each object. In light of the above statement, a novel TWD model with three strategies is proposed. Afterwards, the arithmetic mean method is adopted for patching the lost data to effectively address incomplete MADM problems. Given the uncertainty of the patched data and real data, a new TW-MADM method as well as a corresponding MADM algorithm is designed. By several comparative analysis and experimental analysis, the feasibility, effectiveness, superiority and stability of the method are demonstrated. In addition, the results show that the presented method with optimistic strategies is more viable and stable than the method with compromise and pessimistic strategies.},
  archive      = {J_ISCI},
  author       = {Jin Ye and Jianming Zhan and Bingzhen Sun},
  doi          = {10.1016/j.ins.2021.06.088},
  journal      = {Information Sciences},
  pages        = {22-48},
  shortjournal = {Inf. Sci.},
  title        = {A three-way decision method based on fuzzy rough set models under incomplete environments},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A three-way decision based construction of shadowed sets
from atanassov intuitionistic fuzzy sets. <em>ISCI</em>, <em>577</em>,
1–21. (<a href="https://doi.org/10.1016/j.ins.2021.06.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By combining ideas from three-way decision and Pedrycz shadowed sets, this paper investigates two possible solutions to the problem of constructing a shadowed set from an Atanassov intuitionistic fuzzy set. The first solution treats the pair of membership and nonmembership functions as two evaluations and directly applies the two-evaluation based model of three-way decision. The second solution transforms the pair of membership and nonmembership functions into an evaluation and applies a single-evaluation based model of three-way decision. To address a fundamental issue of the determination of a pair of thresholds on evaluations, we present a general optimization based formulation and use Chebyshev distance to calculate the required thresholds. The results are useful for three-way decision with fuzzy sets, Atanassov intuitionistic fuzzy sets, and shadowed sets.},
  archive      = {J_ISCI},
  author       = {Jilin Yang and Yiyu Yao},
  doi          = {10.1016/j.ins.2021.06.065},
  journal      = {Information Sciences},
  pages        = {1-21},
  shortjournal = {Inf. Sci.},
  title        = {A three-way decision based construction of shadowed sets from atanassov intuitionistic fuzzy sets},
  volume       = {577},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrating object proposal with attention networks for
video saliency detection. <em>ISCI</em>, <em>576</em>, 819–830. (<a
href="https://doi.org/10.1016/j.ins.2021.08.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video saliency detection is an active research issue in both information science and visual psychology. In this paper, we propose an efficient video saliency-detection model, based on integrating object-proposal with attention networks , for efficiently capturing salient objects and human attention areas in the dynamic scenes of videos. In our algorithm, visual object features are first exploited from individual video frame, using real-time neural networks for object detection. Then, the spatial position information of each frame is used to screen out the large background in the video, so as to reduce the influence of background noises. Finally, the results, with backgrounds removed, are further refined by spreading the visual clues through an adaptive weighting scheme into the later layers of a convolutional neural network . Experimental results, conducted on widespread and commonly used databases for video saliency detection , verify that our proposed framework outperforms existing deep models.},
  archive      = {J_ISCI},
  author       = {Muwei Jian and Jiaojin Wang and Hui Yu and Gai-Ge Wang},
  doi          = {10.1016/j.ins.2021.08.069},
  journal      = {Information Sciences},
  pages        = {819-830},
  shortjournal = {Inf. Sci.},
  title        = {Integrating object proposal with attention networks for video saliency detection},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discriminative group-sparsity constrained broad learning
system for visual recognition. <em>ISCI</em>, <em>576</em>, 800–818. (<a
href="https://doi.org/10.1016/j.ins.2021.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad Learning System (BLS) is an emerging network paradigm that has received considerable attention in the regression and classification fields . However, there are two deficiencies which seriously hinder its deployment in real applications. The first one is the internal correlations among samples are not fully considered in the modeling process. Second, the strict binary label matrix utilized in BLS provides little freedom for classification. In this paper, to address the above issues, we propose to impose group-sparsity constraints on the class-specific transformed features and label error terms, respectively. The effect is not only the more appropriate margins between data can be preserved, but also the learnt label space can be flexible for recognition. As a result, the obtained projection matrix can show more vital discriminative ability. Further, we employ the alternating direction method of multipliers to solve the resulting optimization problem . Extensive experiments and analysis on diverse benchmark databases are carried out to confirm our proposed model’s superiority in comparison with other competing classification methods.},
  archive      = {J_ISCI},
  author       = {Junwei Jin and Yanting Li and Tiejun Yang and Liang Zhao and Junwei Duan and C.L. Philip Chen},
  doi          = {10.1016/j.ins.2021.06.008},
  journal      = {Information Sciences},
  pages        = {800-818},
  shortjournal = {Inf. Sci.},
  title        = {Discriminative group-sparsity constrained broad learning system for visual recognition},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient identity-based signature scheme with provable
security. <em>ISCI</em>, <em>576</em>, 790–799. (<a
href="https://doi.org/10.1016/j.ins.2021.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many identity-based digital signature schemes are proved secure in the random oracle model . However, the application of the random oracle may lead to security risks. The used hash function is specific and the response result of the query is not always random, hence it may cause the insecurity of the scheme. To solve the above issues, this paper presents an efficient identity-based signature scheme which is proved secure under the standard model. The security of the proposed scheme is reduced to the well-known computational Diffie–Hellman (CDH) assumption. Furthermore, compared with the related identity-based signature schemes, the scheme proposed in this paper has great advantages in the computation cost of signing and verification.},
  archive      = {J_ISCI},
  author       = {Peng Yi and Jiguo Li and Chengdong Liu and Jinguang Han and Huaqun Wang and Yichen Zhang and Yu Chen},
  doi          = {10.1016/j.ins.2021.08.053},
  journal      = {Information Sciences},
  pages        = {790-799},
  shortjournal = {Inf. Sci.},
  title        = {An efficient identity-based signature scheme with provable security},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intervention optimization for crowd emotional contagion.
<em>ISCI</em>, <em>576</em>, 769–789. (<a
href="https://doi.org/10.1016/j.ins.2021.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When emergencies occur, negative emotional contagion produced in crowds makes people irrational, resulting in stampedes and crushes. The intervention of crowd emotional contagion is an efficient method for avoiding serious accidents and ensuring the safety of people’s lives and properties. However, it is a challenging problem to provide an optimized intervention scheme for crowd emotional contagion because the appropriate intervention intensity is hard to achieve, e.g., too little intervention cannot restrain the outbreak of emotion, while excessive intervention will lead to the waste of manpower and material resources. Moreover, stochastic evolutionary characteristics of emotional contagion have further aggravated this problem since it is difficult to describe the stochastic changes in emotional contagion accurately. To solve this problem, we propose an intervention optimization scheme for crowd emotional contagion to maximize the number of uninfected individuals while minimizing the intervention cost. First, we construct a stochastic event-based emotional contagion (SEEC) model to capture the stochastic evolution characteristics of emotional contagion. Based on SEEC , we then propose a Hawkes process-based intervention (HPI) model to quantify the intervention intensity. Next, we formulate the intervention optimization as a problem of maximizing the ratio of the expected number of individuals being intervened to the cost of manual intervention. Finally, we propose an intervention optimization-artificial bee colony (IO-ABC) algorithm to heuristically solve the optimization problem. The experimental results show that our method can effectively intervene in emotional contagion.},
  archive      = {J_ISCI},
  author       = {Yepeng Shi and Guijuan Zhang and Dianjie Lu and Lei Lv and Hong Liu},
  doi          = {10.1016/j.ins.2021.08.056},
  journal      = {Information Sciences},
  pages        = {769-789},
  shortjournal = {Inf. Sci.},
  title        = {Intervention optimization for crowd emotional contagion},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability analysis for delayed neural networks via an
improved negative-definiteness lemma. <em>ISCI</em>, <em>576</em>,
756–768. (<a href="https://doi.org/10.1016/j.ins.2021.08.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the stability problem for neural networks with a time-varying delay. An improved negative-definiteness lemma (NDL) is proposed by removing some redundant inequality constraints involved in the original one that is recently developed via a quadratic-partitioning method. Furthermore, the improved NDL is presented in the matrix-valued form for convenient application. With regard to the case that the upper bound of the variation of the delay is less than a known constant while the lower bound is unknown, an appropriate Lyapunov–Krasovskii functional (LKF) candidate is deliberately built so that the derivative of the LKF is estimated to be a novel quadratic function with respect to the delay. Consequently, a series of new stability criteria is obtained via the improved NDL, which is shown to be less conservative than existing ones through numerical examples.},
  archive      = {J_ISCI},
  author       = {Jun Chen and Ju H. Park and Shengyuan Xu},
  doi          = {10.1016/j.ins.2021.08.055},
  journal      = {Information Sciences},
  pages        = {756-768},
  shortjournal = {Inf. Sci.},
  title        = {Stability analysis for delayed neural networks via an improved negative-definiteness lemma},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distilling from professors: Enhancing the knowledge
distillation of teachers. <em>ISCI</em>, <em>576</em>, 743–755. (<a
href="https://doi.org/10.1016/j.ins.2021.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) is a successful technique for transferring knowledge from one machine learning model to another model. Specifically, the idea of KD has been widely used for various tasks such as model compression and knowledge transfer between different models. However, existing studies in KD have overlooked the possibility that dark knowledge (i.e., soft targets) obtained from a complex and large model ( a.k.a., a teacher model) may be either incorrect or insufficient. Such knowledge can hinder the effective learning of another small model ( a.k.a., a student model). In this paper, we propose the professor model , which refines the soft target from the teacher model to improve KD. The professor model aims to achieve two goals; 1) improving the prediction accuracy and 2) capturing the inter-class correlation of the soft target from the teacher model. We first design the professor model by reformulating a conditional adversarial autoencoder (CAAE). Then, we devise two KD strategies using both teacher and professor models. Our empirical study demonstrates that the professor model effectively improves KD in three benchmark datasets: CIFAR100, TinyImagenet, and ILSVRC2015. Moreover, our comprehensive analysis shows that the professor model is much more effective than employing the stronger teacher model, in which parameters are greater than the sum of the teacher’s and professor’s parameters. Since the proposed model is model-agnostic, our model can be combined with any KD algorithm and consistently improves various KD techniques.},
  archive      = {J_ISCI},
  author       = {Duhyeon Bang and Jongwuk Lee and Hyunjung Shim},
  doi          = {10.1016/j.ins.2021.08.020},
  journal      = {Information Sciences},
  pages        = {743-755},
  shortjournal = {Inf. Sci.},
  title        = {Distilling from professors: Enhancing the knowledge distillation of teachers},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive graph guided concept factorization on grassmann
manifold. <em>ISCI</em>, <em>576</em>, 725–742. (<a
href="https://doi.org/10.1016/j.ins.2021.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by applications in clustering and optimization, there has been significant interest in the variant for which the database models are high-dimensional data (such as imagesets or videos). Matrix factorization approaches, particularly Nonnegative Matrix Factorization (NMF) have achieved favorable results for data clustering tasks. However, these methods suffer from two major drawbacks. First, matrix factorization approaches only partially explore the inter- or intra- relationships between vector-valued data and are unable to handle high-dimensional data. Second, the clustering results largely rely on the predefined similarity matrix , which usually contain large amounts of noise. In this paper, we propose a novel Adaptive Graph Guided Concept Factorization model on Grassmann manifold (A G 3 CF) for imageset clustering in an unsupervised fashion, which imposes concept factorization over the space of linear subspaces . To further explore the structure of data and assign ideal neighbors, an adaptive graph regularization constraint is designed to automatically capture the local relationships of data samples and integrated well into concept factorization framework. An efficient algorithm is also derived to tackle the resulting optimization problem . Experimental results on several public datasets validate that the proposed approach achieves competitive performance in high-dimensional data clustering .},
  archive      = {J_ISCI},
  author       = {Dong Wei and Xiaobo Shen and Quansen Sun and Xizhan Gao and Zhenwen Ren},
  doi          = {10.1016/j.ins.2021.08.040},
  journal      = {Information Sciences},
  pages        = {725-742},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive graph guided concept factorization on grassmann manifold},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Man-in-the-middle attack against cyber-physical systems
under random access protocol. <em>ISCI</em>, <em>576</em>, 708–724. (<a
href="https://doi.org/10.1016/j.ins.2021.07.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the man-in-the-middle (MITM) attack against cyber-physical systems (CPSs) under the random access protocol (RAP) scheduling, where an attacker intercepts and modifies the transmitted data and then forwards them on to degrade the system performance. The RAP schedules the sensing devices to avoid data collisions, where only one node is allowed to access the shared communication channel at each time instant. Hence, it makes the existing stealthy attacks invalid. To overcome the protocol-induced effects, a novel attack model utilizing only part of the measurements at each time instant is proposed, based on which the strictly stealthy and ∊ ∊ -stealthy attacks are designed. For strictly stealthy attack, the Kullback-Leibler divergence (KLD)-based stealthy constraint is converted into a linear matrix inequality and then a semi-definite program problem is constructed to obtain the optimal attack parameters. In such case, the attack performance is optimal but limited. Furthermore, an ∊ ∊ -stealthy attack is proposed to achieve higher attack performance, where the analytical attack parameters are obtained by solving an off-line convex optimization problem . Finally, simulations are provided to verify the results.},
  archive      = {J_ISCI},
  author       = {Xiao-Guang Zhang and Guang-Hong Yang and Saud Wasly},
  doi          = {10.1016/j.ins.2021.07.083},
  journal      = {Information Sciences},
  pages        = {708-724},
  shortjournal = {Inf. Sci.},
  title        = {Man-in-the-middle attack against cyber-physical systems under random access protocol},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using improved group 2 and linguistic z-numbers combined
approach to analyze the causes of railway passenger train derailment
accident. <em>ISCI</em>, <em>576</em>, 694–707. (<a
href="https://doi.org/10.1016/j.ins.2021.07.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several passenger train derailment accidents occurred in the world. In order to guarantee the reliability and normal operations of railway passenger trains, an improved Group 2 and Linguistic Z-numbers (IG2-LZs) combined approach is proposed to analyze the causes of railway passenger train derailment accident (RPTDA). The weight and attribute value of each cause of accident are calculated by IG2 and LZs, respectively. In order to relax the three limitations of previous G2 approach, the Fault Tree is applied to figure out the least important cause of accident from all causes of accident; the minimum nonempty intersection sets , which can reflect the opinions of experts, are introduced to improve the interval assignment; left offset rate and right offset rate are introduced to improve the risk attitude factor from the experts. The Puyuma case happened in Taiwan is applied as the case study. The calculation results show that, the failure of Automatic Train Protection (ATP) belongs to the most contributed cause. A comparison of Analytic Hierarchy Process (AHP), IG2-Triangular Fuzzy Number and previous G2-LZs show that the IG2-LZs is more reliable and reasonable than AHP, IG2-TFN or G2-LZs.},
  archive      = {J_ISCI},
  author       = {Wencheng Huang and Yue Zhang and Dezhi Yin and Borui Zuo and Minhao Xu and Rui Zhang},
  doi          = {10.1016/j.ins.2021.07.067},
  journal      = {Information Sciences},
  pages        = {694-707},
  shortjournal = {Inf. Sci.},
  title        = {Using improved group 2 and linguistic Z-numbers combined approach to analyze the causes of railway passenger train derailment accident},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure and smart autonomous multi-robot systems for opinion
spammer detection. <em>ISCI</em>, <em>576</em>, 681–693. (<a
href="https://doi.org/10.1016/j.ins.2021.07.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reviews of social media have become very important reference indicators for people shopping. However, in order to attract more consumers, some bad merchants organize many fraudulent reviewers to conduct malicious reviews aim at misleading consumers, which is called opinion spammer group. Previous studies have shown that there is an implicit community between reviewers In this paper, we try to use community discovery approach in secure and smart autonomous multi-robot systems for opinion spammer detection, and improve the prediction precision. We propose a novel approach, named SPClique , which is based on the Clique Percolation Method (CPM) to detect opinion spammer groups by modeling the review dataset as reviewer projection graph. During the process, we introduce approximate computing to get a valuable smaller reviewer-projection graph and expand the computing power. It first executes the CPM algorithm in the reviewer-projection graph to find all k-clique clusters, and then innovatively describes an opinion spammer group based on k-clique clusters. Second, the group-based spam and individual-based spams indicators are used to measure the suspiciousness of each opinion spammer group. Finally, it outputs the suspect ranking of opinion spammer groups. The prediction precision of our proposed method is better than four advanced comparison methods, and our approach can detect more real opinion spammers in large-scale review datasets.},
  archive      = {J_ISCI},
  author       = {Guangxia Xu and Mengxiao Hu and Chuang Ma},
  doi          = {10.1016/j.ins.2021.07.072},
  journal      = {Information Sciences},
  pages        = {681-693},
  shortjournal = {Inf. Sci.},
  title        = {Secure and smart autonomous multi-robot systems for opinion spammer detection},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UFFDFR: Undersampling framework with denoising, fuzzy
c-means clustering, and representative sample selection for imbalanced
data classification. <em>ISCI</em>, <em>576</em>, 658–680. (<a
href="https://doi.org/10.1016/j.ins.2021.07.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of artificial intelligence , classification algorithms tend to be biased toward the majority class samples when encountering imbalanced data , resulting in low recognition rates for minority class samples. Undersampling techniques address this issue by decreasing the number of majority class samples to balance the original data distribution before the dataset is learned. However, current clustering-based undersampling methods have limitations that directly affect the original imbalanced dataset and the final classification performance. To address these problems, we propose a novel three-stage undersampling framework with denoising , fuzzy c-means clustering, and representative sample selection (UFFDFR). This framework improves the classification performance on imbalanced data by removing noise and unrepresentative samples from the majority class. Experiments on 15 different imbalanced datasets demonstrate that UFFDFR effectively removed noise and unrepresentative majority class samples and improved classification performance. Furthermore, UFFDFR outperformed three classic and three state-of-the-art clustering-based undersampling methods in terms F-measure, G-mean, and AUC for five classification algorithms , which was confirmed by the Friedman and Nemenyi post-hoc statistical tests.},
  archive      = {J_ISCI},
  author       = {Ming Zheng and Tong Li and Xiaoyao Zheng and Qingying Yu and Chuanming Chen and Ding Zhou and Changlong Lv and Weiyi Yang},
  doi          = {10.1016/j.ins.2021.07.053},
  journal      = {Information Sciences},
  pages        = {658-680},
  shortjournal = {Inf. Sci.},
  title        = {UFFDFR: Undersampling framework with denoising, fuzzy c-means clustering, and representative sample selection for imbalanced data classification},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Top-aware recommender distillation with deep reinforcement
learning. <em>ISCI</em>, <em>576</em>, 642–657. (<a
href="https://doi.org/10.1016/j.ins.2021.07.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing recommenders focus on providing users with a list of recommended products. In practical, users may only pay attention to the recommendations at the top positions. Our analysis, however, shows that the correctly recommended products from existing methods are not top posited; this would result in sacrificing users’ patience and engagements. To address this issue, this paper proposes a top-aware recommender distillation (TRD) framework, viz., the rank of recommendation lists from given state-of-the-art recommendation approaches are further reinforced and refined using reinforcement learning . Different from the traditional goal of knowledge distillation to mimic the behavior of its teacher, our recommender contrastingly goes step further with the goal of surpassing its teacher recommender. More importantly, our proposed TRD can be plugged on any existed recommender; thus being generic for real-world deployment. Theoretical analysis demonstrates that TRD is guaranteed to perform at least as well as the basic recommender. Extensive experiments on five state-of-the-art recommendation algorithms across three real-world datasets further show that TRD consistently improves the recommendations at top positions.},
  archive      = {J_ISCI},
  author       = {Hongyang Liu and Zhu Sun and Xinghua Qu and Fuyong Yuan},
  doi          = {10.1016/j.ins.2021.07.064},
  journal      = {Information Sciences},
  pages        = {642-657},
  shortjournal = {Inf. Sci.},
  title        = {Top-aware recommender distillation with deep reinforcement learning},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification of adverse disease agents and risk analysis
using frequent pattern mining. <em>ISCI</em>, <em>576</em>, 609–641. (<a
href="https://doi.org/10.1016/j.ins.2021.07.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Life-threatening illnesses such as cancer, cirrhosis of the liver, and hepatitis have become crucial problems for humanity. The risk of mortality can be deflated by early detection of symptoms and providing the best possible diagnosis. This critical role of detection and/or diagnosis can be enhanced using one of the techniques used in data mining, such as periodic pattern mining, association rule mining, classification. Analyzing the commonly occurring possible patterns or signs followed by performing the correlation analysis among those patterns can be exhaustively practiced for early detection and improve the diagnosis. Towards the adoption of association rule mining, devising a cost-effective and time-saving algorithm for mining frequent patterns plays an important role. In this paper, we propose an approach to pattern mining called Improved Frequent Pattern Growth (Improved FP-Growth). Firstly, it constructs an improvised frequent pattern tree data structure called Improved FP-tree. Moreover, Improved FP-Growth introduces a construction of conditional FP-tree data structure layout called Improved Conditional Frequent Pattern Tree (Improved Conditional FP-Tree). Unlike the traditional FP-Growth method, it uses both top-down and bottom-up approaches to efficiently generate frequent patterns without recursively constructing the improved conditional FP-tree. The experimental results emphasize the significance of the proposed Improved FP-Growth algorithm over a few traditional frequent itemset mining algorithms those adopt the approach of recursive conditional FP-tree construction.},
  archive      = {J_ISCI},
  author       = {Shafiul Alom Ahmed and Bhabesh Nath},
  doi          = {10.1016/j.ins.2021.07.061},
  journal      = {Information Sciences},
  pages        = {609-641},
  shortjournal = {Inf. Sci.},
  title        = {Identification of adverse disease agents and risk analysis using frequent pattern mining},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel webpage layout aesthetic evaluation model for
quantifying webpage layout design. <em>ISCI</em>, <em>576</em>, 589–608.
(<a href="https://doi.org/10.1016/j.ins.2021.06.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely accepted that webpage layout is important for website aesthetics. However, knowledge is limited about which kind of webpage layout is aesthetic. In this paper, we conduct a large-scale analysis of 13,017 real webpages with different aesthetic levels. The results demonstrate that there are significant differences between aesthetic webpages and non-aesthetic webpages in several aspects of layout design, such as the position of objects and the average number of objects. In order to identify whether the web layout is aesthetic, we propose a novel Webpage Layout Aesthetic Evaluation model (WLAE) based on an improved Adaboost algorithm to automatically predict the aesthetics of a webpage layout. Experimental results show that our WLAE model is significantly better than other existing methods. Based on the feature analysis of 13,017 real-world webpages and the contribution of each feature to webpage aesthetic prediction, we have summarized 4 webpage design principles for webpage designers. Besides, a large number of real webpages collected by our team can be used for further research on webpage layout aesthetic design and/or related research.},
  archive      = {J_ISCI},
  author       = {Hongyan Wan and Wanting Ji and Guoqing Wu and Xiaoyun Jia and Xue Zhan and Mengting Yuan and Ruili Wang},
  doi          = {10.1016/j.ins.2021.06.071},
  journal      = {Information Sciences},
  pages        = {589-608},
  shortjournal = {Inf. Sci.},
  title        = {A novel webpage layout aesthetic evaluation model for quantifying webpage layout design},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An effective method to improve nonlinearity value of
substitution boxes based on random selection. <em>ISCI</em>,
<em>576</em>, 577–588. (<a
href="https://doi.org/10.1016/j.ins.2021.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today&#39;s digital society, new design alternatives are needed for substitution box structures, which has critical importance in developing secure information systems that are resistant to algebraic and application attacks, as new attacks negatively affect designs based on mathematical transformations. Although random selection-based substitution box structures are a good alternative against algebraic and application attacks, the low value of nonlinearity criterion is an important problem. Solution suggestions using optimization algorithms have been proposed to address this problem. “Information Sciences 523 (2020) 152–166” is the study that reached the highest nonlinearity value based on optimization algorithms to date. However, the high computational costs of optimization algorithms are another challenge that must be overcome. In this study, it has been shown that the nonlinearity values ​​of random (chaotic) selection substitution box structures can be improved as much as mathematically based designs by using a method that is too simple to compare with optimization algorithms. It has been shown that the nonlinearity value can be improved up to 110 for random selection-based substitution box designs. Although this nonlinearity value is the highest achievable value in the literature based on the random selection principle, the fact that it requires only 2 × 255 × 255 2×255×255 processes in the worst case has been evaluated as an important success of the proposed method compared to other design approaches. Other advantages of the proposed method are that the improved substitution box structures are resistant to side-channel attacks, simple structure, easy hardware implementation, and successful results in practical applications such as image encryption . It is believed that all these results will be a motivation for new post-processing techniques to be designed in the future for random selection-based substitution box designs.},
  archive      = {J_ISCI},
  author       = {Fırat Artuğer and Fatih Özkaynak},
  doi          = {10.1016/j.ins.2021.07.036},
  journal      = {Information Sciences},
  pages        = {577-588},
  shortjournal = {Inf. Sci.},
  title        = {An effective method to improve nonlinearity value of substitution boxes based on random selection},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving decomposition-based multiobjective evolutionary
algorithm with local reference point aided search. <em>ISCI</em>,
<em>576</em>, 557–576. (<a
href="https://doi.org/10.1016/j.ins.2021.06.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the fixed and monotonous search direction, the performance of decomposition-based multiobjective evolutionary algorithms (MOEAs) highly depends on the Pareto front (PF) shape. Recent studies have highlighted the complementary effect of the ideal and nadir points. They roughly employed both as the reference points to diversify the search direction. However, few works investigate whether two points are equally important. This paper thereby proposes a novel decomposition-based MOEA, where the ideal point is consistently considered as the global reference point while the nadir point is conditionally employed as the local one. We show that the nadir point may aid the ideal point in some cases and be recognized as a redundant one in others. More specifically, an assignment strategy is suggested to determine the necessity of using a local reference point for each subproblem , by considering whether the solution found by the nadir point and corresponding weight vector can improve the quality of the population. Experimental results finally verify the effectiveness of the proposed algorithm on 57 benchmark test problems with various PF shapes. In comparison with the state-of-the-art decomposition-based MOEAs, the proposed algorithm is promising to bring a more refined search and prevent redundant search behaviors .},
  archive      = {J_ISCI},
  author       = {Jing Jiang and Fei Han and Jie Wang and Qinghua Ling and Henry Han and Zizhu Fan},
  doi          = {10.1016/j.ins.2021.06.068},
  journal      = {Information Sciences},
  pages        = {557-576},
  shortjournal = {Inf. Sci.},
  title        = {Improving decomposition-based multiobjective evolutionary algorithm with local reference point aided search},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fairness improvement for black-box classifiers with gaussian
process. <em>ISCI</em>, <em>576</em>, 542–556. (<a
href="https://doi.org/10.1016/j.ins.2021.06.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications, it is the fairness, not the accuracy, of a machine learning (ML) classifier that is the crucial factor. Post-processing approaches are widely considered as successful tools to improve the fairness of black-box ML classifiers. These aim to learn a relabeling function to modify initial predicted labels provided by a pre-trained “unfair” classifier, resulting in fair classification on a given test set. However, many post-processing methods require a training set with true labels to learn the relabeling function. To the best of our knowledge, there have been only two methods that learn the relabeling function without requiring the true labels of training samples. However, both of these methods require access to the predictions of the pre-trained classifier when performing on the test set, even after they learned the optimal relabeling function, and neither offers theoretical guarantees on the trade-off between accuracy loss and fairness improvement. In this paper, we propose a novel post-processing method based on Gaussian process (GP). We first train a GP with unlabeled samples, and use its posterior mean function to approximate the predictions of the pre-trained classifier. We then adjust the mean function (i.e. the relabeling function) to achieve two goals: (1) maximize the fairness and (2) minimize the difference between the relabeling function and the pre-trained classifier. By doing this, our method can improve fairness while maintaining high accuracy. We provide a theoretical analysis to derive an upper bound on accuracy loss for our method. We demonstrate our method on four real-world datasets, comparing with state-of-the-art baselines, to demonstrate its ability to achieve both fairness and accuracy.},
  archive      = {J_ISCI},
  author       = {Dang Nguyen and Sunil Gupta and Santu Rana and Alistair Shilton and Svetha Venkatesh},
  doi          = {10.1016/j.ins.2021.06.095},
  journal      = {Information Sciences},
  pages        = {542-556},
  shortjournal = {Inf. Sci.},
  title        = {Fairness improvement for black-box classifiers with gaussian process},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-time synchronization of fuzzy neutral-type BAM
memristive inertial neural networks with proportional delays.
<em>ISCI</em>, <em>576</em>, 522–541. (<a
href="https://doi.org/10.1016/j.ins.2021.06.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, fixed-time synchronization (Fix-TS) of fuzzy neutral-type bidirectional associative memory memristive-inertial neural networks (FNT-BAM-MINNs) with proportional delays is investigated by non-reduced order method. First, a new lemma is proposed to solve the parameter mismatch of FNT-BAM-MINNs on the basis of differential inclusion theories and analysis methods. Second, the delay-dependent switched controller and the delay-dependent fuzzy switched controller are designed to reach the Fix-TS of the drive-response FNT-BAM-MINNs, respectively. Based on fixed-time stability theory , inequality techniques and the new lemma, some delay-independent sufficient conditions are given to guarantee the Fix-TS of FNT-BAM-MINNs, which are easy to implement in practice. Furthermore, the settling time independent of the initial value is estimated. Finally, numerical examples indicate that our results are effective.},
  archive      = {J_ISCI},
  author       = {Liyan Duan and Junmin Li},
  doi          = {10.1016/j.ins.2021.06.093},
  journal      = {Information Sciences},
  pages        = {522-541},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time synchronization of fuzzy neutral-type BAM memristive inertial neural networks with proportional delays},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forward and backward secure keyword search with flexible
keyword shielding. <em>ISCI</em>, <em>576</em>, 507–521. (<a
href="https://doi.org/10.1016/j.ins.2021.06.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Searchable Symmetric Encryption (DSSE) has gained increasing popularity as it enables users to perform both file updates and ciphertext retrieval over encrypted data . However, existing DSSE schemes still lead to privacy leakage ( e.g., forward and backward privacy) in the dynamic setting. Some forward and backward secure DSSE schemes have been proposed, but still cannot support the keyword shielding flexibly. To solve this challenging issue, we propose a Forward and Backward Authorized Keyword Search (FB-AKS) scheme with recoverable keyword shielding by using trapdoor permutations and puncturable encryption in this paper. Compared with existing forward and backward private schemes, FB-AKS achieves keyword authorization flexibly ( e.g., keyword shielding, keyword un-shielding). The formal security analysis proves that FB-AKS achieves forward and backward security. And extensive experiments demonstrate that FB-AKS has less computation and storage overheads .},
  archive      = {J_ISCI},
  author       = {Zhijun Li and Jianfeng Ma and Yinbin Miao and Ximeng Liu and Kim-Kwang Raymond Choo},
  doi          = {10.1016/j.ins.2021.06.048},
  journal      = {Information Sciences},
  pages        = {507-521},
  shortjournal = {Inf. Sci.},
  title        = {Forward and backward secure keyword search with flexible keyword shielding},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DSAGAN: A generative adversarial network based on
dual-stream attention mechanism for anatomical and functional image
fusion. <em>ISCI</em>, <em>576</em>, 484–506. (<a
href="https://doi.org/10.1016/j.ins.2021.06.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, extensive multimodal medical image fusion algorithms have been proposed. However, existing methods are primarily based on specific transformation theories. There are many problems with existing algorithms, such as poor adaptability, low efficiency and blurry details. To address these problems, this paper proposes a generative adversarial network based on dual-stream attention mechanism (DSAGAN) for anatomical and functional image fusion. The dual-stream architecture and multiscale convolutions are utilized to extract deep features. In addition, the attention mechanism is utilized to further enhance the fused features. Then, the fusion images and multimodal input images are put into the discriminator . In the update stage of the discriminator , we expect to judge the multimodal images as real, and to judge the fusion images as fake. Furthermore, the fusion images are expected to be judged as real in the update stage of the generator, forcing the generator to improve the fusion quality. The training process continues until the generator and discriminator reach a Nash equilibrium . After training, the fusion images can be obtained directly after inputting anatomical and functional images. Compared with the reference algorithms , DSAGAN consumes less fusion time and achieves better objective metrics in terms of Q AG , Q EN and Q NIQE .},
  archive      = {J_ISCI},
  author       = {Jun Fu and Weisheng Li and Jiao Du and Liming Xu},
  doi          = {10.1016/j.ins.2021.06.083},
  journal      = {Information Sciences},
  pages        = {484-506},
  shortjournal = {Inf. Sci.},
  title        = {DSAGAN: A generative adversarial network based on dual-stream attention mechanism for anatomical and functional image fusion},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A genetic timing scheduling model for urban traffic signal
control. <em>ISCI</em>, <em>576</em>, 475–483. (<a
href="https://doi.org/10.1016/j.ins.2021.06.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As urban traffic condition is diverse and complicated, maximizing the use of urban traffic signal control system to solve traffic issues becomes one of the hot and promising topics. Especially, how to control traffic signals at multiple intersections is a key challenge. To speed up urban traffic flow, this research presents a genetic timing scheduling model (GTSM) for urban traffic signal control. GTSM constructs cellular automata to update the timing cycles of traffic signals at multiple intersections, where state update functions are formulated to coordinate traffic signals. In addition, a proposed genetic optimization algorithm (GOA) in GTSM optimizes the timing cycles of traffic signals at multiple intersections in the dynamic timing optimization . The experimental results on urban road networks show that the performance of our model is excellent in various scenarios to control traffic signals to speed up urban traffic flow.},
  archive      = {J_ISCI},
  author       = {Huan Wang and Po Hu and Hao Wang},
  doi          = {10.1016/j.ins.2021.06.082},
  journal      = {Information Sciences},
  pages        = {475-483},
  shortjournal = {Inf. Sci.},
  title        = {A genetic timing scheduling model for urban traffic signal control},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extracting modular-based backbones in weighted networks.
<em>ISCI</em>, <em>576</em>, 454–474. (<a
href="https://doi.org/10.1016/j.ins.2021.06.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks are an adequate representation for modeling and analyzing a great variety of complex systems. However, understanding networks with millions of nodes and billions of connections can be pretty challenging due to memory and time constraints. Therefore, selecting the relevant nodes and edges of these large-scale networks while preserving their core information is a major issue. In most cases, the so-called backbone extraction methods are based either on coarse-graining or filtering approaches. Coarse-graining techniques reduce the network size by gathering similar nodes into super-nodes, while filter-based methods eliminate nodes or edges according to a statistical property.In this work, a filter-based method is proposed and investigated. It uses the overlapping community structure to build the backbone in weighted networks. While most filtering techniques rely on link features to extract the backbone, the proposed method exploits both nodes and links. It takes advantage of the network communities through their main features (overlapping nodes, hubs, and bridging connections) to select influential edges and nodes while preserving the ability of the information dissemination of the original network. The so-called “Modular filtering backbone” combines two components. The first one is the network connecting the overlapping nodes and the top connected nodes (also called the hubs).One discards the edges with the lowest weights as long as connected components are maintained. The second component uses the network of the inter-community links with the nodes at their extremities. The disparity filter algorithm allows preserving only its most crucial connections. An extensive investigation is performed on a set of real-world weighted networks of various sizes and a wide range of origin. Results show the advantage of the proposed method over alternative filtering-based methods used for comparative purposes. Furthermore, this sheds new light on the most relevant parts of empirical networks hidden by their complexity.},
  archive      = {J_ISCI},
  author       = {Zakariya Ghalmane and Chantal Cherifi and Hocine Cherifi and Mohammed El Hassouni},
  doi          = {10.1016/j.ins.2021.06.087},
  journal      = {Information Sciences},
  pages        = {454-474},
  shortjournal = {Inf. Sci.},
  title        = {Extracting modular-based backbones in weighted networks},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The evidential reasoning approach for renewable energy
resources evaluation under interval type-2 fuzzy uncertainty.
<em>ISCI</em>, <em>576</em>, 432–453. (<a
href="https://doi.org/10.1016/j.ins.2021.06.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting the right renewable energy resources (RESs) is emerging as a solution to alleviate energy crisis and environmental pollution. Due to the limitation of human knowledge and the complexity of reality, the selection process usually involves multiple uncertainties. In this paper, an interval type-2 fuzzy evidential reasoning approach is proposed to solve the RESs evaluation problem with uncertain information. First, the linguistic terms involved in the RESs evaluation process are encoded into the interval type-2 fuzzy sets (IT2FSs). Second, a new interval type-2 fuzzy distance model is developed to measure the distance between the IT2FSs. After obtaining the distance, two new information transformation techniques are respectively defined to transform the IT2FSs and the crisp numbers into the interval belief structures. Then, an interval type-2 fuzzy entropy measure is proposed to determine the weights of attributes and the corresponding axioms are proved mathematically. Finally, the interval expected utility of each alternative is generated by a pair of nonlinear optimization models and then ranked by an enhanced minimax regret approach. A case study about the RESs evaluation is provided to illustrate the effectiveness of the proposed approach, comparisons and discussions are also conducted to show the superiority.},
  archive      = {J_ISCI},
  author       = {Xiaohong Pan and Yingming Wang and Shifan He},
  doi          = {10.1016/j.ins.2021.06.091},
  journal      = {Information Sciences},
  pages        = {432-453},
  shortjournal = {Inf. Sci.},
  title        = {The evidential reasoning approach for renewable energy resources evaluation under interval type-2 fuzzy uncertainty},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable teacher forcing network for semi-supervised large
scale data streams. <em>ISCI</em>, <em>576</em>, 407–431. (<a
href="https://doi.org/10.1016/j.ins.2021.06.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The large-scale data stream problem refers to high-speed information flow which cannot be processed in scalable manner under a traditional computing platform. This problem also imposes expensive labelling cost making the deployment of fully supervised algorithms unfeasible. On the other hand, the problem of semi-supervised large-scale data streams is little explored in the literature because most works are designed in the traditional single-node computing environments while also being fully supervised approaches. This paper offers Weakly Supervised Scalable Teacher Forcing Network (WeScatterNet) to cope with the scarcity of labelled samples and the large-scale data streams simultaneously. WeScatterNet is crafted under distributed computing platform of Apache Spark with a data-free model fusion strategy for model compression after parallel computing stage. It features an open network structure to address the global and local drift problems while integrating a data augmentation , annotation and auto-correction (DA 3 ) method for handling partially labelled data streams. The performance of WeScatterNet is numerically evaluated in the six large-scale data stream problems with only 25\% label proportions. It shows highly competitive performance even if compared with fully supervised learners with 100\% label proportions.},
  archive      = {J_ISCI},
  author       = {Mahardhika Pratama and Choiru Za’in and Edwin Lughofer and Eric Pardede and Dwi A.P. Rahayu},
  doi          = {10.1016/j.ins.2021.06.075},
  journal      = {Information Sciences},
  pages        = {407-431},
  shortjournal = {Inf. Sci.},
  title        = {Scalable teacher forcing network for semi-supervised large scale data streams},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic output-feedback control for singular interval-valued
fuzzy systems: Linear matrix inequality approach. <em>ISCI</em>,
<em>576</em>, 393–406. (<a
href="https://doi.org/10.1016/j.ins.2021.06.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces an admissibilization condition for singular interval-valued fuzzy systems with a dynamic output-feedback controller using a linear matrix inequality approach. The derivation of the admissibility criterion (satisfying regularity, non-impulsiveness and stability) for the closed-loop system of the singular interval-valued fuzzy systems using the dynamic output-feedback controller is concerned. Here, the derived criterion is represented as the parameterized matrix inequalities depending on the membership functions of the system and the controller. To relax the derived parameterized matrix inequalities, this paper proposes a relaxation lemma based on the properties of the membership functions and their relations. By using this lemma, the parameterized matrix inequalities are converted into the matrix inequalities independent of the membership functions but not convex. Therefore, by introducing the structures of the variables and the congruent transformation matrix , a sufficient condition for the admissibility criterion is successfully given in terms of strict linear matrix inequalities. Two numerical examples are given to show the effectiveness of the proposed control.},
  archive      = {J_ISCI},
  author       = {In Seok Park and Chan-eun Park and Nam Kyu Kwon and PooGyeon Park},
  doi          = {10.1016/j.ins.2021.06.053},
  journal      = {Information Sciences},
  pages        = {393-406},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic output-feedback control for singular interval-valued fuzzy systems: Linear matrix inequality approach},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A parallel multi-objective evolutionary algorithm for
community detection in large-scale complex networks. <em>ISCI</em>,
<em>576</em>, 374–392. (<a
href="https://doi.org/10.1016/j.ins.2021.06.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection in large-scale complex networks has recently received significant attention as the volume of available data is becoming larger. The use of evolutionary algorithms (EAs) for community detection in large-scale networks has gained considerable popularity because these algorithms are fairly effective in networks with a relatively small number of nodes. In this paper, we propose a parallel multi-objective EA, called PMOEA, for community detection in large-scale networks, where the communities associated with key network nodes are detected in parallel. Specifically, we develop a multi-objective and a single-objective EA. The former is used to detect the communities of a key node instead of all communities in the network. The latter obtains the communities in the entire network using the previously detected communities of each key node. The performance of the proposed method was verified on both large-scale synthetic benchmark networks and real-world networks. The results demonstrated the superiority of PMOEA over six EA-based and two non-EA-based community-detection algorithms for large-scale networks.},
  archive      = {J_ISCI},
  author       = {Yansen Su and Kefei Zhou and Xingyi Zhang and Ran Cheng and Chunhou Zheng},
  doi          = {10.1016/j.ins.2021.06.089},
  journal      = {Information Sciences},
  pages        = {374-392},
  shortjournal = {Inf. Sci.},
  title        = {A parallel multi-objective evolutionary algorithm for community detection in large-scale complex networks},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multifactorial evolutionary optimization to maximize
lifetime of wireless sensor network. <em>ISCI</em>, <em>576</em>,
355–373. (<a href="https://doi.org/10.1016/j.ins.2021.06.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prolonging network lifetime is a crucial issue for wireless sensor networks , as sensor nodes operate on limited amounts of battery energy, and replacing or recharging nodes is still quite challenging. One approach is using relay nodes to alleviate sensors’ energy usage when transmitting data. In this work, we tackle the issues of relay node assignment for wireless single-hop sensor and multi-hop sensor networks in three-dimensional terrains. Traditionally, researchers have focused on solving relay node selection for either single-hop or multi-hop networks, one at a time. We propose MFRSEA , a multifactorial evolutionary algorithm utilizing a network random key representation, a constraint-aware fitness function, and a novel crossover operator in order to optimize for both network types simultaneously. Experimental results show that our method outperforms the baseline in several key metrics.},
  archive      = {J_ISCI},
  author       = {Nguyen Thi Tam and Vi Thanh Dat and Phan Ngoc Lan and Huynh Thi Thanh Binh and Le Trong Vinh and Ananthram Swami},
  doi          = {10.1016/j.ins.2021.06.056},
  journal      = {Information Sciences},
  pages        = {355-373},
  shortjournal = {Inf. Sci.},
  title        = {Multifactorial evolutionary optimization to maximize lifetime of wireless sensor network},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Signal structure information-based target detection with a
fully convolutional network. <em>ISCI</em>, <em>576</em>, 345–354. (<a
href="https://doi.org/10.1016/j.ins.2021.06.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For target echoes, some structure information can be introduced by the signal processing techniques , such as matched filtering and coherent integration, and are usually omitted in traditional target detection (TTD) methods. The detection performance is supposed to be improved with consideration of these information. To deal with the randomness in the signal structure information (SSI) induced by the sampling and uncertain distribution of scatters, we resort to the data-driven method and propose a novel detection scheme. To make use of the SSI, a fully convolutional network (FCN) is designed to hierarchically learn the SSI. Simulation results show that the better detection performance can be obtained with the proposed SSI-based target detection method comparing to the TTD method. The justifications of using the SSI and the FCN are respectively investigated by considering the oversampling strategy and a post hoc visual explanation technique. Besides, the computational complexity is partially analyzed both in theory and in experiment.},
  archive      = {J_ISCI},
  author       = {Chang Gao and Junkun Yan and Xiaojun Peng and Hongwei Liu},
  doi          = {10.1016/j.ins.2021.06.066},
  journal      = {Information Sciences},
  pages        = {345-354},
  shortjournal = {Inf. Sci.},
  title        = {Signal structure information-based target detection with a fully convolutional network},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel denial-of-service attacks against cloud-based
multi-robot systems. <em>ISCI</em>, <em>576</em>, 329–344. (<a
href="https://doi.org/10.1016/j.ins.2021.06.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of robotics technology is accelerated by the strong support from cloud computing. Massive computation resources and services from the cloud make modern multi-robot systems more efficient and powerful. However, the introduction of cloud servers to multi-robot systems can also incur potential Denial-of-Service (DoS) threats, where an adversary can utilize the shared cloud resources to degrade or bring down the robot systems. In this paper, we conduct a comprehensive study about this security issue. By analyzing different attack vectors in cloud-robotic platforms, we propose three new DoS attacks, which manipulate the network resources, micro-architecture resources, and function parameters respectively. We conduct extensive evaluations and case studies to demonstrate the feasibility and severity of our techniques. We alert the robotics community to these catastrophic attacks on the safety and performance of cloud-robotic systems, and encourage building better defenses for higher reliability, in addition to automation and intelligence.},
  archive      = {J_ISCI},
  author       = {Yuan Xu and Gelei Deng and Tianwei Zhang and Han Qiu and Yungang Bao},
  doi          = {10.1016/j.ins.2021.06.063},
  journal      = {Information Sciences},
  pages        = {329-344},
  shortjournal = {Inf. Sci.},
  title        = {Novel denial-of-service attacks against cloud-based multi-robot systems},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph compression based on transitivity for neighborhood
query. <em>ISCI</em>, <em>576</em>, 312–328. (<a
href="https://doi.org/10.1016/j.ins.2021.06.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many graph compression methods have been introduced. One successful category of them is based on local decompression designed to answer neighborhood queries. These techniques mainly rely on local similarities of vertices. Besides, their performance is usually a function of graph sparsity. The proposed approach, in this paper, is a lossy compression technique used to answer neighborhood queries with a more general precondition, called transitivity. The output of this method is a sparse graph optimized to keep original adjacent vertices, in at most 2-distance from each other and vice versa. In other words, by traversing a compressed graph by depth of 2, from any desired vertex, its original adjacency list is reconstructed, with an acceptable error. This paper models an optimization problem to solve the inverse problem of finding the best compressed graph in order to minimize the reconstruction error. Then, this NP problem is approximated by a heuristic with a low degree polynomial time-complexity near to the complexity of the forward problem. The results of applying the proposed method on toy and real datasets are compared with the state of the art that improves compression ratio and performance with an acceptable query response time.},
  archive      = {J_ISCI},
  author       = {Amin Emamzadeh Esmaeili Nejad and Mansoor Zolghadri Jahromi and Mohammad Taheri},
  doi          = {10.1016/j.ins.2021.06.050},
  journal      = {Information Sciences},
  pages        = {312-328},
  shortjournal = {Inf. Sci.},
  title        = {Graph compression based on transitivity for neighborhood query},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PFLM: Privacy-preserving federated learning with membership
proof. <em>ISCI</em>, <em>576</em>, 288–311. (<a
href="https://doi.org/10.1016/j.ins.2021.05.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy-preserving federated learning is distributed machine learning where multiple collaborators train a model through protected gradients. To achieve robustness to users dropping out, existing practical privacy-preserving federated learning schemes are based on ( t , N )-threshold secret sharing. Such schemes rely on a strong assumption to guarantee security: the threshold t must be greater than half of the number of users. The assumption is so rigorous that in some scenarios the schemes may not be appropriate. Motivated by the issue, we first introduce membership proof for federated learning, which leverages cryptographic accumulators to generate membership proofs by accumulating user IDs. The proofs are issued in a public blockchain for users to verify. With membership proof, we propose a privacy-preserving federated learning scheme called PFLM. PFLM releases the assumption of threshold while maintaining the security guarantees. Additionally, we design a result verification algorithm based on a variant of ElGamal encryption to verify the correctness of aggregated results from the cloud server. The verification algorithm is integrated into PFLM as a part. Security analysis in a random oracle model shows that PFLM guarantees privacy against active adversaries. The implementation of PFLM and experiments demonstrate the performance of PFLM in terms of computation and communication.},
  archive      = {J_ISCI},
  author       = {Changsong Jiang and Chunxiang Xu and Yuan Zhang},
  doi          = {10.1016/j.ins.2021.05.077},
  journal      = {Information Sciences},
  pages        = {288-311},
  shortjournal = {Inf. Sci.},
  title        = {PFLM: Privacy-preserving federated learning with membership proof},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image style transfer for autonomous multi-robot systems.
<em>ISCI</em>, <em>576</em>, 274–287. (<a
href="https://doi.org/10.1016/j.ins.2021.06.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In deep learning, multi-robot systems intelligently cooperate to perform a complex task, and improve the performance of a single robot through communication, collaboration and sharing of information. Intelligent collaborative work makes the research and application of multi-robot systems develop rapidly. The traditional image style transfer algorithm mainly uses mathematical modeling to characterize the texture of the picture, and combines the content image with the style image to achieve the effect of style transfer. This style transfer algorithm ignores the edge distribution of the image, which makes the contour of the generated image blurred, and it takes a long time in the iterative process of style transfer, and the effect is poor. Therefore, this paper proposes a ceramic decoration pattern style migration algorithm based on the ESPCN model. The algorithm uses the Laplace operator to sharpen the image to highlight the edge distribution, and then uses downsampling to generate low-resolution images to reduce the iteration time of image style transfer. The final generated image uses ESPCN super-resolution reconstruction to reconstruct the low-resolution image. Converted to high-resolution images. The experimental results show that multiple image evaluation indicators show that the edge distribution of the generated image is clear, the iteration time is shortened, and the image quality and definition are improved.},
  archive      = {J_ISCI},
  author       = {Hua Huang and Xinxin Liu and Rong Yang},
  doi          = {10.1016/j.ins.2021.06.061},
  journal      = {Information Sciences},
  pages        = {274-287},
  shortjournal = {Inf. Sci.},
  title        = {Image style transfer for autonomous multi-robot systems},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-parameter constrained optimization using enhanced
quality-based cultural algorithm with novel influence and selection
schemes. <em>ISCI</em>, <em>576</em>, 242–273. (<a
href="https://doi.org/10.1016/j.ins.2021.06.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hybridization in context to Evolutionary Computation (EC) strives to combine operators, components, and the best merits of different EC paradigms, to form a new evolutionary algorithm that enjoys a statistically superior performance, compared to its ancestors, over a wide range of application-specific optimization problems . In this paper, we propose a simple yet powerful amalgam composed of a modified Cultural Algorithm (CA) that is supported with an Enhanced Levy Flight Search (ELFS) to guide the search and further promote the harmony between the explorative and exploitative capacities of the conventional techniques. The novel amalgam , denoted by q-a CA + m IS, utilizes a balanced search scheme where it employs an adapted Influence Function (IF) with a novel quality function that establishes a harmony between the Knowledge Sources (KSs) in the Belief Space (BS), and between the BS and other components in the hybrid to produce the most suitable knowledge needed for a certain search mode. The CA framework is reinforced with an updated Selection Function (SF) that employs a successful selection strategy that uses the extended situational knowledge for the future selection of individuals. The proposed algorithm is tested using more than 50 benchmark functions that are taken from the IEEE CEC’06, and the IEEE CEC’19 competitions on constrained real-parameter optimization. Moreover, three well-known engineering design problems are used to test the validity of the algorithm for the solution of complex real-life problems. The comparative study indicates that the q-a CA + m IS algorithm was able to obtain a statistically superior performance and scalability behavior over most of the considered functions in comparison with other state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Rami S. Al-Gharaibeh and Mostafa Z. Ali and Mohammad I. Daoud and Rami Alazrai and Heba Abdel-Nabi and Safaa Hriez and Ponnuthurai N. Suganthan},
  doi          = {10.1016/j.ins.2021.06.057},
  journal      = {Information Sciences},
  pages        = {242-273},
  shortjournal = {Inf. Sci.},
  title        = {Real-parameter constrained optimization using enhanced quality-based cultural algorithm with novel influence and selection schemes},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NeuNAC: A novel fragile watermarking algorithm for integrity
protection of neural networks. <em>ISCI</em>, <em>576</em>, 228–241. (<a
href="https://doi.org/10.1016/j.ins.2021.06.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The last decade has witnessed a massive deployment of Machine Learning tools in everyday life automated tasks. Neural Networks are nowadays in use in a growing number of application areas because of their excellent performances. Unfortunately, it has been shown by many researchers that they can be attacked and fooled in several different ways, and this can dangerously impair their ability to correctly perform their tasks. In this paper we describe a watermarking algorithm that can protect and verify the integrity of (Deep) Neural Networks when deployed in safety critical systems, such as autonomous driving systems or monitoring and surveillance systems.},
  archive      = {J_ISCI},
  author       = {Marco Botta and Davide Cavagnino and Roberto Esposito},
  doi          = {10.1016/j.ins.2021.06.073},
  journal      = {Information Sciences},
  pages        = {228-241},
  shortjournal = {Inf. Sci.},
  title        = {NeuNAC: A novel fragile watermarking algorithm for integrity protection of neural networks},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved dynamic multi-objective optimization approach
for nonlinear equation systems. <em>ISCI</em>, <em>576</em>, 204–227.
(<a href="https://doi.org/10.1016/j.ins.2021.06.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving nonlinear equation systems using evolutionary algorithms involves solving two key problems. One problem is how to efficiently optimize the nonlinear equations derived from the physical features, and the other problems is how to locate more than one optimal solution in a single trial. To address these two problems, an improved dynamic tri-objective differential evolution method is proposed in this paper. First, we transform a given system with any type and number of nonlinear equations into a dynamic tri-objective optimization problem , which targets the first problem. Second, we develop a self-adaptive ranking multi-objective differential evolution, which targets the second problem. In addition, a probability distribution-based local search is introduced, which aims to identify the optimal solutions with a high level of accuracy. Based on previous studies of numerical optimizations with multiple solutions, each component is elaborately proposed and developed, so it is more suitable for a nonlinear equation system. Experiments were conducted on 30 numerical examples collected from real-world applications. The statistical results are encouraging, showing that the performance of the proposed approach is better than that of eight state-of-the-art evolutionary algorithms , with respect to root ratio and success rate metrics.},
  archive      = {J_ISCI},
  author       = {Jing-Yu Ji and Man Leung Wong},
  doi          = {10.1016/j.ins.2021.06.070},
  journal      = {Information Sciences},
  pages        = {204-227},
  shortjournal = {Inf. Sci.},
  title        = {An improved dynamic multi-objective optimization approach for nonlinear equation systems},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fuzzy CMAC learning approach to image based visual
servoing system. <em>ISCI</em>, <em>576</em>, 187–203. (<a
href="https://doi.org/10.1016/j.ins.2021.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a fuzzy robotic joint controller using a cerebellar model articulation controller (CMAC) integrating a Takagi-Sugeno (T-S) framework with an online compensator for an articulated manipulator. The proposed controller is applied to image-based visual servoing (IBVS), including closed-loop feedback control and the kinematic Jacobian calculation. This approach learns a mapping from image feature errors for each joint’s velocity instead of the classical kinematics, thereby reducing the computational complexity and improving the self-regulation ability of the control system. These connecting weights of the cerebellar model learn offline, and an online compensator that uses reinforcement learning is developed to resolve system noise and uncertainties in an unknown environment . Compared with the classical inverse kinematics model, this approach does not need an excessive computational expense so that this proportional controller can be implemented in general scenarios with an eye-in-hand configuration. Experimental results show the proposed method can outperform the classical IBVS controller.},
  archive      = {J_ISCI},
  author       = {Maxwell Hwang and Yu-Jen Chen and Ming-Yi Ju and Wei-Cheng Jiang},
  doi          = {10.1016/j.ins.2021.06.029},
  journal      = {Information Sciences},
  pages        = {187-203},
  shortjournal = {Inf. Sci.},
  title        = {A fuzzy CMAC learning approach to image based visual servoing system},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-order error function designs to compute time-varying
linear matrix equations. <em>ISCI</em>, <em>576</em>, 173–186. (<a
href="https://doi.org/10.1016/j.ins.2021.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper devotes to solving time-varying linear matrix equations (TVLMEs) from the viewpoint of high-order neural networks . For this purpose, high-order zeroing neural network (ZNN) models are designed and studied to solve TVLMEs. Compared with the first-order ZNN model for TVLMEs, the proposed high-order ZNN models are based on the design of the high-order error functions, and different order choices will generate different high-order ZNN models. Two nonlinear activation functions [i.e., tunable activation function (TunAF) and sign-bi-power activation function (SBPAF)] are used to speedup the high-order ZNN models for achieving the finite-time convergence. Furthermore, the strict theoretical analyses are provided to show that high-order ZNN models have better properties (especially in terms of convergence), when the nonlinear activation functions are used. Two numerical simulations are given to reveal the superior convergence property of the proposed high-order ZNN models, as compared to the first-order ZNN model for solving TVLMEs.},
  archive      = {J_ISCI},
  author       = {Lin Xiao and Haiyan Tan and Jianhua Dai and Lei Jia and Wensheng Tang},
  doi          = {10.1016/j.ins.2021.06.038},
  journal      = {Information Sciences},
  pages        = {173-186},
  shortjournal = {Inf. Sci.},
  title        = {High-order error function designs to compute time-varying linear matrix equations},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient dictionary-based multi-view learning method.
<em>ISCI</em>, <em>576</em>, 157–172. (<a
href="https://doi.org/10.1016/j.ins.2021.06.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning can be considered as a kind of classification method which explores common and unique information among different views. For dictionary learning, it can identify informative features by learning sparse representation of samples and has great advantages for classification. However, there are few researches on the problem of multi-view learning with dictionary learning. In order to improve the performance of multi-view classification, we propose a new multi-view dictionary learning with consensus of view(MVDL-CV). First of all, we learn a particular dictionary for each view and obtain the sparse representation of the sample. Then, by utilizing the regularization term between two dictionaries in consensus, we can determine the similarity of samples and obtain the discriminative sparse representation, which can be helpful to construct the improved classifiers. Further, we obtain the solution of the model through an alternating convex optimization method and present the convergence analysis of MVDL-CV. In the experiments, we compare the proposed method with previous multi-view learning methods, and the experimental results show that MVDL-CV is a feasible and competitive method.},
  archive      = {J_ISCI},
  author       = {Bo Liu and Xiaodong Chen and Yanshan Xiao and Weibin Li and Laiwang Liu and Changdong Liu},
  doi          = {10.1016/j.ins.2021.06.069},
  journal      = {Information Sciences},
  pages        = {157-172},
  shortjournal = {Inf. Sci.},
  title        = {An efficient dictionary-based multi-view learning method},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the impact of node mobility on cascading failures
in spatial networks. <em>ISCI</em>, <em>576</em>, 140–156. (<a
href="https://doi.org/10.1016/j.ins.2021.06.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing researches on cascading failures mainly focus on static spatial networks, but rarely consider network scenarios where mobile nodes and static nodes coexist. Therefore, in this work, we explore the impact of node mobility on cascading failures in spatial networks. We first develop a cascading model for static-mobile spatial network systems. In this model, we use the general betweenness to characterize the load of static nodes in the network, and adopt the Gauss–Markov mobility model to generate the movement trajectory of mobile nodes. On this basis, we develop three node interaction modes ( i.e., all-connection mode, high-load priority mode and low-load priority mode) to characterize the interaction between static nodes and mobile nodes. Experimental results have shown that 1) unlike the traditional cascading process that is a continuous process, the cascading process of static-mobile spatial networks consists of multiple cascading processes that occur at different times; 2) expanding the network size and reducing the number of mobile nodes can help the network resist cascading failures; 3) there is a tolerance space for network configuration parameters . When the configuration parameters fall into this space, the network can avoid cascading failures; 4) among the three interaction modes, the network robustness in all-connection mode is the worst, followed by low-load priority mode, and finally high-load priority mode. The obtained results can provide theoretical guidance for users to establish a more robust static-mobile spatial network.},
  archive      = {J_ISCI},
  author       = {Xiuwen Fu and Wenfeng Li and Yongsheng Yang},
  doi          = {10.1016/j.ins.2021.06.067},
  journal      = {Information Sciences},
  pages        = {140-156},
  shortjournal = {Inf. Sci.},
  title        = {Exploring the impact of node mobility on cascading failures in spatial networks},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impulsive optimal control for drug treatment of influenza a
virus in the host with impulsive-axis equivalent model. <em>ISCI</em>,
<em>576</em>, 122–139. (<a
href="https://doi.org/10.1016/j.ins.2021.06.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at investigating the drug optimal problem for influenza A virus treatment with two main dilemmas: i) reducing the number of collected data and ii) considering the closed-loop system as a case of negative control direction with minimum drug usage. For decreasing the number of data, the equivalent model is established by the structure of fuzzy-rules emulated network using only one state-variable “viral titer” on the impulsive axis. The impulsive optimal controller is designed without any knowledge of patients and drug dynamics. As a result, the proposed controller can be utilized for a wide class of patients who have different drug reputations.Furthermore, the closed-loop performance is analyzed by the main theorem and the additional lemma is formulated for a case of negative control direction.Finally, the proposed scheme is validated by comparison tests with the fixed-dose FDA and the neuro-optimal controller.},
  archive      = {J_ISCI},
  author       = {C. Treesatayapun},
  doi          = {10.1016/j.ins.2021.06.051},
  journal      = {Information Sciences},
  pages        = {122-139},
  shortjournal = {Inf. Sci.},
  title        = {Impulsive optimal control for drug treatment of influenza a virus in the host with impulsive-axis equivalent model},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective evolutionary algorithm based on length
reduction for large-scale instance selection. <em>ISCI</em>,
<em>576</em>, 105–121. (<a
href="https://doi.org/10.1016/j.ins.2021.06.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance selection, as an important data pre-processing task, is widely used in supervised classification . Recently, a series of instance selection algorithms with different techniques have been suggested. Among them, evolutionary algorithms (EAs) have shown competitive performance. However, when the size of instance set is large, these EA-based algorithms may face great challenges on search efficiency and computational cost. To this end, in this paper, a multi-objective evolutionary algorithm based on length reduction, termed as LRIS, is proposed for large-scale instance selection, where a length reduction strategy is suggested to recursively shorten the length of each individual in the population, and improve the computational efficiency of LRIS greatly. Specifically, in the proposed length reduction strategy of LRIS, each gene in the individuals has a probability of being deleted, whose probability is obtained according to the importance of the corresponding instance in the instance set and the importance of the corresponding gene in the population. Then, two evolutionary operators (e.g. crossover and mutation) based on the length reduction strategy are developed to generate offspring population from the reduced population. In addition, an individual repairing operator is also designed to repair the length of over-reduced individuals. Experimental results on 12 large-scale data sets have demonstrated the efficiency and the effectiveness of the proposed LRIS in comparison with the state-of-the-art EA-based instance selection algorithms .},
  archive      = {J_ISCI},
  author       = {Fan Cheng and Feixiang Chu and Lei Zhang},
  doi          = {10.1016/j.ins.2021.06.052},
  journal      = {Information Sciences},
  pages        = {105-121},
  shortjournal = {Inf. Sci.},
  title        = {A multi-objective evolutionary algorithm based on length reduction for large-scale instance selection},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient balanced teaching-learning-based optimization
algorithm with individual restarting strategy for solving global
optimization problems. <em>ISCI</em>, <em>576</em>, 68–104. (<a
href="https://doi.org/10.1016/j.ins.2021.06.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Teaching-learning-based optimization (TLBO) is a population-based metaheuristic algorithm which simulates the teaching and learning mechanisms in a classroom. The TLBO algorithm has emerged as one of the most efficient and attractive optimization techniques. Even though the TLBO algorithm has an acceptable exploration capability and fast convergence speed, there may be a possibility to converge into a local optimum during solving complex optimization problems and there is a need to keep a balance between exploration and exploitation capabilities. Hence, a Balanced Teaching-Learning-Based Optimization (BTLBO) algorithm is proposed in this paper. The proposed BTLBO algorithm is a modification of the TLBO algorithm and it consists of four phases: (1) Teacher Phase in which a weighted mean is used instead of a mean value for keeping the diversity, (2) Learner Phase, which is same as the learner phase of basic TLBO algorithm, (3) Tutoring Phase, which is a powerful local search for exploiting the regions around the best ever found solution, and (4) Restarting Phase, which improves exploration capability by replacing inactive learners with new randomly initialized learners. An acceptable balance between the exploration and exploitation capabilities is achieved by the proposed BTLBO algorithm. To evaluate the performance of BTLBO algorithm, several experimental studies are conducted on standard benchmark suits and the results are compared with several TLBO variants and state-of-the-art population-based optimization algorithms. The results are in excellent agreement and confirm the efficiency of BTLBO algorithm with accelerated exploitation and exploration capabilities with an appropriate balance between such criteria for solving complex optimization problems.},
  archive      = {J_ISCI},
  author       = {Ahmad Taheri and Keyvan RahimiZadeh and Ravipudi Venkata Rao},
  doi          = {10.1016/j.ins.2021.06.064},
  journal      = {Information Sciences},
  pages        = {68-104},
  shortjournal = {Inf. Sci.},
  title        = {An efficient balanced teaching-learning-based optimization algorithm with individual restarting strategy for solving global optimization problems},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Output feedback stabilization of linear systems with
infinite distributed input and output delays. <em>ISCI</em>,
<em>576</em>, 54–67. (<a
href="https://doi.org/10.1016/j.ins.2021.06.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the output feedback stabilization problem of linear systems with infinite distributed delays in their inputs and outputs. A low gain observer is proposed to estimate the state of the concerned system with infinite distributed delays in its inputs and outputs. The observer based output feedback controller is then developed. It is shown that the resulting closed loop system is globally asymptotically stable . It should be pointed out that the output feedback control problem of linear systems with infinite distributed input and output delays is first time investigated to the best of our knowledge. Finally, some numerical examples are presented to demonstrate the effectiveness of the proposed controller.},
  archive      = {J_ISCI},
  author       = {Qianghui Zhou and Xiang Xu and Lu Liu and Gang Feng},
  doi          = {10.1016/j.ins.2021.06.060},
  journal      = {Information Sciences},
  pages        = {54-67},
  shortjournal = {Inf. Sci.},
  title        = {Output feedback stabilization of linear systems with infinite distributed input and output delays},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Affine invariance of meta-heuristic algorithms.
<em>ISCI</em>, <em>576</em>, 37–53. (<a
href="https://doi.org/10.1016/j.ins.2021.06.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An algorithm whose performance depends on the objective function being aligned with a privileged coordinate system is a poor choice in general because it is unlikely that the optimal orientation will be known in advance. In this paper, a property of meta -heuristic algorithms, named affine invariance, is introduced to verify whether the algorithm is depended on the privileged coordinate system or not. The concept of affine invariance is described in detail, and some classical algorithms, efficient in most test and actual problems, are proved to be affine invariant. While some recent algorithms in the literature are proved to be not affine invariant. As a conclusion, particle swarm optimization (PSO), differential evolution (DE) and optimal foraging algorithm (OFA) are affine invariant, while grey wolf optimizer (GWO), sine cosine algorithm (SCA) and butterfly optimization algorithm (BOA) are not affine invariant. Furthermore, comparison tests are designed to support the theoretical analysis results. In these tests, same random numbers and initial population are used to avoid the influence of randomness, thus, the conclusion is reliable.},
  archive      = {J_ISCI},
  author       = {ZhongQuan Jian and GuangYu Zhu},
  doi          = {10.1016/j.ins.2021.06.062},
  journal      = {Information Sciences},
  pages        = {37-53},
  shortjournal = {Inf. Sci.},
  title        = {Affine invariance of meta-heuristic algorithms},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrating multiple genomic imaging data for the study of
lung metastasis in sarcomas using multi-dimensional constrained joint
non-negative matrix factorization. <em>ISCI</em>, <em>576</em>, 24–36.
(<a href="https://doi.org/10.1016/j.ins.2021.06.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrative analysis of histopathology images and genomic data enables the discovery of potential biomarkers and multimodal association patterns. However, few studies have established effective association models for complex diseases, such as sarcoma, by combining histopathological images with multiple genetic variation data. Here, we present an integrative multiple genomic imaging framework called multi-dimensional constrained joint non-negative matrix factorization (MDJNMF) to identify modules related to lung metastasis of sarcomas based on sample-matched whole-solid image, DNA methylation , and copy number variation features. Three types of feature matrices were projected onto a common feature space, in which heterogeneous variables with large coefficients in the same projected direction form a common module. The correlation between image features and genetic variation features is used as network-regularized constraints to improve the module accuracy. Sparsity and orthogonal constraints are utilized to achieve the modular sparse solution . Multi-level analysis indicates that our method effectively discovers biologically functional modules associated with sarcoma or lung metastasis. The representative module reveals a significant correlation between image features and genetic variation features and excavates potential diagnostic biomarkers. In summary, the proposed method provides new clues for identifying association patterns and biomarkers using multiple types of data sources for other diseases.},
  archive      = {J_ISCI},
  author       = {Jin Deng and Weiming Zeng and Sizhe Luo and Wei Kong and Yuhu Shi and Ying Li and Hua Zhang},
  doi          = {10.1016/j.ins.2021.06.058},
  journal      = {Information Sciences},
  pages        = {24-36},
  shortjournal = {Inf. Sci.},
  title        = {Integrating multiple genomic imaging data for the study of lung metastasis in sarcomas using multi-dimensional constrained joint non-negative matrix factorization},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning risk-mediated traversability maps in unstructured
terrains navigation through robot-oriented models. <em>ISCI</em>,
<em>576</em>, 1–23. (<a
href="https://doi.org/10.1016/j.ins.2021.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In robotic navigation, safety and efficiency play an important role and must be evaluated together. This paper proposes a simple and efficient method to derive the traversability maps of unstructured environments and the optimal path to be followed to reach target locations based on the specific characteristics of different types of robots available. The optimal solution minimises the path length while maintaining the risk associated with that path below the maximum acceptable upper bound. The ability of each robot to traverse terrains with specific characteristics is formalised and modelled using simple and efficient neural networks and trained in a dynamic simulation environment . The proposed shallow network topology achieves results, in terms of accuracy, that are comparable with other standard classifiers and more complex deep networks. Applying this procedure to different robotic structures, the best system within the team (wheeled, legged, and hybrid) can be selected to accomplish a specific assigned task. The proposed strategy, together with the obtained simulation results is presented, carefully analysed, and then compared using real-life simulated scenarios.},
  archive      = {J_ISCI},
  author       = {Paolo Arena and Luca Patanè and Salvatore Taffara},
  doi          = {10.1016/j.ins.2021.06.007},
  journal      = {Information Sciences},
  pages        = {1-23},
  shortjournal = {Inf. Sci.},
  title        = {Learning risk-mediated traversability maps in unstructured terrains navigation through robot-oriented models},
  volume       = {576},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximum feasibility estimation. <em>ISCI</em>, <em>575</em>,
793–801. (<a href="https://doi.org/10.1016/j.ins.2021.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a previous paper (Kim, 2019), an analytical framework based on the constraint satisfaction problems was proposed to reveal the characteristics of households using event logs from smart door lock systems. This work provides a more rigorous justification for the previous approach. This paper proposes a novel parameter estimation method called the maximum feasibility estimation (MFE). The MFE does not rely on any assumption about the parametric family of probability densities from which a random observation is drawn. Instead, we assume that constraints are imposed on observations and that some of the constraints are a function of a parameter of interest. The proposed estimator maximizes the feasible region, a set of all possible observations that satisfy those constraints. The method proposed is validated using synthetic data as well as real streaming event log data.},
  archive      = {J_ISCI},
  author       = {Sungil Kim},
  doi          = {10.1016/j.ins.2021.04.012},
  journal      = {Information Sciences},
  pages        = {793-801},
  shortjournal = {Inf. Sci.},
  title        = {Maximum feasibility estimation},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Adaptive fuzzy asymptotical tracking control of nonlinear
systems with unmodeled dynamics and quantized actuator. <em>ISCI</em>,
<em>575</em>, 779–792. (<a
href="https://doi.org/10.1016/j.ins.2018.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the problem of adaptive fuzzy asymptotical quantized tracking control of non-strict-feedback systems with unmodeled dynamics. A dynamic signal is used to cope with the unmodeled dynamics and fuzzy systems are introduced to approximate the packaged unknown nonlinearities . Based on backstepping technique and fuzzy approximation property, a systemic fuzzy adaptive control scheme is proposed. By the utilization of Lyapunov theory , the semi-globally uniformly ultimate boundedness of all closed-loop system signals and asymptotical tracking performance are guaranteed. The main contributions of this work are two aspects: (i) a backstepping-based quantized control algorithm is firstly extended to nonlinear systems with unmodeled dynamics and non-strict-feedback structure; (ii) the semi-globally asymptotic tracking control scheme is independent of the quantized parameter. Simulation results verify the presented control approach.},
  archive      = {J_ISCI},
  author       = {Huanqing Wang and Peter Xiaoping Liu and Xuejun Xie and Xiaoping Liu and Tasawar Hayat and Fuad E. Alsaadi},
  doi          = {10.1016/j.ins.2018.04.011},
  journal      = {Information Sciences},
  pages        = {779-792},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy asymptotical tracking control of nonlinear systems with unmodeled dynamics and quantized actuator},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adapting topic map and social influence to the personalized
hybrid recommender system. <em>ISCI</em>, <em>575</em>, 762–778. (<a
href="https://doi.org/10.1016/j.ins.2018.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A recommender system utilizes information filtering techniques to help users obtain accurate information effectively and efficiently. The existing recommender systems, however, recommend items based on the overall ratings or the click-through rate, and emotions expressed by users are neglected. Conversely, the cold-start problem and low model scalability are the two main problems with recommender systems. The cold-start problem is encountered when the system lacks initial rating. Low model scalability indicates that a model is incapable of coping with high-dimensional data. These two problems may mislead the recommender system , and thus, users will not be satisfied with the recommended items. A hybrid recommender system is proposed to mitigate the negative effects caused by these problems. Additionally, ontologies are applied to integrate the extracted features into topics to reduce dimensionality. Topics mentioned in the items are displayed in the form of a topic map, and users can refer to these similar items for further information.},
  archive      = {J_ISCI},
  author       = {Wang Hei-Chia and Jhou Hsu-Tung and Tsai Yu-Shan},
  doi          = {10.1016/j.ins.2018.04.015},
  journal      = {Information Sciences},
  pages        = {762-778},
  shortjournal = {Inf. Sci.},
  title        = {Adapting topic map and social influence to the personalized hybrid recommender system},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel and distributed association rule mining in life
science: A novel parallel algorithm to mine genomics data.
<em>ISCI</em>, <em>575</em>, 747–761. (<a
href="https://doi.org/10.1016/j.ins.2018.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Association rule mining (ARM) is largely employed in several scientific areas and application domains, and many different algorithms for learning association rules from databases have been introduced. Despite the presence of many existing algorithms, there is still room for the introduction of novel approaches tailored for novel kinds of datasets. Because often the efficiency of such algorithms depends on the type of analyzed dataset . For instance, classical ARM algorithms present some drawbacks for biological datasets produced by microarray technologies in particular containing Single Nucleotide Polymorphisms (SNPs). In particular classical algorithms require large execution times also with small datasets. Therefore the possibility to improve the performance of such algorithms by leveraging parallel computing is a growing research area. The main contributions of this paper are: a comparison among different sequential, parallels and distributed ARM techniques, and the presentation of a novel ARM algorithm, named Balanced Parallel Association Rule Extractor from SNPs (BPARES), that employs parallel computing and a novel balancing strategy to improve response time. BPARES improves performance without loosing in accuracy as well as it handles more efficiently the available computational power and reduces the memory consumption.},
  archive      = {J_ISCI},
  author       = {Giuseppe Agapito and Pietro Hiram Guzzi and Mario Cannataro},
  doi          = {10.1016/j.ins.2018.07.055},
  journal      = {Information Sciences},
  pages        = {747-761},
  shortjournal = {Inf. Sci.},
  title        = {Parallel and distributed association rule mining in life science: A novel parallel algorithm to mine genomics data},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quaternion lifting scheme applied to the classification of
motion data. <em>ISCI</em>, <em>575</em>, 732–746. (<a
href="https://doi.org/10.1016/j.ins.2018.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a new method of classification of skeleton-based motion data has been introduced. In the first stage, we performed multiscale feature extraction of rotational data. It is based on the proposed linear quaternion lifting scheme, with respect to the rotations coded by unit quaternions , which computes each scale based on the spherical linear interpolation (SLERP) prediction function and preserves the average signal value on each scale. Consequently, motion descriptors are extracted as quaternion attributes on different scales. The final recognition is performed by the nearest neighbor and minimum distance classifiers, adapted to support nonscalar features. Because of dimensionality of obtained descriptors, an attribute selection with respect to the multiresolution data has been proposed. It takes into consideration a specified number of resolutions, which is similar to low-pass filtering of the frequency domain. This method is utilized to solve the gait-based human identification problem. To validate such an application, a database containing data from 30 subjects was collected at the Human Motion Laboratory of the Polish-Japanese Academy of Information Technology (PJAIT). The obtained results were found to be satisfactory. In the best case, over 96\% precision with only seven misclassified gaits of 178 samples was achieved.},
  archive      = {J_ISCI},
  author       = {Agnieszka Szczęsna and Adam Świtoński and Janusz Słupik and Hafed Zghidi and Henryk Josiński and Konrad Wojciechowski},
  doi          = {10.1016/j.ins.2018.09.006},
  journal      = {Information Sciences},
  pages        = {732-746},
  shortjournal = {Inf. Sci.},
  title        = {Quaternion lifting scheme applied to the classification of motion data},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Multiattribute decision making based on new score function
of interval-valued intuitionistic fuzzy values and normalized score
matrices. <em>ISCI</em>, <em>575</em>, 714–731. (<a
href="https://doi.org/10.1016/j.ins.2021.07.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel multiattribute decision making (MADM) method on the basis of the proposed score function of interval-valued intuitionistic fuzzy values (IVIFVs) and normalized score matrices . Firstly, it calculates the score value of each IVIFV in the decision matrix (DM) based on the proposed score function of IVIFVs to construct the score matrix. Then, it constructs the normalized score matrix based on the obtained score matrix. Then, it computes the optimal weight of the interval-valued intuitionistic fuzzy (IVIF) weight of each attribute. Then, based on the obtained normalized score matrix and the obtained optimal weight of the IVIF weight of each attribute, it constructs the weighted normalized DM. Then, based on the obtained weighted normalized DM, it calculates the weighted score value of each alternative. Finally, it ranks the alternatives based on the weighted score values of the alternatives. The larger the weighted score value of an alternative, the better the preference order (PO) of the alternative. The proposed MADM method overcomes the drawbacks of the existing MADM methods. The proposed MADM method provides a very useful way to us for dealing with MADM problems in IVIF environments.},
  archive      = {J_ISCI},
  author       = {Shyi-Ming Chen and Kai-Yi Tsai},
  doi          = {10.1016/j.ins.2021.07.074},
  journal      = {Information Sciences},
  pages        = {714-731},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making based on new score function of interval-valued intuitionistic fuzzy values and normalized score matrices},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Position control with zero residual vibration for two
degrees-of-freedom flexible systems based on motion trajectory
optimization. <em>ISCI</em>, <em>575</em>, 698–713. (<a
href="https://doi.org/10.1016/j.ins.2021.07.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero residual vibration (RV) in the position control of a flexible system is difficult to achieve because this system has low stiffness and underactuated feature. In this paper, we present a position control strategy to achieve zero RV in the position control of two degrees-of-freedom (DOF) flexible systems. First, a general dynamic model for two-DOF flexible systems is established. Next, we transform the position control with zero RV to motion planning and tracking control . Based on the position control objective with zero RV, three constraints for the desired system trajectory are given. To make the desired system trajectory satisfy these three constraints, we propose a motion trajectory optimization method. Specifically, we plan a forward system trajectory and a reverse system trajectory based on bidirectional trajectory planning method. Then, the rewinding strategy and the trajectory optimization based on genetic algorithm are used to connect these two system trajectories and to obtain a complete desired system trajectory. Finally, a sliding mode tracking controller is designed to make the system track this desired system trajectory. In this way, the system can reach its target-rest-position with zero RV. The effectiveness and superiority of the proposed control strategy are demonstrated in simulations.},
  archive      = {J_ISCI},
  author       = {Qingxin Meng and Xuzhi Lai and Ze Yan and Yawu Wang and Min Wu},
  doi          = {10.1016/j.ins.2021.07.086},
  journal      = {Information Sciences},
  pages        = {698-713},
  shortjournal = {Inf. Sci.},
  title        = {Position control with zero residual vibration for two degrees-of-freedom flexible systems based on motion trajectory optimization},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Peak temperature analysis and optimization for pipelined
hard real-time systems. <em>ISCI</em>, <em>575</em>, 666–697. (<a
href="https://doi.org/10.1016/j.ins.2021.07.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study aims to minimize the peak temperature for pipelined multi-core systems while providing hard real-time guarantees. Periodic Thermal Management (PTM) is adopted to control the temperature by periodically switching each pipelined stage into a lower power mode. The Pay-Burst-Only-Once principle from Real-Time Calculus theory is used in reverse to transform real-time guarantees into the constraints of the PTM schemes applied to all stages. We systematically study the peak temperature under PTM and present two algorithms to calculate it with different levels of accuracy and speed. A greedy principle-based heuristic method is proposed to solve the peak temperature optimization problem. Experiments are conducted on an Intel processor with physical temperature sensors . The results demonstrate that our approaches optimize the peak temperature more effectively than the sub-deadline partition approach. Simulations for scenarios involving more stages reveal that the proposed algorithms are scalable with respect to the number of stages.},
  archive      = {J_ISCI},
  author       = {Long Cheng and Kai Huang and Liang Mi and Gang Chen and Alois Knoll and Xiaoqin Zhang},
  doi          = {10.1016/j.ins.2021.07.062},
  journal      = {Information Sciences},
  pages        = {666-697},
  shortjournal = {Inf. Sci.},
  title        = {Peak temperature analysis and optimization for pipelined hard real-time systems},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-cue based four-stream 3D ResNets for video-based
action recognition. <em>ISCI</em>, <em>575</em>, 654–665. (<a
href="https://doi.org/10.1016/j.ins.2021.07.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition is one of the important computer vision tasks, which has many applications. This paper proposes a Multi-cue based Four-stream 3D ResNets (MF3D) model for action recognition. The proposed MF3D model contains four streams: a video saliency stream, an appearance stream, a motion stream and an audio stream . Four cues ( i.e. the appearance cue , the motion cue, the video saliency cue and audio cue) are captured by the four streams of our proposed MF3D model. In addition, three different connections between different streams are injected, which can transfer different cues between different streams to obtain more effective spatiotemporal features. Experiments are conducted on the Kinetics and Kinetics-Sounds datasets, and the results verify that our MF3D model is effective and outperforms current existing models.},
  archive      = {J_ISCI},
  author       = {Lei Wang and Xiaoguang Yuan and Ming Zong and Yujun Ma and Wanting Ji and Mingzhe Liu and Ruili Wang},
  doi          = {10.1016/j.ins.2021.07.079},
  journal      = {Information Sciences},
  pages        = {654-665},
  shortjournal = {Inf. Sci.},
  title        = {Multi-cue based four-stream 3D ResNets for video-based action recognition},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy decentralized output feedback event-triggered control
for interval type-2 fuzzy systems with saturated inputs. <em>ISCI</em>,
<em>575</em>, 639–653. (<a
href="https://doi.org/10.1016/j.ins.2021.07.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the fuzzy decentralized output feedback event-triggered control problem for the interval type–2 Takagi-Sugeno (IT2 T-S) fuzzy interconnected system with actuator saturation. Firstly, a state decentralized observer is designed and an event-triggered mechanism is established by using the state estimation errors. Secondly, the saturated inputs are represented by a polyhedron model, and then a fuzzy decentralized output feedback even-triggered control approach is developed via the parallel distributed compensation (PDC) algorithm. The asymptotic stabilization sufficient conditions of the closed-loop system are derived by employing Lyapunov theory and linear matrix inequalities (LMIs) method. Finally, a numerical example is provided to verify the feasibility of the developed control scheme.},
  archive      = {J_ISCI},
  author       = {Wenting Song and Shaocheng Tong},
  doi          = {10.1016/j.ins.2021.07.070},
  journal      = {Information Sciences},
  pages        = {639-653},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy decentralized output feedback event-triggered control for interval type-2 fuzzy systems with saturated inputs},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised rotation forest based on ensemble margin
theory for the classification of hyperspectral image with limited
training data. <em>ISCI</em>, <em>575</em>, 611–638. (<a
href="https://doi.org/10.1016/j.ins.2021.06.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive semi-supervised rotation forest (SSRoF) algorithm is proposed for the classification of hyperspectral images with limited training data. Our proposition is based on Rotation Forest (RoF), a classifying technique that has proved to be remarkably accurate in the context of high-dimensional data. It is adapted to the semi-supervised context, by increasing the number of training instances in the learning stage, with high-quality unlabeled samples mined using ensemble margin. SMOTE is adopted to overcome the class imbalance problem . Out-Of-Bag (OOB) instances are used in a second phase to figure out the optimal number of samples to be added to the training set. Five ensemble methods and five semi-supervised methods are employed as comparisons. The results on three real hyperspectral remote sensing datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Wei Feng and Yinghui Quan and Gabriel Dauphin and Qiang Li and Lianru Gao and Wenjiang Huang and Junshi Xia and Wentao Zhu and Mengdao Xing},
  doi          = {10.1016/j.ins.2021.06.059},
  journal      = {Information Sciences},
  pages        = {611-638},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised rotation forest based on ensemble margin theory for the classification of hyperspectral image with limited training data},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Deep discriminative domain adaptation. <em>ISCI</em>,
<em>575</em>, 599–610. (<a
href="https://doi.org/10.1016/j.ins.2021.07.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation studies the problem of how to transfer knowledge across different domains where the source domain with rich labeled source samples and target domain with less or even no labeled target samples are drawn from different probability distribution. A prevailing strategy is to generate transferable features cross-domain, which induces deficient knowledge transfer in learning process, especially close to the input end. Moreover, when target samples distributed far their corresponding class centers, or near the edge of the clusters, only using learned source samples features to predict target samples class which may easily brings about misclassification . Targeting to deal with these issues, we propose Deep Discriminative Domain Adaptation (DDDA) method, which jointly minimizes the supervised classification loss of annotated source examples, the unsupervised center alignment and correlation alignment losses measured on both convolutional layers and fully connected layers with help of attention mechanism . The multi-layer transfer mechanism complementary strengthens each individual transfer component, and markedly improves the generalization ability of transfer models. A series of experiments conducted on several standard datasets validate that the proposed method consistently outperforms contemporary adaptation approaches.},
  archive      = {J_ISCI},
  author       = {Changchun Zhang and Qingjie Zhao},
  doi          = {10.1016/j.ins.2021.07.073},
  journal      = {Information Sciences},
  pages        = {599-610},
  shortjournal = {Inf. Sci.},
  title        = {Deep discriminative domain adaptation},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep low-rank matrix factorization with latent correlation
estimation for micro-video multi-label classification. <em>ISCI</em>,
<em>575</em>, 587–598. (<a
href="https://doi.org/10.1016/j.ins.2021.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, micro-videos are becoming an increasingly prevailing form of user-generated contents (UGCs) on various social platforms. Several studies have been conducted to explore the semantics of micro-videos and the behavior of individuals for various tasks, such as venue categorization, popularity prediction, and personalized recommendation. However, few studies have been dedicated to solving micro-video multi-label classification. More importantly, learning intrinsic and robust feature representations for micro-videos is still a complicated and challenging problem. In this paper, we propose a deep matrix factorization with latent correlation estimation (DMFLCE) for micro-video multi-label classification. In DMFLCE, we develop a deep matrix factorization component constrained by a low-rank constraint to learn the lowest-rank representations for micro-videos and the intrinsic characterizations for latent attributes simultaneously. To explicitly exhibit the dependencies of the learned latent attributes and labels for improved classification performance, we construct two inverse covariance estimation components to automatically encode correlation patterns with respect to the latent attributes and labels. Experiments conducted on a publicly available large-scale micro-video dataset demonstrate the effectiveness of our proposed method compared with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yuting Su and Junyu Xu and Daozheng Hong and Fugui Fan and Jing Zhang and Peiguang Jing},
  doi          = {10.1016/j.ins.2021.07.021},
  journal      = {Information Sciences},
  pages        = {587-598},
  shortjournal = {Inf. Sci.},
  title        = {Deep low-rank matrix factorization with latent correlation estimation for micro-video multi-label classification},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint design of control policy and network scheduling policy
for wireless networked control systems: Theory and application.
<em>ISCI</em>, <em>575</em>, 563–586. (<a
href="https://doi.org/10.1016/j.ins.2021.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a wireless networked control system (WNCS) with N ⩾ 2 sub-systems sharing a common wireless channel. Each sub-system consists of a plant and a controller and the control message must be delivered from the controller to the plant through the shared wireless channel. The wireless channel is unreliable due to shadowing and fading. As a result, a packet can be successfully delivered in a slot with a certain probability . A network scheduling policy determines how to transmit those control messages generated by such N sub-systems and directly influences the transmission delay of control messages. We first consider the case that all sub-systems have the same sampling period. We characterize the stability condition of such a WNCS under the joint design of the control policy and the network scheduling policy by means of 2 N linear inequalities . For scalar systems, we further simplify the stability condition into only one linear inequality for two special cases: the perfect-channel case and the symmetric-structure case. One main technical contribution of this paper is to introduce the recent results on the network scheduling policy design for delay-constrained wireless communications into the analysis of WNCSs. In addition, we have applied our theory to a practical problem of stabilizing multiple pendulum-cart sub-systems over a shared wireless channel. Simulations show that our joint design effectively achieves better performance than existing baseline.},
  archive      = {J_ISCI},
  author       = {Lei Deng and Cheng Tan and Fangfang Zhang and Wing Shing Wong},
  doi          = {10.1016/j.ins.2021.06.023},
  journal      = {Information Sciences},
  pages        = {563-586},
  shortjournal = {Inf. Sci.},
  title        = {Joint design of control policy and network scheduling policy for wireless networked control systems: Theory and application},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementing evolutionary optimization on actual quantum
processors. <em>ISCI</em>, <em>575</em>, 542–562. (<a
href="https://doi.org/10.1016/j.ins.2021.06.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces a new evolutionary algorithm with the support of an actual quantum processor, a computing device which uses phenomena from quantum mechanics to enable a considerable speed-up in computation. In particular, the proposed approach uses quantum superposition and entanglement to implement quantum evolutionary concepts such as quantum chromosome, entangled crossover, rotation mutation, and quantum elitism, to efficiently perform genetic evolution on quantum devices , and converge towards proper sub-optimal solutions of a given optimization problem . The proposed quantum genetic algorithm has been implemented by using a hybrid hardware architecture, where classical processors interact with the family of quantum processors provided by the IBM Q Experience® initiative. As shown in the experimental section, the proposed quantum genetic algorithm’s performance highlights that the synergy between quantum and evolutionary computation results in a new and promising bio-inspired optimization strategy .},
  archive      = {J_ISCI},
  author       = {Giovanni Acampora and Autilia Vitiello},
  doi          = {10.1016/j.ins.2021.06.049},
  journal      = {Information Sciences},
  pages        = {542-562},
  shortjournal = {Inf. Sci.},
  title        = {Implementing evolutionary optimization on actual quantum processors},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved DPoS consensus mechanism in blockchain based on
PLTS for the smart autonomous multi-robot system. <em>ISCI</em>,
<em>575</em>, 528–541. (<a
href="https://doi.org/10.1016/j.ins.2021.06.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the development of robot technology, smart autonomous multi-robot systems face different security problems such as data loss and vulnerabilities. However, the robot information stored in blockchain can be more transparent and effective at ensuring the security of the robot system due to the decentralization, tamper-proof and anonymity of blockchain. In the architectural composition of blockchain, Delegated Proof of Stake (DPoS) consensus mechanism is playing a critical role with more decentralization, lower energy consumption and faster confirmation speed. Similar to the board voting, the holders cast a certain number of delegates to perform verification and block generating on their behalf in DPoS. In order to improve the efficiency and flexibility of DPoS consensus mechanism, we propose an improved DPoS consensus mechanism based on the Probabilistic Linguistic Term Set (PLTS) for the smart autonomous multi-robot system. By adding voting options for nodes, the Voting Algorithm with Probabilistic Linguistic Information (VAPLI) calculates the score and deviation degree of each node after tabulating the voting results. The selection of a delegate is based on the comparison of the score and deviation degree. Finally, we explore the model implementation of the improved DPoS consensus mechanism, and verify its feasibility and effectiveness using examples.},
  archive      = {J_ISCI},
  author       = {Jun Liu and Mingyue Xie and Shuyu Chen and Chuang Ma and Qianhong Gong},
  doi          = {10.1016/j.ins.2021.06.046},
  journal      = {Information Sciences},
  pages        = {528-541},
  shortjournal = {Inf. Sci.},
  title        = {An improved DPoS consensus mechanism in blockchain based on PLTS for the smart autonomous multi-robot system},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient consensus reaching framework for large-scale
social network group decision making and its application in urban
resettlement. <em>ISCI</em>, <em>575</em>, 499–527. (<a
href="https://doi.org/10.1016/j.ins.2021.06.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban resettlement projects involve a large number of stakeholders and impose tremendous cost. Developing resettlement plans and reaching an agreement amongst stakeholders about resettlement plans at a reasonable cost are some of the key issues in urban resettlement. From this perspective, urban resettlement is a typical large-scale group decision-making (GDM) problem, which is challenging because of the scale of participants and the requirement of high consensus levels. Observing that residents who are affected by a resettlement project often have tight social connections, this study proposes a framework to improve the consensus reaching and uses the minimum consensus cost to reduce the total cost for urban resettlement projects with more than 1000 participants. Firstly, we construct a network topology that consists of two layers to deal with incomplete social relationships amongst large-scale participants. An inner layer consists of participants whose preference similarities and trust relations are known. Meanwhile, an outside layer includes participants whose trust relations cannot be determined. Secondly, we develop a classification method to classify participants into small subgroups based on their preference similarities. We can then connect the participants whose trust relations are unknown (the outside layer) with the ones in the inner layer using the classification results . To facilitate effective consensus reaching in large-scale social network GDM, we develop a three-step approach to reconcile conflicting preferences and accelerate the consensus process at the minimum cost. A real-life urban resettlement example is used to validate the proposed approach. Results show that the proposed approach can reduce the total consensus cost compared with the other two practices used in the actual urban resettlement operations.},
  archive      = {J_ISCI},
  author       = {Xiangrui Chao and Gang Kou and Yi Peng and Enrique Herrera-Viedma and Francisco Herrera},
  doi          = {10.1016/j.ins.2021.06.047},
  journal      = {Information Sciences},
  pages        = {499-527},
  shortjournal = {Inf. Sci.},
  title        = {An efficient consensus reaching framework for large-scale social network group decision making and its application in urban resettlement},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive disturbance observer-based event-triggered fuzzy
control for nonlinear system. <em>ISCI</em>, <em>575</em>, 485–498. (<a
href="https://doi.org/10.1016/j.ins.2021.06.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the issue of tracking control of nonlinear system with external disturbance , an event-triggered fuzzy backstepping sliding-mode control strategy is proposed. Firstly, a fuzzy state estimator is designed to estimate the unmeasurable state, and a sliding-mode disturbance observer is presented on the estimation error. In which, consider the conservativeness of the observer parameter, a parameter adaptation law with a double nested structure is proposed to mitigate chattering problems caused by parameter conservativeness . Then an event-triggered mechanism along with backstepping control and sliding-mode strategy is designed to achieve tracking control and save the network resources, and the Zeno phenomenon can be avoided. Furthermore, the backstepping law combines with Lyapunov theory is used to prove that the tracking error can converge to a small bounded set and all the signals of closed-loop plant are bounded. Finally, simulation results are carried out to illustrate the potential of designed approaches.},
  archive      = {J_ISCI},
  author       = {Meng Li and Yong Chen and Yuezhi Liu},
  doi          = {10.1016/j.ins.2021.06.055},
  journal      = {Information Sciences},
  pages        = {485-498},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive disturbance observer-based event-triggered fuzzy control for nonlinear system},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic multiobjective optimization driven by inverse
reinforcement learning. <em>ISCI</em>, <em>575</em>, 468–484. (<a
href="https://doi.org/10.1016/j.ins.2021.06.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the widespread interest in dynamic multiobjective optimization in real-world applications, more and more approaches exploiting machine learning are deployed to tackle this type of problems. Unfortunately, recent works do not make full use of the data obtained during the optimization process, which could be benefit for model training thereby mining the dynamic characteristics of the underlying problem. To address this issue, this paper proposes a dynamic multiobjective evolutionary algorithm driven by inverse reinforcement learning to solve the dynamic multiobjective optimization problems. IRL is widely used to recover the unknown reward function, making it possible to perform at an expert level. The notable features of the proposed algorithm mainly consist of data-driven evolutionary technique, which uses inverse reinforcement learning as a surrogate-assisted model for model training. This design makes full use of the surrogate management strategy based on inverse reinforcement learning to optimize the reward function within a reinforcement learning framework. At the same time, the algorithm can generate a promising policy based on limited training data during the optimization process to achieve better algorithm evolution and guide the search. The experimental results on the benchmark problems validate that the proposed algorithm is effective in dealing with dynamic multiobjective optimization.},
  archive      = {J_ISCI},
  author       = {Fei Zou and Gary G. Yen and Chen Zhao},
  doi          = {10.1016/j.ins.2021.06.054},
  journal      = {Information Sciences},
  pages        = {468-484},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic multiobjective optimization driven by inverse reinforcement learning},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient implementation and parallelization of fuzzy
density based clustering. <em>ISCI</em>, <em>575</em>, 454–467. (<a
href="https://doi.org/10.1016/j.ins.2021.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a commonly used tool for data management and analysis. One of the prominent group of clustering methods consists of the density-based clustering algorithms . The use of fuzzy neighborhood functions for density-based clustering algorithms are known to significantly improve the robustness, such that choosing neighborhood parameters is rather easy for the user. On the other hand, because of the overhead of the fuzzy calculations, they demand higher computing resources. This study discusses how FN-DNSCAN -a fuzzy density-based clustering algorithm- can be implemented efficiently. A rather specific FN-DBSCAN algorithm that adopts techniques used to improve classical density-based clustering algorithms is introduced. Also, a parallel version of the algorithm is proposed and their implementation details are discussed. The proposed algorithms are tested in a set of comparative experiments , along with a straightforward FN-DBSCAN implementation and a curious but unsafe modification of the parallel algorithm . The results of the experiments that are conducted in a modest parallel computing environment of 32 processing units, show a wide variety of differences in relative speed-ups ranging from 2 to 850 times.},
  archive      = {J_ISCI},
  author       = {Can Atilgan and Baris Tekin Tezel and Efendi Nasiboglu},
  doi          = {10.1016/j.ins.2021.06.044},
  journal      = {Information Sciences},
  pages        = {454-467},
  shortjournal = {Inf. Sci.},
  title        = {Efficient implementation and parallelization of fuzzy density based clustering},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constructions of balanced boolean functions on even number
of variables with maximum absolute value in autocorrelation spectra
&lt;2n2☆. <em>ISCI</em>, <em>575</em>, 437–453. (<a
href="https://doi.org/10.1016/j.ins.2021.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The autocorrelation properties of Boolean functions are closely related to the Shannon’s concept of diffusion and can be accompanied with other cryptographic criteria (such as high nonlinearity and algebraic degree) for ensuring an overall robustness to various cryptanalytic methods. In a series of recent articles [14,9,15], the design methods of n-variable balanced Boolean functions n is strictly even) with small absolute indicator Δ f n⩾46 , a recent approach [15] has introduced a generic design framework achieving Δ f n⩾22 . Based on a suitable modification of the method of Rothaus, used to construct new bent functions from known ones, we provide a generic iterative framework for designing balanced functions satisfying the condition Δ f n⩾12 . Even though the problem of specifying functions having Δ f n⩾48 satisfying n ≡ 0 n≡0 mod 4 and n ⩾ 54 n⩾54 with n ≡ 2 n≡2 mod 4. In the latter case, our nonlinearity bound is better than the one presented in [14].},
  archive      = {J_ISCI},
  author       = {Fengrong Zhang and Enes Pasalic and Yongzhuang Wei},
  doi          = {10.1016/j.ins.2021.06.037},
  journal      = {Information Sciences},
  pages        = {437-453},
  shortjournal = {Inf. Sci.},
  title        = {Constructions of balanced boolean functions on even number of variables with maximum absolute value in autocorrelation spectra &lt;2n2☆},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural network quantization in federated learning at the
edge. <em>ISCI</em>, <em>575</em>, 417–436. (<a
href="https://doi.org/10.1016/j.ins.2021.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive amount of data collected in the Internet of Things (IoT) asks for effective, intelligent analytics. A recent trend supporting the use of Artificial Intelligence (AI) solutions in IoT domains is to move the computation closer to the data, i.e., from cloud-based services to edge devices. Federated learning (FL) is the primary approach adopted in this scenario to train AI-based solutions. In this work, we investigate the introduction of quantization techniques in FL to improve the efficiency of data exchange between edge servers and a cloud node. We focus on learning recurrent neural network models fed by edge data producers using the most widely adopted neural networks for time-series prediction. Experiments on public datasets show that the proposed quantization techniques in FL reduces up to 19 × × the volume of data exchanged between each edge server and a cloud node, with a minimal impact of around 5\% on the test loss of the final model.},
  archive      = {J_ISCI},
  author       = {Nicola Tonellotto and Alberto Gotta and Franco Maria Nardini and Daniele Gadler and Fabrizio Silvestri},
  doi          = {10.1016/j.ins.2021.06.039},
  journal      = {Information Sciences},
  pages        = {417-436},
  shortjournal = {Inf. Sci.},
  title        = {Neural network quantization in federated learning at the edge},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SSPNet: Learning spatiotemporal saliency prediction networks
for visual tracking. <em>ISCI</em>, <em>575</em>, 399–416. (<a
href="https://doi.org/10.1016/j.ins.2021.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present SSPNet, a novel method for learning the spatiotemporal saliency of a target for visual tracking. State-of-the-art trackers typically track targets by predicting the target state, ie coordinates of a bounding box encompassing the target, from the target candidates sampled around a previous target state. However, they have two limitations: 1) vulnerability to tracking distractors present in a frame and 2) the strong bias of the target state estimation to the initial frame. The proposed method addresses this problem by predicting the spatiotemporal features of the target so-called current and future target saliencies. Given a frame, the current target saliency represents the spatial aspect of the target, whereas the future target saliency depicts how the target will appear in the next frame based on the temporal features. This technique improves tracking accuracy in two ways: we can exploit the similarity between the current and the future target saliencies to detect the distractors . Further, SSPNet provides better prior knowledge about the current target state compared to using only the previous frame, which mitigates the bias to the initial frame and occlusion problem . We show that SSPNet outperforms the state-of-the-art trackers, particularly in challenging sequences.},
  archive      = {J_ISCI},
  author       = {Hyeonseok Lee and Sungchan Kim},
  doi          = {10.1016/j.ins.2021.06.042},
  journal      = {Information Sciences},
  pages        = {399-416},
  shortjournal = {Inf. Sci.},
  title        = {SSPNet: Learning spatiotemporal saliency prediction networks for visual tracking},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Research on AI security enhanced encryption algorithm of
autonomous IoT systems. <em>ISCI</em>, <em>575</em>, 379–398. (<a
href="https://doi.org/10.1016/j.ins.2021.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the security issues during the multi-types data storage and data transmission in autonomous Internet of Things (IoT) systems, this paper proposes an AI algorithm for data enhanced encryption used in the ends and the intermediate nodes of IoTs. The algorithm in this paper first constructs a three-dimensional Arnold transformation matrix for data unit value encryption in the end of IoTs, and designs a quantum logic intelligent mapping that effectively diffuses the encrypted data units to reduce the linear correlation of the image data and to improve the security performance of IoT edge data. Furthermore, the algorithm designs an AI access strategy for scrambling sequence nodes and builds a random-access route for the elements of the scrambling sequence which can reduce the calculation cost and improve the operating efficiency of IoT system in the ends and intermediate nodes. Finally, the data shared matrix is used to share the encrypted data to achieve the (k, n) threshold strategy. Experimental results prove that the algorithm has high plaintext and key sensitivity and can effectively resist brute force attacks, statistical analysis and differential attacks. The algorithm in this paper provides an AI solution for data security encryption in the ends and the intermediate nodes of autonomous IoT systems.},
  archive      = {J_ISCI},
  author       = {Bin Li and Yuhao Feng and Zenggang Xiong and Weidong Yang and Gang Liu},
  doi          = {10.1016/j.ins.2021.06.016},
  journal      = {Information Sciences},
  pages        = {379-398},
  shortjournal = {Inf. Sci.},
  title        = {Research on AI security enhanced encryption algorithm of autonomous IoT systems},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New differentiability concepts for set-valued functions and
applications to set differential equations. <em>ISCI</em>, <em>575</em>,
355–378. (<a href="https://doi.org/10.1016/j.ins.2021.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose new definitions of derivative for set-valued functions, based on the Pompeiu-Hausdorff distance between compact convex sets . The main properties of the new concepts introduced are also investigated. Moreover, using the differentiability concepts defined, we study the set differential equations and we present the connection between the solutions to set differential equations and their approximations .},
  archive      = {J_ISCI},
  author       = {A. Khastan and R. Rodríguez-López and M. Shahidi},
  doi          = {10.1016/j.ins.2021.06.014},
  journal      = {Information Sciences},
  pages        = {355-378},
  shortjournal = {Inf. Sci.},
  title        = {New differentiability concepts for set-valued functions and applications to set differential equations},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rough approximation-based approach for designing a
personalized tour route under a fuzzy environment. <em>ISCI</em>,
<em>575</em>, 338–354. (<a
href="https://doi.org/10.1016/j.ins.2021.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Trip planning significantly improves tourists’ experiences and enhances the competitive advantage of tourist attractions. We focus on the tourist trip design problem (TTDP) under a fuzzy environment, which is an extension of TTDP that considers the spatiotemporal route structure and variable sightseeing value at points of interest. A rough approximation-based model is proposed to deal with fuzzy variables, and a hybrid genetic algorithm is designed to identify the optimal route. We conduct a numerical experiment to assess the performance of the presented approach. The results of the Wilcoxon rank sum tests indicate that our approach performs significantly better than currently available methods. The evolution strategies based on improved particle swarm optimization also demonstrate better efficiency than existing approaches.},
  archive      = {J_ISCI},
  author       = {Zhixue Liao and Xiaozhu Zhang and Qixiao Zhang and Weimin Zheng and Wenyong Li},
  doi          = {10.1016/j.ins.2021.02.007},
  journal      = {Information Sciences},
  pages        = {338-354},
  shortjournal = {Inf. Sci.},
  title        = {Rough approximation-based approach for designing a personalized tour route under a fuzzy environment},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated arrhythmia detection with homeomorphically
irreducible tree technique using more than 10,000 individual subject ECG
records. <em>ISCI</em>, <em>575</em>, 323–337. (<a
href="https://doi.org/10.1016/j.ins.2021.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arrhythmia constitute a common clinical problem in cardiology. The diagnosis is often made using electrocardiographic (ECG) signals but manual ECG interpretation by experts is expensive and time-consuming. In this work, we developed and validated an arrhythmia classification model based on handcrafted features, which was more computationally efficient than traditional deep learning models. The classification model comprised (i) a specific feature extraction function based on the homeomorphically irreducible tree (HIT) graph pattern, (ii) multilevel feature generation based on maximum absolute pooling, (iii) Chi2 feature selector, and (iv) standard support vector machine classifier. We trained and validated the model on a large dataset comprising 12-leads ECGs acquired from more than 10,000 subjects. Performance metrics were reported for seven- (Case 1) and four-class (Case 2) arrhythmia diagnosis. High classification accuracy rates of 92.95\% and 97.18\% were attained for Case 1 and Case 2, respectively, that were comparable with those of deep learning on the same ECG dataset. The model achieved excellent classification results at low computational cost, which underscores the potential for real world application of the proposed HIT-based ECG classification model.},
  archive      = {J_ISCI},
  author       = {Mehmet Baygin and Turker Tuncer and Sengul Dogan and Ru-San Tan and U. Rajendra Acharya},
  doi          = {10.1016/j.ins.2021.06.022},
  journal      = {Information Sciences},
  pages        = {323-337},
  shortjournal = {Inf. Sci.},
  title        = {Automated arrhythmia detection with homeomorphically irreducible tree technique using more than 10,000 individual subject ECG records},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A network embedding-enhanced bayesian model for generalized
community detection in complex networks. <em>ISCI</em>, <em>575</em>,
306–322. (<a href="https://doi.org/10.1016/j.ins.2021.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection has been a significant and long-standing task in network analysis . While existing methods tend to focus on the assortative structure where communities are densely connected internally, in reality other kinds of network structure (e.g., disassortative) also exist. In addition, previous methods often have difficulties in dealing with noise and redundant information in the network topology . To address these problems, we develop a novel Bayesian probabilistic model for identifying the generalized communities, regardless of whether the network structure is assortative, disassortative, or otherwise. Specifically, the model combines the original adjacency matrix representation with the network embedding (the dense and continuous vector representations of nodes in a low-dimensional space). The two parts are connected and generated jointly via the community memberships of nodes learned from the model. Finally, we take a Bayesian treatment for model parameters and develop an efficient variational inference algorithm to detect communities. Experimental results demonstrate the outstanding performance of the new approach both on synthetic networks and on real-world networks, while case studies validate the ability of the proposed approach to describe generalized communities meaningfully.},
  archive      = {J_ISCI},
  author       = {Dongxiao He and Youyou Wang and Jinxin Cao and Weiping Ding and Shizhan Chen and Zhiyong Feng and Bo Wang and Yuxiao Huang},
  doi          = {10.1016/j.ins.2021.06.020},
  journal      = {Information Sciences},
  pages        = {306-322},
  shortjournal = {Inf. Sci.},
  title        = {A network embedding-enhanced bayesian model for generalized community detection in complex networks},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cluster synchronization of heterogeneous nonlinear
multi-agent systems with actuator faults and IQCs through adaptive
fault-tolerant pinning control. <em>ISCI</em>, <em>575</em>, 289–305.
(<a href="https://doi.org/10.1016/j.ins.2021.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the cluster synchronization problem of a heterogeneous second-order leader-following multi-agent system with nonlinear dynamics , actuator faults , and integral quadratic constraints (IQCs) under a directed topology with a directed spanning tree is investigated. Based on the local topology information, two adaptive fault-tolerant pinning control strategies with fixed and adaptive pinning gains are proposed to guarantee cluster synchronization in finite time. An adaptive input compensation is developed to attenuate the adverse effects of actuator faults . It is worth mentioning that just one parameter needs to be estimated for each agent in this compensation, which implies that the strategies designed in this paper can effectively reduce the computational cost. Furthermore, the use of the pinning control method instead of the fully equipped control method makes the strategies more cost-effective for large-scale multi-agent systems. Finally, numerical simulation examples are introduced to demonstrate the effectiveness and advantages of the proposed strategies.},
  archive      = {J_ISCI},
  author       = {Xiang-Gui Guo and Pei-Ming Liu and Hong-Jian Li and Jian-Liang Wang and Choon Ki Ahn},
  doi          = {10.1016/j.ins.2021.06.019},
  journal      = {Information Sciences},
  pages        = {289-305},
  shortjournal = {Inf. Sci.},
  title        = {Cluster synchronization of heterogeneous nonlinear multi-agent systems with actuator faults and IQCs through adaptive fault-tolerant pinning control},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Systematic categorization and evaluation of CbO-based
algorithms in FCA. <em>ISCI</em>, <em>575</em>, 265–288. (<a
href="https://doi.org/10.1016/j.ins.2021.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algorithms based on Close-by-One (CbO) are polynomial delay algorithms used for the enumeration of closed sets, particularly formal concepts in Formal Concept Analysis. We describe and categorize their distinctive features. We experimentally evaluate the influence of the features on the computation time. We show that via the study of individual features, we can design new and more efficient algorithms.},
  archive      = {J_ISCI},
  author       = {Jan Konecny and Petr Krajča},
  doi          = {10.1016/j.ins.2021.06.024},
  journal      = {Information Sciences},
  pages        = {265-288},
  shortjournal = {Inf. Sci.},
  title        = {Systematic categorization and evaluation of CbO-based algorithms in FCA},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sampled-data fuzzy observer design for nonlinear systems
with a nonlinear output equation under measurement quantization.
<em>ISCI</em>, <em>575</em>, 248–264. (<a
href="https://doi.org/10.1016/j.ins.2021.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a sampled-data fuzzy observer (SDFO) of oscillating nonlinear systems with a nonlinear output equation is proposed based on the Takagi–Sugeno (T–S) fuzzy-model-based approach. First, to handle the low transmission capacity of the network, measurements from the system of interest are assumed to be quantized. Next, we employ an exponentially time-varying gain matrix to the SDFO system for enhancing the decay rate performance of the state estimation error dynamics, and these are represented with the T–S fuzzy model. To show better performance on the state estimation, we focus on developing two points: a novel design methodology and a novel looped Lyapunov–Krasovskii functional (LKF). Furthermore, we propose a novel design condition of an SDFO for systems without measurement quantization, which is less conservative than conventional approaches. All of the proposed design conditions are formulated in terms of linear matrix inequalities (LMIs). Finally, appropriate simulation examples are given to validate the effectiveness of the proposed method, and these show better performance compared to the conventional studies.},
  archive      = {J_ISCI},
  author       = {Han Sol Kim and Kwangil Lee},
  doi          = {10.1016/j.ins.2021.06.030},
  journal      = {Information Sciences},
  pages        = {248-264},
  shortjournal = {Inf. Sci.},
  title        = {Sampled-data fuzzy observer design for nonlinear systems with a nonlinear output equation under measurement quantization},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). First step towards parameters estimation of image operator
chain. <em>ISCI</em>, <em>575</em>, 231–247. (<a
href="https://doi.org/10.1016/j.ins.2021.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many effective techniques have recently been proposed to estimate the parameters of specific tampering operations. Most of them consider the situation in which an image is tampered with by only a single operation. However, in reality, multiple operations are used to falsify an image. Because the tampering traces of previous operations may be weakened or eliminated by later operations, it is difficult for the prior algorithms, each of which was developed for a single operation, to detect all tampering operations. In this paper, we propose a new method for estimating the parameters of operations in different manipulation chains. A framework is presented to investigate the correlation between multiple operations, which divides the degree of correlation into uncoupled and coupled operations. Then, two cases of certain operator chains with different degrees of correlation are adopted to reveal the assessment framework. Under this framework, we design well-directed features to estimate the parameters for each operator chain. Finally, the experimental results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ISCI},
  author       = {Xin Liao and Zihang Huang and Lin Peng and Tong Qiao},
  doi          = {10.1016/j.ins.2021.06.045},
  journal      = {Information Sciences},
  pages        = {231-247},
  shortjournal = {Inf. Sci.},
  title        = {First step towards parameters estimation of image operator chain},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving multikey computing framework for
encrypted data in the cloud. <em>ISCI</em>, <em>575</em>, 217–230. (<a
href="https://doi.org/10.1016/j.ins.2021.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preparing large amounts of training data is the key to the success of machine learning. Due to the public’s concern about individual privacy, different techniques are proposed to achieve privacy preserving machine learning. Homomorphic encryption enables calculation on encrypted data in the cloud. However, current schemes either focus on single key or a specific algorithm. Cooperation between different institutions is quite common in this era of big data. Encrypting data from different institutions under one single key is a risk to data privacy. Moreover, constructing secure scheme for a specific machine learning algorithm lacks universality. Based on an additively homomorphic encryption supporting one multiplication, we propose a general multikey computing framework to execute common arithmetic operations on encrypted data such as addition, multiplication, comparison, sorting, division and etc. Our scheme can be used to run different machine learning algorithms. Our scheme is proven to be secure against semi-honest attackers and the experimental evaluations demonstrate the practicality of our computing framework.},
  archive      = {J_ISCI},
  author       = {Jun Zhang and Zoe L.Jiang and Ping Li and Siu Ming Yiu},
  doi          = {10.1016/j.ins.2021.06.017},
  journal      = {Information Sciences},
  pages        = {217-230},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving multikey computing framework for encrypted data in the cloud},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scaled aggregation functions. <em>ISCI</em>, <em>575</em>,
206–216. (<a href="https://doi.org/10.1016/j.ins.2021.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce and discuss a transformation of aggregation functions yielding interval scale invariant aggregation or weak aggregation functions. Several examples illustrating our approach are included. In particular, we discuss the results for integrals based on semicopulas. We focus our attention on transformations of the Sugeno and Shilkret integrals, and clarify their connection with OWA operators.},
  archive      = {J_ISCI},
  author       = {Anna Kolesárová and LeSheng Jin and Radko Mesiar},
  doi          = {10.1016/j.ins.2021.06.031},
  journal      = {Information Sciences},
  pages        = {206-216},
  shortjournal = {Inf. Sci.},
  title        = {Scaled aggregation functions},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel secure observer-based controller and attack
detection scheme for networked control systems. <em>ISCI</em>,
<em>575</em>, 185–205. (<a
href="https://doi.org/10.1016/j.ins.2021.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes security techniques for detecting and counteracting attacks in Networked Control Systems (NCSs). A partially homomorphic based encryption technique , namely the Paillier scheme, is used to protect the confidentiality of the transmitted data over the network against eavesdropping attacks . An integrated secure and private observer-based controller with guaranteed stability together with a secure and private observer-based detection system has been developed. We start with an encrypted observer. Then, an observer-based encrypted controller is added to stabilize the system. Besides, an encrypted observer-based detection algorithm has been used to detect false data injection attacks . Moreover, in our design, the computations on the observer, the controller, and the decision-maker operate on encrypted data while protecting against eavesdropping attacks . Using digital processors in cyber systems leads to quantized transmitted signals through the network and also to design the observer and controller operations in such a way that they work on quantized data efficiently. Limitations on the parameters of the quantizations and the encryption scheme are given to ensure the stability of the closed-loop system and guarantee reliable bounds on the closed-loop performance. Simulation results using Tennessee Eastman Process demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Ladan Sadeghikhorami and Vijay Varadharajan and Ali Akbar Safavi},
  doi          = {10.1016/j.ins.2021.06.012},
  journal      = {Information Sciences},
  pages        = {185-205},
  shortjournal = {Inf. Sci.},
  title        = {A novel secure observer-based controller and attack detection scheme for networked control systems},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the constructions of t-norms on bounded lattices.
<em>ISCI</em>, <em>575</em>, 173–184. (<a
href="https://doi.org/10.1016/j.ins.2021.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we first generalize some constructions of t-norms on bounded lattices by using order-preserving functions and propose the necessary and sufficient conditions for this kind of construction. Then, we simplify these conditions for practical use. Based on these results, we propose a new type of ordinal sum construction for t-norms. It can be regarded as a generalization of h-ordinal sum. Some examples and comparisons are also provided.},
  archive      = {J_ISCI},
  author       = {Xiang-Rong Sun and Hua-Wen Liu},
  doi          = {10.1016/j.ins.2021.06.027},
  journal      = {Information Sciences},
  pages        = {173-184},
  shortjournal = {Inf. Sci.},
  title        = {On the constructions of t-norms on bounded lattices},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Recurrent emotional contagion for the crowd evacuation of a
cyber-physical society. <em>ISCI</em>, <em>575</em>, 155–172. (<a
href="https://doi.org/10.1016/j.ins.2021.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, emotional contagion has drawn great attention in the field of public security since it often leads to stampedes and crushes during large-scale emergencies. To date, there have been many studies on emotional contagion in both cyberspace and physical space, bringing a strong impetus to the simulation of crowd evacuation in emergencies. However, due to the heterogeneity of crowds in cyberspace and physical space, emotional contagion is rarely comprehensively considered in the cyber-physical society (CPS). In addition, the characteristics of emotional recurrence prone to appear in large-scale evacuation have not yet been fully elucidated. Therefore, the existing models cannot accurately describe the real situation of emotional contagion since there is a wide deviation between it and the reality. To solve this problem, we propose a recurrent emotional contagion (REC) method for crowd evacuation of the CPS. First, we construct a CPS-oriented REC model by considering the influence of emotional recurrence on the emotional contagion process. Second, we build the degree-based Mean-Field Equations to describe the dynamic evolution of the number of individuals while considering the heterogeneity of crowds. Furthermore, we use the Finite Difference Method to derive the numerical solution. Third, we construct recurrent small-world networks, which constitute a special case of CPS-REC, to verify the effectiveness of our model. Finally, we implement a crowd simulation system based on the CPS-REC model to visualize the results of our theoretical analysis. The experimental results show that our method can more realistically simulate the emotional contagion process.},
  archive      = {J_ISCI},
  author       = {Heng Liu and Dianjie Lu and Guijuan Zhang and Xiao Hong and Hong Liu},
  doi          = {10.1016/j.ins.2021.06.036},
  journal      = {Information Sciences},
  pages        = {155-172},
  shortjournal = {Inf. Sci.},
  title        = {Recurrent emotional contagion for the crowd evacuation of a cyber-physical society},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LaPOLeaF: Label propagation in an optimal leading forest.
<em>ISCI</em>, <em>575</em>, 133–154. (<a
href="https://doi.org/10.1016/j.ins.2021.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an efficient graph semisupervised learning (GSSL) method that meets the criterion of optimization without iterations. Most existing GSSL methods require iterative optimization to achieve a preset objective because they consider data points to be in peer-to-peer relationships. Additionally, existing GSSL methods must learn from scratch for unseen data because graph structures are specifically built for a given dataset. By leveraging the partial order relationships induced by the local density and distances between data, we developed a novel label propagation algorithm based on the data structure of an optimal leading forest (OLeaF). The time complexity of our method is O(N) for both labeling unclassified data and labeling new data from a dataset after an OLeaF is constructed. Therefore, the two main weaknesses of traditional GSSL are addressed. Additionally, the constructed leading forest offers good interpretability for learning results. We scale the proposed method to accommodate big data by utilizing the block distance matrix technique and locality-sensitive hashing. Extensive experiments on datasets with different characteristics demonstrate the superior efficiency and competitive accuracy of the proposed method.},
  archive      = {J_ISCI},
  author       = {Ji Xu and Tianrui Li and Yongming Wu and Guoyin Wang},
  doi          = {10.1016/j.ins.2021.06.010},
  journal      = {Information Sciences},
  pages        = {133-154},
  shortjournal = {Inf. Sci.},
  title        = {LaPOLeaF: Label propagation in an optimal leading forest},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive fuzzy tracking for flexible-joint robots with
random noises via command filter control. <em>ISCI</em>, <em>575</em>,
116–132. (<a href="https://doi.org/10.1016/j.ins.2021.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the issue of adaptive tracking control for flexible-joint robots with random disturbances that can be correlated to all system states.The system considered under this case is a typical multi-input and multi-output (MIMO) nonstrict-feedback system, which cannot be controlled by the traditional backstepping design. For this reason, fuzzy logic systems play a vital role in solving this difficulty. Moreover, a finite-time adaptive control scheme is proposed by combining command filtered control and backstepping design, in which the “explosion of complexity” problem is successfully avoided and the tracking error can be kept within a very small range of the origin in a limited time. Finally, the effectiveness of the proposed control scheme is further demonstrated by the simulation results. It can be seen from the simulation comparison that under the proposed method, the maximum value of ‖ q 1 - q r ‖ ‖q1-qr‖ at the steady-state phase is only 0.0055, which is smaller than 0.0199 in the existing method.},
  archive      = {J_ISCI},
  author       = {Wei Sun and Shuzhen Diao and Shun-Feng Su and Yuqiang Wu},
  doi          = {10.1016/j.ins.2021.06.025},
  journal      = {Information Sciences},
  pages        = {116-132},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy tracking for flexible-joint robots with random noises via command filter control},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of hybrid metaheuristic with perturbation-based
k-nearest neighbors algorithm and densest imputation to collaborative
filtering in recommender systems. <em>ISCI</em>, <em>575</em>, 90–115.
(<a href="https://doi.org/10.1016/j.ins.2021.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the rise of E-commerce companies and many other web services, the applications of recommender systems have been adopted more broadly than ever before. Although collaborative filtering is the most well-known approach which utilizes customer’s preference to discover their interest, the problems of data sparsity and similarities selection still exist in it. Thus, this study intends to propose a hybrid metaheuristic with perturbation-based K -nearest neighbors and densest imputation for collaborative filtering (KDI-KNN) algorithm to reduce the effects of data sparsity . A similarities union function is proposed to determine the fittest similarity and enhance the prediction performance. Eventually, the experimental results indicate that hybrid metaheuristics with perturbation-based KDI-KNN algorithms are superior to basic KNN , original KDI-KNN, and most single metaheuristic-based KDI-KNN. In addition, a real-world dataset, fund transaction dataset is adopted in the case study. The analysis reveals that the similarity is seriously affected by the different content of the dataset.},
  archive      = {J_ISCI},
  author       = {R.J. Kuo and Cheng-Kang Chen and Shao-Hong Keng},
  doi          = {10.1016/j.ins.2021.06.026},
  journal      = {Information Sciences},
  pages        = {90-115},
  shortjournal = {Inf. Sci.},
  title        = {Application of hybrid metaheuristic with perturbation-based K-nearest neighbors algorithm and densest imputation to collaborative filtering in recommender systems},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MI-MOTE: Multiple imputation-based minority oversampling
technique for imbalanced and incomplete data classification.
<em>ISCI</em>, <em>575</em>, 80–89. (<a
href="https://doi.org/10.1016/j.ins.2021.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance and data incompleteness problems occur simultaneously in many real-world classification datasets, which negatively affects the training of classifiers. Given an imbalanced and incomplete training dataset, the conventional approach is to address these two problems sequentially by handling data incompleteness first and then focusing on class imbalance. In this study, we propose a multiple imputation-based minority oversampling technique, named MI-MOTE, to address imbalanced and incomplete data classification simultaneously. Majority instances are imputed once and minority instances are oversampled using multiple different imputations without directly manipulating any of their observed values. Accordingly, minority instances are diversified with less data distortion compared to the conventional approach. The proposed method is applied in the data preprocessing phase, meaning it can be used with any type of classifier. Experimental results for benchmark datasets with various missing rates demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Kyoham Shin and Jongmin Han and Seokho Kang},
  doi          = {10.1016/j.ins.2021.06.043},
  journal      = {Information Sciences},
  pages        = {80-89},
  shortjournal = {Inf. Sci.},
  title        = {MI-MOTE: Multiple imputation-based minority oversampling technique for imbalanced and incomplete data classification},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rule-enhanced iterative complementation for knowledge graph
reasoning. <em>ISCI</em>, <em>575</em>, 66–79. (<a
href="https://doi.org/10.1016/j.ins.2021.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) reasoning aims to infer missing valid triples from observed triples, thereby improving the semantics of the whole KG. The general KG reasoning involves rule-based and embedding-based methods. The former can provide an interpretable reasoning process but has low efficiency, while the latter is the converse. Therefore, some hybrid methods have been proposed, but there are still two challenges: the completeness of rule learning and the determination of hidden triples. To address these challenges, this paper proposes a rule-enhanced iterative complementation (Rule-IC) method, which involves three components: rule learning , an embedding learner and a triple discriminator . Such an iterative process enriches the semantics of KG and further increases the completeness of rule learning to generate hidden triples. In order to precisely determine the validity of hidden triples, a multi-relational graph convolutional network (GCN) with attentive message passing is introduced as a triple discriminator . The embedding learner for KG reasoning and the GCN discriminator complement each other by valid hidden triples. In addition, the performance of these three components improves overall during the iterative process. Experimental results show that most evaluation metrics of Rule-IC are better than those of several baselines on four common KGs. Furthermore, it is scalable and can be extended to all KG embedding models theoretically.},
  archive      = {J_ISCI},
  author       = {Qika Lin and Jun Liu and Yudai Pan and Lingling Zhang and Xin Hu and Jie Ma},
  doi          = {10.1016/j.ins.2021.06.040},
  journal      = {Information Sciences},
  pages        = {66-79},
  shortjournal = {Inf. Sci.},
  title        = {Rule-enhanced iterative complementation for knowledge graph reasoning},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A spatially constrained asymmetric gaussian mixture model
for image segmentation. <em>ISCI</em>, <em>575</em>, 41–65. (<a
href="https://doi.org/10.1016/j.ins.2021.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite Gaussian mixture model (GMM) is a flexible and powerful tool for addressing many computer vision and pattern recognition problems. The Gaussian distribution is a probability distribution that is symmetric with respect to the mean. However, in many segmentation applications, the observed data obey an asymmetric distribution. Furthermore, the GMM is sensitive to imaging noise. To alleviate these issues, a new finite anisotropic asymmetric normal mixture model is presented in this paper. Note that GMM is a degraded case of our proposed model. First, the proposed model employs anisotropic spatial information to reduce the effect of imaging noise while preserving the details, such as edges, corners and slim structure objects. Second, the anisotropic spatial information is coupled into the skew normal distribution to fit the observed data obeying an asymmetric distribution. Then the modeling and estimation of the object intensity probability density function are proposed by using the anisotropic skew normal mixture model. The proposed model not only has the capability to fit the observed data obeying a non-symmetric distribution, but also can reduce the effect of noise while preserving the objects details. Finally, expectation maximization (EM) algorithm is adopted to estimate the model parameters in order to maximize the log-likelihood function. The experiment results on synthetic images and natural grayscale images demonstrate the superior performance of the proposed model compared with other state-of-the-art segmentation methods.},
  archive      = {J_ISCI},
  author       = {Yunjie Chen and Ning Cheng and Mao Cai and Chunzheng Cao and Jianwei Yang and Zhichao Zhang},
  doi          = {10.1016/j.ins.2021.06.034},
  journal      = {Information Sciences},
  pages        = {41-65},
  shortjournal = {Inf. Sci.},
  title        = {A spatially constrained asymmetric gaussian mixture model for image segmentation},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TPDE: A tri-population differential evolution based on
zonal-constraint stepped division mechanism and multiple adaptive guided
mutation strategies. <em>ISCI</em>, <em>575</em>, 22–40. (<a
href="https://doi.org/10.1016/j.ins.2021.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution (DE) has been recognized as one of the most effective algorithms for solving numerical optimization problems . In this paper, we propose a tri-population differential evolution (TPDE) to further enhance the search capability of DE. More specifically, the parent population is partitioned into three sub-populations with different emphasises at each iteration based on a newly proposed zonal-constraint stepped division (ZSD) mechanism, which determines the size of each sub-population according to not only individual’s fitness value but also the evolutionary process. To make the best of information provided by elite individuals and play their leading role on other individuals, three elite-guided mutation strategies are presented for each sub-population. Moreover, three sets of adaptive control parameters including the scale factor F and crossover rate CR are configured for three mutations according to Gaussian distribution model, Cauchy distribution model and a triangular wave function respectively. The design of mutation strategies and control parameters for each sub-population is based on the principle of balancing the global exploration and local exploitation capabilities. To evaluate the performance of TPDE, comparative experiments are conducted based on 59 benchmark functions from CEC2014 and CEC2017 test suites. The results indicate that the proposed TPDE is significantly better than, or at least comparable to the recent nine state-of-the-art DE variants.},
  archive      = {J_ISCI},
  author       = {Libao Deng and Chunlei Li and Rongqing Han and Lili Zhang and Liyan Qiao},
  doi          = {10.1016/j.ins.2021.06.035},
  journal      = {Information Sciences},
  pages        = {22-40},
  shortjournal = {Inf. Sci.},
  title        = {TPDE: A tri-population differential evolution based on zonal-constraint stepped division mechanism and multiple adaptive guided mutation strategies},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Continual learning in sensor-based human activity
recognition: An empirical benchmark analysis. <em>ISCI</em>,
<em>575</em>, 1–21. (<a
href="https://doi.org/10.1016/j.ins.2021.04.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor-based human activity recognition (HAR), i.e., the ability to discover human daily activity patterns from wearable or embedded sensors, is a key enabler for many real-world applications in smart homes, personal healthcare, and urban planning. However, with an increasing number of applications being deployed, an important question arises: how can a HAR system autonomously learn new activities over a long period of time without being re-engineered from scratch? This problem is known as continual learning and has been particularly popular in the domain of computer vision , where several techniques to attack it have been developed. This paper aims to assess to what extent such continual learning techniques can be applied to the HAR domain. To this end, we propose a general framework to evaluate the performance of such techniques on various types of commonly used HAR datasets. Then, we present a comprehensive empirical analysis of their computational cost and of their effectiveness of tackling HAR specific challenges (i.e., sensor noise and labels’ scarcity). The presented results uncover useful insights on their applicability and suggest future research directions for HAR systems.},
  archive      = {J_ISCI},
  author       = {Saurav Jha and Martin Schiemer and Franco Zambonelli and Juan Ye},
  doi          = {10.1016/j.ins.2021.04.062},
  journal      = {Information Sciences},
  pages        = {1-21},
  shortjournal = {Inf. Sci.},
  title        = {Continual learning in sensor-based human activity recognition: An empirical benchmark analysis},
  volume       = {575},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Group decision making based on multiplicative
consistency-and-consensus preference analysis for incomplete q-rung
orthopair fuzzy preference relations. <em>ISCI</em>, <em>574</em>,
653–673. (<a href="https://doi.org/10.1016/j.ins.2021.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The q -rung orthopair fuzzy preference relations are useful tools to represent hesitant and uncertain judgments of decision makers . In this paper, we propose a new group decision making method based on multiplicative consistency-and-consensus preference analysis for incomplete q -rung orthopair fuzzy preference relations . First, we provide a novel concept of multiplicative consistency for q -rung orthopair fuzzy preference relations. Then, a multiplicative consistency index is offered, by which we derive the concept of acceptable multiplicative consistency for q -rung orthopair fuzzy preference relations. Following this concept, optimization models for ascertaining unknown values in an incomplete q -rung orthopair fuzzy preference relation are built. Furthermore, optimization models for obtaining acceptable multiplicative q -rung orthopair fuzzy preference relation are proposed. Then, an optimization model for group decision making is proposed to attain an enough consensus. Afterward, a group decision making method with incomplete and unacceptable multiplicative consistent q -rung orthopair fuzzy preference relations is proposed. Finally, we use an application example to show the practicality of the proposed group decision making method. The proposed group decision making method outperforms the existing group decision making methods for group decision making in incomplete q -rung orthopair fuzzy environments.},
  archive      = {J_ISCI},
  author       = {Zhiming Zhang and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2021.07.044},
  journal      = {Information Sciences},
  pages        = {653-673},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making based on multiplicative consistency-and-consensus preference analysis for incomplete q-rung orthopair fuzzy preference relations},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). No-reference image quality assessment for contrast-changed
images via a semi-supervised robust PCA model. <em>ISCI</em>,
<em>574</em>, 640–652. (<a
href="https://doi.org/10.1016/j.ins.2021.07.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contrast plays an important role in human perception of image quality. In this paper, we propose a metric for no-reference quality assessment of contrast-changed images by using a novel semi-supervised robust PCA , which can realize feature selection and denoising simultaneously, guided by the available supervisory information. To select features adaptively, the information-oriented features (e.g. entropy and natural scene statistics) and appearance-oriented features (e.g. colorfulness) are adopted. The proposed model is formulated as a constraint optimization problem , which is further casted to a convex problem and solved via augmented Lagrangian multiplier method. Extensive experimental results on CCID2014, CSIQ, SIQAD and TID2013 databases show that the proposed semi-supervised image quality metric based on robust PCA (SIQMR) provides a more accurate prediction than other metrics on the human perception of contrast variations.},
  archive      = {J_ISCI},
  author       = {Jingchao Cao and Ran Wang and Yuheng Jia and Xinfeng Zhang and Shiqi Wang and Sam Kwong},
  doi          = {10.1016/j.ins.2021.07.052},
  journal      = {Information Sciences},
  pages        = {640-652},
  shortjournal = {Inf. Sci.},
  title        = {No-reference image quality assessment for contrast-changed images via a semi-supervised robust PCA model},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Adaptive fuzzy control of uncertain stochastic nonlinear
systems with full state constraints. <em>ISCI</em>, <em>574</em>,
625–639. (<a href="https://doi.org/10.1016/j.ins.2021.07.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the problem of fuzzy adaptive control design for a class of stochastic nonstrict feedback nonlinear systems with unknown virtual control coefficients and full state constraints. Firstly, fuzzy logic systems (FLSs) are utilized to approximate the unknown nonlinear dynamics of the system under consideration. Secondly, an asymptotic tracking control scheme is presented by introducing a bounded estimation method and some smooth functions. Meanwhile, by constructing barrier Lyapunov functions (BLFs), it is proved that all variables of the controlled system are bounded; the tracking error asymptotically converges to zero, and all states of the stochastic system do not exceed its boundaries. Finally, an illustrative simulation instance is applied to verify the superior performance of the presented adaptive algorithm.},
  archive      = {J_ISCI},
  author       = {Xin Jin and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2021.07.056},
  journal      = {Information Sciences},
  pages        = {625-639},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy control of uncertain stochastic nonlinear systems with full state constraints},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Adaptive fuzzy backstepping control for nonstrict feedback
nonlinear systems with time-varying state constraints and backlash-like
hysteresis. <em>ISCI</em>, <em>574</em>, 606–624. (<a
href="https://doi.org/10.1016/j.ins.2021.07.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an adaptive fuzzy tracking control method is established for nonstrict feedback nonlinear systems (NFNS) with time-varying state constraints and backlash-like hysteresis . The property of the fuzzy basis function is employed to circumvent the algebraic loop problem and the adaptive backstepping technique is deployed in design process. To address the time-varying state constraints, the time-varying barrier Lyapunov function is integrated into the adaptive fuzzy backstepping design framework to keep all states within the predefined region. The devised control scheme not only surmounts the adverse effect caused by backlash-like hysteresis , but also achieves the expected tracking performance for NFNS with time-varying state constraints. Based on the Lyapunov stability analysis , it is proved that all signals of the closed-loop system are uniformly ultimately bounded. Finally, simulation examples are provided to confirm the validity of the designed method.},
  archive      = {J_ISCI},
  author       = {Yongchao Liu and Qidan Zhu and Ning Zhao and Lipeng Wang},
  doi          = {10.1016/j.ins.2021.07.068},
  journal      = {Information Sciences},
  pages        = {606-624},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fuzzy backstepping control for nonstrict feedback nonlinear systems with time-varying state constraints and backlash-like hysteresis},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RHDSI: A novel dimensionality reduction based algorithm on
high dimensional feature selection with interactions. <em>ISCI</em>,
<em>574</em>, 590–605. (<a
href="https://doi.org/10.1016/j.ins.2021.06.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classical statistical learning techniques struggle to perform feature selection in high-dimensional data that includes interaction effects i.e., when independent feature/s influence the effect of another feature on study outcome. Methods like penalized regression and sparse partial least squares regression can help, but penalization restricts the handling of interaction terms. This study proposes a novel Dimensionality Reduction based algorithm on High Dimensional feature Selection with Interactions (RHDSI), a new feature selection method that integrates dimensionality reduction and machine learning . The method can handle high-dimensional data, incorporate interaction terms and perform statistically-interpretable feature selection; and enables existing classical statistical techniques to work on high-dimensional data. RHDSI performs feature selection in three steps. The first step is a coarse feature selection through dimensionality reduction and statistical modeling on multiple resampled datasets and features, along with their interaction terms. The second step uses pooled results for unsupervised statistical learning-based feature refinement. Finally, supervised statistical learning-based feature selection is performed on the refined feature set to identify the final features with interactions. We evaluate the performance of this algorithm on simulated data and real studies. RHDSI shows better or par performance compared to standard feature selection algorithms like LASSO, subset selection , and sparse PLS.},
  archive      = {J_ISCI},
  author       = {Rahi Jain and Wei Xu},
  doi          = {10.1016/j.ins.2021.06.096},
  journal      = {Information Sciences},
  pages        = {590-605},
  shortjournal = {Inf. Sci.},
  title        = {RHDSI: A novel dimensionality reduction based algorithm on high dimensional feature selection with interactions},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DLEA: A dynamic learning evolution algorithm for
many-objective optimization. <em>ISCI</em>, <em>574</em>, 567–589. (<a
href="https://doi.org/10.1016/j.ins.2021.05.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For many-objective problems, how to maintain the diversity and convergence of the distribution of the solution set over Pareto front (PF) has always been the research emphasis. In the iteration process , the state of population is critical to improve the level of evolution. Therefore, this paper will use two convergence and diversity indicators to further strengthen the usage of evolutionary state information and propose a dynamic learning strategy. In addition, a dynamic learning strategy based many-objective evolutionary algorithm (MaOEA) is proposed, called dynamic learning evolution algorithm (DLEA), which continuously changes the direction of learning: convergence and diversity in the iteration process . The purpose is to make the algorithm prefer to convergence in the early iteration and prefer to diversity when it is close to PF in the late iteration, so that the convergence and diversity of the final solution set can be well maintained. And then, the performance of DLEA is measured by two indicators. Meanwhile, DLEA will be compared with four state-of-the-art algorithms on the DTLZ and MaF, and its performance will be verified on a many-objective combinatorial problem . And the experimental results and Friedman test show that DLEA has great advantages.},
  archive      = {J_ISCI},
  author       = {Gui Li and Gai-Ge Wang and Junyu Dong and Wei-Chang Yeh and Keqin Li},
  doi          = {10.1016/j.ins.2021.05.064},
  journal      = {Information Sciences},
  pages        = {567-589},
  shortjournal = {Inf. Sci.},
  title        = {DLEA: A dynamic learning evolution algorithm for many-objective optimization},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convex combination-based consensus analysis for
intuitionistic fuzzy three-way group decision. <em>ISCI</em>,
<em>574</em>, 542–566. (<a
href="https://doi.org/10.1016/j.ins.2021.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A three-way decision (3WD) with group consensus using intuitionistic fuzzy sets (IFSs) involves two pivotal decision steps: achieving a consensus of loss functions and determining the threshold pair in 3WD. We focus on these decision steps and propose a convex combination-based approach to a three-way intuitionistic fuzzy group decision (3WIFGD) considering a group consensus. First, a similarity measure between IFSs is introduced to define a group consensus index (GCI) for an expert group based on loss functions. Then, an automated algorithm is designed with the GCI-based convex combination strategy to improve the group consensus of loss functions. Moreover, we theoretically prove that the GCI in this algorithm is improved and even converges linearly to “1” as the iteration number increases. Second, based on the aggregated collective consensus loss functions, we construct the optimization model pair by extending the existing models and prove its unique solution , leading to the thresholds. Third, a two-decision-steps-based method for 3WIFGD is developed to capture the rules underlying a group consensus. Finally, an illustrative example and its related comparisons are demonstrated to show the validity of our method.},
  archive      = {J_ISCI},
  author       = {Jiubing Liu and Huaxiong Li and Bing Huang and Yu Liu and Dun Liu},
  doi          = {10.1016/j.ins.2021.06.018},
  journal      = {Information Sciences},
  pages        = {542-566},
  shortjournal = {Inf. Sci.},
  title        = {Convex combination-based consensus analysis for intuitionistic fuzzy three-way group decision},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Water leak detection using self-supervised time series
classification. <em>ISCI</em>, <em>574</em>, 528–541. (<a
href="https://doi.org/10.1016/j.ins.2021.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Leaks in water distribution networks cause a loss of water that needs to be compensated to ensure a continuous supply for all customers. This compensation is achieved by increasing the flow of the network, which entails an undesirable economical expense as well as negative consequences for the environment. For these reasons, detecting and fixing leaks is a relevant task for water distribution companies. This paper proposes a water leak detection method based on a self-supervised classification of flow time series. The aim is to detect the leaks in the network, providing a low false positive rate. The proposed method is applied to two water distribution networks and compared to two other methods in the literature, obtaining the best balance between the number of false positives and detected leaks.},
  archive      = {J_ISCI},
  author       = {Ane Blázquez-García and Angel Conde and Usue Mori and Jose A. Lozano},
  doi          = {10.1016/j.ins.2021.06.015},
  journal      = {Information Sciences},
  pages        = {528-541},
  shortjournal = {Inf. Sci.},
  title        = {Water leak detection using self-supervised time series classification},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). A novel triple-image encryption and hiding algorithm based
on chaos, compressive sensing and 3D DCT. <em>ISCI</em>, <em>574</em>,
505–527. (<a href="https://doi.org/10.1016/j.ins.2021.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel triple-image encryption and hiding algorithm is proposed by combining a 2D chaotic system, compressive sensing (CS) and the 3D discrete cosine transform (DCT). First, three grayscale plain images are sparsely represented by the 2D discrete wavelet transform (DWT). The resulting sparse matrices are scrambled twice through index sort scrambling and 3D zigzag scrambling. Then, the measurement matrix generated by the 2D chaotic system is used to compress the scrambled matrices. Finally, the compressed matrices are embedded into a color carrier image using the 3D DCT to obtain a visually meaningful cipher image. It is worth mentioning that most of the existing meaningful encryption algorithms encrypt and embed single images, which cannot meet the requirements of the era of big data. However, in our scheme, three grayscale images are simultaneously encrypted and embedded into a single color carrier image, which, when compared with existing algorithms, greatly improves the encryption efficiency. Moreover, simulation experiments and contrastive analyses show that the proposed visual encryption scheme has excellent visual security, robustness, decryption quality and running efficiency.},
  archive      = {J_ISCI},
  author       = {Xingyuan Wang and Cheng Liu and Donghua Jiang},
  doi          = {10.1016/j.ins.2021.06.032},
  journal      = {Information Sciences},
  pages        = {505-527},
  shortjournal = {Inf. Sci.},
  title        = {A novel triple-image encryption and hiding algorithm based on chaos, compressive sensing and 3D DCT},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FCM-RDpA: TSK fuzzy regression model construction using
fuzzy c-means clustering, regularization, droprule, and powerball
adabelief. <em>ISCI</em>, <em>574</em>, 490–504. (<a
href="https://doi.org/10.1016/j.ins.2021.05.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To effectively optimize Takagi-Sugeno-Kang (TSK) fuzzy systems for regression problems , a mini-batch gradient descent with regularization , DropRule, and AdaBound (MBGD-RDA) algorithm was recently proposed. This paper further proposes FCM-RDpA, which improves MBGD-RDA by replacing the grid partition approach in rule initialization by fuzzy c-means clustering, and AdaBound by Powerball AdaBelief, which integrates recently proposed Powerball gradient and AdaBelief to further expedite and stabilize parameter optimization. Extensive experiments on 22 regression datasets with various sizes and dimensionalities validated the superiority of FCM-RDpA over MBGD-RDA, especially when the feature dimensionality is higher. We also propose an additional approach, FCM-RDpAx, that further improves FCM-RDpA by using augmented features in both the antecedents and consequents of the rules.},
  archive      = {J_ISCI},
  author       = {Zhenhua Shi and Dongrui Wu and Chenfeng Guo and Changming Zhao and Yuqi Cui and Fei-Yue Wang},
  doi          = {10.1016/j.ins.2021.05.084},
  journal      = {Information Sciences},
  pages        = {490-504},
  shortjournal = {Inf. Sci.},
  title        = {FCM-RDpA: TSK fuzzy regression model construction using fuzzy C-means clustering, regularization, droprule, and powerball adabelief},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Isolation forests and landmarking-based representations for
clustering algorithm recommendation using meta-learning. <em>ISCI</em>,
<em>574</em>, 473–489. (<a
href="https://doi.org/10.1016/j.ins.2021.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data clustering problem can be described as the task of organizing data into groups, where in each group the objects share some similar attributes. Most of the problems clustering algorithms address do not have a prior solution. This paper addresses the algorithm selection challenge for data clustering , while taking the difficulty in evaluating clustering solutions into account. We present a new meta-learning method for recommending the most suitable clustering algorithm for a dataset. Based on concepts from the isolation forest algorithm, we propose a new similarity measure between datasets. Our proposed dataset characterization methods generate an embedding for a dataset using this similarity measure, which is then used to improve the quality of the problem’s characterization. The method utilizes landmarking concepts to characterize the dataset and then, inspired by the DeepFM algorithm, applies meta-learning to rank the candidate algorithms that are expected to perform the best for the current dataset. This ranking could, among other things, support AutoML systems. Our approach is evaluated on a corpus of 100 publicly available benchmark datasets. We compare our method’s ranking performance to that of existing meta-learning methods and show the dominance of our method in terms of predictive performance and computational complexity .},
  archive      = {J_ISCI},
  author       = {Itay Gabbay and Bracha Shapira and Lior Rokach},
  doi          = {10.1016/j.ins.2021.06.033},
  journal      = {Information Sciences},
  pages        = {473-489},
  shortjournal = {Inf. Sci.},
  title        = {Isolation forests and landmarking-based representations for clustering algorithm recommendation using meta-learning},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving voluntary-tallying leader election for
internet of things. <em>ISCI</em>, <em>574</em>, 461–472. (<a
href="https://doi.org/10.1016/j.ins.2021.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Things (IoT) is commonly deployed with devices of limited power and computation capability. A centralized IoT architecture provides a simplified management for IoT system but brings redundancy by the unnecessary data traffic with a data center . A decentralized IoT reduces the cost on data traffic and is resilient to the single-point-of-failure. The blockchain technique has attracted a large amount of research, which is redeemed as a perspective of decentralized IoT system infrastructure. It also brings new privacy challenges for that the blockchain is a public ledger of all digital events executed and shared among all participants. The decentralized IoT system relies on the leader election deeply to implement the decentralized communications among the distributed nodes. The conventional leader election must have a centralized authority, contrasting to the decentralization. As an alternative, self-tallying type schemes have been proposed in the literature for decentralized systems. These schemes suffer from adaptive and abortive issues. Also, some additional factors should be considered, such as the availability of candidate nodes. If the candidate node is unavailable after the voting phase due to being offline or ongoing tasks, the next available candidate should be elected. To accommodate such a need, in this paper, we propose a new leader election paradigm called voluntary-tallying leader election, which achieves the core requirements such as ballet secrecy, voter privacy and the additional feature of voluntary-tallying. We formalize the system and security models for this new election paradigm and present a secure and practical construction.},
  archive      = {J_ISCI},
  author       = {Tong Wu and Guomin Yang and Liehuang Zhu and Yulin Wu},
  doi          = {10.1016/j.ins.2021.06.028},
  journal      = {Information Sciences},
  pages        = {461-472},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving voluntary-tallying leader election for internet of things},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Info2vec: An aggregative representation method in
multi-layer and heterogeneous networks. <em>ISCI</em>, <em>574</em>,
444–460. (<a href="https://doi.org/10.1016/j.ins.2021.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mapping nodes in multi-layer and heterogeneous networks to low-dimensional vectors has wide applications in community detection, node classification and link prediction, etc. In this paper, a generalized graph representation learning framework is proposed for information aggregation in various multi-layer and heterogeneous networks . Specifically, an aggregation network is firstly obtained by graph transformation, generating potential information links based on the network structure on different layers. A comprehensive measurement of the similarity between different nodes in the aggregation network is then carried out by aggregating the information of nodes’ identities of structure, nearness and attributes etc. Based on the comprehensive similarity values the nodes have, a context graph can be generated using a simple edge percolation method, which provides a basis facilitating some important downstream work such as classification, clustering and prediction etc. We demonstrate the effectiveness of the new framework in identifying subnetworks in a cyberspace network, where it significantly outperforms all the existing baselines.},
  archive      = {J_ISCI},
  author       = {Guoli Yang and Yuanji Kang and Xianqiang Zhu and Cheng Zhu and Gaoxi Xiao},
  doi          = {10.1016/j.ins.2021.06.013},
  journal      = {Information Sciences},
  pages        = {444-460},
  shortjournal = {Inf. Sci.},
  title        = {Info2vec: An aggregative representation method in multi-layer and heterogeneous networks},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combined cause inference: Definition, model and performance.
<em>ISCI</em>, <em>574</em>, 431–443. (<a
href="https://doi.org/10.1016/j.ins.2021.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many methods have been developed for discovering causal relationships from observed data. However, as an important kind of causes existing in many causal systems , combined causes (e.g. multi-factor causes consisting of two or more component variables that individually might not be a cause) have not received enough attention. The existing approach includes both individual and combined variables in the causal discovery process using constraint-based methods, can neither distinguish a set of Markov equivalence classes nor identify a combined cause containing one (or more) individual cause(s), therefore can output only some combined causes, instead of all combined causes. In this paper, we first subsume all possible combined causes into three types and give them formal definitions, then extend the additive noise model (ANM) to infer combined causes. We show that if a candidate variable set X w.r.t. a target Y satisfies: (1) allowing ANM for only the forward direction X → Y X→Y , and (2) no disturbance variable is contained in X , i.e., removing any component of X will weaken the causal relationship between X and Y , then X forms a combined cause. Based on this finding, we develop an efficient method to discover combined causes. Furthermore, we also conduct extensive experiments to validate the proposed method on both synthetic and real-world data sets.},
  archive      = {J_ISCI},
  author       = {Hao Zhang and Chuanxu Yan and Shuigeng Zhou and Jihong Guan and Ji Zhang},
  doi          = {10.1016/j.ins.2021.06.004},
  journal      = {Information Sciences},
  pages        = {431-443},
  shortjournal = {Inf. Sci.},
  title        = {Combined cause inference: Definition, model and performance},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-archive algorithm with decomposition and fitness
allocation for multi-modal multi-objective optimization. <em>ISCI</em>,
<em>574</em>, 413–430. (<a
href="https://doi.org/10.1016/j.ins.2021.05.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a two-archive algorithm with decomposition and fitness allocation for multi-modal multi-objective optimization problems which have more than one Pareto-optimal solution set corresponding to the same objective vector. The general framework of the proposed method uses two archives, the convergence archive (CA) and the diversity archive (DA), which focus on the convergence and diversity of population, respectively. Both archives are based on a decomposition-based framework. In CA, the population update strategy adopts a fitness scheme, which is designed according to the change state of population during evolution, combining the convergence of the objective space with the diversity of the decision space. In DA, we use the crowding distance strategy to ensure the diversity of the decision space. Moreover, different neighborhood criteria are used to ensure the convergence and diversity of population for two archives. The algorithm is shown to not only locate and maintain a larger number of Pareto-optimal sets, but also to obtain good diversity and convergence in both the decision and objective spaces. In addition, the proposed algorithm is empirically compared with five state-of-the-art evolutionary algorithms on two series of test functions. Comparison results show that the proposed algorithm has better performance than the competing algorithms.},
  archive      = {J_ISCI},
  author       = {Zhipan Li and Juan Zou and Shengxiang Yang and Jinhua Zheng},
  doi          = {10.1016/j.ins.2021.05.075},
  journal      = {Information Sciences},
  pages        = {413-430},
  shortjournal = {Inf. Sci.},
  title        = {A two-archive algorithm with decomposition and fitness allocation for multi-modal multi-objective optimization},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperplane-driven and projection-assisted search for solving
many-objective optimization problems. <em>ISCI</em>, <em>574</em>,
394–412. (<a href="https://doi.org/10.1016/j.ins.2021.05.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Counterpoising convergence and distribution becomes more intractable in many-objective optimization where the number of objectives exceeds three, evolutionary algorithms (EAs) via decomposition are prominent in convergence promotion yet suffer from diversity loss. The setting of direction vectors (DVs), scalarizing function (SF) and selection strategy can significantly affect the performance of this sort of algorithms. To remedy the issue, we develop a hyperplane driven and projection assisted EA, referred here as HPEA, using three-stage search. At the very beginning, search is performed only along the extreme objective-wise points to capture the corners of Pareto front (PF). After that, the convergence and diversity are coordinated, a set of DVs, adapted by the evolving population itself, is utilized to extend the search wideness, and two novel SFs are exploited to collect elites in each subregion for approaching a more complete PF. At last, diversity is emphasized, a projection distance aided elimination mechanism is employed to prune poorly diversified solutions one by one. Note that hyperplane utilized at second stage aims at identifying well-converged solutions, the rationale behind using two novel SFs is to take complementary effects of different criteria. The resultant HPEA is compared with several state-of-the-art multiobjective EAs on handling various types of many-objective problems. Extensive empirical studies demonstrate the effectiveness and competitiveness of the proposal in obtaining high quality solution set.},
  archive      = {J_ISCI},
  author       = {Jiajun Zhou and Liang Gao and Xinyu Li and Chunjiang Zhang and Chengyu Hu},
  doi          = {10.1016/j.ins.2021.05.080},
  journal      = {Information Sciences},
  pages        = {394-412},
  shortjournal = {Inf. Sci.},
  title        = {Hyperplane-driven and projection-assisted search for solving many-objective optimization problems},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How does rumor spreading affect people inside and outside an
institution. <em>ISCI</em>, <em>574</em>, 377–393. (<a
href="https://doi.org/10.1016/j.ins.2021.05.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the propagation characteristics of rumors in an institution and develop the rumor dissemination model inside the institution. Different from the traditional model, a person in the proposed model can make a judgement about the message and decide to propagate it or refute it, and most people inside the institution can refute the rumor spreaders and propagate the genuine messages to uninformed people when they have confirmed the message is a rumor. Then, we split all the people into two institutions (inside and outside). Since the rumors and genuine messages from the institution can have a non-negligible impact on people outside the institution, we put forward a new double-institution rumor propagation model , and the model considers the impact of messages on the inside and outside of the institution simultaneously. Based on the two proposed models, the basic reproduction numbers are obtained respectively, and the local and global stability of the rumor-free equilibrium points are discussed separately. We numerically simulate the propagation of rumors in small-world networks. The simulation is carried out to verify the validity of the proposed model, and our model is closer to the reality than traditional models.},
  archive      = {J_ISCI},
  author       = {Zhongkai Dang and Lixiang Li and Wei Ni and Renping Liu and Haipeng Peng and Yixian Yang},
  doi          = {10.1016/j.ins.2021.05.085},
  journal      = {Information Sciences},
  pages        = {377-393},
  shortjournal = {Inf. Sci.},
  title        = {How does rumor spreading affect people inside and outside an institution},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph visual tracking using conditional uncertainty
minimization and minibatch monte carlo inference. <em>ISCI</em>,
<em>574</em>, 363–376. (<a
href="https://doi.org/10.1016/j.ins.2021.05.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel visual tracking method based on conditional uncertainty minimization (CUM), minibatch Monte Carlo (MMC), and non-nested sampling (NNS). We represent a target as a Markov network with nodes and edges, where each node corresponds to the corresponding pixel of the target and each edge describes the relations among the pixels. The nodes are then grouped into optimal cliques using the proposed CUM, which minimizes the conditional uncertainty ( i.e. the variance of the conditional expectation) between two cliques . The aforementioned minimization process is facilitated using the proposed NNS. During visual tracking, Markov networks evolve across frames and describe the geometrically varying appearances of the target. In many cases, these networks cannot represent the targets perfectly; however, the configurations of the target can be inferred accurately using the CUM and the best configuration can be found at an early stage of the Monte Carlo sampling using the proposed MMC. The numerical results demonstrate that our method qualitatively and quantitatively outperforms other state-of-the-art trackers on standard benchmark datasets. In particular, our method accurately tracks deformable objects in realtime.},
  archive      = {J_ISCI},
  author       = {Junseok Kwon},
  doi          = {10.1016/j.ins.2021.05.052},
  journal      = {Information Sciences},
  pages        = {363-376},
  shortjournal = {Inf. Sci.},
  title        = {Graph visual tracking using conditional uncertainty minimization and minibatch monte carlo inference},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). KB-QA based on multi-task learning and negative sample
generation. <em>ISCI</em>, <em>574</em>, 349–362. (<a
href="https://doi.org/10.1016/j.ins.2021.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question answering over knowledge base (KB-QA) has recently become a popular research topic in NLP. One popular approach to solve the KB-QA problem is to use a pipeline of several NLP modules. Most recent works show promising results in the KB-QA task through improving the accuracy of the subtasks. However, KB-QA is still a challenging problem. First, KB-QA is a pipeline of several NLP modules. Therefore, the results of the previous module will affect the prediction of next module, inevitably resulting in the problem of error propagation. Second, in relation detection, we often need to generate negative samples according to the question to help the model distinguish the correct relations. Existing methods usually employ simple sampling methods to generate incorrect relations. However, these methods do not have a powerful ability to fit the space of fake relations, so the negative samples generated by these methods are poor and degrade the performance of the model. Therefore, to solve these problems, we propose a new multi-task learning framework for KB-QA and design a distance loss to solve the error propagation problem. Additionally, to improve the quality of negative samples in relation detection, we propose a general sample generator.},
  archive      = {J_ISCI},
  author       = {Liao Cheng and Feiyang Xie and Jiangtao Ren},
  doi          = {10.1016/j.ins.2021.06.021},
  journal      = {Information Sciences},
  pages        = {349-362},
  shortjournal = {Inf. Sci.},
  title        = {KB-QA based on multi-task learning and negative sample generation},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inferring statistical trends of the COVID19 pandemic from
current data. Where probability meets fuzziness. <em>ISCI</em>,
<em>574</em>, 333–348. (<a
href="https://doi.org/10.1016/j.ins.2021.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce unprecedented tools to infer approximate evolution features of the COVID19 outbreak when these features are altered by containment measures. In this framework we present: (1) a basic tool to deal with samples that are both truncated and non independently drawn, and (2) a two-phase random variable to capture a game changer along a process evolution. To overcome these challenges we lie in an intermediate domain between probability models and fuzzy sets, still maintaining probabilistic features of the employed statistics as the reference KPI of the tools. This research uses as a benchmark the daily cumulative death numbers of COVID19 in two countries, with no any ancillary data . Numerical results show: (i) the model capability of capturing the inflection point and forecasting the end-of-infection time and related outbreak size, and (ii) the out-performance of the model inference method according to conventional indicators.},
  archive      = {J_ISCI},
  author       = {Bruno Apolloni},
  doi          = {10.1016/j.ins.2021.06.011},
  journal      = {Information Sciences},
  pages        = {333-348},
  shortjournal = {Inf. Sci.},
  title        = {Inferring statistical trends of the COVID19 pandemic from current data. where probability meets fuzziness},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An intelligent computer-aided approach for atrial
fibrillation and atrial flutter signals classification using modified
bidirectional LSTM network. <em>ISCI</em>, <em>574</em>, 320–332. (<a
href="https://doi.org/10.1016/j.ins.2021.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Atrial fibrillation (AF) and atrial flutter (AFL) are the most common arrhythmias. Due to the similar clinical symptoms, both are one of the main causes of misdiagnosis for physicians. The visual inspection of electrocardiogram (ECG) signals is the most traditional detection strategy, however, it is often laborious and time-consuming. Thus, we specially propose a modified bidirectional long short-term memory (MB-LSTM) network for AF and AFL signals recognition. In this network, inspired by illustrious Squeeze-and-Excitation network, a feature recalibration strategy is performed on existing B-LSTM network so that this can enable the model to adaptively reallocate feature representation and thus alleviate the problem of information redundancy in B-LSTM to a certain extent. Further, we embed the proposed network into a convolutional network frame with attention mechanism and use existing LSTM, B-LSTM networks as control groups to evaluate its effectiveness with a subject-independent validation strategy on the two publicly available databases. The result shows that the model yields superior classification performance with an accuracy of 99.1\% and 98.4\% than several state-of-the-art methods while confirming the effectiveness of MB-LSTM. Particularly, the qualitative analysis is provided to elaborate on the mechanism of performance improvement, showing promising model practicability as an intelligent and efficient tool to assist physicians.},
  archive      = {J_ISCI},
  author       = {Jibin Wang},
  doi          = {10.1016/j.ins.2021.06.009},
  journal      = {Information Sciences},
  pages        = {320-332},
  shortjournal = {Inf. Sci.},
  title        = {An intelligent computer-aided approach for atrial fibrillation and atrial flutter signals classification using modified bidirectional LSTM network},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection based on label distribution and fuzzy
mutual information. <em>ISCI</em>, <em>574</em>, 297–319. (<a
href="https://doi.org/10.1016/j.ins.2021.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, high-dimensionality is the most prominent characteristic of the data. An efficient pre-processing step, named feature selection, is required to reduce “the curse of dimensionality” caused by irrelevant and redundant features in the high-dimensional feature space. However, the difference in significance of the related labels of an instance is ubiquitous in most practical applications. Motivated by that, in this paper, the label distribution learning is integrated into multi-label feature selection, which is proposed to mine the more supervised information ignored by equivalence relations in the label space of multi-label data. With the perspective of granular computing , a novel label enhancement algorithm is presented based on the fuzzy similarity relation, which utilizes the similarity between instances to explore the hidden label relevance and transform the logical label in multi-label data into a label distribution. Then, a label distribution feature selection algorithm is presented to measure the significance of features with the fuzzy mutual information framework. Moreover, on twelve publicly available multi-label datasets, the presented algorithm is compared with six state-of-the-art multi-label feature selection algorithms. As indicated in the experimental results, the presented algorithm achieves significant improvement over the extant algorithms.},
  archive      = {J_ISCI},
  author       = {Chuanzhen Xiong and Wenbin Qian and Yinglong Wang and Jintao Huang},
  doi          = {10.1016/j.ins.2021.06.005},
  journal      = {Information Sciences},
  pages        = {297-319},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection based on label distribution and fuzzy mutual information},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SEND: A novel dissimilarity metric using ensemble properties
of the feature space for clustering numerical data. <em>ISCI</em>,
<em>574</em>, 279–296. (<a
href="https://doi.org/10.1016/j.ins.2021.05.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The clustering is an unsupervised learning technique for grouping the unlabeled data based on the proximity between the data points. Therefore, the performance of clustering techniques mainly depends on the proximity measures. The computation of dissimilarity in high dimensional and noisy datasets as well as datasets with imbalanced feature scale, which appear in various applications, is a challenging task. To counter these challenges, we propose a new distance metric to compute the dissimilarity between data points by combining the ensemble properties, entropy and weight information of feature vectors. We consider the statistical information and entropy along each features to compute the dissimilarity between the points. Then each feature is associated with weight based on its distribution information. The proposed Similarity measure based on Entropy for Numerical Datasets (SEND), is free from any domain specific parameters and there are no underlying assumptions about the distribution of the data. The proposed metric is applied on different type of clustering techniques to evaluate its performance. Experimental analyses on synthetic as well as real datasets demonstrate the efficacy of the proposed metric in terms of cluster quality, accuracy, execution time, robustness against noise and its ability to handle the high dimension datasets.},
  archive      = {J_ISCI},
  author       = {Gaurav Mishra and Amit Kumar Kar and Amaresh Chandra Mishra and Sraban Kumar Mohanty and M.K. Panda},
  doi          = {10.1016/j.ins.2021.05.059},
  journal      = {Information Sciences},
  pages        = {279-296},
  shortjournal = {Inf. Sci.},
  title        = {SEND: A novel dissimilarity metric using ensemble properties of the feature space for clustering numerical data},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhanced linguistic computational models and their
similarity with yager’s computing with words. <em>ISCI</em>,
<em>574</em>, 259–278. (<a
href="https://doi.org/10.1016/j.ins.2021.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A generalized computational framework for Computing with Words (CWW) using linguistic information (LI) was proposed by Prof. Yager. This framework is based on three steps: translation, manipulation and retranslation. Other works have independently proposed the Linguistic Computational Models (LCMs) to express the semantics of LI using Type-1 Fuzzy Sets and Ordinal term sets. The former is called the extension principle, and the latter, the symbolic method. We found that a high degree of similarity can be drawn between these methodologies and Yager’s CWW framework, but no discussion exists in the literature of the similarity drawn between them. Further, the extension principle has a drawback: it considers LI to be equally weighted in the aggregation phase. Also, Intuitionistic fuzzy sets (IFSs) and rough sets have gained popularity to model semantics of LI, but no CWW methodologies have been proposed using them. Thus, the novel contributions of this work are twofold. Firstly, showing the similarity of the linguistic computational models based on extension principle and symbolic method, to the Yager’s generalized CWW framework. Secondly, proposing a new augmented flexible weighting for LCM based on the extension principle and two novel CWW methodologies based on IFS and rough sets.},
  archive      = {J_ISCI},
  author       = {Prashant K. Gupta and Deepak Sharma and Javier Andreu-Perez},
  doi          = {10.1016/j.ins.2021.05.038},
  journal      = {Information Sciences},
  pages        = {259-278},
  shortjournal = {Inf. Sci.},
  title        = {Enhanced linguistic computational models and their similarity with yager’s computing with words},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficiently answering top-k frequent term queries in
temporal-categorical range. <em>ISCI</em>, <em>574</em>, 238–258. (<a
href="https://doi.org/10.1016/j.ins.2021.05.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the procedure of extracting hot topics and detecting emerging topic, counting term frequency is one of the most inevitable and time-consuming steps. For the purpose of text exploration, users may change the query range frequently, and the adjustment of ranges would cause recalculation of term frequency when finding hot terms, bringing unacceptable time cost. In addition, real-time update of dimensions is also a challenge. To address these problems, we first propose a novel data structure based on prefix cube to store terms and their frequencies, so that the time for counting term frequency gets a significant reduction. Based on the data structure , we propose an efficient range query algorithm that significantly decreases the number of input word lists involved in top-k queries. Considering the underlying dimension update, we also design an efficient maintenance mechanism to cope with different dimension updates. Finally, we conduct comprehensive experiments to validate the effectiveness of the proposed structure and the efficiency of the optimized query algorithm. We also prove that using the proposed data structure, the time cost of our algorithms in hot topic extraction and emerging topic detection can be reduced by about ten times compared with the previous algorithms.},
  archive      = {J_ISCI},
  author       = {Zhenying He and Lu Wang and Chang Lu and Yinan Jing and Kai Zhang and Weili Han and Jianxin Li and Chengfei Liu and X. Sean Wang},
  doi          = {10.1016/j.ins.2021.05.081},
  journal      = {Information Sciences},
  pages        = {238-258},
  shortjournal = {Inf. Sci.},
  title        = {Efficiently answering top-k frequent term queries in temporal-categorical range},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coronavirus fake news detection via MedOSINT check in health
care official bulletins with CBR explanation: The way to find the real
information source through OSINT, the verifier tool for official
journals. <em>ISCI</em>, <em>574</em>, 210–237. (<a
href="https://doi.org/10.1016/j.ins.2021.05.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research aims to design and prototype a tool to perform intelligence on open sources (OSINT), specifically on official medical bulletins for the detection of false news. MedOSINT is a modular tool that can be adapted to process information from different medical official bulletins. From the processed information, intelligence is generated for decision making, validating the veracity of the COVID-19 news. The tool is compared with other options and it is verified that MedOSINT outperforms the current options when analyzing official bulletins. Moreover, it is complemented with an expert explanation provided by a Case-Based Reasoning (CBR) system. This is proved to be an ideal complement because it can find explanatory cases for an explanation-by-example justification.},
  archive      = {J_ISCI},
  author       = {Sergio Mauricio Martinez Monterrubio and Amaya Noain-Sánchez and Elena Verdú Pérez and Rubén González Crespo},
  doi          = {10.1016/j.ins.2021.05.074},
  journal      = {Information Sciences},
  pages        = {210-237},
  shortjournal = {Inf. Sci.},
  title        = {Coronavirus fake news detection via MedOSINT check in health care official bulletins with CBR explanation: The way to find the real information source through OSINT, the verifier tool for official journals},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative indoor 3D mapping and modeling using LiDAR data.
<em>ISCI</em>, <em>574</em>, 192–209. (<a
href="https://doi.org/10.1016/j.ins.2021.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point clouds and models with semantic information facilitate various indoor automation, ranging from indoor robotics to emergency responses. Studies are currently being conducted on semantic labeling and modeling based on offline mapped point clouds, in which, the performance is strongly limited by the mapping process. To address this issue, we propose a framework to cooperatively perform the three tasks of semantic labeling, mapping, and 3D modeling of point clouds. First, our framework uses a deep-learning-assisted method to perform frame-level point cloud semantic labeling. Subsequently, point cloud frames with semantic labels are used to extract the structural planes of buildings, followed by the generation of line structures from the planes. Then, these frames are used to estimate the initial poses of a 3D sensor for data collection. In the subsequent pose optimization process, the initial poses are optimized under the constraints of the structural planes. Finally, the optimized poses are used to integrate semantic frames and line structures to generate a point cloud map and 3D line model of buildings. The experimental results show that the proposed method achieves better results than the state-of-the-art methods that separately perform one of the two tasks.},
  archive      = {J_ISCI},
  author       = {Chenglu Wen and Jinbin Tan and Fashuai Li and Chongrong Wu and Yitai Lin and Zhiyong Wang and Cheng Wang},
  doi          = {10.1016/j.ins.2021.06.006},
  journal      = {Information Sciences},
  pages        = {192-209},
  shortjournal = {Inf. Sci.},
  title        = {Cooperative indoor 3D mapping and modeling using LiDAR data},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A synchronous feature learning method for multiplex network
embedding. <em>ISCI</em>, <em>574</em>, 176–191. (<a
href="https://doi.org/10.1016/j.ins.2021.05.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with single-layer networks, multiplex networks can describe real-world scenarios in more detail while suffering from requiring considerable computing and storage resources at the same time. Network feature learning , which aims to embed networks into a low dimensional space, is an effective method for solving these problems. Currently, research on multiplex network embedding faces two major challenges: how to make full use of the connected information in different layers and how to embed multiplex networks into a unified space. In this paper, a novel multiplex network embedding model is proposed to solve these two problems. It preserves all the first-, second- and multi-order proximities in multiplex networks by optimizing the corresponding objective functions. The network reconstruction step combines information of different types of relations in other layers while maintaining their distinctive properties. The proposed synchronous learning strategy provides a path to embed multiplex networks into a unified space. Extensive experiments on three real applications: visualization, link prediction and node classification are conducted to validate the effectiveness of the proposed method. The experimental results show that it achieves better or comparable performance compared with several state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Xiangyi Teng and Jing Liu and Liqiang Li},
  doi          = {10.1016/j.ins.2021.05.083},
  journal      = {Information Sciences},
  pages        = {176-191},
  shortjournal = {Inf. Sci.},
  title        = {A synchronous feature learning method for multiplex network embedding},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronizing billion-scale automata. <em>ISCI</em>,
<em>574</em>, 162–175. (<a
href="https://doi.org/10.1016/j.ins.2021.05.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synchronizing sequences for large-scale automata have gained popularity recently due to their practical use cases especially to have a faster and better testing process. In many applications, shorter sequences imply less overhead and faster processing time but the problem of finding the shortest synchronizing sequence is NP-hard and requires heuristic approaches to be solved. State-of-the-art heuristics manage to obtain desirable, short sequences with relatively small execution times. However, all these heuristics suffer their quadratic memory complexity and fail to scale when the input automaton gets larger. In this paper, we propose an approach exploiting GPUs and hybrid parallelism which can generate synchronizing sequences even for billion-scale automata, in a short amount of time. Overall, the algorithm can generate a synchronizing sequence for a random automaton with n = 10 8 n=108 states in 12.1 s, n = 5 × 10 8 n=5×108 states in 69.1 s, and billion states in 148.2 s.},
  archive      = {J_ISCI},
  author       = {Mustafa Kemal Taş and Kamer Kaya and Hüsnü Yenigün},
  doi          = {10.1016/j.ins.2021.05.072},
  journal      = {Information Sciences},
  pages        = {162-175},
  shortjournal = {Inf. Sci.},
  title        = {Synchronizing billion-scale automata},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybridization approach with predicted solution candidates
for improving population-based optimization algorithms. <em>ISCI</em>,
<em>574</em>, 133–161. (<a
href="https://doi.org/10.1016/j.ins.2021.04.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent proliferation of population-based meta-heuristics designed for solving optimization problems and their successes confirm that more promising techniques inspired by physical phenomena or biological systems are desired. Therefore, in this paper, a novel hybridization approach is proposed to improve the performance of optimization algorithms . The approach replaces a small number of worst solutions obtained by a meta-heuristic with predicted candidates without altering its search operators. Specifically, a target fitness value of the predicted candidate is determined based on the fitness of the population and a search strategy. Then, a calibration problem is solved to infer its decision variables. In this study, the proposed hybridization technique is applied to ten state-of-the-art population-based algorithms. The meta-heuristics and hybrids are evaluated on 82 functions, four engineering problems, and a new challenging problem of estimating a constant in Markov’s inequality using minimal polynomials of different degrees. The experimental results reveal the superiority of the hybrids over their counterparts and confirm the suitability of the proposed approach for improving the efficiency of meta-heuristics.},
  archive      = {J_ISCI},
  author       = {Mariusz Oszust and Grzegorz Sroka and Karol Cymerys},
  doi          = {10.1016/j.ins.2021.04.082},
  journal      = {Information Sciences},
  pages        = {133-161},
  shortjournal = {Inf. Sci.},
  title        = {A hybridization approach with predicted solution candidates for improving population-based optimization algorithms},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A structured methodology for designing distributed
algorithms for mobile entities. <em>ISCI</em>, <em>574</em>, 111–132.
(<a href="https://doi.org/10.1016/j.ins.2021.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following the wide investigation in distributed computing issues by mobile entities of the last two decades, we consider the need of a structured methodology to tackle the arisen problems. The aim is to simplify both the design of the resolution algorithms and the writing of the required correctness proofs . We would encourage the usage of a common framework in order to help both algorithm designers and reviewers in the intricate work of delivering and analyzing the proposed resolution strategies. We demonstrate the effectiveness and usefulness of the new methodology by highlighting various peculiarities arising in different scenarios. In particular, we consider two different tasks for asynchronous entities moving in the Euclidean plane and in graphs, respectively. We show how two resolution strategies have been designed by following the accurate guide dictated by the methodology. Furthermore, we also show how the corresponding correctness proofs are obtained.},
  archive      = {J_ISCI},
  author       = {Serafino Cicerone and Gabriele Di Stefano and Alfredo Navarra},
  doi          = {10.1016/j.ins.2021.05.043},
  journal      = {Information Sciences},
  pages        = {111-132},
  shortjournal = {Inf. Sci.},
  title        = {A structured methodology for designing distributed algorithms for mobile entities},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interval-valued seminormed fuzzy operators based on
admissible orders. <em>ISCI</em>, <em>574</em>, 96–110. (<a
href="https://doi.org/10.1016/j.ins.2021.05.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy integral is a well-known class of aggregation operators, which includes the Sugeno integral and Shilkret integral. When performing fuzzy integration over vectors of interval values, recent literature showed that using a simplistic method to independently deal with the lower and upper bounds of interval-valued inputs is sometimes not reasonable in practice. This motivated us to conduct a necessary and thorough study of the possible structures and properties of interval-valued fuzzy operators. This study investigated concepts and revealed some related properties of admissible orders and cones such that interval-valued seminormed fuzzy operator (ISFO) is then well defined. We introduce the relevant set and systematically examine some of its main properties, which forms the basis of the fundamental structural analysis of the ISFO. Furthermore, relationships between the proposed concepts are discussed, and several Jensen-type inequalities for the ISFO are examined.},
  archive      = {J_ISCI},
  author       = {Michał Boczek and LeSheng Jin and Marek Kaluszka},
  doi          = {10.1016/j.ins.2021.05.065},
  journal      = {Information Sciences},
  pages        = {96-110},
  shortjournal = {Inf. Sci.},
  title        = {Interval-valued seminormed fuzzy operators based on admissible orders},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive online learning for IoT botnet detection.
<em>ISCI</em>, <em>574</em>, 84–95. (<a
href="https://doi.org/10.1016/j.ins.2021.05.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the number of Internet of Things (IoT) devices proliferating, the traffic volume of IoT-based attacks has shown a gradually increasing trend. The IoT botnet attack, which aims to commit real, efficient, and profitable cybercrimes , has become one of the most severe IoT threats. Applying traditional techniques to IoT is difficult due to its particular characteristics, such as resource-constrained devices, massive volumes of data, and real-time requirements. In this paper, we explore an adaptive online learning strategy for real-time IoT botnet attack detection. Furthermore, we operate the proposed adaptive strategy in conjunction with online ensemble learning . To evaluate the proposed strategy, we use real IoT traffic data, including benign traffic data and botnet traffic data infected by Mirai. In real-time IoT botnet attack detection, our experimental results demonstrate that the proposed adaptive online learning strategy achieves remarkable performance.},
  archive      = {J_ISCI},
  author       = {Zhou Shao and Sha Yuan and Yongli Wang},
  doi          = {10.1016/j.ins.2021.05.076},
  journal      = {Information Sciences},
  pages        = {84-95},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive online learning for IoT botnet detection},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting predicted answer in label aggregation to make
better use of the crowd wisdom. <em>ISCI</em>, <em>574</em>, 66–83. (<a
href="https://doi.org/10.1016/j.ins.2021.05.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, crowdsourcing is a widespread and effective method to gather the crowd wisdom. At the same time, label aggregation is used to aggregate the noisy and biased data generated by the crowd. In the real-world crowdsourcing tasks, most workers only answer a small fraction of questions, which makes the collected answer sparse. However, the existing label aggregation approaches often build upon some probabilistic modeling procedures which is sensitive to the data sparsity . In this paper, we exploit the predicted answers to improve the performance of label aggregation and propose PLA (Prediction-based Label Aggregation) to intelligently aggregate the crowd wisdom. With PLA, we firstly learn representations to capture the characteristics of the workers and questions. Then we deploy a neural network model to predict the answer given by different workers. After that we add the most valuable predicted answers to the answer set. Finally, we use the augmented answer set to enhance representative label aggregation algorithms. To validate our proposed PLA, we compare it with other 6 existing methods on 8 real-world datasets. Our results show that PLA can enhance the performance of different aggregation algorithms in crowdsourcing tasks and achieves up to 16\% performance improvement.},
  archive      = {J_ISCI},
  author       = {Jiacheng Liu and Feilong Tang and Long Chen and Yanmin Zhu},
  doi          = {10.1016/j.ins.2021.05.060},
  journal      = {Information Sciences},
  pages        = {66-83},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting predicted answer in label aggregation to make better use of the crowd wisdom},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reliability check via weight similarity in
privacy-preserving multi-party machine learning. <em>ISCI</em>,
<em>574</em>, 51–65. (<a
href="https://doi.org/10.1016/j.ins.2021.05.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-party machine learning is a paradigm in which multiple participants collaboratively train a machine learning model to achieve a common learning objective without sharing their privately owned data. The paradigm has recently received a lot of attention from the research community aimed at addressing its associated privacy concerns. In this work, we focus on addressing the concerns of data privacy, model privacy, and data quality associated with privacy-preserving multi-party machine learning, i.e., we present a scheme for privacy-preserving collaborative learning that checks the participants’ data quality while guaranteeing data and model privacy. In particular, we propose a novel metric called weight similarity that is securely computed and used to check whether a participant can be categorized as a reliable participant (holds good quality data) or not. The problems of model and data privacy are tackled by integrating homomorphic encryption in our scheme and uploading encrypted weights, which prevent leakages to the server and malicious participants, respectively. The analytical and experimental evaluations of our scheme demonstrate that it is accurate and ensures data and model privacy.},
  archive      = {J_ISCI},
  author       = {Kennedy Edemacu and Beakcheol Jang and Jong Wook Kim},
  doi          = {10.1016/j.ins.2021.05.071},
  journal      = {Information Sciences},
  pages        = {51-65},
  shortjournal = {Inf. Sci.},
  title        = {Reliability check via weight similarity in privacy-preserving multi-party machine learning},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From comonotone commuting properties of seminormed fuzzy
integrals to solving two open problems. <em>ISCI</em>, <em>574</em>,
33–50. (<a href="https://doi.org/10.1016/j.ins.2021.05.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we characterize the class of solutions for two open problems: one is Problem 1 which is posed by Ouyang et al. (2009), other is Problem 2 which is proposed by Borzová-Molnárová et al. (2015). Many results being wider than the previous ones have been stated. All are summarized in Theorems: 2,3,4,5,7,9,11 and 12.},
  archive      = {J_ISCI},
  author       = {Tran Nhat Luan and Do Huy Hoang and Tran Minh Thuyet},
  doi          = {10.1016/j.ins.2021.05.082},
  journal      = {Information Sciences},
  pages        = {33-50},
  shortjournal = {Inf. Sci.},
  title        = {From comonotone commuting properties of seminormed fuzzy integrals to solving two open problems},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). R-CTSVM+: Robust capped l1-norm twin support vector machine
with privileged information. <em>ISCI</em>, <em>574</em>, 12–32. (<a
href="https://doi.org/10.1016/j.ins.2021.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the new paradigm, learning using privileged information (LUPI) creates a more informative strategy for tasks to achieve better prediction. SVM based methods including SVM+ and TSVM+, have achieved considerable success in LUPI on the clean data. However, these methods typically suffer from the noise and outliers contained in the data, which leads to larger fluctuations in performance. To handle this problem, in this paper, we propose a novel Robust Capped L 1 -norm Twin Support Vector Machine with Privileged Information (R-CTSVM+). The proposed pair of regularization functions (up- and down-bound) can definitely help to increase the learning model’s tolerance to disturbance, because the up-bound function aims to maximize the lower bound of the perturbation of both main feature and privilege feature, meanwhile, the down-bound function aims to minimize the upper bound of the perturbation of both main feature and privilege feature. Moreover, as the widely employed squared L 2 -norm distance typically exaggerates the impact of outliers, we adopt the capped L 1 regularized distance to further guarantee the robustness of the model. We present that the resulted optimization problem is theoretically converged and can be solved using an effective alternating optimization procedure . Experimental results on benchmark datasets indicate that the proposed robust model can produce superior performance in the case where data samples contain much noise and outliers.},
  archive      = {J_ISCI},
  author       = {Yanmeng Li and Huaijiang Sun and Wenzhu Yan and Qiongjie Cui},
  doi          = {10.1016/j.ins.2021.06.003},
  journal      = {Information Sciences},
  pages        = {12-32},
  shortjournal = {Inf. Sci.},
  title        = {R-CTSVM+: Robust capped l1-norm twin support vector machine with privileged information},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Sparse reconstruction via the mixture optimization model
with iterative support estimate. <em>ISCI</em>, <em>574</em>, 1–11. (<a
href="https://doi.org/10.1016/j.ins.2021.05.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to the construction and analysis of a novel hybrid optimization model of the ℓ 0 ℓ0 minimization and the ℓ 1 ℓ1 minimization with a given support estimate. With the help of the Moreau envelop of the ℓ 1 ℓ1 norm, we provide reasonable explanation for the claim that the capped- ℓ 1 ℓ1 penalty is one of the continuous relaxation to the ℓ 0 ℓ0 -norm penalty and thus develop the scale iteratively reweighed ℓ 1 ℓ1 -minimization (SIRL1) aiming to achieve fast reconstruction and a reduced requirement on the number of measurements compared to the ℓ 1 ℓ1 minimization approach. To illustrate the theoretical results, some numerical experiments are presented to demonstrate the effectiveness and flexibility of the proposed SIRL1 algorithm.},
  archive      = {J_ISCI},
  author       = {Jun Wang},
  doi          = {10.1016/j.ins.2021.05.078},
  journal      = {Information Sciences},
  pages        = {1-11},
  shortjournal = {Inf. Sci.},
  title        = {Sparse reconstruction via the mixture optimization model with iterative support estimate},
  volume       = {574},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered positive l1-gain non-fragile filter design
for positive markov jump systems. <em>ISCI</em>, <em>573</em>, 562–584.
(<a href="https://doi.org/10.1016/j.ins.2021.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the event-triggered positive l 1 l1 -gain non-fragile filter design of positive Markov jump systems. By using the upper and lower bounds of the error vector of system measurement outputs, the positive l 1 l1 -gain filtering system to be designed is transformed into interval uncertain systems. Combining linear Lyapunov functions and linear programming, the positivity and stability of such systems can be obtained. Then, the proposed approach is developed to investigate positive l 1 l1 -gain additive and multiplicative non-fragile filters, respectively. Furthermore, two classes of non-fragile positive filters are proposed for positive Markov jump systems with incomplete measurements and sensors saturation, respectively. Finally, two examples are provided to verify the effectiveness of the proposed design.},
  archive      = {J_ISCI},
  author       = {Xuanjin Deng and Junfeng Zhang and Tarek Raïssi},
  doi          = {10.1016/j.ins.2021.02.030},
  journal      = {Information Sciences},
  pages        = {562-584},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered positive l1-gain non-fragile filter design for positive markov jump systems},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reachability in big graphs: A distributed indexing and
querying approach. <em>ISCI</em>, <em>573</em>, 541–561. (<a
href="https://doi.org/10.1016/j.ins.2021.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advent of Big graphs characterized by their enormous number of nodes, with multiple edges between them makes the existing reachability query indexing approaches unable to guarantee a reasonable time for both the index construction and query steps. Therefore a novel approach that takes into account these new characteristics during the graph processing is needed. In this paper, we propose an Overlay Graph-based Distributed Reachability Indexing approach (ODRI), an indexing scheme through which the index construction and reachability query are processed in a parallel and distributed manner. The key idea of ODRI is to process a Big graph as a set of smaller subgraphs (partitions) interconnected to each other through an overlay graph. In this way, the partitions can be indexed in parallel and, at the same time, the reachability information can also be extracted. Hence, the index construction and query processing time will be reduced significantly. Therefore, ODRI ensures the scalability of Big graphs, which is a challenge for the existing reachability approaches. Besides, we formally prove that this strategy preserves the reachability properties. Using real-life data, we experimentally verify that our approach outperforms the state-of-the-art methods, and is scalable in terms of the number of partitions, regardless of how graphs are distributed.},
  archive      = {J_ISCI},
  author       = {Imane Hocine and Saïd Yahiaoui and Ahcene Bendjoudi and Nadia Nouali-Taboudjemat},
  doi          = {10.1016/j.ins.2021.05.053},
  journal      = {Information Sciences},
  pages        = {541-561},
  shortjournal = {Inf. Sci.},
  title        = {Reachability in big graphs: A distributed indexing and querying approach},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). STMTO: A smart and trust multi-UAV task offloading system.
<em>ISCI</em>, <em>573</em>, 519–540. (<a
href="https://doi.org/10.1016/j.ins.2021.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of promising distributed multi-robot system, Unmanned Aerial Vehicles (UAVs) can collaborate to offload complex tasks in edge networks. A Smart and Trust Multi-UAV Task Offloading (STMTO) system is established to offload tasks from Internet of Thing (IoT) devices to edge severs through UAVs with a trust style. In STMTO system, first, a group of UAVs is dispatched to relay tasks from devices to edge servers with rich computing resource. A collaborative task collection scheme is proposed to minimize energy consumption and the task processing delay by dividing working area for each UAV and designing the flight trajectory . Secondly, a many-to-many task double auction model is established for devices and edge servers to maximize the offloading utility, where devices act as buyers, edge servers as sellers, and UAVs as auctioneers. Last, to resist attack of malicious edge servers and ensure the task security, a novel trust evaluation method based on the comparison of true utility and expected utility is integrated in auction mechanism. The theoretical analysis and implementation results show that the proposed STMTO system not only achieve the best utility for devices and edge servers simultaneously, but also identify the malicious edge servers and protect task from attacks.},
  archive      = {J_ISCI},
  author       = {Jialin Guo and Guosheng Huang and Qiang Li and Neal N. Xiong and Shaobo Zhang and Tian Wang},
  doi          = {10.1016/j.ins.2021.05.020},
  journal      = {Information Sciences},
  pages        = {519-540},
  shortjournal = {Inf. Sci.},
  title        = {STMTO: A smart and trust multi-UAV task offloading system},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy best-worst method based on generalized interval-valued
trapezoidal fuzzy numbers for multi-criteria decision-making.
<em>ISCI</em>, <em>573</em>, 493–518. (<a
href="https://doi.org/10.1016/j.ins.2021.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fuzzy best-worst method (BWM), called the GITrF BWM, based on generalized interval-valued trapezoidal fuzzy (GITrF) numbers (GITrFNs) for multi-criteria decision-making (MCDM). The reference comparisons between criteria are represented by GITrFNs and the weights of criteria are also taken the form of GITrFNs. The concept of normalized GITrF weight vector is proposed and a new graded mean integration representation (GMIR) of GITrFN is given. A goal programming model is built to obtain the optimal normalized GITrF weights of criteria. Furthermore, the GITrF consistency index and the GITrF consistency ratio are proposed. The GMIR of the GITrF consistency ratio is calculated to measure the acceptable consistency of all the reference comparisons between criteria. For the unacceptable consistent reference comparisons, we propose an approach to improve the consistency of reference comparisons between criteria. Finally, a GITrF BWM is proposed for MCDM . Three real examples are analyzed to illustrate the proposed GITrF BWM. The comparison analyses show that the proposed GITrF BWM outperforms the existing methods for MCDM in GITrF environments.},
  archive      = {J_ISCI},
  author       = {Shuping Wan and Jiuying Dong and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2021.03.038},
  journal      = {Information Sciences},
  pages        = {493-518},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy best-worst method based on generalized interval-valued trapezoidal fuzzy numbers for multi-criteria decision-making},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neuro-diversified benchmark generator for black box
optimization. <em>ISCI</em>, <em>573</em>, 475–492. (<a
href="https://doi.org/10.1016/j.ins.2021.04.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No Free Lunch Theorem presents a dilemma in the evaluation of emerging evolutionary algorithms in terms of handling various real world problems and their unknown internal structures, since the performances of these algorithms are related to the corresponding benchmarks. Although white and black box schemes have made impressive progress in overcoming this dilemma, such as clear property definition and basis function composition, the evaluation of algorithms on sophisticated suites remains insufficient on account of the limited quantity and diversity of such benchmarks, which can induce bias in a narrow problem domain. Therefore, this study proposes a novel framework for randomly generating diversified benchmark functions to comprehensively evaluate evolutionary algorithms in a black box scenario. The proposed approach adopts a recurrent neural network with various activation functions to produce test problems with important characteristics such as ruggedness and multi-funnels. In addition, the proposed framework can generate virtually limitless chaotic benchmarks by using random weights. The experimental results demonstrate a distinct difference among the performance of the tested optimizers on the proposed problems and the well-known BBOB and CEC problems, which implies the necessity of the proposed benchmarks when facilitating a more comprehensive evaluation.},
  archive      = {J_ISCI},
  author       = {Fengyang Sun and Lin Wang and Bo Yang},
  doi          = {10.1016/j.ins.2021.04.075},
  journal      = {Information Sciences},
  pages        = {475-492},
  shortjournal = {Inf. Sci.},
  title        = {A neuro-diversified benchmark generator for black box optimization},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust subspace clustering based on automatic weighted
multiple kernel learning. <em>ISCI</em>, <em>573</em>, 453–474. (<a
href="https://doi.org/10.1016/j.ins.2021.05.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple kernel learning (MKL), which combines a set of prespecified basic kernels to improve the clustering performance, has become an important research topic. Unfortunately, the current methods have the following defects in noisy circumstances. 1) Their clustering performance may be significantly reduced due to the noise in the kernel, which is caused by the lack of a reliable discriminant guideline for basic kernel combinations. 2) The noise from corrupted data or occlusion may destroy the block-diagonal structures of the affinity matrices they obtained, which will affect the clustering performance when using spectral clustering. In this work, to solve the above problems, we propose an automatic weighted multikernel learning-based robust subspace clustering (AWLKSC) algorithm. The model integrates multikernel learning strategies, the Correntropy-Induced Metric (CIM), low rank approximation technology and block diagonal constraints. In addition, an effective AM&amp;GST algorithm, which is integrated by alternating minimization and generalized soft-thresholding, is developed to optimize the AWLKSC. Seven types of noise are considered in the experiments, and the experimental results illustrate that AWLKSC is more effective and robust than several up-to-date single kernel and multiple kernel clustering methods.},
  archive      = {J_ISCI},
  author       = {Li Guo and Xiaoqian Zhang and Zhigui Liu and Xuqian Xue and Qian Wang and Shijian Zheng},
  doi          = {10.1016/j.ins.2021.05.070},
  journal      = {Information Sciences},
  pages        = {453-474},
  shortjournal = {Inf. Sci.},
  title        = {Robust subspace clustering based on automatic weighted multiple kernel learning},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using argumentation in expert’s debate to analyze
multi-criteria group decision making method results. <em>ISCI</em>,
<em>573</em>, 433–452. (<a
href="https://doi.org/10.1016/j.ins.2021.05.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent multi-criteria group decision making methods focus their analysis on the experts preferences. They do not take into account the reasons why each expert has provided a specific set of preferences. In this paper, a method that introduces novel measures capable of explaining the reasons behind experts decisions is presented. A novel concept, the arguments are presented. They represent the experts have for maintaining a certain position in the debate. Several measures related to the arguments are proposed. These new argumentation measures, along with consensus measures, help us to get a clear idea about how and why a specific resolution has been reached. They help us to determine which is the most influential expert, that is, the expert whose contributions to the debate have inspired the rest. Also, the proposed method allows us to determine which are the arguments that most of the experts have followed. A clear overview about how the debate is evolving in terms of arguments is also provided. The novel presented analysis indicate how the experts change their opinions in every round and what was the reason for it, which changes have occurred between rounds and they also provide global analysis results.},
  archive      = {J_ISCI},
  author       = {J.A. Morente-Molinera and G. Kou and K. Samuylov and F.J. Cabrerizo and E. Herrera-Viedma},
  doi          = {10.1016/j.ins.2021.05.086},
  journal      = {Information Sciences},
  pages        = {433-452},
  shortjournal = {Inf. Sci.},
  title        = {Using argumentation in expert’s debate to analyze multi-criteria group decision making method results},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-way data analytics: Preparing and analyzing data in
threes. <em>ISCI</em>, <em>573</em>, 412–432. (<a
href="https://doi.org/10.1016/j.ins.2021.05.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision and its underlying philosophy of thinking in threes have been investigated in a variety of topics. By observing that many three-way topics are related to data analytics , this work presents three-way data analytics , examine a number of its existing topics, and propose a few potential new topics. Based on the two stages of data analytics (i.e., data preparation and data analysis) and the Data-Information-Knowledge-Wisdom (DIKW) hierarchy, we organize the existing three-way topics into three bunches, namely, three-way data preparation concerning data, three-way data analysis concerning information, and three-way data analysis concerning knowledge and wisdom. This systematic organization may shed light on a new view of understanding current results. Moreover, it may promote the studies on the relationships between topics from different levels and inspire their synthesis to obtain three-way approaches to the complete picture of data analytics. Furthermore, we may discover topics that are commonly studied in conventional data analytics but not with three-way approaches. Since three-way approaches are theoretically and practically proved to be efficient and effective in many existing topics, many new topics may be worth investigating. This work presents a few potential new topics, including three-way data selection, three-way word analysis, and three-way data visualization.},
  archive      = {J_ISCI},
  author       = {Mengjun Hu},
  doi          = {10.1016/j.ins.2021.05.058},
  journal      = {Information Sciences},
  pages        = {412-432},
  shortjournal = {Inf. Sci.},
  title        = {Three-way data analytics: Preparing and analyzing data in threes},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data poisoning against information-theoretic feature
selection. <em>ISCI</em>, <em>573</em>, 396–411. (<a
href="https://doi.org/10.1016/j.ins.2021.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A typical assumption made in machine learning is that a learning model does not consider an adversary’s existence that can subvert a classifier’s objective. As a result, machine learning pipelines exhibit vulnerabilities in an adversarial environment. Feature Selection (FS) is an essential preprocessing stage in data analytics and has been widely used in security-sensitive machine learning applications; however, FS research in adversarial machine learning has been largely overlooked. Recently, empirical works demonstrated that the FS is also vulnerable in an adversarial environment. In the past decade, although the research community has made extensive efforts to promote the classifiers’ robustness and develop countermeasures against adversaries, only a few contributions investigated FS’s behavior in a malicious environment. Given that machine learning pipelines increasingly rely on FS to combat the “curse of dimensionality” and overfitting, insecure FS can be the “Achilles heel” of data pipelines. In this contribution, we explore the weaknesses of information-theoretic FS methods by designing a generic FS poisoning algorithm. We also show the transferability of the proposed poisoning method across seven information-theoretic FS methods. The experiments on 16 benchmark datasets demonstrate the efficacy of our proposed poisoning algorithm and the existence of transferability.},
  archive      = {J_ISCI},
  author       = {Heng Liu and Gregory Ditzler},
  doi          = {10.1016/j.ins.2021.05.049},
  journal      = {Information Sciences},
  pages        = {396-411},
  shortjournal = {Inf. Sci.},
  title        = {Data poisoning against information-theoretic feature selection},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Connectivity status of fuzzy graphs. <em>ISCI</em>,
<em>573</em>, 382–395. (<a
href="https://doi.org/10.1016/j.ins.2021.05.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network science is a widely studied subject and graph theory has a major role in it. This paper studies connectivity status of vertices in a fuzzy graph. This paper adopt connectivity status to build up the status sequence related to a fuzzy graph. Results on connectivity status and status sequence of different structures are obtained. On the basis of connectivity status, vertices of a fuzzy graph can be classified into connectivity status enhancing vertices, connectivity status reducing vertices and connectivity status neutral vertices. Connectivity status analysis of vertices is also carried out. Algorithms related to these concepts are provided and an application related to bandwidth allocation problem in networking is proposed.},
  archive      = {J_ISCI},
  author       = {M. Binu and Sunil Mathew and J.N. Mordeson},
  doi          = {10.1016/j.ins.2021.05.068},
  journal      = {Information Sciences},
  pages        = {382-395},
  shortjournal = {Inf. Sci.},
  title        = {Connectivity status of fuzzy graphs},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PNAS: A privacy preserving framework for neural architecture
search services. <em>ISCI</em>, <em>573</em>, 370–381. (<a
href="https://doi.org/10.1016/j.ins.2021.05.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of deep neural networks has contributed to many fields, such as finance, medic and speech recognition. Machine learning models adopted in these fields are always trained with a massive amount of distributed and highly personalized data harvested directly from users. Concerns for data privacy and the demand for better data exploitation have prompted the design of several secure schemes that allow an untrusted server to train ML models for one or multiple parties. However, these existing schemes only focus on network parameter, and hardly extend their optimization range to model architecture scope. Sine the performance of a neural network is closely related to both parameter and its architecture, service providers are difficult to deliver customized and flexible neural networks to each client. To this end, in this paper we propose PNAS, a novel MLaaS framework that enables a server to jointly optimize network parameter and architecture while ensuring the privacy of training sets. A double-encryption scheme is derived to prevent privacy leakage from sample itself, as well as intermediate feature maps during training. Specifically, we adopt functional encryption and feature transformation to secure forward and back propagation. Extensive experiments have demonstrated the superiority of our proposal.},
  archive      = {J_ISCI},
  author       = {Zijie Pan and Jiajin Zeng and Riqiang Cheng and Hongyang Yan and Jin Li},
  doi          = {10.1016/j.ins.2021.05.073},
  journal      = {Information Sciences},
  pages        = {370-381},
  shortjournal = {Inf. Sci.},
  title        = {PNAS: A privacy preserving framework for neural architecture search services},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Generalized convergence in measure theorems of sugeno
integrals. <em>ISCI</em>, <em>573</em>, 360–369. (<a
href="https://doi.org/10.1016/j.ins.2021.05.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this note, we show a generalized version of convergence in measure theorem of Sugeno integrals in the framework concerning ordered pair of monotone measures. The condition of a kind of absolute continuity we employed is not only sufficient, but also necessary for the generalized version. The previous two versions (standard-form and pseudo-form) of the convergence in measure theorem are recovered by this generalized version. Thus, the convergence in measure theorems of Sugeno integrals are unified in general framework. In the same way the convergence in measure theorem and strict convergence in measure theorem of seminnormed fuzzy integrals are generalized, respectively. The relations between the convergence in measure and the convergence pseudo-in measure of measurable functions sequence are described in the context relating to a pair of monotone measures.},
  archive      = {J_ISCI},
  author       = {Jun Li and Hui Zhang and Tao Chen},
  doi          = {10.1016/j.ins.2021.05.087},
  journal      = {Information Sciences},
  pages        = {360-369},
  shortjournal = {Inf. Sci.},
  title        = {Generalized convergence in measure theorems of sugeno integrals},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Double l2,p-norm based PCA for feature extraction.
<em>ISCI</em>, <em>573</em>, 345–359. (<a
href="https://doi.org/10.1016/j.ins.2021.05.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, robust-norm distance related principal component analysis (PCA) for feature extraction has been shown to be very effective for image analysis, which considers either minimization of reconstruction error or maximization of data variance in low-dimensional subspace. However, both of them are important for feature extraction. Furthermore, most of existing methods cannot obtain satisfactory results due to the utilization of inflexible robust norm for distance metric. To address these problems, this paper proposes a novel robust PCA formulation called Double L 2,p -norm based PCA (DLPCA) for feature extraction, in which the minimization of reconstruction error and the maximization of variance are simultaneously taken into account in a unified framework. In the reconstruction error function, we target to learn a latent subspace to bridge the relationship between the transformed features and the original features. To guarantee the objective to be insensitive to outliers, we take L 2,p -norm as the distance metric for both reconstruction error and data variance. These characteristics make our method more applicable for feature extraction. We present an effective iterative algorithm to obtain the solution of this challenging work, and conduct theoretical analysis on the convergence of the algorithm. The experimental results on several databases show the effectiveness of our model.},
  archive      = {J_ISCI},
  author       = {Pu Huang and Qiaolin Ye and Fanlong Zhang and Guowei Yang and Wei Zhu and Zhangjing Yang},
  doi          = {10.1016/j.ins.2021.05.079},
  journal      = {Information Sciences},
  pages        = {345-359},
  shortjournal = {Inf. Sci.},
  title        = {Double l2,p-norm based PCA for feature extraction},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical identity-based inner product functional
encryption. <em>ISCI</em>, <em>573</em>, 332–344. (<a
href="https://doi.org/10.1016/j.ins.2021.05.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inner product functional encryption (IPFE), as a novel cryptographic primitive, can be classified into public-key IPFE (PK-IPFE) and secret-key IPFE (SK-IPFE). PK-IPFE has the following functions: an encryptor generates the ciphertext by encrypting a vector x → x→ , and a decryptor decrypts the ciphertext and obtains the inner product 〈 x → , y → 〉 〈x→,y→〉 if it holds the secret key related to vector y → y→ . The general IPFE cannot describe the hierarchical structure. The superior cannot use the general IPFE to issue the delegating keys for the subordinates, which complicates key management. We first propose a new primitive, hierarchical identity-based PK-IPFE (HID-PK-IPFE). HID-PK-IPFE has the following features. First, the identity of the decryptor can be specified when encrypting. Second, the identity of the recipient has a hierarchical structure. In the hierarchical tree, the upper-level users can generate the private key of the lower-level users; that is, our scheme has a delegation function. We formalize the selective chosen plaintext attack model of HID-PK-IPFE, propose the scheme in the standard model, and prove the security of the scheme on the basis of d -DBDHE assumption. We conducted two sets of simulations. We set the maximum depth of the identity hierarchy to 10, and increased the vector length from 10 to 15. We then listed the time spent by each algorithm in these two ranges. The simulation results show that the running time of each algorithm of our HID-PK-IPFE is completely acceptable in actual application scenarios.},
  archive      = {J_ISCI},
  author       = {Ge Song and Yuqiao Deng and Qiong Huang and Changgen Peng and Chunming Tang and Xiaohua Wang},
  doi          = {10.1016/j.ins.2021.05.062},
  journal      = {Information Sciences},
  pages        = {332-344},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical identity-based inner product functional encryption},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive memetic differential evolution with niching
competition and supporting archive strategies for multimodal
optimization. <em>ISCI</em>, <em>573</em>, 316–331. (<a
href="https://doi.org/10.1016/j.ins.2021.04.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal optimization, which aims at locating multiple optimal solutions within the search space, is inherently a difficult problem. This work proposes an adaptive memetic differential evolution algorithm with niching competition and supporting archive strategies to tackle the problem. In the proposed algorithm, a niching competition strategy is designed to competitively employ niches according to their potentials by encouraging high potential niches for exploitation while low potential niches for exploration, thus appropriately searching the space to identify multiple optima . Further, a supporting archive strategy is devised and implemented at the niche level with a dual purpose of helping maintain potential optima as well as facilitate the evolution of population. In this strategy, the writing and reading of archive is implicitly implemented during evolution rather than requiring external rules. Additionally, an adaptive Cauchy-based local search scheme, which considers the possible locations of optima to implement the local search, is developed and incorporated into the proposed method to efficiently and properly improve niching seeds. The resulting algorithm has been evaluated with extensive experiments on benchmark functions as well as a robot kinematics problem and compared with related methods. The results show that our method is able to consistently and accurately locate multiple optima in the solution space, and outperform related methods.},
  archive      = {J_ISCI},
  author       = {Weiguo Sheng and Xi Wang and Zidong Wang and Qi Li and Yun Chen},
  doi          = {10.1016/j.ins.2021.04.093},
  journal      = {Information Sciences},
  pages        = {316-331},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive memetic differential evolution with niching competition and supporting archive strategies for multimodal optimization},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Session-aware recommendation: A surprising quest for the
state-of-the-art. <em>ISCI</em>, <em>573</em>, 291–315. (<a
href="https://doi.org/10.1016/j.ins.2021.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are designed to help users in situations of information overload. In recent years we observed increased interest in session-based recommendation scenarios, where the problem is to make item suggestions to users based only on interactions observed in an ongoing session, e.g., on an e-commerce site. However, in cases where interactions from previous user sessions are also available, the recommendations can be personalized according to the users’ long-term preferences, a process called session-aware recommendation. Today, research in this area is scattered, and many works only compare a newly proposed session-aware with existing session-based models. This makes it challenging to understand what represents the state-of-the-art. To close this research gap, we benchmarked recent session-aware algorithms against each other and against a number of session-based recommendation algorithms along with heuristic extensions thereof. Our comparison, to some surprise, revealed that (i) simple techniques based on nearest neighbors consistently outperform recent neural techniques and that (ii) session-aware models were mostly not better than approaches that do not use long-term preference information. Our work therefore points to potential methodological issues where new methods are compared to weak baselines, and it also indicates that there remains a huge potential for more sophisticated session-aware recommendation algorithms.},
  archive      = {J_ISCI},
  author       = {Sara Latifi and Noemi Mauro and Dietmar Jannach},
  doi          = {10.1016/j.ins.2021.05.048},
  journal      = {Information Sciences},
  pages        = {291-315},
  shortjournal = {Inf. Sci.},
  title        = {Session-aware recommendation: A surprising quest for the state-of-the-art},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep embedded multi-view clustering with collaborative
training. <em>ISCI</em>, <em>573</em>, 279–290. (<a
href="https://doi.org/10.1016/j.ins.2020.12.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering has attracted increasing attentions recently by utilizing information from multiple views. However, existing multi-view clustering methods are either with high computation and space complexities, or lack of representation capability. To address these issues, we propose d eep e mbedded m ulti- v iew c lustering with collaborative training (DEMVC) in this paper. Firstly, the embedded representations of multiple views are learned individually by deep autoencoders . Then, both consensus and complementary of multiple views are taken into account and a novel collaborative training scheme is proposed. Concretely, the feature representations and cluster assignments of all views are learned collaboratively. A new consistency strategy for cluster centers initialization is further developed to improve the multi-view clustering performance with collaborative training. Experimental results on several popular multi-view datasets show that DEMVC achieves significant improvements over state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jie Xu and Yazhou Ren and Guofeng Li and Lili Pan and Ce Zhu and Zenglin Xu},
  doi          = {10.1016/j.ins.2020.12.073},
  journal      = {Information Sciences},
  pages        = {279-290},
  shortjournal = {Inf. Sci.},
  title        = {Deep embedded multi-view clustering with collaborative training},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). SieveNet: Decoupling activation function neural network for
privacy-preserving deep learning. <em>ISCI</em>, <em>573</em>, 262–278.
(<a href="https://doi.org/10.1016/j.ins.2021.05.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning as a Service (MLaaS) is increasingly popular but processing prediction requests will cause users to expose potentially sensitive information. Thanks to breakthrough in secure multi-party computation(MPC), privacy-preserving machine learning has attracted more attention. It allows outsourcing calculations to untrusted servers while maintaining data privacy. Some works proposed frameworks for secure prediction, but with high computation and communication overhead. This is the cost for MPC to deal with non-linear functions, and the activation functions that are widely used in neural networks are usually non-linear. We present a practical framework to perform privacy-preserving prediction. We first propose a new component as an alternative to the activation function so that in one forward propagation, the neural network can be regarded as a linear model. We call this component Sieve Layer and the corresponding network SieveNet . We then show how to use additive secret sharing and adversarial training to build privacy-preserving prediction framework based on SieveNet , and we report a comprehensive analysis of information leakage according to specific types of attacker. Finally, we evaluate our framework on MNIST, CIFAR-10 and CIFAR-100. The results show that the prediction time of our framework is in the same order of magnitude as the plaintext inference.},
  archive      = {J_ISCI},
  author       = {Qizheng Wang and Wenping Ma and Ge Liu},
  doi          = {10.1016/j.ins.2021.05.054},
  journal      = {Information Sciences},
  pages        = {262-278},
  shortjournal = {Inf. Sci.},
  title        = {SieveNet: Decoupling activation function neural network for privacy-preserving deep learning},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-fragile observer-based robust control for uncertain
systems via aperiodically intermittent control. <em>ISCI</em>,
<em>573</em>, 239–261. (<a
href="https://doi.org/10.1016/j.ins.2021.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the non-fragile robust stabilization problem for uncertain systems with structural uncertainties via observer-based state-feedback aperiodically intermittent control. First, based on the characteristics of intermittent control, a general representation of the observer coupled with the feedback intermittent controller with variable control periods and control widths is presented. Then, by constructing a piecewise Lyapunov function, an asymptotic stability criterion is established to show what the control gains, the control periods and the control widths for the control scheme are required. After transforming the conditions related to control gains in the stability criterion into linear matrix inequalities via the singular value decomposition technique, two stabilization design criteria are developed for the gains with additive and multiplicative uncertainties, respectively. Furthermore, a simple design procedure is summarized based on the design criteria to show how to calculate the control gains and how to choose the corresponding allowable control periods and control widths. Finally, the effectiveness of the proposed method is demonstrated by a numerical example.},
  archive      = {J_ISCI},
  author       = {Ying Yang and Yong He},
  doi          = {10.1016/j.ins.2021.05.046},
  journal      = {Information Sciences},
  pages        = {239-261},
  shortjournal = {Inf. Sci.},
  title        = {Non-fragile observer-based robust control for uncertain systems via aperiodically intermittent control},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classifier-adaptation knowledge distillation framework for
relation extraction and event detection with imbalanced data.
<em>ISCI</em>, <em>573</em>, 222–238. (<a
href="https://doi.org/10.1016/j.ins.2021.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fundamental information extraction tasks, such as relation extraction and event detection, suffer from a data imbalance problem. To alleviate this problem, existing methods rely mostly on well-designed loss functions to reduce the negative influence of imbalanced data . However, this approach requires additional hyper-parameters and limits scalability. Furthermore, these methods can only benefit specific tasks and do not provide a unified framework across relation extraction and event detection. In this paper, a Classifier-Adaptation Knowledge Distillation (CAKD) framework is proposed to address these issues, thus improving relation extraction and event detection performance. The first step is to exploit sentence-level identification information across relation extraction and event detection, which can reduce identification errors caused by the data imbalance problem without relying on additional hyper-parameters. Moreover, this sentence-level identification information is used by a teacher network to guide the baseline model’s training by sharing its classifier. Like an instructor, the classifier improves the baseline model’s ability to extract this sentence-level identification information from raw texts, thus benefiting overall performance. Experiments were conducted on both relation extraction and event detection using the Text Analysis Conference Relation Extraction Dataset (TACRED) and Automatic Content Extraction (ACE) 2005 English datasets, respectively. The results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_ISCI},
  author       = {Dandan Song and Jing Xu and Jinhui Pang and Heyan Huang},
  doi          = {10.1016/j.ins.2021.05.045},
  journal      = {Information Sciences},
  pages        = {222-238},
  shortjournal = {Inf. Sci.},
  title        = {Classifier-adaptation knowledge distillation framework for relation extraction and event detection with imbalanced data},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust risk-averse multi-armed bandits with application in
social engagement behavior of children with autism spectrum disorder
while imitating a humanoid robot. <em>ISCI</em>, <em>573</em>, 194–221.
(<a href="https://doi.org/10.1016/j.ins.2021.05.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic multi-armed bandit problem is a standard model to solve the exploration–exploitation trade-off in sequential decision problems. In clinical trials, which are sensitive to outlier data, the goal is to learn a risk-averse policy to provide a trade-off between exploration, exploitation, and safety. In this paper, we present a risk-averse multi-armed bandit algorithm to solve a decision-making problem based on the social engagement behaviors of children with Autism Spectrum Disorder (ASD). The algorithm is carried out when children interact with a humanoid robot and imitate a sequence of the robot&#39;s movements. The proposed algorithm is based on the Best Empirical Sampled Average algorithm under Entropic Value-at-Risk as a risk measure to decide on the best sequence of movements that can improve the social engagement behaviors of the children with ASD while imitating the robot&#39;s movements. We provide a detailed experimental analysis to compare the performance of our proposed algorithm to some well-known risk-averse multi-armed bandit algorithms on some artificial scenarios and our real-world problem. The experimental results report that the proposed algorithm outperforms its competitors in terms of robustness, risk avoidance, and cumulative regret, promoting the social engagement behaviors of children with ASD when imitating a robot&#39;s movements.},
  archive      = {J_ISCI},
  author       = {Azra Aryania and Hadi S. Aghdasi and Rasoul Heshmati and Andrea Bonarini},
  doi          = {10.1016/j.ins.2021.05.067},
  journal      = {Information Sciences},
  pages        = {194-221},
  shortjournal = {Inf. Sci.},
  title        = {Robust risk-averse multi-armed bandits with application in social engagement behavior of children with autism spectrum disorder while imitating a humanoid robot},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure and verifiable outsourced data dimension reduction on
dynamic data. <em>ISCI</em>, <em>573</em>, 182–193. (<a
href="https://doi.org/10.1016/j.ins.2021.05.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction aims at reducing redundant information in big data and hence making data analysis more efficient. Resource-constrained enterprises or individuals often outsource this time-consuming job to the cloud for saving storage and computing resources. However, due to inadequate supervision, the privacy and security of outsourced data have been a serious concern to data owners. In this paper, we propose a privacy-preserving and verifiable outsourcing scheme for data dimension reduction, based on incremental Non-negative Matrix Factorization (NMF) method. We emphasize the importance of incremental data processing, exploiting the properties of NMF to enable data dynamics in consideration of data updating in reality. Besides, our scheme can also maintain data confidentiality and provide verifiability of the computation result. Experiment evaluation has shown that the proposed scheme achieves high efficiency, saving about more than 80\% computation time for clients.},
  archive      = {J_ISCI},
  author       = {Zhenzhu Chen and Anmin Fu and Robert H. Deng and Ximeng Liu and Yang Yang and Yinghui Zhang},
  doi          = {10.1016/j.ins.2021.05.066},
  journal      = {Information Sciences},
  pages        = {182-193},
  shortjournal = {Inf. Sci.},
  title        = {Secure and verifiable outsourced data dimension reduction on dynamic data},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised learning with mixed-order graph
convolutional networks. <em>ISCI</em>, <em>573</em>, 171–181. (<a
href="https://doi.org/10.1016/j.ins.2021.05.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph convolutional networks (GCN) have made substantial progress in semi-supervised learning (SSL). However, established GCN-based methods have two major limitations. First, GCN-based methods are restricted by the oversmoothing issue that limits their ability to extract knowledge from distant but informative nodes. Second, most available GCN-based methods exploit only the feature information of unlabeled nodes, and the pseudo-labels of unlabeled nodes, which contain important information about the data distribution, are not fully utilized. To address these issues, we propose a novel end-to-end ensemble framework, which is named mixed-order graph convolutional networks (MOGCN). MOGCN consists of two modules. (1) It constructs multiple simple GCN learners with multi-order adjacency matrices, which can directly capture the high-order connectivity among the nodes to alleviate the problem of oversmoothing. (2) To efficiently combine the results from multiple GCN learners, MOGCN employs a novel ensemble module, in which the pseudo-labels of unlabeled nodes from various GCN learners are used to augment the diversity among the learners. We conduct experiments on three public benchmark datasets to evaluate the performance of MOGCN on semi-supervised node classification tasks. The experimental results demonstrate that MOGCN consistently outperforms state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Jie Wang and Jianqing Liang and Junbiao Cui and Jiye Liang},
  doi          = {10.1016/j.ins.2021.05.057},
  journal      = {Information Sciences},
  pages        = {171-181},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised learning with mixed-order graph convolutional networks},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A development framework of granular prototypes with an
allocation of information granularity. <em>ISCI</em>, <em>573</em>,
154–170. (<a href="https://doi.org/10.1016/j.ins.2021.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid model with both clustering mechanism and regression mechanism is built with aid of an allocation of information granularity . Some numeric prototypes constructed by clustering methods are expanded into granular prototypes. The regression module accepts granular prototypes and outcomes information granules. Some advantages of this idea can be concluded: 1). The constructed granular prototypes are best able to represent original data with comparable smaller quantity and high quality. 2). The granular output could be used to predict a new sample’s real number output by giving a rational range. 3). It can be used to solve clustering and regression problems simultaneously. Two different granularity allocation strategies are proposed and experimented while constructing granular prototypes: non-uniformly allocation of information granularity to each cluster and non-uniformly allocation to each feature. A comprehensive objective function is defined considering specificity and generality of the output. The allocation of granularity itself is in fact a multiple-parameters optimization problem which invokes the usage of an evolutionary method. Two popular methods (GA and PSO) are tried and compared with a real data set’s experiment. Three data sets are collected from UCI website to testify the effectiveness of our approach in the experimental part.},
  archive      = {J_ISCI},
  author       = {Mingli Song and Yapeng Liu},
  doi          = {10.1016/j.ins.2021.06.001},
  journal      = {Information Sciences},
  pages        = {154-170},
  shortjournal = {Inf. Sci.},
  title        = {A development framework of granular prototypes with an allocation of information granularity},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Twin support vector machines with privileged information.
<em>ISCI</em>, <em>573</em>, 141–153. (<a
href="https://doi.org/10.1016/j.ins.2021.05.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of machine learning , collected data always have additional features which are always referred as privileged information. Privileged information learning is mainly used to help train the classifier in the training process, and predict the unseen example by the learned classifier. In this paper, we propose a new method named twin support vector machines with privileged information (TWSVM-PI). In the proposed method, we first introduce the privileged information into twin SVMs so as to construct a model for prediction, and then utilize the Lagrangian multiplier method to optimize the proposed objective function. Thus, we obtain two nonparallel classification hyperplanes by solving two smaller sized quadratic programming problems (QPPs), which can shorter the computational time and improve the accuracy of the prediction. Finally, we conduct extensive experiments to evaluate the performance of the proposed TWSVM-PI method. The results have shown that our proposed method can obtain a better performance compared with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Zhiyong Che and Bo Liu and Yanshan Xiao and Hao Cai},
  doi          = {10.1016/j.ins.2021.05.069},
  journal      = {Information Sciences},
  pages        = {141-153},
  shortjournal = {Inf. Sci.},
  title        = {Twin support vector machines with privileged information},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Matrix completion with column outliers and sparse noise.
<em>ISCI</em>, <em>573</em>, 125–140. (<a
href="https://doi.org/10.1016/j.ins.2021.05.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix completion from very limited information is an important machine learning topic, and has received extensive attention in various scientific applications. Matrix completion aims at finding a low-rank matrix to approximate the incomplete data matrix. However, noise in the data matrix may degrade the performance of the existing matrix completion algorithms, especially if there are different types of noise. In this paper, we proposed a robust matrix completion method with column outliers and sparse noise. The incomplete matrix is iteratively divided into low-rank and sparse parts. The ℓ 2 , 1 ℓ2,1 -norm based objective function makes the recovered matrix keeps a low-rank structure and lets the algorithm robust to column outliers, while the regularization term based on ℓ 1 ℓ1 -norm can alleviate the influence of sparse noise. Besides, a vector completion algorithm has been proposed to help us estimate the missing entries of the out-of-sample vectors. Moreover, the proposed model can be optimized by an efficient iterative re-weighted method, without introducing any additional parameters, while the adaptive weights obtained in the optimization process can help us detect column outliers. Both theoretical analysis and experiments based on synthetic datasets and real world datasets are implemented to validate the performance of the proposed method.},
  archive      = {J_ISCI},
  author       = {Ziheng Li and Zhanxuan Hu and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.ins.2021.05.051},
  journal      = {Information Sciences},
  pages        = {125-140},
  shortjournal = {Inf. Sci.},
  title        = {Matrix completion with column outliers and sparse noise},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cluster analysis with cellwise trimming and applications for
the robust clustering of curves. <em>ISCI</em>, <em>573</em>, 100–124.
(<a href="https://doi.org/10.1016/j.ins.2021.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a robust cluster analysis methodology based on cellwise trimming as an extension to a robust version of Principal Component Analysis . This new approach is more reasonable than traditional casewise trimming when the dimension is not small. This type of trimming avoids an unnecessary loss of information when only a few cells of the entirely trimmed observations are atypical. We propose an algorithm to apply this approach. This algorithm is particularized to the case of functional cluster analysis. We provide simulations and applications using real data sets to illustrate the proposed methodology.},
  archive      = {J_ISCI},
  author       = {L.A. García-Escudero and D. Rivera-García and A. Mayo-Iscar and J. Ortega},
  doi          = {10.1016/j.ins.2021.05.004},
  journal      = {Information Sciences},
  pages        = {100-124},
  shortjournal = {Inf. Sci.},
  title        = {Cluster analysis with cellwise trimming and applications for the robust clustering of curves},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal biometric authentication for mobile edge
computing. <em>ISCI</em>, <em>573</em>, 82–99. (<a
href="https://doi.org/10.1016/j.ins.2021.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we describe a novel Privacy Preserving Biometric Authentication (PPBA) system designed for Mobile Edge Computing (MEC) and multimodal biometrics . We focus on hill climbing attacks that reveal biometric templates to insider adversaries despite the encrypted storage in the cloud. First, we present an impossibility result on the existence of two-party PPBA systems that are resistant to these attacks. To overcome this negative result, we add a non-colluding edge server for detecting hill climbing attacks both in semi-honest and malicious model. The edge server that stores each user’s secret parameters enables to outsource the biometric database to the cloud and perform matching in the encrypted domain. The proposed system combines Set Overlap and Euclidean Distance metrics using score level fusion. Here, both the cloud and edge servers cannot learn the fused matching score. Moreover, the edge server is prevented from accessing any partial score. The efficiency of the crypto-primitives employed for each biometric modality results in linear computation and communication overhead . Under different MEC scenarios, the new system is found to be most efficient with a 2-tier architecture, which achieves\%75 lower latency compared to mobile cloud computing .},
  archive      = {J_ISCI},
  author       = {Neyire Deniz Sarier},
  doi          = {10.1016/j.ins.2021.05.036},
  journal      = {Information Sciences},
  pages        = {82-99},
  shortjournal = {Inf. Sci.},
  title        = {Multimodal biometric authentication for mobile edge computing},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient access methods for very large distributed graph
databases. <em>ISCI</em>, <em>573</em>, 65–81. (<a
href="https://doi.org/10.1016/j.ins.2021.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subgraph searching is an essential problem in graph databases, but it is also challenging due to the involved subgraph isomorphism NP-Complete sub-problem. Filter-Then-Verify (FTV) methods mitigate performance overheads by using an index to prune out graphs that do not fit the query in a filtering stage, reducing the number of subgraph isomorphism evaluations in a subsequent verification stage. Subgraph searching has to be applied to very large databases (tens of millions of graphs) in real applications such as molecular substructure searching. Previous surveys have identified the FTV solutions GraphGrepSX (GGSX) and CT-Index as the best ones for large databases (thousands of graphs), however they cannot reach reasonable performance on very large ones (tens of millions graphs). This paper proposes a generic approach for the distributed implementation of FTV solutions. Besides, three previous methods that improve the performance of GGSX and CT-Index are adapted to be executed in clusters. The evaluation shows how the achieved solutions provide a great performance improvement (between 70\% and 90\% of filtering time reduction) in a centralized configuration and how they may be used to achieve efficient subgraph searching over very large databases in cluster configurations.},
  archive      = {J_ISCI},
  author       = {David Luaces and José R.R. Viqueira and José M. Cotos and Julián C. Flores},
  doi          = {10.1016/j.ins.2021.05.047},
  journal      = {Information Sciences},
  pages        = {65-81},
  shortjournal = {Inf. Sci.},
  title        = {Efficient access methods for very large distributed graph databases},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage rule extraction method based on tree ensemble
model for interpretable loan evaluation. <em>ISCI</em>, <em>573</em>,
46–64. (<a href="https://doi.org/10.1016/j.ins.2021.05.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tree ensemble model has been widely employed as a loan evaluation method in credit risk assessment due to its high accuracy and robustness. However, the tree ensemble model is complex and incomprehensible, which restricts its adoption for decision-making in loan evaluation. In this paper, we propose a novel rule extraction method for improving the ensemble model by balancing predictive performance and interpretability in two stages: a local rule extraction method followed by a global rule extraction method. The local method simplifies each rule by removing its redundant constraints, while the global method optimizes the complete rule set based on the multiobjective optimization method. An interpretable rule-based model is extracted from the tree ensemble model via the proposed method. Comparing the performance to six other methods on three loan evaluation datasets, the proposed method shows superior interpretability and realizes similar predictive performance to the tree ensemble model. For practical loan evaluation, the proposed method provides decision-makers with an interpretable rule-based model, which could replace the opaque tree ensemble model in high-stakes decision-making. In addition, the proposed method could facilitate decision-makers in explaining the tree ensemble model by analyzing the important and valuable rules that are extracted from the original opaque model.},
  archive      = {J_ISCI},
  author       = {Lu-an Dong and Xin Ye and Guangfei Yang},
  doi          = {10.1016/j.ins.2021.05.063},
  journal      = {Information Sciences},
  pages        = {46-64},
  shortjournal = {Inf. Sci.},
  title        = {Two-stage rule extraction method based on tree ensemble model for interpretable loan evaluation},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Dual attention guided multi-scale CNN for fine-grained
image classification. <em>ISCI</em>, <em>573</em>, 37–45. (<a
href="https://doi.org/10.1016/j.ins.2021.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the classification of fine-grained images, the subtle differences among the subclasses of the main category must be distinguished. Intuitively, the key to realizing the fine-grained image categorization lies in locating and identifying the detailed differences in the local regions and capturing their feature representations. In this paper, we propose utilizing an attention module combined with a multi-scale latent representation network to locate the discriminative spatial regions, and then learn an accurate attention map to assist the category decision. Furthermore, an attention module is also employed to determine the channel weights of the distinct scale feature maps before the final step. Extensive experiments demonstrate that our model obtains a competitive performance against state-of-the-art baselines on two benchmark datasets, the attention validation experiments further reveal the ability of the model in choosing the proper channel features for low-quality image categorization.},
  archive      = {J_ISCI},
  author       = {Xiaozhang Liu and Lifeng Zhang and Tao Li and Dejian Wang and Zhaojie Wang},
  doi          = {10.1016/j.ins.2021.05.040},
  journal      = {Information Sciences},
  pages        = {37-45},
  shortjournal = {Inf. Sci.},
  title        = {Dual attention guided multi-scale CNN for fine-grained image classification},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image retrieval for structure-from-motion via graph
convolutional network. <em>ISCI</em>, <em>573</em>, 20–36. (<a
href="https://doi.org/10.1016/j.ins.2021.05.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional image retrieval techniques for Structure-from-Motion (SfM) are limited in their ability to effectively distinguish symmetric or repetitive textured patterns and cannot guarantee an accurate generation of pairwise matches without costly redundancy. In this paper, we formulate the image retrieval task as a node binary classification problem with graph data: if a candidate node is marked as positive, it is believed to share the same scene with the query image. The key idea of our approach is that the local context in the feature space around a query image contains abundant information about the matchable relation between the image and its neighbours. By constructing a subgraph surrounding the query image as input data, we adopt a learnable Graph Convolutional Network (GCN) to determine whether nodes in the subgraph have overlapping regions with the query photograph. Experiments demonstrate that our method performs remarkably well on a challenging dataset of highly ambiguous and duplicated scenes. Furthermore, compared with state-of-the-art matchable retrieval methods , the proposed approach significantly reduces unnecessary attempted matches without sacrificing the accuracy and completeness of reconstruction.},
  archive      = {J_ISCI},
  author       = {Shen Yan and Maojun Zhang and Shiming Lai and Yu Liu and Yang Peng},
  doi          = {10.1016/j.ins.2021.05.050},
  journal      = {Information Sciences},
  pages        = {20-36},
  shortjournal = {Inf. Sci.},
  title        = {Image retrieval for structure-from-motion via graph convolutional network},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Laplacian pair-weight vector projection for semi-supervised
learning. <em>ISCI</em>, <em>573</em>, 1–19. (<a
href="https://doi.org/10.1016/j.ins.2021.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning is a new challenge that exploits the information of unlabeled instances. In this paper, we propose a novel Laplacian pair-weight vector projection (LapPVP) algorithm for semi-supervised classification. LapPVP consists of two stages: projection and classification. In the projection stage, LapPVP integrates a within-class scatter, a between-class scatter and a Laplacian regularization together and formulates a pair of optimization problems . The goal of LapPVP is to maximize the between-class scatter and minimize the within-class scatter on the basis of labeled data, and simultaneously maintain the geometric structure of labeled and unlabeled data in the projected subspace. The optimization problems of LapPVP are identical to generalized eigenvalue ones. Thus, it is easy to obtain the optimal solutions to LapPVP. In the classification stage, LapPVP adopts a minimal distance classifier to implement tasks in the projected subspace. The proposed LapPVP can find a better separability using the geometric information embedded in labeled and unlabeled instances and the discriminative information embedded in labeled instance. Experiments on artificial datasets and UCI datasets validate the feasibility and effectiveness of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Yangtao Xue and Li Zhang},
  doi          = {10.1016/j.ins.2021.05.039},
  journal      = {Information Sciences},
  pages        = {1-19},
  shortjournal = {Inf. Sci.},
  title        = {Laplacian pair-weight vector projection for semi-supervised learning},
  volume       = {573},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed feedback network for single-image deraining.
<em>ISCI</em>, <em>572</em>, 611–626. (<a
href="https://doi.org/10.1016/j.ins.2021.02.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep convolutional neural networks have achieved great success for single-image deraining. However, affected by the intrinsic overlapping between rain streaks and background texture patterns, a majority of these methods tend to almost remove texture details in rain-free regions and lead to over-smoothing effects in the recovered background. To generate reasonable rain streak layers and improve the reconstruction quality of the background, we propose a distributed feedback network (DFN) in recurrent structure. A novel feedback block is designed to implement the feedback mechanism. In each feedback block, the hidden state with high-level information (output) will flow into the next iteration to correct the low-level representations (input). By stacking multiple feedback blocks, the proposed network where the hidden states are distributed can extract powerful high-level representations for rain streak layers. Curriculum learning is employed to connect the loss of each iteration and ensure that hidden states contain the notion of output. In addition, a self-ensemble strategy for rain removal task, which can retain the approximate vertical character of rain streaks, is explored to maximize the potential performance of the deraining model. Extensive experimental results demonstrated the superiority of the proposed method in comparison with other deraining methods.},
  archive      = {J_ISCI},
  author       = {Jiajun Ding and Huanlei Guo and Hang Zhou and Jun Yu and Xiongxiong He and Bo Jiang},
  doi          = {10.1016/j.ins.2021.02.080},
  journal      = {Information Sciences},
  pages        = {611-626},
  shortjournal = {Inf. Sci.},
  title        = {Distributed feedback network for single-image deraining},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group decision making based on consistency and consensus
analysis of dual multiplicative linguistic preference relations.
<em>ISCI</em>, <em>572</em>, 590–610. (<a
href="https://doi.org/10.1016/j.ins.2021.05.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new group decision making (GDM) method based on the consistency and the consensus analysis of dual multiplicative linguistic preference relations (DMLPRs). A new type of linguistic variables , called dual multiplicative linguistic variables (DMLVs), is presented, which is defined on the multiplicative linguistic scale. DMLVs are used to represent asymmetrical qualitative hesitancy judgments of decision makers (DMs). A maximum-consistency-based interactive algorithm to derive multiplicative linguistic intuitionistic preference relations (MLIPRs) is presented, by which the consistency concept for DMLPRs is obtained. Then, we define the concept of inconsistent DMLPRs and propose an optimal-model-based method for deriving consistent DMLPRs. Furthermore, incomplete DMLPRs also can be dealt with by the proposed maximum-consistency-based interactive algorithm. For GDM, the weights of DMs are determined by the cosine-based correlation coefficient between individual DMLPRs. Moreover, we propose a consensus measure to calculate the agreement degree of DMLPRs and build an optimal model to increase the consensus level of individual DMLPRs. Finally, a new GDM method (call Algorithm III ) is offered and an application example is used to illustrate the proposed GDM method. The proposed GDM method outperforms the former GDM methods for GDM in the environments of DMLPRs.},
  archive      = {J_ISCI},
  author       = {Fanyong Meng and Shyi-Ming Chen and Linxian Fu},
  doi          = {10.1016/j.ins.2021.05.056},
  journal      = {Information Sciences},
  pages        = {590-610},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making based on consistency and consensus analysis of dual multiplicative linguistic preference relations},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cluster-based oversampling algorithm combining SMOTE and
k-means for imbalanced medical data. <em>ISCI</em>, <em>572</em>,
574–589. (<a href="https://doi.org/10.1016/j.ins.2021.02.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The algorithm of C4.5 decision tree has the advantages of high classification accuracy , fast calculation speed and comprehensible classification rules, so it is widely used for medical data analysis. However, for imbalanced medical data, the classification accuracy of decision trees-based models is not ideal. Therefore, this paper proposes a cluster-based oversampling algorithm (KNSMOTE) combining Synthetic minority oversampling technique (SMOTE) and k -means algorithm. The sample classes clustered by k -means and the original sample classes are calculated to select the ‘‘safe samples” whose sample classes have not been changed. The ‘‘safe samples” are linearly interpolated to synthesize the new samples. The improved SMOTE sets the oversampling ratio according to the imbalance ratio of the original samples, which is used to synthesize the samples whose number is the same as that of the original samples. Compared with other oversampling algorithms on 8 UCI datasets, our algorithm has achieved significant advantages. Our algorithm was applied to the medical datasets, and the average values of the Sensitivity and Specificity indexes of the Random forest (RF) algorithm were 99.84\% and 99.56\%, respectively.},
  archive      = {J_ISCI},
  author       = {Zhaozhao Xu and Derong Shen and Tiezheng Nie and Yue Kou and Nan Yin and Xi Han},
  doi          = {10.1016/j.ins.2021.02.056},
  journal      = {Information Sciences},
  pages        = {574-589},
  shortjournal = {Inf. Sci.},
  title        = {A cluster-based oversampling algorithm combining SMOTE and k-means for imbalanced medical data},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Individualized extreme dominance (IndED): A new
preference-based method for multi-objective recommender systems.
<em>ISCI</em>, <em>572</em>, 558–573. (<a
href="https://doi.org/10.1016/j.ins.2021.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender Systems (RSs) make personalized suggestions of relevant items to users. However, the concept of relevance may involve different quality aspects (objectives), such as accuracy , novelty , and diversity . In addition, users may have their own expectations regarding what characterizes a good recommendation. More specifically, individual users may wish to prioritize the multiple objectives in different proportions based on their preferences. Previous studies on Multi-Objective (MO) recommendation do not prioritize objectives according to the individual users’ preferences systematically or are biased towards a single objective as in re-ranking strategies. Moreover, traditional preference-based multi-objective solutions do not address the specificities of RSs. In this work, we propose IndED ( Individualized Extreme Dominance ), a new preference-based method for MO-RSs. IndED explores the concepts of Extreme Dominance and Statistical Significance Tests in order to define a new Pareto-based dominance relation that guides the optimization search considering users’ preferences. We also consider a new decision making process that minimizes the distance to the individual user’s preferences. Experiments show that IndED outperformed competitive baselines, obtaining results closer to the users’ preferences and better balancing the objectives trade-offs. IndED is also the method that obtains the best performance regarding the most difficult objective in each considered scenario.},
  archive      = {J_ISCI},
  author       = {Reinaldo Silva Fortes and Daniel Xavier de Sousa and Dayanne G. Coelho and Anisio M. Lacerda and Marcos A. Gonçalves},
  doi          = {10.1016/j.ins.2021.05.037},
  journal      = {Information Sciences},
  pages        = {558-573},
  shortjournal = {Inf. Sci.},
  title        = {Individualized extreme dominance (IndED): A new preference-based method for multi-objective recommender systems},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient transmission algorithm for power grid data
suitable for autonomous multi-robot systems. <em>ISCI</em>,
<em>572</em>, 543–557. (<a
href="https://doi.org/10.1016/j.ins.2021.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the power environment of Internet of things used in autonomous multi-robot systems, due to the influence of various actual environmental factors, the security protection method based on security partition and physical isolation of nodes is difficult to fully meet the information security protection requirements of the power system , and the network threats such as impersonation, eavesdropping, and dexterity on communication links are still difficult to avoid. In order to improve the security of node data transmission in autonomous multi-robot power systems, reducing network energy consumption has become the bottleneck of network application and development. In this paper, we propose an Improved Effective Clustering Algorithm (IECA) and transmission algorithm of power grid data based on autonomous multi-robot systems. The distance between nodes sending data to the next-hop node is equivalent to the energy model. The remaining energy in the cluster head node sending data in the next hop is recorded, and the remaining energy is subtracted from the equivalent energy to find a maximum value. The corresponding node of the maximum value is taken as the number of nodes According to the received node. Compared with the LEACH algorithm and GAF algorithm, this algorithm can not only extend the lifetime of nodes but also has more efficient performance.},
  archive      = {J_ISCI},
  author       = {Xiaoyan Chen and Wei Liang and Xinlian Zhou and Dingchao Jiang and Xiaoyan Kui and Kuang-Ching Li},
  doi          = {10.1016/j.ins.2021.05.033},
  journal      = {Information Sciences},
  pages        = {543-557},
  shortjournal = {Inf. Sci.},
  title        = {An efficient transmission algorithm for power grid data suitable for autonomous multi-robot systems},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximating XGBoost with an interpretable decision tree.
<em>ISCI</em>, <em>572</em>, 522–542. (<a
href="https://doi.org/10.1016/j.ins.2021.05.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing usage of machine-learning models in critical domains has recently stressed the necessity of interpretable machine-learning models. In areas like healthcare, finary – the model consumer must understand the rationale behind the model output in order to use it when making a decision. For this reason, it is impossible to use black-box models in these scenarios, regardless of their high predictive performance . Decision forests, and in particular Gradient Boosting Decision Trees (GBDT), are examples of this kind of model. GBDT models are considered the state-of-the-art in many classification challenges, reflected by the fact that the majority of Kaggle’s recent winners used GBDT methods as a part of their solution (such as XGBoost). But despite their superior predictive performance, they cannot be used in tasks that require transparency. This paper presents a novel method for transforming a decision forest of any kind into an interpretable decision tree . The method extends the tool-set available for machine learning practitioners, who want to exploit the interpretability of decision trees without significantly impairing the predictive performance gained by GBDT models like XGBoost. We show in an empirical evaluation that in some cases the generated tree is able to approximate the predictive performance of a XGBoost model while enabling better transparency of the outputs.},
  archive      = {J_ISCI},
  author       = {Omer Sagi and Lior Rokach},
  doi          = {10.1016/j.ins.2021.05.055},
  journal      = {Information Sciences},
  pages        = {522-542},
  shortjournal = {Inf. Sci.},
  title        = {Approximating XGBoost with an interpretable decision tree},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sufficient conditions in terms of linear matrix inequalities
for guaranteed ultimately boundedness of solutions of switched
takagi-sugeno fuzzy systems using the s-procedure. <em>ISCI</em>,
<em>572</em>, 501–521. (<a
href="https://doi.org/10.1016/j.ins.2021.04.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, sufficient conditions to ensure the existence of a switching law that makes the solutions of switched Takagi-Sugeno (TS) fuzzy systems ultimately bounded are developed by means of linear matrix inequalities (LMIs). These LMIs are based on the existence of a scalar function, which plays a role similar to Lyapunov energy functions for an auxiliary system formed by a convex combination of all subsystems of the switched system. A feature of the developed results is that the derivatives of the scalar function can assume positive values in a bounded set described as level sets. The LMIs explore the S-procedure to obtain low levels of conservativeness and do not require the calculation of the derivative of the membership functions, which facilitates their application to switched TS fuzzy systems with many rules. Exploring the proposed conditions, we estimated the attractor and basin of attraction of some examples of switched TS fuzzy systems under a measurable switching law. These numerical examples showed the effectiveness of the proposed approach in maximizing the estimation of the bounded attraction domain.},
  archive      = {J_ISCI},
  author       = {Michele C. Valentino and Flávio A. Faria and Vilma A. Oliveira and Luís F.C. Alberto},
  doi          = {10.1016/j.ins.2021.04.103},
  journal      = {Information Sciences},
  pages        = {501-521},
  shortjournal = {Inf. Sci.},
  title        = {Sufficient conditions in terms of linear matrix inequalities for guaranteed ultimately boundedness of solutions of switched takagi-sugeno fuzzy systems using the S-procedure},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Musical rhythm transcription based on bayesian
piece-specific score models capturing repetitions. <em>ISCI</em>,
<em>572</em>, 482–500. (<a
href="https://doi.org/10.1016/j.ins.2021.04.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most work on musical score models (a.k.a. musical language models) for music transcription has focused on describing the local sequential dependence of notes in musical scores and failed to capture their global repetitive structure, which can be a useful guide for transcribing music. Focusing on rhythm, we formulate several classes of Bayesian Markov models of musical scores that describe repetitions indirectly using the sparse transition probabilities of notes or note patterns. This enables us to construct piece-specific models for unseen scores with an unfixed repetitive structure and to derive tractable inference algorithms. Moreover, to describe approximate repetitions, we explicitly incorporate a process for modifying the repeated notes/note patterns. We apply these models as prior musical score models for rhythm transcription, where piece-specific score models are inferred from performed MIDI data by Bayesian learning, in contrast to the conventional supervised construction of score models. Evaluations using the vocal melodies of popular music showed that the Bayesian models improved the transcription accuracy for most of the tested model types, indicating the universal efficacy of the proposed approach. Moreover, we found an effective data representation for modelling rhythms that maximizes the transcription accuracy and computational efficiency.},
  archive      = {J_ISCI},
  author       = {Eita Nakamura and Kazuyoshi Yoshii},
  doi          = {10.1016/j.ins.2021.04.100},
  journal      = {Information Sciences},
  pages        = {482-500},
  shortjournal = {Inf. Sci.},
  title        = {Musical rhythm transcription based on bayesian piece-specific score models capturing repetitions},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Study on hotel selection method based on integrating online
ratings and reviews from multi-websites. <em>ISCI</em>, <em>572</em>,
460–481. (<a href="https://doi.org/10.1016/j.ins.2021.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hotel selection method based on online evaluations has become a hot research topic. The existing models based on online ratings or reviews from one website have a disadvantage of information being definite and information amount being small. Therefore, this paper proposes a hotel selection model based on Probabilistic linguistic Term Set (PLTS) which integrates online ratings and reviews from multiple websites: (1) Unifying the rating information’s evaluation attributes among different websites based on the PLTS similarity calculation method, putting forward the transformation method of linguistic scale to unify the rating information’s evaluation scale among different websites; (2) Analyzing the sentiment of review texts and putting forward the aggregation model of user reviews based on different groups&#39; risk attitudes; (3) Improving the linguistic scale function to introduce the unbalanced effect of positive and negative evaluations; (4) According to preference differences among different groups, putting forward the attribute weight calculation method and providing recommendation results for different groups. Take four hotels on TripAdvisor, Ctrip and Hostelworld websites for case studies. The results show that information can be used to a greater extent by integrating online ratings and reviews from multiple websites, thus providing consumers with more objective and reliable decision-making results.},
  archive      = {J_ISCI},
  author       = {Meng Zhao and Linyao Li and Zeshui Xu},
  doi          = {10.1016/j.ins.2021.05.042},
  journal      = {Information Sciences},
  pages        = {460-481},
  shortjournal = {Inf. Sci.},
  title        = {Study on hotel selection method based on integrating online ratings and reviews from multi-websites},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How to generate perfect mazes? <em>ISCI</em>, <em>572</em>,
444–459. (<a href="https://doi.org/10.1016/j.ins.2021.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A perfect maze is a maze where any two cells can be joined by a unique path. In the literature, there exist eleven maze generation algorithms as compiled by Buck in 2015 in his book “ Mazes for Programmers ”. Each algorithm creates mazes differently. Our aim is to analyze how perfect mazes are generated. For this, we use the simple measures introduced by Buck, as well as the physical based measures introduced by McClendon in 2001. We introduce a new measure that helps us establish a ranking for perfect mazes. We also propose two new maze generation algorithms, called Prim &amp; Kill Prim&amp;#x26;Kill and Twist &amp; Merge Twist&amp;#x26;Merge . According to our measure, these two algorithms generate mazes differently than the existing algorithms do.},
  archive      = {J_ISCI},
  author       = {V. Bellot and M. Cautrès and J-M. Favreau and M. Gonzalez-Thauvin and P. Lafourcade and K. Le Cornec and B. Mosnier and S. Rivière-Wekstein},
  doi          = {10.1016/j.ins.2021.03.022},
  journal      = {Information Sciences},
  pages        = {444-459},
  shortjournal = {Inf. Sci.},
  title        = {How to generate perfect mazes?},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A type-3 logic fuzzy system: Optimized by a correntropy
based kalman filter with adaptive fuzzy kernel size. <em>ISCI</em>,
<em>572</em>, 424–443. (<a
href="https://doi.org/10.1016/j.ins.2021.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a self-organizing interval type-3 fuzzy logic system (SO-IT3FLS) with a new learning algorithm is presented. An adaptive kernel size using fuzzy systems is introduced to improve the robustness of conventional correntropy based Kalman filters against non-Gaussian noise. The maximum correntropy Kalman filter (MCKF) and maximum correntropy unscented Kalman filter (MCUKF) with the proposed adaptive fuzzy kernel size are reformulated to optimize both rule and antecedent parameters, respectively. In addition to the rule parameters, the proposed membership function (MF) parameters and the level of α -cuts are also optimized. Five simulation examples with real-world data sets are given for examination. The simulations show that the introduced SO-IT3FLS and learning algorithm result in better accuracy in contrast to the other kind of fuzzy neural networks and conventional learning techniques. Furthermore, it is verified that the robustness of the proposed learning method against non-Gaussian noise is improved in contrast to the conventional Kalman filter, maximum correntropy Kalman filter and unscented Kalman filter.},
  archive      = {J_ISCI},
  author       = {Sultan Noman Qasem and Ali Ahmadian and Ardashir Mohammadzadeh and Sakthivel Rathinasamy and Bahareh Pahlevanzadeh},
  doi          = {10.1016/j.ins.2021.05.031},
  journal      = {Information Sciences},
  pages        = {424-443},
  shortjournal = {Inf. Sci.},
  title        = {A type-3 logic fuzzy system: Optimized by a correntropy based kalman filter with adaptive fuzzy kernel size},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rotation-aware representation learning for remote sensing
image retrieval. <em>ISCI</em>, <em>572</em>, 404–423. (<a
href="https://doi.org/10.1016/j.ins.2021.04.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rising number and size of remote sensing (RS) image archives makes content-based RS image retrieval (CBRSIR) more important. Convolutional neural networks (CNNs) offer good CBRSIR performance, but the features they extract are not rotation-invariant. This is problematic as objects in RS images appear in arbitrary rotation angles . We develop and investigate two new rotation-aware CNN-based CBRSIR methods: 1) In the Feature Map Transformation Based Rotation-Aware Network (FMT-RAN), the last pooling layer is rotated in four different angles during training. Its outputs are passed through the same fully connected-, coding-, and classification layer, and the resulting losses are added. 2) The Spatial Transformer-based Rotation-Aware Network (ST-RAN) contains a spatial transformer network (STN) and a rotation aware network (RAN). For training, the original and a randomly rotated version of an image are fed into the ST-RAN. The STN generates a transformed version of the original to match the rotated image. The RAN extracts the features of all three images. We apply two-stage training, which first optimizes the STN and then the RAN. Both of our methods are efficient in terms of retrieval accuracy and time, but ST-RAN has the overall best performance. It outperforms the state-of-the-art CBRSIR methods.},
  archive      = {J_ISCI},
  author       = {Zhi-Ze Wu and Chang Zou and Yan Wang and Ming Tan and Thomas Weise},
  doi          = {10.1016/j.ins.2021.04.078},
  journal      = {Information Sciences},
  pages        = {404-423},
  shortjournal = {Inf. Sci.},
  title        = {Rotation-aware representation learning for remote sensing image retrieval},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-modal visual adversarial bayesian personalized ranking
model for recommendation. <em>ISCI</em>, <em>572</em>, 378–403. (<a
href="https://doi.org/10.1016/j.ins.2021.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation system is facing the “data sparseness” issue. Additional information, including images, texts, and videos, contributes to alleviating this issue. We propose a new multi-modal visual adversarial Bayesian personalized ranking (MVABPR) model to address the issue. The proposed model takes new features, cross-modal semantics, adversarial learning, and visual interface into account. Two multi-modal datasets are created based on the MovieLens datasets and the correlated images. Besides the shape, texture, color, and deep learning-based features, a set of efficient match kernel features are proposed. More discriminative but low-dimensional cross-modal semantics among these features is mined to characterize each item effectively, which is absorbed into the MVABPR model through a visual interface. A new adversarial learning strategy is employed to optimize the whole training procedure. This makes the MVABPR model more robust and stable. Experimental results demonstrate that the MVABPR model is effective and robust for recommendation. It outperforms other competitive baselines. As another advantage, it can learn visual information and users’ rating jointly, effectively, combined with adversarial learning. And the implicit feeling tone of a recommended item can be accurately captured by the proposed model. More importantly, the model achieves better performance on a large-scale sparser dataset, demonstrating its higher practicality.},
  archive      = {J_ISCI},
  author       = {Guangli Li and Jianwu Zhuo and Chuanxiu Li and Jin Hua and Tian Yuan and Zhengyu Niu and Donghong Ji and Renzhong Wu and Hongbin Zhang},
  doi          = {10.1016/j.ins.2021.05.022},
  journal      = {Information Sciences},
  pages        = {378-403},
  shortjournal = {Inf. Sci.},
  title        = {Multi-modal visual adversarial bayesian personalized ranking model for recommendation},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decomposition-based multiobjective evolutionary algorithm
with weights updated adaptively. <em>ISCI</em>, <em>572</em>, 343–377.
(<a href="https://doi.org/10.1016/j.ins.2021.03.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, decomposition-based multiobjective evolutionary algorithms (DMEAs) have become more prevalent than other patterns (e.g., Pareto-based algorithms and indicator-based algorithms) for solving multiobjective optimization problems (MOPs). They utilize a scalarizing method to decompose an MOP into several subproblems based on the weights provided, resulting in the performances of the algorithms being highly dependent on the uniformity between the problem’s optimal Pareto front and the distribution of the specified weights. However, weight generation is generally based on a simplex lattice design, which is suitable for “regular” Pareto fronts (i.e., simplex-like fronts) but not for other “irregular” Pareto fronts. To improve the efficiency of this type of algorithm, we develop a DMEA with weights updated adaptively (named DMEA-WUA) for the problems regarding various Pareto fronts. Specifically,the DMEA-WUA introduces a novel exploration versus exploitation model for environmental selection.The exploration process finds appropriate weights for a given problem in four steps: weight generation, weight deletion, weight addition and weight replacement. Exploitation means using these weights from the exploration step to guide the evolution of the population. Moreover, exploration is carried out when the exploitation process is stagnant; this is different from the existing method of periodically updating weights. Experimental results show that our algorithm is suitable for solving problems with various Pareto fronts, including those with “regular” and “irregular” shapes.},
  archive      = {J_ISCI},
  author       = {Yuan Liu and Yikun Hu and Ningbo Zhu and Kenli Li and Juan Zou and Miqing Li},
  doi          = {10.1016/j.ins.2021.03.067},
  journal      = {Information Sciences},
  pages        = {343-377},
  shortjournal = {Inf. Sci.},
  title        = {A decomposition-based multiobjective evolutionary algorithm with weights updated adaptively},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autoencoder-like semi-NMF multiple clustering.
<em>ISCI</em>, <em>572</em>, 331–342. (<a
href="https://doi.org/10.1016/j.ins.2021.04.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is performed to partition samples into disjoint groups for facilitating the discovery of hidden patterns in the data. Many real-world applications involve various clustering methods , most of which only produce a single clustering. As a response to this issue, multiple clustering that aims to generate diverse and high-quality clustering, has emerged recently. This study proposes a novel autoencoder-like semi-nonnegative matrix factorization (NMF) multiple clustering (ASNMFMC) model that generates multiple non-redundant, high-quality clustering. The nonnegative property of the semi-NMF is utilized by the algorithm to enforce non-redundancy. Extensive experimental results demonstrate that the ASNMFMC is superior to the existing multiple clustering methods and can explore diverse high-quality clustering.},
  archive      = {J_ISCI},
  author       = {Shihong Yao and Chuli Hu and Tao Wang and Xinyou Cui},
  doi          = {10.1016/j.ins.2021.04.080},
  journal      = {Information Sciences},
  pages        = {331-342},
  shortjournal = {Inf. Sci.},
  title        = {Autoencoder-like semi-NMF multiple clustering},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NN-EVCLUS: Neural network-based evidential clustering.
<em>ISCI</em>, <em>572</em>, 297–330. (<a
href="https://doi.org/10.1016/j.ins.2021.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evidential clustering is an approach to clustering based on the use of Dempster-Shafer mass functions to represent cluster-membership uncertainty. In this paper, we introduce a neural-network based evidential clustering algorithm , called NN-EVCLUS, which learns a mapping from attribute vectors to mass functions, in such a way that more similar inputs are mapped to output mass functions with a lower degree of conflict. The neural network can be paired with a one-class support vector machine to make it robust to outliers and capable of detecting previously unseen clusters when applied to new data. The network is trained to minimize the discrepancy between dissimilarities and degrees of conflict for all or some object pairs. Additional terms can be added to the loss function to account for pairwise constraints or labeled data, which can also be used to adapt the metric. Comparative experiments show the superiority of NN-EVCLUS over state-of-the-art evidential clustering algorithms for a range of unsupervised and constrained clustering tasks involving both attribute and dissimilarity data.},
  archive      = {J_ISCI},
  author       = {Thierry Denœux},
  doi          = {10.1016/j.ins.2021.05.011},
  journal      = {Information Sciences},
  pages        = {297-330},
  shortjournal = {Inf. Sci.},
  title        = {NN-EVCLUS: Neural network-based evidential clustering},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring cohesive subgraphs with vertex engagement and tie
strength in bipartite graphs. <em>ISCI</em>, <em>572</em>, 277–296. (<a
href="https://doi.org/10.1016/j.ins.2021.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel cohesive subgraph model called τ τ -strengthened ( α , β ) (α,β) -core (denoted as ( α , β ) τ (α,β)τ -core), which is the first to consider both tie strength and vertex engagement on bipartite graphs . An edge is a strong tie if contained in at least τ τ butterflies ( 2 × 2 2×2 -bicliques). ( α , β ) τ (α,β)τ -core requires each vertex on the upper or lower level to have at least α α or β β strong ties, given strength level τ τ . To retrieve the vertices of ( α , β ) τ (α,β)τ -core optimally, we construct index I α , β , τ Iα,β,τ to store all ( α , β ) τ (α,β)τ -cores. Effective optimization techniques are proposed to improve index construction . To make our idea practical on large graphs, we propose 2D-indexes I α , β , I β , τ Iα,β,Iβ,τ , and I α , τ Iα,τ that selectively store the vertices of ( α , β ) τ (α,β)τ -core for some α , β α,β , and τ τ . The 2D-indexes are more space-efficient and require less construction time, each of which can support ( α , β ) τ (α,β)τ -core queries. As query efficiency depends on input parameters and the choice of 2D-index, we propose a learning-based hybrid computation paradigm by training a feed-forward neural network to predict the optimal choice of 2D-index that minimizes the query time. Extensive experiments show that (1) ( α , β ) τ (α,β)τ -core is an effective model capturing unique and important cohesive subgraphs; (2) the proposed techniques significantly improve the efficiency of index construction and query processing .},
  archive      = {J_ISCI},
  author       = {Yizhang He and Kai Wang and Wenjie Zhang and Xuemin Lin and Ying Zhang},
  doi          = {10.1016/j.ins.2021.04.027},
  journal      = {Information Sciences},
  pages        = {277-296},
  shortjournal = {Inf. Sci.},
  title        = {Exploring cohesive subgraphs with vertex engagement and tie strength in bipartite graphs},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual non-autonomous deep convolutional neural network for
image denoising. <em>ISCI</em>, <em>572</em>, 263–276. (<a
href="https://doi.org/10.1016/j.ins.2021.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a Dual Non-Autonomous Deep Convolutional Neural Network , namely DNA-Net, and employ it to resolve the image denoising problem. The DNA-Net models the forward and backward processes of network training as two plain ordinary differential equations (ODEs), while the non-autonomous ODEs are employed in both the two processes for efficient feature learning and gradient propagation. The non-autonomy of the forward process is introduced by incorporating the network input to each layer, which allows low-level features to be well sustained in the entire network. The non-autonomy of the backward process is realized by connecting the network output to each layer, facilitating the gradient to be fluently propagated without vanishing. We prove that the forward process of DNA-Net can stably converge to an input dependent equilibrium in the sense of expectation. As a consequence, DNA-Net can be more efficiently trained than the existing deep networks such as the residual network . Experimental results on image denoising demonstrate the leading performance of the proposed DNA-Net.},
  archive      = {J_ISCI},
  author       = {Xixi Jia and Xiangchu Feng and Sanyang Liu},
  doi          = {10.1016/j.ins.2021.05.001},
  journal      = {Information Sciences},
  pages        = {263-276},
  shortjournal = {Inf. Sci.},
  title        = {Dual non-autonomous deep convolutional neural network for image denoising},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time adaptive event-triggered fault-tolerant control
of nonlinear systems based on fuzzy observer. <em>ISCI</em>,
<em>572</em>, 241–262. (<a
href="https://doi.org/10.1016/j.ins.2021.04.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the adaptive event-triggered tracking control problem for a class of uncertain nonlinear systems with actuator failures and disturbances. By designing a fuzzy observer to estimate the unmeasurable states, a novel event-triggered adaptive fuzzy control scheme with a sign function is proposed. Unlike the existing methods, the event-triggered controller with a parameter-updated law containing only one online modulated variable can dynamically compensate for the approximation error caused at each step. The proposed control strategy guarantees that all the signals of the closed-loop systems are bounded, and that the tracking errors can be regulated to a compact set around the origin in finite-time without Zeno behavior. Finally, a numerical example and a practical example validate the effectiveness of the designed scheme.},
  archive      = {J_ISCI},
  author       = {Qingkun Yu and Xiqin He and Libing Wu and Liangdong Guo and Yuhan Hu},
  doi          = {10.1016/j.ins.2021.04.097},
  journal      = {Information Sciences},
  pages        = {241-262},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time adaptive event-triggered fault-tolerant control of nonlinear systems based on fuzzy observer},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LinCbO: Fast algorithm for computation of the
duquenne-guigues basis. <em>ISCI</em>, <em>572</em>, 223–240. (<a
href="https://doi.org/10.1016/j.ins.2021.04.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and evaluate a novel algorithm for computation of the Duquenne-Guigues basis which combines Close-by-One and LinClosure algorithms. This combination enables us to reuse attribute counters used in LinClosure and speed up the computation. Our experimental evaluation shows that it is the most efficient algorithm for computation of the Duquenne-Guigues basis. keyword: non-redundancy; attribute implications; minimalization; closures.},
  archive      = {J_ISCI},
  author       = {Radek Janostik and Jan Konecny and Petr Krajča},
  doi          = {10.1016/j.ins.2021.04.104},
  journal      = {Information Sciences},
  pages        = {223-240},
  shortjournal = {Inf. Sci.},
  title        = {LinCbO: Fast algorithm for computation of the duquenne-guigues basis},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision-theoretic five-way approximation of fuzzy sets.
<em>ISCI</em>, <em>572</em>, 200–222. (<a
href="https://doi.org/10.1016/j.ins.2021.04.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, decision-theoretic five-way approximation of fuzzy sets is introduced by extending existing three-way decision-theoretic models. The proposed model exhibits a number of useful features which allow a decision maker to consider weak acceptance or weak rejection options, thereby minimizing the overall approximation error and cost. Two special models: cost-sensitive and minimum distance, in decision-theoretic five-way approximation of fuzzy sets are investigated. Experimental studies and comparisons with existing decision-theoretic three-way approximation models show the advantage and promising performance of the proposed model.},
  archive      = {J_ISCI},
  author       = {Tamunokuro Opubo William-West and Davide Ciucci},
  doi          = {10.1016/j.ins.2021.04.105},
  journal      = {Information Sciences},
  pages        = {200-222},
  shortjournal = {Inf. Sci.},
  title        = {Decision-theoretic five-way approximation of fuzzy sets},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterated multilevel simulated annealing for large-scale
graph conductance minimization. <em>ISCI</em>, <em>572</em>, 182–199.
(<a href="https://doi.org/10.1016/j.ins.2021.04.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given an undirected connected graph G = ( V , E ) G=(V,E) with vertex set V and edge set E , the minimum conductance graph partitioning problem is to partition V into two disjoint subsets such that the conductance, i.e., the ratio of the number of cut edges to the smallest volume of two partition subsets is minimized. This problem has a number of practical applications in various areas such as community detection, bioinformatics, and computer vision . However, the problem is computationally challenging, especially for large problem instances. This work presents the first iterated multilevel simulated annealing algorithm for large-scale graph conductance minimization. The algorithm features a novel solution-guided coarsening method and an effective solution refinement procedure based on simulated annealing. Computational experiments demonstrate the high performance of the algorithm on 66 very large real-world sparse graphs with up to 23 million vertices. Additional experiments are presented to get insights into the influences of its algorithmic components . The source code of the proposed algorithm is publicly available, which can be used to solve various real world problems .},
  archive      = {J_ISCI},
  author       = {Zhi Lu and Jin-Kao Hao and Una Benlic and David Lesaint},
  doi          = {10.1016/j.ins.2021.04.102},
  journal      = {Information Sciences},
  pages        = {182-199},
  shortjournal = {Inf. Sci.},
  title        = {Iterated multilevel simulated annealing for large-scale graph conductance minimization},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time series analysis and prediction of nonlinear systems
with ensemble learning framework applied to deep learning neural
networks. <em>ISCI</em>, <em>572</em>, 167–181. (<a
href="https://doi.org/10.1016/j.ins.2021.04.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we design a framework to predict the value of time series for nonlinear systems . In order to achieve this goal, many studies of applications and plans for machine learning and even deep learning become currently popular. First, we select four nonlinear systems : including a proposed four-dimensional chaotic system, Lorenz system , Duffing oscillator, and Rössler attractor. The framework has three learning parts as Long Short-Term Memory (LSTM) based on Generate Performance Model (GPM), ensemble learning based on Restrict and Control Model (RCM), and one-dimensional convolution neural network (1-DCNN) of dirichlet distribution based on Overall Verification Model (OVM). Before learning steps, we exploit K-means method as pre-processing and hypothesis verification to improve the prediction accuracy. After learning steps, we construct four forecasting progresses as Point by Point Generated Method (PPGM), Sequence Full Generated Method (SFGM), Sequence Multiple Generated Method (SMGM), and Improvement with RCM and OVM (IPRO) to predict the value of the time steps. Finally, we use Mean Average Error (MAE) as the criterion of the prediction, and estimate the accuracy by comparing the error region of the average standard deviation.},
  archive      = {J_ISCI},
  author       = {Shao-Chun Wen and Cheng-Hsiung Yang},
  doi          = {10.1016/j.ins.2021.04.094},
  journal      = {Information Sciences},
  pages        = {167-181},
  shortjournal = {Inf. Sci.},
  title        = {Time series analysis and prediction of nonlinear systems with ensemble learning framework applied to deep learning neural networks},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-mode function synchronization of memristive neural
networks with mixed delays and parameters mismatch via event-triggered
control. <em>ISCI</em>, <em>572</em>, 147–166. (<a
href="https://doi.org/10.1016/j.ins.2021.04.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As we know, the study of complete synchronization of dynamic systems is usually confined to exponential synchronization and power-rate synchronization. Therefore, it is an interesting topic whether there are other complete synchronization methods or give a unified mathematical expression of these complete synchronization types. In this paper, we look into the issue of multi-mode function synchronization (MMFS) for memristive neural networks (MNNs) with two kinds of time-varying delays via event-triggered control. Two types of parameters mismatch in MNNs are considered. One is state-dependent, and by formulating a new Lyapunov functional , we achieve a sufficient criterion for the drive and response MNNs to synchronize in the form of convergence-like function L ( t ) L(t) . The other is structure-dependent, which can only realize multi-mode function quasi-synchronization (MMFQS). Matrix measure method and a modified Halanay inequality are used to fulfill the multi-mode function quasi-synchronization between the drive and response MNNs. Conclusively, two numerical examples are simulated to prove the effectiveness of our theoretical results.},
  archive      = {J_ISCI},
  author       = {Ailong Wu and Yue Chen and Zhigang Zeng},
  doi          = {10.1016/j.ins.2021.04.101},
  journal      = {Information Sciences},
  pages        = {147-166},
  shortjournal = {Inf. Sci.},
  title        = {Multi-mode function synchronization of memristive neural networks with mixed delays and parameters mismatch via event-triggered control},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Triadic concept approximation. <em>ISCI</em>, <em>572</em>,
126–146. (<a href="https://doi.org/10.1016/j.ins.2021.04.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Formal Concept Analysis is a mathematical theory for knowledge representation as well as data analysis and visualization. It provides a mechanism for understanding and mining data through concept lattice construction and exploration. This theory assists in data processing by providing a framework for applying different analysis techniques. One of its potentials lies in its mathematical foundation that enables the generation, ordering, and visualization of knowledge in the form of formal concepts described in a hierarchy known as a concept lattice . However, as the input dataset grows, the search and especially the visualization and exploration of concepts becomes prohibitive. With the extension of the classical FCA approach to Triadic Concept Analysis, this problem becomes even more evident due to the complexity of the inherent structures in triadic concepts and relationships. In this work, we propose an approach to find triadic concepts when a query in the form of a triple is given, allowing the visualization and exploration of a Hasse diagram of triadic concepts.},
  archive      = {J_ISCI},
  author       = {Kaio H.A. Ananias and Rokia Missaoui and Pedro H.B. Ruas and Luis E. Zarate and Mark A.J. Song},
  doi          = {10.1016/j.ins.2021.04.064},
  journal      = {Information Sciences},
  pages        = {126-146},
  shortjournal = {Inf. Sci.},
  title        = {Triadic concept approximation},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SVSV: Online handwritten signature verification based on
sound and vibration. <em>ISCI</em>, <em>572</em>, 109–125. (<a
href="https://doi.org/10.1016/j.ins.2021.04.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Handwritten signature is one of the most important behavioral biometrics and plays an important role in the field of identity verification . It is regarded as a legal means to verify personal identity by administrative and financial institutions. Traditional manual signature verification requires large labor costs and the probability of verification error is relatively high. Nowadays, tablets are often used for signature capturing, which motivates us to explore the feasibility of using tablets for signature verification. In this paper, we propose an online handwriting s ignature v erification system based on s ound and v ibration (SVSV) generated during the signing process. We develop an application to collect signature-related vibration and sound data. We first extract the time domain features of the sound signal and use Fast Fourier Transform to extract the frequency domain features of the sound data. For vibration data, we use Discrete Cosine Transform for dimensionality reduction and feature extraction. Then we fuse the sound and vibration features. Finally, we design an efficient one-class classifier based on the Convolutional Neural Network to perform signature verification. Through extensive experiments with 12 volunteers, the results show that SVSV is a robust and efficient system with an AUC of 0.984 0.984 and an EER of 0.05 0.05 .},
  archive      = {J_ISCI},
  author       = {Zhixiang Wei and Song Yang and Yadong Xie and Fan Li and Bo Zhao},
  doi          = {10.1016/j.ins.2021.04.099},
  journal      = {Information Sciences},
  pages        = {109-125},
  shortjournal = {Inf. Sci.},
  title        = {SVSV: Online handwritten signature verification based on sound and vibration},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-dependent DEASort: A multiple criteria sorting
method for ecological risk assessment problems. <em>ISCI</em>,
<em>572</em>, 88–108. (<a
href="https://doi.org/10.1016/j.ins.2021.04.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing urban economic development and awareness of environment protection, ecological risk assessment (ERA), as a management mode combined with ecological research and risk assessment, has become a highly relevant topic in environment sustainable development. In this paper, we propose a novel sorting model based on Data Envelopment Analysis (DEA) and Best Worst method (BWM) to solve multi-criteria sorting problems and apply it to ERA. The proposed Context-Dependent DEASort method based on the idea of Context-Dependent DEA to position decision-making units (DMUs) into diverse categories in uncertain circumstance. It also takes experts’ preference into full account as well, which makes the sorting solution more flexible and reasonable. Besides, a common set of weight-based model is introduced to deal with the situation when evaluating attractiveness and progress of each DMU. The common weight set model can ensure to provide an overall evaluation context compared to the original Context-Dependent DEA model, which only distinct the DMU from a single virtual DMU. Furthermore, a case study concerning ecological risk assessment of Yangtze River Economic Zone in China is provided to illustrate the applicability of the developed environment. Finally, comparative analysis and sensitivity analysis are carried out to demonstrate the practicality and effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Jindong Qin and Yingying Zeng and Yujie Zhou},
  doi          = {10.1016/j.ins.2021.04.085},
  journal      = {Information Sciences},
  pages        = {88-108},
  shortjournal = {Inf. Sci.},
  title        = {Context-dependent DEASort: A multiple criteria sorting method for ecological risk assessment problems},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised attribute reduction for mixed data based on
fuzzy rough sets. <em>ISCI</em>, <em>572</em>, 67–87. (<a
href="https://doi.org/10.1016/j.ins.2021.04.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised attribute reduction becomes very challenging due to a lack of decision information, which is to select a subset of attributes that can maintain learning ability without decision information. However, most of the existing unsupervised attribute reduction methods are proposed for numerical or nominal attributes, and little research has been done on unsupervised mixed attribute reduction methods. In view of this, this paper proposes a generalized unsupervised mixed attribute reduction model based on fuzzy rough sets . First, based on all single attribute subsets , the significance is defined to indicate the importance of a candidate attribute. Then, a specific fuzzy rough-based unsupervised attribute reduction (FRUAR) algorithm is designed. Finally, the proposed algorithm is compared with the existing algorithms by using thirty public data sets. Experimental results show that the algorithm FRUAR can select fewer attributes to maintain or improve the performance of learning algorithms, and it is suitable for mixed attribute data.},
  archive      = {J_ISCI},
  author       = {Zhong Yuan and Hongmei Chen and Tianrui Li and Zeng Yu and Binbin Sang and Chuan Luo},
  doi          = {10.1016/j.ins.2021.04.083},
  journal      = {Information Sciences},
  pages        = {67-87},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised attribute reduction for mixed data based on fuzzy rough sets},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Networked opacity for finite state machine with bounded
communication delays. <em>ISCI</em>, <em>572</em>, 57–66. (<a
href="https://doi.org/10.1016/j.ins.2021.04.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networked finite state machines consider the delay factor in real-time communication networks, and the security has become an important research topic in cyber-physical systems (CPSs). In this brief paper, we explore the networked opacity of finite state machine with bounded communication delays. Firstly, the networked opacity is proposed from the perspective of security state reachability, and by use of the Boolean matrix semi-tensor product (STP), we introduce the reachability matrix with respect to all feasible events to give the current dynamics with bounded communication delays. Subsequently, based on the algebraic equation, we continue to discuss the corresponding current estimate of possible reachable states , which can be calculated by a matrix approach . Then, a more simple and effective verification criterion of networked opacity is derived by some matrix manipulations. Finally, a typical example is provided to validate the impact of communication delay on the opacity of CPSs , and our results contribute to deeply understanding the information security in the area of CPSs.},
  archive      = {J_ISCI},
  author       = {Zhipeng Zhang and Shaolong Shu and Chengyi Xia},
  doi          = {10.1016/j.ins.2021.04.072},
  journal      = {Information Sciences},
  pages        = {57-66},
  shortjournal = {Inf. Sci.},
  title        = {Networked opacity for finite state machine with bounded communication delays},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lower order information preserved network embedding based on
non-negative matrix decomposition. <em>ISCI</em>, <em>572</em>, 43–56.
(<a href="https://doi.org/10.1016/j.ins.2021.04.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding has been successfully used for a variety of tasks, e.g., node clustering, community detection, link prediction and evolution analysis on complex networks. For a given network, embedding methods are usually designed based on first-order proximity, second-order proximity, community constraints, etc. However, they are incapable of capturing the structural similarity of nodes. The bridge nodes with small proximity and located in different communities, should be similar in embedding space since they have the same surrounding structure. In this paper, these structural features are referred to as lower-order information, which could reveal and modify the structural similarity of nodes in the embedding space. Specifically, we propose to construct the feature matrix with the lower-order information of the network. In order to effectively fuse the structural features of nodes into embedding space, an intuitive, interpretable and feasible method named LONE-NMF is proposed, which adopts the representation learning framework based on non-negative matrix factorization. It can effectively learn the representation vectors of nodes in the network via preserving the proximity and lower-order information. Moreover, an optimization algorithm is designed for LONE-NMF. Extensive experiments based on clustering and link prediction show that the proposed method achieves significant performance improvement comparing with some baselines. Finally, we validate the principle and advantage of LONE-NMF through a case study.},
  archive      = {J_ISCI},
  author       = {Qiang Tian and Lin Pan and Wang Zhang and Tianpeng Li and Huaming Wu and Pengfei Jiao and Wenjun Wang},
  doi          = {10.1016/j.ins.2021.04.095},
  journal      = {Information Sciences},
  pages        = {43-56},
  shortjournal = {Inf. Sci.},
  title        = {Lower order information preserved network embedding based on non-negative matrix decomposition},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Feature pyramid network for diffusion-based image
inpainting detection. <em>ISCI</em>, <em>572</em>, 29–42. (<a
href="https://doi.org/10.1016/j.ins.2021.04.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inpainting is a technique that can be employed to tamper with the content of images. In this paper, we propose a novel forensics analysis method for diffusion-based image inpainting based on a feature pyramid network (FPN). Our method features an improved u-shaped net to migrate FPN for multi-scale inpainting feature extraction. In addition, a stagewise weighted cross-entropy loss function is designed to take advantage of both the general loss and the weighted loss to improve the prediction rate of inpainted regions of all sizes. The experimental results demonstrate that the proposed method outperforms several state-of-the-art methods, especially when the size of the inpainted region is small.},
  archive      = {J_ISCI},
  author       = {Yulan Zhang and Feng Ding and Sam Kwong and Guopu Zhu},
  doi          = {10.1016/j.ins.2021.04.042},
  journal      = {Information Sciences},
  pages        = {29-42},
  shortjournal = {Inf. Sci.},
  title        = {Feature pyramid network for diffusion-based image inpainting detection},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Locally GAN-generated face detection based on an improved
xception. <em>ISCI</em>, <em>572</em>, 16–28. (<a
href="https://doi.org/10.1016/j.ins.2021.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has become a research hotspot to detect whether a face is natural or GAN-generated. However, all the existing works focus on whole GAN-generated faces. So, an improved Xception model is proposed for locally GAN-generated face detection. To the best of our knowledge, our work is the first one to address this issue. Some improvements over Xception are as follows: (1) Four residual blocks are removed to avoid the overfitting problem as much as possible; (2) Inception block with the dilated convolution is used to replace the common convolution layer in the pre-processing module of the Xception to obtain multi-scale features; (3) Feature pyramid network is utilized to obtain multi-level features for final decision. The first locally GAN-based generated face (LGGF) dataset is constructed by the pluralistic image completion method on the basis of FFHQ dataset. It has a total 952,000 images with the generated regions in different shapes and sizes. Experimental results demonstrate the superiority of the proposed model which outperforms some existing models, especially for the faces having small generated regions.},
  archive      = {J_ISCI},
  author       = {Beijing Chen and Xingwang Ju and Bin Xiao and Weiping Ding and Yuhui Zheng and Victor Hugo C. de Albuquerque},
  doi          = {10.1016/j.ins.2021.05.006},
  journal      = {Information Sciences},
  pages        = {16-28},
  shortjournal = {Inf. Sci.},
  title        = {Locally GAN-generated face detection based on an improved xception},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Misinformation influence minimization problem based on group
disbanded in social networks. <em>ISCI</em>, <em>572</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2021.04.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The booming development of online social media has changed the way people post and access information. The authenticity of content is weakened, and all kinds of misinformation on social media spread rapidly. In Online Social Networks (OSN), users arbitrarily form private groups/communities, which greatly increase the exposure rate of misinformation . Considering that echo chamber effect of groups wildly exists, this paper studies the disbanding strategy of private groups in OSNs to Minimize the Spread of Misinformation under the effect of Echo chamber effect (MSME). Given a directed acyclic OSN G ( V , E , C ) , C G(V,E,C),C denotes a set of private groups, the problem of MSME is to select K groups from C , such that the spread of misinformation will be minimized by disbanding these groups. We prove the problem of MSME is NP-hard, then prove that the objective function computation of the problem of MSME is #P-hard. It is proved that the objective function of the problem of MSME is neither a submodular nor a supermodular. A greedy algorithm is constructed and several heuristic algorithms are proposed to solve the objective function which is non-submodular and non-supermodular. Our experimental simulation on four real world datasets verifies the effectiveness of our constructed algorithm.},
  archive      = {J_ISCI},
  author       = {Jianming Zhu and Peikun Ni and Guoqing Wang and Yuan Li},
  doi          = {10.1016/j.ins.2021.04.086},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Misinformation influence minimization problem based on group disbanded in social networks},
  volume       = {572},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CoV2-detect-net: Design of COVID-19 prediction model based
on hybrid DE-PSO with SVM using chest x-ray images. <em>ISCI</em>,
<em>571</em>, 676–692. (<a
href="https://doi.org/10.1016/j.ins.2021.03.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For Covid-19 suspected cases, it is critical to diagnose them accurately and rapidly so that they can be isolated and provided with required medical care. A self-learning automation model will be helpful to diagnose the COVID-19 suspected individual using chest X-rays. AI based designs, which utilizes chest X-rays, have been recently proposed for the detection of COVID-19. However, these approaches are either using non-public database or having a complex design. In this study we have proposed a novel framework for real time detection of coronavirus patients without manual intervention. In our framework, we have introduced a 3-step process in which initially K-means clustering, and feature extraction is performed as a data pre-processing step. In the second step, the selected features are optimized by a novel feature optimization approach based on hybrid differential evolution algorithm and particle swarm optimization. The optimized features are then feed forwarded to SVM classifier. Empirical results show that our proposed model is able to achieve 99.34\% accuracy. This shows that our model is robust and sustainable in diagnosis of COVID-19 infected individual.},
  archive      = {J_ISCI},
  author       = {Abhishek Dixit and Ashish Mani and Rohit Bansal},
  doi          = {10.1016/j.ins.2021.03.062},
  journal      = {Information Sciences},
  pages        = {676-692},
  shortjournal = {Inf. Sci.},
  title        = {CoV2-detect-net: Design of COVID-19 prediction model based on hybrid DE-PSO with SVM using chest X-ray images},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An axiomatic design-based mathematical programming method
for heterogeneous multi-criteria group decision making with linguistic
fuzzy truth degrees. <em>ISCI</em>, <em>571</em>, 649–675. (<a
href="https://doi.org/10.1016/j.ins.2021.04.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to develop a new axiomatic design-based mathematical programming method for heterogeneous multi-criteria group decision making (HMCGDM) problems with linguistic fuzzy truth degrees (LFTDs). The main contributions of this paper are summarized in five aspects: (1) The information content definitions for six types of fuzzy numbers are initially provided according to axiomatic design . (2) Considering the authority of experts on different criteria and group consensus, a bi-objective programming model is constructed to derive experts’ weights by maximizing individual deviation and minimizing group discordance. (3) Each alternative is assessed on the basis of its information content to a fuzzy positive ideal solution. Information content is firstly used to define the linguistic fuzzy consistency and inconsistency indices. (4) A bi-objective linguistic fuzzy mathematic programming model is built to determine the criteria weights, which considers consistency and inconsistency indices simultaneously. This model can be dexterously transformed into a crisp linear programming model for resolution by the linguistic scale function. (5) The group information content of each alternative to fuzzy positive ideal solution is calculated to determine the ranking order of alternatives. Finally, an example of blockchain service provider selection is given to validate the proposed method.},
  archive      = {J_ISCI},
  author       = {Ai-Hua Liu and Shu-Ping Wan and Jiu-Ying Dong},
  doi          = {10.1016/j.ins.2021.04.091},
  journal      = {Information Sciences},
  pages        = {649-675},
  shortjournal = {Inf. Sci.},
  title        = {An axiomatic design-based mathematical programming method for heterogeneous multi-criteria group decision making with linguistic fuzzy truth degrees},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reinforcement learning approach to distribution-free
capacity allocation for sea cargo revenue management. <em>ISCI</em>,
<em>571</em>, 623–648. (<a
href="https://doi.org/10.1016/j.ins.2021.04.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose learning-based adaptive control based on reinforcement learning for the booking policy in sea cargo revenue management . The problem setting is that the demand distribution is unknown while the historical data is available, and the problem is formulated as a stochastic dynamic programming model. We demonstrate the existence of an optimal control limit policy and investigate the important properties and optimal policy structures of the model. We then propose a reinforcement learning approach for the data-driven approximation of the optimal booking policy to maximize shipping line revenue. The performance of the proposed approach is very close to that of the optimal policy and superior to that of the EMSR-b algorithm.},
  archive      = {J_ISCI},
  author       = {Dong-Wook Seo and Kyuchang Chang and Taesu Cheong and Jun-Geol Baek},
  doi          = {10.1016/j.ins.2021.04.092},
  journal      = {Information Sciences},
  pages        = {623-648},
  shortjournal = {Inf. Sci.},
  title        = {A reinforcement learning approach to distribution-free capacity allocation for sea cargo revenue management},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A stacking weighted k-nearest neighbour with thresholding.
<em>ISCI</em>, <em>571</em>, 605–622. (<a
href="https://doi.org/10.1016/j.ins.2021.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In Multi-label problems, each instance is associated with a set of predefined labels. Binary Relevance, as a common approach, uses one binary classifier for each label and ignores the probable dependencies between some labels. Stacked-Binary Relevance (SBR) was proposed to consider the label dependencies, by augmenting a second layer of binary models using the predicted labels of the first level binary models as additional features. By reusing all predicted labels, SBR implicitly assumes full dependencies between labels, which is not usually a true assumption in the real world. Moreover, SBR uses a constant threshold in decision functions of the binary models, while adjusting the threshold for each label specially for imbalanced ones can improve the performance. This paper proposes a k -Nearest Neighbor stacking method that adjusts the thresholds in decision functions of the binary classifiers and uses a feature-weighted distance measure to reduce the effect of irrelevant labels in stacking. The method can leverage positive/negative and symmetric/asymmetric label dependencies expressed as feature weights. Also, it can tackle the main shortcomings of SBR (revealed in the existence of irrelevant labels and imbalanced data). Using 22 multi-label datasets, the proposed method is assessed and outperforms state-of-the-art methods presented in the literature.},
  archive      = {J_ISCI},
  author       = {Niloofar Rastin and Mohammad Taheri and Mansoor Zolghadri Jahromi},
  doi          = {10.1016/j.ins.2021.05.030},
  journal      = {Information Sciences},
  pages        = {605-622},
  shortjournal = {Inf. Sci.},
  title        = {A stacking weighted k-nearest neighbour with thresholding},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated detection of shockable ECG signals: A review.
<em>ISCI</em>, <em>571</em>, 580–604. (<a
href="https://doi.org/10.1016/j.ins.2021.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sudden cardiac death from lethal arrhythmia is a preventable cause of death. Ventricular fibrillation and tachycardia are shockable electrocardiographic (ECG)rhythms that can respond to emergency electrical shock therapy and revert to normal sinus rhythm if diagnosed early upon cardiac arrest with the restoration of adequate cardiac pump function. However, manual inspection of ECG signals is a difficult task in the acute setting. Thus, computer-aided arrhythmia classification (CAAC) systems have been developed to detect shockable ECG rhythm. Traditional machine learning and deep learning methods are now progressively employed to enhance the diagnostic accuracy of CAAC systems. This paper reviews the state-of-the-art machine and deep learning based CAAC expert systems for shockable ECG signal recognition, discussing their strengths, advantages, and drawbacks. Moreover, unique bispectrum and recurrence plots are proposed to represent shockable and non-shockable ECG signals. Deep learning methods are usually more robust and accurate than standard machine learning methods but require big data of good quality for training. We recommend collecting large accessible ECG datasets with a meaningful proportion of abnormal cases for research and development of superior CAAC systems.},
  archive      = {J_ISCI},
  author       = {Mohamed Hammad and Rajesh N.V.P.S. Kandala and Amira Abdelatey and Moloud Abdar and Mariam Zomorodi‐Moghadam and Ru San Tan and U. Rajendra Acharya and Joanna Pławiak and Ryszard Tadeusiewicz and Vladimir Makarenkov and Nizal Sarrafzadegan and Abbas Khosravi and Saeid Nahavandi and Ahmed A. Abd EL-Latif and Paweł Pławiak},
  doi          = {10.1016/j.ins.2021.05.035},
  journal      = {Information Sciences},
  pages        = {580-604},
  shortjournal = {Inf. Sci.},
  title        = {Automated detection of shockable ECG signals: A review},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extremely simple classifier based on fuzzy logic and gene
expression programming. <em>ISCI</em>, <em>571</em>, 560–579. (<a
href="https://doi.org/10.1016/j.ins.2021.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new design of a very simple data-driven binary classifier and conduct an empirical study of its performance. The data contain continuous and categorical variables . The classification system consists of highly interpretable fuzzy metarules. A new theorem is developed that guarantees that these metarules are equivalent to algebraic expressions . The algebraic expressions are obtained using the gene expression programming technique. The number of features in the modeled dataset does not affect the complexity of the metarules. The performance of the resulting metarules is comparable to that of the rules created by most of the popular machine learning methods. The newly introduced classifier (GPR) appears to be the simplest among the fuzzy rule-based classifiers. Its effectiveness was tested on 16 datasets and compared with 22 other classification algorithms . GPR turned out to be surprisingly good; i.e., it belongs to the group of the best classifiers when the quality criterion is the area under the ROC curve and the classification accuracy . The Scott-Knott analysis indicates that, in terms of performance, GPR is commensurate with the leading group of 3 algorithms, and the Wilcoxon test confirmed the statistical reliability of the obtained results. High interpretability is proved with examples of classification models .},
  archive      = {J_ISCI},
  author       = {Jacek Kluska and Michal Madera},
  doi          = {10.1016/j.ins.2021.05.041},
  journal      = {Information Sciences},
  pages        = {560-579},
  shortjournal = {Inf. Sci.},
  title        = {Extremely simple classifier based on fuzzy logic and gene expression programming},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time foreground object segmentation networks using long
and short skip connections. <em>ISCI</em>, <em>571</em>, 543–559. (<a
href="https://doi.org/10.1016/j.ins.2021.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foreground object segmentation is an important task with various applications in outdoor surveillance and navigation. Most existing methods focus on accuracy and therefore, are computationally expensive and low in speed, making them difficult to use in actual applications. In this study, we aim to address the issue of accuracy and efficiency trade-off. In particular, in contrast with existing methods that use fine-tuning routine on heavyweight pretrained models and/or optimization techniques to enhance results, we propose a lightweight end-to-end network that can be trained from scratch effectively and efficiently. First, long and short skip connections are used among convolutional blocks and within the bottleneck block. By doing so, information flow within the networks is enhanced during the training stage, and thus, the use rate of parameters in the model is increased, allowing a more compact and efficient network design. Second, we use feature fusions based on element-wise summing before each up-sampling layer to reduce the size of the decoder, accelerate the up-sampling process, and stabilize training convergence. Our proposed method is tested rigorously. In particular, we achieved 1000 times higher speed compared with state-of-the-art methods on CD2014 and SBI2015 datasets with comparable accuracy.},
  archive      = {J_ISCI},
  author       = {Cong Lin and Shijie Zhang and Shaodi You and Xiaoxiang Liu and Zhiyu Zhu},
  doi          = {10.1016/j.ins.2021.01.044},
  journal      = {Information Sciences},
  pages        = {543-559},
  shortjournal = {Inf. Sci.},
  title        = {Real-time foreground object segmentation networks using long and short skip connections},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised anomaly detection in dynamic communication
networks. <em>ISCI</em>, <em>571</em>, 527–542. (<a
href="https://doi.org/10.1016/j.ins.2021.04.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the security and stabilization of the communication networks, anomaly detection is the first line of defense. However, their learning process suffers two major issues: (1) inadequate labels : there are many different kinds of attacks but rare abnormal nodes in mt of these atstacks; and (2) inaccurate labels : considering the heavy network flows and new emerging attacks, providing accurate labels for all nodes is very expensive. The inadequate and inaccurate label problem challenges many existing methods because the majority normal nodes result in a biased classifier while the noisy labels will further degrade the performance of the classifier. To tackle these issues, we propose SemiADC, a Semi -supervised A nomaly D etection framework for dynamic C ommunication networks. SemiADC first approximately learns the feature distribution of normal nodes with regularization from abnormal ones. It then cleans the datasets and extracts the nodes sasainaccurate labels by the learned feature distribution and structure-based temporal correlations. These self-learning processes run iteratively with mutual promotion, and finally help increase the accuracy of anomaly detection . Experimental evaluations on real-world datasets demonstrate the effectiveness of our SemiADC, which performs substantially better than the state-of-art anomaly detection approaches without the demand of adequate and accurate supervision.},
  archive      = {J_ISCI},
  author       = {Xuying Meng and Suhang Wang and Zhimin Liang and Di Yao and Jihua Zhou and Yujun Zhang},
  doi          = {10.1016/j.ins.2021.04.056},
  journal      = {Information Sciences},
  pages        = {527-542},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised anomaly detection in dynamic communication networks},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Additive noise model structure learning based on rank
correlation. <em>ISCI</em>, <em>571</em>, 499–526. (<a
href="https://doi.org/10.1016/j.ins.2021.05.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To examine the structural learning of the additive noise model in causal discovery, a new algorithm, i.e., RCB (Rank-Correlation-Based), is proposed in combination with the method of Rank Correlation . This algorithm can effectively process multivariate linear Gaussian, non-Gaussian and multivariate nonlinear non-Gaussian data. In this article we have made three contributions. First, it is proven that rank correlation can be used as the criterion of the independence test. Second, through a series of experiments, the optimal threshold of rank correlation is found to select the potential neighbors of the target node . Thus, the RCB algorithm greatly reduces the search space and achieves good time performance. The third contribution is the improvement of the RCB algorithm in combination with the hypothesis testing method, and the RCS (Rank-Correlation-Statistics) algorithm is proposed to solve the theoretical basis for the threshold selection. Compared with the existing technology on 7 networks, the RCS algorithm is superior to existing algorithms in terms of both accuracy and time performance. In addition, simulations show that the RCS algorithm can achieve a good time performance and accuracy on low-dimensional large samples, high-dimensional large samples and real data.},
  archive      = {J_ISCI},
  author       = {Jing Yang and Gaojin Fan and Kai Xie and Qiqi Chen and Aiguo Wang},
  doi          = {10.1016/j.ins.2021.05.061},
  journal      = {Information Sciences},
  pages        = {499-526},
  shortjournal = {Inf. Sci.},
  title        = {Additive noise model structure learning based on rank correlation},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Double-local rough sets for efficient data mining.
<em>ISCI</em>, <em>571</em>, 475–498. (<a
href="https://doi.org/10.1016/j.ins.2021.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important extension of classical rough sets, local rough set model is effective to handle large data sets with small amounts of labeled data, which has an obvious advantage in improving computational performance. However, the existing mining algorithms based on local rough sets are still computationally time-consuming in processing large-scale labeled data sets . To overcome this limitation, we propose an enhanced local rough set framework called double-local rough sets, by introducing the notion of local equivalence classes. Under this framework, we define the lower deletion matrix, the upper addition matrix , and the upper deletion matrix. Based on these matrices, we develop a fast iteration method for computing the approximations , which is vital for attribute reduction and knowledge discovery. Furthermore, a fast attribute reduction method is presented by accelerating the calculation of stop criteria and attribute significance measures, which can obtain the same attribute reduct as its original local rough set version. Theoretical analysis and experimental results indicate that the proposed algorithms in double-local rough sets significantly outperform their original counterparts in classical local rough sets.},
  archive      = {J_ISCI},
  author       = {Guoqiang Wang and Tianrui Li and Pengfei Zhang and Qianqian Huang and Hongmei Chen},
  doi          = {10.1016/j.ins.2021.05.007},
  journal      = {Information Sciences},
  pages        = {475-498},
  shortjournal = {Inf. Sci.},
  title        = {Double-local rough sets for efficient data mining},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning sentiment sentence representation with multiview
attention model. <em>ISCI</em>, <em>571</em>, 459–474. (<a
href="https://doi.org/10.1016/j.ins.2021.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-attention mechanisms in deep neural networks , such as CNN , GRU and LSTM , have been proven to be effective for sentiment analysis . However, existing attention models tend to focus on individual tokens or aspect meanings in an expression. If a text contains information on multiple sentiments from different perspectives, the existing models will fail to extract the most critical and comprehensive features of the whole text. In the present study, a multiview attention model was proposed for learning sentence representation. Instead of using a single attention, multiple view vectors were used to map the attentions from different perspectives. Then, a fusion gate was adopted to combine these multiview attentions to draw a conclusion. To ensure the differences between multiview attentions, a regularization item was introduced to add a penalty to the loss function. In addition, the proposed model can be extended to other text tasks, such as questions and topics, to provide a comprehensive representation for the classification. Comparative experiments were conducted on both multiclass and multilabel classification datasets. The results revealed that the proposed method improves the performance of several previously proposed attention models.},
  archive      = {J_ISCI},
  author       = {You Zhang and Jin Wang and Xuejie Zhang},
  doi          = {10.1016/j.ins.2021.05.044},
  journal      = {Information Sciences},
  pages        = {459-474},
  shortjournal = {Inf. Sci.},
  title        = {Learning sentiment sentence representation with multiview attention model},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). A network representation learning method based on topology.
<em>ISCI</em>, <em>571</em>, 443–458. (<a
href="https://doi.org/10.1016/j.ins.2021.04.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the network, nodes with similar neighborhood topology often have similar functions and play similar roles. Accurately identifying the role of nodes is the key to our understanding of the network and then facilitates the completion of subsequent tasks. This paper proposes a network representation method based on the Neighborhood Topology Feature (NTF), which learns the latent representations of nodes based on their neighborhood topologies. NTF adopts the idea of energy dissipation and introduces the concept of energy level to measure the influence of neighboring nodes on the central node, and on this basis constructs the influence subgraph of the central node. NTF comprehensively uses the absolute and relative features of the neighboring nodes to describe the neighborhood topology of the central node hierarchically to achieve a better learning effect. It can effectively reduce the interference of noise nodes by measuring the node pairs similarity on the influence subgraph. The experimental results show that NTF performs better than the existing methods on the public datasets, and it also achieves excellent results on the real data of the actual project.},
  archive      = {J_ISCI},
  author       = {Wei Wang and Dongyang Ma and Guodong Xin and Yunpeng Han and Junheng Huang and Bailing Wang},
  doi          = {10.1016/j.ins.2021.04.048},
  journal      = {Information Sciences},
  pages        = {443-458},
  shortjournal = {Inf. Sci.},
  title        = {A network representation learning method based on topology},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering mixed numerical and categorical data with missing
values. <em>ISCI</em>, <em>571</em>, 418–442. (<a
href="https://doi.org/10.1016/j.ins.2021.04.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel framework for clustering mixed numerical and categorical data with missing values. It integrates the imputation and clustering steps into a single process, which results in an algorithm named C lustering M ixed Numerical and Categorical Data with M issing Values ( k -CMM). The algorithm consists of three phases. The initialization phase splits the input dataset into two parts based on missing values in objects and attributes types. The imputation phase uses the decision-tree-based method to find the set of correlated data objects. The clustering phase uses the mean and kernel-based methods to form cluster centers at numerical and categorical attributes, respectively. The algorithm also uses the squared Euclidean and information-theoretic-based dissimilarity measure to compute the distances between objects and cluster centers. An extensive experimental evaluation was conducted on real-life datasets to compare the clustering quality of k -CMM with state-of-the-art clustering algorithms . The execution time, memory usage, and scalability of k -CMM for various numbers of clusters or data sizes were also evaluated. Experimental results show that k -CMM can efficiently cluster missing mixed datasets as well as outperform other algorithms when the number of missing values increases in the datasets.},
  archive      = {J_ISCI},
  author       = {Duy-Tai Dinh and Van-Nam Huynh and Songsak Sriboonchitta},
  doi          = {10.1016/j.ins.2021.04.076},
  journal      = {Information Sciences},
  pages        = {418-442},
  shortjournal = {Inf. Sci.},
  title        = {Clustering mixed numerical and categorical data with missing values},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UDA: A user-difference attention for group recommendation.
<em>ISCI</em>, <em>571</em>, 401–417. (<a
href="https://doi.org/10.1016/j.ins.2021.04.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human beings are gregarious by nature, and thus, group activities are indispensable in people’s daily lives. In light of this, group recommendation systems have attracted wide research attention in recent years. The pivotal task of group recommendation is to learn the weights of group members and then aggregate their preferences. Most existing methods only consider a single user and the target item to calculate their weight, which is insufficient to determine the user’s importance in a group. In this study, we emphasize the importance of comparison information. A comparison is an explicit relationship between users. Motivated by our observation and based on attentive group recommendation, we propose a user-difference attention (UDA) model that explicitly simulates the comparisons between group members using relational attention, which is different from previous single user–based models. Each user is compared with all other users under the guidance of the target item, and a multi-layer perceptron is then exploited to add nonlinear transformations . We propose several user relational kernels (URKs) to simulate different types of relations during group decision-making. Extensive experiments were conducted on three public datasets. The results show that UDA significantly exceeds the state-of-the-art competing methods.},
  archive      = {J_ISCI},
  author       = {Shuxun Zan and Yujie Zhang and Xiangwu Meng and Pengtao Lv and Yulu Du},
  doi          = {10.1016/j.ins.2021.04.084},
  journal      = {Information Sciences},
  pages        = {401-417},
  shortjournal = {Inf. Sci.},
  title        = {UDA: A user-difference attention for group recommendation},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ROBP a robust border-peeling clustering using cauchy kernel.
<em>ISCI</em>, <em>571</em>, 375–400. (<a
href="https://doi.org/10.1016/j.ins.2021.04.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently a novel density-based clustering algorithm , namely, border-peeling (BP) clustering algorithm , is proposed to group data by iteratively identifying border points and peeling off them until separable areas of data remain. The BP clustering is able to correctly recognize the true structure of clusters and automatically detect the outliers on several test cases. However, there are some drawbacks in BP, and these may hinder its widespread application. The BP clustering might yield bad results on datasets with non-uniformly-distributed clusters. Especially, the BP clustering tends to over-partition the data with complex shape. To overcome these defects, a robust border-peeling clustering algorithm (named as ROBP) is proposed in this paper. Our method improves the BP clustering algorithm from two aspects: density influence (i.e. density estimation) and linkage criterion (i.e. association strategy). In density estimation, we use Cauchy kernel with longer tails instead of Gaussian kernel in the local scaling function, and further propose a kernel density estimator , i.e., the density estimator based on Cauchy kernel. It can calculate quickly and accurately the density influence value of each point. In association strategy, we design a linkage criterion based on the shared neighborhood information. The linkage criterion can create some links between peeled border points and their neighboring peeled border points, in order to avoid over-segmentation of the clusters. We integrate the proposed linkage criterion and the uni-directional association strategy, and further propose a bi-directional association strategy. In experiments, we compare ROBP with 7 representative density-based clustering (or hierarchical clustering) algorithms, including BP, DBSCAN, HDBSCAN, density peak (DP) clustering, DPC-KNN, DPC-DBFN and McDPC, on 8 synthetic datasets and 11 real-world datasets. Results show that the proposed algorithm outperforms 7 competitors in most cases. Moreover, we compare the robustness of ROBP and BP, and evaluate their running time. Experimental results indicate that ROBP is much more robust and reliable, as well as it is competitive to BP in computational efficiency.},
  archive      = {J_ISCI},
  author       = {Mingjing Du and Ru Wang and Ru Ji and Xia Wang and Yongquan Dong},
  doi          = {10.1016/j.ins.2021.04.089},
  journal      = {Information Sciences},
  pages        = {375-400},
  shortjournal = {Inf. Sci.},
  title        = {ROBP a robust border-peeling clustering using cauchy kernel},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive fuzzy penalty method for constrained
evolutionary optimization. <em>ISCI</em>, <em>571</em>, 358–374. (<a
href="https://doi.org/10.1016/j.ins.2021.03.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Penalty function is well-known for constrained evolutionary optimization . An open question in the penalty function is how to tune the penalty coefficient. This paper proposes an adaptive fuzzy penalty method to address this issue, where the coefficient is adjusted at both the individual level and the population level. At the individual level, each individual chooses a penalty coefficient from a predefined domain according to some fuzzy rules. At the population level, the domain of the crisp output is adjusted adaptively by using population information. To enhance the population diversity, an effective mutation scheme is developed. Due to its numerous merits, differential evolution is used to design a search algorithm. By the above processes, a constrained optimization evolutionary algorithm called AFPDE is proposed. Since the objective function value and the degree of constraint violation are normalized, AFPDE is less problem-dependent than the seminal work of the fuzzy penalty method. AFPDE introduces a lower penalty value in the early stage of AFPDE while a higher one in the later stage. Thus, it can escape local optima in the infeasible region. Experiments on three well-known benchmark test sets and two mechanical design problems validate that AFPDE is competitive.},
  archive      = {J_ISCI},
  author       = {Bing-Chuan Wang and Han-Xiong Li and Yun Feng and Wen-Jing Shen},
  doi          = {10.1016/j.ins.2021.03.055},
  journal      = {Information Sciences},
  pages        = {358-374},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive fuzzy penalty method for constrained evolutionary optimization},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decision-making framework for evaluating appropriate
business blockchain platforms using multiple preference formats and
VIKOR. <em>ISCI</em>, <em>571</em>, 337–357. (<a
href="https://doi.org/10.1016/j.ins.2021.04.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The blockchain is a shared, reliable, public transaction ledger that can be programmed for virtually anything valuable. Blockchains in terms of permissions and transactions with private ledgers are relatively new. The goal of this study is to present a decision-making process to guide organizations in the evaluation of blockchains as an enterprise platform service. Enterprise platforms can be selected by decision makers who voice their opinions in diverse forms by considering a range of criteria. Multiple preference formats offer suitable methods for evaluating such criteria. In this study, the VIKOR (Vlsekriterijumska Optimizacija I Kompromisno Resenje) technique is employed for evaluating the alternatives and solving the selection problem. It contributes to the blockchain literature by combining multiple preference formats with VIKOR for the first time for the blockchain platform selection problem. The findings suggest that the proposed evaluation framework is powerful for selecting the most suitable enterprise blockchain platform among alternatives.},
  archive      = {J_ISCI},
  author       = {Gülçin Büyüközkan and Gizem Tüfekçi},
  doi          = {10.1016/j.ins.2021.04.044},
  journal      = {Information Sciences},
  pages        = {337-357},
  shortjournal = {Inf. Sci.},
  title        = {A decision-making framework for evaluating appropriate business blockchain platforms using multiple preference formats and VIKOR},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting circRNA-disease associations based on autoencoder
and graph embedding. <em>ISCI</em>, <em>571</em>, 323–336. (<a
href="https://doi.org/10.1016/j.ins.2021.04.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Circular RNAs (circRNAs) are a special kind of non-coding RNA. They play important regulatory role in diseases through interactions of miRNAs associated with the diseases. Due to their insensitivity to nucleases, they are more stable than linear RNAs. It is thus imperative to integrate available information for predicting circRNA-disease associations in humans. Here, we propose a computational model to predict circRNA-disease associations based on accelerated attributed network embedding (AANE) algorithm and autoencoder(AE). First, we use AANE algorithm to extract low-dimensional features of circRNAs and diseases and then stacked autoencoder (SAE) to automatically extract in-depth features. The features obtained by AANE and the SAE are integrated and XGBoost is used as a binary classifier to get the predicted results. The proposed model has an average area under the receiver operating characteristic curve value of 0.8800 in 5-fold cross validation and 0.8988 in 10-fold cross validation. The factors that can affect the performance of the model are discussed and some common diseases are used as case studies. Results indicated that the model has great performance in predicting circRNA-disease associations.},
  archive      = {J_ISCI},
  author       = {Jing Yang and Xiujuan Lei},
  doi          = {10.1016/j.ins.2021.04.073},
  journal      = {Information Sciences},
  pages        = {323-336},
  shortjournal = {Inf. Sci.},
  title        = {Predicting circRNA-disease associations based on autoencoder and graph embedding},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Risk-based decision framework based on r-numbers and
best-worst method and its application to research and development
project selection. <em>ISCI</em>, <em>571</em>, 303–322. (<a
href="https://doi.org/10.1016/j.ins.2021.04.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Presently, fierce market competition has forced companies to invest in targeted research and development (R&amp;D) projects in order to appropriately allocate resources and achieve promising results. For companies to develop, it is crucial that they incorporate the uncertainty and risk factors inherent in R&amp;D project selection into the decision-making framework to obtain reliable outputs. The R-numbers methodology is an innovative model for analyzing the effects of uncertainty and risk. However, relatively few studies have incorporated R-numbers into decision-making problems, especially when the available data are in the form of pairwise comparisons. Nevertheless, the best–worst method (BWM) is a practical multi-criteria framework with pairwise relations. Thus, this study investigated a novel risk-based decision model called “R-BWM” that extended an additive BWM based on R-numbers. The proposed approach is applied to address the uncertainty and risk in the R&amp;D project selection for a medical device company. The results show the ability of the proposed R-BWM to enhance the performance of the classical BWM through capturing data deviations and providing more robust results.},
  archive      = {J_ISCI},
  author       = {Peide Liu and Baoying Zhu and Hamidreza Seiti and Li Yang},
  doi          = {10.1016/j.ins.2021.04.079},
  journal      = {Information Sciences},
  pages        = {303-322},
  shortjournal = {Inf. Sci.},
  title        = {Risk-based decision framework based on R-numbers and best-worst method and its application to research and development project selection},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On lagrangian l2-norm pinball twin bounded support vector
machine via unconstrained convex minimization. <em>ISCI</em>,
<em>571</em>, 279–302. (<a
href="https://doi.org/10.1016/j.ins.2021.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the introduction of the regularization term in the formulation of the well-known twin support vector machine (TWSVM) for classification, twin bounded support vector machine (TBSVM) method was proposed recently as an improved version by implementing the structural risk minimization principle. However, TBSVM employs hinge loss function and it is sensitive to noise and unstable to re-sampling. Since the pinball loss function related to quantile distance enjoys noise insensitivity property, a novel TBSVM method with squared pinball loss function for classification is proposed. The noise insensitivity and scatter minimization properties are discussed. Our formulation is further simplified as a pair of unconstrained strongly convex minimization problems in the dual space free of matrix inversion terms and having only m variables where m is the number of training examples. As opposed to TWSVM and TBSVM wherein approximate kernel generated surfaces are constructed, kernel trick is applied directly in our formulation and thereby elegant formulation as in the classical support vector machine (SVM) is achieved. Numerical experiments performed on a synthetic and thirteen benchmark datasets with noise where better or comparable generalization performance with faster learning speed by the proposed method confirms its suitability and applicability to problems of interest.},
  archive      = {J_ISCI},
  author       = {Subhash Chandra Prasad and S. Balasundaram},
  doi          = {10.1016/j.ins.2021.04.031},
  journal      = {Information Sciences},
  pages        = {279-302},
  shortjournal = {Inf. Sci.},
  title        = {On lagrangian l2-norm pinball twin bounded support vector machine via unconstrained convex minimization},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Separation and recovery markov boundary discovery and its
application in EEG-based emotion recognition. <em>ISCI</em>,
<em>571</em>, 262–278. (<a
href="https://doi.org/10.1016/j.ins.2021.04.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a Bayesian network (BN), the Markov boundary (MB) presents the local causal structure around a target. Due to the interpretability and robustness, it has been widely applied to feature selection and BN structure learning . However, existing MB discovery algorithms might fail to identify some true positives , leading to poor performance in real-world applications. To tackle this issue, we introduce a two-phase-discovery strategy to search more true positives . Based on this strategy, we propose a more accurate and data-efficient algorithm, separation and recovery MB discovery algorithm (SRMB). SRMB first discovers an incomplete parent–child set and spouse set via an MB separation process, and then retrieves the ignored true positives via an MB recovery process, which further exploits a symmetry test to improve accuracy in unfaithful cases. Experiments on standard BN and real-world data sets demonstrate the effectiveness and superiority of SRMB in terms of MB discovery, BN structure learning , and feature selection. To demonstrate the superiority of SRMB in data with distribution shift, we further apply SRMB to EEG-based emotion recognition tasks, where distribution shift exists in multiple unstable sessions. We prove that the most predictive features are from Gamma/Beta frequency bands and are distributed at the lateral temporal area.},
  archive      = {J_ISCI},
  author       = {Xingyu Wu and Bingbing Jiang and Kui Yu and Huanhuan Chen},
  doi          = {10.1016/j.ins.2021.04.071},
  journal      = {Information Sciences},
  pages        = {262-278},
  shortjournal = {Inf. Sci.},
  title        = {Separation and recovery markov boundary discovery and its application in EEG-based emotion recognition},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based output reachable set synthesis for periodic
piecewise time-varying systems. <em>ISCI</em>, <em>571</em>, 246–261.
(<a href="https://doi.org/10.1016/j.ins.2021.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the output reachable set synthesis problem for periodic piecewise time-varying systems has been addressed for the first time. Generalized periodic time-varying conditions of the closed-loop system to guarantee the system output bounded by a collection of finite ellipsoids are developed. The decoupling of time-varying observer and controller gains is achieved by a technical lemma . Moreover, by using time-varying matrix functions in multiple linear-interpolative forms and the relaxed quadratic matrix polynomial definiteness results, sufficient condition is developed to determine the periodic time-varying observer and controller with reduced conservatism. A tractable iterative algorithm is proposed to obtain the periodic time-varying observer and controller gains . A numerical example is presented to illustrate the validity of proposed methods.},
  archive      = {J_ISCI},
  author       = {Chenchen Fan and James Lam and Xiaochen Xie and Xiaoqi Song},
  doi          = {10.1016/j.ins.2021.03.031},
  journal      = {Information Sciences},
  pages        = {246-261},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based output reachable set synthesis for periodic piecewise time-varying systems},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast diagonal distance metric learning approach for
large-scale datasets. <em>ISCI</em>, <em>571</em>, 225–245. (<a
href="https://doi.org/10.1016/j.ins.2021.04.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning (DML) aims to learn distance metrics that reflect the interactions between features and labels. Due to the high computational complexity, existing DML models are unsuitable for large-scale datasets. This study proposes a DML approach for large-scale problems by reducing the number of variables, utilizing sparse structures of the optimization problems, and taking advantage of large-scale computation platforms. The proposed approach treats DML as a linear space transformation problem and suggests that a full DML matrix can be approximated by a diagonal matrix in many cases. We solve the diagonal DML problem along with its ℓ 1 ℓ1 and ℓ 2 ℓ2 regularizations via linear and quadratic programming. To facilitate large-scale learning problems, we design a MapReduce framework to build triplets, which are encapsulations of triple data points used for the optimization problem, and develop a weighting mechanism for triplets according to their contributions to the whole distance distortion. Experiments show that the proposed approach is fast in large-scale DML applications with comparable accuracy to much more time-consuming full-matrix models. Since the approach is implemented with the Scala language based on the Spark platform, it can be used directly by productive Java applications, which makes it highly practical for large-scale datasets.},
  archive      = {J_ISCI},
  author       = {Tie Li and Gang Kou and Yi Peng and Philip S. Yu},
  doi          = {10.1016/j.ins.2021.04.077},
  journal      = {Information Sciences},
  pages        = {225-245},
  shortjournal = {Inf. Sci.},
  title        = {A fast diagonal distance metric learning approach for large-scale datasets},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subtraction and division operations on intuitionistic fuzzy
sets derived from the hamming distance. <em>ISCI</em>, <em>571</em>,
206–224. (<a href="https://doi.org/10.1016/j.ins.2021.04.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intuitionistic fuzzy values, each characterized by a membership degree and a nonmembership degree, are the basic components of intuitionistic fuzzy sets. Arithmetic operations on intuitionistic fuzzy values/sets are of importance in practical problem solving. In this paper, the subtraction and division operations over intuitionistic fuzzy values/sets are derived from the Hamming distance between them by the optimization method. Compared with the existing operations, the developed operations are complete, that is, any two intuitionistic fuzzy values/sets can be performed by these two operations. Then, fundamental properties of the modified arithmetic operations are extensively investigated for intuitionistic fuzzy values/sets. Finally, the continuity and the derivative operation of intuitionistic fuzzy functions are introduced based on the proposed operations, which provides a novel basis for the intuitionistic fuzzy differential calculus .},
  archive      = {J_ISCI},
  author       = {Wen Sheng Du},
  doi          = {10.1016/j.ins.2021.04.068},
  journal      = {Information Sciences},
  pages        = {206-224},
  shortjournal = {Inf. Sci.},
  title        = {Subtraction and division operations on intuitionistic fuzzy sets derived from the hamming distance},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large-scale water quality prediction with integrated deep
neural network. <em>ISCI</em>, <em>571</em>, 191–205. (<a
href="https://doi.org/10.1016/j.ins.2021.04.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water environment time series prediction is important to efficient water resource management. Traditional water quality prediction is mainly based on linear models. However, owing to complex conditions of the water environment, there is a lot of noise in the water quality time series, which will seriously affect the accuracy of water quality prediction. In addition, linear models are difficult to deal with the nonlinear relations of data of time series. To address this challenge, this work proposes a hybrid model based on a long short-term memory-based encoder-decoder neural network and a Savitzky-Golay filter. Among them, the filter of Savitzky-Golay can eliminate the potential noise in the time series of water quality, and the long short-term memory can investigate nonlinear characteristics in a complicated water environment. In this way, an integrated model is proposed and effectively obtains statistical characteristics. Realistic data-based experiments prove that its prediction performance is better than its several state-of-the-art peers.},
  archive      = {J_ISCI},
  author       = {Jing Bi and Yongze Lin and Quanxi Dong and Haitao Yuan and MengChu Zhou},
  doi          = {10.1016/j.ins.2021.04.057},
  journal      = {Information Sciences},
  pages        = {191-205},
  shortjournal = {Inf. Sci.},
  title        = {Large-scale water quality prediction with integrated deep neural network},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic multi-objective optimization algorithm based
decomposition and preference. <em>ISCI</em>, <em>571</em>, 175–190. (<a
href="https://doi.org/10.1016/j.ins.2021.04.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing dynamic multi-objective evolutionary algorithms (DMOEAs) are effective, which focuses on searching for the approximation of Pareto-optimal front (POF) with well-distributed in handling dynamic multi-objective optimization problems (DMOPs). Nevertheless, in real-world scenarios, the decision maker (DM) may be only interested in a portion of the corresponding POF (i.e., the region of interest) for different instances, rather than the whole POF. Consequently, a novel DMOEA based decomposition and preference (DACP) is proposed, which incorporates the preference of DM into the dynamic search process and tracks a subset of Pareto-optimal set (POS) approximation with respect to the region of interest (ROI). Due to the presence of dynamics, the ROI, which is defined in which DM gives both the preference point and the neighborhood size, may be changing with time-varying DMOPs. Consequently, our algorithm moves the well-distributed reference points, which are located in the neighborhood range, to around the preference point to lead the evolution of the whole population. When a change occurs, a novel strategy is performed for responding to the current change. Particularly, the population will be reinitialized according to a promising direction obtained by letting a few solutions evolve independently for a short time. Comprehensive experiments show that this approach is very competitivecompared with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yaru Hu and Jinhua Zheng and Juan Zou and Shouyong Jiang and Shengxiang Yang},
  doi          = {10.1016/j.ins.2021.04.055},
  journal      = {Information Sciences},
  pages        = {175-190},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic multi-objective optimization algorithm based decomposition and preference},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse and robust estimation with ridge minimax concave
penalty. <em>ISCI</em>, <em>571</em>, 154–174. (<a
href="https://doi.org/10.1016/j.ins.2021.04.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important procedure that is used in data mining to extract valuable information from large quantities of data. Existing penalization methods use a single penalty function to select important features. However, these methods do not yield sufficiently accurate predictions and selection outcomes. Therefore, construction of a concise and efficient prediction model would be beneficial. In this study, we propose a novel penalty function using a ridge and minimax concave penalty to overcome the limitations of individual penalty functions. Furthermore, we introduce a robust penalized feature selection method with Huber loss function, which is implemented by a local approximation algorithm. The theoretical properties of the algorithm have been described. Simulated and real-world data analyses are used to demonstrate the efficacy of the proposed method.},
  archive      = {J_ISCI},
  author       = {He Jiang and Weihua Zheng and Yao Dong},
  doi          = {10.1016/j.ins.2021.04.047},
  journal      = {Information Sciences},
  pages        = {154-174},
  shortjournal = {Inf. Sci.},
  title        = {Sparse and robust estimation with ridge minimax concave penalty},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Niche-based and angle-based selection strategies for
many-objective evolutionary optimization. <em>ISCI</em>, <em>571</em>,
133–153. (<a href="https://doi.org/10.1016/j.ins.2021.04.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is well known that balancing population diversity and convergence plays a crucial role in evolutionary many-objective optimization. However, most existing multiobjective evolutionary algorithms encounter difficulties in solving many-objective optimization problems . Thus, this paper suggests niche-based and angle-based selection strategies for many-objective evolutionary optimization. In the proposed algorithm, two strategies are included: niche-based density estimation strategy and angle-based selection strategy. Both strategies are employed in the environmental selection to eliminate the worst individual from the population in an iterative way. To be specific, the former estimates the diversity of each individual and finds the most crowded area in the population. The latter removes individuals with weak convergence in the same niche. Experimental studies on several well-known benchmark problems show that the proposed algorithm is competitive compared with six state-of-the-art many-objective algorithms. Moreover, the proposed algorithm has also been verified to be scalable to deal with constrained many-objective optimization problems.},
  archive      = {J_ISCI},
  author       = {Jinlong Zhou and Juan Zou and Shengxiang Yang and Jinhua Zheng and Dunwei Gong and Tingrui Pei},
  doi          = {10.1016/j.ins.2021.04.050},
  journal      = {Information Sciences},
  pages        = {133-153},
  shortjournal = {Inf. Sci.},
  title        = {Niche-based and angle-based selection strategies for many-objective evolutionary optimization},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving adversarial attacks on deep neural networks via
constricted gradient-based perturbations. <em>ISCI</em>, <em>571</em>,
104–132. (<a href="https://doi.org/10.1016/j.ins.2021.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the remarkable success achieved by the deep learning techniques, adversarial attacks on deep neural networks unveiled the security issues posted in specific domains. Such carefully crafted adversarial instances generated by the adversarial strategies on L p Lp norm bounds freely mislead the deep neural models on many professional tasks. Existing gradient-based adversarial attack methods fool the state-of-the-art classification systems into lapses and gain good adversarial effectiveness on vast professional missions. Nevertheless, we find that adversarial examples generated on gradient-based present massive pixel modifications on the generated adversarial examples . Moreover, the adversarial attack strategies based on stable gradient take the accumulation of the gradient into account. It introduces redundant perturbations with frequently occurring features in the generation of adversarial examples, yet the changes induced on the generated examples are easily detected and perceptible visually. Based on such situations, we propose types of adversarial attack approaches with constricted gradient-based strategy termed Constricted Iterative Fast Gradient Sign Method (CI-FGSM). It focuses on lessening the impact of accumulated information on the crafted perturbations via deducting the mount of preceding cumulative gradient-based entities. CI-FGSM requires few freely gradient-based operations on the generated inputs to reduce the accumulation of historical gradient-based objects, thus crafts natural and imperceptible adversarial perturbations added to the generated examples. We conduct the experiments on MNIST, CIFAR10, and IMAGENET ILSVRC2012(Val) to evaluate the performance of the proposed adversarial approaches in misleading the commonly-used deep neural classification networks . Compared to other gradient-based adversarial attack methods, experimental results reveal that CI-FGSM efficaciously reduces the extra modifications on pristine inputs and maintains perfect effect of adversarial attacks in fooling the classifiers with different norm constraint strategies.},
  archive      = {J_ISCI},
  author       = {Yatie Xiao and Chi-Man Pun},
  doi          = {10.1016/j.ins.2021.04.033},
  journal      = {Information Sciences},
  pages        = {104-132},
  shortjournal = {Inf. Sci.},
  title        = {Improving adversarial attacks on deep neural networks via constricted gradient-based perturbations},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RGAM: A novel network architecture for 3D point cloud
semantic segmentation in indoor scenes. <em>ISCI</em>, <em>571</em>,
87–103. (<a href="https://doi.org/10.1016/j.ins.2021.04.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional (3D) point cloud semantic segmentation is an essential part of computer vision for scene comprehension. Nevertheless, due to their loss of detail, existing networks lack the ability to recognize complex scenes. This paper proposes a novel network architecture , called the ring grouping neural network with attention module (RGAM), which presents four improvements over the existing networks. First, novel multi-scale ring grouping learning is designed to extract the multi-scale neighborhood features without overlapped sampling, allowing the network to adapt to objects of different scales. Second, neighborhood information fusion is defined as the weighted sum of multiple neighborhood features, enabling the representation of each point to be considered in different neighborhoods. Third, in the global view, a spatial attention module is introduced among the neighborhoods, allowing long-range contextual information to be exploited for 3D point cloud semantic segmentation . Finally, a channel attention module is appended to the RGAM: the correlation of each channel with key information enhances the complex scene recognition ability of the RGAM. Experimental results on the challenging S3DIS, ScanNet, and NYU-V2 datasets demonstrate that the RGAM has stronger recognition ability than the existing networks based on several state-of-the-art algorithms for 3D point cloud semantic segmentation.},
  archive      = {J_ISCI},
  author       = {Xue-Tao Chen and Ying Li and Jia-Hao Fan and Rui Wang},
  doi          = {10.1016/j.ins.2021.04.069},
  journal      = {Information Sciences},
  pages        = {87-103},
  shortjournal = {Inf. Sci.},
  title        = {RGAM: A novel network architecture for 3D point cloud semantic segmentation in indoor scenes},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RTFN: A robust temporal feature network for time series
classification. <em>ISCI</em>, <em>571</em>, 65–86. (<a
href="https://doi.org/10.1016/j.ins.2021.04.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data usually contains local and global patterns. Most of the existing feature networks focus on local features rather than the relationships among them. The latter is also essential, yet more difficult to explore because it is challenging to obtain sufficient representations using a feature network. To this end, we propose a novel robust temporal feature network (RTFN) for feature extraction in time series classification, containing a temporal feature network (TFN) and a long short-term memory (LSTM)-based attention network (LSTMaN). TFN is a residual structure with multiple convolutional layers, and functions as a local-feature extraction network to mine sufficient local features from data. LSTMaN is composed of two identical layers, where attention and LSTM networks are hybridized. This network acts as a relation extraction network to discover the intrinsic relationships among the features extracted from different data positions. In experiments, we embed the RTFN into supervised and unsupervised structures as a feature extractor and encoder, respectively. The results show that the RTFN-based structures achieve excellent supervised and unsupervised performances on a large number of UCR2018 and UEA2018 datasets.},
  archive      = {J_ISCI},
  author       = {Zhiwen Xiao and Xin Xu and Huanlai Xing and Shouxi Luo and Penglin Dai and Dawei Zhan},
  doi          = {10.1016/j.ins.2021.04.053},
  journal      = {Information Sciences},
  pages        = {65-86},
  shortjournal = {Inf. Sci.},
  title        = {RTFN: A robust temporal feature network for time series classification},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving paragraph-level question generation with extended
answer network and uncertainty-aware beam search. <em>ISCI</em>,
<em>571</em>, 50–64. (<a
href="https://doi.org/10.1016/j.ins.2021.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Question Generation (QG), which aims to generate a question given the relevant context, is essential to build conversational and question–answering systems. Existing neural question generation models suffer from the inadequate representation of the target answer and inappropriate techniques to reduce repetition. To address these issues, we propose an Extended Answer-aware Network (EAN) which is trained with Word-based Coverage Mechanism (WCM) and decoded with Uncertainty-aware Beam Search (UBS). The EAN represents the target answer by its surrounding sentence with an encoder and incorporates the extended answer to paragraph representation using gated paragraph-to-answer attention to tackle the problem of the inadequate representation of the target answer. To reduce undesirable repetition, the WCM penalizes repeatedly attending to the same words of different time-steps in the training stage. The UBS incorporates an uncertainty score into beam search to alleviate text degeneration and reduce repeated copying words of the paragraph. Experiments on two benchmark datasets demonstrate the effectiveness of our methods of paragraph-level question generation. Specifically, our model has achieved 4.2\% and 27.2\% improvement over BLEU-4 compared to the best paragraph-level QG baseline in SQuAD and NewsQA datasets respectively.},
  archive      = {J_ISCI},
  author       = {Hongwei Zeng and Zhuo Zhi and Jun Liu and Bifan Wei},
  doi          = {10.1016/j.ins.2021.04.026},
  journal      = {Information Sciences},
  pages        = {50-64},
  shortjournal = {Inf. Sci.},
  title        = {Improving paragraph-level question generation with extended answer network and uncertainty-aware beam search},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy graph clustering. <em>ISCI</em>, <em>571</em>, 38–49.
(<a href="https://doi.org/10.1016/j.ins.2021.04.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral clustering is a group of graph-based clustering methods in which the columns of the scaled cluster indicator matrix can be obtained by stacking the eigenvectors of the Laplacian matrix corresponding to the top c smallest eigenvalues ( c is the number of clusters). This leads to the possible existence of negative values in the scaled indicator matrix and therefore a post-processing step such as K means clustering or spectral rotation is necessary to get the discrete cluster assignments. Moreover, such obtained results lack of the interpretability for data points in the boundary area of multiple clusters. To simultaneously address both limitations, we propose a two-stage clustering model, termed FGC (fuzzy graph clustering) in this paper. In FGC, we first construct a doubly stochastic graph affinity matrix which is then approximated by the scaled product of the fuzzy cluster indicator matrices. The newly designed fuzzy cluster indicator matrix has two desirable properties of non-negativity and row normalization, which can bring us two benefits. On one hand, we can directly get the cluster assignment of a certain data point by checking the largest value in the corresponding row of the fuzzy cluster indicator matrix; and on the other hand, we can obtain the membership of each data point to different clusters. An iterative method under the alternative optimization framework is proposed to solve the objective function of FGC. We conduct data clustering experiments on both synthetic and benchmark data sets and the results demonstrate the effectiveness of our proposed FGC model.},
  archive      = {J_ISCI},
  author       = {Yong Peng and Xin Zhu and Feiping Nie and Wanzeng Kong and Yuan Ge},
  doi          = {10.1016/j.ins.2021.04.058},
  journal      = {Information Sciences},
  pages        = {38-49},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy graph clustering},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved stability analysis of takagi-sugeno fuzzy systems
with time-varying delays via an extended delay-dependent reciprocally
convex inequality. <em>ISCI</em>, <em>571</em>, 24–37. (<a
href="https://doi.org/10.1016/j.ins.2021.04.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of stability analysis of Takagi-Sugeno(T-S) fuzzy systems with time-varying delays is investigated in this paper. First, an extended delay-dependent reciprocally convex inequality containing some existing reciprocally convex inequalities is given. Second, a suitable augmented Lyapunov-Krasovskii functional (LKF) is proposed by introducing some new integral vectors ∫ t - h 1 t x v dv - x ( u ) , ∫ t - h 2 t - h 1 x v dv - x ( u ) ∫t-h1txvdv-x(u),∫t-h2t-h1xvdv-x(u) , and several pairs of s -dependent integral vectors. Third, the improved stability criteria for T-S fuzzy systems are derived. Finally, several numerical examples are given to illustrate advantages and effectiveness of the proposed criteria by comparing the maximum delay bounds.},
  archive      = {J_ISCI},
  author       = {Xue-Jun Pan and Bin Yang and Jun-Jun Cao and Xu-Dong Zhao},
  doi          = {10.1016/j.ins.2021.04.043},
  journal      = {Information Sciences},
  pages        = {24-37},
  shortjournal = {Inf. Sci.},
  title        = {Improved stability analysis of takagi-sugeno fuzzy systems with time-varying delays via an extended delay-dependent reciprocally convex inequality},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The design of dynamic ensemble selection strategy for the
error-correcting output codes family. <em>ISCI</em>, <em>571</em>, 1–23.
(<a href="https://doi.org/10.1016/j.ins.2021.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error-Correcting Output Codes (ECOC) is widely deployed to tackle the multiclass classification problem by reducing the original multi-class problem to several binary sub-problems. This study attempts to design a dynamic ensemble selection strategy to promote the performance of ECOC algorithms. Concretely, each column in a coding matrix is matched with a set of feature subsets generated by various feature selection methods. In the decoding process, a novel criterion based on the data complexity theory is proposed to pick up an optimal feature subset from the candidate subsets, so as to better distinguish unknown samples. As this strategy can be embedded in all types of ECOC algorithms, seven classical ECOC algorithms are deployed to verify the effectiveness of our strategy. Experiments are carried out on a set of UCI data sets, and the results confirm that despite different working principle, the proposed strategy can further improve the performance of various ECOC algorithms in most cases. Our python source code is available at: https://github.com/MLDMXM2017/ECOC_DES .},
  archive      = {J_ISCI},
  author       = {Jia-Yu Zou and Meng-Xin Sun and Kun-Hong Liu and Qing-Qiang Wu},
  doi          = {10.1016/j.ins.2021.04.038},
  journal      = {Information Sciences},
  pages        = {1-23},
  shortjournal = {Inf. Sci.},
  title        = {The design of dynamic ensemble selection strategy for the error-correcting output codes family},
  volume       = {571},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrections to “blind quality assessment for image
superresolution using deep two-stream convolutional networks.”
<em>ISCI</em>, <em>570</em>, 848. (<a
href="https://doi.org/10.1016/j.ins.2020.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Wei Zhou and Qiuping Jiang and Yuwang Wang and Zhibo Chen and Weiping Li},
  doi          = {10.1016/j.ins.2020.06.002},
  journal      = {Information Sciences},
  pages        = {848},
  shortjournal = {Inf. Sci.},
  title        = {Corrections to “Blind quality assessment for image superresolution using deep two-stream convolutional networks”},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SwFLOW: A large-scale distributed framework for deep
learning on sunway TaihuLight supercomputer. <em>ISCI</em>,
<em>570</em>, 831–847. (<a
href="https://doi.org/10.1016/j.ins.2020.12.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning technology is widely used in many modern fields and a number of models and software frameworks have been proposed. However, it is still very difficult to process deep learning tasks efficiently on traditional high performance computing (HPC) systems. In this paper, we propose swFLOW: a large-scale distributed framework for deep learning on Sunway TaihuLight. Based on the performance analysis results of convolutional neural network (CNN), we optimize the convolutional layer , and get 10.42× speedup compared to the original version. As for distributed training, we use elastic averaging stochastic gradient descent (EASGD) algorithm to reduce communication. On 512 processes, we get a parallel efficiency of 81.01\% with communication period τ = 8 τ=8 . Particularly, a decentralized implementation of distributed swFLOW system is presented to alleviate bottleneck of the central server. By using distributed swFLOW system, we can scale the batch size up to 4096 among 1024 concurrent processes for cancerous region detection algorithm . The successful application on swFLOW reveals the great opportunity for joint combination of deep learning and HPC system.},
  archive      = {J_ISCI},
  author       = {Mingfan Li and Han Lin and Junshi Chen and Jose Monsalve Diaz and Qian Xiao and Rongfen Lin and Fei Wang and Guang R. Gao and Hong An},
  doi          = {10.1016/j.ins.2020.12.079},
  journal      = {Information Sciences},
  pages        = {831-847},
  shortjournal = {Inf. Sci.},
  title        = {SwFLOW: A large-scale distributed framework for deep learning on sunway TaihuLight supercomputer},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based proportional derivative fuzzy control for
singular takagi-sugeno fuzzy systems. <em>ISCI</em>, <em>570</em>,
815–830. (<a href="https://doi.org/10.1016/j.ins.2021.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the issue of stability analysis and controller synthesis for nonlinear singular systems . Via applying a fuzzy modeling approach, the nonlinear singular system is expressed by a Takagi-Sugeno (T-S) fuzzy model composed of several linear subsystems. Furthermore, the parallel distributed compensation fuzzy controller is designed such that the controlled singular system is stable. Employing Proportional Derivative (PD) control method , the regularity and impulse-free property of the singular systems can be held. However, the PD control method is challengable because the state signals of singular systems are not always measurable. Therefore, a novel fuzzy observer is designed to ensure the existence of estimated states. For the observer-based PD control issue, some sufficient stability conditions are derived for T-S fuzzy singular systems. Moreover, the control gains and observer gains can be conveniently calculated using the Linear Matrix Inequality (LMI) calculation. Finally, two numerical examples are presented to verify the availability and applicability of the proposed design method.},
  archive      = {J_ISCI},
  author       = {Cheung-Chieh Ku and Wen-Jer Chang and Ming-Hsuan Tsai and Yi-Chen Lee},
  doi          = {10.1016/j.ins.2021.01.023},
  journal      = {Information Sciences},
  pages        = {815-830},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based proportional derivative fuzzy control for singular takagi-sugeno fuzzy systems},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep matrix factorization with knowledge transfer for
lifelong clustering and semi-supervised clustering. <em>ISCI</em>,
<em>570</em>, 795–814. (<a
href="https://doi.org/10.1016/j.ins.2021.04.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering analysis aims to group unlabeled data in an unsupervised learning manner. However, most existing methods are tailored for single-task data and do not work for a sequence of tasks. In this paper, we propose a Deep Matrix factorization method with Knowledge transfer (DMK) to address clustering problem in a lifelong setting, where DMK approaches a sequence of tasks; after each task is learned, its knowledge will be retained and later used to help future clustering task . To this end, we delve into deep matrix factorization and graph co-clustering, where (1) the former learns a basis feature library across all arrived tasks and a specific representation for each target task to deal with lifelong clustering and (2) the latter builds a consistent feature embedding library to transfer knowledge between each pair of tasks. An iterative optimization algorithm is then proposed to alternatively update the two libraries. In addition, we extend our DMK into a semi-supervised version and propose a Semi-supervised Deep Matrix factorization method with Knowledge transfer (SDMK) by exploiting a few of prior label information for lifelong semi-supervised clustering. Experimental results using four datasets with sequential tasks demonstrate that the proposed methods outperform state-of-the-art baseline methods markedly.},
  archive      = {J_ISCI},
  author       = {Yiling Zhang and Hao Wang and Yan Yang and Wei Zhou and Tianrui Li and Xiaocao Ouyang and Hongyang Chen},
  doi          = {10.1016/j.ins.2021.04.067},
  journal      = {Information Sciences},
  pages        = {795-814},
  shortjournal = {Inf. Sci.},
  title        = {Deep matrix factorization with knowledge transfer for lifelong clustering and semi-supervised clustering},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PGRA: Projected graph relation-feature attention network for
heterogeneous information network embedding. <em>ISCI</em>,
<em>570</em>, 769–794. (<a
href="https://doi.org/10.1016/j.ins.2021.04.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) have achieved superior performance and gained significant interest in various domains. However, most of the existing GNNs are considered for homogeneous graphs, whereas real-world systems are usually modeled as heterogeneous graphs or heterogeneous information networks (HINs). Designing a GNN to fully capture the rich semantic information of HINs is significantly challenging owing to the heterogeneity and incompatibility of relations in HINs. To address these issues while utilizing the power of GNNs, we propose a novel unsupervised embedding approach, named Projected Graph Relation-Feature Attention Network (PGRA). PGRA is based on three mechanisms: 1) specific-relation projection that projects the representation vector of each node to a relation-specific space, 2) aggregation with a relation-feature attention network that learns salient neighbors in the aggregation by considering the features of the nodes and compatibility between the connected and target relations, 3) an elegantly designed loss function that captures both the first- and second-order proximities between nodes. The results of extensive experiments on seven real-world datasets illustrate that PGRA outperforms the state-of-the-art methods by a large margin.},
  archive      = {J_ISCI},
  author       = {Nuttapong Chairatanakul and Xin Liu and Tsuyoshi Murata},
  doi          = {10.1016/j.ins.2021.04.070},
  journal      = {Information Sciences},
  pages        = {769-794},
  shortjournal = {Inf. Sci.},
  title        = {PGRA: Projected graph relation-feature attention network for heterogeneous information network embedding},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Echo state network with a global reversible autoencoder for
time series classification. <em>ISCI</em>, <em>570</em>, 744–768. (<a
href="https://doi.org/10.1016/j.ins.2021.04.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An echo state network (z) can provide an efficient dynamic solution for predicting time series problems. However, in most cases, ESN models are applied for predictions rather than classifications. The applications of ESN in time series classification (TSC) problems have yet to be fully studied. Moreover, the conventional randomly generated ESN is unlikely to be optimal because of the randomly generated input and reservoir weights, which are not always guaranteed to be optimal. Randomly generating all layer weights is improper, because a purely random layer might destroy the useful features. To overcome this disadvantage, this study provides a new input weight establishment framework of ESN based on autoencoder (AE) theory for TSC tasks. A global reversible AE (GRAE) algorithm is proposed to reestablish the random initialization input weights of the ESN. In existing ESN-AEs, the output weights obtained in the encoding process are directly reused as the initial input weights. By contrast, in GRAE, the reservoir layer with a reversible activation function is calculated by pulling the decoding layer output back and injecting it into the reservoir layer. Thus, feature learning is enriched by additional information, which results in improved performance. The current weights of the encoding layer are iteratively replaced by the decoding layer to ensure that the outputs of the GRAE are remarkably correlated with the input data. Visualization analyses and experiments of the input weights on a massive set of UCR time series datasets indicate that the proposed GRAE method can considerably improve the original two-layer ESN-based classifiers and the proposed GRAE-ESN classifier yields better performance compared with traditional state-of-the-art TSC classifiers. Furthermore, the proposed method can provide comparable performance and considerably faster training speed compared with three deep learning classifiers.},
  archive      = {J_ISCI},
  author       = {Heshan Wang and Q.M. Jonathan Wu and Dongshu Wang and Jianbin Xin and Yimin Yang and Kunjie Yu},
  doi          = {10.1016/j.ins.2021.04.074},
  journal      = {Information Sciences},
  pages        = {744-768},
  shortjournal = {Inf. Sci.},
  title        = {Echo state network with a global reversible autoencoder for time series classification},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of key figures in social networks by combining
harmonic modularity with community structure-regulated network
embedding. <em>ISCI</em>, <em>570</em>, 722–743. (<a
href="https://doi.org/10.1016/j.ins.2021.04.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are three types of social network users: ordinary users, opinion leaders, and structural hole (SH) spanners. Opinion leaders and SH spanners are key circulators of information. SH spanners are the key figures of cross-community information propagation. By contrast, opinion leaders are more important to intra-community information dissemination . Moreover, according to the two-step flow theory, users prefer to connect with opinion leaders rather than ordinary users when connecting with users in other communities. Therefore, the detection of key figures should consider both the community structure and the relationship between opinion leaders and SH spanners. In this paper, we propose three algorithms. The first is an improved harmonic modularity algorithm based on Q-modularity gain (Q-HAM), which can infer community partitions and rank SH nodes. The second proposal is a model of social rank and community structure-regulated network embedding (RaComNE), which is based on the two-step flow theory and relies on the SH spanner ranks and community assignments to guide network representation learning and social rank inference in a supervised manner. Finally, we propose a key figure detection algorithm (KFDA), which integrates both Q-HAM and RaComNE into a single framework by adding a fine-tuning step. In addition to its usual outputs, KFDA outputs community assignments and network embeddings, which are convenient for visualization. Extensive experimentation demonstrated that Q-HAM and RaComNE improved key figure detection relative to state-of-the-art methods. Additionally, the KFDA experiments showed that integrating the two-step theory into the framework significantly improves both SH spanners and opinion leaders detection.},
  archive      = {J_ISCI},
  author       = {YaJun Du and Qiaoyu Zhou and JiaXing Luo and XianYong Li and JinRong Hu},
  doi          = {10.1016/j.ins.2021.04.081},
  journal      = {Information Sciences},
  pages        = {722-743},
  shortjournal = {Inf. Sci.},
  title        = {Detection of key figures in social networks by combining harmonic modularity with community structure-regulated network embedding},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning with reference system to handle
constraints for energy-efficient train control. <em>ISCI</em>,
<em>570</em>, 708–721. (<a
href="https://doi.org/10.1016/j.ins.2021.04.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Train energy-efficient control involves complicated optimization processes subject to constraints such as speed, time, position and comfort requirements. Conventional optimization techniques are not apt at accumulating numerous solution instances into decision intelligence by learning for consecutively confronted new problems. Deep reinforcement learning (DRL), which can directly output control decisions based on current states, has shown great potentials for next-generation intelligent control . However, if the DRL is directly applied to energy-efficient train control, the received results are almost unsatisfactory. The reason lies in that the agent may get into confusion about how to trade off those constraints, and spend great computational time performing a large number of meaningless explorations. This article attempts to propose an approach of DRL with a reference system (DRL-RS) for proactive constraint handling, where the reference system deals with checking and correcting the agent’s learning progresses to avoid stepping farther and farther onto the erroneous road. The proposed approach is evaluated by the numerical experiments on train control in metro lines. The experimental results demonstrate that the DRL-RS can achieve faster learning convergence, compared with the directly applied DRL. Furthermore, it is possible to reduce more energy consumption than the commonly used genetic algorithm .},
  archive      = {J_ISCI},
  author       = {Mengying Shang and Yonghua Zhou and Hamido Fujita},
  doi          = {10.1016/j.ins.2021.04.088},
  journal      = {Information Sciences},
  pages        = {708-721},
  shortjournal = {Inf. Sci.},
  title        = {Deep reinforcement learning with reference system to handle constraints for energy-efficient train control},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Grouping memetic search for the colored traveling salesmen
problem. <em>ISCI</em>, <em>570</em>, 689–707. (<a
href="https://doi.org/10.1016/j.ins.2021.04.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The colored traveling salesmen problem is a node routing problem with multiple salesmen, where the cities are divided into m exclusive city sets and one shared city set. The objective is to minimize the total traveling distance of m Hamiltonian circuits (routes) under the following constraints: each exclusive city is to be visited by the corresponding salesman, while each shared city can be visited by any salesman. In this work, we present the first grouping memetic algorithm for solving this challenging problem. The algorithm includes three main components: (i) a greedy randomized heuristic for population initialization; (ii) a dedicated local search procedure for local optima exploration; (iii) a backbone-based crossover operator for solution recombination. We show computational results on three sets of 65 popular benchmark instances to demonstrate the competitiveness of our algorithm. We especially report improved upper bounds for 38 instances (for more than 58\% cases). We also present first computational results with the general CPLEX solver, including 10 proven optimal solutions. Finally, we shed lights on the impacts of the key components of the algorithm. We make the code of the algorithm publicly available.},
  archive      = {J_ISCI},
  author       = {Pengfei He and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1016/j.ins.2021.04.090},
  journal      = {Information Sciences},
  pages        = {689-707},
  shortjournal = {Inf. Sci.},
  title        = {Grouping memetic search for the colored traveling salesmen problem},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-criteria group decision-making for portfolio
allocation with consensus reaching process under interval type-2 fuzzy
environment. <em>ISCI</em>, <em>570</em>, 668–688. (<a
href="https://doi.org/10.1016/j.ins.2021.04.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The portfolio allocation problem is a hot topic in modern economics and management science. It involves many immeasurable criteria and uncertainties. Given the advantage of interval type-2 fuzzy sets (IT2FSs) in modeling complexities and uncertainties, this study provides an integrated methodology to deal with portfolio allocation problem based on the multiple criteria group decision-making (MCGDM) method considering the consensus reaching process in an interval type-2 fuzzy environment. First, some new information measures for IT2FSs include the weighted mean, and the weighted semi-absolute deviation measures are defined. They are used to describe the return and risk of the portfolio allocation, respectively. Second, a two-stage MCGDM framework is constructed for portfolio allocation: one is to achieve the group consensus, and the other is to obtain the optimal portfolio ratios. Finally, an example on calculating the optimal portfolio ratios for four newly listed stocks in China is offered to elaborate on the performance of our approach. Sensitivity and comparative analyses are also given to show the effectiveness and advantages of the proposed method.},
  archive      = {J_ISCI},
  author       = {Qun Wu and Xinwang Liu and Jindong Qin and Ligang Zhou},
  doi          = {10.1016/j.ins.2021.04.096},
  journal      = {Information Sciences},
  pages        = {668-688},
  shortjournal = {Inf. Sci.},
  title        = {Multi-criteria group decision-making for portfolio allocation with consensus reaching process under interval type-2 fuzzy environment},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generalized cost-sensitive model for decision-theoretic
three-way approximation of fuzzy sets. <em>ISCI</em>, <em>570</em>,
638–667. (<a href="https://doi.org/10.1016/j.ins.2021.04.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-theoretic three-way approximation of a fuzzy set F exploits a three-element set { 0 , 0.5 , 1 } {0,0.5,1} in order to approximate F . By relying on an optimum pair of thresholds ( α , β ) (α,β) , it changes elements’ membership grade μ F ( x ) μF(x) to 0 , 0.5 0,0.5 and 1 if μ F ( x ) μF(x)&amp;lt;α,α⩽μF(x)⩽β and μ F ( x ) &gt; β μF(x)&amp;gt;β respectively. A general three-element system, { n , m , p } , 0 ⩽ n {n,m,p},0⩽n&amp;lt;m&amp;lt;p≤1 , has been proposed in the literature. However, the main issue is to determine appropriate n ≠ 0 , m ≠ 0.5 n≠0,m≠0.5 and p ≠ 1 p≠1 . A recent advancement has determined m ( 0 m(0&amp;lt;m&amp;lt;1) . However, n = 0 n=0 and p = 1 p=1 are still imposed by the model. This restriction on the values of n and p lacks general adaptation for different types of membership distribution. In this paper, a novel way of determining appropriate values of n , m n,m , and p is given without the aforesaid restriction. We consider an alternative { n , m , p } {n,m,p} formula for computing the optimum pair ( α , β ) (α,β) in cost-sensitive three-way approximation context. We use synthetic fuzzy sets and some datasets from UCI Machine Learning repository to demonstrate the suitability of the { n , m , p } {n,m,p} system in minimizing approximation error and producing well-guided approximation regions.},
  archive      = {J_ISCI},
  author       = {Musa Adeku Ibrahim and Tamunokuro Opubo William-West},
  doi          = {10.1016/j.ins.2021.04.098},
  journal      = {Information Sciences},
  pages        = {638-667},
  shortjournal = {Inf. Sci.},
  title        = {A generalized cost-sensitive model for decision-theoretic three-way approximation of fuzzy sets},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). An effective and efficient fuzzy approach for managing
natural noise in recommender systems. <em>ISCI</em>, <em>570</em>,
623–637. (<a href="https://doi.org/10.1016/j.ins.2021.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-quality recommender system (RS) can effectively alleviate information overload by producing recommendations. The quality of the recommender system not only depends on the recommendation algorithm but also on the quality of collected data. Since users are often affected by environmental and accidental factors during the rating process, natural noise is probably brought into the data of RS by non-malicious users, which will lead to deviations in prediction results. In this paper, we propose a scheme based on fuzzy theory to manage the natural noise in RS. We first classify the ratings into three fuzzy categories with variable boundaries. Then, the fuzzy profiles of users and items are built to detect the natural noise in ratings. Finally, once the noisy ratings are detected, we replace them with the rating threshold values according to the Maximum membership principle. The proposed scheme is tested in two benchmark datasets and experimental results verify that the scheme can significantly improve the recommendation quality and has higher efficiency than the schemes based on re-predication.},
  archive      = {J_ISCI},
  author       = {Pengyu Wang and Yong Wang and Leo Yu Zhang and Hong Zhu},
  doi          = {10.1016/j.ins.2021.05.002},
  journal      = {Information Sciences},
  pages        = {623-637},
  shortjournal = {Inf. Sci.},
  title        = {An effective and efficient fuzzy approach for managing natural noise in recommender systems},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Multi-granularity distance measure for interval-valued
intuitionistic fuzzy concepts. <em>ISCI</em>, <em>570</em>, 599–622. (<a
href="https://doi.org/10.1016/j.ins.2021.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interval-valued intuitionistic fuzzy (IvIF) set, a combination of intuitionistic fuzzy sets and interval-valued sets, has been widely employed for multi-attribute decision-making and group decision-making. However, two urgent problems remain to be solved. The first is to determine the coarseness/fineness relation in the IvIF granular space, and the other is to determine the difference between two IvIF granular structures with the same uncertainty. In this paper, a pair of IvIF granular structure distances is proposed to address the aforementioned issues. Then, a more generalized coarseness/fineness relation is defined for the IvIF granular space. Furthermore, two complementary uncertainty measures were formulated based on the coarseness/fineness relation. Finally, we investigate the IvIF approximate granular structure of a target concept and propose a new algorithm for attribute reduction from the perspective of distance. The experiments show that our algorithm possesses a shorter reduct than the other algorithms, ensuring relatively high classification accuracy. Furthermore, a case study is presented to demonstrate the feasibility of using the proposed method to solve a large linguistic group decision-making problem.},
  archive      = {J_ISCI},
  author       = {Shuai Li and Jie Yang and Guoyin Wang and Taihua Xu},
  doi          = {10.1016/j.ins.2021.05.003},
  journal      = {Information Sciences},
  pages        = {599-622},
  shortjournal = {Inf. Sci.},
  title        = {Multi-granularity distance measure for interval-valued intuitionistic fuzzy concepts},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AT-MFCGA: An adaptive transfer-guided multifactorial
cellular genetic algorithm for evolutionary multitasking. <em>ISCI</em>,
<em>570</em>, 577–598. (<a
href="https://doi.org/10.1016/j.ins.2021.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer Optimization is an incipient research area dedicated to solving multiple optimization tasks simultaneously. Among the different approaches that can address this problem effectively, Evolutionary Multitasking resorts to concepts from Evolutionary Computation to solve multiple problems within a single search process. In this paper we introduce a novel adaptive metaheuristic algorithm to deal with Evolutionary Multitasking environments coined as Adaptive Transfer-guided Multifactorial Cellular Genetic Algorithm (AT-MFCGA). AT-MFCGA relies on cellular automata to implement mechanisms in order to exchange knowledge among the optimization problems under consideration. Furthermore, our approach is able to explain by itself the synergies among tasks that were encountered and exploited during the search, which helps us to understand interactions between related optimization tasks. A comprehensive experimental setup is designed to assess and compare the performance of AT-MFCGA to that of other renowned Evolutionary Multitasking alternatives (MFEA and MFEA-II). Experiments comprise 11 multitasking scenarios composed of 20 instances of 4 combinatorial optimization problems , yielding the largest discrete multitasking environment solved to date. Results are conclusive in regard to the superior quality of solutions provided by AT-MFCGA with respect to the rest of the methods, which are complemented by a quantitative examination of the genetic transferability among tasks throughout the search process.},
  archive      = {J_ISCI},
  author       = {Eneko Osaba and Javier Del Ser and Aritz D. Martinez and Jesus L. Lobo and Francisco Herrera},
  doi          = {10.1016/j.ins.2021.05.005},
  journal      = {Information Sciences},
  pages        = {577-598},
  shortjournal = {Inf. Sci.},
  title        = {AT-MFCGA: An adaptive transfer-guided multifactorial cellular genetic algorithm for evolutionary multitasking},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). WGNCS: A robust hybrid cross-version defect model via
multi-objective optimization and deep enhanced feature representation.
<em>ISCI</em>, <em>570</em>, 545–576. (<a
href="https://doi.org/10.1016/j.ins.2021.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a constantly-evolving software project with multiple releasing versions, Cross-Version Defect Prediction (CVDP) can identify the potential defect in the latter one by mining historical defect information from the prior releasing software versions. Unfortunately, the imbalanced class distribution and the complex intrinsic structure in software projects make it challenging to obtain suitable defect features and construct a predominant CVDP model. To address these challenges, we propose a robust hybrid CVDP model named WGNCS based on W GAN- G P (Wasserstein GAN with Gradient Penalty), multi-objective N SGA-III (Non-dominated Sorting Genetic Algorithm - III) algorithm and hybrid C NN- S VM (Convolutional Neural Network – Support Vector Machine) in this study, which has three main merits: (1) employ a powerful deep learning generative model – WGAN-GP to conduct data augmentation tasks, thereby achieving defect class balance and generating more training instances. (2) utilize the multi-objective NSGA-III algorithm to select the fewest representative training feature subset for the minimum error. (3) construct a single powerful defect predictor CNN-SVM by cascading a high-level deep semantic feature extractor (CNN) and a classifier (SVM) with the fixed non-linear Gaussian kernel function . We verify the CVDP performance of WGNCS on 32 cross-version pairs derived from 45 software project versions. The experimental results demonstrate that the WGNCS model can exhibit encouraging performance.},
  archive      = {J_ISCI},
  author       = {Nana Zhang and Shi Ying and Weiping Ding and Kun Zhu and Dandan Zhu},
  doi          = {10.1016/j.ins.2021.05.008},
  journal      = {Information Sciences},
  pages        = {545-576},
  shortjournal = {Inf. Sci.},
  title        = {WGNCS: A robust hybrid cross-version defect model via multi-objective optimization and deep enhanced feature representation},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A privacy-preserving aggregation scheme based on negative
survey for vehicle fuel consumption data. <em>ISCI</em>, <em>570</em>,
526–544. (<a href="https://doi.org/10.1016/j.ins.2021.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vehicle fuel consumption gauge is a vehicle’s basic device that usually records the instantaneous as well as average fuel consumption of the vehicle, which brings a lot of convenience during the driving process. The individual real-time fuel consumption data are meaningless, but its continuous real-time fuel consumption data contains some information that may reveal the user’s privacy, which is sensitive information for users. There are hot topics on privacy protection of sensitive user information, however, most of the studies have focused on privacy protection at the time of data release and the need for a trusted third party. In this paper, we propose a negative survey-based approach that can be utilized to protect aggregated vehicle fuel consumption data against time-series-based differential attacks. Its anonymous algorithm on the user side and estimation algorithm on the server side are able to protect the user’s privacy regardless of changes in the user’s fuel consumption data. The experiment results show that our method can achieve better privacy protection with better application prospects in a simpler and more effective way.},
  archive      = {J_ISCI},
  author       = {Weidong Yang and Xingxing Chen and Zenggang Xiong and Zhenqiang Xu and Gang Liu and Xuemin Zhang},
  doi          = {10.1016/j.ins.2021.05.009},
  journal      = {Information Sciences},
  pages        = {526-544},
  shortjournal = {Inf. Sci.},
  title        = {A privacy-preserving aggregation scheme based on negative survey for vehicle fuel consumption data},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cartesian product of sets without repeated elements.
<em>ISCI</em>, <em>570</em>, 517–525. (<a
href="https://doi.org/10.1016/j.ins.2021.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications, like database management systems , is very useful to have an expression to compute the cardinality of cartesian product of k k sets without repeated elements; we designate this problem as T ( k ) T(k) . The value of | T ( k ) | |T(k)| is upper-bounded by the multiplication of cardinalities of the sets. As long as we have searched, it has not been reported a general expression to compute T ( k ) T(k) using cardinalities of the intersections of sets, this is the main topic of this paper. Given three sets with indices { 0 , 1 , 2 } {0,1,2} , C i Ci is the cardinality of one set, C i , j Ci,j ( i i&amp;lt;j ) and C i , j , l Ci,j,l ( i i&amp;lt;j&amp;lt;l ) are respectively the cardinalities of the intersections of 2 and 3 sets, then the searched formulas for T ( k ) T(k) are: T ( 1 ) = C 0 T(1)=C0 ; T ( 2 ) = C 0 C 1 - C 0 , 1 T(2)=C0C1-C0,1 ; T ( 3 ) = C 0 C 1 C 2 - ( C 0 , 1 C 2 + C 0 , 2 C 1 + C 1 , 2 C 0 ) + 2 C 0 , 1 , 2 T(3)=C0C1C2-(C0,1C2+C0,2C1+C1,2C0)+2C0,1,2 . In this paper, we prove formulas for computing T ( k ) T(k) and its specialization when a set is contained in the next sets. For this purpose, we will use concepts like partitions of the integer k k in v v parts, Bell numbers, Stirling numbers of the first kind and Stirling numbers of the second kind . Additionally, we present a complexity analysis for the computation of T ( k ) T(k) .},
  archive      = {J_ISCI},
  author       = {Jose Torres-Jimenez and Carlos Lara-Alvarez and Carlos Cobos-Lozada and Roberto Blanco-Rocha and Alfredo Cardenas-Castillo},
  doi          = {10.1016/j.ins.2021.05.010},
  journal      = {Information Sciences},
  pages        = {517-525},
  shortjournal = {Inf. Sci.},
  title        = {Cartesian product of sets without repeated elements},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple imputation using nearest neighbor methods.
<em>ISCI</em>, <em>570</em>, 500–516. (<a
href="https://doi.org/10.1016/j.ins.2021.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing values are a major problem in medical research. As the complete case analysis discards useful information, estimation and inference may suffer strongly. Multiple imputation has been shown to be a useful strategy to handle missing data problems and account for the uncertainty of imputation. In the presence of high-dimensional data ( p ≫ n p≫n ), the missing values raise even more serious problems as the existing software packages tend to fail. We present multiple imputation methods based on nearest neighbors. The distances are computed using the information of correlation among the target and candidate predictors. Thus only the relevant predictors contribute for computing distances. The method successfully imputes missing values also in high-dimensional settings. Using a variety of simulated data with MCAR and MAR missing patterns, the proposed algorithm is compared to existing methods. Various measures are used to compare the performance of methods, including MSE for imputation, MSE of estimated regression coefficients , their standard errors, confidence intervals, and their coverage probabilities . The simulation results, for both cases n n&amp;lt;p and n &gt; p n&amp;gt;p , show that the sequential imputation using weighted nearest neighbors can be successfully applied to a wide range of data settings and outperforms or is close to the best when compared to existing methods.},
  archive      = {J_ISCI},
  author       = {Shahla Faisal and Gerhard Tutz},
  doi          = {10.1016/j.ins.2021.04.009},
  journal      = {Information Sciences},
  pages        = {500-516},
  shortjournal = {Inf. Sci.},
  title        = {Multiple imputation using nearest neighbor methods},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The two-person and zero-sum matrix game with probabilistic
linguistic information. <em>ISCI</em>, <em>570</em>, 487–499. (<a
href="https://doi.org/10.1016/j.ins.2021.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Game theory establishes mathematical models of strategic interactions among rational decision-makers. In many situations, the crisp values of payoffs are difficult to obtain while the probabilistic linguistic information is easy to collect. However, the existing research on matrix game did not consider the probabilistic linguistic information . To bridge this gap, this study takes the probabilistic linguistic information as the input of a two-person and zero-sum matrix game , and addresses the vague information by triangular membership functions. Such a two-person and zero-sum matrix game with probabilistic linguistic information is a useful technique for multiple criteria analysis. In addition, it outputs the same form of information as the inputs to increase the interpretability compared with other uncertain matrix games. An illustrative example about the forest management is provided to show the validity and advantages of the two-person and zero-sum matrix game with probabilistic linguistic information.},
  archive      = {J_ISCI},
  author       = {Xiaomei Mi and Huchang Liao and Xiao-Jun Zeng and Zeshui Xu},
  doi          = {10.1016/j.ins.2021.05.019},
  journal      = {Information Sciences},
  pages        = {487-499},
  shortjournal = {Inf. Sci.},
  title        = {The two-person and zero-sum matrix game with probabilistic linguistic information},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New efficient algorithms for the centroid of an interval
type-2 fuzzy set. <em>ISCI</em>, <em>570</em>, 468–486. (<a
href="https://doi.org/10.1016/j.ins.2021.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a type-2 fuzzy logic system , one of the important operations is to calculate the centroid of an interval type-2 fuzzy set (IT2 FS). In this paper, two novel algorithms called binary algorithms are proposed to calculate the centroid of IT2 FSs. Then, the outputs of the proposed binary algorithms are proven to be the optimal values. After analyzing the computational complexities of Karnik-Mendel (KM) algorithms, enhanced Karnik-Mendel (EKM) algorithms, enhanced iterative algorithms based on stopping condition (EIASC) algorithms and the proposed binary algorithms, it is found that the proposed binary algorithms are superior to the KM algorithms, EKM algorithms and EIASC algorithms. Finally, two extended binary algorithms are proposed to compute the centroid of an IT2 FS. The efficiencies of the proposed binary algorithms and extended binary algorithms are demonstrated by extensive simulations.},
  archive      = {J_ISCI},
  author       = {Xianliang Liu and Yicheng Lin and Shu-Ping Wan},
  doi          = {10.1016/j.ins.2021.04.032},
  journal      = {Information Sciences},
  pages        = {468-486},
  shortjournal = {Inf. Sci.},
  title        = {New efficient algorithms for the centroid of an interval type-2 fuzzy set},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Resolution of fuzzy relation equations with increasing
operations over complete lattices. <em>ISCI</em>, <em>570</em>, 451–467.
(<a href="https://doi.org/10.1016/j.ins.2021.04.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss the resolution of max - M max-M compositional and min - M min-M compositional fuzzy relation equations over complete lattices , where M is a left-increasing or right-increasing binary operation . The solvability, the existence of the least and the greatest solutions, and the unique solvability of these fuzzy relation equations are characterized.},
  archive      = {J_ISCI},
  author       = {Feng Sun and Xiao-bing Qu},
  doi          = {10.1016/j.ins.2021.04.065},
  journal      = {Information Sciences},
  pages        = {451-467},
  shortjournal = {Inf. Sci.},
  title        = {Resolution of fuzzy relation equations with increasing operations over complete lattices},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient class-specific shapelets learning for
interpretable time series classification. <em>ISCI</em>, <em>570</em>,
428–450. (<a href="https://doi.org/10.1016/j.ins.2021.03.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, time series classification approaches based on time-independent shapelets, have received considerable attention due to their high prediction accuracy and intuitive interpretability . However, most existing shapelets discovery approaches find shapelets by evaluating the discriminatory power of all subsequences of the series, which is computationally expensive even with certain speed-up techniques. Even though some shapelet learning approaches learn the near-to-optimal shapelets from the training series rather than searching from numerous segments, they still have significant drawbacks in their performance regarding the accuracy, efficiency, and interpretability due to the numerous class-shared shapelets with fixed lengths. Thus, we propose a new shapelet learning approach that can learn as few as possible class-specific and variable-length shapelets. Extensive experiments demonstrate that our proposed method is competitive about classification accuracy over 18 baselines on 25 datasets, outperforms 2 orders of magnitude about efficiency, and is more interpretable than existing classifiers.},
  archive      = {J_ISCI},
  author       = {Zhiyu Liang and Hongzhi Wang},
  doi          = {10.1016/j.ins.2021.03.063},
  journal      = {Information Sciences},
  pages        = {428-450},
  shortjournal = {Inf. Sci.},
  title        = {Efficient class-specific shapelets learning for interpretable time series classification},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision making with incomplete interval multiplicative
preference relations based on stochastic program and interval category.
<em>ISCI</em>, <em>570</em>, 403–427. (<a
href="https://doi.org/10.1016/j.ins.2021.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval multiplicative preference relations (IMPRs) have been widely used in decision making for their ability to efficiently express the uncertainty of information. This paper investigates the decision making with incomplete IMPRs. First, a new consistency index of IMPR is defined. By minimizing the consistency index, the missing values in an incomplete IMPR can be estimated. Subsequently, considering the risk attitude of decision-makers (DMs), two optimization models are constructed to obtain the most pessimistic and optimistic acceptably multiplicative consistent IMPRs, respectively. Based on the triangular distribution of intervals, a stochastic programming model is built to derive the priority weights from an acceptably multiplicative consistent IMPR. Thus, a new method is put forward for individual decision making with an incomplete IMPR. To reach maximum group support degree, a 0–1 mixed integer programming model is established to determine DMs’ weights for group decision making with IMPRs. Considering the category information of the individual intervals and collective intervals, the adjusted DMs’ weights are defined. The individual IMPRs are integrated into the collective IMPR. The ranking of alternatives is generated by the collective IMPR. Two real-life examples are demonstrated to validate the proposed methods. A decision support system based on the proposed methods is designed.},
  archive      = {J_ISCI},
  author       = {Shuping Wan and Huwei Yuan and Jiuying Dong},
  doi          = {10.1016/j.ins.2021.03.005},
  journal      = {Information Sciences},
  pages        = {403-427},
  shortjournal = {Inf. Sci.},
  title        = {Decision making with incomplete interval multiplicative preference relations based on stochastic program and interval category},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spiking neural p systems with autapses. <em>ISCI</em>,
<em>570</em>, 383–402. (<a
href="https://doi.org/10.1016/j.ins.2021.04.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the structure and communication method of neural systems, a parallel computing model, spiking neural P systems (SN P systems, for short), was proposed in 2006. A new class of SN P systems, SN P systems with autapses (SNP-AU systems), is presented in this work. Autapses are a special kind of synapses, connecting the axon of a neuron onto itself. We prove that SNP-AU systems can generate Turing-computable numbers, through the simulation of the modules of universal register machines. This result improves significantly the results given by classical SN P systems in terms of the number of neurons and rules, while preserving simplicity and power to a reasonable extent. Moreover, we construct an SNP-AU system using 53 neurons, proving its universality for computing functions. Finally, going beyond the design of the building blocks of register machines, a whole universal machine is provided. Thus, a simulator is developed and used to check the correctness of two universal SNP-AU systems proposed in this paper, complementing the theoretical proof with the experimental validation of our systems with respect to the reference example appearing in the foundational paper of small register machines.},
  archive      = {J_ISCI},
  author       = {Xiaoxiao Song and Luis Valencia-Cabrera and Hong Peng and Jun Wang},
  doi          = {10.1016/j.ins.2021.04.051},
  journal      = {Information Sciences},
  pages        = {383-402},
  shortjournal = {Inf. Sci.},
  title        = {Spiking neural p systems with autapses},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information-intensive design solution evaluator combined
with multiple design and preference information in product design.
<em>ISCI</em>, <em>570</em>, 360–382. (<a
href="https://doi.org/10.1016/j.ins.2021.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To assist designers in making comprehensive decisions for objective design values (DVs) and subjective preference values (PVs) during the design solution evaluation stage, this study builds an information-intensive design solution evaluator (IIDSE) that combines multi-information from DVs and PVs. In the IIDSE, the importance degrees of the DVs and PVs are analysed based on their differences. Then, according to the importance classifications, values, characteristics, and numbers of DVs and PVs, a multi-information fusion (MIF)-based ideal solution definition strategy, which covers quantitative criteria with i) benefit characteristics, ii) cost characteristics, and iii) qualitative criteria, is proposed. A rough multi-criteria decision-making (R-MCDM) model is used to evaluate an alternative by computing its deviation from the defined ideal solution. The effectiveness of the IIDSE was validated via empirical comparisons. Experiment I showed that the MIF-based strategy is compatible with different R-MCDM models for selecting the preferred and best performing solution. In experiment II, among the R-MCDM models, R-COPRAS plus the MIF-based strategy is the best combination for constructing the IIDSE. Experiments III and IV demonstrated that the IIDSE can obtain more reasonable solutions compared with classical evaluators, especially in the case where conflictions between the objective DVs and subjective PVs exist.},
  archive      = {J_ISCI},
  author       = {Jin Qi and Jie Hu and Yinghong Peng},
  doi          = {10.1016/j.ins.2021.03.052},
  journal      = {Information Sciences},
  pages        = {360-382},
  shortjournal = {Inf. Sci.},
  title        = {Information-intensive design solution evaluator combined with multiple design and preference information in product design},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TKUS: Mining top-k high utility sequential patterns.
<em>ISCI</em>, <em>570</em>, 342–359. (<a
href="https://doi.org/10.1016/j.ins.2021.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-utility sequential pattern mining (HUSPM) has recently emerged as a focus of intense research interest. The main task of HUSPM is to find all subsequences, within a quantitative sequential database, that have high utility with respect to a user-defined minimum utility threshold. However, it is difficult to specify the minimum utility threshold, especially when database features, which are invisible in most cases, are not understood. To handle this problem, top- k HUSPM was proposed. Up to now, only very preliminary work has been conducted to capture top- k HUSPs, and existing strategies require improvement in terms of running time, memory consumption, unpromising candidate filtering, and scalability. Moreover, no systematic problem statement has been defined. In this paper, we formulate the problem of top- k HUSPM and propose a novel algorithm called TKUS. To improve efficiency, TKUS adopts a projection and local search mechanism and employs several schemes, including the Sequence Utility Raising, Terminate Descendants Early, and Eliminate Unpromising Items strategies, which allow it to greatly reduce the search space. Finally, experimental results demonstrate that TKUS can achieve sufficiently good top- k HUSPM performance compared to state-of-the-art algorithm TKHUS-Span.},
  archive      = {J_ISCI},
  author       = {Chunkai Zhang and Zilin Du and Wensheng Gan and Philip S. Yu},
  doi          = {10.1016/j.ins.2021.04.035},
  journal      = {Information Sciences},
  pages        = {342-359},
  shortjournal = {Inf. Sci.},
  title        = {TKUS: Mining top-k high utility sequential patterns},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new generalized collaborative filtering approach on sparse
data by extracting high confidence relations between users.
<em>ISCI</em>, <em>570</em>, 323–341. (<a
href="https://doi.org/10.1016/j.ins.2021.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new collaborative filtering method is proposed based on finding similar users directly and indirectly to overcome sparsity challenge. Moreover, selecting these users through extracting dominant opinion patterns leads to tackling scalability. In this method, frequent opinions between users are extracted to be used as dominant patterns. Then, users corresponding to the same dominant pattern are considered as direct similar users. Direct similar users who have seen more items and have corresponded to more than one pattern are regarded as reference users. Each reference user mediates between users who may have no/few commonly seen items and they are considered as indirect similar users. Utilizing indirect similar user helps the method to predict opinion of query user about items, which have not been seen by any direct similar user before. Clearly, indirect users are selected based on speculation using available information about direct users’ preferences. Thus, the effect of indirect users is considered to be stricter than that of direct users on the final prediction step. Experiments conducted on MovieLens small, MovieLens 100 k, MovieLens 1 M, and Jester datasets showed that the proposed method outperforms the previously introduced methods, especially on sparse data.},
  archive      = {J_ISCI},
  author       = {Mohsen Ramezani and Fardin Akhlaghian Tab and Alireza Abdollahpouri and Mahmud Abdulla Mohammad},
  doi          = {10.1016/j.ins.2021.04.025},
  journal      = {Information Sciences},
  pages        = {323-341},
  shortjournal = {Inf. Sci.},
  title        = {A new generalized collaborative filtering approach on sparse data by extracting high confidence relations between users},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fuzzy preference-based dempster-shafer evidence theory for
decision fusion. <em>ISCI</em>, <em>570</em>, 306–322. (<a
href="https://doi.org/10.1016/j.ins.2021.04.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer evidence theory (D-S) is an effective instrument for merging the collected pieces of basic probability assignment (BPA), and it exhibits superiority in achieving robustness of soft computing and decision making in an uncertain and imprecise environment. However, the determination of BPA is still uncertain, and merely applying evidence theory can sometimes lead to counterintuitive results when lines of evidence conflict. In this paper, a novel BPA generation method for binary problems called as the base algorithm is designed based on the kernel density estimation to construct the probability density function models, using the pairwise learning method to establish binary classification pairs. By means of the new BPA generation method, a new decision-making algorithm based on D-S evidence theory, fuzzy preference relation and nondominance criterion is effectively designed. The strength of the proposed method is presented in applying pairwise learning, which transforms the original complex problem into simple subproblems . With this process, the complexity of the problem to be solved is greatly reduced, which increases the feasibility for industrial applications. Furthermore, the fuzzy computing technique is used to aggregate the output for each single subproblem, and the nondominance degree of each class is determined from the fuzzy preference relation matrix, which can be directly used for the determination of the input instance. Based on several industrial-based classification experiments, the proposed BPA generation method and decision-making algorithm present the effectiveness and improvement in terms of precision and Cohen’s kappa.},
  archive      = {J_ISCI},
  author       = {Chaosheng Zhu and Bowen Qin and Fuyuan Xiao and Zehong Cao and Hari Mohan Pandey},
  doi          = {10.1016/j.ins.2021.04.059},
  journal      = {Information Sciences},
  pages        = {306-322},
  shortjournal = {Inf. Sci.},
  title        = {A fuzzy preference-based dempster-shafer evidence theory for decision fusion},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic mutual information gradient estimation for
dimensionality reduction networks. <em>ISCI</em>, <em>570</em>, 298–305.
(<a href="https://doi.org/10.1016/j.ins.2021.04.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature ranking and selection is a widely used approach in various applications of supervised dimensionality reduction in discriminative machine learning . Nevertheless there exists significant evidence on feature ranking and selection algorithms based on any criterion leading to potentially sub-optimal solutions for class separability . In that regard, we introduce emerging information theoretic feature transformation protocols as an end-to-end neural network training approach. We present a dimensionality reduction network (MMINet) training procedure based on the stochastic estimate of the mutual information gradient. The network projects high-dimensional features onto an output feature space where lower dimensional representations of features carry maximum mutual information with their associated class labels. Furthermore, we formulate the training objective to be estimated non-parametrically with no distributional assumptions. We experimentally evaluate our method with applications to high-dimensional biological data sets, and relate it to conventional feature selection algorithms to form a special case of our approach.},
  archive      = {J_ISCI},
  author       = {Ozan Özdenizci and Deniz Erdoğmuş},
  doi          = {10.1016/j.ins.2021.04.066},
  journal      = {Information Sciences},
  pages        = {298-305},
  shortjournal = {Inf. Sci.},
  title        = {Stochastic mutual information gradient estimation for dimensionality reduction networks},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep analysis of word sense disambiguation via
semi-supervised learning and neural word representations. <em>ISCI</em>,
<em>570</em>, 278–297. (<a
href="https://doi.org/10.1016/j.ins.2021.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Word Sense Disambiguation (WSD) aims to determine the meaning of a word in context. Different approaches have been proposed in supervised and unsupervised domains. In most cases, supervised learning provides superior WSD performance. Since sense-annotated corpora can be difficult or time-consuming to obtain, which must be repeated for new domains, languages, and sense inventories, semi-supervised learning (SSL) methods, that combine a small amount of sense-annotated data, start to be pre-eminent. In SSL, graph-based methods are common, because they capture the relationships between terms using an undirected graph. This paper aims to investigate semi-supervised WSD by considering different graph-based SSL algorithms with features generated by word embeddings from Word2Vec, FastText, GloVe, BERT and ELECTRA models combined with parts-of-speech tags and word context. We test several combinations of word-embedding models, similarity measures for graph construction and SSL classification algorithms to disambiguate classical lexical sample WSD datasets. The results indicate our SSL algorithms achieved competitive results compared to supervised ones and the ELECTRA models performed better than other embeddings for SSL.},
  archive      = {J_ISCI},
  author       = {José Marcio Duarte and Samuel Sousa and Evangelos Milios and Lilian Berton},
  doi          = {10.1016/j.ins.2021.04.006},
  journal      = {Information Sciences},
  pages        = {278-297},
  shortjournal = {Inf. Sci.},
  title        = {Deep analysis of word sense disambiguation via semi-supervised learning and neural word representations},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A graphical decomposition and similarity measurement
approach for topic detection from online news. <em>ISCI</em>,
<em>570</em>, 262–277. (<a
href="https://doi.org/10.1016/j.ins.2021.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topic detection aims to discover valuable topics from the massive online news. It can help people to capture what is happening in real world and alleviate the burden of information overload. It also has great significance since the online news is experiencing an explosive growth. Topic detection is typically transformed into a document clustering problem, whose core idea is to cluster news documents that report on the same topic to the same group based on document similarity. Due to the complex structure and long length of news documents, the similarity measurement of news is very challenging. Existing term-based methods represent news documents based on a set of informative keywords in the document with a vector space model (VSM) and then the relationship between documents is calculated by cosine similarity . However, VSM ignores the relationship between words and has sparse semantics, which leads to low precision of topic detection. In recent years, the probabilistic methods and the graph analytical methods have been proposed for topic detection. However, both of them have high time complexity. To cope with these problems, we first present a novel document representation approach based on graphical decomposition, which decomposes each news document into different semantic units and then relationship between the semantic units is constructed to form a capsule semantic graph (CSG). The CSG can retain the relationship between words and alleviate the sparse semantics compared to VSM representation. We next introduce the graph kernel to measure the similarity between the CSGs based on their substructures. Finally, we use an incremental clustering method to cluster the news documents, in which the documents are represented by CSGs and the similarity between documents is calculated by graph kernel. The experiment results on three standard datasets show that our method obtains higher precision, recall and F1 score than several state-of-the-art methods. Moreover, the experiment results on a large news dataset show that our CSG-SM has lower time complexity than probabilistic methods and graph analytical methods.},
  archive      = {J_ISCI},
  author       = {Kejing Xiao and Zhaopeng Qian and Biao Qin},
  doi          = {10.1016/j.ins.2021.04.029},
  journal      = {Information Sciences},
  pages        = {262-277},
  shortjournal = {Inf. Sci.},
  title        = {A graphical decomposition and similarity measurement approach for topic detection from online news},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Passenger-centric vehicle routing for first-mile
transportation considering request uncertainty. <em>ISCI</em>,
<em>570</em>, 241–261. (<a
href="https://doi.org/10.1016/j.ins.2021.04.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First-mile transportation provides convenient transit service for passengers to travel from their homes, workplaces, or public institutions to a public transit station that is located beyond comfortable walking distance. This paper studies the Passenger-Centric Vehicle Routing for First-Mile Transportation (PCVR-FMT) problem to plan optimal vehicle routes that provide a high quality of service (QoS) to enhance passenger experience. We consider a practical scenario with 1) deterministic requests, consisting of travel requests that are known in advance (e.g., submitted by passengers through a mobile application), and 2) uncertain requests (e.g., new travel requests generated during service operation). We formally formulate the PCVR-FMT problem to maximize the QoS in terms of the passenger waiting and riding time (for both deterministic and uncertain requests) while jointly considering the traditional constraints on the pickup time window as well as vehicle capacity. We developed an Ant-Colony Optimization algorithm based on a novel Dynamic Request Driven scheme for vehicle route construction, denoted as DRD-ACO, to efficiently solve PCVR-FMT. DRD-ACO relies on a novel request-location graph that models both deterministic and uncertain requests, which enable the ants to share information across different generations via pheromone for dealing with uncertain requests. A dynamic seat reservation mechanism is devised to determine a suitable number of reserved seats to deal with uncertain requests. A time window expansion mechanism is developed to selectively expand passengers’ pickup time window if the number of vehicles is insufficient. The effectiveness of the proposed methods is evaluated using Singapore’s road network and synthetic travel requests generated from real bus travel demands. Some of the travel requests are treated as uncertain requests. The results show that on relatively small size instances, our methods obtain solutions that are close to the optimal ones computed by CPLEX, with deviations ranging from only 2.55\% to 8.79\%. In comparison to other baselines, our methods achieve better results in the objective function, ratio of served uncertain passengers, as well as the expansion in waiting time due to request uncertainty, for both small-scale and large-scale problem instances.},
  archive      = {J_ISCI},
  author       = {Fangxin Ning and Guiyuan Jiang and Siew-Kei Lam and Changhai Ou and Peilan He and Yidan Sun},
  doi          = {10.1016/j.ins.2021.04.054},
  journal      = {Information Sciences},
  pages        = {241-261},
  shortjournal = {Inf. Sci.},
  title        = {Passenger-centric vehicle routing for first-mile transportation considering request uncertainty},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HI-GAN: A hierarchical generative adversarial network for
blind denoising of real photographs. <em>ISCI</em>, <em>570</em>,
225–240. (<a href="https://doi.org/10.1016/j.ins.2021.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep convolutional neural networks (DCNNs) and generative adversarial networks (GANs) have achieved remarkable success in image denoising , they have been facing a severe problem of the trade-off between removing noise and artifacts on the one hand, and preserving details on the other. In comparison with conventional DCNNs, GANs might be better in balancing between erasing different types of noise and recovering texture details. However, they often generate fake details and unexpected artifacts in the image owing to the instability of their discriminator during training. In this study, we propose a hierarchical generative adversarial network (HI-GAN) that adopts useful solutions for handling these serious problems of image denoising . Unlike the conventional GAN, the proposed HI-GAN comprises three main generators. The first generator tackles the problem of losing high-frequency features such as edges and texture. This generator was trained together with the discriminator to improve its ability to preserve essential details. The second generator focuses on eliminating the effect of instabilities caused by the discriminator and restoring low-frequency features in the noisy image . Both generators use different criteria to evaluate the denoising performance, and none of them outperformed the other. Then, a third generator is employed to help them cooperate more effectively and boost reconstruction performance. Moreover, to improve the effectiveness of the generators, we also propose a novel boosted residual dense UNet, which is designed to maximize information flow to pass through all convolutional layers in the network. In addition, we propose the AdaRaGAN loss function that effectively prevents the instability of the discriminator of the HI-GAN and improves the denoising performance. The experimental results of the experiments involving challenging datasets of real-world noisy images show that our proposed method is superior to other state-of-the-art denoisers in terms of quantitative metrics and visual quality. Our source codes and datasets for HI-GAN are available at https://github.com/ZeroZero19/HI-GAN.git.},
  archive      = {J_ISCI},
  author       = {Duc My Vo and Duc Manh Nguyen and Thao Phuong Le and Sang-Woong Lee},
  doi          = {10.1016/j.ins.2021.04.045},
  journal      = {Information Sciences},
  pages        = {225-240},
  shortjournal = {Inf. Sci.},
  title        = {HI-GAN: A hierarchical generative adversarial network for blind denoising of real photographs},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MR-MVPP: A map-reduce-based approach for creating MVPP in
data warehouses for big data applications. <em>ISCI</em>, <em>570</em>,
200–224. (<a href="https://doi.org/10.1016/j.ins.2021.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Materialized view selection (MVS) is the problem of selecting an appropriate set of views to be materialized to speed up analytical query processing of data warehouses . Online analytical processing (OLAP) of queries is an essential application of the MVS problem, in which, the response times of the queries are reduced by storing the selected views. Views are intermediate results of query processing and are selected in the MVS problem to be stored and will then be exploited in answering process of several queries. Views are usually organized as a view representation structure in the MVS problem. Multiple Views Processing Plan (MVPP) is a standard structure used for view representation in the MVS problem. Due to the tremendous amount of data, constructing the MVPP is a challenge in the big data applications . The MR-MVPP (Map-Reduce-based construction of the MVPP) is the proposed method of this paper to address this problem. The MR-MVPP performs a set similarity join (similarity-based join) on the base relations and views using the map-reduce model and the hashing technique. The MVPP construction time in the proposed method is reduced by avoiding redundant calculations in the process of creating the MVPP. The performance of the proposed method is empirically evaluated. According to the results of the experiments, the execution time of the MR-MVPP method is better than the other methods. The average time improvement is about 26.5 units. This improvement is better than the other similar researches in this area and is significant due to the high volume of data in real applications. Moreover, the proposed method works well in terms of the effectiveness of the created MVPP and has about a 50\% coverage rate for view selection methods. Deterministic methods are more accurate than hashing methods and can be utilized for set similarity join as future work to probably improve the effectiveness of the constructed MVPP.},
  archive      = {J_ISCI},
  author       = {Hossein Azgomi and Mohammad Karim Sohrabi},
  doi          = {10.1016/j.ins.2021.04.004},
  journal      = {Information Sciences},
  pages        = {200-224},
  shortjournal = {Inf. Sci.},
  title        = {MR-MVPP: A map-reduce-based approach for creating MVPP in data warehouses for big data applications},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Author topic model for co-occurring normal documents and
short texts to explore individual user preferences. <em>ISCI</em>,
<em>570</em>, 185–199. (<a
href="https://doi.org/10.1016/j.ins.2021.04.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The investigation of user preferences through user comments has attracted significant attention. Although topic models have been verified as useful tools to facilitate the understanding of textual contents, they cannot be directly applied to accomplish this task because of two problems. The first problem is the severe data sparsity suffered by user comments because they are generally short. The second problem is the mixture of opinions from both user comments and the original documents the users commented on. To simultaneously solve the data sparsity problem and explore clean user preferences, we propose an author co-occurring topic model (AOTM) for normal documents and their short user comments. By considering authorship, AOTM allows each author of short texts to have a probability distribution over a set of topics represented only short texts. Accordingly, the individual user preferences can be investigated based on these author-level distributions. We verify the performance of AOTM using two news article datasets and one e-commerce dataset. Extensive experiments demonstrate that the AOTM outperforms several state-of-the-art methods in topic learning and topic representation of documents. The potential usage of AOTM in exploring individual user preferences is further illustrated by drawing user portraits and predicting user posting behaviors.},
  archive      = {J_ISCI},
  author       = {Yang Yang and Feifei Wang},
  doi          = {10.1016/j.ins.2021.04.060},
  journal      = {Information Sciences},
  pages        = {185-199},
  shortjournal = {Inf. Sci.},
  title        = {Author topic model for co-occurring normal documents and short texts to explore individual user preferences},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent evolutionary extreme gradient boosting
algorithm development for modeling scour depths under submerged weir.
<em>ISCI</em>, <em>570</em>, 172–184. (<a
href="https://doi.org/10.1016/j.ins.2021.04.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research presents a new hybridized evolutionary artificial intelligence (AI) model for modeling depth scouring under submerged weir ( d s ds ). The proposed model is based on the hybridization of the Extreme Gradient Boosting (XGBoost) model and genetic algorithm (GA) optimizer. The GA is hybridized to solve the hyper-parameter problem of the XGBoost model and to recognize the influential input predictors of d s ds . The proposed XGBoost-GA model is developed based on the incorporation of fifteen physical parameters of submerged weir. The feasibility of the XGBoost-GA model is validated against several well-established AI models introduced in the literature in addition to a hybrid XGBoost-Grid model. Several statistical performance metrics is computed for the modeling evaluation in parallel with a graphical assessment. Based on the attained prediction results, the proposed model revealed an optimistic and superior predictability performance with a maximum coefficient of determination ( R 2 R2 = 0.933) and a minimum root mean square error ( RMSE = 0.014 m). In addition, the XGBoost-GA model demonstrated reliable feature selection for the essential physical parameters. The fifteen parameters are re-scaled to seven parameters based on their essential impacts on the d s ds determination.},
  archive      = {J_ISCI},
  author       = {Hai Tao and Maria Habib and Ibrahim Aljarah and Hossam Faris and Haitham Abdulmohsin Afan and Zaher Mundher Yaseen},
  doi          = {10.1016/j.ins.2021.04.063},
  journal      = {Information Sciences},
  pages        = {172-184},
  shortjournal = {Inf. Sci.},
  title        = {An intelligent evolutionary extreme gradient boosting algorithm development for modeling scour depths under submerged weir},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A highly scalable algorithm for weak rankings aggregation.
<em>ISCI</em>, <em>570</em>, 144–171. (<a
href="https://doi.org/10.1016/j.ins.2021.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Optimal Bucket Order Problem (OBOP) is a rank aggregation problem which consists in finding a consensus ranking (with ties) that generalizes a set of input rankings. In this paper, with the aim of solving the OBOP in an efficient and scalable way, we propose several greedy algorithms based on different sort-first and cluster-second strategies. More specifically, the sorting step is based on the Borda method, whereas in the cluster step, pairs of adjacent buckets are suitably joined. The proposed methods are experimentally compared with the state-of-the-art greedy algorithms for solving the OBOP by using a large benchmark of real-world databases. Furthermore, we provide a complete statistical analysis of the experimental study, which shows that several of the proposed algorithms outperform the current state-of-the-art greedy algorithms. We also analyze the trade-off between accuracy and execution time of the algorithms to guide the users regarding the selection of the best option for each particular case. The study carried out shows that our proposal is not only competitive in terms of accuracy with the state-of-the-art evolutionary strategy for dealing with the OBOP, but is also fast and scalable.},
  archive      = {J_ISCI},
  author       = {Juan A. Aledo and José A. Gámez and Alejandro Rosete},
  doi          = {10.1016/j.ins.2021.04.034},
  journal      = {Information Sciences},
  pages        = {144-171},
  shortjournal = {Inf. Sci.},
  title        = {A highly scalable algorithm for weak rankings aggregation},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel framework of collaborative early warning for
COVID-19 based on blockchain and smart contracts. <em>ISCI</em>,
<em>570</em>, 124–143. (<a
href="https://doi.org/10.1016/j.ins.2021.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early warning is a vital component of emergency response systems for infectious diseases. However, most early warning systems are centralized and isolated, thus there are potential risks of single evidence bias and decision-making errors. In this paper, we tackle this issue via proposing a novel framework of collaborative early warning for COVID-19 based on blockchain and smart contracts , aiming to crowdsource early warning tasks to distributed channels including medical institutions, social organizations, and even individuals. Our framework supports two surveillance modes, namely, medical federation surveillance based on federated learning and social collaboration surveillance based on the learning markets approach, and fuses their monitoring results on emerging cases to alert. By using our framework, medical institutions are expected to obtain better federated surveillance models with privacy protection, and social participants without mutual trusts can also share verified surveillance resources such as data and models, and fuse their surveillance solutions. We implemented our proposed framework based on the Ethereum and IPFS platforms. Experimental results show that our framework has advantages of decentralized decision-making, fairness, auditability, and universality. It also has potential guidance and reference value for the early warning and prevention of unknown infectious diseases.},
  archive      = {J_ISCI},
  author       = {Liwei Ouyang and Yong Yuan and Yumeng Cao and Fei-Yue Wang},
  doi          = {10.1016/j.ins.2021.04.021},
  journal      = {Information Sciences},
  pages        = {124-143},
  shortjournal = {Inf. Sci.},
  title        = {A novel framework of collaborative early warning for COVID-19 based on blockchain and smart contracts},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategy evolution of panic pedestrians in emergent
evacuation with assailants based on susceptible-infected-susceptible
model. <em>ISCI</em>, <em>570</em>, 105–123. (<a
href="https://doi.org/10.1016/j.ins.2021.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Panic pedestrian evacuation in emergent situations with assailants is of great practical significance. Although game theory have been applied to analyze pedestrians’ decision making in pedestrian evacuation, there are fewer works addressing strategy evolution of panic pedestrians in emergent evacuation with assailants. To fill this gap, this paper built a new model for emergent evacuation with assailants (called EEA-SIS) based on Susceptible-Infected-Susceptible model (SIS). In our model, pedestrians’ decision-making is guided by game theory models . Pedestrian-relationship network is built to indicate pedestrians’ interaction. The process of changing evacuation strategy between cooperation and defection is indicated through the SIS model on this pedestrian-relationship network. Experiments are conducted on four different social dilemmas related to four evacuation scenarios. The simulation results show that with the evolution of pedestrian-relationship network, the evolution trend of different types of pedestrians’ strategies has changed significantly. A sensitivity test is carried out to investigates the influence of panic value on the strategy evolution of pedestrians and show the possible behavior changes of them. Several useful results are obtained for safety management. Finally, comparison experiments show that both evacuation time and casualty in our model are less than those in the classical agent-based model for all evacuation scenarios.},
  archive      = {J_ISCI},
  author       = {Yunyun Niu and Yulin Chen and Detian Kong and Bo Yuan and Jieqiong Zhang and Jianhua Xiao},
  doi          = {10.1016/j.ins.2021.04.040},
  journal      = {Information Sciences},
  pages        = {105-123},
  shortjournal = {Inf. Sci.},
  title        = {Strategy evolution of panic pedestrians in emergent evacuation with assailants based on susceptible-infected-susceptible model},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure consensus of multiagent systems with DoS attacks via
a graph-based approach. <em>ISCI</em>, <em>570</em>, 94–104. (<a
href="https://doi.org/10.1016/j.ins.2021.03.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the secure consensus problem of multiagent systems under switching topologies . The studied multiagent systems are affected by both denial-of-service (DoS) attacks and external disturbances . To solve the secure H ∞ H∞ consensus problems, some modified definitions are presented. Some graph-based Lyapunov functions , which are based on the solutions of some Lyapunov equations and the graph information , are also designed for the H ∞ H∞ performance analysis. Moreover, graph-based frequency and durations have also been presented for attaining the expected system performance. The stabilization controllers are also developed based on the solutions to some Lyapunov equations and an algebraic Riccati equation (ARE), which are easy to acquire. Some simulations are provided to validate the feasibility of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Shengli Du and Yuee Wang and Lijing Dong and Xiaoli Li},
  doi          = {10.1016/j.ins.2021.03.054},
  journal      = {Information Sciences},
  pages        = {94-104},
  shortjournal = {Inf. Sci.},
  title        = {Secure consensus of multiagent systems with DoS attacks via a graph-based approach},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). JUDO: Just-in-time rumour detection in streaming social
platforms. <em>ISCI</em>, <em>570</em>, 70–93. (<a
href="https://doi.org/10.1016/j.ins.2021.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web platforms, especially social media, are facing a new and ever-evolving cyber threat operating at the information level. Their open nature allows a high velocity flow of rumours that emerge unexpectedly and spread quickly. While rumour detection has attracted many theoretical and practice studies, the timing of the detection is often neglected or not properly considered. Rumours often cause irreversible damage worldwide before being successfully detected. To address this, we approach early rumour detection from a streaming perspective. We present a just-in-time rumour detection framework that is built on top of the continuous scoring of rumour-related signals. To overcome the trade-off between timeliness and the coefficient of detection, our model treats social graphs as a data stream and computes the anomaly score of potential rumours at both the element-level and subgraph-level. This multi-level approach not only captures the propagation structure of rumours but also focuses on abnormal elements that are responsible for bootstrapping or amplifying the rumours (the ‘explore vs exploit’ effect). With extensive evaluations on our published benchmark, our model identifies rumours earlier than the baselines while achieving an even better detection coefficient.},
  archive      = {J_ISCI},
  author       = {Thanh Toan Nguyen and Thanh Tam Nguyen and Thanh Thi Nguyen and Bay Vo and Jun Jo and Quoc Viet Hung Nguyen},
  doi          = {10.1016/j.ins.2021.04.018},
  journal      = {Information Sciences},
  pages        = {70-93},
  shortjournal = {Inf. Sci.},
  title        = {JUDO: Just-in-time rumour detection in streaming social platforms},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rulebase construction using variables with data-dependent
domains. <em>ISCI</em>, <em>570</em>, 52–69. (<a
href="https://doi.org/10.1016/j.ins.2021.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy inference systems are used to determine output values based on input values, with the connection between output and input determined through a training phase. This approach lends itself when this connection is not easily modelled. Here, such a system is considered for spatial data, where an underlying (spatial) distribution is not known but can be estimated from other available data to perform a regridding. The spatial context provides interesting constraints, justifying modifications to the traditional approach in order to improve its performance for this problem. We will present a methodology where the most suitable domain of the variables of the rulebase is dependent on the datapair; this dependency is dealt with using two different approaches: one where the values are scaled to a common domain and one where the fuzzy sets are redefined on the fly. The spatial data problem serves as a test case to illustrate the performance, using the basic Mamdani rulebase construction algorithm as a benchmark to verify and assess the methodology. The presented methodology is not limited to spatial data processing and generally is applicable when subsets of the dataset behave similarly if the domain is appropriately reconsidered.},
  archive      = {J_ISCI},
  author       = {Jörg Verstraete and Weronika Radziszewska},
  doi          = {10.1016/j.ins.2021.04.037},
  journal      = {Information Sciences},
  pages        = {52-69},
  shortjournal = {Inf. Sci.},
  title        = {Rulebase construction using variables with data-dependent domains},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Second order takagi-sugeno fuzzy model with domain
adaptation for nonlinear regression. <em>ISCI</em>, <em>570</em>, 34–51.
(<a href="https://doi.org/10.1016/j.ins.2021.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the regression analysis, Takagi-Sugeno fuzzy model gives a way of exploiting fuzzy logic to tackle nonlinear issues. However, the general Takagi-Sugeno fuzzy model encounters challenges when facing second order regression problems because of its insufficient fitting ability. In this study, the second order Takagi-Sugeno fuzzy model called TS 2 fuzzy model is proposed to extend the application scope of the original model. Moreover, domain adaptation in transfer learning is applied to the proposed model by using space transformation. It aims to further reduce the model’s cumulative error. The experimental results indicate that the proposed model has a better performance with not much extra processing time when dealing with second order nonlinear regression tasks .},
  archive      = {J_ISCI},
  author       = {Jiayi Sun and Yaping Dai and Kaixin Zhao and Zhiyang Jia},
  doi          = {10.1016/j.ins.2021.04.024},
  journal      = {Information Sciences},
  pages        = {34-51},
  shortjournal = {Inf. Sci.},
  title        = {Second order takagi-sugeno fuzzy model with domain adaptation for nonlinear regression},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online bagging of evolving fuzzy systems. <em>ISCI</em>,
<em>570</em>, 16–33. (<a
href="https://doi.org/10.1016/j.ins.2021.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolving fuzzy systems (EFS) have received increased attention from the community for the purpose of data stream modeling in an incremental, single-pass and transparent manner . To date, a wide variety of EFS approaches have been developed and successfully used in real-world applications which address structural evolution and parameter adaptation in single EFS models. We propose a specific ensemble scheme of EFS to increase their robustness in predictive performance on new stream samples. Our approach relies on an online variant of bagging in which various EFS ensemble members are generated from online bags, that is, the members are updated based on a specific probabilistic online sampling technique, and this with guaranteed convergence to classical sampling in batch bagging. The autonomous pruning of ensemble members is undertaken to omit undesired members with atypically higher errors than other members. We propose two variants, hard pruning where undesired members are deleted forever from the ensemble, and soft pruning where members receive weights to calculate the overall ensemble prediction, according to their single performance; thus, members who are undesired at a certain point of time may be dynamically recalled at a later stage. The autonomous evolution of new ensemble members is carried out whenever a drift in the stream is detected, based on a significantly worsening performance indicator, measured in terms of the Hoeffding inequality. Newer members typically represent the drifted state better and are thus up-weighed compared to older members within an advanced (weighted) calculation of the overall ensemble prediction. The new approach termed online bagged EFS (OB-EFS) was successfully evaluated and compared with single EFS models and related SoA approaches on four data streams from real-world applications (containing various noise levels, drifts and new operating conditions) and showed significantly lower prediction error trend lines.},
  archive      = {J_ISCI},
  author       = {Edwin Lughofer and Mahardhika Pratama and Igor Škrjanc},
  doi          = {10.1016/j.ins.2021.04.041},
  journal      = {Information Sciences},
  pages        = {16-33},
  shortjournal = {Inf. Sci.},
  title        = {Online bagging of evolving fuzzy systems},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matching user accounts with spatio-temporal awareness across
social networks. <em>ISCI</em>, <em>570</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2021.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User identification aims at matching user accounts across social sites, which benefits many real-world applications. Existing works based on user trajectories usually address spatial and temporal data separately while not fully utilizing the coupling relation between them. Differently, in this work, we jointly consider spatialtemporal information in users’ acitvities to improve the user identification method. In particular, we observe that check-in records of different users tend to create inconsistent spatialtemporal information. These inconsistencies are useful for eliminating false user matching. Inspired by this observation, we propose a novel user identification method that captures the correlation of spatial and temporal information and the inconsistency in check-in records. It contains three main steps. 1) We measure the similarity of users’ trajectories based on a kernel density estimation, which considers spatial and temporal information simultaneously. 2) We assign a weight to each check-in record to favor discriminative ones. 3) We utilize the inconsistency among check-in records to compute penalties for trajectory similarity. The pair of accounts with higher similarity (than a predefined threshold) is then considered to be from the same user. We evaluate our approach on three ground-truth datasets. The results show that the proposed method offers competitive performance, with F1 values reaching 86.12\%, 85.08\% and 78.34\%, which demonstrates the superiority of the proposed method over state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yongjun Li and Wenli Ji and Xing Gao and Yao Deng and Wei Dong and Dongxu Li},
  doi          = {10.1016/j.ins.2021.04.030},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Matching user accounts with spatio-temporal awareness across social networks},
  volume       = {570},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning-based QoE-oriented dynamic adaptive
streaming framework. <em>ISCI</em>, <em>569</em>, 786–803. (<a
href="https://doi.org/10.1016/j.ins.2021.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic adaptive streaming over the HTTP (DASH) standard has been widely adopted by many content providers for online video transmission and greatly improve the performance. Designing an efficient DASH system is challenging because of the inherent large fluctuations characterizing both encoded video sequences and network traces. In this paper, a reinforcement learning (RL)-based DASH technique that addresses user quality of experience (QoE) is constructed. The DASH adaptive bitrate (ABR) selection problem is formulated as a Markov decision process (MDP) problem. Accordingly, an RL-based solution is proposed to solve the MDP problem, in which the DASH clients act as the RL agent, and the network variation constitutes the environment. The proposed user QoE is used as the reward by jointly considering the video quality and buffer status . The goal of the RL algorithm is to select a suitable video quality level for each video segment to maximize the total reward. Then, the proposed RL-based ABR algorithm is embedded in the QoE-oriented DASH framework. Experimental results show that the proposed RL-based ABR algorithm outperforms state-of-the-art schemes in terms of both temporal and visual QoE factors by a noticeable margin while guaranteeing application-level fairness when multiple clients share a bottlenecked network.},
  archive      = {J_ISCI},
  author       = {Xuekai Wei and Mingliang Zhou and Sam Kwong and Hui Yuan and Shiqi Wang and Guopu Zhu and Jingchao Cao},
  doi          = {10.1016/j.ins.2021.05.012},
  journal      = {Information Sciences},
  pages        = {786-803},
  shortjournal = {Inf. Sci.},
  title        = {Reinforcement learning-based QoE-oriented dynamic adaptive streaming framework},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disturbance observer-based takagi-sugeno fuzzy control of a
delay fractional-order hydraulic turbine governing system with elastic
water hammer via frequency distributed model. <em>ISCI</em>,
<em>569</em>, 766–785. (<a
href="https://doi.org/10.1016/j.ins.2021.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hydraulic turbine governing system (HTGS) is a core part of a hydropower station, and the dynamic characteristics of its transition process and stability under disturbances have been strong concerns for the stable operations of units. In this paper, a disturbance observer-based Takagi-Sugeno (T-S) fuzzy control (DOBFC) method using the frequency distributed model (FDM) is proposed to improve the anti-interference control performance of a delay fractional-order HTGS. First, a more practical mathematical model of a fractional-order HTGS considering both the mechanical time delay and an elastic water hammer is established, and then its fuzzy model is presented on the basis of the generalized T-S fuzzy rules. Second, the disturbance observer is constructed by utilizing the system state and disturbance information, and the output estimated value of the observer is input into the designed fuzzy state feedback controller to compensate for the effect of external disturbances on the system and achieve disturbance suppression. Third, by means of a new FDM transformation and the construction of a novel Lyapunov function, the stability condition and the parameter solving method of the controller are derived using the linear matrix inequality (LMI) technique. Finally, simulation results are given to verify the effectiveness of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Teng Ma and Bin Wang},
  doi          = {10.1016/j.ins.2021.05.013},
  journal      = {Information Sciences},
  pages        = {766-785},
  shortjournal = {Inf. Sci.},
  title        = {Disturbance observer-based takagi-sugeno fuzzy control of a delay fractional-order hydraulic turbine governing system with elastic water hammer via frequency distributed model},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Perceiving more truth: A dilated-block-based convolutional
network for rumor identification. <em>ISCI</em>, <em>569</em>, 746–765.
(<a href="https://doi.org/10.1016/j.ins.2021.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To mitigate the negative influence of rumor spreading, rumor identification is urgently needed. Conventional feature-based identification models rely heavily on hand-crafted features and are thus not suitable for dynamic and complicated rumor identification scenarios. Although existing identification models based on deep neural networks eliminate manual effort and achieve automatic feature extraction, they can be further improved by modifying the underlying architecture—e.g., convolutional neural networks (CNNs). In this study, dilated convolution was used to form a dilated-block design architecture, with the aim of weakening the mutual constraint between the receptive field expansion and data loss in CNN-based models. In this architecture, a dilated convolution-based model called the “dilated-block-based convolutional network” (DBCN) is proposed. The DBCN stacks several dilated blocks to achieve a wider receptive field and automatically extract features from the input with less information loss. Accordingly, the constraint existing in CNN-based models are removed. An experiment on a rumor dataset showed that the DBCN model outperformed other baseline models in rumor identification,with an F1 avg measure of 0.7719, which is an increase of 7.18\% over the result of the previously best baseline model (the convolutional approach for misinformation identification). The DBCN model also performed well for early identification.},
  archive      = {J_ISCI},
  author       = {Yue Yuan and Yanli Wang and Kan Liu},
  doi          = {10.1016/j.ins.2021.05.014},
  journal      = {Information Sciences},
  pages        = {746-765},
  shortjournal = {Inf. Sci.},
  title        = {Perceiving more truth: A dilated-block-based convolutional network for rumor identification},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient constrained global optimization algorithm with
a clustering-assisted multiobjective infill criterion using gaussian
process regression for expensive problems. <em>ISCI</em>, <em>569</em>,
728–745. (<a href="https://doi.org/10.1016/j.ins.2021.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained optimization problems trouble engineers and researchers because of their high complexity and computational cost. When the objective function and constraints are both expensive black-box problems, there are many difficulties in solving them due to the unknown mathematical expressions and limited computational resources. To address these difficulties, we propose an efficient constrained global optimization algorithm . In the proposed algorithm, Gaussian process regression models are used to approximate the expensive objective function and constraints. Differential evolution (DE) is adopted to find the minimum value of the constrained lower confidence bounding (LCB). To further improve the accuracy of the Gaussian process regression models for the objective and constraints simultaneously, a clustering-assisted multiobjective infill criterion is proposed. The multiobjective infill criterion is utilized to balance the exploration between the objective and constraints. The clustering selection method is used to maintain the diversity of the sample points. The experimental results show that the proposed algorithm is better than or at least comparable to classic algorithms and other state-of-the-art algorithms},
  archive      = {J_ISCI},
  author       = {Puyu Jiang and Yuansheng Cheng and Jiaxiang Yi and Jun Liu},
  doi          = {10.1016/j.ins.2021.05.015},
  journal      = {Information Sciences},
  pages        = {728-745},
  shortjournal = {Inf. Sci.},
  title        = {An efficient constrained global optimization algorithm with a clustering-assisted multiobjective infill criterion using gaussian process regression for expensive problems},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autoencoder-based deep metric learning for network intrusion
detection. <em>ISCI</em>, <em>569</em>, 706–727. (<a
href="https://doi.org/10.1016/j.ins.2021.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays intrusion detection systems are a mandatory weapon in the war against the ever-increasing amount of network cyber attacks. In this study we illustrate a new intrusion detection method that analyses the flow-based characteristics of the network traffic data. It learns an intrusion detection model by leveraging a deep metric learning methodology that originally combines autoencoders and Triplet networks. In the training stage, two separate autoencoders are trained on historical normal network flows and attacks, respectively. Then a Triplet network is trained to learn the embedding of the feature vector representation of network flows. This embedding moves each flow close to its reconstruction, restored with the autoencoder associated with the same class as the flow, and away from its reconstruction, restored with the autoencoder of the opposite class. The predictive stage assigns each new flow to the class associated with the autoencoder that restores the closest reconstruction of the flow in the embedding space. In this way, the predictive stage takes advantage of the embedding learned in the training stage, achieving a good prediction performance in the detection of new signs of malicious activities in the network traffic. In fact, the proposed methodology leads to better predictive accuracy when compared to competitive intrusion detection architectures on benchmark datasets.},
  archive      = {J_ISCI},
  author       = {Giuseppina Andresini and Annalisa Appice and Donato Malerba},
  doi          = {10.1016/j.ins.2021.05.016},
  journal      = {Information Sciences},
  pages        = {706-727},
  shortjournal = {Inf. Sci.},
  title        = {Autoencoder-based deep metric learning for network intrusion detection},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BDF: A new decision forest algorithm. <em>ISCI</em>,
<em>569</em>, 687–705. (<a
href="https://doi.org/10.1016/j.ins.2021.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The foremost requirement for a decision forest to achieve better ensemble accuracy is building a set of accurate and diverse individual decision trees as base classifiers . Existing decision forest algorithms mainly differ from each other on how they induce diversity among the decision trees . At the same time, most of the drawbacks of existing algorithms originate from their induction processes of diversity. In this paper, we propose a new decision forest algorithm that is more balanced through effective synchronization between different sources of diversity. The proposed algorithm is balanced theoretically and empirically. We carried out experiments on 25 well-known data sets that are publicly available from the UCI Machine Learning Repository, to perform an extensive empirical evaluation. The experimental results indicate that the proposed algorithm has the best average ensemble accuracy rank of 1.8 compared to its closest competitor at 3.5. Using the Friedman and Bonferroni-Dunn tests, we also show that such an improvement is indeed statistically significant. In addition, the proposed algorithm is found to be competitive in terms of complexity and other relevant parameters.},
  archive      = {J_ISCI},
  author       = {Md Nasim Adnan and Ryan H.L. Ip and Michael Bewong and Md Zahidul Islam},
  doi          = {10.1016/j.ins.2021.05.017},
  journal      = {Information Sciences},
  pages        = {687-705},
  shortjournal = {Inf. Sci.},
  title        = {BDF: A new decision forest algorithm},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adapting h-infinity controller for the desired reference
tracking of the sphere position in the maglev process. <em>ISCI</em>,
<em>569</em>, 669–686. (<a
href="https://doi.org/10.1016/j.ins.2021.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Maglev process consists in a magnetic field geerated by the modulation of a coil current which yields the sphere levitation. Foucault current is the current transmitted from the coil to a sphere in the Maglev process which yields the undesired sphere vibrations. In this study, an adapting H-infinity controller is introduced as the combination of the adapting and H-infinity strategies for the desired reference tracking of the sphere position in the Maglev process. The adapting strategy is used for the unknown dynamics estimation, and the H-infinity strategy is used for the desired reference tracking. The Lyapunov technique is used to satisfy the error convergence and the H-infinity criterion. Two simulations show the effectiveness of the considered method for the desired reference tracking of the sphere position in the Maglev process.},
  archive      = {J_ISCI},
  author       = {José de Jesús Rubio and Edwin Lughofer and Jeff Pieper and Panuncio Cruz and Dany Ivan Martinez and Genaro Ochoa and Marco Antonio Islas and Enrique Garcia},
  doi          = {10.1016/j.ins.2021.05.018},
  journal      = {Information Sciences},
  pages        = {669-686},
  shortjournal = {Inf. Sci.},
  title        = {Adapting H-infinity controller for the desired reference tracking of the sphere position in the maglev process},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A three-way clustering approach for novelty detection.
<em>ISCI</em>, <em>569</em>, 650–668. (<a
href="https://doi.org/10.1016/j.ins.2021.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Novelty detection aims to identify novel instances in the test data that differ in some respect from the normal instances in the training data. Novel instances may be defined and interpreted in different ways. We consider a specific interpretation where novel instances are instances from unknown classes which are not seen during the training phase. This is also sometimes referred to as open world classification or open set recognition . A key challenge in this scenario is to design approaches that effectively classify normal instances and reject the classification of novel instances. Three-way decisions may be realized as a useful strategy to deal with this challenge. It provides provision for deferring the decisions of classifying objects whenever the available evidence is not enough. The deferred cases may be realized as novel or unknown since their classification results are not known and not available. Three-way clustering is an important three-way decision model which can be used for the classification of objects by considering classes as clusters in the data. In this paper, we introduce a three-way clustering based algorithm called reduction and elevation based three-way clustering for open world classification or RE3OWC. A three-way cluster consists of a pair of core and support sets. The RE3OWC uses the operations of reduction and elevation to define the core and support of a three-way cluster. The two sets lead to the three regions of inside, partial and outside corresponding to a cluster. The three regions provide the realization of three-way decisions and are used to identify instances from the unknown classes. Experimental results on datasets of 20 Newsgroups and Amazon reviews suggest improvements in commonly and widely used F1 measure by up to 2.3\% and 6.5\%, respectively, in comparisons to some of the best known available approaches of DOC, cbsSVM, openMax and others, for identifying instances from unknown classes.},
  archive      = {J_ISCI},
  author       = {Anwar Shah and Nouman Azam and Bahar Ali and Muhammad Taimoor Khan and JingTao Yao},
  doi          = {10.1016/j.ins.2021.05.021},
  journal      = {Information Sciences},
  pages        = {650-668},
  shortjournal = {Inf. Sci.},
  title        = {A three-way clustering approach for novelty detection},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterisation of environment type and difficulty for
streamed data classification problems. <em>ISCI</em>, <em>569</em>,
615–649. (<a href="https://doi.org/10.1016/j.ins.2021.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SDCP require classifiers with the ability to learn and to adjust to the underlying relationships in data streams in real-time. This requirement poses a challenge to classifiers, because the learning task is no longer just to find the optimal decision boundaries, but also to track changes in the decision boundaries as new training data is received. Each SDCP can be described in terms of its environment and difficulty. The environment of an SDCP describes the rate and magnitude of changes in the decision boundaries in the data streams. On the other hand, the difficulty of an SDCP describes the availability of the data that define the decision boundaries during an environment instance. In any empirical analysis of streamed data classifiers, a set of SDCP is used. Understanding the environment and difficulty of each SDCP allows for a more holistic analysis of empirical results. This article proposes (i) a novel quantitative method for analysing the environment of SDCP, and (ii) a difficulty classification scheme based on the construction of SDCP. The proposed methods are evaluated by applying them to a benchmark suite of SDCP.},
  archive      = {J_ISCI},
  author       = {Mathys Ellis and Anna S. Bosman and Andries P. Engelbrecht},
  doi          = {10.1016/j.ins.2021.05.023},
  journal      = {Information Sciences},
  pages        = {615-649},
  shortjournal = {Inf. Sci.},
  title        = {Characterisation of environment type and difficulty for streamed data classification problems},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multivariate times series classification through an
interpretable representation. <em>ISCI</em>, <em>569</em>, 596–614. (<a
href="https://doi.org/10.1016/j.ins.2021.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series classification is a machine learning task with increasing importance due to the proliferation of information sources in different domains (economy, health, energy, crops, etc.). Univariate methods lack the ability to capture the relationships between the different variables that compose a multivariate time series and therefore cannot be directly extrapolated to multivariate environments. Despite the good performance and competitive results of the multivariate proposals published to date, they are hard to interpret due to their high complexity. In this paper, we propose a multivariate time series classification method based on an alternative representation of the time series, composed of a set of 41 descriptive time series features, in order to improve the interpretability of time series and results obtained. Our proposal uses traditional classifiers over the extracted features to look for relationships between the different variables that form a multivariate time series. We have selected four state-of-the-art algorithms as base classifiers to evaluate our method. We have tested our proposal on the complete University of East Anglia repository, obtaining highly interpretable results capable of explaining the relationships between the features that compose the time series and achieving performance results statistically indistinguishable from the best algorithms of the state-of-the-art.},
  archive      = {J_ISCI},
  author       = {Francisco J. Baldán and José M. Benítez},
  doi          = {10.1016/j.ins.2021.05.024},
  journal      = {Information Sciences},
  pages        = {596-614},
  shortjournal = {Inf. Sci.},
  title        = {Multivariate times series classification through an interpretable representation},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust multi-view graph clustering in latent
energy-preserving embedding space. <em>ISCI</em>, <em>569</em>, 582–595.
(<a href="https://doi.org/10.1016/j.ins.2021.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the powerful capacity of exploring complementary and consistent information by generating a consensus affinity graph from multi-view data, multi-view graph clustering (MVGC) methods have attracted intensive attention. However, multi-view data is usually existed in high-dimensional space, where redundant and irrelevant features may result in the curse of dimensionality . Moreover, original data often mix with noise and outliers that will destroy the underlying clustering structure , such that unreliable and inaccurate affinity graphs will be generated. To alleviate the aforementioned problems, we propose a novel multi-view latent energy-preserving embedding (MLEE) method, which seamlessly integrates the clean embedding space learning and consensus affinity graph learning into a unified objective function. Concretely, for each view, we first learn the low-dimensional yet clean data by proposing a full-energy projection and recovering method. This can well reduce the redundancy and interference in the data. Furthermore, by leveraging adaptive neighbors graph learning (ANGL), the local manifold structure of the clean embedding data can be implicitly preserved. To integrate the complementary and consistent information of different views, an early-fusion scheme is proposed to directly yield a consensus graph for clustering purpose. Experiments on six benchmark datasets demonstrate that our method achieves state-of-the-art clustering performance.},
  archive      = {J_ISCI},
  author       = {Zhenwen Ren and Xingfeng Li and Mithun Mukherjee and Yuqing Huang and Quansen Sun and Zhen Huang},
  doi          = {10.1016/j.ins.2021.05.025},
  journal      = {Information Sciences},
  pages        = {582-595},
  shortjournal = {Inf. Sci.},
  title        = {Robust multi-view graph clustering in latent energy-preserving embedding space},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A novel three-way group investment decision model under
intuitionistic fuzzy multi-attribute group decision-making environment.
<em>ISCI</em>, <em>569</em>, 557–581. (<a
href="https://doi.org/10.1016/j.ins.2021.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision (3WD) provides a new research perspective for dealing with uncertain and complex investment decision-making problems. This paper aims to study a novel three-way group investment decision (3WGID) model under intuitionistic fuzzy multi-attribute group decision-making (MAGDM) environment, which can deepen the understanding of 3WD and expand its applications in profit-based investment decision-making problems. Firstly, we design the calculation methods of the relative cost and revenue functions of alternatives with the aid of attribute values expressed by intuitionistic fuzzy values. Subsequently, aiming at multiple attributes in MAGDM problems, we calculate the aggregated cost and revenue functions of alternatives in each evaluation matrix . Then, we integrate the aggregated cost functions and the aggregated revenue functions to obtain the relative profit functions of alternatives in each evaluation matrix . In the context of group decision-making, we determine the overall profit functions of alternatives by fusing the collective opinions of multiple experts. In addition, considering that there is no decision attribute in MAGDM problems, we use intuitionistic fuzzy TOPSIS method to estimate the conditional probability in each evaluation matrix and calculate the comprehensive conditional probability by an aggregation approach. With these discussions, a 3WGID model is established by Bayesian decision procedure and the maximum-profit principle. Meanwhile, the decision rules and associated profits of alternatives are further induced. Ultimately, a coalfield investment case study, along with a sensitivity analysis and a comparative analysis, is adopted to demonstrate the effectiveness and feasibility of the established 3WGID model.},
  archive      = {J_ISCI},
  author       = {Haibo Jiang and Bao Qing Hu},
  doi          = {10.1016/j.ins.2021.05.026},
  journal      = {Information Sciences},
  pages        = {557-581},
  shortjournal = {Inf. Sci.},
  title        = {A novel three-way group investment decision model under intuitionistic fuzzy multi-attribute group decision-making environment},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Boolean factor based community extraction from directed
networks with the non reciprocal link relationship. <em>ISCI</em>,
<em>569</em>, 544–556. (<a
href="https://doi.org/10.1016/j.ins.2021.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The community extraction from the networks has gained more attention this last decade due to the available data provided by the online social media. This task consists in extracting the homogeneous groups from the network modelled by a graph. The graph models the interaction between entities of the network through the edges. Most of the existing approaches of the community extraction have been designed for the non-directed graph or considered that the relationship between entities is symmetric or reciprocal. In most of the real world application like food web or hierarchical relationship between employees, it is not the case. In this paper, we propose a boolean factor based approach for community detection in directed networks. The main advantage of the boolean factor, based on formal concepts is that, it keeps the relationship between the two sets of related entities. The semantic relationship (non reciprocal) is taken into account during the candidate community extraction process by splitting concept into two parts. The final communities is obtained after refinement of these candidates. We have experimented this approach on some collected directed networks available on internet and the results show the effectiveness of this approach.},
  archive      = {J_ISCI},
  author       = {Norbert Tsopze and Félicité Gamgne Domgue},
  doi          = {10.1016/j.ins.2021.05.027},
  journal      = {Information Sciences},
  pages        = {544-556},
  shortjournal = {Inf. Sci.},
  title        = {Boolean factor based community extraction from directed networks with the non reciprocal link relationship},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered fixed-time adaptive neural dynamic surface
control for stochastic non-triangular structure nonlinear systems.
<em>ISCI</em>, <em>569</em>, 527–543. (<a
href="https://doi.org/10.1016/j.ins.2021.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of event-triggered fixed-time adaptive neural dynamic surface control (DSC) for stochastic non-triangular structure nonlinear systems is discussed in this article. Combined with the fixed-time stability theory, DSC technique and event-triggered control (ETC) technique, a novel event-triggered fixed-time adaptive controller is designed, under which both the closed-loop stability and the tracking performance can be guaranteed simultaneously in a fixed time. At the same time, the problems of “explosion of complexity” and “singularity” under the traditional backstepping design framework are avoided. Moreover, the design of event-triggered control mechanism can save the network resources effectively. In addition, the unknown nonlinear functions are approximated by some radial basis function neural networks (RBFNNs), and the filtering errors are compensated by the novel error compensating signals. Rigorous theoretical derivation and two simulations are included to illustrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yangang Yao and Jieqing Tan and Jian Wu and Xu Zhang},
  doi          = {10.1016/j.ins.2021.05.028},
  journal      = {Information Sciences},
  pages        = {527-543},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered fixed-time adaptive neural dynamic surface control for stochastic non-triangular structure nonlinear systems},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impact of resampling methods and classification models on
the imbalanced credit scoring problems. <em>ISCI</em>, <em>569</em>,
508–526. (<a href="https://doi.org/10.1016/j.ins.2021.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For imbalanced credit scoring, the most common solution is to balance the class distribution of the training set with a resampling method , and then train a classification model and classify the customer samples in the test set. However, it is still difficult to select the most appropriate resampling methods and classification models, and the optimal combinations of them have not been identified. Therefore, this study proposes a new benchmark models comparison framework for imbalanced credit scoring. In the framework, we introduce the index of balanced accuracy and four other evaluation measures, experimentally compare the performance of 10 benchmark resampling methods and nine benchmark classification models respectively on six credit scoring data sets, and analyze the optimal combinations of them. The experimental result shows: (1) as for benchmark resampling methods, random under-sampling (a traditional resampling method) and synthetic minority over-sampling technique combined with Wilson’s edited nearest neighbor (an intelligent resampling method) present the best performance; (2) as for benchmark classification models, logistic regression (a single classification model) and adaptive boosting (an ensemble classification model) present the best performance; (3) as for optimal combinations, random under-sampling combined with random subspace (an ensemble classification model) can obtain the most satisfactory credit scoring performance.},
  archive      = {J_ISCI},
  author       = {Jin Xiao and Yadong Wang and Jing Chen and Ling Xie and Jing Huang},
  doi          = {10.1016/j.ins.2021.05.029},
  journal      = {Information Sciences},
  pages        = {508-526},
  shortjournal = {Inf. Sci.},
  title        = {Impact of resampling methods and classification models on the imbalanced credit scoring problems},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modular neural network via exploring category hierarchy.
<em>ISCI</em>, <em>569</em>, 496–507. (<a
href="https://doi.org/10.1016/j.ins.2021.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modular is a powerful and inherently hierarchical concept in the human brain to process a large variety of complex tasks. Converging evidence has shown several advantages to hierarchically modular network organizations in the human brain such as interpretability and evolvability of network function. Inspired by previous neuroscience studies, we propose MNN-CH, a novel modular neural network that is constructed with explored category hierarchy. The basic idea is learning to learn an optimized category hierarchy to decompose complex patterns. And specific patterns are imposed into corresponding modules to realize a transparent design of the neural network. Specifically, for a given classification task , each class or superclass is first represented as a prototype. Afterward, the category hierarchy is initially determined by investigating class similarity and gather similar ones to train each branch neural network (i.e., modular) separately. Finally, an error-driven prototype learning is introduced to refine the category hierarchy by updating the class-superclass affiliation. Experiment results on several image classification datasets show that our model has a good performance, especially in complex tasks. Beyond, we conduct an analysis to illustrate the tree-manner interpretability of the modular neural network.},
  archive      = {J_ISCI},
  author       = {Wei Han and Changgang Zheng and Rui Zhang and Jinxia Guo and Qinli Yang and Junming Shao},
  doi          = {10.1016/j.ins.2021.05.032},
  journal      = {Information Sciences},
  pages        = {496-507},
  shortjournal = {Inf. Sci.},
  title        = {Modular neural network via exploring category hierarchy},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the role of distance transformations in baddeley’s delta
metric. <em>ISCI</em>, <em>569</em>, 479–495. (<a
href="https://doi.org/10.1016/j.ins.2021.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparison and similarity measurement have been a key topic in computer vision for a long time. There is, indeed, an extensive list of algorithms and measures for image or subimage comparison. The superiority or inferiority of different measures is hard to scrutinize, especially considering the dimensionality of their parameter space and their many different configurations. In this work, we focus on the comparison of binary images , and study different variations of Baddeley’s Delta Metric, a popular metric for such images. We study the possible parameterizations of the metric, stressing the numerical and behavioural impact of different settings. Specifically, we consider the parameter settings proposed by the original author, as well as the substitution of distance transformations by regularized distance transformations, as recently presented by Brunet and Sills. We take a qualitative perspective on the effects of the settings, and also perform quantitative experiments on separability of datasets for boundary evaluation.},
  archive      = {J_ISCI},
  author       = {C. Lopez-Molina and S. Iglesias-Rey and H. Bustince and B. De Baets},
  doi          = {10.1016/j.ins.2021.05.034},
  journal      = {Information Sciences},
  pages        = {479-495},
  shortjournal = {Inf. Sci.},
  title        = {On the role of distance transformations in baddeley’s delta metric},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BBAS: Towards large scale effective ensemble adversarial
attacks against deep neural network learning. <em>ISCI</em>,
<em>569</em>, 469–478. (<a
href="https://doi.org/10.1016/j.ins.2020.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent decades have witnessed rapid development of deep neural networks (DNN). As DNN learning is becoming more and more important to numerous intelligent system, ranging from self driving car to video surveillance system , significant research efforts have been devoted to explore how to improve DNN model’s robustness and reliability against adversarial example attacks. Distinguish from previous study, we address the problem of adversarial training with ensemble based approach and propose a novel boosting based black-box attack scheme call BBAS to facilitate high diverse adversarial example generation. BBAS not only separates example generation from the settings of the trained model but also enhance the diversity of perturbation over class distribution through seamless integration of stratified sampling and ensemble adversarial training . This leads to reliable and effective training example selection. To validate and evaluate the scheme from different perspectives, a set of comprehensive tests have been carried out based on two large open data sets. Experimental results demonstrate the superiority of our method in terms of effectiveness.},
  archive      = {J_ISCI},
  author       = {Jialie Shen and Neil Robertson},
  doi          = {10.1016/j.ins.2020.11.026},
  journal      = {Information Sciences},
  pages        = {469-478},
  shortjournal = {Inf. Sci.},
  title        = {BBAS: Towards large scale effective ensemble adversarial attacks against deep neural network learning},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Cascade tracking control of servo motor with robust
adaptive fuzzy compensation. <em>ISCI</em>, <em>569</em>, 450–468. (<a
href="https://doi.org/10.1016/j.ins.2021.03.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Servo motor drive systems with high-accuracy position tracking control suffer from some uncertainties from inherent mechanical friction and varying end-load. In this paper, a novel cascade controller with feedforward robust adaptive fuzzy compensation is proposed to overcome the negative impacts of the uncertainties. An adaptive fuzzy logic system is used to estimate the friction, which is applied for designing a feedforward compensator to improve the tracking performance. Based on Lyapunov stability theory , we show that closed-loop system can ensure the semi-global asymptotic tracking performance. Our proposed compensation strategy takes advantage of utilizing the cascade P/PI controller without changing the original control system structure, which is practical and valuable to industrial applications. Simulation results indicate some merits of the proposed controll scheme in terms of the system stability, adaptivity and robustness with respect to different uncertainties.},
  archive      = {J_ISCI},
  author       = {Y. Liu and Z.Z. Wang and Y.F. Wang and D.H. Wang and J.F. Xu},
  doi          = {10.1016/j.ins.2021.03.065},
  journal      = {Information Sciences},
  pages        = {450-468},
  shortjournal = {Inf. Sci.},
  title        = {Cascade tracking control of servo motor with robust adaptive fuzzy compensation},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An incremental-learning model-based multiobjective
estimation of distribution algorithm. <em>ISCI</em>, <em>569</em>,
430–449. (<a href="https://doi.org/10.1016/j.ins.2021.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge obtained from the properties of a Pareto-optimal set can guide an evolutionary search. Learning models for multiobjective estimation of distributions have led to improved search efficiency, but they incur a high computational cost owing to their use of a repetitive learning or iterative strategy. To overcome this drawback, we propose an algorithm for incremental-learning model-based multiobjective estimation of distributions. A learning mechanism based on an incremental Gaussian mixture model is embedded within the search procedure. In the proposed algorithm, all new solutions generated during the evolution are passed to a data stream, which is fed incrementally into the learning model to adaptively discover the structure of the Pareto-optimal set. The parameters of the model are updated continually as each newly generated datum is collected. Each datum is learned only once for the model, regardless of whether it has been preserved or deleted. Moreover, a sampling strategy based on the learned model is designed to balance the exploration/exploitation dilemma in the evolutionary search. The proposed algorithm is compared with six state-of-the-art algorithms for several benchmarks. The experimental results show that there is a significant improvement over the representative algorithms.},
  archive      = {J_ISCI},
  author       = {Tingrui Liu and Xin Li and Liguo Tan and Shenmin Song},
  doi          = {10.1016/j.ins.2021.04.011},
  journal      = {Information Sciences},
  pages        = {430-449},
  shortjournal = {Inf. Sci.},
  title        = {An incremental-learning model-based multiobjective estimation of distribution algorithm},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New decision-making methods with interval reciprocal
preference relations: A new admissible order relation of intervals.
<em>ISCI</em>, <em>569</em>, 400–429. (<a
href="https://doi.org/10.1016/j.ins.2021.03.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval reciprocal preference relations (IRPRs) have been extensively applied to real-life decision-making problems. This paper aims at introducing two new decision-making methods with IRPRs. To overcome drawbacks of several extant order relations of intervals, a new admissible order relation of intervals is proposed. An algorithm is then introduced to rank a series of intervals. We define a new consistency index and the satisfactory consistency of IRPRs. For improving the consistency level of IRPRs, a linear programming model is built. Subsequently, a new individual decision-making (IDM) method with an IRPR is introduced. For group decision making, a group consensus index is proposed. To improve the group consensus degree, an interactive convergent iterative algorithm is designed. Decision makers’ weights are determined by combining the logarithmic Manhattan distance between two IRPRs with the consistency indices of IRPRs. Accordingly, a novel consistent and consensus-based group decision-making (GDM) method with IRPRs is presented. Eventually, a decision support system is developed based on the proposed IDM method and GDM method. Illustrative examples and simulation experiments are provided to illustrate the superiority of the proposed IDM method and GDM method.},
  archive      = {J_ISCI},
  author       = {Xianjuan Cheng and Shuping Wan and Jiuying Dong and Luis Martínez},
  doi          = {10.1016/j.ins.2021.03.053},
  journal      = {Information Sciences},
  pages        = {400-429},
  shortjournal = {Inf. Sci.},
  title        = {New decision-making methods with interval reciprocal preference relations: A new admissible order relation of intervals},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensor decomposition-based alternate sub-population
evolution for large-scale many-objective optimization. <em>ISCI</em>,
<em>569</em>, 376–399. (<a
href="https://doi.org/10.1016/j.ins.2021.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel alternate evolution of sub-populations based on tensor decomposition called, TASE is proposed, for solving multi- and many-objective optimization problems with large-scale decision variables in this work. Tensor canonical polyadic (CP) decomposition is introduced for the first time to divide the heterogeneous variables of higher-dimensional decision space into several lower-dimensional sub-components. Furthermore, these sub-populations are optimized alternatively to search for improved solutions in their respective lower-dimensional decision subspace. Finally, a cross-population matching scheme is designed to reconstruct the whole population accurately. The experiments use some largescale multi- and many-objective problems with 2–6 objectives and 1000–5000 variables. The proposed algorithm is compared with other state-of-the-art algorithms, and the experimental results indicate that it can solve some problems that other well-known large-scale optimization algorithms cannot, as well as outperforming other algorithms in terms of solution quality and convergence rate.},
  archive      = {J_ISCI},
  author       = {Qingzhu Wang and Lingling Zhang and Shuang Wei and Bin Li},
  doi          = {10.1016/j.ins.2021.04.003},
  journal      = {Information Sciences},
  pages        = {376-399},
  shortjournal = {Inf. Sci.},
  title        = {Tensor decomposition-based alternate sub-population evolution for large-scale many-objective optimization},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonlinear control using human behavior learning.
<em>ISCI</em>, <em>569</em>, 358–375. (<a
href="https://doi.org/10.1016/j.ins.2021.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we discuss a human behavior learning approach for nonlinear systems control. We use several cognitive models and human skills to model and accelerate the learning process. A neural reinforcement learning algorithm is applied as main cognitive model. A persistent exciting signal and experience replay methods are proposed to improve learning accuracy and overcome the sensitivity problem of the human actions. The stability and convergence of the neural network based reinforcement learning is discussed. Simulations results verify the approach with two benchmark control problems.},
  archive      = {J_ISCI},
  author       = {Adolfo Perrusquía and Wen Yu and Xiaoou Li},
  doi          = {10.1016/j.ins.2021.03.043},
  journal      = {Information Sciences},
  pages        = {358-375},
  shortjournal = {Inf. Sci.},
  title        = {Nonlinear control using human behavior learning},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-based passification of delayed memristive neural
networks. <em>ISCI</em>, <em>569</em>, 344–357. (<a
href="https://doi.org/10.1016/j.ins.2021.03.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the passification issue of delayed memristive neural networks via the event-based control. First, by designing an appropriate controller based on a static event trigger scheme, the passification conditions are deduced for delayed memristive neural networks . Then, under the same controller, the passivity is discussed for the delayed memristive neural network system with a more economical and realistic dynamic event trigger rule. Meanwhile, in order to ensure these two event trigger control schemes are Zeno free, the existence of positive lower bounds are approved for the inter event time. Finally, illustrative examples are elaborated to support the theoretical results.},
  archive      = {J_ISCI},
  author       = {Yuting Cao and Shiqin Wang and Zhenyuan Guo and Tingwen Huang and Shiping Wen},
  doi          = {10.1016/j.ins.2021.03.045},
  journal      = {Information Sciences},
  pages        = {344-357},
  shortjournal = {Inf. Sci.},
  title        = {Event-based passification of delayed memristive neural networks},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ma-CODE: A multi-phase approach on community detection in
evolving networks. <em>ISCI</em>, <em>569</em>, 326–343. (<a
href="https://doi.org/10.1016/j.ins.2021.02.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting communities or clusters in networks becomes a decisive issue in various interdisciplinary areas in recent years. Numerous methods are proposed to uncover community in networks, although the fundamental problem of most of the methods is the evolving nature of the networks and the presence of the imprecise number of communities. Since, real-world networks are scale-free networks and due to the preferential attachment properties, the low degree nodes are attracted towards the hub nodes showing the power-law distributions. Hub nodes are highly surrounded by their neighbors and connectedness among the nodes within a community is larger than the others. As a result, the underlying structural details facilitate to uncover precise community structure. In this work, we present a multi-phase model ma-CODE to uncover communities based on the inherent association without having any prior information about the presence of the number of communities. The multi-phase approach contains the identification of high degree nodes, label propagation and community merging. The high degree nodes are identified based on the voting by the adjacent members; the label propagation is to assign the same community identification number to those members showing high similarity; the community merging is performed among the different communities only when there is a significant increase in the modularity after combination. We examine the competence of our proposed methods in the light of twelve (12) popular real-world social networks and eight (08) artificial networks. Experiments and simulation results using five (05) different statistical assessment parameters show that ma-CODE is superior over contemporary community detection methods.},
  archive      = {J_ISCI},
  author       = {Keshab Nath and Ram Shanmugam and Vijayakumar Varadaranjan},
  doi          = {10.1016/j.ins.2021.02.068},
  journal      = {Information Sciences},
  pages        = {326-343},
  shortjournal = {Inf. Sci.},
  title        = {Ma-CODE: A multi-phase approach on community detection in evolving networks},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Multimodal medical image fusion based on joint bilateral
filter and local gradient energy. <em>ISCI</em>, <em>569</em>, 302–325.
(<a href="https://doi.org/10.1016/j.ins.2021.04.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful assistance technique for biomedical diagnosis, multimodal medical image fusion has emerged as a hot topic in recent years. Unfortunately, the trade-off among fusion performance, time consumption and noise robustness for many medical image fusion algorithms remains an enormous challenge. In this paper, an effective, fast and robust medical image fusion method is proposed. A two-layer decomposition scheme is introduced by the joint bilateral filter, the energy layer containing rich intensity information, and the structure layer capturing ample details. Then a novel local gradient energy operator based on the structure tensor and neighbor energy is proposed to fuse the structure layer and the l 1 -max rule is introduced to fuse the energy layer. A total of 118 co-registered pairs of medical images covering five different categories of medical image fusion problems are tested in experiments. Seven latest representative medical image fusion methods are compared, and six representative quality evaluation metrics with complementary characteristics are fully employed to objectively evaluate the fused results. Extensive experimental results demonstrate that the proposed method yields better performance than some state-of-the-art methods in both visual quality and quantitative evaluation, and achieves nearly real-time computational efficiency and robustness to noise.},
  archive      = {J_ISCI},
  author       = {Xiaosong Li and Fuqiang Zhou and Haishu Tan and Wanning Zhang and Congyang Zhao},
  doi          = {10.1016/j.ins.2021.04.052},
  journal      = {Information Sciences},
  pages        = {302-325},
  shortjournal = {Inf. Sci.},
  title        = {Multimodal medical image fusion based on joint bilateral filter and local gradient energy},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CDAE: Color decomposition-based adversarial examples for
screen devices. <em>ISCI</em>, <em>569</em>, 287–301. (<a
href="https://doi.org/10.1016/j.ins.2021.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial examples can easily fool existing powerful deep neural networks . However, we find that the attack ability of most existing adversarial attack methods is significantly degraded once the generated adversarial examples are shown on screen devices and are further captured. This is mainly attributed to two challenges: (1) Extra noises and variance during the capturing process, such as lens distortion and diverse capturing angle. (2) They get stuck in a self-contradictory problem between visual quality and attack ability. Inspired by the properties of the human visual system (HVS), this paper dedicatedly designs the first color decomposition-based adversarial example method CDAE for screen devices. Specifically, it decomposes one regular screen frame into two symmetric adversarial frames with maximum modifications while theoretically guaranteeing the visual quality perceived by human observers. Thanks to the powerful generalization ability of the proposed method, we can combine it with most adversarial example generation methods and achieve state-of-the-art attack ability. Additionally, it can also be used to protect important information from leakage and attack existing video action recognition networks.},
  archive      = {J_ISCI},
  author       = {Huanyu Bian and Hao Cui and Kunlin Liu and Hang Zhou and Dongdong Chen and Wenbo Zhou and Weiming Zhang and Nenghai Yu},
  doi          = {10.1016/j.ins.2021.04.005},
  journal      = {Information Sciences},
  pages        = {287-301},
  shortjournal = {Inf. Sci.},
  title        = {CDAE: Color decomposition-based adversarial examples for screen devices},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group decision-making based on the aggregation of z-numbers
with archimedean t-norms and t-conorms. <em>ISCI</em>, <em>569</em>,
264–286. (<a href="https://doi.org/10.1016/j.ins.2021.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the information description and aggregation of group decision-making (GDM), this study develops an innovative GDM method based on Z-numbers and their aggregation techniques. The Z-number is a powerful tool for describing real-life information and reflecting information reliability. However, Z-numbers have a complicated three-dimensional structure, and many existing studies did not manage Z-numbers appropriately. Besides, no study has investigated Z-number aggregation considering Z-numbers’ potential probability distributions. To remove the above defects, many valid techniques are introduced. An optimisation model is constructed to determine the potential probability distributions involved in Z-numbers. Then, a mean function for comparing Z-numbers is presented, and a series of Z-number operations are defined based on Archimedean t -norms and t -conorms. Moreover, a Z-number Bonferroni mean aggregation operator for integrating Z-number information is proposed. To test the applicability and validity of the developed Z-number GDM method , a new energy investment selection problem is addressed, and the sensitivity analysis and comparison discussion are conducted. The sensitivity results show that the developed method possesses favourable stability and effectiveness. In addition, the comparison results demonstrate that it outperforms other existing methods, and it can handle existing defects effectively.},
  archive      = {J_ISCI},
  author       = {Hong-gang Peng and Xiao-kang Wang and Hong-Yu Zhang and Jian-qiang Wang},
  doi          = {10.1016/j.ins.2021.04.022},
  journal      = {Information Sciences},
  pages        = {264-286},
  shortjournal = {Inf. Sci.},
  title        = {Group decision-making based on the aggregation of Z-numbers with archimedean t-norms and t-conorms},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interval-valued fractional q-calculus and applications.
<em>ISCI</em>, <em>569</em>, 241–263. (<a
href="https://doi.org/10.1016/j.ins.2021.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the generalized Hukuhara difference, fractional q-differentiability, q-integrability, and fractional q-integrability for interval-valued functions defined on the q -geometric set of real numbers. We show the connections between real-valued and interval-valued derivatives. Furthermore, we present some examples and applications.},
  archive      = {J_ISCI},
  author       = {Awais Younus and Muhammad Asif and Khurram Farhad},
  doi          = {10.1016/j.ins.2021.04.010},
  journal      = {Information Sciences},
  pages        = {241-263},
  shortjournal = {Inf. Sci.},
  title        = {Interval-valued fractional q-calculus and applications},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A privacy image encryption algorithm based on piecewise
coupled map lattice with multi dynamic coupling coefficient.
<em>ISCI</em>, <em>569</em>, 217–240. (<a
href="https://doi.org/10.1016/j.ins.2021.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new tent-multi dynamic piecewise coupled mapping lattice (TMDPCML). Through the comprehensive analysis of the performance test results, TMDPCML system increases the correlation dynamics of spatiotemporal behavior and improves the efficiency of energy diffusion between lattices. Moreover, TMDPCML system has larger parameter space, better chaos and outstanding cryptographic characteristics. Therefore, this paper proposes a privacy image encryption algorithm combined with TMDPCML system. The application of TMDPCML system in private images encryption further proves that TMDPCML system has good chaotic behavior and meets the requirements of cryptography.},
  archive      = {J_ISCI},
  author       = {Xingyuan Wang and Jingjing Yang},
  doi          = {10.1016/j.ins.2021.04.013},
  journal      = {Information Sciences},
  pages        = {217-240},
  shortjournal = {Inf. Sci.},
  title        = {A privacy image encryption algorithm based on piecewise coupled map lattice with multi dynamic coupling coefficient},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic event-triggered output feedback control for a class
of nonlinear systems with time-varying delays. <em>ISCI</em>,
<em>569</em>, 205–216. (<a
href="https://doi.org/10.1016/j.ins.2021.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note studies the problem of dynamic event-triggered output feedback control for a class of nonlinear systems under homogeneous growth condition with unknown growth rate and time delays . Firstly, in order to deal with unknown growth rate and time-varying state delays, a double-gain dynamic scheme is introduced and a suitable Lyapunov–Krasovskii functional is selected. Secondly, a dynamic event-triggered strategy is proposed by introducing the dynamic gain to the event-triggered condition, which makes the triggering threshold be tuned dynamically. Compared with some existing works related to event-triggered strategy, the proposed strategy is more flexible for saving communication resources. Subsequently, a new output feedback control law is developed in the context of event-triggered mechanism to guarantee the boundedness of system signals while the system states globally enter a compact set around the origin. Finally, two examples are given to show the feasibility and merit of the presented scheme.},
  archive      = {J_ISCI},
  author       = {Feng Shu and Junyong Zhai},
  doi          = {10.1016/j.ins.2021.04.020},
  journal      = {Information Sciences},
  pages        = {205-216},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered output feedback control for a class of nonlinear systems with time-varying delays},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Responsive threshold search based memetic algorithm for
balanced minimum sum-of-squares clustering. <em>ISCI</em>, <em>569</em>,
184–204. (<a href="https://doi.org/10.1016/j.ins.2021.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a common task in data mining for constructing well-separated groups (clusters) from a large set of data points. The balanced minimum sum-of-squares clustering problem is a variant of the classic minimum sum-of-squares clustering (MSSC) problem and arises from broad real-life applications where the cardinalities of any two clusters differ by at most one. This study presents the first memetic algorithm for solving the balanced MSSC problem. The proposed algorithm combines a backbone-based crossover operator for generating offspring solutions and a responsive threshold search that alternates between a threshold-based exploration procedure and a descent-based improvement procedure for improving new offspring solutions. Numerical results on 16 real-life datasets show that the proposed algorithm competes very favorably with several state-of-the-art methods from the literature. Key components of the proposed algorithm are investigated to understand their effects on the performance of the algorithm.},
  archive      = {J_ISCI},
  author       = {Qing Zhou and Jin-Kao Hao and Qinghua Wu},
  doi          = {10.1016/j.ins.2021.04.014},
  journal      = {Information Sciences},
  pages        = {184-204},
  shortjournal = {Inf. Sci.},
  title        = {Responsive threshold search based memetic algorithm for balanced minimum sum-of-squares clustering},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-granularity locally optimal prototype-based approach
for classification. <em>ISCI</em>, <em>569</em>, 157–183. (<a
href="https://doi.org/10.1016/j.ins.2021.04.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prototype-based approaches generally provide better explainability and are widely used for classification. However, the majority of them suffer from system obesity and lack transparency on complex problems. In this paper, a novel classification approach with a multi-layered system structure self-organized from data is proposed. This approach is able to identify local peaks of multi-modal density derived from static data and filter out more representative ones at multiple levels of granularity acting as prototypes. These prototypes are then optimized to their locally optimal positions in the data space and arranged in layers with meaningful dense links in-between to form pyramidal hierarchies based on the respective levels of granularity accordingly. After being primed offline, the constructed classification model is capable of self-developing continuously from streaming data to self-expend its knowledge base. The proposed approach offers higher transparency and is convenient for visualization thanks to the hierarchical nested architecture. Its system identification process is objective, data-driven and free from prior assumptions on data generation model with user- and problem- specific parameters. Its decision-making process follows the “nearest prototype” principle, and is highly explainable and traceable. Numerical examples on a wide range of benchmark problems demonstrate its high performance.},
  archive      = {J_ISCI},
  author       = {Xiaowei Gu and Miqing Li},
  doi          = {10.1016/j.ins.2021.04.039},
  journal      = {Information Sciences},
  pages        = {157-183},
  shortjournal = {Inf. Sci.},
  title        = {A multi-granularity locally optimal prototype-based approach for classification},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leave or not leave? Group members’ departure prediction in
dynamic information networks. <em>ISCI</em>, <em>569</em>, 138–156. (<a
href="https://doi.org/10.1016/j.ins.2021.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic information networks, containing evolving nodes and links, exist in various applications. For example, in a Facebook network, nodes represent users, links represent friendship, and users often form different groups. Over time, some users will leave some groups. Thus, for both users and groups, it’s meaningful to predict which users would leave which groups. Existing studies consider that a user is more likely to leave if most of his/her friends leave. However, in reality, the low-degree nodes usually make up the majority of all nodes and there exist some users with very few friends but keeping staying in a group. Therefore, it might lead to precision loss if only neighborhood information is utilized, but previous work ignored this. To improve prediction precision, we firstly introduce novel definitions of a group’s activeness and a user’s own activeness respectively. Then we propose the group-combined activeness score of each user so that a user with a lower score would be more possible to leave. After that, we present an unsupervised prediction algorithm to continuously predict group members’ departure behaviors in a dynamic information network. Experiments on several real datasets show the effectiveness, efficiency and superiority of our algorithm compared with the state-of-the-art competitors.},
  archive      = {J_ISCI},
  author       = {Xinrui Wang and Hong Gao and Zhipeng Cai and Jianzhong Li},
  doi          = {10.1016/j.ins.2021.04.015},
  journal      = {Information Sciences},
  pages        = {138-156},
  shortjournal = {Inf. Sci.},
  title        = {Leave or not leave? group members’ departure prediction in dynamic information networks},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Fusion of latent categorical prediction and sequential
prediction for session-based recommendation. <em>ISCI</em>,
<em>569</em>, 125–137. (<a
href="https://doi.org/10.1016/j.ins.2021.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation is to predict the next item for an anonymous item sequence. Most of recent neural models have focused on how to learn sessions’ sequential representations based on the assumption that items can be projected into a single latent embedding space to describe their latent attributes. In this paper, we argue that an item can also be described by some latent categorical abstractions. To examine our argument, we first mine items’ latent categorical distributions via random walk on an item graph constructed from sessions. We design a new neural model which consists of two prediction modules: One is to learn a session’s latent categorical representation; The other is to learn a session’s sequential representation. Each module independently makes a next item prediction, and their predictions are fused as the final recommendation result. Experiments on three public datasets validate that our model achieves performance improvements over the recent state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Zizhuo Zhang and Bang Wang},
  doi          = {10.1016/j.ins.2021.04.019},
  journal      = {Information Sciences},
  pages        = {125-137},
  shortjournal = {Inf. Sci.},
  title        = {Fusion of latent categorical prediction and sequential prediction for session-based recommendation},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improvement of rough sets’ accuracy measure using
containment neighborhoods with a medical application. <em>ISCI</em>,
<em>569</em>, 110–124. (<a
href="https://doi.org/10.1016/j.ins.2021.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rough set theory is a nonstatistical mathematical approach to address the issues of vagueness and uncertain knowledge. The rationale of this theory relies on associating a subset with two crisp sets called lower and upper approximations which are utilized to determine the boundary region and accuracy measure of that subset. Neighborhoods systems are pivotal technique to reduce the boundary region and improve the accuracy measure. Therefore, we aim through this paper to introduce new types of neighborhoods called containment neighborhoods (briefly, C j Cj -neighborhoods). They are defined depending on the inclusion relations between j -neighborhoods under arbitrary binary relation . We study their relationships with some previous types of neighborhoods, and determine the conditions under which they are equivalent. Then, we applied C j Cj -neighborhoods to present the concepts of C j Cj -lower and C j Cj -upper approximations and reveal main properties with the help of examples. We also prove that a C j Cj -accuracy measure is the highest in cases of j = i , 〈 i 〉 j=i,〈i〉 . Furthermore, we compare our approach with two approaches given in published literatures and show that accuracy measure induced from our technique is the best. Finally, we successfully applied C j Cj -neighborhoods, N j Nj -neighborhoods and E j Ej -neighborhoods in a medical application aiming to classify medical staff in terms of suspected infection with the new corona-virus (COVID-19).},
  archive      = {J_ISCI},
  author       = {Tareq M. Al-shami},
  doi          = {10.1016/j.ins.2021.04.016},
  journal      = {Information Sciences},
  pages        = {110-124},
  shortjournal = {Inf. Sci.},
  title        = {An improvement of rough sets’ accuracy measure using containment neighborhoods with a medical application},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Augmented skeleton based contrastive action learning with
momentum LSTM for unsupervised action recognition. <em>ISCI</em>,
<em>569</em>, 90–109. (<a
href="https://doi.org/10.1016/j.ins.2021.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition via 3D skeleton data is an emerging important topic. Most existing methods rely on hand-crafted descriptors to recognize actions, or perform supervised action representation learning with massive labels. In this paper, we for the first time propose a contrastive action learning paradigm named AS-CAL that exploits different augmentations of unlabeled skeleton sequences to learn action representations in an unsupervised manner. Specifically, we first propose to contrast similarity between augmented instances of the input skeleton sequence, which are transformed with multiple novel augmentation strategies, to learn inherent action patterns (“ pattern-invariance ”) in different skeleton transformations. Second, to encourage learning the pattern-invariance with more consistent action representations, we propose a momentum LSTM , which is implemented as the momentum-based moving average of LSTM based query encoder, to encode long-term action dynamics of the key sequence. Third, we introduce a queue to store the encoded keys, which allows flexibly reusing proceeding keys to build a consistent dictionary to facilitate contrastive learning . Last, we propose a novel representation named Contrastive Action Encoding (CAE) to represent human’s action effectively. Empirical evaluations show that our approach significantly outperforms hand-crafted methods by 10–50\% Top-1 accuracy, and it can even achieve superior performance to many supervised learning methods (Our codes are available at https://github.com/Mikexu007/AS-CAL ).},
  archive      = {J_ISCI},
  author       = {Haocong Rao and Shihao Xu and Xiping Hu and Jun Cheng and Bin Hu},
  doi          = {10.1016/j.ins.2021.04.023},
  journal      = {Information Sciences},
  pages        = {90-109},
  shortjournal = {Inf. Sci.},
  title        = {Augmented skeleton based contrastive action learning with momentum LSTM for unsupervised action recognition},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved CBSO: A distributed fuzzy-based adaptive synthetic
oversampling algorithm for imbalanced judicial data. <em>ISCI</em>,
<em>569</em>, 70–89. (<a
href="https://doi.org/10.1016/j.ins.2021.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data problem is a big challenge for judicial data analysis since it often leads to a low accuracy of the data classification . Synthesizing new samples by means of oversampling is a useful method to handle this problem. However, most oversampling algorithms have been obtained regardless of noise samples and the data distribution has not been fully taken into consideration. For this purpose, an improved cluster-based synthetic oversampling algorithm, namely distributed fuzzy-based adaptive synthetic oversampling (DFBASO) algorithm, is proposed by simultaneously considering the distribution of inter-class, the distribution of intra-cluster and the characteristic of noise samples. The proposed DFBASO algorithm is equipped with: 1) fuzzy c-means (FCM) clustering algorithm application for samples of minority and majority classes; 2) weighted distribution based on two factors including the inter-class distance and the cluster capacity; and 3) a mixed synthetic method under different distribution cases of intra-cluster. Finally, the judicial data set and eight public data sets are utilized to show the effectiveness and universal applicability of the proposed DFBASO algorithm for the imbalanced data classification .},
  archive      = {J_ISCI},
  author       = {Feifan Dai and Yan Song and Weiyun Si and Guisong Yang and Jianhua Hu and Xinli Wang},
  doi          = {10.1016/j.ins.2021.04.017},
  journal      = {Information Sciences},
  pages        = {70-89},
  shortjournal = {Inf. Sci.},
  title        = {Improved CBSO: A distributed fuzzy-based adaptive synthetic oversampling algorithm for imbalanced judicial data},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive sliding mode control of hydraulic systems with the
event trigger and finite-time disturbance observer. <em>ISCI</em>,
<em>569</em>, 55–69. (<a
href="https://doi.org/10.1016/j.ins.2021.03.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a class of hydraulic servo system control problems with digital communication constraints and model uncertainty. A cooperative design method of adaptive robust sliding mode controller with event trigger strategy and the finite time disturbance observer is proposed. The introduced event trigger strategy can remove a large amount of redundant data and release the communication bandwidth. Besides, the non-matching interference can be accurately estimated by the finite time disturbance observer, and the uncertainty of the matching parameter can be online through the proposed parameter adaptation update. Theoretical analysis shows that the control algorithm not only maintains the asymptotic stability of the hemisphere but also enables the reachability of a given sliding surface. Finally, the simulation results also verify the feasibility and validity of the theoretical resultss.},
  archive      = {J_ISCI},
  author       = {Wei Shen and Shuai Liu and Ming Liu},
  doi          = {10.1016/j.ins.2021.03.051},
  journal      = {Information Sciences},
  pages        = {55-69},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive sliding mode control of hydraulic systems with the event trigger and finite-time disturbance observer},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Evidence integration credal classification algorithm versus
missing data distributions. <em>ISCI</em>, <em>569</em>, 39–54. (<a
href="https://doi.org/10.1016/j.ins.2021.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In complex incomplete pattern classification, the classification results produced by a single classifier and used for decision-making may be quite unreliable and uncertain due to the random distribution of missing data. This paper proposes a new evidence integration credal classification algorithm (EICA) for multiple classifiers working on different attributes, aiming to reduce the negative impact on incomplete pattern classification by modeling the missing values locally. In EICA, the dataset is first grouped into several subsets, and missing values in each subset are estimated by similar subpatterns with different weights. The similarity is measured by discounting the overall similarity of subpatterns and the local similarity of attributes on the basis of fully exploiting the distribution characteristics of the attributes. The greater the variation in distribution across classes, the greater the weight. The classification results of the edited subpatterns with different discounting factors obtained by the optimization function can often provide (more or less) useful information for the classification of the query pattern. Thus, these discounted pieces of evidence (outputs) represented by basic belief assignments (BBAs) are globally fused to classify the query pattern on the basis of evidence theory . The validity has been demonstrated with various real datasets.},
  archive      = {J_ISCI},
  author       = {Zuo-wei Zhang and Zhe Liu and Zong-fa Ma and Ji-huan He and Xing-yu Zhu},
  doi          = {10.1016/j.ins.2021.04.008},
  journal      = {Information Sciences},
  pages        = {39-54},
  shortjournal = {Inf. Sci.},
  title        = {Evidence integration credal classification algorithm versus missing data distributions},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-way decision based on third-generation prospect theory
with z-numbers. <em>ISCI</em>, <em>569</em>, 13–38. (<a
href="https://doi.org/10.1016/j.ins.2021.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision provides a practical and updated research orientation to deal with decision problems. In this article, a new three-way decision model combined with Z-numbers and third-generation prospect theory is proposed. To construct the proposed model, Z-numbers are utilized to depict the decision information containing in the outcome matrix, uncertain reference points, and information table. All the Z-numbers are transformed into triangular fuzzy numbers for better calculating and processing to achieve this goal. The triangular fuzzy value functions and cumulative decision weights of the proposed model are determined based on third-generation prospect theory to derive maximum-prospect-value decision rules. Then, the properties and thresholds of decision rules are discussed and analyzed under Z-information environment. Considering a universal circumstance that there are no decision attributes in the information system, we utilize two multi-attribute decision-making methods with Z-numbers to estimate the conditional probability . Both two methods involve third-generation prospect theory for representing the risk attitude and preference of decision-makers. An illustrative example of the task assessment problem is presented to verify the efficacy of our model. Finally, we take the comparative analysis and some experiments to show the proposed model’s performance and characteristics.},
  archive      = {J_ISCI},
  author       = {Tianxing Wang and Huaxiong Li and Xianzhong Zhou and Dun Liu and Bing Huang},
  doi          = {10.1016/j.ins.2021.04.001},
  journal      = {Information Sciences},
  pages        = {13-38},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision based on third-generation prospect theory with Z-numbers},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep kernel supervised hashing for node classification in
structural networks. <em>ISCI</em>, <em>569</em>, 1–12. (<a
href="https://doi.org/10.1016/j.ins.2021.03.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node classification in structural networks is a longstanding important problem in many real-world applications. Recent studies have shown that network embedding can greatly facilitate node classification by employing embedding algorithms to learn feature representations of nodes. Despite of promising performance, existing network embedding based methods are hard to capture the actual category features of a node because of the linearly inseparable problem in low-dimensional space; meanwhile they cannot incorporate both network structure information and node labels information into the representations simultaneously. To address the above problems, this paper presents a novel Deep Kernel Supervised Hashing (DKSH) method to learn hashing representations of nodes for node classification. Specifically, a deep multiple kernel learning is first employed to map nodes into suitable Hilbert space to deal with linearly inseparable problem. Then, instead of only considering structural similarity between two nodes, a novel similarity matrix is designed to merge both network structure information and node labels information. Supervised by the similarity matrix , the learned hashing representations can preserve the two kinds of information simultaneously from the learned Hilbert space . Extensive experiments show that the proposed method significantly outperforms the state-of-the-art baselines over three real-world benchmark datasets.},
  archive      = {J_ISCI},
  author       = {Jia-Nan Guo and Xian-Ling Mao and Shu-Yang Lin and Wei Wei and Heyan Huang},
  doi          = {10.1016/j.ins.2021.03.068},
  journal      = {Information Sciences},
  pages        = {1-12},
  shortjournal = {Inf. Sci.},
  title        = {Deep kernel supervised hashing for node classification in structural networks},
  volume       = {569},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical feature selection with multi-granularity
clustering structure. <em>ISCI</em>, <em>568</em>, 448–462. (<a
href="https://doi.org/10.1016/j.ins.2021.04.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical feature selection addresses the issues caused by the presence of high-dimensional features in multi-category classification systems with hierarchical structures. Granular calculations are made to analyze the hierarchical relationships among categories when selecting the optimal feature subset. However, semantic hierarchy-based feature selection methods are prone to the semantic gap problem, which affects classification accuracy . In this paper, we propose a hierarchical feature selection method with a multi-granularity clustering structure that can effectively alleviate the semantic gap problem. Firstly, a hierarchical structure is constructed via bottom-up multi-granularity clustering based on feature similarities rather than semantic categories. This clustering hierarchy is conducive to solving semantic gap problems in the existing hierarchy. Secondly, the optimal feature subset is selected using the ℓ 1 , 2 ℓ1,2 -norms in each hierarchy’s granularity layer. This joint minimization approach can retain both the granularity layers’ shared features and granularity-specific features. Finally, we execute hierarchical classification according to the granular structure in a coarse to fine sequence. Extensive experiments demonstrate that the proposed method outperforms several state-of-the-art hierarchical feature selection approaches.},
  archive      = {J_ISCI},
  author       = {Shunxin Guo and Hong Zhao and Wenyuan Yang},
  doi          = {10.1016/j.ins.2021.04.046},
  journal      = {Information Sciences},
  pages        = {448-462},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical feature selection with multi-granularity clustering structure},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel method for automated congestive heart failure and
coronary artery disease recognition using THC-net. <em>ISCI</em>,
<em>568</em>, 427–447. (<a
href="https://doi.org/10.1016/j.ins.2021.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coronary artery disease (CAD) and congestive heart failure (CHF) lead to many deaths worldwide. Generally, an electrocardiogram (ECG) is employed as the diagnostic tool for CAD/CHF recognition. However, since ECG changes are sometimes subtle, visually distinguishing long-term ECG abnormalities is time consuming and laborious. To address these issues, we proposed a novel two-channel hybrid convolutional network (THC-Net) for automatic ECG recognition. THC-Net contains a canonical correlation analysis (CCA)-principal component analysis (PCA) convolutional network , an independent component analysis (ICA)-PCA convolutional network, and a Dempster-Shafer (D-S) theory-based linear support vector machine (SVM). The CCA-PCA and ICA-PCA convolutional networks are developed to extract deep features containing the lead-correlation and lead-specific information, respectively, from ECGs. Compared to common convolutional neural networks (CNNs), their kernels can be directly extracted by CCA, ICA, and PCA with a faster training time. Then, the D-S theory-based linear SVM, which can process multi-channel uncertainty information, is employed as the classification model . In this work, an accuracy of 95.54\% was obtained for classifying normal, CHF and CAD patients based on leave-one-out cross-validation. Additionally, experiments on multi-level noisy and imbalanced data yielded remarkable results. Hence, the proposed method has the potential to diagnose CAD and CHF in clinical settings.},
  archive      = {J_ISCI},
  author       = {Weiyi Yang and Yujuan Si and Gong Zhang and Di Wang and Meiqi Sun and Wei Fan and Xin Liu and Liangliang Li},
  doi          = {10.1016/j.ins.2021.04.036},
  journal      = {Information Sciences},
  pages        = {427-447},
  shortjournal = {Inf. Sci.},
  title        = {A novel method for automated congestive heart failure and coronary artery disease recognition using THC-net},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bilingual autoencoder-based efficient harmonization of
multi-source private data for accurate predictive modeling.
<em>ISCI</em>, <em>568</em>, 403–426. (<a
href="https://doi.org/10.1016/j.ins.2021.03.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sharing electronic health record data is essential for advanced analysis, but may put sensitive information at risk. Several studies have attempted to address this risk using contextual embedding, but with many hospitals involved, they are often inefficient and inflexible. Thus, we propose a bilingual autoencoder-based model to harmonize local embeddings in different spaces. Cross-hospital reconstruction of embeddings makes encoders map embeddings from hospitals to a shared space and align them spontaneously. We also suggest two-phase training to prevent distortion of embeddings during harmonization with hospitals that have biased information. In experiments, we used medical event sequences from the Medical Information Mart for Intensive Care-III dataset and simulated the situation of multiple hospitals. For evaluation, we measured the alignment of events from different hospitals and the prediction accuracy of a patient’s diagnosis in the next admission in three scenarios in which local embeddings do not work. The proposed method efficiently harmonizes embeddings in different spaces, increases prediction accuracy, and gives flexibility to include new hospitals, so is superior to previous methods in most cases. It will be useful in predictive tasks to utilize distributed data while preserving private information.},
  archive      = {J_ISCI},
  author       = {Taek-Ho Lee and Junghye Lee and Chi-Hyuck Jun},
  doi          = {10.1016/j.ins.2021.03.064},
  journal      = {Information Sciences},
  pages        = {403-426},
  shortjournal = {Inf. Sci.},
  title        = {Bilingual autoencoder-based efficient harmonization of multi-source private data for accurate predictive modeling},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influence maximization algorithm based on gaussian
propagation model. <em>ISCI</em>, <em>568</em>, 386–402. (<a
href="https://doi.org/10.1016/j.ins.2021.04.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The influence of each entity in a network is a crucial index of the network information dissemination. Greedy influence maximization algorithms suffer from time efficiency and scalability issues. In contrast, heuristic influence maximization algorithms improve efficiency, but they cannot guarantee accurate results. Considering this, this paper proposes a Gaussian propagation model based on the social networks. Multi-dimensional space modeling is constructed by offset, motif, and degree dimensions for propagation simulation. This space’s circumstances are controlled by some influence diffusion parameters. An influence maximization algorithm is proposed under this model, and this paper uses an improved CELF algorithm to accelerate the influence maximization algorithm. Further, the paper evaluates the effectiveness of the influence maximization algorithm based on the Gaussian propagation model supported by theoretical proofs. Extensive experiments are conducted to compare the effectiveness and efficiency of a series of influence maximization algorithms. The results of the experiments demonstrate that the proposed algorithm shows significant improvement in both effectiveness and efficiency.},
  archive      = {J_ISCI},
  author       = {WeiMin Li and Zheng Li and Alex Munyole Luvembe and Chao Yang},
  doi          = {10.1016/j.ins.2021.04.061},
  journal      = {Information Sciences},
  pages        = {386-402},
  shortjournal = {Inf. Sci.},
  title        = {Influence maximization algorithm based on gaussian propagation model},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrigendum to “distributivity and conditional
distributivity for t-uninorms” [inform. Sci., (424) (2018) 91–103].
<em>ISCI</em>, <em>568</em>, 384–385. (<a
href="https://doi.org/10.1016/j.ins.2021.04.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Some clarifications on the role of element e , so called the IFC element, of a T -uninorm are given.},
  archive      = {J_ISCI},
  author       = {Dragan Jočić and Ivana Štajner-Papuga},
  doi          = {10.1016/j.ins.2021.04.049},
  journal      = {Information Sciences},
  pages        = {384-385},
  shortjournal = {Inf. Sci.},
  title        = {Corrigendum to “Distributivity and conditional distributivity for T-uninorms” [Inform. sci., (424) (2018) 91–103]},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Multiattribute decision making based on the improved
intuitionistic fuzzy einstein weighted averaging operator of
intuitionistic fuzzy values. <em>ISCI</em>, <em>568</em>, 369–383. (<a
href="https://doi.org/10.1016/j.ins.2021.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes the improved intuitionistic fuzzy Einstein weighted averaging (IIFEWA) operator of intuitionistic fuzzy values (IFVs). The proposed IIFEWA operator can overcome the drawbacks of the intuitionistic fuzzy Einstein improved weighted averaging (IFEIWA) operator, the intuitionistic fuzzy Hamacher improved weighted averaging (IFHIWA) operator, the intuitionistic fuzzy Hamacher weighted averaging (IFHWA) operator, the intuitionistic fuzzy Einstein weighted averaging ( I F W A ω ε IFWAωε ) operator, the intuitionistic fuzzy weighted averaging (IFWA) operator and the intuitionistic fuzzy Hamacher interactive ordered weighted averaging (IFHIOWA) operator of IFVs, where they have the drawbacks that (1) the membership grades and the non-membership grades of their obtained aggregating IFVs are indeterminated in some situations and (2) if there is only one IFV whose membership grade is equal to 1, then the membership grade of the aggregated IFV of n n IFVs becomes 1; if there is only one IFV whose non-membership grade is equal to 0, then the non-membership grade of the aggregated IFV of n n IFVs becomes 0. Based on the proposed IIFEWA operator, we propose a new multiattribute decision making (MADM) method. The proposed MADM method overcomes the drawbacks of the existing MADM methods, where they cannot distinguish the ranking orders of alternatives in some situations.},
  archive      = {J_ISCI},
  author       = {Kamal Kumar and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2021.03.020},
  journal      = {Information Sciences},
  pages        = {369-383},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making based on the improved intuitionistic fuzzy einstein weighted averaging operator of intuitionistic fuzzy values},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained similarity fusion for multi-view spectral
clustering. <em>ISCI</em>, <em>568</em>, 350–368. (<a
href="https://doi.org/10.1016/j.ins.2021.03.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in multi-view clustering have attracted significant attention. However, many methods suffer from high time complexity or difficulty in tuning their parameters. Moreover, in multi-view clustering, it is very common to allocate weights to different views for ensuring adequate utilization of information from multi-view data. Most methods allocate the same weight to every view, whereas some methods attempt to learn the optimal weight of each view. Since multi-view clustering can be deemed as a task of fusion, we propose a novel method, Fine-grained sImilariTy fuSion for Multi-view Spectral Clustering (FITS-MSC), which can address the problem that exists when assigning the same weight to instances in one view (coarse-grained information fusion): some samples may be corrupted or missing in partial views whereas others remain intact in all views. To obtain promising results, we employ sparse subspace clustering for constructing the initial similarity matrices. Additionally, to address the deficiency of coarse-grained information fusion, we design a fine-grained similarity fusion strategy for obtaining the final consensus affinity matrix. In the fusion process, the local inter-view and global intra-view weight relationships are explored. With only one parameter, FITS-MSC is very practical. Experiments on real-world datasets demonstrate the advantages of our method.},
  archive      = {J_ISCI},
  author       = {Xiao Yu and Hui Liu and Yan Wu and Caiming Zhang},
  doi          = {10.1016/j.ins.2021.03.059},
  journal      = {Information Sciences},
  pages        = {350-368},
  shortjournal = {Inf. Sci.},
  title        = {Fine-grained similarity fusion for multi-view spectral clustering},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise-free attribute-oriented induction. <em>ISCI</em>,
<em>568</em>, 333–349. (<a
href="https://doi.org/10.1016/j.ins.2021.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute-oriented induction (AOI) was originally developed to facilitate the mining of generalized knowledge in relational databases . Input data for the AOI method comprises a relational table and a concept tree for each attribute. The output is a small relation that contains a number of generalized tuples which summarize the general characteristics of the relational table . Ideally, the generalized tuples shown in the induction table represent the patterns of information that appear in the table. However, if the input data contains a large amount of noise, the generalized tuples may contain too little information to be useful. Existing research into AOI has yet to focus on the elimination of noise. To fill this gap, we developed two noise-free AOI algorithms that filter out noise to enhance the specificity of AOI results.},
  archive      = {J_ISCI},
  author       = {Hsiao-Wei Hu and Yen-Liang Chen and Jia-Yu Hong},
  doi          = {10.1016/j.ins.2021.04.002},
  journal      = {Information Sciences},
  pages        = {333-349},
  shortjournal = {Inf. Sci.},
  title        = {Noise-free attribute-oriented induction},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The longitudinal research of type-2 fuzzy sets domain: From
conceptual structure and knowledge diffusion perspectives.
<em>ISCI</em>, <em>568</em>, 317–332. (<a
href="https://doi.org/10.1016/j.ins.2021.03.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, more scholars and practitioners are committed to improving and applying type-2 fuzzy sets (T2FSs) in various domains because of the stronger ability to handle the uncertainty of fuzzy complex systems. To explore the status and internal laws of development of this field, this paper presents the development overview based on the bibliometric analysis, then the dynamic evolution of main topics and the knowledge diffusion trajectory are also displayed on the basis of the strategy diagram and main path analysis (MPA). From 1997 to 2019, 1749 documents are retrieved from Web of Science (WoS) repository for the analysis. The results show that there are four stable collaborative communities existing in the countries/regions’ collaborative network and the collaboration is affected by geographical factors to some degree. Three main evolution paths of hot topics are also presented in this paper and the multi-criteria decision-making (MCDM) has gradually developed into the moto theme. Furthermore, articles appearing on the main path mainly focus on the research of basic concept and framework, self-optimization and applications in various domains of T2FSs. In general, this paper provides a new landscape in the longitudinal research based on the development overview, thematic evolution and the knowledge diffusion trajectory.},
  archive      = {J_ISCI},
  author       = {Dejian Yu and Yitong Chen and Zeshui Xu},
  doi          = {10.1016/j.ins.2021.03.061},
  journal      = {Information Sciences},
  pages        = {317-332},
  shortjournal = {Inf. Sci.},
  title        = {The longitudinal research of type-2 fuzzy sets domain: From conceptual structure and knowledge diffusion perspectives},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards reducing delegation overhead in replication-based
verification: An incentive-compatible rational delegation computing
scheme. <em>ISCI</em>, <em>568</em>, 286–316. (<a
href="https://doi.org/10.1016/j.ins.2021.03.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the verifiable problem of delegation computing in cloud, which means a client needs to outsource a computing function to untrusted servers, and verify the returned computational results. A recently related result of Dong et al. (CCS 2017) shows a client outsources the same computation task to two different servers, which achieves verifiability by simply cross-checking. In Dong’s replication-based scheme, although the expensive cryptographic algorithms for verification is not needed, the delegation overhead is double. In order to reduce delegation overhead of Dong’s scheme, we propose a novel incentive-compatible rational delegation computing scheme. Specifically, the client sends duplicate tasks to some servers for cross-checking, meanwhile, each sever only knows the probability distribution of receiving a duplicate task. Furthermore, considering rational delegation computing as a dynamic game with imperfect information , we design reasonable and effective incentive mechanisms. Afterwards, we seek a unique sequential equilibrium in each game, and strictly prove that rational players still have no motivation to deviate from honest behavior under a condition of lower delegation overhead. Detailed analysis indicates that the lowest delegation overhead achieved by our scheme is only n 2 n - 2 n2n-2 of that achieved by Dong’s scheme, where n means the number of servers.},
  archive      = {J_ISCI},
  author       = {Zerui Chen and Youliang Tian and Jinbo Xiong and Changgen Peng and Jianfeng Ma},
  doi          = {10.1016/j.ins.2021.03.047},
  journal      = {Information Sciences},
  pages        = {286-316},
  shortjournal = {Inf. Sci.},
  title        = {Towards reducing delegation overhead in replication-based verification: An incentive-compatible rational delegation computing scheme},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient face detection and tracking in video sequences
based on deep learning. <em>ISCI</em>, <em>568</em>, 265–285. (<a
href="https://doi.org/10.1016/j.ins.2021.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video-based face detection and tracking technology has been widely used in video surveillance, safe driving, and medical diagnosis. In video sequences, most existing face detection and tracking methods face interference caused by occlusion, ambient illumination, and changes in human posture. To accurately track human faces in video sequences, we propose an efficient face detection and tracking framework based on deep learning, which includes a SENResNet face detection model and a Regression Network-based Face Tracking (RNFT) model. Firstly, the SENResNet model integrates the Squeeze and Excitation Network (SEN) with the Residual Neural Network (ResNet). To solve the problem that deep neural networks are difficult to train, we use ResNet to overcome the problem of gradient disappearance in deep network training. To fuse the features of each channel during the convolution operation, we further integrate the SEN module into the SENResNet model. SENResNet accurately detects facial information in each frame and extracts the position of the target face, thereby providing an initialization window for face tracking. Then, the RNFT model extracts facial features from adjacent frames and predict the position of the target face in the next frame. To address the problem of feature scaling, we add a correction network to the RNFT model. The improved RNFT model extracts the rectangular frame of the target face in the previous frame and strengthens the perception of feature scaling, thereby improving its accuracy. Extensive experimental results on public facial and video datasets show that the proposed SENResNet and RNFT models are superior to the state-of-the-art comparison methods in terms of accuracy and performance.},
  archive      = {J_ISCI},
  author       = {Guangyong Zheng and Yuming Xu},
  doi          = {10.1016/j.ins.2021.03.027},
  journal      = {Information Sciences},
  pages        = {265-285},
  shortjournal = {Inf. Sci.},
  title        = {Efficient face detection and tracking in video sequences based on deep learning},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient algorithms for mining frequent high utility
sequences with constraints. <em>ISCI</em>, <em>568</em>, 239–264. (<a
href="https://doi.org/10.1016/j.ins.2021.01.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important data mining task is to discover all high utility sequences in a quantitative sequence database. Although useful, the number of discovered sequences is often very large. To find patterns that are more tailored to a user’s needs, this paper studies the problem of mining frequent high utility sequences satisfying item constraints. This article proposes a novel algorithm named C-FHUSM to quickly obtain these sequences from two concise representations discovered from a quantitative sequence database, namely frequent generator high utility sequences and frequent closed high utility sequences. The first set is extracted using a novel algorithm named FGenHUSM, while an existing algorithm is applied to extract the second set. C-FHUSM integrates novel pruning techniques to ignore sequences that do not satisfy item constraints early by checking only a small number of representative sequences at the beginning of the mining process. Experimental results show that C-FHUSM can be more than ten times faster and has better scalability than a modified version of the state-of-the-art EHUSM algorithm for mining sequences with item constraints. Moreover, it is found that using C-FHUSM is beneficial when a user frequently changes constraints as results can be updated without rescanning the database.},
  archive      = {J_ISCI},
  author       = {Tin Truong and Hai Duong and Bac Le and Philippe Fournier-Viger and Unil Yun and Hamido Fujita},
  doi          = {10.1016/j.ins.2021.01.060},
  journal      = {Information Sciences},
  pages        = {239-264},
  shortjournal = {Inf. Sci.},
  title        = {Efficient algorithms for mining frequent high utility sequences with constraints},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering probabilistic graphs using neighbourhood paths.
<em>ISCI</em>, <em>568</em>, 216–238. (<a
href="https://doi.org/10.1016/j.ins.2021.03.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic graphs have gained much interest in the data mining community since the big data revolution. Graph clustering is a widely used technique in exploratory data analysis such as data compression, information retrieval, protein–protein interaction network, etc. Traditional clustering algorithms assume that the data represented in a graph is deterministic, i.e., the edges between nodes are certain, though they may vary in their importance (weight). In probabilistic graphs, however, edges are uncertain and are represented as probabilities. In this work, we propose an evolutionary algorithm based clustering technique specifically to deal with uncertainties in such data. It has been observed that correlation usually exists among adjacent edges. Our work exploits this principle and explores the paths between nodes (including those of multiple order) to provide an estimate of the similarity between nodes with probabilistic edges. We embed this information into the fitness function and use Genetic algorithm to optimize the solution. The algorithm is tested on several benchmark datasets and compared with recent state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Syed Fawad Hussain and Iffat Maab},
  doi          = {10.1016/j.ins.2021.03.057},
  journal      = {Information Sciences},
  pages        = {216-238},
  shortjournal = {Inf. Sci.},
  title        = {Clustering probabilistic graphs using neighbourhood paths},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning deep discriminative representations with pseudo
supervision for image clustering. <em>ISCI</em>, <em>568</em>, 199–215.
(<a href="https://doi.org/10.1016/j.ins.2021.03.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image clustering is a crucial but challenging task in machine learning and computer vision . Its performance highly depends on the quality of image feature representations. Recently, deep joint clustering which combines representation learning with clustering has presented a promising performance. However, existing joint methods suffer from two severe problems. That is, the learned representations lack discriminability especially for intricate images, and the performance often encounters a bottleneck due to the lack of supervision information. To address these problems, we propose a pseudo-supervised joint method for image clustering, i.e., Discriminative Pseudo Supervision Clustering (DPSC). Our key idea is to discover and utilize the pseudo supervision information to provide supervisory guidance for discriminative representation learning . With the aid of pseudo supervision, the representations can be continuously refined to facilitate inter-cluster separability and intra-cluster compactness, thereby leading to more discriminative representations and correctly separated clusters . To fully benefit from joint learning, we further introduce a self-evolution training algorithm to jointly optimize the DPSC model, in which the learned representations and clustering results boost each other progressively as more reliable pseudo supervision information is discovered during the iteration. Experimental results show that DPSC significantly outperforms state-of-the-art methods on various image datasets. Moreover, the learned feature representations generalize well across various algorithms.},
  archive      = {J_ISCI},
  author       = {Weibo Hu and Chuan Chen and Fanghua Ye and Zibin Zheng and Yunfei Du},
  doi          = {10.1016/j.ins.2021.03.066},
  journal      = {Information Sciences},
  pages        = {199-215},
  shortjournal = {Inf. Sci.},
  title        = {Learning deep discriminative representations with pseudo supervision for image clustering},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A three-way decision methodology to multi-attribute
decision-making in multi-scale decision information systems.
<em>ISCI</em>, <em>568</em>, 175–198. (<a
href="https://doi.org/10.1016/j.ins.2021.03.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision (3WD) provides a new perspective and methodology for solving multi-attribute decision-making (MADM) problem. In this paper, we introduce 3WD into a multi-scale decision information system (MS-DIS), which provides a new idea for solving MADM issues in MS-DISs. By using fuzzy membership functions , a multi-scale evaluation information table is first converted into a numerical evaluation value table. To calculate loss functions at two states generated by the decision class partition, a distance-based cost measurement is then defined. With reference to fuzzy σ σ -neighborhood classes, conditional probabilities are further calculated and 3WD rules from MS-DISs can be unravelled. As a result, the ranking about all objects in the data is obtained according to expected losses. Finally, a specific numerical example is used to illustrate the effectiveness of the proposed method comparing with other ones. An experimental analysis is also used to describe the superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Jiang Deng and Jianming Zhan and Wei-Zhi Wu},
  doi          = {10.1016/j.ins.2021.03.058},
  journal      = {Information Sciences},
  pages        = {175-198},
  shortjournal = {Inf. Sci.},
  title        = {A three-way decision methodology to multi-attribute decision-making in multi-scale decision information systems},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Document-level relation extraction with entity-selection
attention. <em>ISCI</em>, <em>568</em>, 163–174. (<a
href="https://doi.org/10.1016/j.ins.2021.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document-level relation extraction is a complex natural language processing task that predicts relations of entity pairs by capturing the critical semantic features on entity pairs from the document. However, current methods usually consider that the entity pairs contain the vast majority of information which can represent relational facts, and thus focus on modeling the entity pair, ignoring features on whole document and sentences. In the document-level relation extraction, the distance between entity pairs is relatively long. Judging the relation between entities usually requires reading many sentences or the whole document. Therefore, sentences and documents are particularly crucial for document-level relation extraction. In order to make full use of the multi-level information of sentences and documents, this paper proposes a document-level relation extraction framework with two advantages. First, we use the encoder to obtain the semantic features about the document and use the inter-sentence attention based on entity pairs to dynamically capture the features of multiple vital sentences. Second, we design a document gating that combines sentence-level features with document-level features to predict relations. Extensive experiments on a benchmark dataset have well-validated the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Changsen Yuan and Heyan Huang and Chong Feng and Ge Shi and Xiaochi Wei},
  doi          = {10.1016/j.ins.2021.04.007},
  journal      = {Information Sciences},
  pages        = {163-174},
  shortjournal = {Inf. Sci.},
  title        = {Document-level relation extraction with entity-selection attention},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel IoT network intrusion detection approach based on
adaptive particle swarm optimization convolutional neural network.
<em>ISCI</em>, <em>568</em>, 147–162. (<a
href="https://doi.org/10.1016/j.ins.2021.03.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of network security , it is of great significance to accurately detect various types of Internet of Things (IoT) network intrusion attacks which launched by the attacker-controlled zombie hosts. In this paper, we propose a novel IoT network intrusion detection approach based on Adaptive Particle Swarm Optimization Convolutional Neural Network (APSO-CNN). In particular, the PSO algorithm with change of inertia weight is used to adaptively optimize the structure parameters of one-dimensional CNN. The cross-entropy loss function value of the validation set, which is obtained from the first training of CNN, is taken as the fitness value of PSO. Especially, we define a new evaluation method that considers both the prediction probability assigned to each category and prediction label to compare the proposed APSO-CNN algorithm with CNN set parameters manually (R-CNN). Meanwhile, the comprehensive performance of proposed APSO-CNN and other three well known algorithms are compared in the five traditional evaluation indicators and the accuracy statistical characteristics of 10 times independent experiments. The simulation results show that the multi-type IoT network intrusion attack detection task based on APSO-CNN algorithm is effective and reliable.},
  archive      = {J_ISCI},
  author       = {Xiu Kan and Yixuan Fan and Zhijun Fang and Le Cao and Neal N. Xiong and Dan Yang and Xuan Li},
  doi          = {10.1016/j.ins.2021.03.060},
  journal      = {Information Sciences},
  pages        = {147-162},
  shortjournal = {Inf. Sci.},
  title        = {A novel IoT network intrusion detection approach based on adaptive particle swarm optimization convolutional neural network},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PMT-net: Progressive multi-task network for one-shot person
re-identification. <em>ISCI</em>, <em>568</em>, 133–146. (<a
href="https://doi.org/10.1016/j.ins.2021.03.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing person Re-Identification (Re-ID) algorithms require abundant labeled data from paired non-overlapping camera views in the fully supervised scenario. However, the fully supervised Re-ID suffers from the limited availability of labeled training samples due to the sharply increased cost of manual efforts. To tackle this problem, a novel Progressive Multi-Task Network (PMT-Net) for person Re-ID is proposed. PMT-Net initializes a model using only one labeled sample for each identity, and it iteratively optimizes the model by sampling the most reliable pseudo labels dynamically from unlabeled samples . Firstly, pedestrian attributes recognition is incorporated as an auxiliary task to learn discriminative features . Then, based on the discriminative features , the identity label for unlabeled samples is estimated by the distance between the labeled samples and unlabeled samples in feature space. In addition, to enhance the accuracy of label estimation for the unlabeled samples, a semi-supervised clustering method , named Distance Ranked Weight Clustering (DRW-Clustering) is designed. The clustering method weights partial unlabeled samples by the indexed ordinal of distance sorting, so that it can find the real cluster center quickly and effectively. Extensive comparative evaluation experiments are conducted on Market1501 and DukeMTMC-reID datasets, and the experimental results indicate that the proposed method achieves performance competitive or better than that of the state-of-the-art for one-shot person Re-ID.},
  archive      = {J_ISCI},
  author       = {Yulin Zhang and Bo Ma and Yuqing Feng and Meng Li},
  doi          = {10.1016/j.ins.2021.03.048},
  journal      = {Information Sciences},
  pages        = {133-146},
  shortjournal = {Inf. Sci.},
  title        = {PMT-net: Progressive multi-task network for one-shot person re-identification},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A distance for evidential preferences with application to
group decision making. <em>ISCI</em>, <em>568</em>, 113–132. (<a
href="https://doi.org/10.1016/j.ins.2021.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on measuring the dissimilarity between preferences with uncertainty and imprecision, modelled by evidential preferences based on the theory of belief functions. Two issues are targeted: The first concerns the conflicting interpretations of incomparability , leading to a lack of consensus within the preference modelling community. This discord affects the value settings of dissimilarity measures between preference relations. After reviewing the state of the art, we propose to distinguish between two cases: indecisive and undecided , respectively modelled by a binary relation and union of all relations. The second concerns a flaw that becomes apparent when measuring the dissimilarity in the theory of belief functions. Existing dissimilarity functions in the theory of belief functions are not suitable for evidential preferences, because they measure the dissimilarity between preference relations as being identical. This is counter-intuitive and conflicting with almost all the related works. We propose a novel distance named Unequal Singleton Pair (USP) distance, able to discriminate specific singletons from others when measuring the dissimilarity. The advantages of USP distances are illustrated by the evidential preference aggregation and group decision-making applications. The experiments show that USP distance effectively improves the quality of decision results.},
  archive      = {J_ISCI},
  author       = {Zhang Yiru and Bouadi Tassadit and Wang Yewan and Martin Arnaud},
  doi          = {10.1016/j.ins.2021.03.011},
  journal      = {Information Sciences},
  pages        = {113-132},
  shortjournal = {Inf. Sci.},
  title        = {A distance for evidential preferences with application to group decision making},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection via max-independent ratio and
min-redundant ratio based on adaptive weighted kernel density
estimation. <em>ISCI</em>, <em>568</em>, 86–112. (<a
href="https://doi.org/10.1016/j.ins.2021.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection based on entropy structure can be roughly divided into two types according to whether they are related to kernel density estimation (KDE). The first type is feature selection based on non-KDE entropy. The second type is feature selection based on KDE entropy. Compared with the first type, the second type avoids discretization and obtains more accurate mutual information when handling continuous data. However, existing feature selection methods based on KDE entropy neglect the fact that samples with noise have negative impacts on KDE. Besides, the feature evaluation functions don’t effectively assess relevance and redundancy of features. Thus, a feature selection method via maximizing independent and minimizing redundant classification information ratio is constructed based on adaptive weighted kernel density estimation . Firstly, an adaptive weighted kernel density estimation model is designed. Secondly, the entropy structure is defined by the adaptive weighted kernel density estimation model, and their theoretical properties are explored. Thirdly, a feature selection algorithm via maximizing independent and minimizing redundant classification information ratio is designed from the viewpoint of adaptive weighted kernel density estimation. Finally, comprehensive experiments are performed. The results illustrate that our approach has certain robustness, validity and superiority compared with other representative feature selection approaches.},
  archive      = {J_ISCI},
  author       = {Jianhua Dai and Ye Liu and Jiaolong Chen},
  doi          = {10.1016/j.ins.2021.03.049},
  journal      = {Information Sciences},
  pages        = {86-112},
  shortjournal = {Inf. Sci.},
  title        = {Feature selection via max-independent ratio and min-redundant ratio based on adaptive weighted kernel density estimation},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new classification and ranking decision method based on
three-way decision theory and TOPSIS models. <em>ISCI</em>,
<em>568</em>, 54–85. (<a
href="https://doi.org/10.1016/j.ins.2021.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theoretical researches of three-way decision have become saturated. Hence, more and more researchers have focused on the applications and expansions of three-way decision. Combining three-way decision ideas with multi-criteria decision-making is a feasible research direction. In light of this, this paper proposes a novel TOPSIS method based on three-way decision models. First of all, for two types of fuzzy concepts with opposite characteristics, we establish the corresponding three-way decision models. Then, based on the decision regions calculated by these two types of fuzzy concepts, we analyze and study two ranking regulations for objects belonging to the same (different) decision regions , respectively. On the basis of these two regulations, we define the concept of a united decision region and further explore two ranking rules for objects belonging to the same (different) united decision regions, respectively. Subsequently, the positive ideal distance fuzzy set and the negative ideal distance fuzzy set obtained by the core idea of the TOPSIS method are respectively seen as “Cost fuzzy concept” and “Benefit fuzzy concept”. Using the established decision rules based on the united decision regions, the classification and ranking of all objects are obtained. Finally, for the TOPSIS method based on three-way decision models, we test the feasibility and validity of the method from the perspectives of qualitative and quantitative analyses.},
  archive      = {J_ISCI},
  author       = {Kai Zhang and Jianhua Dai and Jianming Zhan},
  doi          = {10.1016/j.ins.2021.03.039},
  journal      = {Information Sciences},
  pages        = {54-85},
  shortjournal = {Inf. Sci.},
  title        = {A new classification and ranking decision method based on three-way decision theory and TOPSIS models},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved glasius bio-inspired neural network for target
search by multi-agents. <em>ISCI</em>, <em>568</em>, 40–53. (<a
href="https://doi.org/10.1016/j.ins.2021.03.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on solving the multi-agent cooperative target search problem with the demand for obtaining the maximal cumulative detection reward, given the prior target probability map and the sensor detection ability under various constraints. First, a topologically organized model of Glasius bio-inspired neural network (GBNN) is constructed individually for each agent in order to represent the searching environment. The neural activities are determined not only by the activity propagation among neurons, but also by the external input containing the single detection reward and various constraints synthetically. Then, the agent’s searching motion can be selected greedily based on the dynamic activity landscape of GBNN. With the disadvantages of propagation time delay and activity attenuation, however, the relatively global mechanism in GBNN may lead to unsatisfactory performance or even fail to avoid the local optimal problem. Hence the Gaussian mixture model (GMM) is utilized to extract the high-value subregions and compute the future detection reward quantitatively, which can be introduced into the neuron’s external excitatory input of GBNN directly. The simulation results verify the high efficiency and strong robustness of GBNN-GMM in the searching scenarios.},
  archive      = {J_ISCI},
  author       = {Peng Yao and Zhiyao Zhao},
  doi          = {10.1016/j.ins.2021.03.056},
  journal      = {Information Sciences},
  pages        = {40-53},
  shortjournal = {Inf. Sci.},
  title        = {Improved glasius bio-inspired neural network for target search by multi-agents},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Real-time and dynamic fault-tolerant scheduling for
scientific workflows in clouds. <em>ISCI</em>, <em>568</em>, 13–39. (<a
href="https://doi.org/10.1016/j.ins.2021.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing has become a popular technology for executing scientific workflows. However, with a large number of hosts and virtual machines (VMs) being deployed, the cloud resource failures, such as the permanent failure of hosts (HPF), the transient failure of hosts (HTF), and the transient failure of VMs (VMTF), bring the service reliability problem. Therefore, fault tolerance for time-consuming scientific workflows is highly essential in the cloud. However, existing fault-tolerant (FT) approaches consider only one or two above failure types and easily neglect the others, especially for the HTF. This paper proposes a Real-time and dynamic Fault-tolerant Scheduling (ReadyFS) algorithm for scientific workflow execution in a cloud, which guarantees deadline constraints and improves resource utilization even in the presence of any resource failure. Specifically, we first introduce two FT mechanisms , i.e., the replication with delay execution (RDE) and the checkpointing with delay execution (CDE), to cope with HPF and VMTF, simultaneously. Additionally, the rescheduling (ReSC) is devised to tackle the HTF that affects the resource availability of the entire cloud datacenter. Then, the resource adjustment (RA) strategy, including the resource scaling-up (RS-Up) and the resource scaling-down (RS-Down), is used to adjust resource demands and improve resource utilization dynamically. Finally, the ReadyFS algorithm is presented to schedule real-time scientific workflows by combining all the above FT mechanisms with RA strategy. We conduct the performance evaluation with real-world scientific workflows and compare ReadyFS with five vertical comparison algorithms and three horizontal comparison algorithms. Simulation results confirm that ReadyFS is indeed able to guarantee the fault tolerance of scientific workflow execution and improve cloud resource utilization.},
  archive      = {J_ISCI},
  author       = {Zhongjin Li and Victor Chang and Haiyang Hu and Hua Hu and Chuanyi Li and Jidong Ge},
  doi          = {10.1016/j.ins.2021.03.003},
  journal      = {Information Sciences},
  pages        = {13-39},
  shortjournal = {Inf. Sci.},
  title        = {Real-time and dynamic fault-tolerant scheduling for scientific workflows in clouds},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task sequence learning for performance prediction and
KPI mining in database management system. <em>ISCI</em>, <em>568</em>,
1–12. (<a href="https://doi.org/10.1016/j.ins.2021.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting future performance curve and mining the top-K influential KPIs are two important tasks for Database Management System (DBMS) operations. In this paper, we propose a multi-task sequence learning approach to address the two tasks in a uniform framework. The proposed approach adopts a Long Short-Term Memory (LSTM) based deep neural network model that uses multilevel discrete wavelets transform and LSTM-based Seq2Seq forecaster to capture the features in both time and frequency domains from high-dimensional time series, and achieves multi-step performance prediction and top-K KPI mining concurrently. The performance of the proposed multi-task sequence learning approach is evaluated based on two real-world DBMS datasets, which shows that the proposed approach achieves the lowest mean absolute error and root mean squared error in predicting performance scores, and significantly outperforms the state-of-the-art algorithms in both learning tasks.},
  archive      = {J_ISCI},
  author       = {Chen Wan and Wenzhong Li and Wangxiang Ding and Zhijie Zhang and Qingning Lu and Lin Qian and Ji Xu and Jixiang Lu and Rongrong Cao and Baoliu Ye and Sanglu Lu},
  doi          = {10.1016/j.ins.2021.03.046},
  journal      = {Information Sciences},
  pages        = {1-12},
  shortjournal = {Inf. Sci.},
  title        = {Multi-task sequence learning for performance prediction and KPI mining in database management system},
  volume       = {568},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Empirical risk minimization for dominance-based rough set
approaches. <em>ISCI</em>, <em>567</em>, 395–417. (<a
href="https://doi.org/10.1016/j.ins.2021.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider two parametric dominance-based rough set approaches (DRSA) proposed in the literature: variable precision DRSA (VP-DRSA) and variable consistency DRSA (VC-DRSA). They were introduced to cope with classification data encountered in practice for which the original definition of lower approximations is too restrictive. Both these extensions allow an augmentation of lower approximations , which is controlled parametrically in different ways. We give statistical interpretations for VP-DRSA and VC-DRSA from the perspective of empirical risk minimization typical for machine learning . Given families of classifiers and loss functions, we consider classification problems which relate directly VP-DRSA and VC-DRSA to ordinal classification. Then, we characterize the parametrically augmented lower approximations of both approaches as optimal solutions of associated empirical risk minimization problems. As a consequence, a connection between parametric DRSA and statistical learning is established. Moreover, new characterizations of the augmented lower approximations allow us to exhibit differences and similarities between VP-DRSA and VC-DRSA.},
  archive      = {J_ISCI},
  author       = {Yoshifumi Kusunoki and Jerzy Błaszczyński and Masahiro Inuiguchi and Roman Słowiński},
  doi          = {10.1016/j.ins.2021.02.043},
  journal      = {Information Sciences},
  pages        = {395-417},
  shortjournal = {Inf. Sci.},
  title        = {Empirical risk minimization for dominance-based rough set approaches},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reversible data hiding in encrypted images with block-based
adaptive MSB encoding. <em>ISCI</em>, <em>567</em>, 375–394. (<a
href="https://doi.org/10.1016/j.ins.2021.02.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary cloud storage and social media networks have matured and; as a result, the privacy protection of image content in these applications have attracted more attention. R eversible d ata h iding in e ncrypted i mages (RDHEI) is an efficient technique to embed additional data such as timestamps, watermarks, and copyright information into encrypted images to protect the image content. This paper proposes a reversible data hiding scheme in encrypted images based on a b lock-based a daptive M SB e ncoding technique (BAME-RDHEI). The content owner first uses a block-based image encryption method, including block permutation , pixel permutation in each block, and the block-based bitwise exclusive-or operation, to encrypt an image. This specific image encryption method preserves the relevance of the MSB bit planes in each block, and the block-based adaptive MSB encoding technique can be applied to classify and encode eight block types according to the number of MSB bit planes where all the values are all ‘1’ or ‘0’. After embedding the indicators that are generated by Huffman coding into the first MSB bit plane of each block, the remaining values of these MSB bit planes can be vacated for data embedding. The receiver can extract additional data, decrypted the image or recover the original image according to the different keys. The experimental results demonstrate that our proposed scheme provides enhanced security, significantly improves the embedding rate , and obtains higher visual quality for the decrypted image compared to other state-of-the-art schemes.},
  archive      = {J_ISCI},
  author       = {Xu Wang and Chin-Chen Chang and Chia-Chen Lin},
  doi          = {10.1016/j.ins.2021.02.079},
  journal      = {Information Sciences},
  pages        = {375-394},
  shortjournal = {Inf. Sci.},
  title        = {Reversible data hiding in encrypted images with block-based adaptive MSB encoding},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Portfolio optimization using higher moments in an uncertain
random environment. <em>ISCI</em>, <em>567</em>, 348–374. (<a
href="https://doi.org/10.1016/j.ins.2021.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a multi-objective portfolio optimization problem is studied in an uncertain random environment using higher moments. We consider a scenario involving an asset universe wherein some assets have sufficient historical return data for modelling as random variables , and others, listed relatively recently, lack historical data. The asset returns of such assets are modelled as uncertain variables. Thus, a hybrid environment involving both uncertain and random variables is considered. We use mean absolute semi-deviation as a risk measure and employ skewness (i.e., third moment) in the portfolio optimization model. The expressions for the mean absolute semi-deviation and skewness of an uncertain random variable have been derived. We show that the derivation of mean absolute semi-deviation is not based on any stipulation and thus is an accurate measure of risk (unlike the variance of an uncertain random variable, which uses stipulation). We propose a hybrid genetic algorithm as a solution methodology and provide empirical proofs to illustrate its advantages. The proposed methodology has been applied to a case study involving 100 assets listed in the NASDAQ-100 index of the U.S. stock market. We do an ex-post analysis to track the performance of our model out-of-sample and illustrate its advantages.},
  archive      = {J_ISCI},
  author       = {Mukesh Kumar Mehlawat and Pankaj Gupta and Ahmad Zaman Khan},
  doi          = {10.1016/j.ins.2021.03.019},
  journal      = {Information Sciences},
  pages        = {348-374},
  shortjournal = {Inf. Sci.},
  title        = {Portfolio optimization using higher moments in an uncertain random environment},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid-triggered interval type-2 fuzzy control for networked
systems under attacks. <em>ISCI</em>, <em>567</em>, 332–347. (<a
href="https://doi.org/10.1016/j.ins.2021.03.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the security control problem is considered for nonlinear networked control systems under cyber attacks . The nonlinearities are described by interval type-2 fuzzy models. To enhance bandwidth utilization and improve network control performance, a hybrid-triggered scheme is proposed. The networked control systems contain parametric uncertainties and time delays and are subject to external disturbances and cyber attacks . A hybrid-triggered-based control method is established to ensure the robust stability and a prescribed performance of the resulting closed-loop systems against attacks. Numerical simulation and a practical example of the bolt-tightening tool are provided to illustrate the effectiveness of the new control design method.},
  archive      = {J_ISCI},
  author       = {Zhi Lian and Peng Shi and Cheng-Chew Lim},
  doi          = {10.1016/j.ins.2021.03.050},
  journal      = {Information Sciences},
  pages        = {332-347},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid-triggered interval type-2 fuzzy control for networked systems under attacks},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical segment-channel attention network for
explainable multichannel signal classification. <em>ISCI</em>,
<em>567</em>, 312–331. (<a
href="https://doi.org/10.1016/j.ins.2021.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multichannel signal data collected from multiple sensors are widely used to monitor the status of various mechanical systems. Recently, deep neural networks have been successfully applied to multichannel signal data analysis because of their capability to learn discriminative features with minimum feature engineering. However, the latest deep neural networks for multichannel signal analysis lack explainability, which is essential for post hoc analysis in various fields. In this study, we propose an explainable neural network for the multichannel signal classification task. The proposed method is equipped with two levels of attention mechanisms –at the segment and channel levels– encouraging the model to focus on important parts in discriminating the status of a system. The derived attention probabilities facilitate interpretation of network behavior and thus can support post hoc analysis. To demonstrate the practicality and applicability of the proposed method, we conducted experiments on both simulated and real-world automobile data. The results confirmed that the proposed method is capable of accurately classifying multichannel signals and correctly identifying the critical segments and channels.},
  archive      = {J_ISCI},
  author       = {Jiyoon Lee and Hyungrok Do and Mingu Kwak and Hyungu Kahng and Seoung Bum Kim},
  doi          = {10.1016/j.ins.2021.03.024},
  journal      = {Information Sciences},
  pages        = {312-331},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical segment-channel attention network for explainable multichannel signal classification},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Full state constraints and command filtering-based adaptive
fuzzy control for permanent magnet synchronous motor stochastic systems.
<em>ISCI</em>, <em>567</em>, 298–311. (<a
href="https://doi.org/10.1016/j.ins.2021.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an adaptive fuzzy control scheme based on command filtering is proposed for the position tracking control of permanent magnet synchronous motor (PMSM) stochastic system with full state constraints. Firstly, fuzzy logic systems are employed to approximate unknown stochastic nonlinear functions in PMSM stochastic system. Then, the barrier Lyapunov functions are constructed to ensure that all states of the system do not violate its constrained boundary. In addition, the problem of “explosion of complexity” in traditional backstepping design is solved by using the command filtering technique and the error compensation mechanism is introduced to reduce filtering errors. At last, the effectiveness of the scheme is illustrated by simulation results.},
  archive      = {J_ISCI},
  author       = {Qi Jiang and Jiapeng Liu and Jinpeng Yu and Chong Lin},
  doi          = {10.1016/j.ins.2021.02.050},
  journal      = {Information Sciences},
  pages        = {298-311},
  shortjournal = {Inf. Sci.},
  title        = {Full state constraints and command filtering-based adaptive fuzzy control for permanent magnet synchronous motor stochastic systems},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed adaptive clustering learning over time-varying
multitask networks. <em>ISCI</em>, <em>567</em>, 278–297. (<a
href="https://doi.org/10.1016/j.ins.2021.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increasing research on distributed processing in networks, adaptive learning strategies have gradually attracted researchers’ attention. The traditional adaptive learning strategy mainly aims at a single task unchanged over time, while real networks often entail multitasks scenarios with tasks that change over time. Furthermore, although cooperation among agents is beneficial for single task time-invariant networks, agents’ indiscriminate cooperation in time-varying multitask networks may cause undesirable effects. In this paper, an adaptive clustering learning approach based on an event-triggered scheme over time-varying multitask networks is proposed. With this process, agents are enabled to distinguish their clusters to determine cooperative neighbors and improve the accuracy of estimation over networks. The mean-square of the proposed algorithm is analyzed in detail, and the error probability of false alarms and false detections of the clustering mechanism is evaluated. An extensive simulation is given to validate the analytical performance of the distributed learning strategy over time-varying multitasks.},
  archive      = {J_ISCI},
  author       = {Qing Shi and Feng Chen and Xinyu Li and Shukai Duan},
  doi          = {10.1016/j.ins.2021.03.036},
  journal      = {Information Sciences},
  pages        = {278-297},
  shortjournal = {Inf. Sci.},
  title        = {Distributed adaptive clustering learning over time-varying multitask networks},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure two-party input-size reduction: Challenges, solutions
and applications. <em>ISCI</em>, <em>567</em>, 256–277. (<a
href="https://doi.org/10.1016/j.ins.2021.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The computation and communication costs of many secure multiparty protocols would benefit from a preprocessing that replaces large inputs with much smaller values without changing the outputs. This preprocessing is especially advantageous when its cost can be amortized over subsequent computations that all benefit from smaller inputs. The above holds for protocols based on garbled circuits, homomorphic encryption, or other techniques. Problems benefiting from such preprocessing include pattern matching, information retrieval, and sequence comparisons that depend on (in)equality of comparands. Motivated by this (in)equality-preservation requirement, we define the problem as follows: Alice’s and Bob’s inputs are their respective private sets S A SA and S B SB of large integers, and their private outputs are images of their sets under a function ρ ρ that injectively maps S A ∪ S B SA∪SB into { 0 , 1 , … , N - 1 } {0,1,…,N-1} for a small N ⩾ | S A | + | S B | N⩾|SA|+|SB| . Alice’s (Bob’s) knowledge of this mapping on S A SA ( S B SB ) must reveal nothing about S B SB ( S A SA ). Thus, neither party should be able to learn ρ ( x ) ρ(x) for any x that is not in its private set; otherwise, s/he could exploit the small codomain of ρ ρ to learn about the other party’s set. We formalize the problem, propose efficient and secure (semi-honest model) solutions to it, and discuss its use cases.},
  archive      = {J_ISCI},
  author       = {Javad Darivandpour and Duc V. Le and Mikhail J. Atallah},
  doi          = {10.1016/j.ins.2021.01.038},
  journal      = {Information Sciences},
  pages        = {256-277},
  shortjournal = {Inf. Sci.},
  title        = {Secure two-party input-size reduction: Challenges, solutions and applications},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effectiveness of three-way classification with
interpretable perspective. <em>ISCI</em>, <em>567</em>, 237–255. (<a
href="https://doi.org/10.1016/j.ins.2021.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a typical methodology to deal with uncertain issues, the three-way decision (3WD) has been developed rapidly in nearly ten years, both in theories and applications. Three-way classification is one of the important research fields of 3WD, which utilizes the idea of 3WD to solve classification problems. In this paper, we focus on investigating the effectiveness of three-way classification through two evaluation indicators: the classification quality ( Precision , Recall , Accuracy Precision,Recall,Accuracy and F 1 F1 ) and the decision cost. The comparisons between two-way classification and three-way classification are concretely analyzed, some mathematical properties , judging conditions and decision criteria of these two classification methods are also discussed in detail. Finally, the experimental results on eight UCI data sets validate the mathematical analysis, which reveal the effectiveness of three-way classification.},
  archive      = {J_ISCI},
  author       = {Dun Liu},
  doi          = {10.1016/j.ins.2021.03.030},
  journal      = {Information Sciences},
  pages        = {237-255},
  shortjournal = {Inf. Sci.},
  title        = {The effectiveness of three-way classification with interpretable perspective},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning joint latent representations based on information
maximization. <em>ISCI</em>, <em>567</em>, 216–236. (<a
href="https://doi.org/10.1016/j.ins.2021.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning disentangled and interpretable representations is an important aspect of information understanding. In this paper, we propose a novel deep learning model representing both discrete and continuous latent variable spaces which can be used in either supervised or unsupervised learning . The proposed model is trained using an optimization function employing the mutual information maximization criterion. For the unsupervised learning setting we define a lower bound to the mutual information between the joint distribution of the latent variables corresponding to the real data and those generated by the model. The maximization of this lower bound during the training induces the learning of disentangled and interpretable data representations. Such representations can be used for attribute manipulation and image editing tasks.},
  archive      = {J_ISCI},
  author       = {Fei Ye and Adrian. G. Bors},
  doi          = {10.1016/j.ins.2021.03.007},
  journal      = {Information Sciences},
  pages        = {216-236},
  shortjournal = {Inf. Sci.},
  title        = {Learning joint latent representations based on information maximization},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-varying nonholonomic robot consensus formation using
model predictive based protocol with switching topology. <em>ISCI</em>,
<em>567</em>, 201–215. (<a
href="https://doi.org/10.1016/j.ins.2021.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, for controlling the time-varying consensus formation (TVCF) of multiply nonholonomic robots under switching information transforming topology, a generalized consensus formation system, which is controlled by a neural-dynamic-optimized distributed model predictive control (NDMPC) based consensus protocol strategy, is developed. The system consists of an auxiliary consensus maneuvering subsystem and a formation tracking subsystem. Through simultaneously stabilizing the generalized errors consisted of these two subsystems under the switching topologies, the consensus object is achieved. Within each sampling time, the NDMPC method can formulate and solve a constrained quadratic programming (QP) problem with time-varying desired formation pattern and get the optimal inputs for each robot in a distributed manner. The constraints of the system, as well as the switching structure brought by the changing topologies, can be tackled by utilizing the proposed method. In the end, numerical examples verify the effectiveness of the proposed formation control method.},
  archive      = {J_ISCI},
  author       = {Hanzhen Xiao and C.L. Philip Chen},
  doi          = {10.1016/j.ins.2021.01.034},
  journal      = {Information Sciences},
  pages        = {201-215},
  shortjournal = {Inf. Sci.},
  title        = {Time-varying nonholonomic robot consensus formation using model predictive based protocol with switching topology},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TAERT: Triple-attentional explainable recommendation with
temporal convolutional network. <em>ISCI</em>, <em>567</em>, 185–200.
(<a href="https://doi.org/10.1016/j.ins.2021.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable Recommendation aims at not only providing the recommended items to users, but also enabling users to be aware of why these items are recommended. To better understand the recommended results, textual reviews have been playing an increasingly important role in the recommender systems . However, how to learn the latent representation of user preferences and item features, and how to model the interactions between them effectively via specific aspects in the reviews are two crucial problems in the explainable recommendation. To this end, we propose a novel T riple- A ttentional E xplainable R ecommendation with T emporal Convolutional Network , named TAERT, which is to jointly generate recommendation results and explanations. Specifically, we first explore a feature learning method based on Temporal Convolutional Network (TCN) to derive word-aware and review-aware vector representations . Then, we introduce three levels of attention networks to model word contribution, review usefulness and importance of latent factors , respectively. Finally, the predicted rating is inferred by the factor-level attention based prediction layer. Furthermore, the attention mechanism is also conducive to identifying the representative item reviews and highlighting the informative words to generate explanations. Compared with the state-of-the-art methods, comprehensive experiments on six real-world datasets are conducted to verify the effectiveness on both recommendation and explanation.},
  archive      = {J_ISCI},
  author       = {Siyuan Guo and Ying Wang and Hao Yuan and Zeyu Huang and Jianwei Chen and Xin Wang},
  doi          = {10.1016/j.ins.2021.03.034},
  journal      = {Information Sciences},
  pages        = {185-200},
  shortjournal = {Inf. Sci.},
  title        = {TAERT: Triple-attentional explainable recommendation with temporal convolutional network},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Arbitrary-term-absent max-product fuzzy relation
inequalities and its lexicographic minimal solution. <em>ISCI</em>,
<em>567</em>, 167–184. (<a
href="https://doi.org/10.1016/j.ins.2021.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently the max-product fuzzy relation inequalities were applied to describe the wireless communication station system. However, when an arbitrary line fault appears between the emission basic station and the signal testing point, the classical max-product system is no longer effective. Considering an arbitrary line fault in the wireless communication station system, we introduce and investigate the so-called arbitrary-term-absent (ATA) max-product fuzzy relation inequalities in this paper. In order to reduce the damage caused by the electromagnetic radiation from the basic stations, a minimal solution is usually desired. However, the structure of solution set to the ATA max-product fuzzy relation inequalities shows that the minimal solutions are not unique in most cases. Hence, we further introduce the lexicographic order and define the relevant concept of lexicographic minimal solution. A lexicographic minimal solution is indeed an optimal scheduling, minimizing the electromagnetic radiations in a lexicographic order . An efficient algorithm with polynomial complexity is developed for obtaining the unique lexicographic minimal solution of the ATA max-product system. At last, our proposed resolution algorithm is compared to the existing one and illustrated by a numerical example.},
  archive      = {J_ISCI},
  author       = {Jianjun Qiu and Guanrong Li and Xiaopeng Yang},
  doi          = {10.1016/j.ins.2021.03.021},
  journal      = {Information Sciences},
  pages        = {167-184},
  shortjournal = {Inf. Sci.},
  title        = {Arbitrary-term-absent max-product fuzzy relation inequalities and its lexicographic minimal solution},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-varying output formation-containment control for
homogeneous/heterogeneous descriptor fractional-order multi-agent
systems. <em>ISCI</em>, <em>567</em>, 146–166. (<a
href="https://doi.org/10.1016/j.ins.2021.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the time-varying output formation-containment (TV-OFC) problem of homogeneous and heterogeneous descriptor fractional-order multi-agent systems (DFO-MASs) is investigated. The results obtained in previous works for nonsingular integer-order multi-agent systems can be regarded as particular cases of our results. This control aims at making leaders keep time-varying shape to move and followers move inside the convex hull spanned by leaders simultaneously. First, both the output feedback control strategy and observer-based control algorithm are designed to address the TV-OFC problem of heterogeneous DFO-MASs, where the virtual leader provides the reference trajectory for leaders to achieve the formation tracking. Then, sufficient conditions with less computation complexity are presented and the methods to determine gain matrices of the schemes are proposed for homogeneous and heterogeneous DFO-MASs, so as to achieve the TV-OFC. Finally, numerical examples are given to demonstrate the effectiveness of theoretical conclusions.},
  archive      = {J_ISCI},
  author       = {Zhiyun Gao and Huaguang Zhang and Yingchun Wang and Yunfei Mu},
  doi          = {10.1016/j.ins.2021.03.017},
  journal      = {Information Sciences},
  pages        = {146-166},
  shortjournal = {Inf. Sci.},
  title        = {Time-varying output formation-containment control for homogeneous/heterogeneous descriptor fractional-order multi-agent systems},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-cooperative behavior management in group decision making
by a conflict resolution process and its implementation for
pharmaceutical supplier selection. <em>ISCI</em>, <em>567</em>, 131–145.
(<a href="https://doi.org/10.1016/j.ins.2021.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of Pharmaceutical Industry 4.0 , products and services provided by suppliers play a significantly important role for a pharmaceutical enterprise. To evaluate the performance of suppliers comprehensively regarding multiple criteria, it is necessary to invite inside managers from the enterprise and outside consultants with expertise to form a decision-making committee. Within this context, this study proposes a multi-attribute group decision making model for pharmaceutical supplier selection with internal and external (heterogeneous) experts. Considering the complexity of the decision-making environment, we suppose that the experts use triangular fuzzy numbers to express their imprecise information. We identify two kinds of conflicts among experts, and introduce a conflict resolution process with a feedback mechanism. In the feedback mechanism, two non-cooperative behavior management approaches are introduced corresponding to the two kinds of experts. Afterwards, an algorithm for multiple-attribute group decision making with triangular fuzzy numbers and heterogeneous experts is presented. Finally, an illustrative example about pharmaceutical supplier selection is provided to verify the feasibility of the proposed method and some managerial insights are given.},
  archive      = {J_ISCI},
  author       = {Huchang Liao and Lisi Kuang and Yuxi Liu and Ming Tang},
  doi          = {10.1016/j.ins.2021.03.010},
  journal      = {Information Sciences},
  pages        = {131-145},
  shortjournal = {Inf. Sci.},
  title        = {Non-cooperative behavior management in group decision making by a conflict resolution process and its implementation for pharmaceutical supplier selection},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised deep quadruplet hashing with isometric
quantization for image retrieval. <em>ISCI</em>, <em>567</em>, 116–130.
(<a href="https://doi.org/10.1016/j.ins.2021.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerous studies have shown deep hashing can facilitate large-scale image retrieval since it employs neural networks to learn feature representations and binary codes simultaneously. Despite supervised deep hashing has made great achievements under the guidance of label information, it is hardly applicable to a real-world image retrieval application because of its reliance on extensive human-annotated data. Furthermore, the pair-wise or triplet-wise unsupervised hashing can hardly achieve satisfactory performance due to the absence of local similarity of image pairs. To solve those problems, we propose a novel unsupervised deep hashing framework to learn compact binary codes , which takes the quadruplet forms as input units, called Unsupervised Deep Quadruplet Hashing with Isometric Quantization (UDQH-IQ). Specifically, by introducing the rotation invariance of images, the novel quadruplet-based loss is designed to explore the underlying semantic similarity of image pairs, which could preserve local similarity with its neighbors in Hamming space. To decrease the quantization errors , Hamming-isometric quantization is exploited to maximize the consistency of semantic similarity between binary-like embedding and corresponding binary codes. To alleviate redundancy in different bits, an orthogonality constraint is developed to decorrelate different bits in binary codes. Experimental results on three benchmark datasets indicate that our UDQH-IQ achieves promising performance.},
  archive      = {J_ISCI},
  author       = {Qibing Qin and Lei Huang and Zhiqiang Wei and Jie Nie and Kezhen Xie and Jinkui Hou},
  doi          = {10.1016/j.ins.2021.03.006},
  journal      = {Information Sciences},
  pages        = {116-130},
  shortjournal = {Inf. Sci.},
  title        = {Unsupervised deep quadruplet hashing with isometric quantization for image retrieval},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Auto-weighted robust low-rank tensor completion via
tensor-train. <em>ISCI</em>, <em>567</em>, 100–115. (<a
href="https://doi.org/10.1016/j.ins.2021.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, multi-dimensional data (tensor data) have shown their capability of preserving multilinear structures. Due to the measuring error or other non-human factors, these data often suffer signal corruptions or missing values, or even both. To address these issues simultaneously, this paper studies the Robust Tensor Completion (RTC) problem, a mixed problem of the known Low-Rank Tensor Completion (LRTC) and Robust Principal Component Analysis (RPCA). Based on Tensor-Train rank (TT rank), the proposed model is able to capture the latent structure information of tensor data by recovering the low-rank component and separating the sparse component from the partial observations. To make TT rank more effective, an auto-weighted mechanism is utilized to balance the importance of different matricizations from the same tensor. We also propose a more flexible tensor augmentation approach called Tree Ket Augmentation (Tree-KA) to obtain a higher-order tensor from a lower one with it a new general explanation. Alternating direction method of multipliers (ADMM) is employed to solve the resulting model and extensive numerical experiments have verified the effectiveness of the proposed model compared with other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Chuan Chen and Zhe-Bin Wu and Zi-Tai Chen and Zi-Bin Zheng and Xiong-Jun Zhang},
  doi          = {10.1016/j.ins.2021.03.025},
  journal      = {Information Sciences},
  pages        = {100-115},
  shortjournal = {Inf. Sci.},
  title        = {Auto-weighted robust low-rank tensor completion via tensor-train},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent sliding mode controller based on LAMDA for a
class of SISO uncertain systems. <em>ISCI</em>, <em>567</em>, 75–99. (<a
href="https://doi.org/10.1016/j.ins.2021.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new intelligent sliding mode controller based on LAMDA (Learning Algorithm for Multivariate Data Analysis), a fuzzy method used for supervised and unsupervised learning applicable to the detection of functional systemic states. LAMDA computes the Global Adequacy Degree (GAD) of an object to a class or functional state to determine its degree of similarity. An inference stage has been added to LAMDA to make it work as a controller, in combination with the basic features of a sliding mode control (SMC) and Lyapunov stability theory . The novelty of this proposal is that we have used the LAMDA algorithm to compute the SMC continuous and discontinuous control actions to obtain a chattering-free controller, which can then be applied to a class of SISO systems with variable dynamics and model uncertainties. Simulations on two nonlinear chemical processes have validated the proposal: 1) control of a continuous stirred tank reactor (CSTR) under bounded disturbances and reference changes, and 2) regulation of a mixing tank with variable parameters (variable dynamics). The experiments are compared with other control techniques, demonstrating that the proposed method can accurately control the tanks, improving the results in performance, robustness, and disturbance rejection.},
  archive      = {J_ISCI},
  author       = {Luis Morales and Jose Aguilar and Oscar Camacho and Andrés Rosales},
  doi          = {10.1016/j.ins.2021.03.012},
  journal      = {Information Sciences},
  pages        = {75-99},
  shortjournal = {Inf. Sci.},
  title        = {An intelligent sliding mode controller based on LAMDA for a class of SISO uncertain systems},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven floor plan understanding in rural residential
buildings via deep recognition. <em>ISCI</em>, <em>567</em>, 58–74. (<a
href="https://doi.org/10.1016/j.ins.2021.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic understanding of floor plan images is a key component of various applications. Due to the style diversity of rural housing design, the latest learning-based approaches cannot achieve satisfactory recognition results. In this paper, we present a new framework for parsing floor plans of rural residence that combines semantic neural networks with a post-processed room segmentation. First, we take case studies from typical residential buildings in China’s rural areas and provide a novel image dataset, called RuralHomeData , containing 800 rural residence floor plans with accurate man-made annotations. Based on the dataset, we propose a new deep learning-based recognition framework using a joint neural network to predict the geometric elements and text information on the floor plan simultaneously. Our insight is that walls and openings (doors and windows) are the basic elements corresponding to the room boundary that a closed 1D loop must form a certain room. Then the semantic information (e.g., the room function) of room regions can be obtained through text detection and identification. Furthermore, we use the MIQP algorithm to divide the area containing multiple room type texts into multiple room areas. Finally, the input floor plan can be transformed into a room layout graph with room attributes and adjacent relationships. The proposed algorithm has been tested on both urban and rural datasets, and the experimental results demonstrate our efficiency and robustness compared with the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Zhengda Lu and Teng Wang and Jianwei Guo and Weiliang Meng and Jun Xiao and Wei Zhang and Xiaopeng Zhang},
  doi          = {10.1016/j.ins.2021.03.032},
  journal      = {Information Sciences},
  pages        = {58-74},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven floor plan understanding in rural residential buildings via deep recognition},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning with neighborhood preserving embedding
regularization and its application for soft sensor in an industrial
hydrocracking process. <em>ISCI</em>, <em>567</em>, 42–57. (<a
href="https://doi.org/10.1016/j.ins.2021.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning has attracted increasing attention for soft sensor applications in industrial processes. Hierarchical features can be learned from massive process data by deep learning , which is the key step for quality variable prediction. However, few deep learning algorithms consider the neighborhood structure of data samples for feature extraction in industrial processes. In this paper, a novel stacked neighborhood preserving autoencoder (S-NPAE) is proposed to extract hierarchical neighborhood-preserving features. As for each NPAE, a novel loss function is proposed to reconstruct the input data and preserve the neighborhood structure of the input data simultaneously. By minimizing this loss function, NPAE can efficiently extract the neighborhood-preserved features from its input data. Then, the deep S-NPAE network is constructed by stacking multiple NPAEs in a hierarchical way. Finally, the extracted features can be used for accurate quality prediction in soft sensor modeling. The experimental results on an industrial hydrocracking process demonstrate the effectiveness of the proposed method when compared with other commonly used methods.},
  archive      = {J_ISCI},
  author       = {Chenliang Liu and Kai Wang and Lingjian Ye and Yalin Wang and Xiaofeng Yuan},
  doi          = {10.1016/j.ins.2021.03.026},
  journal      = {Information Sciences},
  pages        = {42-57},
  shortjournal = {Inf. Sci.},
  title        = {Deep learning with neighborhood preserving embedding regularization and its application for soft sensor in an industrial hydrocracking process},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HAN, image captioning, and forensics ensemble multimodal
fake news detection. <em>ISCI</em>, <em>567</em>, 23–41. (<a
href="https://doi.org/10.1016/j.ins.2021.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, news publication, propagation, and consumption have been diverted to online social media networks and web portals, which has given rise to falsified and fabricated news articles containing both textual and visual information formats. Most of the research to date is centered on textual fake news detection using machine learning approaches , where multimedia data forgery is hardly addressed. Hence, a multimodal fake news detection framework is proposed, which unitedly exploits hidden pattern extraction capabilities from text using Hierarchical Attention Network (HAN) and visual image features using image captioning and forensic analysis. We specifically focused on four different techniques of multimodal data analysis, such as HAN deep model for text, generating image caption and headline matching with news text (CHM), Noise Variance Inconsistency (NVI), and Error Level Analysis (ELA). All these algorithms have been tested, first independently and then collectively using the max voting Ensemble method on three different datasets. The experimental results and comparisons with contemporary techniques put forward the fact that the proposed method outperforms state-of-the-art with 95.90\% highest accuracy on the Fake News Samples dataset . The achieved results also prove that the combined model beats individual methods’ capabilities in classifying fake news accurately.},
  archive      = {J_ISCI},
  author       = {Priyanka Meel and Dinesh Kumar Vishwakarma},
  doi          = {10.1016/j.ins.2021.03.037},
  journal      = {Information Sciences},
  pages        = {23-41},
  shortjournal = {Inf. Sci.},
  title        = {HAN, image captioning, and forensics ensemble multimodal fake news detection},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EPEM: Efficient parameter estimation for multiple class
monotone missing data. <em>ISCI</em>, <em>567</em>, 1–22. (<a
href="https://doi.org/10.1016/j.ins.2021.02.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of monotone missing data has been broadly studied during the last two decades and has many applications in various fields such as bioinformatics or statistics . Commonly used imputation techniques require multiple iterations through the data before yielding convergence. Moreover, those approaches may introduce extra noises and biases to the subsequent modeling. In this work, we derive exact formulas and propose a novel algorithm to compute the maximum likelihood estimators (MLEs) of a multiple class, monotone missing dataset when all the covariance matrices of all categories are assumed to be equal, namely Efficient Parameter Estimation for Multiple Class Monotone Missing Data (EPEM). We then illustrate an application of our proposed methods in Linear Discriminant Analysis (LDA). As the computation is exact, our EPEM algorithm does not require multiple iterations through the data as other imputation approaches, thus promising to handle much less time-consuming than other methods. This effectiveness was validated by empirical results when EPEM reduced the error rates significantly and required a short computation time compared to several imputation-based approaches. We also release all codes and data of our experiments in a GitHub repository to contribute to the research community related to this problem.},
  archive      = {J_ISCI},
  author       = {Thu Nguyen and Duy H.M. Nguyen and Huy Nguyen and Binh T. Nguyen and Bruce A. Wade},
  doi          = {10.1016/j.ins.2021.02.077},
  journal      = {Information Sciences},
  pages        = {1-22},
  shortjournal = {Inf. Sci.},
  title        = {EPEM: Efficient parameter estimation for multiple class monotone missing data},
  volume       = {567},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust consumer preference analysis with a social network.
<em>ISCI</em>, <em>566</em>, 379–400. (<a
href="https://doi.org/10.1016/j.ins.2021.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of social media makes it possible for online consumers to seek decision-making support for product selections from their social networks. Users (platforms, manufacturers, etc.) can employ social networks in turn to identify products that consumers prefer, which is important for users to launch marketing strategies such as market segmentation and advertisements. However, there is a challenge for users with regard to knowing consumer preferences about products in a social network environment. To address this issue, we establish a robust consumer preference analysis that includes social network information. First, based on a social network analysis , we estimate a target consumer’s missing preference, which is represented by pairwise comparisons between candidate products. Second, we utilize a consensus reaching process to obtain the bounds of the consumer’s preferences. Finally, we apply robust optimization to obtain the priority weights of products such that the consumer’s preferences regarding these products can be shown. As a tool for analyzing consumer preferences, the robust optimization method only requires the lower and upper bounds of consumer preferences, and it is robust to errors with respect to the preferences. For illustration purposes, we apply this method to analyze consumer preferences based on a rating dataset called filmtrust .},
  archive      = {J_ISCI},
  author       = {Long Ren and Bin Zhu and Zeshui Xu},
  doi          = {10.1016/j.ins.2021.03.018},
  journal      = {Information Sciences},
  pages        = {379-400},
  shortjournal = {Inf. Sci.},
  title        = {Robust consumer preference analysis with a social network},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards an efficient real-time kernel function stream
clustering method via shared nearest-neighbor density for the IIoT.
<em>ISCI</em>, <em>566</em>, 364–378. (<a
href="https://doi.org/10.1016/j.ins.2021.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of 5G communication technology will considerably help the expansion and gth Industrial Internet of things (IIoT). Indeed, both the data scale and dimension will significantly increase, leading to a challenging problem of the effective real-time stream clustering in the field of IIoT streaming mining. This paper proposes an efficient and novel real-time kernel function stream clustering method based on shared nearest-neighbor density for IIoT. In the proposed method, the projection technology is used to select the dimensions of high-dimensional data, while the Euler kernel function is used as the similarity measure. Furthermore, the micro-clusters are divided by the shared nearest-neighbor density, and the outliers are relearned. The main innovation lies in using the Euler kernel function to measure the similarity, reduce the sensitivity of outliers, and use the relearning strategy to improve the clustering quality of the data stream. The theoretical analysis and experimental comparisons on the simulated data sets show that the proposed method is very effective and represents a good solution for clustering real-time data streams of IIoT.},
  archive      = {J_ISCI},
  author       = {Ruohe Huang and Ruliang Xiao and Weifu Zhu and Ping Gong and Jinhui Chen and Imad Rida},
  doi          = {10.1016/j.ins.2021.02.025},
  journal      = {Information Sciences},
  pages        = {364-378},
  shortjournal = {Inf. Sci.},
  title        = {Towards an efficient real-time kernel function stream clustering method via shared nearest-neighbor density for the IIoT},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel prediction model for the inbound passenger flow of
urban rail transit. <em>ISCI</em>, <em>566</em>, 347–363. (<a
href="https://doi.org/10.1016/j.ins.2021.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-precision short-term inbound passenger flow prediction is of great significance to the daily crowd management and line rescheduling in urban rail systems. Although current models have been applied to prediction, most methods need optimization to meet refined passenger flow management demand. In order to better predict the passenger flow, a novel Wave-LSTM model, based on long short-term memory network (LSTM) and wavelet, is introduced in this paper. In an empirical study with practical passenger flow data of Dongzhimen Station in the Beijing Subway system, the hybrid model exhibited more effective performance in terms of prediction accuracy than the existing algorithms, e.g., autoregressive integrated moving average (ARIMA), nonlinear regression (NAR), and traditional LSTM model. The study illustrates that our newly adopted model is a promising approach for predicting high-precision short-term inbound passenger flow.},
  archive      = {J_ISCI},
  author       = {Xin Yang and Qiuchi Xue and Xingxing Yang and Haodong Yin and Yunchao Qu and Xiang Li and Jianjun Wu},
  doi          = {10.1016/j.ins.2021.02.036},
  journal      = {Information Sciences},
  pages        = {347-363},
  shortjournal = {Inf. Sci.},
  title        = {A novel prediction model for the inbound passenger flow of urban rail transit},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Order based on associative operations. <em>ISCI</em>,
<em>566</em>, 326–346. (<a
href="https://doi.org/10.1016/j.ins.2021.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the classical works on obtaining order from semigroups, recently, many researchers have proposed orders based on associative fuzzy logic connectives. However, the use of these monotone operators succinctly assumes and implies the presence of an (existing) order on the underlying set. In this work, we consider associative operations F on a non-empty set P P without recourse to any ordering that may or may not be available on it. Picking the most general of the definitions of order proposed so far, that of Karaçal and Kesiciogˇlu, we determine the necessary and sufficient conditions on an associative operation F to obtain a poset on P P . Following this we investigate the classes of t-norms, t-conorms, uninorms and nullnorms – which are the typical fuzzy logic operations considered so far to obtain orders – that satisfy these conditions and also do a comparative study of the structures obtained from the different orders proposed so far. Finally, we explore further conditions required on an associative operation F to obtain richer order-theoretic structures.},
  archive      = {J_ISCI},
  author       = {Vikash Kumar Gupta and Balasubramaniam Jayaram},
  doi          = {10.1016/j.ins.2021.02.020},
  journal      = {Information Sciences},
  pages        = {326-346},
  shortjournal = {Inf. Sci.},
  title        = {Order based on associative operations},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Space-efficient representations of raster time series.
<em>ISCI</em>, <em>566</em>, 300–325. (<a
href="https://doi.org/10.1016/j.ins.2021.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Raster time series, a.k.a. temporal rasters, are collections of rasters covering the same region at consecutive timestamps. These data have been used in many different applications ranging from weather forecast systems to monitoring of forest degradation or soil contamination. Many different sensors are generating this type of data, which makes such analyses possible, but also challenges the technological capacity to store and retrieve the data. In this work, we propose a space-efficient representation of raster time series that is based on Compact Data Structures (CDS). Our method uses a strategy of snapshots and logs to represent the data, in which both components are represented using CDS. We study two variants of this strategy, one with regular sampling and another one based on a heuristic that determines at which timestamps should the snapshots be created to reduce the space redundancy. We perform a comprehensive experimental evaluation using real datasets. The results show that the proposed strategy is competitive in space with alternatives based on pure data compression , while providing much more efficient query times for different types of queries.},
  archive      = {J_ISCI},
  author       = {Fernando Silva-Coira and José R. Paramá and Guillermo de Bernardo and Diego Seco},
  doi          = {10.1016/j.ins.2021.03.035},
  journal      = {Information Sciences},
  pages        = {300-325},
  shortjournal = {Inf. Sci.},
  title        = {Space-efficient representations of raster time series},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-clause dynamic deduction algorithm based on standard
contradiction separation rule. <em>ISCI</em>, <em>566</em>, 281–299. (<a
href="https://doi.org/10.1016/j.ins.2021.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decades, automated theorem proving (ATP) for first-order logic has made good progress, in which binary resolution inference rule plays a crucial role. However, as shown in the latest benchmark library of the ATP system, there are still many practical problems that have not been resolved or cannot be effectively resolved. Recently, in order to overcome the limitations of ATP based on binary resolution inference rules, a novel multi-clause dynamic standard contradiction separation (S-CS) inference rule and its automated deduction theory have been proposed. Based on this theory, this paper first clarifies the generality of this S-CS rule by comparing it with some well-known variants of the binary resolution rule, and then focuses on how to design a specific and effective algorithm along with search strategies to realize the S-CS based deductive theory with its implementation. Specifically, the present work proposes a novel S-CS dynamic deduction algorithm (in short SDDA) based on different strategies and summarizes its implementation procedures. In addition, we focus on evaluating whether SDDA, as a novel perspective multi-clause dynamic automatic deduction algorithm, can be applied on top of the current leading ATP system architectures to further improve their performances. Therefore, SDDA is applied to the current leading first-order ATP systems, i.e., Vampire and E, respectively forming two integrated APT systems, denoted as SDDA_V and SDDA_E. Then the capabilities of SDDA_V and SDDA_E are evaluated on the latest benchmark database TPTP , such as the CASC-J9 problems (FOF division) as well as the hard problems with a rating of 1 in the TPTP benchmark database. The experimental results show the effectiveness of SDDA: SDDA_V outperforms Vampire itself, and SDDA_E, outperforms E itself, and the two improved ATP systems have solved a number of hard problems with the rating of 1 in TPTP, that is, some problems in the latest benchmark database TPTP which have not yet been solved by other current first-order ATP systems.},
  archive      = {J_ISCI},
  author       = {Feng Cao and Yang Xu and Jun Liu and Shuwei Chen and Jianbing Yi},
  doi          = {10.1016/j.ins.2021.03.015},
  journal      = {Information Sciences},
  pages        = {281-299},
  shortjournal = {Inf. Sci.},
  title        = {A multi-clause dynamic deduction algorithm based on standard contradiction separation rule},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-local musical statistics as guides for audio-to-score
piano transcription. <em>ISCI</em>, <em>566</em>, 262–280. (<a
href="https://doi.org/10.1016/j.ins.2021.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an automatic piano transcription system that converts polyphonic audio recordings into musical scores. This has been a long-standing problem of music information processing, and recent studies have made remarkable progress in the two main component techniques: multipitch detection and rhythm quantization. Given this situation, we study a method integrating deep-neural-network-based multipitch detection and statistical-model-based rhythm quantization. In the first part, we conducted systematic evaluations and found that while the present method achieved high transcription accuracies at the note level, some global characteristics of music, such as tempo scale, metre (time signature), and bar line positions, were often incorrectly estimated. In the second part, we formulated non-local statistics of pitch and rhythmic contents that are derived from musical knowledge and studied their effects in inferring those global characteristics. We found that these statistics are markedly effective for improving the transcription results and that their optimal combination includes statistics obtained from separated hand parts. The integrated method had an overall transcription error rate of 7.1\% 7.1\% and a downbeat F-measure of 85.6\% 85.6\% on a dataset of popular piano music, and the generated transcriptions can be partially used for music performance and assisting human transcribers, thus demonstrating the potential for practical applications.},
  archive      = {J_ISCI},
  author       = {Kentaro Shibata and Eita Nakamura and Kazuyoshi Yoshii},
  doi          = {10.1016/j.ins.2021.03.014},
  journal      = {Information Sciences},
  pages        = {262-280},
  shortjournal = {Inf. Sci.},
  title        = {Non-local musical statistics as guides for audio-to-score piano transcription},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust h∞ observer-based sliding mode control for uncertain
takagi–sugeno fuzzy descriptor systems with unmeasurable premise
variables and time-varying delay. <em>ISCI</em>, <em>566</em>, 239–261.
(<a href="https://doi.org/10.1016/j.ins.2021.02.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on the observer-based sliding mode control (OBSMC) synthesis for non-linear T-S fuzzy descriptor time-varying delay systems, which subject to uncertainties and unmeasurable premise variables (UPVs). Due to the state variables are difficult to completely accessible, a sliding mode observer (SMO) is designed to estimate the unmeasurable variables, and the nonlinear systems are represented to an equivalent multiple model (MM) forms under the MM formulation with UPVs. Then two sliding surfaces are proposed for the observer system and error system respectively to ensure stabilization, which can effectively deal with the nonlinearity and uncertainties as well. By the utilization of the linear matrix inequality (LMI) technique, we present the stability criterions such that the sliding mode dynamics with H ∞ H∞ performance are proved to be admissible. Moreover, the SMC is obtained so we can drive the system trajectories to the predefined sliding surface in a finite time. At last, three simulation examples are provided to certificate the availability of our approach.},
  archive      = {J_ISCI},
  author       = {Zhiqi Wei and Yuechao Ma},
  doi          = {10.1016/j.ins.2021.02.073},
  journal      = {Information Sciences},
  pages        = {239-261},
  shortjournal = {Inf. Sci.},
  title        = {Robust h∞ observer-based sliding mode control for uncertain Takagi–Sugeno fuzzy descriptor systems with unmeasurable premise variables and time-varying delay},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Biased parameter adaptation in differential evolution.
<em>ISCI</em>, <em>566</em>, 215–238. (<a
href="https://doi.org/10.1016/j.ins.2021.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper describes the problem of bias in parameter adaptation in Differential Evolution and other Evolutionary Algorithms . Based on the newly proposed Expected Fitness Improvement metric, the shift towards exploitation is demonstrated. The generalized Lehmer mean and Linear Bias Reduction are for the first time proposed to control the parameter adaptation bias for the fitness improvement based L-SHADE and distance based Db-L-SHADE algorithms. The experiments are performed on the benchmark functions of the Institute of Electrical and Electronics Engineers (IEEE) Congress on Evolutionary Computation (CEC) 2017 competition on real-parameter optimization. The influence of the modified scaling factor and crossover rate adaptation is evaluated using Friedman ranking procedure and Mann–Whitney statistical test. The usage of Lehmer mean and Linear Bias Reduction is shown to deliver statistically better results for high-dimensional functions and improve the exploration properties of the search algorithm in the long-term perspective. To support the statements made, the search process is additionally analyzed using diversity measures and cluster analysis techniques.},
  archive      = {J_ISCI},
  author       = {Vladimir Stanovov and Shakhnaz Akhmedova and Eugene Semenkin},
  doi          = {10.1016/j.ins.2021.03.016},
  journal      = {Information Sciences},
  pages        = {215-238},
  shortjournal = {Inf. Sci.},
  title        = {Biased parameter adaptation in differential evolution},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Echo-state networks for soft sensor design in an SRU
process. <em>ISCI</em>, <em>566</em>, 195–214. (<a
href="https://doi.org/10.1016/j.ins.2021.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The implementation of soft sensors for industrial processes is expanding in applications for recent machine learning techniques . In this work, strategies based on reservoir computing are applied to developing dynamical models of target variables in a sulfur recovery unit (SRU) of a refinery plant in Italy. In particular, a specific type of recurrent network , namely an echo-state network (ESN), is adopted to estimate key process variables on the SRU. Two process lines are considered to evaluate the proposed algorithm on different datasets in terms of estimation performance and computational effort of the learning process. The obtained results are evaluated in comparison with other recurrent networks, based on long short-term memory, and with other techniques reported in the literature, demonstrating the feasibility of the proposed approach. Furthermore, the introduction of intrinsic plasticity (IP) is also considered to adapt the reservoir parameters to the provided inputs, achieving a significant improvement in the statistical distribution of the results obtained for the pool of learned networks. The reported results show that ESN-IP represents a suitable solution for identifying dynamical models of the industrial processes, avoiding the time-consuming regressor selection procedure, which is needed when a static network is adopted to design a dynamical model.},
  archive      = {J_ISCI},
  author       = {Luca Patanè and Maria Gabriella Xibilia},
  doi          = {10.1016/j.ins.2021.03.013},
  journal      = {Information Sciences},
  pages        = {195-214},
  shortjournal = {Inf. Sci.},
  title        = {Echo-state networks for soft sensor design in an SRU process},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive discriminant analysis for semi-supervised feature
selection. <em>ISCI</em>, <em>566</em>, 178–194. (<a
href="https://doi.org/10.1016/j.ins.2021.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As semi-supervised feature selection is becoming much more popular among researchers, many related methods have been proposed in recent years. However, many of these methods first compute a similarity matrix prior to feature selection, and the matrix is then fixed during the subsequent feature selection process. Clearly, the similarity matrix generated from the original dataset is susceptible to the noise features. In this paper, we propose a novel adaptive discriminant analysis for semi-supervised feature selection, namely, SADA. Instead of computing a similarity matrix first, SADA simultaneously learns an adaptive similarity matrix S and a projection matrix W with an iterative process. Moreover. we introduce the ℓ 2 , p ℓ2,p norm to control the sparsity of S by adjusting p. Experimental results show that S will become sparser with the decrease of p. The experimental results for synthetic datasets and nine benchmark datasets demonstrate the superiority of SADA, in comparison with 6 semi-supervised feature selection methods.},
  archive      = {J_ISCI},
  author       = {Weichan Zhong and Xiaojun Chen and Feiping Nie and Joshua Zhexue Huang},
  doi          = {10.1016/j.ins.2021.02.035},
  journal      = {Information Sciences},
  pages        = {178-194},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive discriminant analysis for semi-supervised feature selection},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust node embedding against graph structural
perturbations. <em>ISCI</em>, <em>566</em>, 165–177. (<a
href="https://doi.org/10.1016/j.ins.2021.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite achieving superior performance for many graph-related tasks, recent works have shown that Graph Neural Networks (GNNs) are vulnerable to adversarial attacks on graph structures. In particular, by adding or removing a small number of carefully selected edges in a graph, an adversary can maliciously manipulate a GNNs-based classifier. The vulnerability to adversarial attacks poses numerous concerns for employing GNNs in real-world applications. Previously research aims to overcome the negative impact from adversarial edges with graph-based regularization of some heuristic properties. However, the real-world graph data is far more intricate, and these defense mechanisms do not fully utilize comprehensive semantic information of graph data. In this work, we present a novel defense method, H olistic S emantic C onstraint G raph N eural N etwork (HSC-GNN), which approaches the joint modeling of the node features, labels, and the graph structure to mitigate the effects of malicious perturbations. Extensive experimental evaluation under various graph datasets demonstrates that our approach results in more robust node embedding and better performance than existing models.},
  archive      = {J_ISCI},
  author       = {Zhendong Zhao and Xiaojun Chen and Dakui Wang and Yuexin Xuan and Gang Xiong},
  doi          = {10.1016/j.ins.2021.02.046},
  journal      = {Information Sciences},
  pages        = {165-177},
  shortjournal = {Inf. Sci.},
  title        = {Robust node embedding against graph structural perturbations},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating the phenomenon of NSFW posts in reddit.
<em>ISCI</em>, <em>566</em>, 140–164. (<a
href="https://doi.org/10.1016/j.ins.2021.01.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the characteristics of NSFW (Not Safe For Work) posts in Reddit, highlighting their differences from SFW (Safe For Work) posts, which have been much more studied in the past literature. In our investigation, we studied all Reddit posts from 2019. Through both descriptive analytics techniques and social network analysis techniques, we extract three findings on the main differences between NSFW and SFW posts in Reddit. Thanks to these findings, we are able to better understand the dynamics (authors, subreddits, readers) behind NSFW posts. In particular, it becomes clear that this is a niche world where authors are strongly cohesive. However, at the same time, the most popular ones show a clear opening to new authors, whom they are willing to collaborate with, from the beginning.},
  archive      = {J_ISCI},
  author       = {Enrico Corradini and Antonino Nocera and Domenico Ursino and Luca Virgili},
  doi          = {10.1016/j.ins.2021.01.062},
  journal      = {Information Sciences},
  pages        = {140-164},
  shortjournal = {Inf. Sci.},
  title        = {Investigating the phenomenon of NSFW posts in reddit},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emphasis on the flipping variable: Towards effective local
search for hard random satisfiability. <em>ISCI</em>, <em>566</em>,
118–139. (<a href="https://doi.org/10.1016/j.ins.2021.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uniform random satisfiability (URS) and hard random satisfiability (HRS) are two important benchmarks for algorithms that solve Boolean satisfiability problems, i.e., SAT solvers, especially for random SAT solvers. Recently, the stochastic local search (SLS) algorithms have made major breakthroughs in URS, resulting in several new state-of-the-art algorithms, e.g., Dimetheus, YalSAT, ProbSAT, and Score 2 SAT. However, compared to the great progress of SLS on URS, the performance of SLS on HRS lags far behind. In this paper, we propose a new SLS algorithm, named EPEFV for HRS, which employs the extended framework of ProbSAT, and adds a new heuristic method that emphasizes the role of flipping variable, called EFV . EFV focuses on the flipping variables and is based on three components: 1) A new clause weighting scheme focusing on the flipping variable, which is based on a new clause property called UnsatT . By applying this new weighting scheme and a biased random walk, we design a new clause selection mechanism. 2) Design a new scoring function named U v by combining a novel variable property vUnsatT based on the flipping variable with the commonly used property score .3) A new tie-breaking strategy in the variable selection mechanism based on the new scoring function U v . Extensive experimental results demonstrate that EPEFV can not only greatly outperforms the state-of-the-art SLS algorithms as well as complete solver competitors on HRS instances, but also can effectively solve URS instances with long clauses. On the contrary, the most advanced SLS solvers, however, can only effectively solve URS instances, while the most advanced complete solvers can only effectively solve HRS instances. At present, no solver can effectively solve both HRS and URS at the same time, which means that the EPEFV can be regarded as the state-of-the-art SLS solver for both HRS instances and URS instances with long clauses. Finally, further empirical analysis confirms the effectiveness of each mechanism underlying the EFV heuristic on HRS instances.},
  archive      = {J_ISCI},
  author       = {Huimin Fu and Yang Xu and Guanfeng Wu and Jun Liu and Shuwei Chen and Xingxing He},
  doi          = {10.1016/j.ins.2021.03.009},
  journal      = {Information Sciences},
  pages        = {118-139},
  shortjournal = {Inf. Sci.},
  title        = {Emphasis on the flipping variable: Towards effective local search for hard random satisfiability},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-driven structural damage detection framework based on
parallel convolutional neural network and bidirectional gated recurrent
unit. <em>ISCI</em>, <em>566</em>, 103–117. (<a
href="https://doi.org/10.1016/j.ins.2021.02.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the extensive use of structural health monitoring technologies, vibration-based structural damage detection becomes a crucial task in both academic and industrial communities. Following the noteworthy trends of data-driven paradigms in recent years, some solutions have been released to identify, localize, and classify damages via deep neural networks . However, some deficiencies still exist for effective damage-intensive feature extraction and representation. To overcome such a problem, this paper proposes a novel end-to-end structural damage detection neural model by taking the advantages of the Convolutional Neural Network and Bidirectional Gated Recurrent Unit in parallel. The well-known IASC-ASCE benchmark and TCRF dataset are used for evaluation. The experimental results show that the proposed approach can achieve a better detecting effect than other existing manners.},
  archive      = {J_ISCI},
  author       = {Jianxi Yang and Fei Yang and Yingxin Zhou and Di Wang and Ren Li and Guiping Wang and Wangqiao Chen},
  doi          = {10.1016/j.ins.2021.02.064},
  journal      = {Information Sciences},
  pages        = {103-117},
  shortjournal = {Inf. Sci.},
  title        = {A data-driven structural damage detection framework based on parallel convolutional neural network and bidirectional gated recurrent unit},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary continuous constrained optimization using
random direction repair. <em>ISCI</em>, <em>566</em>, 80–102. (<a
href="https://doi.org/10.1016/j.ins.2021.02.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve constrained optimization problems (COPs), it is crucial to guide the infeasible solution to a feasible region. Gradient-based repair (GR) is a successful repair strategy, where the forward difference is often used to estimate the gradient. However, GR has major deficiencies. First, it is difficult to deal with individuals falling into the local optima. Second, large amounts of fitness evaluations are required to estimate the gradient. In this paper, we proposed a new repair strategy, random direction repair (RDR). RDR generates a set of random directions, and calculates the repair direction and the repair step size of infeasible individual to reduce its constraint violation. Since the introduction of randomness, RDR could deal with individuals falling into the local optima. Furthermore, RDR only requires a few number of fitness evaluation. To demonstrate the performance of RDR, RDR was embedded into two state-of-the-art evolutionary continuous constrained optimization algorithms, tested on the Congress on Evolutionary Computation 2017 constrained real-parameter optimization benchmark. Experimental results demonstrated that RDR combined with evolutionary algorithms are highly competitive.},
  archive      = {J_ISCI},
  author       = {Peilan Xu and Wenjian Luo and Xin Lin and Yingying Qiao},
  doi          = {10.1016/j.ins.2021.02.055},
  journal      = {Information Sciences},
  pages        = {80-102},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary continuous constrained optimization using random direction repair},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FQTSFM: A fuzzy-quantum time series forecasting model.
<em>ISCI</em>, <em>566</em>, 57–79. (<a
href="https://doi.org/10.1016/j.ins.2021.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The study shows that there are two main problems that affect the performance of fuzzy time series (FTS) models, namely the selection of the universe of discourse and the determination of the fuzzy degree of the memberships. However, the selection of the appropriate universe of discourse along with the degree of memberships is simultaneously associated with the multiobjective optimization problem (MOOP). Therefore, in this study, an improved version of the quantum optimization algorithm (QOA) has been proposed to find their optimal solutions. This improved QOA is called fast forward quantum optimization algorithm (FFQOA) . Finally, by integrating FFQOA with the FTS modelling approach, a hybrid model called fuzzy-quantum time series forecasting model (FQTSFM) is designed. The main objective of FFQOA in FQTSFM is to select the Pareto-optimal front (POF) from all optimal non-dominated Pareto solutions by using the archive and grid concept during simulation. The main advantages of the proposed FQTSFM are that it converges very fast compared to the existing hybridized based FTS models and is able to evolve one-step ahead forecasted results. The FQTSFM is tested with three different datasets, namely daily average temperatures of Taipei, Taiwan Futures Exchange (TAIFEX) index and Taiwan Stock Exchange Corporation (TSEC) weighted index. The performance of the FQTSFM is compared with various established well-known FTS and non-FTS models in terms of different statistical metrics. In the case of daily average temperatures, TAIFEX index and TSEC weighted index datasets, the FQTSFM achieves correlation coefficients of 0.9988, 0.9978 and 0.9768, respectively. For daily average temperatures, TAIFEX index and TSEC weighted index datasets, the Theil’s U statistic values of the FQTSFM are 0.0022, 0.0022 and 0.0054, respectively. The FQTSFM has mean squared errors of 0.3959, 22.3965 and 83.6793 for the daily average temperatures, the TAIFEX index and the TSEC-weighted index datasets, respectively. In the case of daily average temperatures, TAIFEX index and TSEC weighted index datasets, the FQTSFM shows cross entropy values of 3.3498, 189.5018 and 708.0296, respectively. These metrics, including other empirical analyses, confirm that the forecasted accuracy of the proposed FQTSFM exceeds that of well-known time series models.},
  archive      = {J_ISCI},
  author       = {Pritpal Singh},
  doi          = {10.1016/j.ins.2021.02.024},
  journal      = {Information Sciences},
  pages        = {57-79},
  shortjournal = {Inf. Sci.},
  title        = {FQTSFM: A fuzzy-quantum time series forecasting model},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multicriteria group decision-making method based on
AIVIFSs, z-numbers, and trapezium clouds. <em>ISCI</em>, <em>566</em>,
38–56. (<a href="https://doi.org/10.1016/j.ins.2021.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multicriteria group decision-making (MCGDM), with the strong uncertainty and randomness, has always been a hotspot in the world. The chief purpose of the paper is to address the problem with Atanassov’s interval-valued intuitionistic fuzzy sets (AIVIFSs), Z-numbers, and trapezium clouds. First, some related concepts and former operators of AIVIFSs, Z-numbers, and trapezium clouds are reviewed, meanwhile, AIVIFSs and Z-numbers are synthesized to come up with a novel linguistic expression . Then, Z-trapezium-trapezium cloud (ZTTC) is proposed to quantify the linguistic evaluation information to avoid excessive computation caused by traditional methods. Later, a new approach of calculating the objective weight vector is presented based on entropy weight method (EWM). To take the huge advantages of technique for order preference by similarity to ideal solution (TOPSIS) method in ranking, 2-norm in mathematical theory is applied to derive a way of calculating the distance between different ZTTCs. Finally, an example about the grade assessment of coronavirus Disease 2019 (COVID-19) is given. For further confirming the validity and feasibility, sensitivity analysis and comparison with other methods are conducted.},
  archive      = {J_ISCI},
  author       = {Qianlei Jia and Jiayue Hu and Qizhi He and Weiguo Zhang and Ehab Safwat},
  doi          = {10.1016/j.ins.2021.02.042},
  journal      = {Information Sciences},
  pages        = {38-56},
  shortjournal = {Inf. Sci.},
  title        = {A multicriteria group decision-making method based on AIVIFSs, Z-numbers, and trapezium clouds},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RT-GSOM: Rough tolerance growing self-organizing map.
<em>ISCI</em>, <em>566</em>, 19–37. (<a
href="https://doi.org/10.1016/j.ins.2021.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of rough tolerance set is introduced within growing self-organizing map (GSOM) to reduce the uncertainty in decision-making by developing a new algorithm, namely rough tolerance GSOM (RT-GSOM). This algorithm aims to address the issues of (i) identifying the suitable size of clusters in SOM , (ii) information loss in rough SOM (RSOM), and (iii) uncertainty arising from the overlapping patterns of decision classes in GSOM. In RT-GSOM, the network is allowed to grow based on indiscernible reducts and tolerance thresholds extracted from data in an unsupervised way. The network is initialized with the samples extracted from these reducts, and the weights are initialized with random category index. For each decision class, one set of indiscernible reducts is obtained. The tolerance threshold for each decision class is defined using the average distance among all the samples present in the reduct set corresponding to the same class. The superiority of RT-GSOM is demonstrated over twelve benchmark datasets (both categorical and continuous) obtained from UCI machine learning repository. Results reveal that RT-GSOM is efficient than some state-of-the-art algorithms in terms of learning rate , and quality of clusters for both categorical, and continuous data.},
  archive      = {J_ISCI},
  author       = {Anima Pramanik and Sobhan Sarkar and J. Maiti and Pabitra Mitra},
  doi          = {10.1016/j.ins.2021.01.039},
  journal      = {Information Sciences},
  pages        = {19-37},
  shortjournal = {Inf. Sci.},
  title        = {RT-GSOM: Rough tolerance growing self-organizing map},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised feature selection using integration of densest
subgraph finding with floating forward–backward search. <em>ISCI</em>,
<em>566</em>, 1–18. (<a
href="https://doi.org/10.1016/j.ins.2021.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel approach of supervised feature selection is proposed based on the principle of dense subgraph discovery. To exploit dense subgraph discovery for the purpose of feature selection, the dataset is initially mapped to an equivalent weighted graph notation by considering the set of all features as its vertex set and the mutual dependency between each pair of features as the weight of the corresponding edge. The proposed feature selection algorithm proceeds in a two-phase manner. In the first stage, a dense sub-graph is first discovered so that the features within it become maximally non-redundant among each other and the averaged class relevance as well as averaged standard deviation of all these features are obtained as maximal as possible. In this regard, a novel induced degree is also defined for each feature by incorporating the aforesaid three important objectives of feature selection. In this phase, a modified version of an existing approximation algorithm is also used to find dense subgraph module. Finally, in the second stage, a floating forward–backward search is performed on the dense subgraph so obtained to reveal a better feature subset. In both stages, an existing version of the normalized mutual information score is employed to compute both the class relevance and redundancy. The main contribution of this paper is proposing a feature selection strategy by which the reduced features have the characteristics like maximal average class relevance, minimal average pairwise redundancy, and good discriminating power. The experimental results demonstrate that the proposed approach is competent with several conventional as well as state-of-art algorithms of supervised feature selection.},
  archive      = {J_ISCI},
  author       = {Tapas Bhadra and Sanghamitra Bandyopadhyay},
  doi          = {10.1016/j.ins.2021.02.034},
  journal      = {Information Sciences},
  pages        = {1-18},
  shortjournal = {Inf. Sci.},
  title        = {Supervised feature selection using integration of densest subgraph finding with floating forward–backward search},
  volume       = {566},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Continuous-time synthesizing robust sampled-data dynamic
output-feedback controllers for uncertain nonlinear systems in
takagi–sugeno form: A descriptor representation approach. <em>ISCI</em>,
<em>565</em>, 456–468. (<a
href="https://doi.org/10.1016/j.ins.2021.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses controller design techniques for robust sampled-data dynamic output-feedback (DOF) for nonlinear systems in the Takagi–Sugeno (T–S) fuzzy form with parametric uncertainties and L 2 L2 / L ∞ L∞ disturbances. We perform the sampled-data syntheses in a continuous-time domain based on an augmented sampled-data closed-loop model in descriptor form. Hence, the investigation does not require any (approximate) discrete-time model of a T–S fuzzy system, which is a significant obstacle in nonlinear sampled-data control system designs. Moreover, various cross-product terms among system matrices, to-be-designed DOF controller matrices, and other decision variables are reduced, yielding single-stage linear matrix inequality-based design conditions.},
  archive      = {J_ISCI},
  author       = {Jaejun Lee and Ji Hyun Moon and Ho Jae Lee},
  doi          = {10.1016/j.ins.2021.02.032},
  journal      = {Information Sciences},
  pages        = {456-468},
  shortjournal = {Inf. Sci.},
  title        = {Continuous-time synthesizing robust sampled-data dynamic output-feedback controllers for uncertain nonlinear systems in Takagi–Sugeno form: A descriptor representation approach},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel oversampling technique for class-imbalanced learning
based on SMOTE and natural neighbors. <em>ISCI</em>, <em>565</em>,
438–455. (<a href="https://doi.org/10.1016/j.ins.2021.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing techniques for the machine learning of a classifier from class-imbalanced data presents an important challenge. Among the existing methods for addressing this problem, SMOTE has been successful, has received great praise, and features an extensive range of practical applications. In this paper, we focus on SMOTE and its extensions, aiming to solve the most challenging issues, namely, the choice of the parameter k and the determination of the neighbor number of each sample. Hence, a synthetic minority oversampling technique with natural neighbors (NaNSMOTE) is proposed. In NaNSMOTE, the random difference between a selected base sample and one of its natural neighbors is used to generate synthetic samples. The main advantages of NaNSMOTE are that (a) it has an adaptive k value related to the data complexity; (b) samples of class centers have more neighbors to improve the generalization of synthetic samples, while border samples have fewer neighbors to reduce the error of synthetic samples; and (c) it can remove outliers. The effectiveness of NaNSMOTE is proven by comparing it with SMOTE and extended versions of SMOTE on real data sets .},
  archive      = {J_ISCI},
  author       = {Junnan Li and Qingsheng Zhu and Quanwang Wu and Zhu Fan},
  doi          = {10.1016/j.ins.2021.03.041},
  journal      = {Information Sciences},
  pages        = {438-455},
  shortjournal = {Inf. Sci.},
  title        = {A novel oversampling technique for class-imbalanced learning based on SMOTE and natural neighbors},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ARAIL: Learning to rank from incomplete demonstrations.
<em>ISCI</em>, <em>565</em>, 422–437. (<a
href="https://doi.org/10.1016/j.ins.2021.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Imitation Learning (GAIL) has been successfully applied to imitation learning in control tasks. However, most GAIL-like approaches require complete and high-quality demonstrations that are scarcely available in practice, which leads to unsatisfactory performances. Researches have proposed algorithms for incomplete demonstrations, which, however, are supposed to be effective only when exceptionally high-quality demonstrations are provided. To solve the problem, the Action-Rank Adversarial Imitation Learning (ARAIL) algorithm is introduced to target the issue of incomplete demonstrations. By reconstructing the standard GAIL framework and introducing the ranker model, ARAIL reshapes the reward function from the discriminator and auxiliary information from the ranker. The primary insight is that the ranker makes a better assessment of missing actions, which in turn helps to learn a better policy. We empirically compare our approach with SOTA algorithms on Atari and Mujoco platforms with imitation learning benchmarks, demonstrating that ARAIL improves both performance and robustness on various levels of incompleteness of actions in demonstrations.},
  archive      = {J_ISCI},
  author       = {Dayong Xu and Fei Zhu and Quan Liu and Peiyao Zhao},
  doi          = {10.1016/j.ins.2021.02.001},
  journal      = {Information Sciences},
  pages        = {422-437},
  shortjournal = {Inf. Sci.},
  title        = {ARAIL: Learning to rank from incomplete demonstrations},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive polyploid memetic algorithm for scheduling
trucks at a cross-docking terminal. <em>ISCI</em>, <em>565</em>,
390–421. (<a href="https://doi.org/10.1016/j.ins.2021.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many supply chain stakeholders rely on the cross-docking concept, according to which products delivered in specific transportation management units to the cross-docking terminal (CDT) undergo decomposition, sorting based on the end customer preferences, consolidation, and then transported to the final destinations. Scheduling of the inbound and outbound trucks for service at the CDT doors is considered as one of the convoluted decision problems faced by the CDT operators. This study proposes a new Adaptive Polyploid Memetic Algorithm (APMA) for the problem of scheduling CDT trucks that can assist with proper CDT operations planning. APMA directly relies on the polyploidy concept, where copies of the parent chromosomes (i.e., solutions) are stored before performing the crossover operations and producing the offspring chromosomes. The number of chromosome copies is controlled through the adaptive polyploid mechanism based on the objective function improvements achieved and computational time changes. Moreover, a number of problem-specific hybridization techniques are used within the algorithm to facilitate the search process. Computational experiments show that the application of adaptive polyploidy alone may not be sufficient for the considered decision problem. Hybridization techniques that directly consider problem-specific properties are required in order to improve solution quality at convergence. Furthermore, the APMA algorithm developed in this article substantially outperforms some of the well-known state of the art metaheuristics with regards to solution quality and returns truck schedules that have lower total truck service cost.},
  archive      = {J_ISCI},
  author       = {Maxim A. Dulebenets},
  doi          = {10.1016/j.ins.2021.02.039},
  journal      = {Information Sciences},
  pages        = {390-421},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive polyploid memetic algorithm for scheduling trucks at a cross-docking terminal},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaborative filtering with a deep adversarial and
attention network for cross-domain recommendation. <em>ISCI</em>,
<em>565</em>, 370–389. (<a
href="https://doi.org/10.1016/j.ins.2021.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation can alleviate the data sparsity problem in the target domain and has become a promising research area. Recently, various models have been proposed to provide recommendation across domains. Some models successfully embedded adversarial learning to reduce domain discrepancies between the source and target domains; however, these models only focuse on extracting the domain-shared features among multiple domains. In this paper, we devise a novel framework that considers both domain-shared and domain-specific knowledge across domains, namely, DAAN . Specifically, we tightly couple matrix factorization-based collaborative filtering with deep adversarial domain adaptation via an attention network . In this framework, we first learn the domain-specific representations for each user and each item from the source and target user-item interaction matrices . Then, we capture the domain-shared features between two domains with common user (or item) embeddings in a domain-adversarial paradigm. Additionally, an attention network is used to adjust the degree of importance between domain-shared and domain-specific knowledge. Extensive experiments on six tasks demonstrate that our method outperforms various baselines in terms of two ranking metrics. To the best of our knowledge, our proposed approach is the first deep model that considers both domain-shared and domain-specific knowledge across domains within a domain-adversarial training paradigm for cross-domain recommendation.},
  archive      = {J_ISCI},
  author       = {Huiting Liu and Lingling Guo and Peipei Li and Peng Zhao and Xindong Wu},
  doi          = {10.1016/j.ins.2021.02.009},
  journal      = {Information Sciences},
  pages        = {370-389},
  shortjournal = {Inf. Sci.},
  title        = {Collaborative filtering with a deep adversarial and attention network for cross-domain recommendation},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive density-based clustering algorithm with shared KNN
conflict game. <em>ISCI</em>, <em>565</em>, 344–369. (<a
href="https://doi.org/10.1016/j.ins.2021.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, density-based clustering algorithms have been garnering considerable attention in the unsupervised learning field as they can identify arbitrary cluster shapes. However, classical density-based algorithms are non-backtracking such as density-based spatial clustering of applications with noise (DBSCAN) and its improved variants. Therefore, the allocation of samples cannot be optimised during the clustering process . An incorrect division can cause subsequent errors. Furthermore, when the density is unevenly distributed, the globally uniform parameters will inevitably lead to catastrophic error consequences. To address these limitations, this study proposes an adaptive density-based clustering algorithm using the shared k-nearest neighbours (SKNN) conflict game (DC-SKCG). A local density-based adaptive cut-off distance-setting method is designed for the DC-SKCG, and a conflict game method based on SKNN is proposed to optimise the clustering process. Moreover, an automatic fusion mechanism for redundant high-density core regions is presented to (1) reduce the parameter sensitivity of the algorithm and (2) improve the parameter tolerance capacity. A series of experiments are conducted using various datasets demonstrate that DC-SKCG offers higher accuracy and robustness in most cases than state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Rui Zhang and Tao Du and Shouning Qu and Hongwei Sun},
  doi          = {10.1016/j.ins.2021.02.017},
  journal      = {Information Sciences},
  pages        = {344-369},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive density-based clustering algorithm with shared KNN conflict game},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DFFNet: An IoT-perceptive dual feature fusion network for
general real-time semantic segmentation. <em>ISCI</em>, <em>565</em>,
326–343. (<a href="https://doi.org/10.1016/j.ins.2021.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is a valuable yet challenging research in the Internet of Things (IoT), especially for some real-time and resource-constrained applications. Recently we witness a strong tendency of fusing multi-level features or multi-scale context information to achieve promising segmentation performance . However, we find that existing literature has at least one of the following issues: 1) relying on more resource-consuming feature extraction operations, e.g., standard convolution with large kernels, for multiple information fusion; 2) seldom considering that how to narrow the semantic gap between multi-layer features, leading to sub-optimal performance. To tackle these issues, we propose a novel IoT-perceptive Dual Feature Fusion Network (DFFNet) for semantic segmentation, which aims to leverage multi-level features and multi-scale context information in an efficient yet effective manner. Specifically, the multi-level feature fusion module (MFFM), which enhances the semantic consistency between multi-level features by two attention refinement blocks, is proposed to exploit multi-layer features for jointly learning spatial and semantic information with small overheads. Moreover, a multi-scale component termed as lightweight semantic pyramid module (LSPM) is presented to improve the efficiency of context encoding by depthwise factorized convolution operations. Extensive experimental results on benchmarks have demonstrated that DFFNet achieves better performance than existing advanced methods.},
  archive      = {J_ISCI},
  author       = {Xiangyan Tang and Wenxuan Tu and Keqiu Li and Jieren Cheng},
  doi          = {10.1016/j.ins.2021.02.004},
  journal      = {Information Sciences},
  pages        = {326-343},
  shortjournal = {Inf. Sci.},
  title        = {DFFNet: An IoT-perceptive dual feature fusion network for general real-time semantic segmentation},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast finite time adaptive neural network control for a class
of uncertain nonlinear systems subject to unmodeled dynamics.
<em>ISCI</em>, <em>565</em>, 306–325. (<a
href="https://doi.org/10.1016/j.ins.2021.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a fast finite time adaptive control issue is discussed for a class of uncertain nonlinear systems . The systems considered involve unmodeled dynamics as well as dynamical disturbances. First, neural networks (NNs) are introduced to deal with the difficulties caused by unknown nonlinear uncertainties, and dynamical signal functions are utilized to handle unmodeled dynamics and dynamical disturbances. Second, based on adaptive backstepping technique and a fast finite-time stability criterion, a fast finite time adaptive neural network control scheme for a class of uncertain nonlinear systems subject to unmodeled dynamics is proposed for the first time. The proposed control scheme can not only ensure that all closed-loop signals are bounded, but also has the robustness to unmodeled dynamics and dynamical disturbances. The main innovations of this work lie in the ingenious design of parameter adaptive laws and controller, and the development of fast finite-time adaptive control algorithm from a new point of view. Finally, the feasibility of the proposed control algorithm is elaborated by two simulation examples.},
  archive      = {J_ISCI},
  author       = {Yan Zhang and Fang Wang and Feng Yan},
  doi          = {10.1016/j.ins.2021.02.048},
  journal      = {Information Sciences},
  pages        = {306-325},
  shortjournal = {Inf. Sci.},
  title        = {Fast finite time adaptive neural network control for a class of uncertain nonlinear systems subject to unmodeled dynamics},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel wrapper-based feature subset selection method using
modified binary differential evolution algorithm. <em>ISCI</em>,
<em>565</em>, 278–305. (<a
href="https://doi.org/10.1016/j.ins.2021.02.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In classification problems, normally there exists a large number of features, but not all of them contributing to the improvement of classification performance. These redundant features make the classification problem time consuming and often result in poor performance. Feature selection methods have been proposed to reduce the number of features, minimize computational cost, and maximize classification accuracy. As a wrapper-based approach, evolutionary algorithms have been widely applied in feature subset selection tasks. However, some of them trap into local minima, especially when the number of features increases, while others are not efficient in computational time. This paper proposes a Modified Differential Evolution (DE) approach to Feature Selection (MDEFS) by utilizing two new mutation strategies to create a feasible balance between exploration and exploitation and maintain the classification performance in an acceptable range concerning both the number of features and accuracy. Some modifications are made to the standard DE crossover and its key control parameters to enhance the proposed algorithm’s capabilities further. The proposed method has been compared to several state-of-the-art methods utilizing standard datasets from the UCI repository and results of the experiments demonstrate the superiority of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Omid Tarkhaneh and Thanh Thi Nguyen and Samaneh Mazaheri},
  doi          = {10.1016/j.ins.2021.02.061},
  journal      = {Information Sciences},
  pages        = {278-305},
  shortjournal = {Inf. Sci.},
  title        = {A novel wrapper-based feature subset selection method using modified binary differential evolution algorithm},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Micro-MetaStream: Algorithm selection for time-changing
data. <em>ISCI</em>, <em>565</em>, 262–277. (<a
href="https://doi.org/10.1016/j.ins.2021.02.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data stream mining needs to deal with scenarios where data distribution can change over time. As a result, different learning algorithms can be more suitable in different time periods. This paper proposes micro-MetaStream, a meta-learning based method to recommend the most suitable learning algorithm for each new example arriving in a data stream. It is an evolution of MetaStream, which recommends learning algorithms for batches of examples. By using a unitary granularity, micro-MetaStream is able to respond more efficiently to changes in data distribution than its predecessor. The meta-data combines meta-features, characteristics describing recent data, with base-level features, the original variables of the new example. In experiments on real-world regression data streams, micro-metaStream outperformed MetaStream and a baseline method at the meta-level and frequently improved the predictive performance at the base-level.},
  archive      = {J_ISCI},
  author       = {André Luis Debiaso Rossi and Carlos Soares and Bruno Feres de Souza and André Carlos Ponce de Leon Ferreira de Carvalho},
  doi          = {10.1016/j.ins.2021.02.075},
  journal      = {Information Sciences},
  pages        = {262-277},
  shortjournal = {Inf. Sci.},
  title        = {Micro-MetaStream: Algorithm selection for time-changing data},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). A curvature-segmentation-based minimum time algorithm for
autonomous vehicle velocity planning. <em>ISCI</em>, <em>565</em>,
248–261. (<a href="https://doi.org/10.1016/j.ins.2021.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Velocity planning serves as an important issue in motion planning for autonomous vehicles. The presented paper proposes a novel velocity planning method with minimum moving time on the basis of path curvature which is accomplished in three steps. First, the assigned path is divided into some elementary parts based on the path curvature . Second, the velocity planning is transformed into an unconstrained optimization problem by assuming the velocity of vehicle to be a specific cubic polynomial on every elementary part to avoid a sudden acceleration in path switching. Finally, we use a modified projection particle swarm optimization (PPSO) algorithm to obtain the time-optimal velocity profile . The proposed method can generate a smooth time-optimal velocity profile while considering all possible relevant constraints. Three examples are provided on different types of path to demonstrate that the final velocity profile is efficient to avoid the sudden acceleration change. Furthermore, the modified PPSO algorithm in this paper is used to solve the optimization problem with high dimensional variables when its upper bound is known, which can not be achieved by the general PPSO algorithm.},
  archive      = {J_ISCI},
  author       = {Miao Wang and Qingshan Liu and Yanling Zheng},
  doi          = {10.1016/j.ins.2021.02.037},
  journal      = {Information Sciences},
  pages        = {248-261},
  shortjournal = {Inf. Sci.},
  title        = {A curvature-segmentation-based minimum time algorithm for autonomous vehicle velocity planning},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The detection of low-rate DoS attacks using the SADBSCAN
algorithm. <em>ISCI</em>, <em>565</em>, 229–247. (<a
href="https://doi.org/10.1016/j.ins.2021.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rate denial-of-service (DoS) attacks, which can exploit vulnerabilities in Internet protocols to deteriorate the quality of service, are variants of DoS attacks. It is challenging to identify low-rate DoS attacks using traditional DoS defence mechanisms due to their low attack rate and stealthy nature. Most of the existing attack detection techniques are based on statistical analysis and signal processing. They usually show a high false negative rate and are only applicable to small-scale data. We propose a new low-rate DoS attack detection scheme based on the self-adaptive density-based spatial clustering of applications with noise (SADBSCAN) algorithm. The SADBSCAN algorithm provides a solution to adaptively identify clusters in multidensity datasets. We use the SADBSCAN algorithm to group network traffic according to the characteristics of the network traffic subject to low-rate DoS attacks. Then, we use cosine similarity to determine whether the groups contain low-rate DoS attacks. To evaluate performance, we conducted experiments and compared the results with those of other detection solutions. The experimental data include data generated by the NS-2 and TestBed simulations and the WIDE public dataset. The results show that our scheme improves the detection accuracy, reduces the false negative rate, and can be adapted to large-scale complex network environments.},
  archive      = {J_ISCI},
  author       = {Dan Tang and Siqi Zhang and Jingwen Chen and Xiyin Wang},
  doi          = {10.1016/j.ins.2021.02.038},
  journal      = {Information Sciences},
  pages        = {229-247},
  shortjournal = {Inf. Sci.},
  title        = {The detection of low-rate DoS attacks using the SADBSCAN algorithm},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective anytime algorithm for multiobjective combinatorial
optimization problems. <em>ISCI</em>, <em>565</em>, 210–228. (<a
href="https://doi.org/10.1016/j.ins.2021.02.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multiobjective optimization , the result of an optimization algorithm is a set of efficient solutions from which the decision maker selects one. It is common that not all the efficient solutions can be computed in a short time and the search algorithm has to be stopped prematurely to analyze the solutions found so far. A set of efficient solutions that are well-spread in the objective space is preferred to provide the decision maker with a great variety of solutions. However, just a few exact algorithms in the literature exist with the ability to provide such a well-spread set of solutions at any moment: we call them anytime algorithms. We propose a new exact anytime algorithm for multiobjective combinatorial optimization combining three novel ideas to enhance the anytime behavior. We compare the proposed algorithm with those in the state-of-the-art for anytime multiobjective combinatorial optimization using a set of 480 instances from different well-known benchmarks and four different performance measures : the overall non-dominated vector generation ratio, the hypervolume, the general spread and the additive epsilon indicator. A comprehensive experimental study reveals that our proposal outperforms the previous algorithms in most of the instances.},
  archive      = {J_ISCI},
  author       = {Miguel Ángel Domínguez-Ríos and Francisco Chicano and Enrique Alba},
  doi          = {10.1016/j.ins.2021.02.074},
  journal      = {Information Sciences},
  pages        = {210-228},
  shortjournal = {Inf. Sci.},
  title        = {Effective anytime algorithm for multiobjective combinatorial optimization problems},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PA-net: Learning local features using by pose attention for
short-term person re-identification. <em>ISCI</em>, <em>565</em>,
196–209. (<a href="https://doi.org/10.1016/j.ins.2021.02.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) is an important but challenging task in video surveillance applications. In Re-ID tasks, pose is an extremely useful cue to identify a person, even from the back view. Therefore, pose-detection models may learn the features that are beneficial to the Re-ID task and improve the Re-ID performance by fusing the feature maps into the Re-ID model. Two key problems in integrating the pose cues are addressed in this study. One is how to reduce the noise caused by cross-domain datasets. The other is how to fuse the feature maps to better utilize high-level semantic pose cues. To address these two key problems, we first propose PA-Net by combining the pose attention stream and the global attention stream, where the global attention stream distinguishes persons with different global appearances, and the pose attention stream distinguishes persons with similar global appearance but different poses. Then, we present a pose attention stream that learns local features to reduce the noise in the pose cues caused by the cross-domain datasets and provide more semantic information for the Re-ID task. The effects of the proposed pose attention are demonstrated in an ablation study, and comparative experiments show that PA-Net achieves state-of-the-art performance.},
  archive      = {J_ISCI},
  author       = {Kai Wang and Shichao Dong and Nian Liu and Junhui Yang and Tao Li and Qinghua Hu},
  doi          = {10.1016/j.ins.2021.02.066},
  journal      = {Information Sciences},
  pages        = {196-209},
  shortjournal = {Inf. Sci.},
  title        = {PA-net: Learning local features using by pose attention for short-term person re-identification},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed optimization without boundedness of gradients
for second-order multi-agent systems over unbalanced network.
<em>ISCI</em>, <em>565</em>, 177–195. (<a
href="https://doi.org/10.1016/j.ins.2021.02.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is mainly devoted to the distributed second-order multi-agent optimization problem with unbalanced and directed networks, where the gradient of the private objective functions might be unbounded. To deal with this problem, a new distributed algorithm is proposed based on the local neighbor information and the private objective functions. By a coordination transformation, the closed-loop system is divided into two simple first-order subsystems. Under the assumption of the strong connectivity of networks, it is proved that all agents can collaboratively converge to some optimal solution of the team objective function. At last, we give two numerical examples to show the effectiveness of our proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Lipo Mo and Haokun Hu and Yongguang Yu and Guojian Ren},
  doi          = {10.1016/j.ins.2021.02.049},
  journal      = {Information Sciences},
  pages        = {177-195},
  shortjournal = {Inf. Sci.},
  title        = {Distributed optimization without boundedness of gradients for second-order multi-agent systems over unbalanced network},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ClEnDAE: A classifier based on ensembles with built-in
dimensionality reduction through denoising autoencoders. <em>ISCI</em>,
<em>565</em>, 146–176. (<a
href="https://doi.org/10.1016/j.ins.2021.02.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dimensionality is an issue that affects most classification algorithms . This factor implies that the predictive performance of many traditional classifiers decreases considerably as the number of features increases. Therefore, there are numerous proposals that try to mitigate the effects of this issue. This study proposes ClEnDAE , a new classifier based on ensembles whose components incorporate denoising autoencoders (DAEs) to reduce the dimensionality of the input space. On the one hand, the use of ensembles improves the predictive performance by using several components that work jointly. On the other hand, the use of DAEs allows a new higher-level, smaller-sized feature space to be generated, reducing high dimensionality effects. Finally, an experimentation is conducted with the goal of evaluating the behavior of ClEnDAE . The first part of the test compares the performance of ClEnDAE to a model based on basic DAE and to the original untreated data. The second part analyzes the results of ClEnDAE and other traditional methods of dimensionality reduction in order to determine the improvement achieved with the proposed algorithm. In both parts of the experimentation, conclusions show that ClEnDAE offers better predictive performance than the other analyzed models. The main advantage of the ClEnDAE method is the combination of the potential of the ensemble-based methodology, where several components work in parallel, and DAEs, which generate new low-dimensional features that provide more relevant information. Therefore, the classification performance is better than with other classic proposals.},
  archive      = {J_ISCI},
  author       = {Francisco J. Pulgar and Francisco Charte and Antonio J. Rivera and María J. del Jesus},
  doi          = {10.1016/j.ins.2021.02.060},
  journal      = {Information Sciences},
  pages        = {146-176},
  shortjournal = {Inf. Sci.},
  title        = {ClEnDAE: A classifier based on ensembles with built-in dimensionality reduction through denoising autoencoders},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information space of multi-sensor networks. <em>ISCI</em>,
<em>565</em>, 128–145. (<a
href="https://doi.org/10.1016/j.ins.2021.02.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a challenging problem to explore the capability of multi-sensor networks due to the identity of the underlying information space across modalities. In this paper, the information space for multi-sensor networks is developed from information geometry . The relationship between information space and the performance of multi-sensor networks is investigated. Different sensor information obtained by multi-sensor networks is represented, analyzed and fused concisely. The structure of the information space is studied such as geodesic, Ricci tensor and the information metric matrix. The structural properties of the information space are introduced: i) the symmetry; ii) the connection between information space’s curvature and Einstein’s field equation; iii) noise essence conjecture. The proposed analysis techniques are validated in many scenarios. The theoretical demonstration and numerical results indicate that the information described in different coordinate systems is equivalent.},
  archive      = {J_ISCI},
  author       = {Mo Tao and Shaoping Wang and Hong Chen and Xingjian Wang},
  doi          = {10.1016/j.ins.2021.02.059},
  journal      = {Information Sciences},
  pages        = {128-145},
  shortjournal = {Inf. Sci.},
  title        = {Information space of multi-sensor networks},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TAGA: Tabu asexual genetic algorithm embedded in a
filter/filter feature selection approach for high-dimensional data.
<em>ISCI</em>, <em>565</em>, 105–127. (<a
href="https://doi.org/10.1016/j.ins.2021.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is the process of selecting an optimal subset of features required for maintaining or improving the performance of data mining models . Recently, hybrid filter/wrapper feature selection methods have shown promising results for high-dimensional data. However, filter/wrapper methods lack of generalisation power, which enables the selected features to be trainable over different classifiers without having to repeat the feature selection process. To address the generalisation power problem, this paper proposes a novel evolutionary-based filter feature selection algorithm that is sequentially hybridised with the Fisher score filter algorithm in a new hybrid framework called filter/filter. The proposed algorithm is based on a long-term memory Tabu Search combined with an Asexual (i.e. mutation-based) Genetic Algorithm (TAGA). TAGA benefits from a new integer-encoded solution representation, a novel mutation operator , a new tabu list encoding scheme, and uses a minimum redundancy maximum relevance information theory-based criterion as the fitness function. Experiments were carried out on various high-dimensional datasets including image, text, and biological data. The goodness of the selected subsets was evaluated using different classifiers and the experimental results demonstrate that TAGA outperforms other conventional and state-of-the-art feature selection algorithms.},
  archive      = {J_ISCI},
  author       = {Sadegh Salesi and Georgina Cosma and Michalis Mavrovouniotis},
  doi          = {10.1016/j.ins.2021.01.020},
  journal      = {Information Sciences},
  pages        = {105-127},
  shortjournal = {Inf. Sci.},
  title        = {TAGA: Tabu asexual genetic algorithm embedded in a filter/filter feature selection approach for high-dimensional data},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of petersen graph pattern technique for
automated detection of heart valve diseases with PCG signals.
<em>ISCI</em>, <em>565</em>, 91–104. (<a
href="https://doi.org/10.1016/j.ins.2021.01.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work aimed to use machine learning to diagnose four heart valve disease conditions and normal heart sounds. This paper proposed the automated classification of normal, aortic stenosis, mitral valve prolapse, mitral stenosis, and mitral regurgitation using phonocardiogram (PCG) signals. This work proposed a novel graph-based feature generator developed using a graph-based technique called Petersen graph pattern (PGP). In addition, a new decomposition model was proposed using variable-sized overlapping blocks, namely tent pooling (TEP) decomposition. By combining TEP and PGP, a novel multilevel feature generation network was developed. Iterative neighborhood component analysis (INCA) was used to select the features. The selected features were fed to decision tree (DT), linear discriminant (LD), bagged tree (BT), and support vector machine (SVM) classifiers for automated classification into five classes. The proposed method&#39;s results yielded 100.0\% classification accuracy using the k nearest neighbor (kNN) classifier with a ten-fold cross-validation strategy in classifying the five classes. DT, LD, BT, SVM classifiers yielded an accuracy of 95.10\%, 98.30\%, 98.60\%, and 99.90\%, respectively. Our attained high classification accuracy suggests that the proposed PGP and TEP based model can be used for heart sound classification using PCG signals.},
  archive      = {J_ISCI},
  author       = {Turker Tuncer and Sengul Dogan and Ru-San Tan and U. Rajendra Acharya},
  doi          = {10.1016/j.ins.2021.01.088},
  journal      = {Information Sciences},
  pages        = {91-104},
  shortjournal = {Inf. Sci.},
  title        = {Application of petersen graph pattern technique for automated detection of heart valve diseases with PCG signals},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Dimensional-varying integral sliding mode controller design
for uncertain takagi–sugeno fuzzy systems. <em>ISCI</em>, <em>565</em>,
77–90. (<a href="https://doi.org/10.1016/j.ins.2021.02.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An integral sliding mode control method for uncertain Takagi–Sugeno fuzzy systems is investigated in this paper. Considering the time-varying property of the fuzzy system control matrix , a dimensional-varying integral sliding mode controller is proposed. With a membership function piecewise linearization technique, the gain matrices of equivalent control law are derived. Then a dimension switching sliding model control scheme is designed to close the control loop. As a result, traditional restrictions on input matrix can be further relaxed. Finally, a numerical and a Diesel Engine Air-Path control examples are provided to certificate the merits and effectiveness of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Jian Zhang and Wen-Jie Wu and Wen-Bo Xie and Chen Peng},
  doi          = {10.1016/j.ins.2021.02.062},
  journal      = {Information Sciences},
  pages        = {77-90},
  shortjournal = {Inf. Sci.},
  title        = {Dimensional-varying integral sliding mode controller design for uncertain Takagi–Sugeno fuzzy systems},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning based moving object grasping.
<em>ISCI</em>, <em>565</em>, 62–76. (<a
href="https://doi.org/10.1016/j.ins.2021.01.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional grasping methods for locating unpredictable positions of moving objects under an unstructured environment cannot achieve good performance. This paper studies the utilization of deep reinforcement learning (DRL) with a Kinect depth sensor to resolve this challenging problem. The proposed grasping system integrates the DRL algorithm, Soft-Actor-Critic, and object detection techniques to implement an approaching-tracking-grasping scheme. Considering the state and action space for the high-degree-of-freedom manipulator, we employ an improved Soft-Actor-Critic algorithm to speed up the learning process. The proposed system can decouple object detection from the DRL control, which allows us to generalize the framework from a simulation environment to a real robot. Experimental results demonstrate that the developed system can autonomously grasp a moving object with different moving trajectories.},
  archive      = {J_ISCI},
  author       = {Pengzhan Chen and Weiqing Lu},
  doi          = {10.1016/j.ins.2021.01.077},
  journal      = {Information Sciences},
  pages        = {62-76},
  shortjournal = {Inf. Sci.},
  title        = {Deep reinforcement learning based moving object grasping},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Volatility GARCH models with the ordered weighted average
(OWA) operators. <em>ISCI</em>, <em>565</em>, 46–61. (<a
href="https://doi.org/10.1016/j.ins.2021.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Volatility is an important issue for companies, policy-makers, and researches. Autoregressive conditional heteroscedasticity (ARCH) and generalized ARCH (GARCH) models are frequently used to study volatility. However, forecasting efficiency tends to fail when complex data is used. This paper proposes the use of ordered weighted average (OWA) operators in combination with ordinary least squares (OLS) to create an estimator that can treat high degrees of uncertainty. In the application of the ARCH-GARCH models, we develop approaches with the OWA and the induced OWA operator. Some further generalizations are also developed by using generalized means. The main advantage of this new methodology is to add additional information to the process of estimating the models according to the attitudinal character of the decision-maker. Finally, the work presents an application in the volatility of the MX/US exchange rate, where the efficiency of the OWA operators in forecasting is proved.},
  archive      = {J_ISCI},
  author       = {Martha Flores-Sosa and Ezequiel Avilés-Ochoa and José M. Merigó and Ronald R. Yager},
  doi          = {10.1016/j.ins.2021.02.051},
  journal      = {Information Sciences},
  pages        = {46-61},
  shortjournal = {Inf. Sci.},
  title        = {Volatility GARCH models with the ordered weighted average (OWA) operators},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A turning point-based offline map matching algorithm for
urban road networks. <em>ISCI</em>, <em>565</em>, 32–45. (<a
href="https://doi.org/10.1016/j.ins.2021.02.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Offline map matching is a crucial step to facilitate many trajectory-based services in urban areas by finding vehicles’ travel paths from recorded and stored trajectory data . This paper proposes a novel turning point-based offline map matching algorithm , which introduces the concept of vehicle turning points to implement map matching piecewisely. The algorithm first separates the entire trajectory into multiple sub-trajectories using the identified turning points. It then selects the best-matched path for each sub-trajectory from the corresponding K -shortest paths. Extensive experiments are conducted to compare the performance of our algorithm with five state-of-the-art map matching algorithms in terms of four different criteria, including one correctly matched criterion, two incorrectly matched criteria, and one computation time-related criterion. Experimental results show that our algorithm has the best average matching accuracy and efficiency at different sampling intervals. Specifically, compared with the five benchmark algorithms, our algorithm can improve the correctly matched percentages by 1.43\% to 34.66\%, reduce the incorrectly matched percentages by 15.23\% to 56.79\%, and improve the matching speeds by 3.16–61.01 times.},
  archive      = {J_ISCI},
  author       = {Dongqing Zhang and Yucheng Dong and Zhaoxia Guo},
  doi          = {10.1016/j.ins.2021.02.052},
  journal      = {Information Sciences},
  pages        = {32-45},
  shortjournal = {Inf. Sci.},
  title        = {A turning point-based offline map matching algorithm for urban road networks},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Command-filter-based adaptive finite-time consensus control
for nonlinear strict-feedback multi-agent systems with dynamic leader.
<em>ISCI</em>, <em>565</em>, 17–31. (<a
href="https://doi.org/10.1016/j.ins.2021.02.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive finite-time consensus control method is investigated for nonlinear strict-feedback multi-agent systems that contain unknown parameters and a dynamic leader with both input and output. By using command filters, the “explosion of complexity” phenomenon in traditional backstepping technique can be avoided. The filter errors can be compensated by introducing compensating signals. Adaptive finite-time controllers are constructed by a backstepping technique, command filters, and compensating signals. In addition, the consensus performance and stability of closed-loop systems can be guaranteed in finite time basd on a practical finite-time stability criterion. Finally, a simulation example demonstrates the feasibility and effectiveness of the proposed adaptive finite-time consensus control method .},
  archive      = {J_ISCI},
  author       = {Yang Cui and Xiaoping Liu and Xin Deng and Guoxing Wen},
  doi          = {10.1016/j.ins.2021.02.078},
  journal      = {Information Sciences},
  pages        = {17-31},
  shortjournal = {Inf. Sci.},
  title        = {Command-filter-based adaptive finite-time consensus control for nonlinear strict-feedback multi-agent systems with dynamic leader},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constructing classifiers for imbalanced data using diversity
optimisation. <em>ISCI</em>, <em>565</em>, 1–16. (<a
href="https://doi.org/10.1016/j.ins.2021.02.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data is challenging in classification. This paper proposes a new approach to address imbalanced data by adopting diversity optimisation to generate synthetic instances for over-sampling the minority class. Diversity optimisation assures that the generated instances are close to the minority group but not identical. It also ensures the optimal spread of the generated instances in the space. We develop two formulations named as Diversity-based Average Distance Over-sampling (DADO) and Diversity-based Instance-Wise Over-sampling (DIWO). We evaluate the proposed formulations’ performance by designing experiments using both synthetic and real data with unbalanced classes. We examine the performance through area under curve (AUC), F1-score and g-mean measures in comparison with comparable synthetic over-sampling methods. We compare the methods using the obtained measures of the best performing classifier and statistical testing of all combinations over three imbalance levels using seven classifiers. The results show that both proposed formulations perform competitive to improve the performance of classifiers, and DIWO outperforms other comparable methods. Both perform robust by reducing the classifiers’ variance. We discuss the strengths and limitations of these formulations using the real data examples, runtime complexity and sensitivity analysis. We also demonstrate the possibility of utilising DADO and DIWO for multi-class imbalanced data.},
  archive      = {J_ISCI},
  author       = {Hadi A. Khorshidi and Uwe Aickelin},
  doi          = {10.1016/j.ins.2021.02.069},
  journal      = {Information Sciences},
  pages        = {1-16},
  shortjournal = {Inf. Sci.},
  title        = {Constructing classifiers for imbalanced data using diversity optimisation},
  volume       = {565},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A nondominated selection procedure with partially
consistent non-reciprocal probabilistic linguistic preference relations
and its application in social donation channel selection under the
COVID-19 outbreaks. <em>ISCI</em>, <em>564</em>, 416–429. (<a
href="https://doi.org/10.1016/j.ins.2021.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A non-reciprocal fuzzy preference relation (NrFPR) can express partial relations of alternatives, including indifference relations, preference relations and incomparability relations, but cannot depict linguistic preference intensities. A probabilistic linguistic preference relation (PLPR) can represent preference intensities in forms of probabilities and linguistic terms, but the incomparability relations of alternatives were not defined in a PLPR. Given that the NrFPR and PLPR can overcome each other’s drawbacks, this study proposes the non-reciprocal probabilistic linguistic preference relation (NrPLPR). Six conditions are given to express the partial relations of alternatives. Since the P P -cut of probabilistic linguistic term sets (PLTSs) is effective in the operations of PLTSs without information loss, we construct the P P -cut matrix of an NrPLPR by an adaptive P P -determination method. Afterwards, nine rules are provided to define the partially consistent NrPLPR. To repair the inconsistent NrPLPR, a two-stage consistency repairing process, containing the linguistic information and probability repairing stages, is introduced. In addition, a non-reciprocal probabilistic linguistic nondominated selection procedure is proposed to rank alternatives. A case study on selecting social donation channels under the COVID-19 outbreaks is given to demonstrate the applicability of the proposed method. A comparative analysis is done to show the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Lisheng Jiang and Huchang Liao},
  doi          = {10.1016/j.ins.2021.02.044},
  journal      = {Information Sciences},
  pages        = {416-429},
  shortjournal = {Inf. Sci.},
  title        = {A nondominated selection procedure with partially consistent non-reciprocal probabilistic linguistic preference relations and its application in social donation channel selection under the COVID-19 outbreaks},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outlier detection based on weighted neighbourhood
information network for mixed-valued datasets. <em>ISCI</em>,
<em>564</em>, 396–415. (<a
href="https://doi.org/10.1016/j.ins.2021.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is of great importance in industry as unexpected errors or faults, abnormal behaviours or phenomena, etc. can occur due to a variety of human, system, and environmental reasons. To identify and analyse these rare items, events or observations can find either anomalies or novelties and, as a result, can help avoid potential unexpected consequences or improve industrial system performance. The operating data collected from industrial systems in the Industry 4.0 era are characterized as multi-attribute (e.g., both numerical and categorical) compared to previous studies. Therefore, a new outlier detection method for mixed-valued datasets based on the weighted network model is proposed in this paper. Concretely, a weighted neighbourhood information network (WNIN) is constructed by considering the neighbourhood relations and similarities among objects to represent a dataset with mixed-valued attributes (DMA). A tailored Markov random walk method is employed to detect outlier on the predefined network model. After reaching the equilibrium, the inlier score is defined according to the out-degree of nodes in the WNIN to represent the inlier degree of objects. Experiments on two real datasets and a case study illustrate the effectiveness and adaptability of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yu Wang and Yupeng Li},
  doi          = {10.1016/j.ins.2021.02.045},
  journal      = {Information Sciences},
  pages        = {396-415},
  shortjournal = {Inf. Sci.},
  title        = {Outlier detection based on weighted neighbourhood information network for mixed-valued datasets},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Visual relationship detection with region topology
structure. <em>ISCI</em>, <em>564</em>, 384–395. (<a
href="https://doi.org/10.1016/j.ins.2021.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual relationship detection is crucial for scene understanding of images, which aims to detect objects in the image and classify the visual relation for each pair of objects. In addition, it builds a bridge between computer vision and natural language. Current studies transform the visual relationship detection task into a classification task between detected objects, and propose various models which integrate vision feature, position feature and semantic features of certain image regions. Following this manner, our proposed method also extracts features from these three cues. Furthermore, it is often neglected that the topology between regions plays an important role in capturing different visual relationships. In order to take advantage of topology, we treat the region visual features as vertexes and construct a visual region graph, and we model the dependency between ( subject , object ) (subject,object) pairs with the weighted edges. We further propose a visual relation detection framework based on the regional topology structure, which enables the model to incrementally aggregate topology structure information. We evaluate our method on VRD dataset and VG dataset, the results of the proposed method are close to even higher than that of the state-of-art methods on some evaluation metrics.},
  archive      = {J_ISCI},
  author       = {Le Zhang and Ying Wang and HaiShun Chen and Jie Li and ZhenXi Zhang},
  doi          = {10.1016/j.ins.2021.01.049},
  journal      = {Information Sciences},
  pages        = {384-395},
  shortjournal = {Inf. Sci.},
  title        = {Visual relationship detection with region topology structure},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed predictor-based stabilization of interconnected
systems with network induced delays. <em>ISCI</em>, <em>564</em>,
368–383. (<a href="https://doi.org/10.1016/j.ins.2021.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents sufficient stability conditions for distributed prediction-based control of interconnected systems subject to network-induced time-varying delay. Due to the flexibility of the proposed criteria, continuous-time, sampled-data control and output-feedback problems can be handled by the same framework. A detuning procedure is combined with a distributed LQR design in order to ensure the closed-loop stability for a given network-induced delay bound. If compared with related works, the proposed framework can be applied to obtain the time-varying delay bound derived from distinct combinations of distributed dead-time compensation strategies with stabilizing control laws. Two simulation case studies based on a benchmark problem and the level control of a irrigation canal are presented to illustrate the usefulness of the proposed framework.},
  archive      = {J_ISCI},
  author       = {Tito L.M. Santos and Taniel S. Franklin},
  doi          = {10.1016/j.ins.2021.02.041},
  journal      = {Information Sciences},
  pages        = {368-383},
  shortjournal = {Inf. Sci.},
  title        = {Distributed predictor-based stabilization of interconnected systems with network induced delays},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Negative influence blocking maximization with uncertain
sources under the independent cascade model. <em>ISCI</em>,
<em>564</em>, 343–367. (<a
href="https://doi.org/10.1016/j.ins.2021.02.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The propagation of negative influences, such as epidemic spreading, rumors, and false information in social networks and computer viruses, may lead to serious consequences. The issue of negative influence blocking maximization (IBM) has aroused intense interest from researchers. However, in real-world social network environments, the source of negative influence is typically unknown. In most cases, we only know the distribution of negative seeds and the probability for each node to be a negative seed. In this paper, this problem is defined as negative influence blocking maximization with an uncertain source (IBM-US), and a model is shown to approximately describe opposing effects that proliferate in the IBM-US problem. To calculate the blocking effect of the joint impact of positive and negative seed sets, a blocking function is defined, and an algorithm called IBM-Seed is used for the IBM problem in the independent cascade (IC) propagation model . A sampling-based algorithm IBM-US-SB-Seed is proposed to achieve an approximate solution for the IBM-US problem. The convergence of the IBM-US-SB-Seed algorithm is proven, and the convergence speed and the number of samples are analyzed. An extended sampling-based algorithm IBM-US-Seed for the IBM-US problem is shown to achieve a proper balance between result precision and computation time. The proposed algorithms are tested on real datasets, and the experimental results demonstrate that the proposed algorithms can yield higher quality results than other similar methods.},
  archive      = {J_ISCI},
  author       = {Ling Chen and Yuliang Zhang and Yixin Chen and Bin Li and Wei Liu},
  doi          = {10.1016/j.ins.2021.02.063},
  journal      = {Information Sciences},
  pages        = {343-367},
  shortjournal = {Inf. Sci.},
  title        = {Negative influence blocking maximization with uncertain sources under the independent cascade model},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active contour driven by adaptively weighted signed pressure
force combined with legendre polynomial for image segmentation.
<em>ISCI</em>, <em>564</em>, 327–342. (<a
href="https://doi.org/10.1016/j.ins.2021.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an active contour driven by adaptively weighted signed pressure force (SPF) combined with the Legendre polynomial method for image segmentation . First, an adaptively weighted global average intensity (GAI) term is defined wherein GAI differences are the weighted factors of the interior and exterior region-driving centers. Second, an adaptively weighted Legendre polynomial intensity (LPI) term is defined which adopts the Legendre polynomial intensity average differences as the weighted factors of the interior and exterior region-driving centers. Finally, the GAI and LPI terms are introduced into a novel SPF function and a coefficient is applied to weight their effect degrees; a new edge stopping function (ESF) is defined and combined with the region-based method to robustly converge the curve to the boundary of the object. Experiments demonstrate that this method is highly accurate and computationally efficient for images with inhomogeneous intensity, blurred edge, low contrast, and noise problems. Moreover, the segmentation results are independent of the initial contour .},
  archive      = {J_ISCI},
  author       = {Xingyu Fu and Bin Fang and Mingliang Zhou and Sam Kwong},
  doi          = {10.1016/j.ins.2021.02.019},
  journal      = {Information Sciences},
  pages        = {327-342},
  shortjournal = {Inf. Sci.},
  title        = {Active contour driven by adaptively weighted signed pressure force combined with legendre polynomial for image segmentation},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image robust adaptive steganography adapted to lossy
channels in open social networks. <em>ISCI</em>, <em>564</em>, 306–326.
(<a href="https://doi.org/10.1016/j.ins.2021.02.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, the demand for covert communication in open social networks brings new opportunities and challenges to existing image steganography technology in terms of robustness and security. To this end, an image robust adaptive steganography is proposed with robustness against multiple image processing attacks and detection resistance. First, a robust embedding domain with theoretical foundation and optimal invisibility is constructed based on the compression resistance principle. Then, utilizing the robust image abstraction and saliency measurement, the embedding channel is selected to avoid modifications in smooth regions and enhance visual quality. On this basis, the proposed method is given combining with error-correcting and STC codes to realize message embedding with minimum costs and improve extraction accuracy. Lastly, after parameters discussion and selection, the performance experiments are conducted compared with previous representative steganography algorithms, concerning robustness and detection resistance, and the fault tolerance is deduced, thereby providing the recommended coding parameters to improve message extraction integrity. The experimental results show that the proposed method can realize message extraction with high accuracy after JPEG compression, Gaussian noising, and scaling attacks, while holding comparable detection resistance to adaptive steganography against statistical features, which indicates its application prospect for covert communication in open lossy channels .},
  archive      = {J_ISCI},
  author       = {Yi Zhang and Xiangyang Luo and Jinwei Wang and Yanqing Guo and Fenlin Liu},
  doi          = {10.1016/j.ins.2021.02.058},
  journal      = {Information Sciences},
  pages        = {306-326},
  shortjournal = {Inf. Sci.},
  title        = {Image robust adaptive steganography adapted to lossy channels in open social networks},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust guaranteed cost control for uncertain discrete-time
systems with state and input quantizations. <em>ISCI</em>, <em>564</em>,
288–305. (<a href="https://doi.org/10.1016/j.ins.2021.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The robust guaranteed cost control problem for uncertain discrete-time systems with state and input quantizations has been studied in this paper. The polytope type uncertainties are considered in the plants. Different from previous related works, a novel guaranteed cost control strategy has been put forward in this paper. The novelty and challenge lie in that the quantized state and quantized input are included in the guaranteed cost function. Through introducing some auxiliary scalars and combining with the S -procedure, new criteria are developed for the robust stability and guaranteed cost performance for discrete-time systems with state and input quantizations. Based on a new two-step design strategy, the controller and dynamic quantizers can be easily obtained by means of linear matrix inequalities . In the end, two examples are given to demonstrate the effectiveness and applicability of the proposed method.},
  archive      = {J_ISCI},
  author       = {Qunxian Zheng and Haoling Chen and Shengyuan Xu},
  doi          = {10.1016/j.ins.2021.02.057},
  journal      = {Information Sciences},
  pages        = {288-305},
  shortjournal = {Inf. Sci.},
  title        = {Robust guaranteed cost control for uncertain discrete-time systems with state and input quantizations},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep multi-view document clustering with enhanced semantic
embedding. <em>ISCI</em>, <em>564</em>, 273–287. (<a
href="https://doi.org/10.1016/j.ins.2021.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering, which aims to group data with multiple views, has recently attracted intense research attention. Text documents bring additional difficulties to multi-view clustering due to the sparseness, high dimensionality , and inconsistency of document views. In this paper, we introduced a novel model on multi-view document clustering with enhanced semantic embedding , namely, MDCE, to address all of the above difficulties of clustering text documents with more than one representation view. Enhanced semantic embedders are designed to learn and improve the semantic mapping from higher-dimensional document space to lower-dimensional feature space with complementary semantic information. Specifically, three types of complementary semantic information are involved in an unsupervised manner : neighbour-wise, view-wise, and cluster-wise complementary information. A deep network is designed to optimize the enhanced semantic mapping , integrate lower-dimensional features from multiple views, and discover document clustering assignments simultaneously. We conducted extensive experiments on our proposed MDCE model by using realistic datasets compared with a number of state-of-the-art multi-view clustering approaches . Experimental results demonstrate that the MDCE-related models perform substantially better than all other models.},
  archive      = {J_ISCI},
  author       = {Ruina Bai and Ruizhang Huang and Yanping Chen and Yongbin Qin},
  doi          = {10.1016/j.ins.2021.02.027},
  journal      = {Information Sciences},
  pages        = {273-287},
  shortjournal = {Inf. Sci.},
  title        = {Deep multi-view document clustering with enhanced semantic embedding},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prescribed performance synchronization of complex dynamical
networks with event-based communication protocols. <em>ISCI</em>,
<em>564</em>, 254–272. (<a
href="https://doi.org/10.1016/j.ins.2021.02.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper addresses the prescribed performance synchronization (PPS) issue for complex dynamical networks (CDNs) using an event-triggered communication mechanism and PPS scheme with event-based protocols is designed for the CDNs. The designed synchronization control strategy can reduce the overshoot in transient processes, and stabilize synchronous errors at the origin. Furthermore, by introducing event-based protocols, continuous communication of the networks is avoided, so that the frequency of information communication is reduced and network resources are saved. Moreover, Zeno behavior in the networks can be excluded. Combining the Lyapunov stability method, a sufficient condition for asymptotic synchronization is proposed. Finally, the validity of the results is demonstrated by the CDNs with one link pendulum and Chua’s chaotic circuit (CCC) systems.},
  archive      = {J_ISCI},
  author       = {Aili Fan and Junmin Li},
  doi          = {10.1016/j.ins.2021.02.072},
  journal      = {Information Sciences},
  pages        = {254-272},
  shortjournal = {Inf. Sci.},
  title        = {Prescribed performance synchronization of complex dynamical networks with event-based communication protocols},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamical behaviors and control measures of rumor-spreading
model in consideration of the infected media and time delay.
<em>ISCI</em>, <em>564</em>, 237–253. (<a
href="https://doi.org/10.1016/j.ins.2021.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development and the progress of science and technology, the spread of rumors presents new characteristics. The spreaders publish false and malicious rumors on public social networks media, and individuals visit these networks and share them with their friends through the friendship network, which provides a convenient hotbed for the indiscriminate spread of rumors. In this paper, an improved rumor spreading model is established to explore the new characteristics of rumor spreading process on the basis of considering the delay of interactive system. By studying the dynamic behavior of the delay spreading model, we calculate the threshold of rumor spreading extinction, and prove the local and global asymptotic behavior of the boundary equilibrium point and endemic equilibrium point of the model. On this basis, we further consider the control strategies such as deleting rumor posts, popular science education, immunotherapy, etc., and propose an optimal control problem to minimize the spread scale and control cost of rumors. The optimal condition of the optimal control problem is calculated by mathematical analysis, and the correctness of the theoretical results is verified by numerical simulations. Finally, we compare the influence of time delays, optimal control and the media network on rumor spreading.},
  archive      = {J_ISCI},
  author       = {Yingying Cheng and Liang&#39;an Huo and Laijun Zhao},
  doi          = {10.1016/j.ins.2021.02.047},
  journal      = {Information Sciences},
  pages        = {237-253},
  shortjournal = {Inf. Sci.},
  title        = {Dynamical behaviors and control measures of rumor-spreading model in consideration of the infected media and time delay},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correlation-oriented complex system structural risk
assessment using copula and belief rule base. <em>ISCI</em>,
<em>564</em>, 220–236. (<a
href="https://doi.org/10.1016/j.ins.2021.02.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural risk assessment is very important for maintaining the safe operations of many complex systems. However, there are two major requirements that still need to be addressed, namely the correlation among multiple factors and high interpretability to produce a trustworthy result. For the first challenge on correlation, the Copula model is applied to quantitatively measure the correlation among the data gathered from multiple sources. For the second challenge on interpretability, the Belief Rule Base (BRB) model is applied since it is essentially a white-box approach that can provide good interpretability by its transparent inferencing and decision-making process. With this, a novel approach is proposed by combining the Copula model and BRB, namely Copula-BRB. Moreover, two frameworks are separately designed as well. The first is a knowledge-driven inferencing framework when experts’ knowledge is available but with limited data. The second is a data-driven optimization framework when there is a large quantity of data. Correspondingly, a numerical case with only limited data and another practical case with 1000 sets of data are studied to explain and validate the two frameworks of the Copula-BRB approach, respectively. The numerical case is mainly used to explain the knowledge-driven Copula-BRB inferencing framework, and the practical case is conducted in a comparative fashion where three Copula functions are used, namely Clayton, Frank, and Gumbel, and the results are compared with the Support Vector Machine (SVM) and conventional BRB (without consideration of the attribute correlation). The results of the two case studies show that, by using the Copula-BRB which incorporates the attribute correlation into the conventional BRB, superior performance has been achieved in comparison with SVM and BRB. A detailed exploration of how this superior performance concerning outputs in intervals has been conducted as well.},
  archive      = {J_ISCI},
  author       = {Leilei Chang and Limao Zhang and Xiaojian Xu},
  doi          = {10.1016/j.ins.2021.02.076},
  journal      = {Information Sciences},
  pages        = {220-236},
  shortjournal = {Inf. Sci.},
  title        = {Correlation-oriented complex system structural risk assessment using copula and belief rule base},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explainable classification by learning human-readable
sentences in feature subsets. <em>ISCI</em>, <em>564</em>, 202–219. (<a
href="https://doi.org/10.1016/j.ins.2021.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new methodology (Sentences in Feature Subsets, i.e., SiFS) to mine human-readable decision rules from empirical data sets. Unlike opaque classifiers obtained using deep learning , the proposed methodology derives decision rules that are compact and comprised of Boolean logic sentences involving subsets of features in the input data. For this purpose, we develop a new classifier model defined in terms of sets of inequalities among selected features in the input data. To empirically derive suitable inequalities from training data, our approach combines a differentiable representation of sets of Boolean logic sentences, gradient-based optimization of coefficients in the inequalities, a genetic-based algorithm for selection of the subsets of features, and a “goodness” model of sentences to prune and down-select sentences. We present results on synthetic and real-world benchmark datasets to demonstrate efficacy of SiFS in deriving human-readable decision rules. It is seen that SiFS achieves comparable accuracies to the best among various other classification algorithms (accuracies of 95\% to 100\% on several datasets, F 1 F1 scores between 0.95 and 1.0), reasonable computation times (training times of a few seconds for considered datasets), and compact human-readable decision rules (between 1 to 10 sentences of 3 words or less for considered datasets).},
  archive      = {J_ISCI},
  author       = {Prashanth Krishnamurthy and Alireza Sarmadi and Farshad Khorrami},
  doi          = {10.1016/j.ins.2021.02.031},
  journal      = {Information Sciences},
  pages        = {202-219},
  shortjournal = {Inf. Sci.},
  title        = {Explainable classification by learning human-readable sentences in feature subsets},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the minimality of some generating sets of the aggregation
clone on a finite chain. <em>ISCI</em>, <em>564</em>, 193–201. (<a
href="https://doi.org/10.1016/j.ins.2021.02.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clone theory plays an important role in studying aggregation functions on bounded posets or bounded lattices . Several important classes of aggregation functions on a bounded lattice L form a clone, particularly the set of all aggregation functions on L , the so-called full aggregation clone on L . For any finite lattice L , this clone is known to be finitely generated and various generating sets and their constructions have been presented in recent papers. The aim of this paper is to extend previous results concerning generating sets of aggregation clones on finite chains. Namely, the objective is to discuss the minimality of certain generating bases, the so-called ( χ , ⊕ ) (χ,⊕) -generating sets.},
  archive      = {J_ISCI},
  author       = {Radomír Halaš and Zbyněk Kurač and Jozef Pócs},
  doi          = {10.1016/j.ins.2021.02.070},
  journal      = {Information Sciences},
  pages        = {193-201},
  shortjournal = {Inf. Sci.},
  title        = {On the minimality of some generating sets of the aggregation clone on a finite chain},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ACT-detector: Adaptive channel transformation-based
light-weighted detector for adversarial attacks. <em>ISCI</em>,
<em>564</em>, 163–192. (<a
href="https://doi.org/10.1016/j.ins.2021.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the extensive application of deep neural networks (DNNs) in computer vision tasks, the vulnerability of such systems to carefully crafted adversarial examples has attracted increasing attention. Although various adversarial defense methods have been proposed to improve the robustness of DNNs, the detection of adversarial examples remains challenging. Previous studies have demonstrated that adversarial examples are sensitive to channel transformation operations, such as rotate and resize, whereas clean examples are immune to them. The detection efficiency heavily relies on the numbers and types of transformation operations. Thus, we propose an adaptive channel transformation-based light-weighted detector known as the ACT-Detector, which selects approximately optimal channel transformation types and the minimal channel transformation number through a cuckoo search. The ACT-Detector can not only detect adversarial and clean examples but can also identify the type of attack, such as white-box and black-box attacks. Comprehensive experiments were performed on the MNIST, CIFAR10, and ImageNet datasets to verify the detection efficiency of the ACT-Detector. The ACT-Detector outperformed a detector containing 45 channel transformations, using only five channel transformations to achieve 99.05\% and 98.8\% detection rates on the MNIST and CIFAR10 datasets, respectively. This is because the ACT-Detector could select channels with different features, whereas the features in the 45 channels were redundant. By reducing the channel number, the total time required for the ACT-Detector to detect one example was approximately one-quarter that required for the detector with 45 channels during testing. Thus, the proposed detector is proven to be effective and efficient, which is valuable for the detection of adversarial examples.},
  archive      = {J_ISCI},
  author       = {Jinyin Chen and Haibin Zheng and Wenchang Shangguan and Liangying Liu and Shouling Ji},
  doi          = {10.1016/j.ins.2021.01.035},
  journal      = {Information Sciences},
  pages        = {163-192},
  shortjournal = {Inf. Sci.},
  title        = {ACT-detector: Adaptive channel transformation-based light-weighted detector for adversarial attacks},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A highly effective hybrid evolutionary algorithm for the
covering salesman problem. <em>ISCI</em>, <em>564</em>, 144–162. (<a
href="https://doi.org/10.1016/j.ins.2021.02.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Covering salesman problem (CSP) is an extension of the popular traveling salesman problem (TSP) arising from a number of real-life applications. Given a set of vertices and a predetermined coverage radius associated with each vertex, the goal of CSP is to find a minimum cost Hamiltonian cycle across a subset of vertices, such that each unvisited vertex must be within the coverage radius of at least one vertex included in the tour. For this NP-hard problem, we present a highly effective hybrid evolutionary algorithm (HEA) that integrates a crossover operator based on solution reconstruction, a destroy-and-repair mutation operator to generate multiple distinct offspring solutions, and a two-phase tabu search procedure to seek for high-quality local optima. Another distinguishing feature of HEA is the use of the Lin–Kernighan TSP heuristic to find an improved node sequence of a CSP tour during multiple stages of HEA. Extensive experiments on a large set of benchmark instances show that the proposed approach is able to surpass the current best-performing CSP heuristics. In particular, it reports new upper bound (improved best-known solution) for 21 out of the 27 large instances, while matching the best-known result for the remaining small and medium instances. In addition to CSP, the proposed HEA is adapted to solve the generalized covering traveling salesman problem (GCTSP). Extensive experimental results on the GCTSP benchmark disclose that the proposed adaptation of HEA outperforms all the existing GCTSP heuristics from the literature.},
  archive      = {J_ISCI},
  author       = {Yongliang Lu and Una Benlic and Qinghua Wu},
  doi          = {10.1016/j.ins.2021.02.053},
  journal      = {Information Sciences},
  pages        = {144-162},
  shortjournal = {Inf. Sci.},
  title        = {A highly effective hybrid evolutionary algorithm for the covering salesman problem},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blessing of dimensionality at the edge and geometry of
few-shot learning. <em>ISCI</em>, <em>564</em>, 124–143. (<a
href="https://doi.org/10.1016/j.ins.2021.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present theory and algorithms enabling classes of Artificial Intelligence (AI) systems to continuously and incrementally improve with a priori quantifiable guarantees – or more specifically remove classification errors – over time. This is distinct from state-of-the-art machine learning, AI, and software approaches. The theory enables building few-shot AI correction algorithms and provides conditions justifying their successful application. Another feature of this approach is that, in the supervised setting, the computational complexity of training is linear in the number of training samples. At the time of classification, the computational complexity is bounded by few inner product calculations. Moreover, the implementation is shown to be very scalable. This makes it viable for deployment in applications where computational power and memory are limited, such as embedded environments. It enables the possibility for fast on-line optimisation using improved training samples. The approach is based on the concentration of measure effects and stochastic separation theorems and is illustrated with an example on the identification faulty processes in Computer Numerical Control (CNC) milling and with a case study on adaptive removal of false positives in an industrial video surveillance and analytics system.},
  archive      = {J_ISCI},
  author       = {Ivan Y. Tyukin and Alexander N. Gorban and Alistair A. McEwan and Sepehr Meshkinfamfard and Lixin Tang},
  doi          = {10.1016/j.ins.2021.01.022},
  journal      = {Information Sciences},
  pages        = {124-143},
  shortjournal = {Inf. Sci.},
  title        = {Blessing of dimensionality at the edge and geometry of few-shot learning},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimized and federated soft-impute for privacy-preserving
tensor completion in cyber-physical-social systems. <em>ISCI</em>,
<em>564</em>, 103–123. (<a
href="https://doi.org/10.1016/j.ins.2021.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-physical-social systems (CPSSs) handle large-scale multi-source data in different application areas, and the collected data usually contain personal private information and uncompleted information, which are typically distributed in different locations. Tensor completion has been widely used for recovering the missing entries in scale multidimensional data, and has proven to be an effective method. Privacy-preserving tensor completion in CPSSs, however, faces challenging issues, such as scalability, scatter, and security. In this paper, we propose a privacy-preserving tensor completion method that uses the optimized federated soft-impute algorithm with a differentially private guarantee. Moreover, we theoretically analyzed the privacy guarantee and utility guarantee. We evaluated the proposed algorithms on both synthetic data and real-world data. The results show that our algorithm performed better and provided strong privacy protection under a federated learning framework. Our method significantly saved space and time for privacy-preserving tensor completion in a CPSS.},
  archive      = {J_ISCI},
  author       = {Jia Yang and Cai Fu and Hongwei Lu},
  doi          = {10.1016/j.ins.2021.02.028},
  journal      = {Information Sciences},
  pages        = {103-123},
  shortjournal = {Inf. Sci.},
  title        = {Optimized and federated soft-impute for privacy-preserving tensor completion in cyber-physical-social systems},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ontology-based deep learning approach for triple
classification with out-of-knowledge-base entities. <em>ISCI</em>,
<em>564</em>, 85–102. (<a
href="https://doi.org/10.1016/j.ins.2021.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs (KGs) are one of the most common frameworks for knowledge representation. However, they suffer from a severe scalability problem that hinders their usage. KG embedding aims to provide a solution to this issue. Nonetheless, general approaches are incapable of representing and reasoning about information not previously contained in the graph. This paper proposes to leverage semantic and ontological information for a significant benefit of knowledge graph completion, focusing on triple classification. The goal of this task is to determine whether a given fact holds. Furthermore, this paper also considers the classification of facts that include entities that have not been seen during training, denoted out-of-knowledge-base or OOKB entities. An incremental method is presented, composed of six stages. Although the proposal can be applied to any KG embedding model, this work focuses on its application for semantic matching models, such as ComplEx and DistMult. Compared to other approaches, our proposal is model-agnostic, computationally inexpensive, and does not require retraining. The results show that triple classification accuracy scales up to 15\% with the proposed approach, as well as accelerating the convergence of the model to its optimal solution. Furthermore, facts containing OOKB entities can be classified with a reasonable accuracy.},
  archive      = {J_ISCI},
  author       = {Elvira Amador-Domínguez and Emilio Serrano and Daniel Manrique and Patrick Hohenecker and Thomas Lukasiewicz},
  doi          = {10.1016/j.ins.2021.02.018},
  journal      = {Information Sciences},
  pages        = {85-102},
  shortjournal = {Inf. Sci.},
  title        = {An ontology-based deep learning approach for triple classification with out-of-knowledge-base entities},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Viewpoint adaptation learning with cross-view distance
metric for robust vehicle re-identification. <em>ISCI</em>,
<em>564</em>, 71–84. (<a
href="https://doi.org/10.1016/j.ins.2021.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many vehicle re-identification (Re-ID) problems require the robust recognition of vehicle instances across multiple viewpoints. Existing approaches for dealing with the vehicle re-ID problem are insufficiently robust because they cannot distinguish among vehicles of the same type nor recognize high-level representations in deep networks for identical vehicles with various views. To address these issues, this paper proposes a viewpoint adaptation network (VANet) with a cross-view distance metric for robust vehicle Re-ID. This method consists of two modules. The first module is the VANet with cross-view label smoothing regularization (CVLSR), which abstracts different levels of a vehicle’s visual patterns and subsequently integrates multi-level features. In particular, CVLSR based on color domains assigns a virtual label to the generated data to smooth image-image translation noise. Accordingly, this module supplies the viewing angle information of the training data and provides strong robust capability for vehicles across different viewpoints. The second module is the cross-view distance metric, which designs a cascaded cross-view matching approach to combine the original features with the generated ones, and thus, obtain additional supplementary viewpoint information for the multi-view matching of vehicles. Results of extensive experiments on two large scale vehicle Re-ID datasets, namely, VeRi-776 and VehiclelD demonstrate that the performance of the proposed method is robust and superior to other state-of-the-art Re-ID methods across multiple viewpoints.},
  archive      = {J_ISCI},
  author       = {Qi Wang and Weidong Min and Qing Han and Ziyuan Yang and Xin Xiong and Meng Zhu and Haoyu Zhao},
  doi          = {10.1016/j.ins.2021.02.013},
  journal      = {Information Sciences},
  pages        = {71-84},
  shortjournal = {Inf. Sci.},
  title        = {Viewpoint adaptation learning with cross-view distance metric for robust vehicle re-identification},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-time time-varying formation tracking for nonlinear
multi-agent systems under event-triggered mechanism. <em>ISCI</em>,
<em>564</em>, 45–70. (<a
href="https://doi.org/10.1016/j.ins.2021.02.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the fixed-time event-triggered time-varying formation tracking issue for a class of nonlinear multi-agent systems with multi-dimensional dynamics, uncertain disturbances and non-zero control input of leader. Firstly, a distributed fixed-time event-triggered control scheme is proposed such that the time-varying formation tracking can be achieved with intermittent controller updates and intermittent communication. To reduce the chattering phenomenon, a novel control protocol with saturation function is designed. It should be noted that continuous triggering condition monitoring is needed in the triggering mechanism. To address above issue, a novel triggering mechanism is further proposed. Moreover, the fixed-time event-triggered time-varying formation containment with multiple leaders is considered. It is verified that the Zeno behavior can be excluded. Finally, two examples are presented to demonstrate the feasibility of the main theoretical findings.},
  archive      = {J_ISCI},
  author       = {Yuliang Cai and Huaguang Zhang and Yingchun Wang and Juan Zhang and Qiang He},
  doi          = {10.1016/j.ins.2021.02.071},
  journal      = {Information Sciences},
  pages        = {45-70},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time time-varying formation tracking for nonlinear multi-agent systems under event-triggered mechanism},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Distributed adaptive fixed-time formation control for
second-order multi-agent systems with collision avoidance.
<em>ISCI</em>, <em>564</em>, 27–44. (<a
href="https://doi.org/10.1016/j.ins.2021.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the distributed fixed-time formation control problem for a group of second-order multi-agent systems is investigated with consideration of collision avoidance , external disturbances, and connected undirected topology. As a stepping stone, a novel distributed fixed-time sliding manifold is proposed to achieve the predefined convergence performance. Furthermore, by combining repulsive potential function with the presented sliding manifold, an adaptive fixed-time formation protocol is developed to guarantee the tracking errors converge to small regions of zero, whilst providing collision-avoidance ability for multiple agents. Finally, numerical simulations are conducted to demonstrate the effectiveness of the proposed protocol.},
  archive      = {J_ISCI},
  author       = {Qi Li and Jinyuan Wei and Qiuxiong Gou and Zhiqi Niu},
  doi          = {10.1016/j.ins.2021.02.029},
  journal      = {Information Sciences},
  pages        = {27-44},
  shortjournal = {Inf. Sci.},
  title        = {Distributed adaptive fixed-time formation control for second-order multi-agent systems with collision avoidance},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ILUNA: Single-pass incremental method for uncertain frequent
pattern mining without false positives. <em>ISCI</em>, <em>564</em>,
1–26. (<a href="https://doi.org/10.1016/j.ins.2021.02.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, due to the mass production of uncertain data, numerous methods have been proposed for mining frequent patterns from uncertain data; however, none of them are proper for dynamic data environments. In many real-world applications, transactions are constantly being updated. After incremental updates, the validity of the uncertain patterns changes. The existing static algorithms to handle this state have to rerun the whole mining process from scratch, which is very costly. Incremental-CUF-growth is a method dealing with dynamic data but it generates many false positives and requires an additional time-consuming database scan to filter them. To handle these drawbacks, in this paper, an efficient single-pass method called ILUNA is proposed for incremental mining of uncertain frequent patterns without false positives. It introduces two new data structures namely IUP-List and ICUP-List to efficiently store data which can be increased. Upon receiving each new database, it only updates the lists without having to rebuild them from scratch. This is the first study in which single-pass incremental mining of uncertain frequent patterns is performed. Comprehensive experimental results show that the proposed method dramatically reduces the runtime and enhances the scalability compared to the state-of-the-art methods for dense and sparse incremental datasets.},
  archive      = {J_ISCI},
  author       = {Razieh Davashi},
  doi          = {10.1016/j.ins.2021.02.067},
  journal      = {Information Sciences},
  pages        = {1-26},
  shortjournal = {Inf. Sci.},
  title        = {ILUNA: Single-pass incremental method for uncertain frequent pattern mining without false positives},
  volume       = {564},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aggregation of triangle of distortion functions.
<em>ISCI</em>, <em>563</em>, 401–417. (<a
href="https://doi.org/10.1016/j.ins.2021.02.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we introduce notions of distortion function and aggregated distortion function. Applying some extended aggregation function on the triangle of distortion functions, a new extended aggregation function is obtained. Properties of the aggregation function constructed in this way depend on the properties of applied aggregation function and the distortion functions used. Its properties as continuity, convexity, concavity , subadditivity and superadditivity are investigated.},
  archive      = {J_ISCI},
  author       = {Ljubo Nedović and Endre Pap and Đorđe Dragić},
  doi          = {10.1016/j.ins.2021.02.065},
  journal      = {Information Sciences},
  pages        = {401-417},
  shortjournal = {Inf. Sci.},
  title        = {Aggregation of triangle of distortion functions},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the estimation of pareto front and dimensional similarity
in many-objective evolutionary algorithm. <em>ISCI</em>, <em>563</em>,
375–400. (<a href="https://doi.org/10.1016/j.ins.2021.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithms have been proven to be effective in solving multi-objective optimization problems. However, their performance deteriorates progressively in handling many-objective optimization problems due to the sensitivity upon the curvature of Pareto front, as well as the implicit evaluation on similarity in high dimensionality. This paper proposes an on-line Pareto front curvature estimator for an adaptive selection, in which the achievement scalarizing function is used to identify the pivotal solution to extrapolate the geometric information. Then an adaptive scalarizing function based fitness assessment, which guarantees the Pareto optimality , is presented. The diversity of the Pareto optimal solutions is also ensured by introducing a novel similarity metric. Finally, an extensive experimental analysis is presented to corroborate the analytical result by evaluating problems with various types of Pareto fronts. The experimental results substantiate the efficacy of the results with competitive performance.},
  archive      = {J_ISCI},
  author       = {Li Li and Gary G. Yen and Avimanyu Sahoo and Liang Chang and Tianlong Gu},
  doi          = {10.1016/j.ins.2021.03.008},
  journal      = {Information Sciences},
  pages        = {375-400},
  shortjournal = {Inf. Sci.},
  title        = {On the estimation of pareto front and dimensional similarity in many-objective evolutionary algorithm},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The improved AdaBoost algorithms for imbalanced data
classification. <em>ISCI</em>, <em>563</em>, 358–374. (<a
href="https://doi.org/10.1016/j.ins.2021.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance is one of the most popular and important issues in the domain of classification. The AdaBoost algorithm is an effective solution for classification, but it still needs improvement in the imbalanced data problem. This paper proposes a method to improve the AdaBoost algorithm using the new weighted vote parameters for the weak classifiers . Our proposed weighted vote parameters are determined not only by the global error rate but also by the classification accuracy rate of the positive class, which is our primary interest. The imbalanced index of the data is also a factor in constructing our algorithms. Our proposed algorithms outperform the traditional ones, especially regarding the evaluation criterion of F - 1 Measure F-1Measure . Theoretic proofs of the advantages of our proposed algorithms are presented. Two kinds of simulated datasets and four real datasets are applied in the experiment as the specific support to our proposed algorithms.},
  archive      = {J_ISCI},
  author       = {Wenyang Wang and Dongchu Sun},
  doi          = {10.1016/j.ins.2021.03.042},
  journal      = {Information Sciences},
  pages        = {358-374},
  shortjournal = {Inf. Sci.},
  title        = {The improved AdaBoost algorithms for imbalanced data classification},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature construction and smote-based imbalance handling for
multi-label learning. <em>ISCI</em>, <em>563</em>, 342–357. (<a
href="https://doi.org/10.1016/j.ins.2021.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The class-imbalance is intrinsic in Multi-label datasets due to the higher number of labels, few relevant labels in many instances, and a varied number of relevant instances for different labels. It causes multi-label learning biased toward majority instances for many labels. Therefore, it is essential to handle the multi-label datasets’ imbalances before using any multi-label learning algorithm. There are a handful of proposals in recent times to extricate this problem. However, it is still a significant challenge to date. This paper proposes a method termed F eature C onstruction and Sm ote-based I mbalance handling ( FCSMI ) for multi-label datasets. The FCSMI works in a label-wise manner as follows. First, it determines whether the label is a minority based on the mean imbalance ratio . Further, for minority labels, it calculates the distances of each instance from all the minority-instances. These distances are used as features. Then, it uses Smote to balance the ratio between minority and majority instances. Finally, the dataset, which has a lower imbalance ratio than its initial counterpart, is used to train the classifier. The experimental results demonstrate the effectiveness of our proposed FCSMI method compared to the prevailing state-of-the-art multi-label sampling methods.},
  archive      = {J_ISCI},
  author       = {Nitin Kumar Mishra and Pramod Kumar Singh},
  doi          = {10.1016/j.ins.2021.03.001},
  journal      = {Information Sciences},
  pages        = {342-357},
  shortjournal = {Inf. Sci.},
  title        = {Feature construction and smote-based imbalance handling for multi-label learning},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IR-rec: An interpretive rules-guided recommendation over
knowledge graph. <em>ISCI</em>, <em>563</em>, 326–341. (<a
href="https://doi.org/10.1016/j.ins.2021.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing recommendation methods focus on the improvement of recommender accuracy while ignoring the influence of recommended explanation. Recommender explainability is an efficient way to help consumers make much more suitable decisions and enhance their acceptance and trustfulness in recommender systems (RSs). Incorporating a knowledge graph (KG) into RS is a promising way to improve recommender results while enhancing the strength of explanation. In this paper, an interactive rules-guided recommender (IR-Rec) framework based on KG is proposed. First, an existing KG is enriched by introducing it to facts about e-commerce. Then, a number of paths are extracted from the enhanced KG for user-item interactions that are able to ascertain the underlying reason for recommendations according to the semantic strength of the KG. These paths are summarized into some common behavior rules that have the ability to explain the underlying motivations of users. According to the characteristics of users, items, and rules, different neural networks are designed, such as a graph convolutional network , to learn more accurate embeddings. Furthermore, recommendations that meet users’ personalized interests are made by combining the public behavior rules and their individual features. Extensive experiments are carried out on four Amazon datasets for top- K recommendation. All the results show that the proposed method performs better than other respective baselines and demonstrate the effectiveness of rule extraction for making recommendations.},
  archive      = {J_ISCI},
  author       = {Jiaying Chen and Jiong Yu and Wenjie Lu and Yurong Qian and Ping Li},
  doi          = {10.1016/j.ins.2021.03.004},
  journal      = {Information Sciences},
  pages        = {326-341},
  shortjournal = {Inf. Sci.},
  title        = {IR-rec: An interpretive rules-guided recommendation over knowledge graph},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speech emotion recognition based on formant characteristics
feature extraction and phoneme type convergence. <em>ISCI</em>,
<em>563</em>, 309–325. (<a
href="https://doi.org/10.1016/j.ins.2021.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) has numerous applications including human-robot interaction, online gaming, and health care assistance. While deep learning-based approaches achieve considerable precision, they often come with high computational and time costs. Indeed, feature learning strategies must search for important features in a large amount of speech data. In order to reduce these time and computational costs, we propose pre-processing step in which speech segments with similar formant characteristics are clustered together and labeled as the same phoneme. The phoneme occurrence rates in emotional utterances are then used as the input features for classifiers. Using six databases (EmoDB, RAVDESS, IEMOCAP, ShEMO, DEMoS and MSP-Improv) for evaluation, the level of accuracy is comparable to that of current state-of-the-art methods and the required training time was significantly reduced from hours to minutes.},
  archive      = {J_ISCI},
  author       = {Zhen-Tao Liu and Abdul Rehman and Min Wu and Wei-Hua Cao and Man Hao},
  doi          = {10.1016/j.ins.2021.02.016},
  journal      = {Information Sciences},
  pages        = {309-325},
  shortjournal = {Inf. Sci.},
  title        = {Speech emotion recognition based on formant characteristics feature extraction and phoneme type convergence},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning task-driving affinity matrix for accurate
multi-view clustering through tensor subspace learning. <em>ISCI</em>,
<em>563</em>, 290–308. (<a
href="https://doi.org/10.1016/j.ins.2021.02.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering seeks an underlying partition of the data from multiple views. Organizing the data into a tensor and then learning a self-expressive latent one to exploit cross-view information has attracted much attention. Most of the recent works mainly focus on the tensor representation, but they fail to directly extract the task-driving affinity matrix for clustering. Such method is typically modeled by a separated two-stage optimization, making the decoupled representation perform unsatisfactorily. One of the core issues is how to explore the common subspace across all views while learning self-representation tensor. To tackle the problem, we propose to jointly learn the two parts within a united optimization framework for consistent clustering performance, thus obtaining T ask-driving A ffinity M atrix for accurate M ulti-view C lustering (TAMMC). First, the proposed method preserves the local affinities of all views via a graph regularization on self-expressive tensor. Second, by penalizing a Laplacian rank on a learned common subspace, our algorithm can guarantee superior clustering. An effective optimization procedure is proposed for the proposed model. Extensive experiments on eight benchmark datasets well demonstrate that our approach, named by TAMMC, achieves superior performances over other popular methods.},
  archive      = {J_ISCI},
  author       = {Haiyan Wang and Guoqiang Han and Junyu Li and Bin Zhang and Jiazhou Chen and Yu Hu and Chu Han and Hongmin Cai},
  doi          = {10.1016/j.ins.2021.02.054},
  journal      = {Information Sciences},
  pages        = {290-308},
  shortjournal = {Inf. Sci.},
  title        = {Learning task-driving affinity matrix for accurate multi-view clustering through tensor subspace learning},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive denoising algorithm using peak statistics-based
thresholding and novel adaptive complementary ensemble empirical mode
decomposition. <em>ISCI</em>, <em>563</em>, 269–289. (<a
href="https://doi.org/10.1016/j.ins.2021.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an adaptive denoising methodology for noisy signals that employs a novel adaptive complementary ensemble empirical mode decomposition (NACEEMD) and a peak statistics (PS)-based thresholding technique. The key idea in this paper is the peak statistics (PS)-based thresholding technique,which breaks the traditional strategy with respect to selecting more accurate and more adaptive thresholds. The NACEEMD algorithm is proposed to decompose the noisy signal into a series of intrinsic mode functions (IMFs). At the same time, NACEEMD is also used to verify the applicability of the PS-based thresholding technique in different decomposition algorithms. The PS-based threshold is used to remove the noise inherent in noise-dominant IMFs , and the denoised signal is reconstructed by combining the denoised noise-dominant IMFs and the signal-dominant IMFs. This paper uses a various of simulated signals in various noisy environments for experiments, the experimental results indicate that the proposed algorithm outperforms traditional threshold denoising methodologies in terms of signal-to-noise ratio, root mean square error, and percent root distortion. Moreover, through real ECG signal and multi-sensor data fusion experiments, the application of the proposed algorithm in the field of engineering is explored and expanded.},
  archive      = {J_ISCI},
  author       = {Mengfei Hu and Shuqing Zhang and Wei Dong and Fengjiao Xu and Haitao Liu},
  doi          = {10.1016/j.ins.2021.02.040},
  journal      = {Information Sciences},
  pages        = {269-289},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive denoising algorithm using peak statistics-based thresholding and novel adaptive complementary ensemble empirical mode decomposition},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Distributed h∞ state estimation for switched sensor
networks with packet dropouts via persistent dwell-time switching
mechanism. <em>ISCI</em>, <em>563</em>, 256–268. (<a
href="https://doi.org/10.1016/j.ins.2021.01.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed H ∞ H∞ state estimation problem for a class of sensor networks with switching characteristics, where the switchings of parameters are presumed to obey persistent dwell-time switching mechanism rather than dwell time or average dwell-time ones in the discrete-time context. For the purpose of tracking the unavailable state of the target plant, a sensor network is formed by employing multiple sensor nodes distributed in space and worked cooperatively under a specific connection topology . The intention of the paper mainly centers on deriving some sufficient criteria for the addressed model to achieve the exponential mean-square stability with a prescribed H ∞ H∞ performance, and the estimator gains corresponding to differently constructed estimators are further solved by means of the convex optimization method. Finally, the validity of the proposed approach is illustrated by a numerical example.},
  archive      = {J_ISCI},
  author       = {Jing Wang and Xiaohui Hu and Jianwei Xia and Ju H. Park and Hao Shen},
  doi          = {10.1016/j.ins.2021.01.057},
  journal      = {Information Sciences},
  pages        = {256-268},
  shortjournal = {Inf. Sci.},
  title        = {Distributed h∞ state estimation for switched sensor networks with packet dropouts via persistent dwell-time switching mechanism},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Static output-feedback control for cyber-physical LPV
systems under DoS attacks. <em>ISCI</em>, <em>563</em>, 241–255. (<a
href="https://doi.org/10.1016/j.ins.2021.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the static output-feedback secure control problem for Cyber-physical linear parameter varying systems under Denial of Service (DoS) attacks. A scenario where the number of consecutive DoS attacks is bounded is considered. A packet-based output control method for the design of gain-scheduling output-feedback controllers that diminish the influence of malicious attack on the system behavior is presented. Moreover, the technique may also be adapted to design a fixed robust or gain-scheduled controller. The system dynamic during the attack is modeled as a switching linear parameter varying system. The proposed conditions are written in the form of parameter-dependent Linear Matrix Inequalities and no structural constraints on the systems matrices are imposed. Differently from existing approaches, a lifted condition that considers the free of attack dynamics in the construction of the Lyapunov function is introduced. Numerical experiments illustrate the potential of the proposed approach and its ability to guarantee the stability of the closed-loop system under DoS attacks.},
  archive      = {J_ISCI},
  author       = {Paulo S.P. Pessim and Márcia L.C. Peixoto and Reinaldo M. Palhares and Márcio J. Lacerda},
  doi          = {10.1016/j.ins.2021.02.023},
  journal      = {Information Sciences},
  pages        = {241-255},
  shortjournal = {Inf. Sci.},
  title        = {Static output-feedback control for cyber-physical LPV systems under DoS attacks},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jointly modeling and simultaneously discovering topics and
clusters in text corpora using word vectors. <em>ISCI</em>,
<em>563</em>, 226–240. (<a
href="https://doi.org/10.1016/j.ins.2021.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An innovative model-based approach to coupling text clustering and topic modeling is introduced, in which the two tasks take advantage of each other. Specifically, the integration is enabled by a new generative model of text corpora. This explains topics, clusters and document content via a Bayesian generative process . In this process, documents include word vectors, to capture the (syntactic and semantic) regularities among words. Topics are multivariate Gaussian distributions on word vectors. Clusters are assigned corresponding topic distributions as their semantics. Content generation is ruled by text clusters and topics, which act as interacting latent factors . Documents are at first placed into respective clusters, then the semantics of these clusters is then repeatedly sampled to draw document topics, which are in turn sampled for word-vector generation. Under the proposed model, collapsed Gibbs sampling is derived mathematically and implemented algorithmically with parameter estimation for the simultaneous inference of text clusters and topics. A comparative assessment on real-world benchmark corpora demonstrates the effectiveness of this approach in clustering texts and uncovering their semantics. Intrinsic and extrinsic criteria are adopted to investigate its topic modeling performance, whose results are shown through a case study. Time efficiency and scalability are also studied.},
  archive      = {J_ISCI},
  author       = {Gianni Costa and Riccardo Ortale},
  doi          = {10.1016/j.ins.2021.01.019},
  journal      = {Information Sciences},
  pages        = {226-240},
  shortjournal = {Inf. Sci.},
  title        = {Jointly modeling and simultaneously discovering topics and clusters in text corpora using word vectors},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Class-specific information measures and attribute reducts
for hierarchy and systematicness. <em>ISCI</em>, <em>563</em>, 196–225.
(<a href="https://doi.org/10.1016/j.ins.2021.01.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction of rough set theory underlies knowledge acquisition and has two hierarchical types (classification-based and class-specific attribute reducts) and two perspectives from algebra and information theory; thus, there are four combined modes in total. Informational class-specific reducts are fundamental but lacking and are thus investigated by correspondingly constructing class-specific information measures. First, three types of information measures (i.e., information entropy, conditional entropy, and mutual information) are novelly established at the class level by hierarchical decomposition to acquire their hierarchical connection, systematical relationship, uncertainty semantics, and granulation monotonicity. Second, three types of informational class-specific reducts are correspondingly proposed to acquire their internal relationship, basic properties, and heuristic algorithm. Third, the informational class-specific reducts achieve their transverse connections, including the strength feature and consistency degeneration, with the algebraic class-specific reducts and their hierarchical connections, including the hierarchical strength and balance, with the informational classification-based reducts. Finally, relevant information measures and attribute reducts are effectively verified by decision tables and data experiments. Class-specific information measures deepen existing classification-based information measures by a hierarchical isomorphism, while the informational class-specific reducts systematically perfect attribute reduction by level and viewpoint isomorphisms; these results facilitate uncertainty measurement and information processing, especially at the class level.},
  archive      = {J_ISCI},
  author       = {Xianyong Zhang and Hong Yao and Zhiying Lv and Duoqian Miao},
  doi          = {10.1016/j.ins.2021.01.080},
  journal      = {Information Sciences},
  pages        = {196-225},
  shortjournal = {Inf. Sci.},
  title        = {Class-specific information measures and attribute reducts for hierarchy and systematicness},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decidable characterizations of dynamical properties for
additive cellular automata over a finite abelian group with applications
to data encryption. <em>ISCI</em>, <em>563</em>, 183–195. (<a
href="https://doi.org/10.1016/j.ins.2021.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Additive cellular automata over a finite abelian group are a wide class of cellular automata (CA) that are able to exhibit the complex behaviors of general CA and are often exploited for designing applications in different practical contexts. We provide decidable characterizations for Additive CA of the following important properties defining complex behaviors of complex systems: injectivity , surjectivity, equicontinuity, sensitivity to the initial conditions, topological transitivity , and ergodicity . Since such properties describe the main features required by real systems, the decision algorithms from our decidability results are then important tools for designing proper applications based on Additive CA. Indeed, we describe how our results can be exploited in some emblematic applications of cryptosystems , a paradigmatic and nowadays crucial applicative domain in which Additive CA are extensively used. We deal with methods for data encryption and, namely, we propose some strong modifications to the existing schemes in order to increase their security level and make attacks much harder.},
  archive      = {J_ISCI},
  author       = {Alberto Dennunzio and Enrico Formenti and Darij Grinberg and Luciano Margara},
  doi          = {10.1016/j.ins.2021.02.012},
  journal      = {Information Sciences},
  pages        = {183-195},
  shortjournal = {Inf. Sci.},
  title        = {Decidable characterizations of dynamical properties for additive cellular automata over a finite abelian group with applications to data encryption},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamics and convergence of hyper-networked evolutionary
games with time delay in strategies☆. <em>ISCI</em>, <em>563</em>,
166–182. (<a href="https://doi.org/10.1016/j.ins.2021.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networked evolutionary game theory is an important tool to study the emergence and maintenance of cooperation in natural, social, and economical systems. In this paper, we investigate the dynamics and convergence of a generalized networked evolutionary game, i.e., delayed hyper-networked evolutionary game (HNEG), which considers the multi-players in fundamental network game and time delay in strategies simultaneously. Based on the tool of semi-tensor product (STP) of matrices, the definition of delayed potential HNEG and representation of potential function are given. Moreover, we conclude the steps to analyze the dynamics and convergence of delayed potential HNEGs. Considering the efficiency in updating process, we define a new strategy updating rule based on the myopic best response adjustment rule (MBRAR), which is called delayed group-based sequential MBRAR. Furthermore, we prove that delayed potential HNEG converges to one of the pure Nash equilibrium trajectories under this rule. Finally, public good game is provided to illustrate the realistic application of our results.},
  archive      = {J_ISCI},
  author       = {Jing Zhang and Jungang Lou and Jianlong Qiu and Jianquan Lu},
  doi          = {10.1016/j.ins.2021.02.033},
  journal      = {Information Sciences},
  pages        = {166-182},
  shortjournal = {Inf. Sci.},
  title        = {Dynamics and convergence of hyper-networked evolutionary games with time delay in strategies☆},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new non-kernel quadratic surface approach for imbalanced
data classification in online credit scoring. <em>ISCI</em>,
<em>563</em>, 150–165. (<a
href="https://doi.org/10.1016/j.ins.2021.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data sets are very common in online credit scoring. Their imbalanced structures may cause statistical bias and poor performance of those traditional models. Hence, how to properly deal with them and dig useful information from them are very crucial for the risk management . This paper proposes a new approach to address the imbalanced data classification in this area by directly generating two quadratic surfaces in the original space. In this way, it avoids the time-consuming task for searching a proper kernel function and its corresponding parameters in the traditional support vector machine (SVM) models, hence significantly improve the total efficiency of the approach. Moreover, the homocentric structure and maximization margin principle are applied to obtain a good performance of our model on the issue. Besides, fuzzy weight is also incorporated to further increase the classification accuracy and robustness. It is worth noting that the linear programming structure of our model not only guarantees the global optimality of its solution, but also leads to a much higher efficiency than those benchmark models . In addition, the fewer parameters in our model further saves more time in the tuning process. Hence it is quite suitable for handling those huge-sized problems in this big data era. Finally, we conduct a comprehensive experiment to compare the performances and efficiencies of different methods. The numerical results on various data sets strongly verify the superiority of our method to some benchmark methods in handling the imbalanced data classification in online credit scoring.},
  archive      = {J_ISCI},
  author       = {Ye Tian and Bo Bian and Xiaofei Tang and Jing Zhou},
  doi          = {10.1016/j.ins.2021.02.026},
  journal      = {Information Sciences},
  pages        = {150-165},
  shortjournal = {Inf. Sci.},
  title        = {A new non-kernel quadratic surface approach for imbalanced data classification in online credit scoring},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-JPEG-image reversible data hiding. <em>ISCI</em>,
<em>563</em>, 130–149. (<a
href="https://doi.org/10.1016/j.ins.2021.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the widespread popularity of JPEG image compression format, reversible data hiding (RDH) for JPEG images has practical application value with increasing research attention. This paper proposes a dual-image RDH method based on a modification of the discrete cosine transform (DCT) coefficients. Because of the limited embedding capacity, a dual-image strategy is introduced and improved according to the characteristics of JPEG. In our method, all nonzero DCT coefficients are embedded without the additional distortion caused by invalid modifications, and the spatial distortion caused by the modification of DCT coefficients with different frequencies varies. A dynamic allocation method is proposed to arrange the embedding capacity reasonably to achieve less distortion. The nonzero DCT coefficients can be embedded flexibly with different bits of secret data to significantly improve the embedding capacity. As far as we know, this is the first work to achieve RDH in JPEG images in a dual-image manner. Furthermore, we also apply the proposed method to the reversible authentication of JPEG images. Experimental results demonstrate the efficacy of the proposed method with high embedding capacity and satisfactory visual quality while suppressing file size expansion.},
  archive      = {J_ISCI},
  author       = {Heng Yao and Fanyu Mao and Chuan Qin and Zhenjun Tang},
  doi          = {10.1016/j.ins.2021.02.015},
  journal      = {Information Sciences},
  pages        = {130-149},
  shortjournal = {Inf. Sci.},
  title        = {Dual-JPEG-image reversible data hiding},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Fuzzy adaptive event-triggered control for a class of
nonlinear systems with time-varying full state constraints.
<em>ISCI</em>, <em>563</em>, 111–129. (<a
href="https://doi.org/10.1016/j.ins.2021.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a fuzzy adaptive event-triggered control (ETC) design method for nonlinear systems with time-varying state constraints. Fuzzy logic systems (FLSs) is adopted to approximate the unknown smooth functions and the constraints are satisfied by using an appropriate asymmetric time-varying barrier Lyapunov function (BLF). The communication burden from the controller to the actuator is reduced by designing an appropriate ETC scheme. Finally, it is shown that the full-state constraints are not violated at any step of the backstepping design and the signals in the closed-loop system are bounded. The effectiveness of the proposed adaptive ETC scheme is verified by two simulation examples.},
  archive      = {J_ISCI},
  author       = {Xin Jin and Yuan-Xin Li},
  doi          = {10.1016/j.ins.2021.02.021},
  journal      = {Information Sciences},
  pages        = {111-129},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy adaptive event-triggered control for a class of nonlinear systems with time-varying full state constraints},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel one-dimensional chaotic map generator and its
application in a new index representation-based image encryption scheme.
<em>ISCI</em>, <em>563</em>, 91–110. (<a
href="https://doi.org/10.1016/j.ins.2021.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fast growth in digital image transmission technologies requires more secure and effective image encryption schemes to provide essential security. In this paper, we present a novel one-dimensional chaotic map amplifier (1-DCMA). The evaluation of the proposed chaotic system shows that the 1-DCMA improve the chaotic behavior, control parameters’ structure, and sensitivity of the 1-D chaotic maps used as input. We further implement a chaotic map generated by the 1-DCMA in a new asymmetric image encryption scheme (Amp-Lg-IE). Using the secret key, the proposed encryption algorithm adds rows and implement a new index representation (IR) concept with shifting sequences to manipulate the pixels’ positions and values synchronously. Finally, we execute bit-level operations to obtain the ciphered image. The simulation and security analysis prove that the Amp-Lg-IE, in a satisfying time, can encrypt a plain image into an unidentified random-like one with high resistance to different types of threats and attacks.},
  archive      = {J_ISCI},
  author       = {Ali Mansouri and Xingyuan Wang},
  doi          = {10.1016/j.ins.2021.02.022},
  journal      = {Information Sciences},
  pages        = {91-110},
  shortjournal = {Inf. Sci.},
  title        = {A novel one-dimensional chaotic map generator and its application in a new index representation-based image encryption scheme},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Many-objective evolutionary algorithm with adaptive
reference vector. <em>ISCI</em>, <em>563</em>, 70–90. (<a
href="https://doi.org/10.1016/j.ins.2021.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convergence is always a major concern for many-objective optimization problems . Over the past few decades, various methods have been designed for measuring the convergence. However, according to our mathematical and empirical analyses, most of these methods are more focused on the convergence, and may neglect the exploration of boundary solutions, resulting in the incomplete Pareto fronts and the poor extent of spread achieved among the obtained non-dominated solutions. Regarding this issue, this paper proposes a Many-Objective Evolutionary Algorithm with Adaptive Reference Vector (MaOEA-ARV). In MaOEA-ARV, an adaptive reference vector strategy is designed to dynamically adjust the reference vectors according to the current distribution of candidate solutions for ensuring the spread and convergence simultaneously. Additionally, a hierarchical clustering strategy is employed to adaptively partition candidate solutions into multiple clusters for the diversity of candidate solutions. Experimental results on DTLZ, BT, ZDT and WFG test suites with up to 12 objectives demonstrate the effectiveness of MaOEA-ARV.},
  archive      = {J_ISCI},
  author       = {Maoqing Zhang and Lei Wang and Wuzhao Li and Bo Hu and Dongyang Li and Qidi Wu},
  doi          = {10.1016/j.ins.2021.01.015},
  journal      = {Information Sciences},
  pages        = {70-90},
  shortjournal = {Inf. Sci.},
  title        = {Many-objective evolutionary algorithm with adaptive reference vector},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delayed nonquadratic l2-stabilization of continuous-time
nonlinear takagi–sugeno fuzzy models. <em>ISCI</em>, <em>563</em>,
59–69. (<a href="https://doi.org/10.1016/j.ins.2021.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work deals with the design of fuzzy controllers for stabilization of continuous-time nonlinear systems subject to L 2 L2 disturbances, which are represented by nonlinear Takagi–Sugeno fuzzy models, i.e. , Takagi–Sugeno fuzzy models with nonlinear consequents. A nonquadratic Lyapunov function is used to derive sufficient design conditions based on linear matrix inequality constraints as well as to reduce the conservativeness when compared to existing control approaches in the literature. Furthermore, the nonquadratic Lyapunov function is defined in terms of an integral membership function, which leads to a delayed nonquadratic L 2 L2 -stabilization condition. This condition avoids the well-known difficulties in dealing with time derivatives of membership functions and/or path-independent conditions, found in most of the nonquadratic control approaches for continuous-time Takagi–Sugeno fuzzy models. Two numerical examples are performed to illustrate the reduction in conservativeness provided by the proposed approach.},
  archive      = {J_ISCI},
  author       = {Rodrigo F. Araújo and Pedro H.S. Coutinho and Anh-Tu Nguyen and Reinaldo M. Palhares},
  doi          = {10.1016/j.ins.2021.01.007},
  journal      = {Information Sciences},
  pages        = {59-69},
  shortjournal = {Inf. Sci.},
  title        = {Delayed nonquadratic l2-stabilization of continuous-time nonlinear Takagi–Sugeno fuzzy models},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint tracking of multiple quantiles through conditional
quantiles. <em>ISCI</em>, <em>563</em>, 40–58. (<a
href="https://doi.org/10.1016/j.ins.2021.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The estimation of quantiles is one of the most fundamental data mining tasks. As most real-time data streams vary dynamically over time, there is a quest for adaptive quantile estimators. The most well-known type of adaptive quantile estimators is the incremental one which documents the state-of-the art performance in tracking quantiles. However, the absolute vast majority of incremental quantile estimators fail to jointly estimate multiple quantiles in a consistent manner without violating the monotone property of quantiles. In this paper, first we introduce the concept of conditional quantiles that can be used to extend incremental estimators to jointly track multiple quantiles. Second, we resort to the concept of conditional quantiles to propose two new estimators. Extensive experimental results, based on both synthetic and real-life data, show that the proposed estimators clearly outperform legacy state-of-the-art joint quantile tracking algorithms in terms of accuracy while achieving faster adaptivity in the face of dynamically varying data streams.},
  archive      = {J_ISCI},
  author       = {Hugo Lewi Hammer and Anis Yazidi and Håvard Rue},
  doi          = {10.1016/j.ins.2021.02.014},
  journal      = {Information Sciences},
  pages        = {40-58},
  shortjournal = {Inf. Sci.},
  title        = {Joint tracking of multiple quantiles through conditional quantiles},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective soft subspace clustering in the composite
kernel space. <em>ISCI</em>, <em>563</em>, 23–39. (<a
href="https://doi.org/10.1016/j.ins.2021.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional subspace clustering algorithms group the data samples by optimizing the objective function which aggregates different clustering criteria using the linear combination. However, the performance is sensitive to the user-defined coefficients. Besides, the widely used Euclidean distance metric falls short of handling the linear indivisible problems. Some composite kernel metrics are proposed to overcome this drawback, but it is still difficult to determine the proper weight of base kernels. To address these problems, a novel multi-objective soft subspace clustering model is proposed. The novel model simultaneously optimizes three clustering criteria without setting coefficients. The distance between data points is measured in a composite kernel space. The weight of base kernels is optimized by a multi-objective evolutionary algorithm. A decomposition-based local search strategy is developed to enhance the performance of the proposed algorithm. The experimental results indicate that the proposed algorithm can achieve better solutions.},
  archive      = {J_ISCI},
  author       = {Yuanrui Li and Qiuhong Zhao and Kaiping Luo},
  doi          = {10.1016/j.ins.2021.02.008},
  journal      = {Information Sciences},
  pages        = {23-39},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective soft subspace clustering in the composite kernel space},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Representing complex networks without connectivity via
spectrum series. <em>ISCI</em>, <em>563</em>, 16–22. (<a
href="https://doi.org/10.1016/j.ins.2021.01.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new paradigm for describing complex networks in terms of the spectrum of the adjacency matrix and its submatrices . We show that a variety of basic node information, such as degree, clique , and subgraph centrality, can be calculated analytically. Moreover, we find that energy of spectrum series can uncover randomness and complexity of network structure. Interestingly, it presents an universal linear growth pattern with the growth of networks. Furthermore, the spectrum series of synthetic and real networks present clearly self-similarity characteristics for which the associated scaling exponents remain constant. Our work reveals that spectrum series representation will provide an alternative perspective for studying and understanding structure and function of complex networks rather than connectivity.},
  archive      = {J_ISCI},
  author       = {Tongfeng Weng and Haiying Wang and Huijie Yang and Changgui Gu and Jie Zhang and Michael Small},
  doi          = {10.1016/j.ins.2021.01.067},
  journal      = {Information Sciences},
  pages        = {16-22},
  shortjournal = {Inf. Sci.},
  title        = {Representing complex networks without connectivity via spectrum series},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse fuzzy two-dimensional discriminant local preserving
projection (SF2DDLPP) for robust image feature extraction.
<em>ISCI</em>, <em>563</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2021.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, image feature extraction algorithms based on 2D discriminant local preserving projection (2DDLPP) algorithms have been successfully applied in many fields. The 2DDLPP can maintain the discrimination information of the local intrinsic manifold structure using two-dimensional image representation data. However, the 2DDLPP algorithm encounters the problem of the sensitivity of overlapping points (outliers) and requires high computational cost in real-world applications. In order to resolve the problems mentioned above, we introduce a new elastic feature extraction algorithm called the sparse fuzzy 2D discriminant local preserving projection (SF2DDLPP). First, the membership matrix is calculated using the fuzzy k-nearest neighbours (FKNN), which is applied to the intraclass weighted matrix and the interclass weighted matrix. Second, two theorems are developed to directly solve the generalized eigenfunctions . Finally, the optimal sparse fuzzy 2D discriminant projection matrix is regressed using the elastic net regression. The experiments show the effectiveness and stability of this algorithm on several face (ORL, Yale, AR and Yale B), USPS and palm print datasets.},
  archive      = {J_ISCI},
  author       = {Minghua Wan and Xueyu Chen and Tianming Zhan and Chao Xu and Guowei Yang and Huiting Zhou},
  doi          = {10.1016/j.ins.2021.02.006},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Sparse fuzzy two-dimensional discriminant local preserving projection (SF2DDLPP) for robust image feature extraction},
  volume       = {563},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiparty verification in image secret sharing.
<em>ISCI</em>, <em>562</em>, 475–490. (<a
href="https://doi.org/10.1016/j.ins.2021.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiparties in image secret sharing (ISS) need to verify (detect and recognize) each other, which is seldom considered and realized in traditional methods. In this paper, we introduce the definition of multiparty verification. It includes two stages, i.e., a detection stage and a recognition stage, with evaluation methods that are also discussed. A multiparty verification scheme without pixel expansion is developed, which is suitable for both dealer attendance and nonattendance. The classic hash function , public key cryptography and visual cryptography are technically fused in the developed scheme. In the shadow distribution phase, each participant can verify the received shadow using his private key. In the restoration phase, for the case of dealer attendance, he can verify each shadow received using his secret key; for the case of dealer nonattendance, participants can verify each other before exchanging their shadows. We conduct analyses and illustrations to validate the developed scheme.},
  archive      = {J_ISCI},
  author       = {Xuehu Yan and Junhao Li and Zulie Pan and Xiaofeng Zhong and Guozheng Yang},
  doi          = {10.1016/j.ins.2021.03.029},
  journal      = {Information Sciences},
  pages        = {475-490},
  shortjournal = {Inf. Sci.},
  title        = {Multiparty verification in image secret sharing},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An image matching optimization algorithm based on pixel
shift clustering RANSAC. <em>ISCI</em>, <em>562</em>, 452–474. (<a
href="https://doi.org/10.1016/j.ins.2021.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on improving the accuracy of image matching by eliminating the residual mismatches in the matching results of standard RANSAC. Based on pixel shift clustering and RANSAC algorithms, a matching optimization algorithm called pixel shift clustering RANSAC, PSC-RANSAC in short, is proposed in this paper. Firstly, the pixel shift model of space point from two perspectives are established by parallax principle and camera projection model. Then, based on the established pixel shift model, density peaks clustering (DPC) algorithm is used to select the mismatches out to enhance the accuracy of image matching. Meanwhile the comparisons among PSC-RANSAC, standard RANSAC, progressive sample consensus and graph-cut RANSAC show that PSC-RANSAC can more effectively and robustly eliminate the residual mismatches in initial matching results. The proposed method provides an effective tool for optimization on image matching.},
  archive      = {J_ISCI},
  author       = {Shuhua Ma and Peikai Guo and Hairong You and Ping He and Guanglin Li and Heng Li},
  doi          = {10.1016/j.ins.2021.03.023},
  journal      = {Information Sciences},
  pages        = {452-474},
  shortjournal = {Inf. Sci.},
  title        = {An image matching optimization algorithm based on pixel shift clustering RANSAC},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Accelerated manifold embedding for multi-view
semi-supervised classification. <em>ISCI</em>, <em>562</em>, 438–451.
(<a href="https://doi.org/10.1016/j.ins.2021.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view semi-supervised learning has gained much attention since a great number of unlabeled multi-view data are easy to obtain while few labeled data are available. Accordingly, how to utilize the relationship between labeled and unlabeled data is of significance in multi-view semi-supervised learning. In this paper, we propose an auto-weighted manifold embedding model to address multi-view semi-supervised classification problems, where only a small percentage of labeled data points are used for model training. In the proposed model, data points close to each other in the feature space will be assigned to similar classes in the label space through manifold embedding. Accordingly, the class information of labeled data will be employed in the prediction process for unlabeled data. Moreover, an optimal weight for each view of multi-view data is learned automatically, which enables an encouraging fusion quality for multi-view manifold embedding. To further speed up the calculation process and reduce the computational complexity of the proposed model, an effective accelerated auto-weighted manifold embedding scheme is developed. Besides, theoretical analyses are then provided to indicate a tight approximation bound for the primary manifold embedding method, while the accelerated method is designed by an order decrease of magnitude of computational complexity. Finally, comprehensive experiments on eight publicly available data sets demonstrate the superiority of the proposed models over compared state-of-the-art semi-supervised methods and fully supervised classifiers. Furthermore, the experimental results are suggestive of positive robustness and promising generalization capacity of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Shiping Wang and Zhewen Wang and Wenzhong Guo},
  doi          = {10.1016/j.ins.2021.03.040},
  journal      = {Information Sciences},
  pages        = {438-451},
  shortjournal = {Inf. Sci.},
  title        = {Accelerated manifold embedding for multi-view semi-supervised classification},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate models in evolutionary single-objective
optimization: A new taxonomy and experimental study. <em>ISCI</em>,
<em>562</em>, 414–437. (<a
href="https://doi.org/10.1016/j.ins.2021.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs), which use efficient surrogate models or meta-models to approximate the fitness function in evolutionary algorithms (EAs), are effective and popular methods for solving computationally expensive optimization problems. During the past decades, a number of SAEAs have been proposed by combining different surrogate models and EAs. This paper dedicates to providing a more systematical review and comprehensive empirical study of surrogate models used in single-objective SAEAs. A new taxonomy of surrogate models in SAEAs for single-objective optimization is introduced in this paper. Surrogate models are classified into two major categories: absolute fitness models, which directly approximate the fitness function values of candidate solutions, and relative fitness models, which estimates the relative rank or preference of candidates rather than their fitness values. Then, the characteristics of different models are analyzed and compared by conducting a series of experiments in terms of time complexity (execution time), model accuracy, parameter influence, and the overall performance when used in EAs. The empirical results are helpful for researchers to select suitable surrogate models when designing SAEAs. Open research questions and future work are discussed at the end of the paper.},
  archive      = {J_ISCI},
  author       = {Hao Tong and Changwu Huang and Leandro L. Minku and Xin Yao},
  doi          = {10.1016/j.ins.2021.03.002},
  journal      = {Information Sciences},
  pages        = {414-437},
  shortjournal = {Inf. Sci.},
  title        = {Surrogate models in evolutionary single-objective optimization: A new taxonomy and experimental study},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). Supervisory control of discrete-event systems under
external attacks. <em>ISCI</em>, <em>562</em>, 398–413. (<a
href="https://doi.org/10.1016/j.ins.2021.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resilience is a critical criterion to evaluate a networked system including discrete-event systems (DESs). This research touches upon the supervisory control problem of a DES modeled with labeled Petri nets under malicious attacks. Attacks on a system can be categorized into actuator attacks and sensor attacks. The former may cause a failure of an actuator for executing the commands issued from a supervisor that enforces a specification. The latter may corrupt an observation (i.e., a sequence of observable transition labels) from a sensor by different types of attacks such as insertion, removal, and replacement of transition labels. For actuator attacks, if we can detect them and disable some particular controllable transition labels before reaching a state that does not satisfy the specification, then we can find a modified supervisor to enforce the specification. For sensor attacks, we assume that, once a time, only one attack can be carried out, i.e., the attacker does not change the attack during an observation corruption. Given a specification, we consider in a plant model any two feasible transition sequences that share the same corrupted observation under attacks. It is shown that there exists a supervisor to enforce the specification if the one-step controllable extensions of the two transition sequences either satisfy or violate the specification simultaneously. To this end, a novel structure, namely a product observation reachability graph constructed from a plant and its specification, is proposed to decide the existence of such a supervisor by checking whether each state in the graph satisfies a particular condition. The application of the reported methods is demonstrated through examples.},
  archive      = {J_ISCI},
  author       = {Yi Wang and Yuting Li and Zhenhua Yu and Naiqi Wu and Zhiwu Li},
  doi          = {10.1016/j.ins.2021.03.033},
  journal      = {Information Sciences},
  pages        = {398-413},
  shortjournal = {Inf. Sci.},
  title        = {Supervisory control of discrete-event systems under external attacks},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On embedding sequence correlations in attributed network for
semi-supervised node classification. <em>ISCI</em>, <em>562</em>,
385–397. (<a href="https://doi.org/10.1016/j.ins.2021.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks(GNNs) has dominated the semi-supervised node classification task by its neighborhood aggregation mechanism over traditional network embedding methods. However, GNNs still encounters with two vital problems when scales to large networks. It requires the whole graph as input and aggregates attribute only, which brings out-of-memory(OOM) problem on single machine scenery and attribute over-smoothing respectively. To tackle these issues, from the traditional view, we propose a S equence correlation preserving method for A ttributed N etwork E mbedding (SANE) which transforms the network properties into three types of sequences and preserves the correlations among them. Firstly, SANE extracts three types of sequences in attributed network, namely node sequence, attribute sequence, and label sequence, which provide distinct insight into networks. Secondly, the proposed method preserves attribute-node sequence correlation and attribute-label sequence correlation by (1) extracting dual-directional features from attribute sequence and (2) exploiting the extracted features to decode node sequence and label sequence. SANE can scale to large networks and relieve the over-smoothing causing by attribute only aggregation. Experimental results on five real-world datasets demonstrate that SANE outperforms the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Haodong Zou and Zhen Duan and Xinru Guo and Shu Zhao and Jie Chen and Yanping Zhang and Jie Tang},
  doi          = {10.1016/j.ins.2021.03.044},
  journal      = {Information Sciences},
  pages        = {385-397},
  shortjournal = {Inf. Sci.},
  title        = {On embedding sequence correlations in attributed network for semi-supervised node classification},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Channel-exchanged feature representations for person
re-identification. <em>ISCI</em>, <em>562</em>, 370–384. (<a
href="https://doi.org/10.1016/j.ins.2021.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting from convolutional neural networks, person re-identification (Re-ID) has achieved great improvements with most state-of-the-art studies. However, person Re-ID in real scenarios is still confronted by intricate challenges, especially regarding the color problem. Scenarios in which different people wear clothes with the same or similar colors will make person Re-ID more difficult. In this work, we formulate a novel two-stream channel-exchanged multi-layer network (CENet), which can not only learn color-robust features to alleviate color interference but also essentially be regarded as a data augmentation method. For the first stream, we use the original RGB image as the input to extract global pedestrian features. Furthermore, we can obtain six images with different colors by exchanging the three channels of the RGB image, and then, we randomly select one image, which is fed to the second stream to alleviate the interference of colors. Moreover, by swapping RGB channels, we can obtain six types of images that still retain the same identities, increasing the training sets immensely. Extensive experiments conducted on three benchmark datasets, Market-1501, DukeMTMC-reID and CUHK03, demonstrate that our proposed method achieves the best Rank-1/mAP of 95.6\%/88.1\% and 89.2\%/77.5\% on the Market-1501 and DukeMTMC-reID datasets, respectively, outperforming current state-of-the-art methods significantly.},
  archive      = {J_ISCI},
  author       = {Jianchen Wang and Liming Yuan and Haixia Xu and Gengsheng Xie and Xianbin Wen},
  doi          = {10.1016/j.ins.2021.03.028},
  journal      = {Information Sciences},
  pages        = {370-384},
  shortjournal = {Inf. Sci.},
  title        = {Channel-exchanged feature representations for person re-identification},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A consensus process based on regret theory with
probabilistic linguistic term sets and its application in venture
capital. <em>ISCI</em>, <em>562</em>, 347–369. (<a
href="https://doi.org/10.1016/j.ins.2021.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a consensus model for multi-experts multi-criteria decision making (MEMCDM) problems with probabilistic linguistic term sets (PLTSs), which also considers the regret-rejoice emotions of decision makers (DMs) in their decision-making processes. Additionally, the Dempster-Shafer theory is applied to estimate the probability of the market status which is related to the perceived values of the alternatives. Moreover, an algorithm is given to determine the weight of each DM. Then, a detailed consensus procedure is proposed and an illustrative example is used to show the feasibility of the proposed model. Finally, some comparative analyses are carried out to demonstrate the advantages of the proposed consensus process.},
  archive      = {J_ISCI},
  author       = {Xiaoli Tian and Zeshui Xu and Jing Gu and Francisco Herrera},
  doi          = {10.1016/j.ins.2021.02.003},
  journal      = {Information Sciences},
  pages        = {347-369},
  shortjournal = {Inf. Sci.},
  title        = {A consensus process based on regret theory with probabilistic linguistic term sets and its application in venture capital},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonnegative matrix factorization with local similarity
learning. <em>ISCI</em>, <em>562</em>, 325–346. (<a
href="https://doi.org/10.1016/j.ins.2021.01.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing nonnegative matrix factorization methods usually focus on learning global structure of the data to construct basis and coefficient matrices , which ignores the local structure that commonly exists among data. To overcome this drawback, in this paper, we propose a new type of nonnegative matrix factorization method, which learns local similarity and clustering in a mutually enhanced way. The learned new representation is more representative in that it better reveals inherent geometric property of the data. Moreover, the new representation is performed in the kernel space, which enhances the capability of the proposed model in discovering nonlinear structures of data. Multiplicative updating rules are developed with theoretical convergence guarantees. Extensive experimental results have confirmed the effectiveness of the proposed model.},
  archive      = {J_ISCI},
  author       = {Chong Peng and Zhilu Zhang and Zhao Kang and Chenglizhao Chen and Qiang Cheng},
  doi          = {10.1016/j.ins.2021.01.087},
  journal      = {Information Sciences},
  pages        = {325-346},
  shortjournal = {Inf. Sci.},
  title        = {Nonnegative matrix factorization with local similarity learning},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visually meaningful image encryption based on universal
embedding model. <em>ISCI</em>, <em>562</em>, 304–324. (<a
href="https://doi.org/10.1016/j.ins.2021.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visually meaningful image encryption (VMIE) means that a plain image can be encrypted into a visually meaningful cipher image (VMCI), which makes the secret more imperceptible than noise-like cipher images. Here, we first present a universal embedding model (UEM) and further present a new UEM-based VMIE algorithm. The plain image is pre-encrypted and then embedded into the integer wavelet subbands of the host image in a dynamic way. In order to avoid the overflow, a threshold limiting function is used to modify the range of pixel values of the host image. To adapt different types of wavelet transform subbands, a UEM is proposed to be used to embed the secret information domain into the host domain. Moreover, in the embedding process, a four-dimensional discrete chaotic system is used to ensure the security of embedding. The numbers of embedded bits in the four embedded domains can be adjusted flexibly. A traversal algorithm is designed to find the optimal numbers of embedded bits for different types of wavelet transform in order to achieve an optimal visual quality of cipher images. A matrix-bit-depth-conversion algorithm is designed where a large matrix with low bit depth can be transformed into a small matrix with high bit depth to meet the input requirements of UEM, which means that the size of the plain image is not limited to a quarter of the size of the host image. Simulation results and performance comparisons show that the proposed VMIE algorithm can achieve a better visual quality than existing VMIE algorithms.},
  archive      = {J_ISCI},
  author       = {Yu-Guang Yang and Bao-Pu Wang and Yong-Li Yang and Yi-Hua Zhou and Wei-Min Shi and Xin Liao},
  doi          = {10.1016/j.ins.2021.01.041},
  journal      = {Information Sciences},
  pages        = {304-324},
  shortjournal = {Inf. Sci.},
  title        = {Visually meaningful image encryption based on universal embedding model},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incremental classifier in crime prediction using
bi-objective particle swarm optimization. <em>ISCI</em>, <em>562</em>,
279–303. (<a href="https://doi.org/10.1016/j.ins.2021.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the increase in criminal activities has resulted in a massive generation of crime reports describing the details of the crime incidents. Analyzing these reports for crime type prediction helps the law enforcement agencies deal with crime prevention strategies. But it is quite a demanding and difficult task to consider these reports individually and determine their crime types. In the proposed work, an efficient classifier has been designed to analyze the crime reports which not only predict the crime types of the reports but at the same time upgrades itself with the help of new crime reports. Therefore, this task demands an incremental supervised learning technique that continuously learns the existing classifier based on the new set of reports and information already extracted from the old set of reports. Developing an incremental classifier infuses the knowledge that keep coming from the newly generated reports and help in increasing the report-discriminating power of the classifier. In this work, we have applied a Bi-objective Particle Swarm Optimization technique for generating an efficient incremental classifier for classifying and predicting the crime reports dynamically. Crime reports of different countries, such as India, the United States of America, and the United Arab Emirates, have been collected from online classified newspapers to measure the performance of the proposed as well as some state-of-the-art classifiers. Also, the method has been evaluated based on an unbiased police witness narrative crime reports and finally, a statistical test has been performed using all four considered datasets to measure the statistical significance of the proposed methodology.},
  archive      = {J_ISCI},
  author       = {Priyanka Das and Asit Kumar Das and Janmenjoy Nayak and Danilo Pelusi and Weiping Ding},
  doi          = {10.1016/j.ins.2021.02.002},
  journal      = {Information Sciences},
  pages        = {279-303},
  shortjournal = {Inf. Sci.},
  title        = {Incremental classifier in crime prediction using bi-objective particle swarm optimization},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decrease and conquer-based parallel tensor factorization for
diversity and real-time of multi-criteria recommendation. <em>ISCI</em>,
<em>562</em>, 259–278. (<a
href="https://doi.org/10.1016/j.ins.2021.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of recommender systems, diversity as the measure of recommendation quality has gained much attention recently. Unfortunately, many researchers have shown that it has a trade-off relation with accuracy. Meanwhile, tensor factorization has been used as a useful technique that considers multi-correlations between user-item-other factors directly. However, it generally suffers from the model sparsity caused by high dimensionality and requirement of high computational costs. To improve diversity and response time while preserving accuracy in multi-criteria recommender systems (MCRS), we propose a decrease and conquer-based parallel tensor factorization (DnCPTF). In the DnCPTF , sentiment analysis alleviates the sparsity problem, and a two-phase clustering groups similar user reviews into sub-models. Furthermore, a controllable subdivision guarantees high diversity and short response time. The sub-models are then factorized in parallel to predict ratings, and top-N items are recommended via ratings consolidated from the sub-models. On a real-world dataset gathered from TripAdvisor, experimental results demonstrated that the DnCPTF significantly improve recommendation diversity (55× of a conventional tensor factorization (CTF)) and response time (182× of the CTF) with preserving high precision and recall. Furthermore, it outperformed recent techniques in precision, diversity and required response time within 1 s on average.},
  archive      = {J_ISCI},
  author       = {Minsung Hong},
  doi          = {10.1016/j.ins.2021.02.005},
  journal      = {Information Sciences},
  pages        = {259-278},
  shortjournal = {Inf. Sci.},
  title        = {Decrease and conquer-based parallel tensor factorization for diversity and real-time of multi-criteria recommendation},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling the dynamics of rumor diffusion over complex
networks. <em>ISCI</em>, <em>562</em>, 240–258. (<a
href="https://doi.org/10.1016/j.ins.2020.12.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumor propagation on complex networks is rapidly affecting people’s life. As we all know, the regulatory control of rumors by regulators has a specific impact on the spread of rumors. Limited regulatory resources may saturate the regulatory level. Therefore, in this paper, we have introduced a saturation treatment function to model this phenomenon and further establish an SIS rumor propagation model with consideration of some comprehensive influence on rumor diffusion. First of all, we prove the boundedness of solutions, and the basic reproduction number R 0 R0 is obtained by the method of the next generation matrix . Secondly, by constructing Lyapunov function and applying the linearization method of differential equations, the stability conditions of the equilibrium points are derived. Further, we determine the condition for the backward bifurcation of the rumor propagation model . Moreover, in order to control the spread of rumors, we propose targeted immunization control, acquaintance immunization control and optimal control strategies based on complex networks. Finally, the sensitivity analysis of the basic reproduction number is carried out, and the correctness of the theoretical results is verified by numerical simulations. Our results may provide us with useful insights into the dynamics of online rumor propagation. For example, the basic reproduction number R 0 R0 gives the threshold of rumor propagation, which provides control conditions for suppressing the spread of rumors. Stability analysis indicates the likelihood of local or global outbreaks for rumors. In addition, the comparison of the effect for control strategies gives a variety of options for the control method .},
  archive      = {J_ISCI},
  author       = {Linhe Zhu and Fan Yang and Gui Guan and Zhengdi Zhang},
  doi          = {10.1016/j.ins.2020.12.071},
  journal      = {Information Sciences},
  pages        = {240-258},
  shortjournal = {Inf. Sci.},
  title        = {Modeling the dynamics of rumor diffusion over complex networks},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Binary multi-layer classifier. <em>ISCI</em>, <em>562</em>,
220–239. (<a href="https://doi.org/10.1016/j.ins.2021.01.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary decision trees (BDTs), where each node of the tree is split into two child nodes, are among the most popular classifiers. An alternative type of classification tree, namely, the multi-layer classifier (MLC), has been proposed to split the parent node into 1 or 2 classified child nodes and an unclassified child node at each layer. In contrast to the nodes in a BDT, only the unclassified node of the MLC can be further split. Though the use of MLC is plausible, it has not been widely applied due to a lack of theoretical investigations and thorough tests with real datasets. In this study, we attempt to lay a solid theoretical foundation for a simple MLC with a binary split, i.e., a split into only two nodes, namely, one classified and the other unclassified. Based on the theories developed, we propose a variance-ratio algorithm to construct tree models. The proposed algorithm is thoroughly tested with 40 datasets from well-known repositories. The results indicate that binary MLC models are easier to interpret than other models, achieve significantly better average classification performance than seven other BDT methods and construct fewer tree nodes than most other methods except CTree and NBTree.},
  archive      = {J_ISCI},
  author       = {Huanze Zeng and Argon Chen},
  doi          = {10.1016/j.ins.2021.01.085},
  journal      = {Information Sciences},
  pages        = {220-239},
  shortjournal = {Inf. Sci.},
  title        = {Binary multi-layer classifier},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Average convergence rate of evolutionary algorithms in
continuous optimization. <em>ISCI</em>, <em>562</em>, 200–219. (<a
href="https://doi.org/10.1016/j.ins.2020.12.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The average convergence rate (ACR) measures how fast the approximation error of an evolutionary algorithm converges to zero per generation. It is defined as the geometric average of the reduction rate of the approximation error over consecutive generations. This paper makes a theoretical analysis of the ACR in continuous optimization. The obtained results are summarized as follows. According to the limit property, the ACR is classified into two categories: (1) linear ACR whose limit inferior value is larger than a positive and (2) sublinear ACR whose value converges to zero. Then, it is proven that the ACR is linear for evolutionary programming using positive landscape-adaptive mutation, but sublinear for that using landscape-invariant or zero landscape-adaptive mutation. The relationship between the ACR and the decision space dimension is also classified into two categories: (1) polynomial ACR whose value is larger than the reciprocal of a polynomial function of the dimension for any generation, and (2) exponential ACR whose value is less than the reciprocal of an exponential function of the dimension for an exponential long period. It is proven that for easy problems such as linear functions, the ACR of the (1 + 1) adaptive random univariate search is polynomial. But for hard functions such as the deceptive function, the ACR of both the (1 + 1) adaptive random univariate search and evolutionary programming is exponential.},
  archive      = {J_ISCI},
  author       = {Yu Chen and Jun He},
  doi          = {10.1016/j.ins.2020.12.076},
  journal      = {Information Sciences},
  pages        = {200-219},
  shortjournal = {Inf. Sci.},
  title        = {Average convergence rate of evolutionary algorithms in continuous optimization},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lattice-valued overlap and quasi-overlap functions.
<em>ISCI</em>, <em>562</em>, 180–199. (<a
href="https://doi.org/10.1016/j.ins.2021.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important class of aggregation operators, the notion of overlap functions was first presented in 2009 in order to be considered for applications in image processing context. Later, many other researches arised bringing some variations of those functions for different purposes. Here, our main goal is defining overlap functions on lattices and discuss how a weakned version of it, named quasi-overlaps, works when continuity is eliminated from the definition. Some properties of quasi-overlaps on lattices , namely convex sum, migrativity, homogeneity, idempotency and cancellation law are investigated. Also, Finally, properties related to continuity as “Archimedean” and “limiting” are studied.},
  archive      = {J_ISCI},
  author       = {Rui Paiva and Regivan Santiago and Benjamín Bedregal and Eduardo Palmeira},
  doi          = {10.1016/j.ins.2021.02.010},
  journal      = {Information Sciences},
  pages        = {180-199},
  shortjournal = {Inf. Sci.},
  title        = {Lattice-valued overlap and quasi-overlap functions},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy rule-based models: A design with prototype relocation
and granular generalization. <em>ISCI</em>, <em>562</em>, 155–179. (<a
href="https://doi.org/10.1016/j.ins.2020.12.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rule-based models and the extension of classical fuzzy models have been widely used in many domains. From a holistic perspective, regardless of the design methods and rules adopted in a fuzzy model, the determination of fuzzy sets is a pivotal issue. In the proposed methods, instead of traditional data clustering with no directional tendency, we introduce an optimization algorithm that can adjust the position of the prototypes of zero- and first-order fuzzy models to learn internal structure information from the data in the process of parameter identification. Furthermore, to build a granular fuzzy model, the prototypes are then scaled to more robust intervals by generating information granularity with specific semantics such that they split the whole output space. Particle swarm optimization algorithm is applied to adjust both the locations of the prototypes and the allocation of information granularity to improve the performance of the data-driven models. Experimental studies on synthetic and real-world datasets are provided to demonstrate the effectiveness of these methods.},
  archive      = {J_ISCI},
  author       = {Yan Li and Chao Chen and Xingchen Hu and Jindong Qin and Yang Ma},
  doi          = {10.1016/j.ins.2020.12.093},
  journal      = {Information Sciences},
  pages        = {155-179},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy rule-based models: A design with prototype relocation and granular generalization},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-step hybrid collaborative filtering using deep
variational bayesian autoencoders. <em>ISCI</em>, <em>562</em>, 136–154.
(<a href="https://doi.org/10.1016/j.ins.2021.01.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing recommender systems rely on user and item representations in a fixed continuous low-dimensional latent space. To predict ratings, they use only an implicit feedback matrix , whereas user and item side information is ignored. Furthermore, they use the same arbitrary priors for the user and item latent vectors, reducing the ability of the model to identify the actual latent vectors. Currently, the latent parameters should be learned directly for every user and movie. This is problematic, as it would require both model retraining and learning the latent vector representations when users or items are added to the underlying dataset. To address these issues, we propose a two-step hybrid variational Bayesian autoencoder to characterize the uncertainty of predicted ratings. An encoder is first trained to map data vectors to the latent space so that the latent representations can be dynamically computed. Subsequently, we use the generative process of users and items with their priors as side-specific information to handle matrix sparsity and better learn their latent vectors. Finally, we consider stochastic variational inference to approximate the posterior density of intractable user-item latent vectors. Experiments conducted on two real-world datasets demonstrate the effectiveness of the proposed method compared with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Ravi Nahta and Yogesh Kumar Meena and Dinesh Gopalani and Ganpat Singh Chauhan},
  doi          = {10.1016/j.ins.2021.01.083},
  journal      = {Information Sciences},
  pages        = {136-154},
  shortjournal = {Inf. Sci.},
  title        = {Two-step hybrid collaborative filtering using deep variational bayesian autoencoders},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sentiment analysis with genetic programming. <em>ISCI</em>,
<em>562</em>, 116–135. (<a
href="https://doi.org/10.1016/j.ins.2021.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of online social networks , people became more eager to express and share their opinions and sentiment about all kinds of targets. The overwhelming amount of opinion texts soon attracted the interest of many entities (industry, e-commerce, celebrities, etc.) that were interested in analyzing the sentiment people express about what they produce or communicate. This interest has led to the surge of the sentiment analysis (SA) field. One of the most studied subfields of SA is polarity detection, which is the problem of classifying a text as positive, negative, or neutral. This classification problem is difficult to solve automatically, and many hand-adjusted resources are needed to overcome the difficulties in detecting sentiment from text. These resources include hand-adjusted textual features as well as lexicons. Deciding which resource and which combination of resources are more appropriate to a given scenario is a time-consuming trial-and-error process. Thus, in this work, we propose the use of Genetic Programming (GP) as a tool for automatically choosing, combining, and classifying sentiment from text. We propose a series of functions that allow GP to deal with preprocessing tasks, handcrafted features, and automatic weighting of lexicons for a given training set. Our experiments show that our GP solution is competitive and sometimes better than SVM and superior to naïve Bayes , logistic regression , and stochastic gradient descent , which are methods used in SA competitions.},
  archive      = {J_ISCI},
  author       = {Airton Bordin Junior and Nádia Félix F. da Silva and Thierson Couto Rosa and Celso G.C. Junior},
  doi          = {10.1016/j.ins.2021.01.025},
  journal      = {Information Sciences},
  pages        = {116-135},
  shortjournal = {Inf. Sci.},
  title        = {Sentiment analysis with genetic programming},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). O3ERS: An explainable recommendation system with online
learning, online recommendation, and online explanation. <em>ISCI</em>,
<em>562</em>, 94–115. (<a
href="https://doi.org/10.1016/j.ins.2020.12.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable recommendation systems (ERSs) have attracted increasing attention from researchers, which generate high-quality recommendations with intuitive explanations to help users make appropriate decisions. However, most of the existing ERSs are designed with an offline setting, which can hardly adjust their models using the online feedback instantly for improved performance. To overcome the limitations of ERSs with the offline setting, we propose a novel online setting for ERSs and devise an effective model called O 3 ERS in this online setting, which can perform online learning with good scalability and rigorous theoretical guides for better online recommendations and online explanations. O 3 ERS also addresses two challenging problems in real scenarios, namely, the sparsity and delay of online explanations’ feedback as well as the partialness and insufficiency of online recommendations’ feedback. Specifically, O 3 ERS not only instantly leverages the knowledge learned from the recommendations’ feedback to adjust the sparse and delayed explanations’ feedback for better explanations but also utilizes a novel exploitation–exploration strategy that incorporates the explanations’ feedback to adjust the partial and insufficient recommendations’ feedback for better recommendations. Our theoretical analysis and empirical studies on one simulated and two real-world datasets show that our model outperforms the state-of-the-art models in online scenarios remarkably.},
  archive      = {J_ISCI},
  author       = {Qianqiao Liang and Xiaolin Zheng and Yan Wang and Mengying Zhu},
  doi          = {10.1016/j.ins.2020.12.070},
  journal      = {Information Sciences},
  pages        = {94-115},
  shortjournal = {Inf. Sci.},
  title        = {O3ERS: An explainable recommendation system with online learning, online recommendation, and online explanation},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Attributed community search based on effective scoring
function and elastic greedy method. <em>ISCI</em>, <em>562</em>, 78–93.
(<a href="https://doi.org/10.1016/j.ins.2021.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the proliferation of rich attribute information available for entities in real-world networks and the increasing demand for more personalized community searches, attributed community search (ACS), an upgraded version of the community search problem, has attracted great attention from the both academic and industry areas. Some algorithms have been proposed to solve this novel research problem. However, they have a deficiency in evaluating the quality of the attributed community structure, which may mislead them and discover less valuable structures. In this paper, we make up for this defect, and propose the SFEG algorithm to better solve the ACS problem. SFEG designs a more effective scoring function to measure the quality of the discovered attributed community structure, and presents an elastic greedy optimization method to quickly maximize the function value to determine the target community with a specific meaning. The extensive experiments conducted on the attributed graph datasets with ground-truth communities show that our algorithm significantly outperforms the state-of-the-art.},
  archive      = {J_ISCI},
  author       = {Chunnan Wang and Hongzhi Wang and Hanxiao Chen and Daxin Li},
  doi          = {10.1016/j.ins.2021.01.013},
  journal      = {Information Sciences},
  pages        = {78-93},
  shortjournal = {Inf. Sci.},
  title        = {Attributed community search based on effective scoring function and elastic greedy method},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hip-DE: Historical population based mutation strategy in
differential evolution with parameter adaptive mechanism. <em>ISCI</em>,
<em>562</em>, 44–77. (<a
href="https://doi.org/10.1016/j.ins.2021.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential Evolution (DE) was a powerful population-based evolutionary algorithm for global optimization, and it achieved great success in both evolutionary computation competitions and engineering applications . Despite the excellent performance of the state-of-the-art DE variants, there are still two main weaknesses existing within them: one is the weakness in a given mutation strategy and the other is the weakness in the corresponding parameter control (of the mutation strategy). By reviewing the existing mutation strategies in the recent state-of-the-art DE variants, it can be seen that all of them have insufficient use of the knowledge obtained during the evolution because the historical information of the population is not taken into consideration, which inevitably leads to a bad perception of the landscapes of the objectives. Moreover, the adaptations of the control parameters including F and CR in these state-of-the-art DE variants are interlaced with one another. A bad F and a good CR may produce a good trial vector candidate , then the bad F is of misuse in the parameter control and vice versa. In this paper, a novel DE variant, called Hip-DE, meaning the latest fashion of DE, with historical population based mutation strategy was proposed to tackle the above mentioned weaknesses. Moreover, novel parameter adaptive mechanisms for control parameters F and CR as well as a platform based step-decrease scheme of population size were proposed to enhance capacity of the mutation strategy. By incorporating these three advancements, the novel Hip-DE algorithm secured an overall better performance on the tested benchmarks in comparison with the recent proposed state-of-the-art DE variants.},
  archive      = {J_ISCI},
  author       = {Zhenyu Meng and Cheng Yang},
  doi          = {10.1016/j.ins.2021.01.031},
  journal      = {Information Sciences},
  pages        = {44-77},
  shortjournal = {Inf. Sci.},
  title        = {Hip-DE: Historical population based mutation strategy in differential evolution with parameter adaptive mechanism},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered adaptive fuzzy control for switched
nonlinear systems with state constraints. <em>ISCI</em>, <em>562</em>,
28–43. (<a href="https://doi.org/10.1016/j.ins.2021.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the event-triggered adaptive fuzzy control (AFC) problem for switched nonlinear systems with state constraints. Fuzzy logic systems are explored to handle the lumped unknown dynamics. The barrier Lyapunov function is deployed to solve state constraints. In addition, event-triggered mechanism is incorporated into the backstepping framework to mitigate the communication burden. The constructed event-triggered AFC scheme not only surmounts the effect of state constraints to system performance, but also saves network and data transmission. By resorting to the Lyapunov stability analysis and the average dwell time method, it is shown that all system signals are bounded under switching signals and the predefined constraints are not violated. Finally, simulation analysis on the mass-spring-damper systems are conducted to substantiate the validity of the designed scheme.},
  archive      = {J_ISCI},
  author       = {Yongchao Liu and Qidan Zhu and Ning Zhao},
  doi          = {10.1016/j.ins.2021.01.030},
  journal      = {Information Sciences},
  pages        = {28-43},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered adaptive fuzzy control for switched nonlinear systems with state constraints},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep model based on mode elimination and fisher criterion
combined with self-organizing map for visual multimodal chemical process
monitoring. <em>ISCI</em>, <em>562</em>, 13–27. (<a
href="https://doi.org/10.1016/j.ins.2021.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimode feature is widely adopted in complex continuous chemical processes to meet changes in market demand. However, conducting effective process monitoring in a multimode chemical process is challenging because data usually have multimodal distribution . In this study, DMF, a novel model based on a deep network, is proposed for learning new feature spaces; the multimodality of the mix data is eliminated, the same faults from all operating modes are assembled, and different faults are separated from each other. The proposed model uses a three-layer stacked autoencoder to extract features from the mixed data, uses a mode elimination term to remove data multimodality, and adopts a Fisher criterion term to separate the normal and fault states. Subsequently, DMF is combined with a self-organizing map (DMF–SOM) for visual process monitoring. DMF extracts discriminative features from the original data, and SOM visualizes these features such that the normal and fault states are distinguished on the two-dimensional output plane. The effectiveness of the DMF–SOM in process monitoring is verified by a study on the multimodal Tennessee Eastman process.},
  archive      = {J_ISCI},
  author       = {Weipeng Lu and Xuefeng Yan},
  doi          = {10.1016/j.ins.2021.01.036},
  journal      = {Information Sciences},
  pages        = {13-27},
  shortjournal = {Inf. Sci.},
  title        = {Deep model based on mode elimination and fisher criterion combined with self-organizing map for visual multimodal chemical process monitoring},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Jointly learning multi-instance hand-based biometric
descriptor. <em>ISCI</em>, <em>562</em>, 1–12. (<a
href="https://doi.org/10.1016/j.ins.2021.01.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multibiometric recognition has become one of the most important solutions for enhancing overall personal recognition performance due to several inherent limitations of unimodal biometrics , such as nonuniversality and unacceptable reliability. However, most existing multibiometrics fuse completely different biometric traits based on addition schemes, which usually require several sensors and make the final feature sets large. In this paper, we propose a joint multi-instance hand-based biometric feature learning method for biometric recognition. Specifically, we first exploit the important direction data from multi-instance biometric images. Then, we simultaneously learn the discriminative features of multi-instance biometric traits and exploit the collaborative representations of multi-instance biometric features such that the final joint multi-instance feature descriptor is compact. Moreover, the importance weights of different biometric instances can be adaptively learned. Experimental results on the baseline multi-instance finger-knuckle-print and palmprint databases demonstrate the promising effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Lunke Fei and Bob Zhang and Chunwei Tian and Shaohua Teng and Jie Wen},
  doi          = {10.1016/j.ins.2021.01.086},
  journal      = {Information Sciences},
  pages        = {1-12},
  shortjournal = {Inf. Sci.},
  title        = {Jointly learning multi-instance hand-based biometric descriptor},
  volume       = {562},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rough concepts. <em>ISCI</em>, <em>561</em>, 371–413. (<a
href="https://doi.org/10.1016/j.ins.2020.05.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper proposes a novel way to unify Rough Set Theory and Formal Concept Analysis. Our method stems from results and insights developed in the algebraic theory of modal logic, and is based on the idea that Pawlak’s original approximation spaces can be seen as special instances of enriched formal contexts, i.e. relational structures based on formal; contexts from Formal Concept Analysis.},
  archive      = {J_ISCI},
  author       = {Willem Conradie and Sabine Frittella and Krishna Manoorkar and Sajad Nazari and Alessandra Palmigiano and Apostolos Tzimoulis and Nachoem M. Wijnberg},
  doi          = {10.1016/j.ins.2020.05.074},
  journal      = {Information Sciences},
  pages        = {371-413},
  shortjournal = {Inf. Sci.},
  title        = {Rough concepts},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Optimization-based group decision making using
interval-valued intuitionistic fuzzy preference relations.
<em>ISCI</em>, <em>561</em>, 352–370. (<a
href="https://doi.org/10.1016/j.ins.2020.12.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an optimization-based group decision making (GDM) method using interval-valued intuitionistic fuzzy preference relations (IVIFPRs). First, the concept of consistency of intuitionistic fuzzy preference relations (IFPRs) is provided. Moreover, the consistency index for IFPRs is presented. Subsequently, by splitting an IVIFPR into two IFPRs, an additive consistency is proposed for IVIFPRs. Afterward, a consensus index is presented for GDM. When the consistency and the consensus do not achieve the requirement, we propose several models to reach the requirement. Furthermore, individual IVIFPRs are integrated into a collective IVIFPR. After that, a procedure is offered to obtain the interval-valued intuitionistic fuzzy (IVIF) priority weights of the alternatives. Moreover, a new GDM method with IVIFPRs is offered. Finally, some application examples are offered. The proposed GDM method can conquer the shortcomings of the existing GDM methods. It offers us a useful way for GDM in the IVIF context.},
  archive      = {J_ISCI},
  author       = {Zhiming Zhang and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2020.12.047},
  journal      = {Information Sciences},
  pages        = {352-370},
  shortjournal = {Inf. Sci.},
  title        = {Optimization-based group decision making using interval-valued intuitionistic fuzzy preference relations},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online multiple pedestrians tracking using deep temporal
appearance matching association. <em>ISCI</em>, <em>561</em>, 326–351.
(<a href="https://doi.org/10.1016/j.ins.2020.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In online multi-target tracking, modeling of appearance and geometric similarities between pedestrians visual scenes is of great importance. The higher dimension of inherent information in the appearance model compared to the geometric model is problematic in many ways. However, due to the recent success of deep-learning-based methods, handling of high-dimensional appearance information becomes feasible. Among many deep neural networks, Siamese network with triplet loss has been widely adopted as an effective appearance feature extractor. Since the Siamese network can extract the features of each input independently, one can update and maintain target-specific features. However, it is not suitable for multi-target settings that require comparison with other inputs. To address this issue, we propose a novel track appearance model based on the joint-inference network. The proposed method enables a comparison of two inputs to be used for adaptive appearance modeling and contributes to the disambiguation of target-observation matching and to the consolidation of identity consistency. Diverse experimental results support the effectiveness of our method. Our work was recognized as the 3rd-best tracker in BMTT MOTChallenge 2019 , held at CVPR2019. ( https://motchallenge.net/results/CVPR_2019_Tracking_Challenge/ ) The code is available at https://github.com/yyc9268/Deep-TAMA .},
  archive      = {J_ISCI},
  author       = {Young-Chul Yoon and Du Yong Kim and Young-Min Song and Kwangjin Yoon and Moongu Jeon},
  doi          = {10.1016/j.ins.2020.10.002},
  journal      = {Information Sciences},
  pages        = {326-351},
  shortjournal = {Inf. Sci.},
  title        = {Online multiple pedestrians tracking using deep temporal appearance matching association},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient surrogate-assisted hybrid optimization
algorithm for expensive optimization problems. <em>ISCI</em>,
<em>561</em>, 304–325. (<a
href="https://doi.org/10.1016/j.ins.2020.11.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms (SAEAs) are potential approaches to solve computationally expensive optimization problems . The critical idea of SAEAs is to combine the powerful searching capabilities of evolutionary algorithms with the predictive capabilities of surrogate models . In this study, an efficient surrogate-assisted hybrid optimization (SAHO) algorithm is proposed via combining two famous algorithms, namely, teaching–learning-based optimization (TLBO) and differential evolution (DE). The TLBO is focused on global exploration and the DE is concentrated on local exploitation. These two algorithms are carried out alternately when no better candidate solution can be found. Meanwhile, a new prescreening criterion based on the best and top collection information is introduced to choose promising candidates for real function evaluations. Besides, two evolution control (i.e., the generation-based and individual-based) strategies and a top-ranked restart strategy are integrated in the SAHO. Moreover, a local RBF surrogate which does not need too many training samples is employed to model the landscapes of the target function. Sixteen benchmark functions and the tension/compression spring design problem are adopted to compare the proposed SAHO with other state-of-the-art approaches. Extensive comparison results demonstrate that the proposed SAHO has superior performance for solving expensive optimization problems .},
  archive      = {J_ISCI},
  author       = {Jeng-Shyang Pan and Nengxian Liu and Shu-Chuan Chu and Taotao Lai},
  doi          = {10.1016/j.ins.2020.11.056},
  journal      = {Information Sciences},
  pages        = {304-325},
  shortjournal = {Inf. Sci.},
  title        = {An efficient surrogate-assisted hybrid optimization algorithm for expensive optimization problems},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Learning adaptive criteria weights for active
semi-supervised learning. <em>ISCI</em>, <em>561</em>, 286–303. (<a
href="https://doi.org/10.1016/j.ins.2021.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Batch mode active learning (BMAL) is devoted to training trustful learning models with scarce labeled samples by efficiently asking the ground truth annotations of the most beneficial unlabeled points for supervision with the feedback of an expert. Particularly, BMAL algorithms always sample points based on the decent-designed criteria, such as (un)certainty and representativeness , etc. However, present BMAL approaches consistently are afflicted with one limitation: They simply integrate the sampling criteria with fixed weights to select instances for supervised training, which may yield suboptimal batch acquisition since the criteria values of the plentiful candidate unlabeled samples would fluctuate after retraining the classifier with the newly augmented training set. Instead, the weights of sampling criteria should be allocated appropriately. To overcome this problem, this work proposes a novel A daptive C riteria W eights batch selection algorithm , abbreviated ACW, which dynamically adjusts the importance of (un)certainty and representativeness to choose critical instances for semi-supervised learning. A submodular function is employed to recognize a diverse mini-batch from the selected batch of samples. We apply our proposed ACW batch sampling algorithm to two types of essential semi-supervised tasks, i.e., semi-supervised classification and semi-supervised clustering. To the best of our knowledge, this work is the first devoted attempt to explore adaptive mechanism of criteria weights in the context of active learning. The superiority and effectiveness of ACW against the present state-of-the-art BMAL approaches have also been demonstrated by the encouraging experimental results.},
  archive      = {J_ISCI},
  author       = {Hao Li and Yongli Wang and Yanchao Li and Gang Xiao and Peng Hu and Ruxin Zhao and Bo Li},
  doi          = {10.1016/j.ins.2021.01.045},
  journal      = {Information Sciences},
  pages        = {286-303},
  shortjournal = {Inf. Sci.},
  title        = {Learning adaptive criteria weights for active semi-supervised learning},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TAGCN: Station-level demand prediction for bike-sharing
system via a temporal attention graph convolution network.
<em>ISCI</em>, <em>561</em>, 274–285. (<a
href="https://doi.org/10.1016/j.ins.2021.01.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, bike-sharing is available in many cities, solving the problem of the last mile, and it is an environmental-friendly way to commute. However, there is a tidal phenomenon in the bike-sharing system, and the rents/returns of bikes at different stations are unbalanced. Thus, bikes at different stations need to be rebalanced regularly and station-level demand prediction plays an essential role in bike-sharing rebalancing. In this paper, a novel deep graph convolutional network ( GCN ) model with temporal attention ( TAGCN ) is proposed for bike check-out/in number prediction of each station. TAGCN can not only model the spatial and temporal dependency between varying stations, but also reflect the influence of different time granularity , which are hour-level, day-level and week-level time periodicity. With the help of well-designed temporal attention mechanism , our model can capture the dynamical temporal correlations and comprehensive spatial patterns in bike check-out/in flow effectively. The proposed model consistently outperforms state-of-the-art methods on four real-world bike-sharing datasets that are four seasons data of Divvy Bike System in Chicago.},
  archive      = {J_ISCI},
  author       = {Wenjie Zi and Wei Xiong and Hao Chen and Luo Chen},
  doi          = {10.1016/j.ins.2021.01.065},
  journal      = {Information Sciences},
  pages        = {274-285},
  shortjournal = {Inf. Sci.},
  title        = {TAGCN: Station-level demand prediction for bike-sharing system via a temporal attention graph convolution network},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approach for a decision-making support system based on
measuring the user satisfaction level on twitter. <em>ISCI</em>,
<em>561</em>, 243–273. (<a
href="https://doi.org/10.1016/j.ins.2021.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks are a very popular channel for people to communicate with, to find, to reference other users before making decisions, especially those concerning purchase. How can users’ opinions within social networks be used in making decisions cost-effective and reliable? In this paper, we propose an approach for supporting decision-making based on measuring the user satisfaction level by analyzing the sentiment of aspects and mining the fuzzy decision trees. Our proposal has been proved to overcome some of the disadvantages of previous methods. Specifically, we consider the fuzzy sentiments of users for aspects and the effects of user satisfaction, dissatisfaction, and hesitation for decision-making. The proposed method comprises four main stages. The first stage identifies a topic, which the user is interested. In the second stage, aspects of the topic and their sentiments within tweets are extracted. At the third stage, the user satisfaction level is calculated according to each kind of sentiment identified in the second step. Finally, a decision matrix is constructed, and the fuzzy decision tree is built to generate a set of rules for supporting users in decision-making. The experiments using tweets show that the proposed method achieves promising results regarding the accuracy and gained information.},
  archive      = {J_ISCI},
  author       = {Huyen Trang Phan and Ngoc Thanh Nguyen and Van Cuong Tran and Dosam Hwang},
  doi          = {10.1016/j.ins.2021.01.008},
  journal      = {Information Sciences},
  pages        = {243-273},
  shortjournal = {Inf. Sci.},
  title        = {An approach for a decision-making support system based on measuring the user satisfaction level on twitter},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One enhanced secure access scheme for outsourced data.
<em>ISCI</em>, <em>561</em>, 230–242. (<a
href="https://doi.org/10.1016/j.ins.2020.10.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popularity of apps makes smart phones rapidly become the most widespread form of communication. Due to the impact of resource constraints in mobile phones, users prefer to outsource data from the local device to the cloud. Access control of outsourced data drives the researches for protecting sensitive data from all the possibly malicious software access or from cloud service provider misbehavior. The unexpected attacks from the local device or the cloud that are trying to breach the data access policy imposed by data owner has resulted in inadequate current access control solutions. Therefore, this paper proposes one access control scheme for Android devices to avoid authentication bypass attacks from both sides. Attribute-Based Encryption is used to design one app-level fine-grained data access for the purpose of data confidentiality in the local side. Moreover, Trusted Execution Environment is employed as a trusted computing environment which provides essential security services to protect encrypted data from unwanted access by cloud service providers or unauthorized apps from the local side. Finally, a prototype system is implemented and the performance is evaluated by the various operations used in the scheme. The experimental results show that the enhanced secure access model is flexible, efficient and secure for outsourcing data to the cloud.},
  archive      = {J_ISCI},
  author       = {Yongkai Fan and Jiaxu Liu and Kuan-Ching Li and Wei liang and Xia Lei and Gan Tan and Mingdong Tang},
  doi          = {10.1016/j.ins.2020.10.058},
  journal      = {Information Sciences},
  pages        = {230-242},
  shortjournal = {Inf. Sci.},
  title        = {One enhanced secure access scheme for outsourced data},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An investigation of testing capacity for evaluating and
modeling the spread of coronavirus disease. <em>ISCI</em>, <em>561</em>,
211–229. (<a href="https://doi.org/10.1016/j.ins.2021.01.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the consistent recommendation to scale-up the testing of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), comprehensive analysis on determining the desirable testing capacity ( TC ) is limited. This study aims to investigate the daily TC and the percentage of positive cases over the tested population ( PPCTP ) to evaluate the novel coronavirus disease 2019 (COVID-19) trajectory phase and generate benchmarks on desirable TC . Data were retrieved from government facilities, including 101 countries and 55 areas in the USA. We have divided the pandemic situations of investigated areas into four phases, i.e., low-level, suppressing, widespread, or uncertain transmission phase. Findings indicate each country should increase TC to roughly two tests per thousand people each day. Additionally, based on TC , a susceptible-unconfirmed-confirmed-recovered (SUCR) model, which can capture the dynamic growth of confirmed cases and estimate the group size of unconfirmed cases in a country or area, is proposed. We examined our proposed SUCR model for 55 areas in the USA. Results show that the SUCR model can accurately capture the dynamic growth of confirmed cases in each area. By increasing TC by five times and applying strict control measures, the total number of COVID-19 patients would reduce to 33\%.},
  archive      = {J_ISCI},
  author       = {Choujun Zhan and Jiaqi Chen and Haijun Zhang},
  doi          = {10.1016/j.ins.2021.01.084},
  journal      = {Information Sciences},
  pages        = {211-229},
  shortjournal = {Inf. Sci.},
  title        = {An investigation of testing capacity for evaluating and modeling the spread of coronavirus disease},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kronecker-decomposable robust probabilistic tensor
discriminant analysis. <em>ISCI</em>, <em>561</em>, 196–210. (<a
href="https://doi.org/10.1016/j.ins.2021.01.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a generative model , probabilistic linear discriminant analysis (PLDA) has achieved good performance in supervised learning tasks. The model incorporates both within-individual and between-individual variation, and remaining unexplained data variation is assumed to follow Gaussian distribution . However, the assumption of Gaussian distribution makes the model sensitive to the presence of noise and outliers in training set. To address this issue, this paper proposes a robust probabilistic linear discriminant analysis model by assuming Laplace prior on the noise term. Instead of solving high-dimensional linear systems, we embed a Kronecker-decomposable component in the new model for tensor data, significantly reducing the size of problems. As the non-conjugacy of Laplace distribution complicates the calculation of the posteriors of latent variables, we express it to a hierarchical architecture using an Inverse Gamma distribution and then adopt variational expectation–maximization (EM) algorithm to learn model parameters. The reconstruction and classification experiments on several public databases show the superiority of the proposed model compared with the state-of-the-art LDA-based algorithms.},
  archive      = {J_ISCI},
  author       = {Fujiao Ju and Yanfeng Sun and Junbin Gao and Yongli Hu and Baocai Yin},
  doi          = {10.1016/j.ins.2021.01.054},
  journal      = {Information Sciences},
  pages        = {196-210},
  shortjournal = {Inf. Sci.},
  title        = {Kronecker-decomposable robust probabilistic tensor discriminant analysis},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MSGP-LASSO: An improved multi-stage genetic programming
model for streamflow prediction. <em>ISCI</em>, <em>561</em>, 181–195.
(<a href="https://doi.org/10.1016/j.ins.2021.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the development and verification of a new multi-stage genetic programming (MSGP) technique, called MSGP-LASSO, which was applied for univariate streamflow forecasting in the Sedre River, an intermittent river in Turkey. The MSGP-LASSO is a practical and cost-neutral improvement over classic genetic programming (GP) that increases modelling accuracy, while decreasing its complexity by coupling the MSGP and multiple regression LASSO methods. The new model uses average mutual information to identify the optimum lags, and root mean-square technique to minimize forecasting error. Based on Nash-Sutcliffe efficiency and bias-corrected Akaike information criterion , MSGP-LASSO is superior to GP, multigene GP, MSGP, and hybrid MSGP-least-square models. It is explicit and promising for real-life applications.},
  archive      = {J_ISCI},
  author       = {Ali Danandeh Mehr and Amir H. Gandomi},
  doi          = {10.1016/j.ins.2021.02.011},
  journal      = {Information Sciences},
  pages        = {181-195},
  shortjournal = {Inf. Sci.},
  title        = {MSGP-LASSO: An improved multi-stage genetic programming model for streamflow prediction},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic event-triggered l∞ control for networked control
systems under deception attacks: A switching method. <em>ISCI</em>,
<em>561</em>, 168–180. (<a
href="https://doi.org/10.1016/j.ins.2021.01.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the event-triggered scheme (ETS), the L ∞ L∞ control problem is considered for networked control systems subject to stochastic deception attacks. A novel dynamic switching ETS is proposed to reduce the number of transmitted signals. A stochastic model is used for deception attacks, where the system states are corrupted by attackers. Under this framework, the system to be investigated is modeled as a new switched system . By using the constructed Lyapunov function , sufficient criteria are derived to guarantee the exponential mean-square stability and L ∞ L∞ performance. Subsequently, the corresponding controller is designed. Finally, the effectiveness of the dynamic ETS is illustrated by using an unmanned aerial vehicle system.},
  archive      = {J_ISCI},
  author       = {Zhiying Wu and Junlin Xiong and Min Xie},
  doi          = {10.1016/j.ins.2021.01.076},
  journal      = {Information Sciences},
  pages        = {168-180},
  shortjournal = {Inf. Sci.},
  title        = {Dynamic event-triggered l∞ control for networked control systems under deception attacks: A switching method},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disturbance-observer-based finite-time adaptive fuzzy
control for non-triangular switched nonlinear systems with input
saturation. <em>ISCI</em>, <em>561</em>, 152–167. (<a
href="https://doi.org/10.1016/j.ins.2021.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates finite-time adaptive fuzzy control for a class of non-triangular switched nonlinear systems with asymmetric input saturation and mismatched external disturbances . Firstly, the mismatched external disturbances and fuzzy approximation errors are regarded as total disturbances of the system, which are estimated accurately via the finite-time exact disturbance observer. Secondly, the prescribed performance function is adopted to constrain the system output to meet the prescribed dynamic properties. To cope with the obstacle arising from asymmetric input saturation, a smooth nonlinear function is applied to approximate the actuator nonlinearity by utilizing the mean-value theorem. Thirdly, on the basis of the fast practical finite-time stability criteria, a finite-time adaptive fuzzy control where the adaptive parameter laws contain fractional-order item is developed. Meanwhile, the stability analysis verifies that all the signals in closed-loop system are bounded and error signals can converge to the prescribed small compact sets in finite time. Finally, a simulation example is included to further demonstrate the effectiveness of the proposed control strategies.},
  archive      = {J_ISCI},
  author       = {Weihai Zhang and Wei Wei},
  doi          = {10.1016/j.ins.2021.01.026},
  journal      = {Information Sciences},
  pages        = {152-167},
  shortjournal = {Inf. Sci.},
  title        = {Disturbance-observer-based finite-time adaptive fuzzy control for non-triangular switched nonlinear systems with input saturation},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Entropy measure for orderable sets. <em>ISCI</em>,
<em>561</em>, 141–151. (<a
href="https://doi.org/10.1016/j.ins.2021.01.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to measure the uncertainty of orderable sets is still an open issue. In this paper, a new method based on Deng entropy to measure the uncertainty of orderable sets is proposed. When orderable sets degenerate as unorderable sets, the new entropy would degenerate as Deng entropy. When orderable sets degenerate into singleton , the new entropy would degenerate into Shannon entropy . Some numerical examples are used to illustrate the efficiency and accuracy of the proposed method.},
  archive      = {J_ISCI},
  author       = {Hui Zhang and Yong Deng},
  doi          = {10.1016/j.ins.2021.01.073},
  journal      = {Information Sciences},
  pages        = {141-151},
  shortjournal = {Inf. Sci.},
  title        = {Entropy measure for orderable sets},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). An efficient identity tracing scheme for blockchain-based
systems. <em>ISCI</em>, <em>561</em>, 130–140. (<a
href="https://doi.org/10.1016/j.ins.2021.01.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The enhancement of anonymity for blockchain users received much attention. However, in some cases tracing user’s identity is also very important, especially to expose illegal transactions. In this paper, we propose an identity tracing scheme and implement it using a simple and efficient proof method. In particular, we design a new signature scheme that is used to generate a user’s certificate, and present a binding method for the user’s certificate and trading public key . Users only need to register once with the supervision center, and then the center may trace sender’s identity of the transactions on the blockchain . Our scheme is suitable to blockchain-based systems that explicitly use public/private key pairs, and does not affect the anonymity property of the original system.},
  archive      = {J_ISCI},
  author       = {Peili Li and Haixia Xu and Tianjun Ma},
  doi          = {10.1016/j.ins.2021.01.081},
  journal      = {Information Sciences},
  pages        = {130-140},
  shortjournal = {Inf. Sci.},
  title        = {An efficient identity tracing scheme for blockchain-based systems},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Document-level event causality identification via graph
inference mechanism. <em>ISCI</em>, <em>561</em>, 115–129. (<a
href="https://doi.org/10.1016/j.ins.2021.01.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event causality identification is an important research task in natural language processing . Existing methods largely focus on identifying explicit causal relations , and give poor performance in implicit causalities, especially in the document level. In this paper, we formalize event causality identification as a graph-based edge prediction problem and propose a novel document-level context-based graph inference mechanism. Specifically, we use attention-based neural networks to automatically extract document-level contextual information, and a direction-sensitive graph inference mechanism to achieve information transfer and interaction among event causalities. Experimental results on the EventStoryLine v1.5 dataset show that our approach outperforms previous methods and baseline systems by a large margin in F1-score metrics (2.45\% improvement on intra-sentence causalities and 3.08\% improvement on cross-sentence causalities). Further analysis demonstrates that our model can effectively capture the document-level contextual information and latent causal information among events.},
  archive      = {J_ISCI},
  author       = {Kun Zhao and Donghong Ji and Fazhi He and Yijiang Liu and Yafeng Ren},
  doi          = {10.1016/j.ins.2021.01.078},
  journal      = {Information Sciences},
  pages        = {115-129},
  shortjournal = {Inf. Sci.},
  title        = {Document-level event causality identification via graph inference mechanism},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comprehensive study on complex-valued ZNN models activated
by novel nonlinear functions for dynamic complex linear equations.
<em>ISCI</em>, <em>561</em>, 101–114. (<a
href="https://doi.org/10.1016/j.ins.2020.12.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes two complex-valued zeroing neural network (Cv-ZNN) models for solving dynamic complex time-variant linear equations . The models involve two complex-valued nonlinear processing methods and adapt two real-valued activation functions . The convergence and robustness of the two Cv-ZNN models are analyzed comprehensively. Firstly, the convergence discussion shows that the corresponding stable error can rapidly converge to zero in finite time, with the upper limit of constriction time calculated. The upper limit of stable error is successfully obtained when the model implementation error is injected into the Cv-ZNN models, which displays their superior robustness. Besides, the results of numerical simulations reveal that the Cv-ZNN models effectively address the time-variant linear system of equations over complex field, even in noisy environments . The simulation results also demonstrate that two novel nonlinear activation functions perform much better than the Linear, Power, Bipolar Sigmoid Power-Sigmoid and Sign-bi-power activation functions.},
  archive      = {J_ISCI},
  author       = {Jianhua Dai and Yiwei Li and Lin Xiao and Lei Jia and Qing Liao and Jichun Li},
  doi          = {10.1016/j.ins.2020.12.078},
  journal      = {Information Sciences},
  pages        = {101-114},
  shortjournal = {Inf. Sci.},
  title        = {Comprehensive study on complex-valued ZNN models activated by novel nonlinear functions for dynamic complex linear equations},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EOCD: An ensemble optimization approach for concept drift
applications. <em>ISCI</em>, <em>561</em>, 81–100. (<a
href="https://doi.org/10.1016/j.ins.2021.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data streams applications generate a continuous stream of data in a high rate that it is not possible to store all data in available memory. Hence, it is important to apply techniques that are capable of learning concepts according to data presentation, taking into consideration available time, processing and memory resources. This paper presents a new ensemble-based approach to detect concept drift in the data stream context. This approach uses an explicit mechanism to adapt to concept drifts using a genetic algorithm in order to define the best ensemble configuration for the current scenario (detected drifts). The main aim of this approach is to provide an efficient structure to detect and to adapt to concept drifts and, as a consequence, to improve the performance of this system. Our findings show that the proposed method delivers outstanding results, outperforming the results delivered by the most efficient methods presented in the literature.},
  archive      = {J_ISCI},
  author       = {Antonino Feitosa Neto and Anne M.P. Canuto},
  doi          = {10.1016/j.ins.2021.01.051},
  journal      = {Information Sciences},
  pages        = {81-100},
  shortjournal = {Inf. Sci.},
  title        = {EOCD: An ensemble optimization approach for concept drift applications},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-based mobile edge computing system.
<em>ISCI</em>, <em>561</em>, 70–80. (<a
href="https://doi.org/10.1016/j.ins.2021.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the Internet of Things (IoT), the number of mobile terminal devices is increasing rapidly. Due to high transmission delay and bandwidth limitation, computing power requirements for IoT devices are getting higher and higher. Recently, edge computing is an effective way to reduce system delay, and blockchain solves the security problem of edge computing . In this paper, a three-layer network model, named blockchain-based mobile edge computing system (BMEC), is proposed for clone block identification. Specifically, a neural network based clone block identification (NCBI) method is proposed to prevent clone block attacks. After that, the Prim algorithm is applied to BMEC to generate a weighted undirected graph minimum spanning tree that is composed of edge blocks. This can divide a main chain into several side chains to improve the transaction speed of blockchain . Finally, the blockchain is constructed based on the time slicing round-robin scheduling algorithm to control resources from edge servers and regulate edge devices’ activities based on the predefined rules of priority, application type, and past behavior. Experimental results show that our clone block identification method can achieve block validation effectively in BMEC, and our construction of blockchain delay is lower than conventional edge computing methods.},
  archive      = {J_ISCI},
  author       = {Guangshun Li and Xinrong Ren and Junhua Wu and Wanting Ji and Haili Yu and Jiabin Cao and Ruili Wang},
  doi          = {10.1016/j.ins.2021.01.050},
  journal      = {Information Sciences},
  pages        = {70-80},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based mobile edge computing system},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OPLS-SR: A novel face super-resolution learning method using
orthonormalized coherent features. <em>ISCI</em>, <em>561</em>, 52–69.
(<a href="https://doi.org/10.1016/j.ins.2021.01.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face super-resolution (FSR) is an effective way to deal with low-resolution (LR) face images, which can infer the latent high-resolution (HR) face images from the LR inputs. In contrast with traditional FSR methods such as interpolation, learning-based methods generate more realistic HR images of LR faces by exploiting the relationship between HR and LR images . In this paper, we propose a novel FSR learning approach based on orthonormalized partial least squares referred to as OPLS-SR. It first learns a latent coherent feature space of low-dimensional HR and LR face embeddings via a recursive optimization, and then super-resolves the LR face images through global face reconstruction and facial detail compensation. Experimental results on the CAS-PEAL-R1 and FERET face databases have demonstrated the effectiveness of the proposed OPLS-SR method in terms of quantitative and qualitative evaluations.},
  archive      = {J_ISCI},
  author       = {Yun-Hao Yuan and Jin Li and Yun Li and Jipeng Qiang and Bin Li and Wankou Yang and Furong Peng},
  doi          = {10.1016/j.ins.2021.01.082},
  journal      = {Information Sciences},
  pages        = {52-69},
  shortjournal = {Inf. Sci.},
  title        = {OPLS-SR: A novel face super-resolution learning method using orthonormalized coherent features},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disjunctive attribute dependencies in formal concept
analysis under the epistemic view of formal contexts. <em>ISCI</em>,
<em>561</em>, 31–51. (<a
href="https://doi.org/10.1016/j.ins.2020.12.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an epistemic interpretation of formal contexts, interpreting blank entries in the context matrix as absence of information, which is in agreement with the usual focus on the extraction of implications between attributes. After recalling non-classical connections induced by rough sets and possibility theory in formal concept analysis (FCA), and the standard theory of attribute implications in FCA, this paper presents the notion of disjunctive attribute implications, which reflect additional information that can be extracted from an epistemic context. We show that they can be computed like standard attribute implications from the complementary context. The paper also recalls the logic of classical attribute implications, relying on works pertaining to functional dependencies in database theory, and proposes a dual logic for disjunctive attribute implications. A method for extracting the latter kind of rules from a formal context is proposed, using a counterpart of pseudo-intents. Lastly, the paper outlines a generalization of both conjunctive and disjunctive attribute implications under the form of rules, with a conjunction of conditions in the body and a disjunction of conditions in the head, that hold in a formal context under the epistemic view.},
  archive      = {J_ISCI},
  author       = {D. Dubois and J. Medina and H. Prade and E. Ramírez-Poussa},
  doi          = {10.1016/j.ins.2020.12.085},
  journal      = {Information Sciences},
  pages        = {31-51},
  shortjournal = {Inf. Sci.},
  title        = {Disjunctive attribute dependencies in formal concept analysis under the epistemic view of formal contexts},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Index selection for NoSQL database with deep reinforcement
learning. <em>ISCI</em>, <em>561</em>, 20–30. (<a
href="https://doi.org/10.1016/j.ins.2021.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of big data technology , the data management of complex applications has become more and more resource intensive. In this paper, we propose an automatic approach (DRLISA) to achieve NoSQL database index selection. For different workloads, we automatically select its corresponding indexes and parameters which can totally improve the database performance . Our DRLISA establishes an optimal index by building a deep reinforcement learning model which is able to adapt the dynamic change of workloads. We conducted our experiments in five aspects (the impact of data manipulation, the impact of operation count, comparison with random selection, comparison with existing method and the robustness of DRLISA) using the open source benchmark, YCSB. The experimental results showed that DRLISA has a high efficient index recommendation under the dynamic workloads .},
  archive      = {J_ISCI},
  author       = {Yu Yan and Shun Yao and Hongzhi Wang and Meng Gao},
  doi          = {10.1016/j.ins.2021.01.003},
  journal      = {Information Sciences},
  pages        = {20-30},
  shortjournal = {Inf. Sci.},
  title        = {Index selection for NoSQL database with deep reinforcement learning},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Local interpretation of supervised learning models based on
high dimensional model representation. <em>ISCI</em>, <em>561</em>,
1–19. (<a href="https://doi.org/10.1016/j.ins.2021.01.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning models have been widely used to obtain prediction in various domains; however, most of such models are black boxes owing to the high complexity. The lack of transparency of machine learning models hampers their applications because the practitioners do not understand the internal mechanism of these models. This study proposes a model-agnostic method, based on the high dimensional model representation (HDMR), to interpret supervised learning models by determining the local feature contribution. Compared to the existing methods, which only assign a single value to the feature contribution and do not consider the feature dependence, the HDMR-based feature contribution can be decomposed into individual and combined contribution, and it can take feature dependence into account. Certain agnostic and specific methods to measure the HDMR-based feature contributions are developed and categorized as pertaining to either feature independence or dependence. Experiments are performed to demonstrate the effects of the HDMR-based feature contributions, and compare the performance of several estimation methods.},
  archive      = {J_ISCI},
  author       = {Xiaohang Zhang and Ling Wu and Zhengren Li},
  doi          = {10.1016/j.ins.2021.01.079},
  journal      = {Information Sciences},
  pages        = {1-19},
  shortjournal = {Inf. Sci.},
  title        = {Local interpretation of supervised learning models based on high dimensional model representation},
  volume       = {561},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Methodically unified procedures for a conditional approach
to outlier detection, clustering, and classification. <em>ISCI</em>,
<em>560</em>, 504–527. (<a
href="https://doi.org/10.1016/j.ins.2020.08.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The subject of this study is three fundamental procedures of contemporary data analysis: outlier detection , clustering and classification. These issues are considered in a conditional approach – the introduction of specific (e.g., current) values to the model allows, in practice, a significantly precise description of the reality under research. The same methodology has been used for all three of the above tasks, and it considerably facilitates the interpretations, potential modifications and practical applications of the material investigated. Using non-parametric methods frees the procedures under investigation from a distribution in the considered dataset. This paper contains a complete set of formulas that allow easy implementation of the presented material in real-world problems.},
  archive      = {J_ISCI},
  author       = {Piotr Kulczycki and Krystian Franus},
  doi          = {10.1016/j.ins.2020.08.122},
  journal      = {Information Sciences},
  pages        = {504-527},
  shortjournal = {Inf. Sci.},
  title        = {Methodically unified procedures for a conditional approach to outlier detection, clustering, and classification},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MHAT: An efficient model-heterogenous aggregation training
scheme for federated learning. <em>ISCI</em>, <em>560</em>, 493–503. (<a
href="https://doi.org/10.1016/j.ins.2021.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning allows multiple participants to jointly train a global model while guaranteeing the confidentiality and integrity of private datasets. However, current server aggregation algorithms for federated learning only focus on model parameters, resulting in heavy communication costs and low convergence speed. Most importantly, they are unable to handle the scenario wherein different clients hold different local models with various network architectures. In this paper, we view these challenges from an alternative perspective: we draw attention to what should be aggregated and how to improve convergence efficiency. Specifically, we propose MHAT, a novel model-heterogenous aggregation training federated learning scheme which exploits a technique of Knowledge Distillation (KD) to extract the update information of the heterogenous model of all clients and trains an auxiliary model on the server to realize information aggregation. MHAT relaxes clients from fixing on an unified model architecture and significantly reduces the required computing resources while maintaining acceptable model convergence accuracy. Various experiments verify the effectiveness and applicability of our proposed scheme.},
  archive      = {J_ISCI},
  author       = {Li Hu and Hongyang Yan and Lang Li and Zijie Pan and Xiaozhang Liu and Zulong Zhang},
  doi          = {10.1016/j.ins.2021.01.046},
  journal      = {Information Sciences},
  pages        = {493-503},
  shortjournal = {Inf. Sci.},
  title        = {MHAT: An efficient model-heterogenous aggregation training scheme for federated learning},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic topography of high-dimensional data sets by
non-parametric density peak clustering. <em>ISCI</em>, <em>560</em>,
476–492. (<a href="https://doi.org/10.1016/j.ins.2021.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data analysis in high-dimensional spaces aims at obtaining a synthetic description of a data set, revealing its main structure and its salient features. We here introduce an approach providing this description in the form of a topography of the data, namely a human-readable chart of the probability density from which the data are harvested. The approach is based on an unsupervised extension of Density Peak clustering and on a non-parametric density estimator that measures the probability density in the manifold containing the data. This allows finding automatically the number and the height of the peaks of the probability density, and the depth of the “valleys” separating them. Importantly, the density estimator provides a measure of the error, which allows distinguishing genuine density peaks from density fluctuations due to finite sampling. The approach thus provides robust and visual information about the density peaks height, their statistical reliability and their hierarchical organization, offering a conceptually powerful extension of the standard clustering partitions. We show that this framework is particularly useful in the analysis of complex data sets.},
  archive      = {J_ISCI},
  author       = {Maria d’Errico and Elena Facco and Alessandro Laio and Alex Rodriguez},
  doi          = {10.1016/j.ins.2021.01.010},
  journal      = {Information Sciences},
  pages        = {476-492},
  shortjournal = {Inf. Sci.},
  title        = {Automatic topography of high-dimensional data sets by non-parametric density peak clustering},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delay-dependent consensus criteria for fractional-order
takagi-sugeno fuzzy multi-agent systems with time delay. <em>ISCI</em>,
<em>560</em>, 456–475. (<a
href="https://doi.org/10.1016/j.ins.2021.01.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the consensus of fractional-order Takagi-Sugeno fuzzy multi-agent systems with time delay is studied. First, the fractional-order Barbaˇlat lemma is proposed to explore fractional-order systems by using the integer-order Lyapunov method . In addition, the adaptive controllers with and without an input time delay are designed to ensure consensus of fractional-order Takagi-Sugeno fuzzy multi-agent systems with time delay. Next, a class of new Lyapunov-Krasovskii functions is constructed that utilize time delay information, unlike the previous functions. Then, based on the designed adaptive controls and the constructed Lyapunov-Krasovskii functions, some consensus criteria are proposed to guarantee consensus of fractional-order Takagi-Sugeno fuzzy multi-agent systems with time delay. Finally, three examples are given to verify the correctness and effectiveness of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Yali Cheng and Taotao Hu and Yonghong Li and Xiaojun Zhang and Shouming Zhong},
  doi          = {10.1016/j.ins.2021.01.074},
  journal      = {Information Sciences},
  pages        = {456-475},
  shortjournal = {Inf. Sci.},
  title        = {Delay-dependent consensus criteria for fractional-order takagi-sugeno fuzzy multi-agent systems with time delay},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling of photo-responsive liquid crystal elastomer
actuators. <em>ISCI</em>, <em>560</em>, 441–455. (<a
href="https://doi.org/10.1016/j.ins.2021.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liquid crystal elastomers (LCEs) offer promising prospect in applications such as soft robot actuators due to the fact that they can be chemically doped to have photo-responsive deformation characteristics . With the purpose of accurate control of LCE actuators in soft robot applications, the establishment of a model which quantitatively describes the deformation characteristics of LCE becomes essential. However, current models for LCE are very preliminary, which restricts the implementation of LCE actuators. This paper develops a model to describe the deformation of LCE actuators. First, the deformation process is discussed, which is in nature the macroscopic shape change corresponding to the phase change of LCE. Then, the relationship between the deformation and the temperature of LCE is established according to thermodynamic analysis on the free energy, and the phase transition process. Unknown parameters are determined through parameter identification with experimental data based on the non-linear least-squares method. This model has the advantage that it quantitatively describes the deformation characteristics of LCE without the aid of numerical simulation, and it reflects the physical nature of the deformation of LCE. This model lays a basis for the accurate control of the LCE actuators, which leads to future photo-responsive soft robot applications.},
  archive      = {J_ISCI},
  author       = {Jundong Wu and Wenjun Ye and Yawu Wang and Chun-Yi Su},
  doi          = {10.1016/j.ins.2021.01.009},
  journal      = {Information Sciences},
  pages        = {441-455},
  shortjournal = {Inf. Sci.},
  title        = {Modeling of photo-responsive liquid crystal elastomer actuators},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction of information cascades via content and structure
proximity preserved graph level embedding. <em>ISCI</em>, <em>560</em>,
424–440. (<a href="https://doi.org/10.1016/j.ins.2020.12.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding the mechanisms how one message acquires more popularity than another and modeling how it gains popularity dynamically are of tremendous interest to related AI-based decision support systems. The information cascade prediction begins benefiting from the development of deep learning on graphs. However, recent studies are generally learning the representation of nodes in the graph, which may be not suitable as cascades contain all nodes in the dissemination path as a whole. Thus, we investigate whether the whole graph of cascade could be directly embedded in low dimension and how it would be effective for predicting the future popularity. Rather than learning the representation of all nodes in the cascade, we design a framework to learn the low dimension representation of each cascade graph by constructing the content and structure proximity-based high-order graph where each node refers to each cascade. By random walk and a semi-supervised language model , the embedding of the whole cascade graph can be obtained. Our results show that the proposed method can reduce the prediction error by at least 10.29\%, 22.89\% and 20.01\% (measured by RMSPE) respectively on three real datasets over baselines. Moreover, the running time of the model training is much less than baselines.},
  archive      = {J_ISCI},
  author       = {Xiaodong Feng and Qihang Zhao and Zhen Liu},
  doi          = {10.1016/j.ins.2020.12.074},
  journal      = {Information Sciences},
  pages        = {424-440},
  shortjournal = {Inf. Sci.},
  title        = {Prediction of information cascades via content and structure proximity preserved graph level embedding},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view subspace clustering via partition fusion.
<em>ISCI</em>, <em>560</em>, 410–423. (<a
href="https://doi.org/10.1016/j.ins.2021.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering is an important approach for analyzing multi-view data in an unsupervised way. Among various methods, the multi-view subspace clustering approach has gained increasing attention due to its encouraging performance. Essentially, it integrates multi-view information into graphs, which are then fed into spectral clustering algorithm for final results. However, its performance may degrade due to noises existing in each individual view or inconsistencies between heterogeneous features. Orthogonal to current work, we propose to fuse multi-view information in a partition space, which enhances the robustness of Multi-view clustering. Specifically, we generate multiple partitions and integrate them to find a shared partition. The proposed model unifies graph learning, generation of basic partitions, and view weight learning. These three components co-evolve towards better quality outputs. We have conducted comprehensive experiments on benchmark datasets and our empirical results verify the effectiveness and robustness of our approach.},
  archive      = {J_ISCI},
  author       = {Juncheng Lv and Zhao Kang and Boyu Wang and Luping Ji and Zenglin Xu},
  doi          = {10.1016/j.ins.2021.01.033},
  journal      = {Information Sciences},
  pages        = {410-423},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view subspace clustering via partition fusion},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cluster-based intelligence ensemble learning method for
classification problems. <em>ISCI</em>, <em>560</em>, 386–409. (<a
href="https://doi.org/10.1016/j.ins.2021.01.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification is a vital task in machine learning. By learning patterns of samples of known categories, the model can develop the ability to distinguish the categories of samples of unknown categories. Noticing the advantages of the clustering method in cluster structure analysis, we combine the clustering and classification methods to develop the novel cluster-based intelligence ensemble learning (CIEL) method. We use the clustering method to analyze the inherent distribution of the data and divide all the samples into clusters according to the characteristics of the dataset. Then, for each specific cluster, we use different classification algorithms to establish the corresponding classification model. Finally, we integrate the prediction results of each base classifier to form the final prediction result. In view of the problem of parameter sensitivity, we use a swarm intelligence algorithm to optimize the key parameters involved in the clustering, classification, and ensemble stages in order to boost the classification performance. To assess the effectiveness of CIEL , we perform tenfold cross-validation experiments on the 24 benchmark datasets provided by UCI and KEEL. Designed to improve the performance of the classifiers, CIEL outperforms other popular machine learning methods such as naive Bayes, k -nearest neighbors, random forest, and support vector machine.},
  archive      = {J_ISCI},
  author       = {Shaoze Cui and Yanzhang Wang and Yunqiang Yin and T.C.E. Cheng and Dujuan Wang and Mingyu Zhai},
  doi          = {10.1016/j.ins.2021.01.061},
  journal      = {Information Sciences},
  pages        = {386-409},
  shortjournal = {Inf. Sci.},
  title        = {A cluster-based intelligence ensemble learning method for classification problems},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast inference in convolutional neural networks based on
sequential three-way decisions. <em>ISCI</em>, <em>560</em>, 370–385.
(<a href="https://doi.org/10.1016/j.ins.2021.01.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel image recognition algorithm based on sequential three-way decisions is introduced to speed up the inference in a convolutional neural network . In contrast to the majority of existing studies, our approach does not require a special procedure to train a neural network , and thus it can be used with arbitrary architectures including pre-trained convolutional nets. Each image is associated with a sequence of features extracted at different layers of the neural network . Features from earlier layers stand for coarse-grained image representation. Fine-grained representations include embeddings from one of later layers. Confidence scores of classifiers representing the input image at each granularity level are computed in order to populate a set of unlikely classes with low confidence scores. The thresholds for these scores are chosen by using the step-up multiple testing procedure. The categories from this set are not considered at the next levels with finer granularity . The algorithm selecting the granularity levels and thresholds for each level is trained on a small sample. An experimental study for several datasets and neural architectures demonstrated that the proposed approach reduces the running time by up to 40\% with a controllable decrease in accuracy.},
  archive      = {J_ISCI},
  author       = {A.V. Savchenko},
  doi          = {10.1016/j.ins.2021.01.068},
  journal      = {Information Sciences},
  pages        = {370-385},
  shortjournal = {Inf. Sci.},
  title        = {Fast inference in convolutional neural networks based on sequential three-way decisions},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correlated tuple data release via differential privacy.
<em>ISCI</em>, <em>560</em>, 347–369. (<a
href="https://doi.org/10.1016/j.ins.2021.01.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy preserving methods supporting for tuple data release have attracted the attention of researchers in multidisciplinary fields. Among the advanced methods, differential privacy (DP), introducing independent Laplace noise, has become an influential privacy mechanism owing to its provable and rigorous privacy guarantee. Nonetheless, in practice, tuple data to be protected are always correlated while independent noise may cause undesirable information disclosure than expected. Recent researches attempt to optimize the sensitivity function of DP with consideration of the correlation strength between data – but have a drawback in a substantial growth of noise level. Therefore, for correlated tuple data release, how to decrease the noise level incurred by correlation strength is yet to be explored. To remedy this problem, this paper exploits the degradation of DP in expected privacy levels for correlated tuple data and proposes a solution to mitigate it. We first demonstrate a filtering attack, presenting a possibility of using the different dependence between original outputs and perturbations to sanitize a certain level of noise to extract individual’s sensitive information . Secondly, we introduce the notion of correlated tuple differential privacy (CTDP) to preserve expected privacy for correlated tuple data and further propose a generalized Laplace mechanism (GLM) to achieve privacy guarantees in CTDP. Then we design a practical iteration mechanism, including an update function, to conduct GLM when facing large scale queries. Finally, experimental evaluation on real-world datasets over multiple fields show that our solution consistently outperforms state-of-the-art mechanisms in data utility while providing the same privacy guarantee as other approaches for correlated tuple data.},
  archive      = {J_ISCI},
  author       = {Hao Wang and Huan Wang},
  doi          = {10.1016/j.ins.2021.01.058},
  journal      = {Information Sciences},
  pages        = {347-369},
  shortjournal = {Inf. Sci.},
  title        = {Correlated tuple data release via differential privacy},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OSN: Onion-ring support neighbors for correspondence
selection. <em>ISCI</em>, <em>560</em>, 331–346. (<a
href="https://doi.org/10.1016/j.ins.2021.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correspondence Selection (CS) identifies the reliable correspondences from the putative ones. It provides fundamental cues for many computer vision tasks, therefore the performance and efficiency of CS are pivotal. Previous methods are either accurate but time-consuming process or efficient but ambiguous. It is difficult to strike a good balance between performance and efficiency. In this paper, we propose the Onion-ring Support Neighbors (OSN) method for CS. OSN can fully exhaust the coherency information of neighbors to identify all reliable correspondences but it only requires the O ( n ) O(n) time and space complexity. To our best knowledge, we are the first to prove that the performance of CS can be improved by considering information from more neighbors. To this end, onion-ring shaped support neighbors are introduced, whereby the directional relationships can be eliminated from the central region to neighbor regions, and rotation invariance in putative correspondences can be retained. To efficiently identify the reliable correspondences, we present the Fixed Correspondence algorithm. This algorithm can reduce the search space of putative correspondences within constant time, which contributes to a O ( n ) O(n) time complexity of the overall OSN process. Extensive experiments over widely used datasets show that OSN achieves state-of-the-art performance in F 1 F1 -measure and Pose estimation.},
  archive      = {J_ISCI},
  author       = {Cheng Gong and Ye Lu and Chunying Song and Tao Li and Kai Wang},
  doi          = {10.1016/j.ins.2021.01.042},
  journal      = {Information Sciences},
  pages        = {331-346},
  shortjournal = {Inf. Sci.},
  title        = {OSN: Onion-ring support neighbors for correspondence selection},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A decision variable classification-based cooperative
coevolutionary algorithm for dynamic multiobjective optimization.
<em>ISCI</em>, <em>560</em>, 307–330. (<a
href="https://doi.org/10.1016/j.ins.2021.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new decision variable classification-based cooperative coevolutionary algorithm , which uses the information of decision variable classification to guide the search process, for handling dynamic multiobjective problems . In particular, the decision variables are divided into two groups: convergence variables (CS) and diversity variables (DS), and different strategies are introduced to optimize these groups. Two kinds of subpopulations are used in the proposed algorithm, i.e., the subpopulations that represent DS and the subpopulations that represent CS. In the evolution process, the coevolution of DS and CS is carried out through genetic operators, and subpopulations of CS are gradually merged into DS, which is optimized in the global search space, based on an indicator to avoid becoming trapped in local optimum. Once a change is detected, a prediction method and a diversity introduction approach are adopted for these two kinds of variables to get a promising population with good diversity and convergence in the new environment. The proposed algorithm is tested on 16 benchmark dynamic multiobjective optimization problems , in comparison with state-of-the-art algorithms. Experimental results show that the proposed algorithm is very competitive for dynamic multiobjective optimization .},
  archive      = {J_ISCI},
  author       = {Huipeng Xie and Juan Zou and Shengxiang Yang and Jinhua Zheng and Junwei Ou and Yaru Hu},
  doi          = {10.1016/j.ins.2021.01.021},
  journal      = {Information Sciences},
  pages        = {307-330},
  shortjournal = {Inf. Sci.},
  title        = {A decision variable classification-based cooperative coevolutionary algorithm for dynamic multiobjective optimization},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opinion subset selection via submodular maximization.
<em>ISCI</em>, <em>560</em>, 283–306. (<a
href="https://doi.org/10.1016/j.ins.2020.12.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current research on subset selection for opinion analysis assumes that their methods can retrieve the opinions expressed in documents from general text features. However, such relaxed conditions can hardly maintain the performance of the analysis in opinion mining , especially when given strict limitations on the subset size . In this paper, we propose a framework for opinion subset selection . This framework can select a small set of instances from original data to convey a subjective representation for opinion classification and regression. Compared with our framework, the conventional submodular based subset selection approach cannot capture the fine-grained opinion features expressed in the corpus. Specifically, we propose a monotone non-decreasing score function and a framework based on topic modeling and submodular maximization for filtering irrelevant information and selecting the subsets. Our work further introduces an opinion-sensitive algorithm for optimizing the proposed function for opinion subset construction . We perform extensive experiments and comparative analysis of different subset selection methods in this work. The experimental result shows that the proposed opinion subset selection framework can compress the original text training set and preserve the test set’s classification and regression metric performance at the same time.},
  archive      = {J_ISCI},
  author       = {Yang Zhao and Tommy W.S. Chow},
  doi          = {10.1016/j.ins.2020.12.083},
  journal      = {Information Sciences},
  pages        = {283-306},
  shortjournal = {Inf. Sci.},
  title        = {Opinion subset selection via submodular maximization},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Operators invariant under finitely many input changes with
applications to aggregation of sequences. <em>ISCI</em>, <em>560</em>,
271–282. (<a href="https://doi.org/10.1016/j.ins.2021.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the framework of finitely additive measures defined on the power set of an infinite set X X , we consider related operators defined on bounded functions on X X invariant under finitely many changes of input values. Specifically, we reconsider these operators with an extended use of the concept of filter, which provides novel insights into the problem. Then, we apply the obtained results to the study of the aggregation of infinite sequences.},
  archive      = {J_ISCI},
  author       = {F. Durante and J. Fernández Sánchez and C. Ignazzi},
  doi          = {10.1016/j.ins.2021.01.040},
  journal      = {Information Sciences},
  pages        = {271-282},
  shortjournal = {Inf. Sci.},
  title        = {Operators invariant under finitely many input changes with applications to aggregation of sequences},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Robust feature learning for adversarial defense via
hierarchical feature alignment. <em>ISCI</em>, <em>560</em>, 256–270.
(<a href="https://doi.org/10.1016/j.ins.2020.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have demonstrated excellent performance in most computer vision tasks in recent years. However, they are vulnerable to adversarial perturbations generated by adversarial attacks. These human-imperceptible perturbations often lead to severe distortion in the high-dimensional intermediate feature space, which is one of the major reasons for the vulnerabilities in deep neural networks. Therefore, input images with perturbations can completely change the predictions of the networks in the decision space. To overcome this drawback, we propose to progressively align the intermediate feature representations extracted from the adversarial domain with feature representations extracted from a clean domain through domain adaptation. The difference between two feature distributions can be accurately measured via an optimal transport-based Wasserstein distance. Thus, the deep networks are forced to learn robust and domain-invariant feature representations, so that the gap between the different domains is minimized and that the networks are no longer easily fooled by diverse adversaries. Extensive evaluations are conducted on four classification benchmark datasets in white-box attack scenarios. The evaluation results demonstrate a significant performance improvement over several state-of-the-art defense methods.},
  archive      = {J_ISCI},
  author       = {Xiaoqin Zhang and Jinxin Wang and Tao Wang and Runhua Jiang and Jiawei Xu and Li Zhao},
  doi          = {10.1016/j.ins.2020.12.042},
  journal      = {Information Sciences},
  pages        = {256-270},
  shortjournal = {Inf. Sci.},
  title        = {Robust feature learning for adversarial defense via hierarchical feature alignment},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical study into finding optima in stochastic
optimization of neural networks. <em>ISCI</em>, <em>560</em>, 235–255.
(<a href="https://doi.org/10.1016/j.ins.2021.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mini-batch sub-sampling (MBSS) in neural network training is unavoidable due to growing data demands, memory-limited computational resources such as graphical processing units, and the dynamics of on-line learning. This study distinguishes between static MBSS and dynamic MBSS. In static MBSS, mini-batches are intermittently fixed during training, resulting in smooth but biased loss functions. During dynamic MBSS, mini-batches are resampled at every loss evaluation, resulting in sampling induced discontinuities by trading sampling bias for sampling variance. This renders classical minimization strategies ineffective in dynamic MBSS losses, as these may locate spurious sampling induced minima, while critical points may not exist. This paper re-evaluates the information used to define optima in stochastic loss functions of neural networks by defining the solution to a stochastic optimization problem as the stochastic non-negative associated gradient projection point (SNN-GPP). We demonstrate that SNN-GPPs offer a more robust description of full-batch optima than minimizers and critical points. An empirical investigation compares local minima to SNN-GPPs for the potential training of a simple neural network training problem with different activation functions. Since SNN-GPPs better approximate the location of true optima, we conclude that line searches locating SNN-GPPs can contribute significantly to automating neural network training.},
  archive      = {J_ISCI},
  author       = {Dominic Kafka and Daniel N. Wilke},
  doi          = {10.1016/j.ins.2021.01.005},
  journal      = {Information Sciences},
  pages        = {235-255},
  shortjournal = {Inf. Sci.},
  title        = {An empirical study into finding optima in stochastic optimization of neural networks},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Less complexity one-class classification approach using
construction error of convolutional image transformation network.
<em>ISCI</em>, <em>560</em>, 217–234. (<a
href="https://doi.org/10.1016/j.ins.2021.01.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One-class classification is a machine learning problem, where training data has only one class. The objective is to determine if the input data is seen class or unseen class. Traditional deep learning algorithms are not suitable for this task since the algorithm can predict only class in training data. In this paper, the one-class classification algorithm using construction error of image transformation network (OCITN) is proposed. In particular, image transformation network (ITN) is introduced as a subtask, which transforms input image into one image, namely goal image. Moreover, the error of ITN, namely construction error (CE), is computed as a distance metric between the goal image and model output. ITN model is trained using only one-class images and is applied for testing images. Since the model is trained with only one-class images, the CE for one-class is small relative to other classes. Thus, one-class classification is made determining CE is large or small. The proposed method is experimented with using MNIST, Fashion MNIST, CIFAR10, CIFAR100, and Cat-vs-Dog datasets. OCITN shows good results where the goal image has high entropy. Additionally, the extension of OCITN, namely OCITNE, is implemented. This method shows the state of the art performance in MNIST (98.0), Fashion MNIST(95.6), and acceptable performance in CIFAR10(78.4). Furthermore, these methods provide high-speed processing, OCITN process 5291 images, and OCITNE 1261 images per second, 137 times and 33 times faster than state of the art. The source code used in this paper can be downloaded from: https://github.com/ToshiHayashi/OCITN .},
  archive      = {J_ISCI},
  author       = {Toshitaka Hayashi and Hamido Fujita and Andres Hernandez-Matamoros},
  doi          = {10.1016/j.ins.2021.01.069},
  journal      = {Information Sciences},
  pages        = {217-234},
  shortjournal = {Inf. Sci.},
  title        = {Less complexity one-class classification approach using construction error of convolutional image transformation network},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-trigger-based recursive sliding-mode dynamic surface
containment control with nonlinear gains for nonlinear multi-agent
systems. <em>ISCI</em>, <em>560</em>, 202–216. (<a
href="https://doi.org/10.1016/j.ins.2021.01.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with event-triggered containment control for a class of networked nonlinear multi-agent systems (MASs) subject to limited communication resources. A distributed containment output feedback control strategy with an event-triggered communication mechanism is proposed for the concerned MAS. Considering only a subset of followers to be informed by the leaders, we design a distributed estimator, based on neighbor’s triggered outputs, for estimation of the desired trajectory in real time. A state observer is designed for reconstruction of the unmeasured states of individual followers. Both a nonlinear gain function and a recursive sliding-mode surface are introduced to overcome drawbacks in dynamic surface control approach. It is formally proved that the proposed control strategy guarantees the containment of all followers by the leaders and the ultimate boundedness of the containment errors around the origin. It is also shown that the proposed event-triggered containment controller exhibits a Zeno-free behavior. Finally, two illustrative examples are presented to verify the effectiveness of the obtained results.},
  archive      = {J_ISCI},
  author       = {Yang Yang and Yue Qian},
  doi          = {10.1016/j.ins.2021.01.072},
  journal      = {Information Sciences},
  pages        = {202-216},
  shortjournal = {Inf. Sci.},
  title        = {Event-trigger-based recursive sliding-mode dynamic surface containment control with nonlinear gains for nonlinear multi-agent systems},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A user collaboration privacy protection scheme with
threshold scheme and smart contract. <em>ISCI</em>, <em>560</em>,
183–201. (<a href="https://doi.org/10.1016/j.ins.2021.01.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the revolution of 5G networks has promoted a wide application of wireless technology , and then followed with the prosperity of Location-Based Service (LBS). However, an intricate problem called privacy violation still restricts the development of this type of service. To preserve users’ privacy, some privacy preservation strategies had been proposed. As an efficient framework used for protecting personal privacy, users’ collaboration is mainly proposed for dealing with the issue of service bottleneck and the issue of attack focus. However, there are still several challenges far from being perfectly solved, such as the collusion attacks as well as the willingness of collaborative users. Therefore, to address these challenges, in this paper, based on the conception of information division and user’s incentive, a ( t , n ) (t,n) smart contract privacy preservation scheme short for ( t , n ) (t,n) SCPPS is proposed. In this scheme, the query information is encrypted and split by ( t , n ) threshold scheme , so the collaborative users will be difficult to learn anything about the initiator, and the collusion will be difficult to constitute the integral query without t users colluding with each other. On the other hand, the combination of ( t , n ) threshold scheme and smart contract further provide incentive competition, as just the earliest collaborative users that submit the partition information and get the corresponding feedback will obtain the incentive. At last, the security analyses were given, and then tests of users’ granularity and locations difference in the continuous query in the real environment. Furthermore, simulation experiments are conducted to demonstrate the effectiveness of the proposed scheme, and the experimental verification is executed using two different types of datasets. Thus, compared with other similar schemes, the results with brief explanations about reasons can further demonstrate the superiority of the proposed scheme.},
  archive      = {J_ISCI},
  author       = {Lei Zhang and Desheng Liu and Meina Chen and Hongyan Li and Chao Wang and Yunxiang Zhang and Yunming Du},
  doi          = {10.1016/j.ins.2021.01.071},
  journal      = {Information Sciences},
  pages        = {183-201},
  shortjournal = {Inf. Sci.},
  title        = {A user collaboration privacy protection scheme with threshold scheme and smart contract},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecast combination with meta possibilistic fuzzy
functions. <em>ISCI</em>, <em>560</em>, 168–182. (<a
href="https://doi.org/10.1016/j.ins.2021.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are many methods to obtain accurate forecasts for time series data in the literature. It is imperative to find an appropriate method with the correct assumptions for a given data set and circumstances. However, the assumptions of existing individual methods rarely apply perfectly to data sets of real-life problems. Meta possibilistic fuzzy functions (MPFF) is introduced to overcome the limitations of individual methods by using meta fuzzy functions (MFF) in which the optimum function and weights for method aggregation are found. The possibilistic fuzzy c-means clustering algorithm is adapted in MFFs to mitigate the cost of misspecification of individual methods through weighted combination of methods in functions. The optimum effect sizes (weights) of the forecasting methods in the best function is determined from MPFFs. 9 real-world time series and a forecasting method are selected, and 1 real-world dataset and 13 different forecasting methods are determined for the experimental study of the proposed method. The results verified that the proposed approach achieves greater accuracy in terms of both mean absolute percentage error and root mean square error than existing forecasting methodology.},
  archive      = {J_ISCI},
  author       = {Nihat Tak},
  doi          = {10.1016/j.ins.2021.01.024},
  journal      = {Information Sciences},
  pages        = {168-182},
  shortjournal = {Inf. Sci.},
  title        = {Forecast combination with meta possibilistic fuzzy functions},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mutual-information-inspired heuristics for constraint-based
causal structure learning. <em>ISCI</em>, <em>560</em>, 152–167. (<a
href="https://doi.org/10.1016/j.ins.2020.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In constraint-based approaches to Bayesian network structure learning , when the assumption of orientation-faithfulness is violated, not only the correctness of edge orientation can be greatly degraded, the soaring cost of conditional independence testing also limits their applicability in learning very large causal networks. Inspired by the strong connection between the degree of mutual information shared by two variables and their conditional independence , we extend the PC-MI algorithm in two ways: (a) the Weakest Edge-First (WEF) strategy implemented in PC-MI is further integrated with Markov-chain consistency to reduce the number of independence testing and sustain the number of false positive edges in skeletal learning; (b) the Smaller Adjacency-Set (SAS) strategy is proposed and we prove that the Smaller Adjacency-Set captures sufficient information for determining whether an unshielded triple forms a v-structure. We have conducted experiments with both low-dimensional and high-dimensional data sets, and the results indicate that our MIIPC approach outperforms the state-of-the-art approaches in both the quality of learning and the execution time.},
  archive      = {J_ISCI},
  author       = {Xiaolong Qi and Xiaocong Fan and Huiling Wang and Ling Lin and Yang Gao},
  doi          = {10.1016/j.ins.2020.12.009},
  journal      = {Information Sciences},
  pages        = {152-167},
  shortjournal = {Inf. Sci.},
  title        = {Mutual-information-inspired heuristics for constraint-based causal structure learning},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rumor2vec: A rumor detection framework with joint text and
propagation structure representation learning. <em>ISCI</em>,
<em>560</em>, 137–151. (<a
href="https://doi.org/10.1016/j.ins.2020.12.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rumors often yield adverse societal and economic impacts. Therefore, rumor detection has attracted a surge of research interests. Existing methods mainly focus on finding clues from textual contents, which is not quite effective as rumors can be intentionally manipulated. Recent studies have demonstrated that the propagation structure of rumors can significantly improve rumor detection performance. However, propagation-based methods are still limited as the propagation structure is often sparse at an early stage. In this study, we propose Rumor2vec, a novel rumor detection framework with joint text and propagation structure representation learning . First, we present the concept of the union graph to incorporate propagation structures of all tweets to mitigate the sparsity issue. Then, we leverage network embedding to learn representations of nodes in the union graph. Finally, we propose a framework for rumor representation learning and detection. Experimental results on three real-world datasets demonstrate that our proposed framework can achieve better performance than the state-of-the-art approaches. On two Twitter datasets, our method achieves 79.6\% and 85.2\% accuracies respectively. On the Weibo dataset, our method achieves a 95.1\% accuracy. Further experiments on early rumor detection show that our method can identify rumors ahead of other methods by at least 12 h.},
  archive      = {J_ISCI},
  author       = {Kefei Tu and Chen Chen and Chunyan Hou and Jing Yuan and Jundong Li and Xiaojie Yuan},
  doi          = {10.1016/j.ins.2020.12.080},
  journal      = {Information Sciences},
  pages        = {137-151},
  shortjournal = {Inf. Sci.},
  title        = {Rumor2vec: A rumor detection framework with joint text and propagation structure representation learning},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heuristic algorithms for aggregation of incomplete rankings
in multiple criteria group decision making. <em>ISCI</em>, <em>560</em>,
107–136. (<a href="https://doi.org/10.1016/j.ins.2021.01.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose heuristics for constructing a compromise incomplete ranking based on partial rankings admitting incomparability. We consider the utilitarian and egalitarian perspectives oriented toward minimizing an average or a maximal distance from any input ranking. The proposed algorithms incorporate genetic algorithms, simulated annealing, tabu search, local search, and intuitive, dedicated procedures. We demonstrate their efficiency in a real-world case study concerning the ranking of insulating materials based on the conflicting, incomplete preferences of a few tens of Decision Makers (DMs). For each DM, we consider a single representative ranking consistent with his/her preferences or thousands of such rankings following incorporation of the robustness concern. The experimental comparison is generalized to artificially generated problems that differ in terms of the numbers of alternatives and input rankings, and diversity levels. The results are quantified with the quality of obtained rankings and computation time.},
  archive      = {J_ISCI},
  author       = {Grzegorz Miebs and Miłosz Kadziński},
  doi          = {10.1016/j.ins.2021.01.055},
  journal      = {Information Sciences},
  pages        = {107-136},
  shortjournal = {Inf. Sci.},
  title        = {Heuristic algorithms for aggregation of incomplete rankings in multiple criteria group decision making},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised classification by graph p-laplacian
convolutional networks. <em>ISCI</em>, <em>560</em>, 92–106. (<a
href="https://doi.org/10.1016/j.ins.2021.01.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph convolutional networks (GCN) generalizes convolution neural networks into the graph with an arbitrary topology structure. Since the geodesic function in the null space of the graph Laplacian matrix is constant, graph Laplacian fails to preserve the local topology structure information between samples properly. GCN thus cannot learn better representative sample features by the convolution operation of the graph Laplacian based structure information and input sample information. To address this issue, this paper exploits the manifold structure information of data by the graph p -Laplacian matrix and proposes the graph p -Laplacian convolutional networks (GpLCN). As the graph p -Laplacian matrix is a generalization of the graph Laplacian matrix , GpLCN can extract more abundant sample features and improves the classification performance utilizing graph p -Laplacian to preserve the rich intrinsic data manifold structure information. Moreover, after simplifying and deducing the formula of the one-order spectral graph p-Laplacian convolution, we introduce a new layer-wise propagation rule based on the one-order approximation . Extensive experiment results on the Citeseer, Cora and Pubmed database demonstrate that our GpLCN outperforms GCN.},
  archive      = {J_ISCI},
  author       = {Sichao Fu and Weifeng Liu and Kai Zhang and Yicong Zhou and Dapeng Tao},
  doi          = {10.1016/j.ins.2021.01.075},
  journal      = {Information Sciences},
  pages        = {92-106},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised classification by graph p-laplacian convolutional networks},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-stage evolutionary algorithm for multi-objective
optimization with complex constraints. <em>ISCI</em>, <em>560</em>,
68–91. (<a href="https://doi.org/10.1016/j.ins.2021.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Constrained multi-objective optimization problems (CMOPs) are difficult to handle because objectives and constraints need to be considered simultaneously, especially when the constraints are extremely complex. Some recent algorithms work well when dealing with CMOPs with a simple feasible region; however, the effectiveness of most algorithms degrades considerably for CMOPs with complex feasible regions. To address this issue, this paper proposes a multi-stage evolutionary algorithm , where constraints are added one after the other and handled in different stages of evolution. Specifically, in the early stages, the algorithm only considers a small number of constraints, which can make the population efficiently converge to the potential feasible region with good diversity. As the algorithm moves to the later stages, more constraints are considered to search the optimal solutions based on the solutions obtained in the previous stages. Furthermore, a strategy for sorting the constraint-handling priority according to the impact on the unconstrained Pareto front is proposed, which can accelerate the convergence of the algorithm. Experimental results on five benchmark suites and three real-world applications showed that the proposed algorithm outperforms several state-of-the-art constraint multi-objective evolutionary algorithms when dealing with CMOPs, especially for problems with complex constraints.},
  archive      = {J_ISCI},
  author       = {Haiping Ma and Haoyu Wei and Ye Tian and Ran Cheng and Xingyi Zhang},
  doi          = {10.1016/j.ins.2021.01.029},
  journal      = {Information Sciences},
  pages        = {68-91},
  shortjournal = {Inf. Sci.},
  title        = {A multi-stage evolutionary algorithm for multi-objective optimization with complex constraints},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data quality measures based on granular computing for
multi-label classification. <em>ISCI</em>, <em>560</em>, 51–67. (<a
href="https://doi.org/10.1016/j.ins.2021.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rough set theory is a granular computing formalism that allows analyzing a given dataset through well-defined measures. Some of these measures aim to characterize datasets used to discover knowledge, mostly in traditional classification problems. Measuring the data quality is pivotal to estimate beforehand the problem’s difficulty since a classification model’s accuracy heavily depends on the data quality. However, to the best of our knowledge, there are no measures devoted to analyzing the quality of multi-label datasets. In this paper, we propose six data quality measures for multi-label problems, which are based on different granular approaches. Some of these measures redefine the decision class concept, while others redefine the consistency concept. Moreover, we study the impact of the similarity threshold parameters and the distance functions on the behavior of these measures. The numerical simulations show a statistical correlation between the measures that redefine the consistency concept and the performance of the ML- k NN classifier.},
  archive      = {J_ISCI},
  author       = {Marilyn Bello and Gonzalo Nápoles and Koen Vanhoof and Rafael Bello},
  doi          = {10.1016/j.ins.2021.01.027},
  journal      = {Information Sciences},
  pages        = {51-67},
  shortjournal = {Inf. Sci.},
  title        = {Data quality measures based on granular computing for multi-label classification},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An autoencoder wavelet based deep neural network with
attention mechanism for multi-step prediction of plant growth.
<em>ISCI</em>, <em>560</em>, 35–50. (<a
href="https://doi.org/10.1016/j.ins.2021.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-step-ahead prediction is considered of major significance for time series analysis in many real life problems. Existing methods mainly focus on one-step-ahead forecasting, since multiple step forecasting generally fails due to accumulation of prediction errors. This paper presents a novel approach for predicting plant growth in agriculture, focusing on prediction of plant Stem Diameter Variations (SDV). The proposed approach consists of three main steps. At first, wavelet decomposition is applied to the original data, so as to facilitate model fitting and reduce noise. Then an encoder-decoder framework is developed using Long Short Term Memory (LSTM) and used for appropriate feature extraction from the data. Finally, a recurrent neural network including LSTM and an attention mechanism is proposed for modelling long-term dependencies in the time series data . Experimental results are presented which illustrate the good performance of the proposed approach and that it significantly outperforms the existing models, in terms of error criteria such as RMSE , MAE and MAPE.},
  archive      = {J_ISCI},
  author       = {Bashar Alhnaity and Stefanos Kollias and Georgios Leontidis and Shouyong Jiang and Bert Schamp and Simon Pearson},
  doi          = {10.1016/j.ins.2021.01.037},
  journal      = {Information Sciences},
  pages        = {35-50},
  shortjournal = {Inf. Sci.},
  title        = {An autoencoder wavelet based deep neural network with attention mechanism for multi-step prediction of plant growth},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Master–slave synchronization of neural networks subject to
mixed-type communication attacks. <em>ISCI</em>, <em>560</em>, 20–34.
(<a href="https://doi.org/10.1016/j.ins.2021.01.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concerns the master–slave synchronization issue of neural networks subject to mixed-type communication attacks. The synchronization strategy is based on static output feedback controller followed by an event-triggered scheme. The communication network is assumed to be under various types of cyber-attacks, namely, deception, replay, and denial-of-service attacks. All these attacks are investigated in a unified Markovian jump framework. Using the Lyapunov–Krasovskii theory and stochastic analysis techniques, some design criteria are derived and formulated in terms of matrix inequalities. A convex optimization algorithm is proposed to design the static output feedback controller . Finally, two chaotic examples are presented to demonstrate the effectiveness of the event-triggered static output feedback controller.},
  archive      = {J_ISCI},
  author       = {Ali Kazemy and Ramasamy Saravanakumar and James Lam},
  doi          = {10.1016/j.ins.2021.01.063},
  journal      = {Information Sciences},
  pages        = {20-34},
  shortjournal = {Inf. Sci.},
  title        = {Master–slave synchronization of neural networks subject to mixed-type communication attacks},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Black hole entropic fuzzy clustering-based image indexing
and tversky index-feature matching for image retrieval in cloud
computing environment. <em>ISCI</em>, <em>560</em>, 1–19. (<a
href="https://doi.org/10.1016/j.ins.2021.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the expansion of social websites, the data owner accumulates multimedia data and stores in cloud server. The owner encrypts the images before uploading it in cloud server for security. However, the conventional encryption method failed to support feasible retrieval on the encrypted images. This paper proposes novel technique, namely Black Hole Entropic Fuzzy Clustering-based Tversky index for effective image retrieval . Here, the SLBP (Spatial Local Binary Pattern) features, semantic features , statistical features, and low image features are considered in the feature extraction. In addition, encryption of feature vector using Elliptic Curve Cryptography (ECC) is done for encrypting the images contained in cloud server. The Black Hole Entropic Fuzzy Clustering (BHEFC) is adapted for grouping the images. Whenever users request an input query then, the query image is fed to feature extraction, and encryption phase, wherein the Tversky index is applied for matching the similarity between the images for retrieval. The proposed BHEFC-based Tversky index outperformed other methods with maximal accuracy of 95.737\%, maximal precision of 83.563\%, maximal recall of 94.697\%, and maximal F-measure of 83.014\%.},
  archive      = {J_ISCI},
  author       = {K. Nalini Sujantha Bel and I. Shatheesh Sam},
  doi          = {10.1016/j.ins.2021.01.043},
  journal      = {Information Sciences},
  pages        = {1-19},
  shortjournal = {Inf. Sci.},
  title        = {Black hole entropic fuzzy clustering-based image indexing and tversky index-feature matching for image retrieval in cloud computing environment},
  volume       = {560},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approach based on timed petri nets and tree encoding to
implement search algorithms for a class of scheduling problems.
<em>ISCI</em>, <em>559</em>, 314–335. (<a
href="https://doi.org/10.1016/j.ins.2020.12.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scheduling problems have been approached several times by Petri nets . Indeed, the usage of a Petri net model guarantees the feasibility of the candidate solutions, but it does not provide an accurate evaluation of the time required to complete the considered workshop. For this purpose, a class of timed Petri nets , namely structured nets , is defined and the encoding of the structure and time information of such nets as a tree is presented. This encoding, in combination with the resolution of some linear matrix inequalities, is used to estimate the residual time required to complete each job of the considered workshop. The main advantage of this computation is to provide an estimation of the residual time as an interval that includes necessarily the exact residual duration. Consequently, the lower bound of the interval never overestimates the exact duration and can be used as a part of the cost function involved in many exploration algorithms as the A* or the Beam Search algorithms. In this paper, the proposed estimation function is used with the Hybrid Filtered Beam Search algorithm and performances are discussed for several examples of workshops. The paper also illustrates that the approach can be combined with supervisory control to accelerate the convergence of the exploration since deadlocked solutions can be eliminated directly in the model.},
  archive      = {J_ISCI},
  author       = {Dimitri Lefebvre and Francesco Basile},
  doi          = {10.1016/j.ins.2020.12.087},
  journal      = {Information Sciences},
  pages        = {314-335},
  shortjournal = {Inf. Sci.},
  title        = {An approach based on timed petri nets and tree encoding to implement search algorithms for a class of scheduling problems},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An erratum to “extended karush-kuhn-tucker condition for
constrained interval optimization problems and its application in
support vector machines.” <em>ISCI</em>, <em>559</em>, 309–313. (<a
href="https://doi.org/10.1016/j.ins.2020.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we correct some errors in the extended first and second Gordan’s theorems in a recent paper—Information Sciences 504 (2019) 276–292.},
  archive      = {J_ISCI},
  author       = {Ram Surat Chauhan and Debdas Ghosh},
  doi          = {10.1016/j.ins.2020.12.034},
  journal      = {Information Sciences},
  pages        = {309-313},
  shortjournal = {Inf. Sci.},
  title        = {An erratum to “Extended karush-kuhn-tucker condition for constrained interval optimization problems and its application in support vector machines”},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-singleton fuzzification made simpler. <em>ISCI</em>,
<em>559</em>, 286–308. (<a
href="https://doi.org/10.1016/j.ins.2020.12.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-singleton fuzzification is used in rule-based fuzzy systems when the measurements that activate them are imperfect or uncertain or when their inputs are words. It models such measurements or words as fuzzy numbers or more general fuzzy sets so that, regardless of the cause of a measurement’s or word’s imperfections or uncertainties, they are treated within the framework of fuzzy sets and systems. Since 2011, there has been a resurgence of interest in both type-1 and interval type-2 non-singleton fuzzy systems. This paper removes a computational bottleneck associated with computing the firing level or firing interval for such fuzzy systems, by providing closed-form formulas for them when the involved fuzzy sets are trapezoidal or triangular, which are widely used fuzzy sets. This is done for both the minimum and product t-norms. It is also demonstrated that a non-singleton fuzzy system that uses the product t-norm has the potential to outperform a non-singleton fuzzy system that uses the minimum t-norm. The results in this paper greatly simplify non-singleton fuzzy systems, which should make them much more popular.},
  archive      = {J_ISCI},
  author       = {Jerry M. Mendel},
  doi          = {10.1016/j.ins.2020.12.061},
  journal      = {Information Sciences},
  pages        = {286-308},
  shortjournal = {Inf. Sci.},
  title        = {Non-singleton fuzzification made simpler},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Stabilization of permanent magnet synchronous
generator-based wind turbine system via fuzzy-based sampled-data control
approach. <em>ISCI</em>, <em>559</em>, 270–285. (<a
href="https://doi.org/10.1016/j.ins.2020.12.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study concerns the stabilization analysis for nonlinear permanent magnet synchronous generator (PMSG)-based wind turbine system under fuzzy-based memory sampled-data (FBMSD) control scheme. In this regard, the Takagi-Sugeno (T-S) fuzzy theory is utilized in the conversion of the proposed nonlinear model into linear-sub models and the corresponding FBMSD controller is designed. The paper introduces a suitable Lyapunov–Krasovskii functional that contains the information about the length of the sampling interval and a constant transmission delay. In order to stabilize the proposed system, sufficient conditions are derived in the form of linear matrix inequalities. As a test benchmark, the derived T-S fuzzy PMSG model is evaluated with a particular data set values and then validated with derived conditions. Besides that, the dynamical nature of system variables with respect to a blade pitch angle of the wind turbine system also discusses along with d - q d-q axes inductance via numerical simulations. Finally, a comparison of derived conditions with the existing works is discussed to prove the less conservatism of the proposed method.},
  archive      = {J_ISCI},
  author       = {Lakshmanan Shanmugam and Young Hoon Joo},
  doi          = {10.1016/j.ins.2020.12.088},
  journal      = {Information Sciences},
  pages        = {270-285},
  shortjournal = {Inf. Sci.},
  title        = {Stabilization of permanent magnet synchronous generator-based wind turbine system via fuzzy-based sampled-data control approach},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preview-based leader-following consensus control of
distributed multi-agent systems. <em>ISCI</em>, <em>559</em>, 251–269.
(<a href="https://doi.org/10.1016/j.ins.2020.12.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The preview-based leader-following consensus control of distributed multi-agent systems (MAS) with a directed acyclic graph is investigated in this paper. The external disturbance considered in this paper is the step function that can be previewed, and the information of the leader can be obtained in advance. The leader-following consensus control of MAS is solved by using the state augmentation technique and the preview control method that transforms the consensus control problem into the finite horizon linear quadratic regulator (LQR) problem and the infinite horizon LQR problem. In the finite horizon, the minimum principle is utilized to design the optimal controller. In the infinite horizon, the standard infinite horizon LQR is applied to devise the corresponding controller. Assuming the original systems are stabilisable and detectable, the distributed consensus controller guarantees the asymptotic consensus of the preview MAS. The simulation illustrates the effectiveness of the distributed leader-following consensus controller designed in this paper.},
  archive      = {J_ISCI},
  author       = {Guilu Li and Chang-E Ren and C. L. Philip Chen},
  doi          = {10.1016/j.ins.2020.12.081},
  journal      = {Information Sciences},
  pages        = {251-269},
  shortjournal = {Inf. Sci.},
  title        = {Preview-based leader-following consensus control of distributed multi-agent systems},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information theory and player archetype choice in
hearthstone. <em>ISCI</em>, <em>559</em>, 236–250. (<a
href="https://doi.org/10.1016/j.ins.2021.01.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using three years of game data of the online collectible card game Hearthstone , we analyse the evolution of the game’s system over the period 2016–2019. By considering the frequencies that archetypes are played, and their corresponding win-rates, we are able to provide narratives of the system-wide changes that have occurred over time, and player reactions to them. Applying the archetype frequencies to analyse the system’s Shannon entropy , we characterise the salient features of the time series of player choice. Paying particular attention to how entropy is affected during periods of both small and large-scale change, we are able to demonstrate the effects of increased player experimentation before popular decks and tactics emerge. Furthermore, constructing conditional probabilities that simulate understandable player behaviour, we analyse the system’s information storage and test the explain-ability of current player choice based on previous decision-making.},
  archive      = {J_ISCI},
  author       = {Mathew Zuparic and Duy Khuu and Tzachi Zach},
  doi          = {10.1016/j.ins.2021.01.066},
  journal      = {Information Sciences},
  pages        = {236-250},
  shortjournal = {Inf. Sci.},
  title        = {Information theory and player archetype choice in hearthstone},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CLAVER: An integrated framework of convolutional layer,
bidirectional LSTM with attention mechanism based scholarly venue
recommendation. <em>ISCI</em>, <em>559</em>, 212–235. (<a
href="https://doi.org/10.1016/j.ins.2020.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scholarly venue recommendation is an emerging field due to a rapid surge in the number of scholarly venues concomitant with exponential growth in interdisciplinary research and cross collaboration among researchers. Finding appropriate publication venues is confronted as one of the most challenging aspects in paper publication as a larger proportion of manuscripts face rejection due to a disjunction between the scope of the venue and the field of research pursued by the research article. We present CLAVER--an integrated framework of Convolutional Layer , bi-directional LSTM with an Attention mechanism-based scholarly VEnue Recommender system . The system is the first of its kind to integrate multiple deep learning-based concepts, that requires only the abstract and the title of a manuscript to identify academic venues. An extensive and exhaustive set of experiments conducted on the DBLP dataset certify that the postulated model CLAVER performs better than most of the modern techniques as entrenched by standard metrics such as stability, accuracy, MRR, average venue quality, precision@k, nDCG@k and diversity.},
  archive      = {J_ISCI},
  author       = {Tribikram Pradhan and Prashant Kumar and Sukomal Pal},
  doi          = {10.1016/j.ins.2020.12.024},
  journal      = {Information Sciences},
  pages        = {212-235},
  shortjournal = {Inf. Sci.},
  title        = {CLAVER: An integrated framework of convolutional layer, bidirectional LSTM with attention mechanism based scholarly venue recommendation},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach of two-stage three-way co-opetition
decision for crowdsourcing task allocation scheme. <em>ISCI</em>,
<em>559</em>, 191–211. (<a
href="https://doi.org/10.1016/j.ins.2021.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the crowdsourcing task allocation scheme, there is an emerging and realistic co-opetition phenomenon. To availably solve the crowdsourcing task allocation problem with co-opetition, this paper designs a two-stage co-opetition model by constructing novel three-way decision (TWD), including a competition-optimization model and a negotiation-cooperation model. Unlike the other studies, the two-stage co-opetition model with TWD can not only protect the profits of the task candidates, but also optimize the overall benefits. Specifically speaking, in the competition-optimization model, we construct an optimization model based on the data envelopment analysis (DEA) method in advance, which maximizes the personal benefit. By integrating information system and the loss function matrix, we consider the linkage of evaluation information and risk information and then improve the original TWD to make an initial allocation. In the negotiation-cooperation model, considering that the relationship among the candidates may influence the task performance, the fuzzy measure is introduced to describe a broader partnership. Meanwhile, we also design two different schemes to coordinate and optimize the best task allocations based on the initial allocation. In order to choose the best scheme, the selection strategy between schemes is further investigated under the guidance of the utility and the loss. Finally, we give an example of a medical supply chain crowdsourcing problem to illustrate and verify our proposed approach.},
  archive      = {J_ISCI},
  author       = {Decui Liang and Wen Cao and Zeshui Xu and Mingwei Wang},
  doi          = {10.1016/j.ins.2021.01.048},
  journal      = {Information Sciences},
  pages        = {191-211},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach of two-stage three-way co-opetition decision for crowdsourcing task allocation scheme},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Output event-triggered tracking synchronization of
heterogeneous systems on directed digraph via model-free reinforcement
learning. <em>ISCI</em>, <em>559</em>, 171–190. (<a
href="https://doi.org/10.1016/j.ins.2021.01.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an event-triggered controller for the output tracking synchronization problem in heterogeneous multi-agent systems on a directed digraph is developed. Initially, the design of the distributed observer is proposed to estimate the information of the leader. Owing to the communication among agents, there exists a coupling behavior in the design of controllers for followers. The separation theorem is exploited to realize decoupling between agents. Then, an optimal conventional controller and event-triggered controller are designed to achieve the synchronization service of the output tracking problem for agents; the latter also improves the efficiency precisely by deliberately aperiodic sampling. Additionally, we prove that the inter-event time interval is strictly positive in the event-triggered controller; that is, the Zeno behavior can be avoided. Furthermore, the optimal control gain is obtained in a model-free manner. More specifically, a model-free reinforcement learning algorithm is investigated to learn the control gain, which does not require the followers’ dynamics. Finally, two simulation examples show the availability of the algorithm.},
  archive      = {J_ISCI},
  author       = {Qing Li and Lina Xia and Ruizhuo Song and Lu Liu},
  doi          = {10.1016/j.ins.2021.01.056},
  journal      = {Information Sciences},
  pages        = {171-190},
  shortjournal = {Inf. Sci.},
  title        = {Output event-triggered tracking synchronization of heterogeneous systems on directed digraph via model-free reinforcement learning},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-class financial distress prediction based on support
vector machines integrated with the decomposition and fusion methods.
<em>ISCI</em>, <em>559</em>, 153–170. (<a
href="https://doi.org/10.1016/j.ins.2021.01.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Binary financial distress prediction (FDP), which categorizes corporate financial status into the two classes of distress and nondistress, cannot provide enough support for effective financial risk management . This paper focuses on research on multiclass FDP based on the support vector machine (SVM) integrated with the decomposition and fusion methods. Corporate financial status is subdivided into four states: financial soundness, financial pseudosoundness, moderate financial distress and serious financial distress. Three multiclass FDP models are built by integrating the SVM with three decomposition and fusion methods, i.e., one-versus-one (OVO), one-versus-rest (OVR), and error-correcting output coding (ECOC), and they are, respectively called OVO-SVM, OVR-SVM and ECOC-SVM. Empirical research based on data from Chinese listed companies shows that OVO-SVM overall outperforms OVR-SVM and ECOC-SVM and is preferred for multiclass FDP. In addition, all three models trained on the original highly class-imbalanced training dataset cannot obtain satisfying performance, and the data level preprocessing mechanisms that make class distributions balanced in the training dataset can greatly improve their multiclass FDP performance. Compared with multivariate discriminant analysis (MDA) and multinomial logit (MNLogit), OVO-SVM has significantly higher accuracy for financial pseudosoundness and moderate financial distress and lower accuracy for financial soundness and serious financial distress, resulting in no significant difference among their overall multiclass FDP performance. However, OVO-SVM is still more competitive than MDA and MNLogit in that financial pseudosoundness and moderate financial distress are much more difficult to predict by human expertise than the other two financial states.},
  archive      = {J_ISCI},
  author       = {Jie Sun and Hamido Fujita Ph.D and Yujiao Zheng and Wenguo Ai},
  doi          = {10.1016/j.ins.2021.01.059},
  journal      = {Information Sciences},
  pages        = {153-170},
  shortjournal = {Inf. Sci.},
  title        = {Multi-class financial distress prediction based on support vector machines integrated with the decomposition and fusion methods},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A new deep auto-encoder using multiscale reconstruction
errors and weight update correlation. <em>ISCI</em>, <em>559</em>,
130–152. (<a href="https://doi.org/10.1016/j.ins.2021.01.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Auto-Encoder (DAE) is a promising deep learning model to extract the features of data. However, it is difficult to achieve the desired network parameters by training due to the issue of inappropriate learning rate , which usually affects its performance of extracting features. In order to solve such an issue, in this paper we propose a new Variable Learning Speed DAE (VLSDAE) using Multiscale Reconstruction Errors (MRE) and Weights Update Correlation (WUC) to adaptively adjust its learning rate. Specifically, the reconstruction errors based on the multiscales, i.e. mini-batch, epoch and phase, are considered to reflect the macroscopic training effect. Moreover, for the sake of further representing the microscopic training state, WUC is proposed to depict the training effect of each neuron. We first give the complexity analysis and the theoretical proof for the convergence of VLSDAE. To further exhibit its performance, a parameter sensitivity analysis is then provided to investigate the effects of two key parameters. In addition, the proposed MRE, WUC and our integrated method are studied individually to reveal their learning effects. Finally, we compare VLSDAE with eight state-of-the-art algorithms. The experimental results demonstrate that VLSDAE outperforms the other eight competitors in terms of training error, classification accuracy, precision, recall and macro- F 1 .},
  archive      = {J_ISCI},
  author       = {Wei Song and Wei Li and Ziyu Hua and Fuxin Zhu},
  doi          = {10.1016/j.ins.2021.01.064},
  journal      = {Information Sciences},
  pages        = {130-152},
  shortjournal = {Inf. Sci.},
  title        = {A new deep auto-encoder using multiscale reconstruction errors and weight update correlation},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relevance aggregation for neural networks interpretability
and knowledge discovery on tabular data. <em>ISCI</em>, <em>559</em>,
111–129. (<a href="https://doi.org/10.1016/j.ins.2021.01.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The lack of interpretability of neural networks is partially why they are not adopted in a wider variety of applications. Many works focus on explaining their predictions, but few take tabular data into consideration, which led to a small adoption even though this data is of high academic and business interest. We present relevance aggregation, an algorithm that combines the relevance computed from several samples as learned by a neural network and generates scores for each input feature. We also present two methods for visualizing the learned patterns, leading to a better model comprehension. The method was tested in synthetic and real-world datasets (breast cancer gene expression, online shopping behavior, and national high school exam) for classification and regression tasks . It correctly identified which features are the most important for the network’s predictions. The selected features can be distinct for each class. The rank of features scores also matches their contribution to the model’s performance. The results selected relevant features from the data, paving the way for knowledge discovery. The top-ranked features were consistently able to improve the performance of another independent classifier. For poorly trained neural networks , relevance aggregation helped identify incorrect rules or machine bias.},
  archive      = {J_ISCI},
  author       = {Bruno Iochins Grisci and Mathias J. Krause and Marcio Dorn},
  doi          = {10.1016/j.ins.2021.01.052},
  journal      = {Information Sciences},
  pages        = {111-129},
  shortjournal = {Inf. Sci.},
  title        = {Relevance aggregation for neural networks interpretability and knowledge discovery on tabular data},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-weighted fuzzy support vector machines for
classification in changing environments. <em>ISCI</em>, <em>559</em>,
97–110. (<a href="https://doi.org/10.1016/j.ins.2021.01.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The predictive performance of classification methods relies heavily on the nature of the environment, as in the joint distribution of inputs and outputs may evolve over time. This issue is known as dataset shift. Given that most statistical and machine learning techniques assume that the training sample is drawn from the same distribution as the test data used for evaluation, an appreciable amount of researchers and practitioners tend to ignore this issue at the model construction stage. In this paper, we propose a novel Fuzzy Support Vector Machine strategy, in which the traditional hinge loss function is redefined to account for dataset shift. Additionally, we propose a general version of this loss function applying aggregation operators in order to improve performance by dealing with dataset shift via fuzzy logic. Originally developed as linear approaches, our proposals are extended to kernel-based classification for non-linear machine learning . Our methods are able to perform best compared to traditional classifiers in terms of out-of-time prediction using simulated and real-world dataset for credit scoring, confirming the theoretical virtues of our approach.},
  archive      = {J_ISCI},
  author       = {Sebastián Maldonado and Julio López and Carla Vairetti},
  doi          = {10.1016/j.ins.2021.01.070},
  journal      = {Information Sciences},
  pages        = {97-110},
  shortjournal = {Inf. Sci.},
  title        = {Time-weighted fuzzy support vector machines for classification in changing environments},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-way decisions based multi-attribute decision making
with probabilistic dominance relations. <em>ISCI</em>, <em>559</em>,
75–96. (<a href="https://doi.org/10.1016/j.ins.2021.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute decision making (MADM) refers to a decision problem of choosing the best alternative or carrying out the ranking of alternatives under multiple attributes, and it is a key component of modern decision sciences. Three-way decisions (3WD) can effectively address MADM problems by reducing decision risks compared with traditional two-way decisions (2WD), and a decision model based on probabilistic dominance relations is presented in this paper. Particularly, we put forward a kind of 3WD-based MADM (3WD-MADM) with probabilistic dominance relations, where the two state sets are developed by virtue of probabilistic dominance classes. Afterwards, the independent innovation ability of high-tech enterprises is evaluated by using the proposed new method. At last, the newly proposed 3WD-MADM model in this paper is verified from different perspectives by comparative and experimental analyses.},
  archive      = {J_ISCI},
  author       = {Wenjie Wang and Jianming Zhan and Chao Zhang},
  doi          = {10.1016/j.ins.2021.01.028},
  journal      = {Information Sciences},
  pages        = {75-96},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decisions based multi-attribute decision making with probabilistic dominance relations},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Business location planning based on a novel geo-social
influence diffusion model. <em>ISCI</em>, <em>559</em>, 61–74. (<a
href="https://doi.org/10.1016/j.ins.2021.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern smart cities, an increasing number of businesses rely on social network marketing to capture potential customers and third-party delivery systems to serve them; this system is called “online to offline”. Consequently, the well-known business location planning problem, which is used to attract nearby offline users, must be redefined. Thus, we propose a novel influence diffusion model to simulate the spread of advertisements for a given location within the geo-social networks; this model considers the distance from the social network users to the location and other existing competitors. We present an approximation algorithm to evaluate the maximum influence that can be achieved for a location based on the diffusion model. Moreover, to efficiently select the optimal location (with the largest maximum influence spread) from multiple candidates, a clustering-based pruning strategy is proposed. Our experimental results demonstrated the effectiveness and efficiency of our approach.},
  archive      = {J_ISCI},
  author       = {Qian Zeng and Ming Zhong and Yuanyuan Zhu and Tieyun Qian and Jianxin Li},
  doi          = {10.1016/j.ins.2021.01.047},
  journal      = {Information Sciences},
  pages        = {61-74},
  shortjournal = {Inf. Sci.},
  title        = {Business location planning based on a novel geo-social influence diffusion model},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross adversarial consistency self-prediction learning for
unsupervised domain adaptation person re-identification. <em>ISCI</em>,
<em>559</em>, 46–60. (<a
href="https://doi.org/10.1016/j.ins.2021.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain-invariant feature-extraction has become very popular for unsupervised domain adaptation (UDA) person re-identification (Re-ID). However, most methods using it are limited by weak discrimination of learned domain-invariant features. To solve this problem, we develop a new approach: cross-adversarial consistency self-prediction learning. Cross-adversarial consistency is used to endow the learned feature with domain invariance and discrimination; consistency self-prediction fine-tunes the pre-trained model by selecting non-paired samples from target data. First, the camera views of source domain are randomly divided into two groups with their samples. Then, the two identifiers are used crosswise on both groups, forcing consistent results through adversarial learning between the identifiers and the feature encoder. To refine the model, a self-prediction mechanism is introduced that conservatively selects target domain samples with high identity similarities to labeled source domain samples. This practical design helps to alleviate domain bias between the source and target domains. The results of experiments conducted on five benchmark datasets verify that the proposed method is effective and outperforms state-of-the-art competitors. The source code of our method is available at https://github.com/PangJian123/CAC-CSP.},
  archive      = {J_ISCI},
  author       = {Huafeng Li and Jian Pang and Dapeng Tao and Zhengtao Yu},
  doi          = {10.1016/j.ins.2021.01.016},
  journal      = {Information Sciences},
  pages        = {46-60},
  shortjournal = {Inf. Sci.},
  title        = {Cross adversarial consistency self-prediction learning for unsupervised domain adaptation person re-identification},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CTSVM: A robust twin support vector machine with
correntropy-induced loss function for binary classification problems.
<em>ISCI</em>, <em>559</em>, 22–45. (<a
href="https://doi.org/10.1016/j.ins.2021.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a variant of the support vector machine (SVM), the twin support vector machine (TSVM) has attracted substantial attention; however, TSVM is sensitive to outliers. To remedy it,this study introduces the correntropy-induced loss (C-loss) function, which is a non-convex, bounded, smooth loss function, and proposes the C-loss TSVM (CTSVM). CTSVM is designed to perform the following optimizations: minimization of the C-loss function, the 2-norm regularization of model coefficients, and the distance between the positive (negative) samples and the positive-class (negative-class) hyperplane, which ensures that negative (positive) samples are far away from the positive (negative) hyperplane. CTSVM is cast into two half-quadratic optimization problems that can be solved by using an alternating iterative method. This approach enables the computational time of CTSVM to remain comparable to that of related methods, especially when solving linear problems. Experimental results were processed statistically to compare the performance of multiple algorithms on multiple datasets. These results confirmed that CTSVM outperforms similar classifiers in terms of its robustness to outliers and classification accuracy for binary tasks. In the future, we aim to investigate the performance of CTSVM with respect to multi-class classification tasks.},
  archive      = {J_ISCI},
  author       = {Xiaohan Zheng and Li Zhang and Leilei Yan},
  doi          = {10.1016/j.ins.2021.01.006},
  journal      = {Information Sciences},
  pages        = {22-45},
  shortjournal = {Inf. Sci.},
  title        = {CTSVM: A robust twin support vector machine with correntropy-induced loss function for binary classification problems},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DRBFT: Delegated randomization byzantine fault tolerance
consensus protocol for blockchains. <em>ISCI</em>, <em>559</em>, 8–21.
(<a href="https://doi.org/10.1016/j.ins.2020.12.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain , as a potentially revolutionary technology, has been used in cryptocurrency to record transactions chronologically among multiple parties. Due to the fast development of the blockchain and its de-centralization, blockchain technology has been applied in broader scenarios, such as smart factories, supply chains, and smart cities. Consensus protocol plays a vital role in the blockchain, which addresses the issue of reaching consensus on transaction results among involved participants. Nevertheless, with the complexity of the network environment and growing amount of network users, the advance of blockchain is gradually restricted by the efficiency, security and reliability of consensus protocols. In this paper, we propose a delegated randomization Byzantine fault tolerance consensus protocol named DRBFT based on Practical Byzantine Fault Tolerance (PBFT) to enhance the efficiency and reliability of the consensus procedure. Specifically, a random selection algorithm called RS is developed to cooperate with the voting mechanism, which can effectively reduce the number of nodes participating in the consensus process. Our proposed scheme is characterized by the unpredictability, randomicity and impartiality, which accelerate the system to reach consensus on the premise of ensuring the system activity. Furthermore, the feasibility of our proposed scheme is also proved by both theoretical analysis and experimental evaluations.},
  archive      = {J_ISCI},
  author       = {Yu Zhan and Baocang Wang and Rongxing Lu and Yong Yu},
  doi          = {10.1016/j.ins.2020.12.077},
  journal      = {Information Sciences},
  pages        = {8-21},
  shortjournal = {Inf. Sci.},
  title        = {DRBFT: Delegated randomization byzantine fault tolerance consensus protocol for blockchains},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A note on the cayley-menger determinant and the molecular
distance geometry problem. <em>ISCI</em>, <em>559</em>, 1–7. (<a
href="https://doi.org/10.1016/j.ins.2020.12.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using information from protein geometry and distance data provided by Nuclear Magnetic Resonance (NMR) experiments, the Molecular Distance Geometry Problem (MDGP) can be solved by a combinatorial approach , called Branch-and-Prune (BP). The primal version of BP algorithm seeks MDGP graph realizations, while the dual BP looks for completions of associated partial distance matrices . These two algorithms are very similar when distance values are precise. In the literature, there are some proposals for extending the primal BP to take care of NMR uncertainties. Using Cayley-Menger determinant, we present a global optimization approach that also allows the dual BP to deal with NMR uncertainties.},
  archive      = {J_ISCI},
  author       = {Luiz Leduino de Salles Neto and Carlile Lavor and Weldon Lodwick},
  doi          = {10.1016/j.ins.2020.12.072},
  journal      = {Information Sciences},
  pages        = {1-7},
  shortjournal = {Inf. Sci.},
  title        = {A note on the cayley-menger determinant and the molecular distance geometry problem},
  volume       = {559},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extracting salient features from convolutional
discriminative filters. <em>ISCI</em>, <em>558</em>, 265–279. (<a
href="https://doi.org/10.1016/j.ins.2020.12.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNN) have been widely used in various tasks, largely due to their ability to efficiently extract n-gram features for text analysis and document representation. In this paper, we intend to insight the CNN model regarding its capability on text analysis. Vanilla CNNs do have weaknesses when it comes to the representation and feature extraction. Duplicate filters are inevitable with vanilla CNNs, which reduces the discriminative power of the representations. In addition, the current pooling operations either limit the CNN to the local optimum (i.e., max pooling) or they do not consider the importance of all features (i.e., mean pooling). In this paper, we propose two modules for vanilla CNNs to overcome these shortcomings. The first equips the CNN with discriminative filters (distinct filters with maximised divergence) and the second provides the ability to comprehensively extract all salient features . Specifically, our model increases the discriminative power of the model by maximizing the distance between different filters, and a novel global pooling mechanism for feature extraction. Validation tests against state-of-the-art baselines on five benchmark classification datasets achieve the competitive performance of our proposed model. Furthermore, visualization on upgrade filters and pooling features verify our hypothesis that the proposed model can receive discriminative filters and salient features.},
  archive      = {J_ISCI},
  author       = {Yuxiang Zhou and Lejian Liao and Yang Gao and Heyan Huang},
  doi          = {10.1016/j.ins.2020.12.084},
  journal      = {Information Sciences},
  pages        = {265-279},
  shortjournal = {Inf. Sci.},
  title        = {Extracting salient features from convolutional discriminative filters},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient key-dependent dynamic s-boxes based on permutated
elliptic curves. <em>ISCI</em>, <em>558</em>, 246–264. (<a
href="https://doi.org/10.1016/j.ins.2021.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Key-dependent dynamic substitution boxes (S-boxes) are important building blocks of many image encryption schemes, in which a session key controls the construction of dynamic S-boxes. Frequently changing the dynamic S-boxes is necessary to improve security. However, the computational overhead of dynamic S-box construction limits the achievable encryption throughput. Therefore, minimizing the construction time of dynamic S-boxes is required. In this paper, we exploit key-dependent permutations over finite elliptic curves to present a novel computationally efficient method for dynamic S-box construction. Theoretical analysis shows that the proposed S-box construction method is immune to chosen-plaintext attacks. Analysis of an image encryption application using the proposed key-dependent S-box indicates resistance to statistical, related key, and chosen-plaintext attacks. Experimental results show that the proposed method is asymptotically an order-of-magnitude faster than relevant methods. A dynamic S-box with 512-bit key can be generated by the proposed method in 0.76 ms, paving the way to reach 1 GB/s encryption throughput. Results show that the generated S-boxes satisfy the standard S-box security criteria and have a competitive nonlinearity distribution compared with rival methods.},
  archive      = {J_ISCI},
  author       = {Saleh Ibrahim and Alaa M. Abbas},
  doi          = {10.1016/j.ins.2021.01.014},
  journal      = {Information Sciences},
  pages        = {246-264},
  shortjournal = {Inf. Sci.},
  title        = {Efficient key-dependent dynamic S-boxes based on permutated elliptic curves},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Cost-sensitive positive and unlabeled learning.
<em>ISCI</em>, <em>558</em>, 229–245. (<a
href="https://doi.org/10.1016/j.ins.2021.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Positive and Unlabeled learning (PU learning) aims to train a binary classifier solely based on positively labeled and unlabeled data when negatively labeled data are absent or distributed too diversely. However, none of the existing PU learning methods takes the class imbalance problem into account, which significantly neglects the minority class and is likely to generate a biased classifier. Therefore, this paper proposes a novel algorithm termed “ C ost- S ensitive P ositive and U nlabeled learning” (CSPU) which imposes different misclassification costs on different classes when conducting PU classification. Specifically, we assign distinct weights to the losses caused by false negative and false positive examples, and employ double hinge loss to build our CSPU algorithm under the framework of empirical risk minimization . Theoretically, we analyze the computational complexity , and also derive a generalization error bound of CSPU which guarantees the good performance of our algorithm on test data. Empirically, we compare CSPU with the state-of-the-art PU learning methods on synthetic dataset , OpenML benchmark datasets, and real-world datasets. The results clearly demonstrate the superiority of the proposed CSPU to other comparators in dealing with class imbalanced tasks.},
  archive      = {J_ISCI},
  author       = {Xiuhua Chen and Chen Gong and Jian Yang},
  doi          = {10.1016/j.ins.2021.01.002},
  journal      = {Information Sciences},
  pages        = {229-245},
  shortjournal = {Inf. Sci.},
  title        = {Cost-sensitive positive and unlabeled learning},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PlexNet: A fast and robust ECG biometric system for human
recognition. <em>ISCI</em>, <em>558</em>, 208–228. (<a
href="https://doi.org/10.1016/j.ins.2021.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have explored the potential of electrocardiogram (ECG) to use as biometrics from past two decades. ECG has the inherent feature of vitality for securing the biometric system from fraudulent attacks. This paper proposes a novel ensemble of the state-of-the-art pre-trained deep neural networks i.e. , ResNet and DenseNet for ECG biometric recognition. The principle of transfer learning is utilized to prepare fine-tuned models. The gathered knowledge of four fine-tuned models is fused to prepare one stacking model i.e. , ‘PlexNet’. The PlexNet takes advantage of transfer learning along with ensemble learning , thus making a novel model for ECG biometrics that is robust and secure than other methods using deep networks. Two public datasets PTB and CYBHI are tested on the proposed ensemble for human identification. The experimental results demonstrate the efficacy of the model with identification accuracy reported the best as 99.66\% on healthy and unhealthy subjects. Finally, the proposed ECG biometric method proves its robustness from signal acquisition methods, size of datasets, and subject health statuses.},
  archive      = {J_ISCI},
  author       = {Ranjeet Srivastva and Ashutosh Singh and Yogendra Narain Singh},
  doi          = {10.1016/j.ins.2021.01.001},
  journal      = {Information Sciences},
  pages        = {208-228},
  shortjournal = {Inf. Sci.},
  title        = {PlexNet: A fast and robust ECG biometric system for human recognition},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous formation control of multiple rotorcrafts with
unknown dynamics by reinforcement learning. <em>ISCI</em>, <em>558</em>,
194–207. (<a href="https://doi.org/10.1016/j.ins.2021.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a distributed model-free solution based on reinforcement learning is proposed for the leader–follower formation control problem of heterogeneous multi-agent systems. The multi-agent system consists of multiple rotorcrafts involving a virtual leader and multiple followers, where the dynamics of leaders and followers is unknown. The formation control problem is firstly formulated as an optimal output regulation problem. A discounted performance function is then introduced to guarantee that the tracking error asymptotically converges to zero, and an online off-policy reinforcement learning algorithm is proposed to solve the optimal output problem online using the data generated along the trajectories of the agents. A simulation example is provided to validate the effectiveness of the proposed control method.},
  archive      = {J_ISCI},
  author       = {Hao Liu and Fachun Peng and Hamidreza Modares and Bahare Kiumarsi},
  doi          = {10.1016/j.ins.2021.01.011},
  journal      = {Information Sciences},
  pages        = {194-207},
  shortjournal = {Inf. Sci.},
  title        = {Heterogeneous formation control of multiple rotorcrafts with unknown dynamics by reinforcement learning},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discovering three-dimensional patterns in real-time from
data streams: An online triclustering approach. <em>ISCI</em>,
<em>558</em>, 174–193. (<a
href="https://doi.org/10.1016/j.ins.2020.12.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Triclustering algorithms group sets of coordinates of 3-dimensional datasets. In this paper, a new triclustering approach for data streams is introduced. It follows a streaming scheme of learning in two steps: offline and online phases. First, the offline phase provides a summary model with the components of the triclusters. Then, the second stage is the online phase to deal with data in streaming. This online phase consists in using the summary model obtained in the offline stage to update the triclusters as fast as possible with genetic operators. Results using three types of synthetic datasets and a real-world environmental sensor dataset are reported. The performance of the proposed triclustering streaming algorithm is compared to a batch triclustering algorithm, showing an accurate performance both in terms of quality and running times.},
  archive      = {J_ISCI},
  author       = {Laura Melgar-García and David Gutiérrez-Avilés and Cristina Rubio-Escudero and Alicia Troncoso},
  doi          = {10.1016/j.ins.2020.12.089},
  journal      = {Information Sciences},
  pages        = {174-193},
  shortjournal = {Inf. Sci.},
  title        = {Discovering three-dimensional patterns in real-time from data streams: An online triclustering approach},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating mini-batch SARAH by step size rules.
<em>ISCI</em>, <em>558</em>, 157–173. (<a
href="https://doi.org/10.1016/j.ins.2020.12.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {StochAstic Recursive grAdient algoritHm (SARAH), originally proposed for convex optimization and also proven to be effective for general nonconvex optimization, has received great attention because of its simple recursive framework for updating stochastic gradient estimates. The performance of SARAH significantly depends on the choice of the step size sequence. However, SARAH and its variants often manually select a best-tuned step size, which is time consuming in practice. Motivated by this gap, we propose a variant of the Barzilai-Borwein (BB) method, referred to as the Random Barzilai-Borwein (RBB) method, to determine the step size for SARAH in the mini-batch setting, leading to a new SARAH method: MB-SARAH-RBB. We prove that MB-SARAH-RBB converges linearly in expectation for strongly convex objective functions. Moreover, we analyze the gradient complexity of MB-SARAH-RBB and show that it is better than the original method. To further confirm the efficacy of the RBB method, we propose the MB-SARAH+-RBB method, by incorporating it into the MB-SARAH + method. Numerical experiments on standard data sets indicate that our proposed methods outperform or match state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Zhuang Yang and Zengping Chen and Cheng Wang},
  doi          = {10.1016/j.ins.2020.12.075},
  journal      = {Information Sciences},
  pages        = {157-173},
  shortjournal = {Inf. Sci.},
  title        = {Accelerating mini-batch SARAH by step size rules},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy adaptive output feedback control for uncertain
nonlinear systems with unknown control gain functions and unmodeled
dynamics. <em>ISCI</em>, <em>558</em>, 140–156. (<a
href="https://doi.org/10.1016/j.ins.2020.12.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the fuzzy adaptive robust output feedback control issues are investigated for single-input single-output (SISO) strict-feedback nonlinear systems . The controlled systems under consideration of this paper contain the unknown control gain functions, unmodeled dynamics and immeasurable states. The unknown nonlinear functions are be approximated by utilizing the fuzzy logic systems , and the immeasurable states are estimated by constructing a new fuzzy state observer. In order to handle the unknown control gain functions and the unmodeled dynamics problems , the Logarithm Lyapunov functions are constructed, under which a new fuzzy adaptive robust output feedback control scheme is proposed by using the adaptive backstepping control design technique and a dynamical signal function. The designed fuzzy adaptive control algorithm can ensure that the closed-loop system is semi-globally uniformly ultimately boundedness (SGUUB) and has the robustness to the unmodeled dynamics. Finally, a simulation example is considered to illustrate the availability of the designed controller.},
  archive      = {J_ISCI},
  author       = {Jipeng Zhao and Shaocheng Tong and Yongming Li},
  doi          = {10.1016/j.ins.2020.12.092},
  journal      = {Information Sciences},
  pages        = {140-156},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy adaptive output feedback control for uncertain nonlinear systems with unknown control gain functions and unmodeled dynamics},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BELIEF: A distance-based redundancy-proof feature selection
method for big data. <em>ISCI</em>, <em>558</em>, 124–139. (<a
href="https://doi.org/10.1016/j.ins.2020.12.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of Big Data era, data reduction methods are in highly demand given their ability to simplify huge data, and ease complex learning processes. Concretely, algorithms able to select relevant dimensions from a set of millions are of huge importance. Although effective, these techniques also suffer from the “scalability” curse when they are brought into tackle large-scale problems. In this paper, we propose a distributed feature weighting algorithm which precisely estimates feature importance in large datasets using the well-know algorithm RELIEF in small problems. Our solution, called BELIEF, incorporates a novel redundancy elimination measure that generates similar schemes to those based on entropy, but at a much lower time cost. Furthermore, BELIEF provides a smooth scale-up when more instances are required to increase precision in estimations. Empirical tests performed on our method illustrate the estimation ability of BELIEF in manifold huge sets – both in number of features and instances, as well as its reduced runtime cost as compared to other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {D. López and S. Ramírez-Gallego and S. García and N. Xiong and F. Herrera},
  doi          = {10.1016/j.ins.2020.12.082},
  journal      = {Information Sciences},
  pages        = {124-139},
  shortjournal = {Inf. Sci.},
  title        = {BELIEF: A distance-based redundancy-proof feature selection method for big data},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Membrane-based models for service selection in cloud.
<em>ISCI</em>, <em>558</em>, 103–123. (<a
href="https://doi.org/10.1016/j.ins.2020.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud service selection is one of the prime areas of research within the ambit of cloud computing , which has gained wide attention in the recent past. The service selection algorithm primarily involves selecting the best service from a set of available services, based on Quality of Service (QoS) attributes. The QoS attributes are the parameters which allow the users to ascertain the actual quality of the service, often quantitatively. Over the years, there have been several methods designed for service selection in the cloud that are primarily sequential, with many being sensitive to changes. Thus, the aim is to propose multiple robust and parallel models for cloud service selection. The proposed models are designed using Membrane Computing paradigm , which is an inherently parallel computing model, combined with the Improved Technique for Order of Preference by Similarity to Ideal Solution (ITOPSIS), a popular Multi-Criteria Decision Making Method. Two methods based on a tactical amalgamation of ITOPSIS and Enzymatic Numerical P System (A membrane computing device variant) structure are proposed here. The proposed parallel models are implemented, tested, and the obtained results are analyzed. The results indicate one model to be robust (less sensitive) and the other to be moderately sensitive.},
  archive      = {J_ISCI},
  author       = {S. Raghavan and K. Chandrasekaran},
  doi          = {10.1016/j.ins.2020.12.015},
  journal      = {Information Sciences},
  pages        = {103-123},
  shortjournal = {Inf. Sci.},
  title        = {Membrane-based models for service selection in cloud},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Pruning of generative adversarial neural networks for
medical imaging diagnostics with evolution strategy. <em>ISCI</em>,
<em>558</em>, 91–102. (<a
href="https://doi.org/10.1016/j.ins.2020.12.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Networks (DCNNs) have the potential to revolutionize the field of Medical Imaging Diagnostics due to their capabilities of learning by using only raw data. However, DCNNs can only learn when trained using thousands of data points, which is not always available when dealing with medical data. Moreover, due to patient privacy concerns and the small prevalence of certain diseases in the population, medical data often presents unbalanced classes and fewer data points than other data types. Researchers often rely on Generative Adversarial Networks (GANs) to synthesize more data from a given distribution to solve this problem. Nevertheless, GANs are computationally intensive models requiring the use of powerful hardware to run. In the present work, an algorithm for pruning GANs based on Evolution Strategy (ES) and Multi-Criteria Decision Making (MCDM) is proposed in which a model with the best trade-off between computational complexity and synthesis performance can be found without the use of any trade-off parameter. In the proposed algorithm, the model with the best trade-off is defined geometrically as the candidate solution with the minimum Manhattan distance (MMD) in a two-dimensional objective space established by the number of Floating-Point Operations (FLOPs) and the Wasserstein distance of all candidate solutions, also known as the knee solution. The results show that the pruned GAN model achieves similar performance compared with the original model with up to 70\% fewer Floating-Point Operations.},
  archive      = {J_ISCI},
  author       = {Francisco Erivaldo Fernandes Jr. and Gary G. Yen},
  doi          = {10.1016/j.ins.2020.12.086},
  journal      = {Information Sciences},
  pages        = {91-102},
  shortjournal = {Inf. Sci.},
  title        = {Pruning of generative adversarial neural networks for medical imaging diagnostics with evolution strategy},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fusing attributed and topological global-relations for
network embedding. <em>ISCI</em>, <em>558</em>, 76–90. (<a
href="https://doi.org/10.1016/j.ins.2021.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding aims to learn a vector for each node while preserves inherent properties of the network. Topological structure and node attributes are both critical for understanding the network formulation. This paper focuses on making the topological and attributed properties complement each other. We propose FATNet for integrating the global relations of the topology and attributes into robust representations. Specifically, non-local attribute relations are proposed to capture long-distance dependencies for enriching the topological structure. Meanwhile, we design attributes smoothing filter to preserve the critical attribute values, while interpolating global topology relations via high-order proximity. These relations provide reasonable principles to fuse the structure and attribute for network embedding. Extensive experiments are carried out with five real-world datasets on four downstream tasks, including node classification , link prediction, node clustering and graph visualization. Experiments have shown that the FATNet can achieve superior performance in most cases.},
  archive      = {J_ISCI},
  author       = {Xin Sun and Yongbo Yu and Yao Liang and Junyu Dong and Claudia Plant and Christian Böhm},
  doi          = {10.1016/j.ins.2021.01.012},
  journal      = {Information Sciences},
  pages        = {76-90},
  shortjournal = {Inf. Sci.},
  title        = {Fusing attributed and topological global-relations for network embedding},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). H-polytope decomposition-based algorithm for continuous
optimization. <em>ISCI</em>, <em>558</em>, 50–75. (<a
href="https://doi.org/10.1016/j.ins.2020.12.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new fractal search space decomposition-based algorithm to address the issue of scaling up the divide and conquer approach to deal with large scale problems (up to 50 continuous decision variables). The proposed algorithm, called polyFrac, fractally decomposes the search space using hyper-polytopes. It allows moving throughout different granularity levels by only computing the average of vertices of a hyper-polytope to obtain the coordinates of the centroids . Only the most promising hyper-polytopes are decomposed into child-polytopes. Then, a simple deterministic local search (single solution-based metaheuristic) is used to perform the intensification process to find the best solution within the selected lowest hyper-polytope. The proposed algorithm performance is evaluated on the well-known SOCO 2011, CEC 2013, and CEC 2017 benchmarks and compared with 26 states of the art algorithms. A real-world optimization problem is also used to calibrate its performance. The obtained results show that polyFrac outperforms all the algorithms. Moreover, experimental results and analysis suggest that polyFrac is a highly competitive optimization algorithm for solving large-scale and complex optimization problems.},
  archive      = {J_ISCI},
  author       = {Ghazaleh Khodabandelou and Amir Nakib},
  doi          = {10.1016/j.ins.2020.12.090},
  journal      = {Information Sciences},
  pages        = {50-75},
  shortjournal = {Inf. Sci.},
  title        = {H-polytope decomposition-based algorithm for continuous optimization},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Positive opinion maximization in signed social networks.
<em>ISCI</em>, <em>558</em>, 34–49. (<a
href="https://doi.org/10.1016/j.ins.2020.12.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinion maximization is a kind of optimization method, which leverages a subset of influential nodes in social networks to spread user opinions towards the target product and eventually obtains the largest opinion propagation. The current propagation models on the opinion maximization mainly focus on the activated nodes and the static opinion formation process. However, they neglect the combination between the activated nodes and the dynamic opinion formation process. Moreover, previous studies are more attentive to the positive relationships among users. In the real scenario, negative relationships among users may damage the product reputation. Therefore, in this paper, we study positive opinion maximization by using an Activated Opinion Maximization Framework (AOMF) in signed social networks. The proposed AOMF is composed of three phases: i) the selection of candidate seed nodes, ii) the activated opinion formation process and iii) the determination of seed nodes. We first use an effective heuristic rule to select candidate seed nodes. To model the activation and dynamic opinion formation process of network nodes, we devise the activated opinion formation model based on the multi-stage linear threshold model and the Degroot model. Then, we calculate the opinion propagation of each candidate seed node by using the activated opinion formation model. Based on the candidate seed nodes and the activated opinion formation process, seed nodes are further determined. Finally, experimental results on six social network datasets demonstrate that the proposed method has superior potential opinions and positive ratio than the chosen benchmarks.},
  archive      = {J_ISCI},
  author       = {Qiang He and Lihong Sun and Xingwei Wang and Zhenkun Wang and Min Huang and Bo Yi and Yuantian Wang and Lianbo Ma},
  doi          = {10.1016/j.ins.2020.12.091},
  journal      = {Information Sciences},
  pages        = {34-49},
  shortjournal = {Inf. Sci.},
  title        = {Positive opinion maximization in signed social networks},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intrinsic dimension estimation based on local adjacency
information. <em>ISCI</em>, <em>558</em>, 21–33. (<a
href="https://doi.org/10.1016/j.ins.2021.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intrinsic dimension (ID) of a data set is crucial for data processing, especially for high-dimensional data sets. In order to obtain an accurate ID estimate, two neighborhoods of sample points with a radius ratio of k are considered. The ratio of the number of sample points contained in the two neighborhoods is denoted as ∊ q ∊ q∊ . When the data set is located on a d -dimensional submanifold in R D RD , the expected value of ∊ q ∊ q∊ is k d kd . Based on this consideration, we redefine the adjacency matrix by using the local adjacency information of sample points and propose a new ID estimation method known as ID( k ). The ID( k ) algorithm contains only one parameter, the scaling ratio k , and we outline the criterion through which the user can select an appropriate k value. We demonstrate the convergence of the new method both theoretically and experimentally. Experimental results from artificial and real data sets show that the estimates obtained by this new ID( k ) method are closer to the true intrinsic dimension than those derived using similar methods.},
  archive      = {J_ISCI},
  author       = {Haiquan Qiu and Youlong Yang and Benchong Li},
  doi          = {10.1016/j.ins.2021.01.017},
  journal      = {Information Sciences},
  pages        = {21-33},
  shortjournal = {Inf. Sci.},
  title        = {Intrinsic dimension estimation based on local adjacency information},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A visual analysis method of randomness for classifying and
ranking pseudo-random number generators. <em>ISCI</em>, <em>558</em>,
1–20. (<a href="https://doi.org/10.1016/j.ins.2020.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of new pseudo-random number generators (PRNGs) has steadily increased over the years. Commonly, PRNGs’ randomness is “measured” by using statistical pass/fail suite tests, but the question remains, which PRNG is the best when compared to others. Existing randomness tests lack means for comparisons between PRNGs, since they are not quantitatively analysing. It is, therefore, an important task to analyze the quality of randomness for each PRNG, or, in general, comparing the randomness property among PRNGs. In this paper, we propose a novel visual approach to analyze PRNGs randomness allowing for a ranking comparison concerning the PRNGs’ quality. Our analysis approach is applied to ensembles of time series which are outcomes of different PRNG runs. The ensembles are generated by using a single PRNG method with different parameter settings or by using different PRNG methods. We propose a similarity metric for PRNG time series for randomness and apply it within an interactive visual approach for analyzing similarities of PRNG time series and relating them to an optimal result of perfect randomness. The interactive analysis leads to an unsupervised classification, from which respective conclusions about the impact of the PRNGs’ parameters or rankings of PRNGs on randomness are derived. We report new findings using our approach in a study of randomness for state-of-the-art numerical PRNGs such as LCG, PCG, SplitMix, Mersenne Twister , and RANDU as well as chaos-based PRNG families such as K -Logistic map and K -Tent map with varying parameter K .},
  archive      = {J_ISCI},
  author       = {Jeaneth Machicao and Quynh Quang Ngo and Vladimir Molchanov and Lars Linsen and Odemir Bruno},
  doi          = {10.1016/j.ins.2020.10.041},
  journal      = {Information Sciences},
  pages        = {1-20},
  shortjournal = {Inf. Sci.},
  title        = {A visual analysis method of randomness for classifying and ranking pseudo-random number generators},
  volume       = {558},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-label classification with weighted classifier
selection and stacked ensemble. <em>ISCI</em>, <em>557</em>, 421–442.
(<a href="https://doi.org/10.1016/j.ins.2020.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification has attracted increasing attention in various applications, such as medical diagnosis and semantic annotation . With such trend, a large number of ensemble approaches have been proposed for multi-label classification tasks . Most of these approaches construct the ensemble members by using bagging schemes, but few stacked ensemble approaches are developed. Existing research on stacked ensemble approaches remains active, but several issues remain such as (1) little has been done to learn the weights of classifiers for classifier selection; (2) the relationship between pairwise label correlations and multi-label classification performance has not been investigated sufficiently. To address these issues, we propose a novel stacked ensemble approach that simultaneously exploits label correlations and the process of learning weights of ensemble members. In our approach, first, a weighted stacked ensemble with sparsity regularization is developed to facilitate classifier selection and ensemble members construction for multi-label classification. Second, in order to improve the classification performance, the pairwise label correlations are further considered for determining weights of these ensemble members. Finally, we develop an optimization algorithm based on both of the accelerated proximal gradient and the block coordinate descent techniques to achieve the optimal ensemble solution efficiently. Extensive experiments on publicly available datasets and real Cardiovascular and Cerebrovascular Disease datasets demonstrate that our proposed algorithm outperforms related state-of-the-art methods from perspectives of benchmarking and real-world applications.},
  archive      = {J_ISCI},
  author       = {Yuelong Xia and Ke Chen and Yun Yang},
  doi          = {10.1016/j.ins.2020.06.017},
  journal      = {Information Sciences},
  pages        = {421-442},
  shortjournal = {Inf. Sci.},
  title        = {Multi-label classification with weighted classifier selection and stacked ensemble},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance assessment and analysis of high-dimensional samples
using variational autoencoders. <em>ISCI</em>, <em>557</em>, 407–420.
(<a href="https://doi.org/10.1016/j.ins.2020.06.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important question in many machine learning applications is whether two samples arise from the same generating distribution . Although an old topic in Statistics , simple accept/reject decisions given by most hypothesis tests are often not enough: it is well known that the rejection of the null hypothesis does not imply that differences between the two groups are meaningful from a practical perspective. In this work, we present a novel nonparametric approach to visually assess the dissimilarity between the datasets that goes beyond two-sample testing. The key idea of our approach is to measure the distance between two (possibly) high-dimensional datasets using variational autoencoders . We also show how this framework can be used to create a formal statistical test to test the hypothesis that both samples arise from the same distribution. We evaluate both the distance measurement and hypothesis testing approaches on simulated and real world datasets. The results show that our approach is useful for data exploration (as it, for instance, allows for quantification of the discrepancy/separability between categories of images), which can be particularly helpful in early phases of the a machine learning pipeline.},
  archive      = {J_ISCI},
  author       = {Marco Inácio and Rafael Izbicki and Bálint Gyires-Tóth},
  doi          = {10.1016/j.ins.2020.06.065},
  journal      = {Information Sciences},
  pages        = {407-420},
  shortjournal = {Inf. Sci.},
  title        = {Distance assessment and analysis of high-dimensional samples using variational autoencoders},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient top-k high utility itemset mining on massive data.
<em>ISCI</em>, <em>557</em>, 382–406. (<a
href="https://doi.org/10.1016/j.ins.2020.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, top- k high utility itemset mining (top- k HUIM) is an interesting operation to find the k itemsets with the highest utilities. It is analyzed that, the existing algorithms only can deal with the small and medium-sized data, and their performance degrades significantly on massive data. This paper presents a novel top- k HUIM algorithm PTM which can mine top- k high utility itemsets on massive data efficiently. PTM maintains the transaction database as a set of prefix-based partitions, each of which can fit in the memory and keeps the transactions with the same prefix item. The utility of an itemset can be computed by the transactions in one particular partition. PTM processes the prefix-based partitions in the order of average transaction utility to raise utility threshold faster. By the concise assistant data structures , PTM can skip majority of the partitions directly. For the partitions to be processed, PTM utilizes depth-first search on the set enumeration tree of the promising items to find the required results. The full-suffix-utility-based subtree pruning rule is devised to reduce the exploration space of set enumeration tree effectively. The extensive experimental results show that PTM can discover the top- k high utility itemsets on massive data efficiently.},
  archive      = {J_ISCI},
  author       = {Xixian Han and Xianmin Liu and Jianzhong Li and Hong Gao},
  doi          = {10.1016/j.ins.2020.08.028},
  journal      = {Information Sciences},
  pages        = {382-406},
  shortjournal = {Inf. Sci.},
  title        = {Efficient top-k high utility itemset mining on massive data},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel approach for panel data: An ensemble of weighted
functional margin SVM models. <em>ISCI</em>, <em>557</em>, 373–381. (<a
href="https://doi.org/10.1016/j.ins.2019.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble machine learning methods are frequently used for classification problems and it is known that they may boost the prediction accuracy. Support Vector Machines are widely used as base classifiers during the construction of different types of ensembles. In this study, we have constructed a weighted functional margin classifier ensemble on panel financial ratios to discriminate between solid and unhealthy banks for Turkish commercial bank case. We proposed a novel ensemble generation method enhanced by a pruning strategy to increase the prediction performance and developed a novel aggregation approach for ensemble learning by using the idea of weighted sums. The prediction performances are compared with a panel logistic regression which is considered a benchmark method for panel data. The results show that the proposed ensemble method is more successful than the straight SVM and the classical generalized linear model approach.},
  archive      = {J_ISCI},
  author       = {Bi̇rsen Eygi Erdogan and Süreyya Özöğür-Akyüz and Pınar Karadayı Ataş},
  doi          = {10.1016/j.ins.2019.02.045},
  journal      = {Information Sciences},
  pages        = {373-381},
  shortjournal = {Inf. Sci.},
  title        = {A novel approach for panel data: An ensemble of weighted functional margin SVM models},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The weighted average multiexperton. <em>ISCI</em>,
<em>557</em>, 355–372. (<a
href="https://doi.org/10.1016/j.ins.2020.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Experton theory, a generalization of probabilistic set theory, that is of great usefulness to group decision analysis , was first proposed as a means of improving the processing and analysis of opinions issued by experts. This theory produces an information-fusion mathematical object , the experton, which can be used in predictive problems to justify decisions based on well-constructed reasoning. The aim of this paper is to present an aggregative method of several expertons, with the idea that some of the groups of experts involved in producing these expertons may have more influence than others in the decision-making process. In this article, we carry out an aggregation analysis of expertons, not experts, which culminates in the creation of a new mathematical object . This object, which is called the weighted average multiexperton, is coherent with an experton-type object created from a weighting of the initial data provided by all experts. Since the aggregation method presented has been devised to represent the decision-maker’s attitude regarding the importance of different groups of experts, this approach represents a new tool for dealing with group decision-making problems. Additionally, the study presents some properties of the new object. Finally, the paper ends with an application for business decision-making.},
  archive      = {J_ISCI},
  author       = {Salvador Linares-Mustarós and Joan Carles Ferrer-Comalat and Dolors Corominas-Coll and Jose M. Merigó},
  doi          = {10.1016/j.ins.2020.08.029},
  journal      = {Information Sciences},
  pages        = {355-372},
  shortjournal = {Inf. Sci.},
  title        = {The weighted average multiexperton},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A constrained agglomerative clustering approach for
unipartite and bipartite networks with application to credit networks.
<em>ISCI</em>, <em>557</em>, 332–354. (<a
href="https://doi.org/10.1016/j.ins.2019.12.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers and practitioners have been interested in solving real-world problems through clustering. The clustering of nodes in networks with unipartite or bipartite structure is important to explore real-world complex networks present in nature and society. Bipartite networks form an important class of complex networks because they reveal the heterogeneity of nodes in a network. However, most extant clustering methods focus only on unipartite networks. In this work, a novel constrained agglomerative clustering method applicable to unipartite and bipartite networks has been proposed. Initially, the topology of a network is modeled according to set-theoretic principles. Subsequently, the concepts related to rough set theory and relative linkage are used to cluster the set of nodes. The utility and effectiveness of the proposed approach are demonstrated through offline experiments on unipartite and bipartite networks. A comparison against ten state-of-the-art similarity measures over two different partitional clustering algorithms reveals the effectiveness of the proposed relative linkage measure. Moreover, a comparative analysis with state-of-the-art network clustering methods reveals the viability of the proposed rough set-based constrained agglomerative clustering algorithm. Finally, the proposed method has been applied for the detection of cohesive subgroups of banks in a real bipartite network formed by mapping credit relationships between Indian firms and banks.},
  archive      = {J_ISCI},
  author       = {Samrat Gupta and Pradeep Kumar},
  doi          = {10.1016/j.ins.2019.12.085},
  journal      = {Information Sciences},
  pages        = {332-354},
  shortjournal = {Inf. Sci.},
  title        = {A constrained agglomerative clustering approach for unipartite and bipartite networks with application to credit networks},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining unsupervised and supervised learning in credit
card fraud detection. <em>ISCI</em>, <em>557</em>, 317–331. (<a
href="https://doi.org/10.1016/j.ins.2019.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised learning techniques are widely employed in credit card fraud detection, as they make use of the assumption that fraudulent patterns can be learned from an analysis of past transactions. The task becomes challenging, however, when it has to take account of changes in customer behavior and fraudsters’ ability to invent novel fraud patterns. In this context, unsupervised learning techniques can help the fraud detection systems to find anomalies. In this paper we present a hybrid technique that combines supervised and unsupervised techniques to improve the fraud detection accuracy. Unsupervised outlier scores, computed at different levels of granularity , are compared and tested on a real, annotated, credit card fraud detection dataset. Experimental results show that the combination is efficient and does indeed improve the accuracy of the detection.},
  archive      = {J_ISCI},
  author       = {Fabrizio Carcillo and Yann-Aël Le Borgne and Olivier Caelen and Yacine Kessaci and Frédéric Oblé and Gianluca Bontempi},
  doi          = {10.1016/j.ins.2019.05.042},
  journal      = {Information Sciences},
  pages        = {317-331},
  shortjournal = {Inf. Sci.},
  title        = {Combining unsupervised and supervised learning in credit card fraud detection},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HOBA: A novel feature engineering methodology for credit
card fraud detection with a deep learning architecture. <em>ISCI</em>,
<em>557</em>, 302–316. (<a
href="https://doi.org/10.1016/j.ins.2019.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit card transaction fraud costs billions of dollars to card issuers every year. A well-developed fraud detection system with a state-of-the-art fraud detection model is regarded as essential to reducing fraud losses. The main contribution of our work is the development of a fraud detection system that employs a deep learning architecture together with an advanced feature engineering process based on homogeneity-oriented behavior analysis (HOBA). Based on a real-life dataset from one of the largest commercial banks in China, we conduct a comparative study to assess the effectiveness of the proposed framework. The experimental results illustrate that our proposed methodology is an effective and feasible mechanism for credit card fraud detection. From a practical perspective, our proposed method can identify relatively more fraudulent transactions than the benchmark methods under an acceptable false positive rate. The managerial implication of our work is that credit card issuers can apply the proposed methodology to efficiently identify fraudulent transactions to protect customers’ interests and reduce fraud losses and regulatory costs.},
  archive      = {J_ISCI},
  author       = {Zhang Xinwei and Han Yaoci and Wei Xu and Wang Qili},
  doi          = {10.1016/j.ins.2019.05.023},
  journal      = {Information Sciences},
  pages        = {302-316},
  shortjournal = {Inf. Sci.},
  title        = {HOBA: A novel feature engineering methodology for credit card fraud detection with a deep learning architecture},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Targeting customers for profit: An ensemble learning
framework to support marketing decision-making. <em>ISCI</em>,
<em>557</em>, 286–301. (<a
href="https://doi.org/10.1016/j.ins.2019.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Marketing messages are most effective if they reach the right customers. Deciding which customers to contact is an important task in campaign planning. The paper focuses on empirical targeting models. We argue that common practices to develop such models do not account sufficiently for business goals. To remedy this, we propose profit-conscious ensemble selection, a modeling framework that integrates statistical learning principles and business objectives in the form of campaign profit maximization. Studying the interplay between data-driven learning methods and their business value in real-world application contexts, the paper contributes to the emerging field of profit analytics and provides original insights how to implement profit analytics in marketing. The paper also estimates the degree to which profit-concious modeling adds to the bottom line. The results of a comprehensive empirical study confirm the business value of the proposed ensemble learning framework in that it recommends substantially more profitable target groups than several benchmarks.},
  archive      = {J_ISCI},
  author       = {Stefan Lessmann and Johannes Haupt and Kristof Coussement and Koen W. De Bock},
  doi          = {10.1016/j.ins.2019.05.027},
  journal      = {Information Sciences},
  pages        = {286-301},
  shortjournal = {Inf. Sci.},
  title        = {Targeting customers for profit: An ensemble learning framework to support marketing decision-making},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tcc2vec: RFM-informed representation learning on call graphs
for churn prediction. <em>ISCI</em>, <em>557</em>, 270–285. (<a
href="https://doi.org/10.1016/j.ins.2019.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying social network analytics for telco churn prediction has become indispensable for almost a decade. However, in the current literature, the uptake does not reflect in a significantly increased leverage of the available information that these networks convey. First, network featurization in general is a very cumbersome process due to the complex nature of networks and the lack of a respective methodology. This results in ad hoc approaches and hand-crafted features. Second, deriving certain structural features in very large graphs is computationally expensive and, as a consequence, often neglected. Third, call networks are mostly treated as static in spite of their inherently dynamic nature. In this study, we propose tcc2vec , a panoptic approach aiming at devising representation learning (to address the first problem) on enriched call networks that integrate interaction and structural information (to overcome the second problem), which are being sliced in different time periods in order to account for different temporal granularities (hence addressing the third problem). In an extensive experimental analysis, insights are provided regarding an optimal choice of interaction and temporal granularities , as well as representation learning parameters.},
  archive      = {J_ISCI},
  author       = {Sandra Mitrović and Bart Baesens and Wilfried Lemahieu and Jochen De Weerdt},
  doi          = {10.1016/j.ins.2019.02.044},
  journal      = {Information Sciences},
  pages        = {270-285},
  shortjournal = {Inf. Sci.},
  title        = {Tcc2vec: RFM-informed representation learning on call graphs for churn prediction},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial letter special issue “business analytics –
emerging trends and challenges.” <em>ISCI</em>, <em>557</em>, 268–269.
(<a href="https://doi.org/10.1016/j.ins.2021.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  doi          = {10.1016/j.ins.2021.01.032},
  journal      = {Information Sciences},
  pages        = {268-269},
  shortjournal = {Inf. Sci.},
  title        = {Editorial letter special issue “Business analytics – emerging trends and challenges”},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regional input-to-state stabilization of fuzzy state-delayed
discrete-time systems with saturating actuators. <em>ISCI</em>,
<em>557</em>, 250–267. (<a
href="https://doi.org/10.1016/j.ins.2020.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the regional input-to-state stabilization of discrete-time Takagi-Sugeno fuzzy models under delayed state, saturating actuators, and external energy bounded disturbances . We propose a convex method to design state feedback-based non-parallel distributed compensation, ensuring the fuzzy closed-loop system’s regional stability. Moreover, we introduce a geometrical estimate of the region of attraction in an augmented space, allowing a more extensive set of safe initial sequences. Furthermore, the minimization of the ℓ 2 ℓ2 -gain from the external disturbance to the controlled output ensures closed-loop performance. Also, we provide optimization procedures allowing the maximization of the estimate of the region of attraction or the disturbance energy tolerance. By employing numerical examples, we compare our approach with similar ones found in the literature, showing our proposal’s efficacy, and its outperform concerning the compared methods.},
  archive      = {J_ISCI},
  author       = {Luís F.P. Silva and Valter J.S. Leite and Eugênio B. Castelan and Carla de Souza},
  doi          = {10.1016/j.ins.2020.12.043},
  journal      = {Information Sciences},
  pages        = {250-267},
  shortjournal = {Inf. Sci.},
  title        = {Regional input-to-state stabilization of fuzzy state-delayed discrete-time systems with saturating actuators},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A switched fuzzy filter approach to h∞ filtering for
takagi-sugeno fuzzy markov jump systems with time delay: The
continuous-time case. <em>ISCI</em>, <em>557</em>, 236–249. (<a
href="https://doi.org/10.1016/j.ins.2021.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the H ∞ H∞ filtering problem for continuous-time T-S fuzzy Markov jump systems with time-varying delay. A switched fuzzy filter approach is proposed for the first time to improve the previous filter solutions independent of the derivative of fuzzy membership functions (FMFs). Furthermore, a novel delay-product-type FMFs-dependent Lyapunov-Krasovskii functional (LKF) is constructed to make full use of the information on FMFs and time delay simultaneously. A parameter-dependent reciprocally convex inequality (PDRCI) is proposed to more accurately estimate the delay-product-type FMFs-dependent LKF. Based on these ingredients, the existence condition and explicit design method of fuzzy H ∞ H∞ filter are both given. Two examples are employed to illustrate the effectiveness of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Yufeng Tian and Zhanshan Wang},
  doi          = {10.1016/j.ins.2021.01.018},
  journal      = {Information Sciences},
  pages        = {236-249},
  shortjournal = {Inf. Sci.},
  title        = {A switched fuzzy filter approach to h∞ filtering for takagi-sugeno fuzzy markov jump systems with time delay: The continuous-time case},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A blockchain-based approach for matching desired and real
privacy settings of social network users. <em>ISCI</em>, <em>557</em>,
220–235. (<a href="https://doi.org/10.1016/j.ins.2021.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social networks store a considerable amount of personal data, which are also a source of information for business. To comply with users’ privacy rights, all social networks allow users to select the level of privacy they desire. However, what occurs if the privacy choices of a user are modified unilaterally by the social network? The privacy settings chosen by the user are stored by the social network, which acts as a privileged party , which could tamper with the user’s choices at any time. This paper addresses this problem and proposes a decentralized approach to manage the privacy settings of a user. Any change in the privacy settings of a social network user is validated by a smart contract to ensure that it is compliant with users’ expectations. The proposed solution has been implemented as an Ethereum-based decentralized application to validate the effectiveness of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Gianluca Lax and Antonia Russo and Lara Saidia Fascì},
  doi          = {10.1016/j.ins.2021.01.004},
  journal      = {Information Sciences},
  pages        = {220-235},
  shortjournal = {Inf. Sci.},
  title        = {A blockchain-based approach for matching desired and real privacy settings of social network users},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-stage hierarchical clustering algorithm based on
centroid of tree and cut edge constraint. <em>ISCI</em>, <em>557</em>,
194–219. (<a href="https://doi.org/10.1016/j.ins.2020.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The minimum spanning tree clustering algorithm is known to be capable of detecting clusters with irregular boundaries. The paper presents a novel hierarchical clustering algorithm based on minimum spanning tree (MST), which tends to reduce the complexity of the merging process with guaranteed clustering performance. There are two core ideas in the proposed method: (1) The inter-cluster distance is calculated with the centroid of MST instead of the center of cluster. (2) The length of cut edge at the intersection of two adjacent clusters is taken as a merge condition. Based on this idea, we propose a three-stage MST-based hierarchical clustering algorithm (CTCEHC). In Stage 1, a preliminary partition is performed with the degrees of vertices in MST. In Stage 2, small subclusters are merged via the geodesic distance between the centroids of MST in two clusters and the cut edge constraint I. In Stage 3, the adjacent cluster pairs satisfying the cut edge constraint II are merged. The experimental results on the synthetic data sets and real data sets demonstrate a good performance of the proposed clustering method .},
  archive      = {J_ISCI},
  author       = {Yan Ma and Hongren Lin and Yan Wang and Hui Huang and Xiaofu He},
  doi          = {10.1016/j.ins.2020.12.016},
  journal      = {Information Sciences},
  pages        = {194-219},
  shortjournal = {Inf. Sci.},
  title        = {A multi-stage hierarchical clustering algorithm based on centroid of tree and cut edge constraint},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An agglomerative hierarchical clustering algorithm for
linear ordinal rankings. <em>ISCI</em>, <em>557</em>, 170–193. (<a
href="https://doi.org/10.1016/j.ins.2020.12.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly proposes a new method for clustering linear ordinal ranking (LOR) information by agglomerative hierarchical clustering (AHC) algorithm. Considering that the cores of the AHC algorithm for LOR clustering are the difference measure among different LORs and the aggregation of the individual LORs, we firstly systematically analyze the existing studies for LOR distance measure, based on which we extend the method to depict LORs. Subsequently, the corresponding new distance measure is proposed starting from the perspective of utilizing the rankings’ position information and relationship information together. In addition, we simplify the dominating index and dominated index-based aggregation method for LORs fusion. Further, we present a numerical case on online financial product recommendation to illustrate the usage of the algorithm and also try to provide a feasible way for online financial product recommendation. Then, we make some discussions on the proposed distance measure and the aggregation method under the framework of the AHC algorithm to show the features of the algorithm proposed in this paper.},
  archive      = {J_ISCI},
  author       = {Nana Liu and Zeshui Xu and Xiao-Jun Zeng and Peijia Ren},
  doi          = {10.1016/j.ins.2020.12.056},
  journal      = {Information Sciences},
  pages        = {170-193},
  shortjournal = {Inf. Sci.},
  title        = {An agglomerative hierarchical clustering algorithm for linear ordinal rankings},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time fuzzy adaptive quantized output feedback control
of triangular structural systems. <em>ISCI</em>, <em>557</em>, 153–169.
(<a href="https://doi.org/10.1016/j.ins.2020.12.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a finite-time fuzzy adaptive quantized control scheme for a class of triangular structural nonlinear systems . Specifically, a smooth function with intermediate control law is introduced in the modified backstepping recursive process to eliminate the effect of quantization. The output constraints issue is solved by employing a barrier Lyapunov function . Then, a command filter is applied to avoid repeatedly differentiating virtual control signals and reduce the computational complexity. Moreover, the proposed method can guarantee that the tracking error converges to a small neighborhood of the origin in the finite time. Finally, the performance and the effectiveness of the proposed method are demonstrated via simulation results.},
  archive      = {J_ISCI},
  author       = {Kangkang Sun and Hamid Reza Karimi and Jianbin Qiu},
  doi          = {10.1016/j.ins.2020.12.059},
  journal      = {Information Sciences},
  pages        = {153-169},
  shortjournal = {Inf. Sci.},
  title        = {Finite-time fuzzy adaptive quantized output feedback control of triangular structural systems},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FastForest: Increasing random forest processing speed while
maintaining accuracy. <em>ISCI</em>, <em>557</em>, 130–152. (<a
href="https://doi.org/10.1016/j.ins.2020.12.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Random Forest remains one of Data Mining’s most enduring ensemble algorithms, achieving well-documented levels of accuracy and processing speed, as well as regularly appearing in new research. However, with data mining now reaching the domain of hardware-constrained devices such as smartphones and Internet of Things (IoT) devices, there is continued need for further research into algorithm efficiency to deliver greater processing speed without sacrificing accuracy. Our proposed FastForest algorithm achieves this result through a combination of three optimising components - Subsample Aggregating (‘Subbagging’), Logarithmic Split-Point Sampling and Dynamic Restricted Subspacing. Empirical testing shows FastForest delivers an average 24\% increase in model-training speed compared with Random Forest whilst maintaining (and frequently exceeding) classification accuracy over tests involving 45 datasets on both PC and smartphone platforms. Further tests show FastForest achieves favourable results against a number of ensemble classifiers including implementations of Bagging and Random Subspace. With growing interest in machine-learning on mobile devices , FastForest provides an efficient ensemble classifier that can achieve faster results on hardware-constrained devices, such as smartphones.},
  archive      = {J_ISCI},
  author       = {Darren Yates and Md Zahidul Islam},
  doi          = {10.1016/j.ins.2020.12.067},
  journal      = {Information Sciences},
  pages        = {130-152},
  shortjournal = {Inf. Sci.},
  title        = {FastForest: Increasing random forest processing speed while maintaining accuracy},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A secure and privacy-preserving protocol for holding double
auctions in smart grid. <em>ISCI</em>, <em>557</em>, 108–129. (<a
href="https://doi.org/10.1016/j.ins.2020.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most used types of auctions in the smart grid is the double auction, in which both buyers and sellers can respectively submit their bids and asks to participate in the auction. In recent years, many schemes have been designed to propose a double auction mechanism for the smart grids; however, few of these schemes consider the information security aspects and users’ privacy. In this paper, we propose a protocol that helps different double auction mechanisms be implemented securely in the smart grids. This protocol not only can satisfy the security requirements of a double auction scheme but is also compatible with the smart grid technologies . In this scheme, in order to preserve the users’ anonymity and privacy, a pseudo-identity is assigned to each participant, and the bids/asks are encrypted using the Paillier cryptosystem . By virtue of the Pedersen commitment scheme used in this paper, the participants can be verified as having correctly and honestly followed the auction protocol. Moreover, the theoretical analysis and implementation results show that the proposed scheme can be considered as an efficient scheme for the smart grid entities involved in the auction process.},
  archive      = {J_ISCI},
  author       = {Roozbeh Sarenche and Mahmoud Salmasizadeh and Mohammad Hassan Ameri and Mohammad Reza Aref},
  doi          = {10.1016/j.ins.2020.12.038},
  journal      = {Information Sciences},
  pages        = {108-129},
  shortjournal = {Inf. Sci.},
  title        = {A secure and privacy-preserving protocol for holding double auctions in smart grid},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing vehicle routing via stackelberg game framework
and distributionally robust equilibrium optimization method.
<em>ISCI</em>, <em>557</em>, 84–107. (<a
href="https://doi.org/10.1016/j.ins.2020.12.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the vehicle routing problem (VRP) with multiple firms in depot with focus on the carbon cap-and-trade policy. By establishing the upper-level carbon trading revenue model from the government’s perspective and the lower-level model from the firm’s perspective, we describe the VRP based on the Stackelberg game framework. In addition, a traffic density objective is put forward. As a consequence, the lower-level model is a double objective optimization model including transportation cost and traffic density. Due to the influence of uncontrollable factors, the batches of distributed vehicles are uncertain and characterized as random fuzzy variables with uncertain credibility distribution. To address this situation, we propose a new distributionally robust equilibrium optimization (DREO) method, in which it describes the existence range of the real credibility distribution by constructing the uncertainty distribution set. For a given specific uncertainty distribution set, we derive its equivalent formulation for the proposed method. Moreover, given the single-period, we reduce the derived model to a single-layer multi-criteria optimization model by using the parameter-driven approach, so as to avoid solving the complicated original model. Besides, we analyze dynamic process of the multi-period Stackelberg game model. Finally, we apply a lexicographic optimization algorithm to solve the proposed model under the single-period, thereby verifying its effectiveness and also obtaining some promising results.},
  archive      = {J_ISCI},
  author       = {Fanghao Yin and Yi Zhao},
  doi          = {10.1016/j.ins.2020.12.057},
  journal      = {Information Sciences},
  pages        = {84-107},
  shortjournal = {Inf. Sci.},
  title        = {Optimizing vehicle routing via stackelberg game framework and distributionally robust equilibrium optimization method},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent scheme for big data recovery in internet of
things based on multi-attribute assistance and extremely randomized
trees. <em>ISCI</em>, <em>557</em>, 66–83. (<a
href="https://doi.org/10.1016/j.ins.2020.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the inherent characteristics of sensor nodes in Internet of Things , such as constrained energy, data redundancy , limited communication range and computing capabilities, the data loss problem becomes one key issue for applications which depends heavily on the data completeness. Some of the current solutions, such as interpolation, are designed to use data correlation for the data recovery problem. Spatiotemporal correlation is an important characteristic of sensory data since the nodes are generally deployed to observed similar physical phenomenon. However, it is very difficult to extract data correlation especially in case that the coupling degree between different perceptual attributes is low. Machine learning is an efficient auto-learning method that can obtain the inherent rules automatically. This paper has proposed an intelligent recovery scheme for big data in Internet of Things based on Multi-Attribute assistance and Extremely randomized Trees (MAET). Firstly, the collected dataset is denoised by detecting and removing the outliers. Secondly, the slave attributes are chosen whose correlations are high with the target attribute by using the Spearman correlation coefficient. Thirdly, the proposed scheme is trained by using extremely randomized trees with slave attributes. Finally, the missing data can be recovered with the trained model as well as the help of other attributes whose data is not lost. Experiment shows that the proposed scheme with multiple attributes is efficient and can improve the accuracy of recovered data compared with other algorithms.},
  archive      = {J_ISCI},
  author       = {Hongju Cheng and Yushi Shi and Leihuo Wu and Yingya Guo and Naixue Xiong},
  doi          = {10.1016/j.ins.2020.12.041},
  journal      = {Information Sciences},
  pages        = {66-83},
  shortjournal = {Inf. Sci.},
  title        = {An intelligent scheme for big data recovery in internet of things based on multi-attribute assistance and extremely randomized trees},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Edge computing and its role in industrial internet:
Methodologies, applications, and future directions. <em>ISCI</em>,
<em>557</em>, 34–65. (<a
href="https://doi.org/10.1016/j.ins.2020.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proliferation of Industrial Internet has dramatically changed the way we live and work. It brings convenience to our society and sometimes requires real-time processing of dramatic data at the same time. However, traditional paradigm of computing on the center cloud can’t always meet such requirement, for the non-negligible time delay of data transmission and communication. Edge computing is a novel computing paradigm proposed to resolve such a problem. As a promising technology, it extends computing from cloud center to the edge of network. Edge computing has the advantage of low latency to achieve a shorter response time, as well as potential to address the concerns of energy consuming, bandwidth burden and security issue. In this paper, we give a survey about edge computing from the aspect of methodologies, application scenarios and its role in Industrial Internet. Some open issues of edge computing are also introduced in this paper. At the end of the manuscript, a discussion about future direction is proposed. The shallow network algorithms such as broad learning system (BLS), which have achieved great improvement in computing efficiency, show an optimistic outlook in this area. We propose our conceive about future applications when shallow network methods like BLS are applied in edge computing and hope the paper will inspire research in relative directions.},
  archive      = {J_ISCI},
  author       = {Tong Zhang and Yikai Li and C.L. Philip Chen},
  doi          = {10.1016/j.ins.2020.12.021},
  journal      = {Information Sciences},
  pages        = {34-65},
  shortjournal = {Inf. Sci.},
  title        = {Edge computing and its role in industrial internet: Methodologies, applications, and future directions},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble learning from model based trees with application to
differential price sensitivity assessment. <em>ISCI</em>, <em>557</em>,
16–33. (<a href="https://doi.org/10.1016/j.ins.2020.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of price sensitivity is a relevant issue with important implications in decision making for revenue management . The issue has attracted interest among companies evolving towards the data-driven culture through the exploitation of their data sources. Thus, the design of pricing strategies that rely on analytics to identify groups of customers that exhibit differential price sensitivity has a great potential for revenue managers. This work proposes a data-driven approach, using ensemble learning from model based trees, to assess differential price sensitivity in a similar way as random forests algorithm does to assess variable importance. A differential price sensitivity score is defined and a ranking is obtained as a result so that the top ranked variables can be selected as candidate inputs for segmentation and differential price sensitivity group finding. Then optimal price allocation is carried out on the derived groups in order to compute the expected revenues which are compared with the revenues given by un-optimized prices and by optimal price allocation derived from the logit estimation of the bid response function. The proposed approach is validated in synthetic experiments and by application to the real business case of an auto lending company; the resulting revenues show its benefit.},
  archive      = {J_ISCI},
  author       = {Jorge M. Arevalillo},
  doi          = {10.1016/j.ins.2020.12.039},
  journal      = {Information Sciences},
  pages        = {16-33},
  shortjournal = {Inf. Sci.},
  title        = {Ensemble learning from model based trees with application to differential price sensitivity assessment},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metaheuristic-based possibilistic fuzzy k-modes algorithms
for categorical data clustering. <em>ISCI</em>, <em>557</em>, 1–15. (<a
href="https://doi.org/10.1016/j.ins.2020.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart devices and technology applications are used in many fields. Much information is now recorded and collected rapidly so data analysis, especially clustering analysis , is vital to the process of analyzing and obtaining valuable information from datasets. However, data has different types of attributes: numerical, categorical, and mixed attributes. Some datasets also contain noise and outliers. An appropriate clustering is necessary to exploit the data structure . This study proposes a clustering algorithm that is called a possibilistic fuzzy k -modes (PFKM) algorithm. This combines the concept of possibility with the fuzzy k -modes (FKM) algorithm to address the effect of outliers and to improve the clustering results for categorical data . This study also implements three metaheuristics to increase clustering performance: a genetic algorithm (GA), a particle swarm optimization (PSO) and the sine-cosine algorithm (SCA). Three clustering algorithms are proposed: the GA-PFKM, PSO-PFKM, and SCA-PFKM algorithms. The performance of the algorithms is compared with that for the classical FKM algorithm using two indices: the sum-of-squared error ( SSE ) and the accuracy. The experimental results show that the PSO-PFKM and SCA-PFKM algorithms perform better for most datasets.},
  archive      = {J_ISCI},
  author       = {R.J. Kuo and Y.R. Zheng and Thi Phuong Quyen Nguyen},
  doi          = {10.1016/j.ins.2020.12.051},
  journal      = {Information Sciences},
  pages        = {1-15},
  shortjournal = {Inf. Sci.},
  title        = {Metaheuristic-based possibilistic fuzzy k-modes algorithms for categorical data clustering},
  volume       = {557},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Paul wang: Pro memoria. <em>ISCI</em>, <em>556</em>, iii.
(<a href="https://doi.org/10.1016/S0020-0255(21)00221-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Witold Pedrycz},
  doi          = {10.1016/S0020-0255(21)00221-8},
  journal      = {Information Sciences},
  pages        = {iii},
  shortjournal = {Inf. Sci.},
  title        = {Paul wang: Pro memoria},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel decomposition-based multiobjective evolutionary
algorithm using improved multiple adaptive dynamic selection strategies.
<em>ISCI</em>, <em>556</em>, 472–494. (<a
href="https://doi.org/10.1016/j.ins.2020.08.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, the decomposition-based multiobjective optimization evolutionary algorithm (MOEA/D) has displayed promising performance when dealing with multiobjective optimization problems (MOPs). However, for some complex MOPs, the conventional MOEA/D often leads to the loss of population diversity in the iterative process, and the convergence performance of the population is weakened in the mean time. In this paper, a novel MOEA/D, based on improved multiple adaptive dynamic selection strategies and elite archive strategy (MOEA/D-IMA), is proposed to improve the population diversity and convergence. First, a novel differential evolution (DE) operator is constructed, which constitutes an operator pool with other DE operators. According to the search information of the current population, an adaptive dynamic selection strategy is proposed, which is used by MOEA/D-IMA to select a suitable DE operator to replace the simulated binary crossover (SBX) operator. Second, a parameter adaptive dynamic selection strategy is proposed to enhance the robustness of MOEA/D-IMA by using the information of population evolution state. Third, an elite archive strategy is introduced to improve the convergence and diversity of the population where mutual dominance of individuals and their aggregation distance is employed. Finally, the proposed MOEA/D-IMA is compared with several state-of-the-art algorithms on three suits of 18 test problems. Experimental results indicate that the proposed MOEA/D-IMA can significantly improve the optimization performance when coping with MOPs.},
  archive      = {J_ISCI},
  author       = {Yingbo Xie and Junfei Qiao and Ding Wang and Baocai Yin},
  doi          = {10.1016/j.ins.2020.08.070},
  journal      = {Information Sciences},
  pages        = {472-494},
  shortjournal = {Inf. Sci.},
  title        = {A novel decomposition-based multiobjective evolutionary algorithm using improved multiple adaptive dynamic selection strategies},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards a physical-world adversarial patch for blinding
object detection models. <em>ISCI</em>, <em>556</em>, 459–471. (<a
href="https://doi.org/10.1016/j.ins.2020.08.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As one of the core components of the computer vision, the object detection model plays a vital role in various security-sensitive systems. However, it has been proved that the object detection model is vulnerable to the adversarial attack . In this paper, we propose a novel adversarial patch attack against object detection models. Our attack can make the object of a specific class invisible to object detection models. We design the detection score to measure the detection model’s output and generate the adversarial patch by minimizing the detection score. We successfully suppress the model’s inference and fool several state-of-the-art object detection models. We triumphantly achieve a minimum recall of 11.02\% and a maximum fooling rate of 81.00\% and demonstrates the high transferability of adversarial patch between different architecture and datasets. Finally, we successfully fool a real-time object detection system in the physical world, demonstrating the feasibility of transferring the digital adversarial patch to the physical world. Our work illustrates the vulnerability of the object detection model against the adversarial patch attack in both the digital and physical world.},
  archive      = {J_ISCI},
  author       = {Yajie Wang and Haoran Lv and Xiaohui Kuang and Gang Zhao and Yu-an Tan and Quanxin Zhang and Jingjing Hu},
  doi          = {10.1016/j.ins.2020.08.087},
  journal      = {Information Sciences},
  pages        = {459-471},
  shortjournal = {Inf. Sci.},
  title        = {Towards a physical-world adversarial patch for blinding object detection models},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel multipopulation optimization for belief rule base
learning. <em>ISCI</em>, <em>556</em>, 436–458. (<a
href="https://doi.org/10.1016/j.ins.2020.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a rule-based expert system, the belief rule base (BRB) exhibits tremendous advantages in modeling nonlinearity for complex systems. Present BRB learning studies can be classified into three categories: BRB structure learning , BRB parameter learning, and BRB joint optimization but only in an iterative and separate fashion. In this study, a novel Parallel Multipopulation optimization approach for BRB, i.e., PMP-BRB, is proposed that simultaneously optimizes the structure and parameters of a BRB. In the optimization model of PMP-BRB, the structure of BRB, i.e., the number of rules, is used as another decisive variable. In the optimization algorithm of PMP-BRB, multiple populations are initialized and subsequently optimized, with different populations representing BRBs of varied sizes. Furthermore, a “completion and deletion” strategy is proposed, wherein individual BRBs in different populations are completed with additional genes that only engage in the optimization operations but not in fitness calculations. Moreover, a trade-off analysis is conducted for decision-makers to identify the final optimal configuration of a BRB based on their preference. The proposed PMP-BRB approach is validated by four cases, namely a numerical case, two practical cases, and a case study with five classification benchmarks. Four evolutionary algorithms are tested and compared. With the structure and parameters optimized simultaneously, all the four cases yield competitive results in comparison with those of previous studies.},
  archive      = {J_ISCI},
  author       = {Wei Zhu and Leilei Chang and Jianbin Sun and Guohua Wu and Xiaobin Xu and Xiaojian Xu},
  doi          = {10.1016/j.ins.2020.09.035},
  journal      = {Information Sciences},
  pages        = {436-458},
  shortjournal = {Inf. Sci.},
  title        = {Parallel multipopulation optimization for belief rule base learning},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kriging-assisted teaching-learning-based optimization
(KTLBO) to solve computationally expensive constrained problems.
<em>ISCI</em>, <em>556</em>, 404–435. (<a
href="https://doi.org/10.1016/j.ins.2020.09.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel algorithm KTLBO is presented to achieve computationally expensive constrained optimization. In KTLBO, Kriging is adopted to develop dynamically updated surrogate models for costly objective and inequality constraints. A data managing method aiming at solving expensive constrained problems is developed to archive, classify and update expensive samples, where a penalty function is set to adaptively select elite individuals. Moreover, based on the Teaching-Learning-based Optimization (TLBO), a Kriging-assisted two-phase optimization framework is presented to alternately conduct local and global searches. In Kriging-assisted Teaching and Learning Phases, two different prescreening operators considering the probability of feasibility are respectively proposed to select the high-quality samples around the present best solution and the samples exhibiting better space-filling performance, as an attempt to balance exploitation of surrogates and exploration of unknown area. In brief, KTLBO retains the meta -heuristic search mechanism of TLBO while adopting Kriging to accelerate its search, thereby acting as a novel idea for surrogate-assisted constrained optimization. Lastly, KTLBO is compared with 6 well-known methods on 27 benchmark cases, and then its significant advantages in expensive constrained optimization are verified. Furthermore, KTLBO is adopted to design the structure of a Blended-Wing-Body underwater glider, and the satisfactory solution is yielded.},
  archive      = {J_ISCI},
  author       = {Huachao Dong and Peng Wang and Chongbo Fu and Baowei Song},
  doi          = {10.1016/j.ins.2020.09.073},
  journal      = {Information Sciences},
  pages        = {404-435},
  shortjournal = {Inf. Sci.},
  title        = {Kriging-assisted teaching-learning-based optimization (KTLBO) to solve computationally expensive constrained problems},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-source transfer regression via source-target pairwise
segment. <em>ISCI</em>, <em>556</em>, 389–403. (<a
href="https://doi.org/10.1016/j.ins.2020.09.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning addresses the problem of how to leverage acquired knowledge from a source domain to improve the learning efficiency and accuracy of the target domain that has insufficient labeled data. Instead of one source domain, multiple domains could be the source domains that are available for knowledge transfer in practice. However, there are large differences between the source and target domains, how to extract the useful knowledge from these different source domains remains a problem. To solve this problem, we propose a source-target pairwise segment method for multi-source transfer regression (STPS-MTR). The STPS-MTR method adaptively segments the different source domains and the target domain into different similar parts, and it extracts the most similar part in different source domains as the transfer knowledge. The STPS-MTR method can effectively extract the transfer knowledge from different source domains even when the source domain and the target domain have relatively low similarity, and it can avoid the negative influence between different source domains to ensure the transfer performance. Experimental results using synthetic datasets and real-world datasets demonstrate that the proposed method has better performance than existing methods, particularly when there are significant differences between different source domains and the target domain.},
  archive      = {J_ISCI},
  author       = {Kai Yang and Jie Lu and Wanggen Wan and Guangquan Zhang},
  doi          = {10.1016/j.ins.2020.09.074},
  journal      = {Information Sciences},
  pages        = {389-403},
  shortjournal = {Inf. Sci.},
  title        = {Multi-source transfer regression via source-target pairwise segment},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Multi-stage consistency optimization algorithm for decision
making with incomplete probabilistic linguistic preference relation.
<em>ISCI</em>, <em>556</em>, 361–388. (<a
href="https://doi.org/10.1016/j.ins.2020.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete probabilistic linguistic term sets (InPLTSs) can effectively describe the qualitative pairwise judgment information in uncertain decision-making problems, making them suitable for solving real decision-making problems under time pressure and lack of knowledge. Thus, in this study, an optimization algorithm is developed for preference decision-making with the incomplete probabilistic linguistic preference relation (InPLPR). First, to fully investigate the ability of InPLTSs to express uncertain information, they are divided into two categories. Then, a two-stage mathematical optimization model based on an expected multiplicative consistency for estimating missing information is constructed, which can obtain the complete information more scientifically and effectively than some exiting methods. Subsequently, for the InPLPR with unacceptable consistency, a multi-stage consistency-improving optimization model is proposed for improving the consistency of the InPLPR by minimizing the information distortion and the number of adjusted linguistic terms, which can also minimize the uncertainty of the relationship as small as possible. Afterward, to rank all the alternatives, a mathematical model for deriving the priority weights of the alternatives is constructed and solved, which can obtain the priority weight conveniently and quickly. A decision-making algorithm based on the consistency of the InPLPR is developed, which involves estimating missing information, checking and improving the consistency, and ranking the alternatives. Finally, a numerical case involving the selection of excellent students is presented to demonstrate the application of the proposed algorithm, and a detailed validation test and comparative analysis are presented to highlight the advantages of the proposed algorithm.},
  archive      = {J_ISCI},
  author       = {Peng Wang and Peide Liu and Francisco Chiclana},
  doi          = {10.1016/j.ins.2020.10.004},
  journal      = {Information Sciences},
  pages        = {361-388},
  shortjournal = {Inf. Sci.},
  title        = {Multi-stage consistency optimization algorithm for decision making with incomplete probabilistic linguistic preference relation},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Randomized shortest paths with net flows and capacity
constraints. <em>ISCI</em>, <em>556</em>, 341–360. (<a
href="https://doi.org/10.1016/j.ins.2020.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work extends the randomized shortest paths (RSP) model by investigating the net flow RSP and adding capacity constraints on edge flows. The standard RSP is a model of movement, or spread, through a network interpolating between a random-walk and a shortest-path behavior (Kivimäki et al., 2014; Saerens et al., 2009; Yen et al., 2008). The framework assumes a unit flow injected into a source node and collected from a target node with flows minimizing the expected transportation cost, together with a relative entropy regularization term. In this context, the present work first develops the net flow RSP model considering that edge flows in opposite directions neutralize each other (as in electric networks), and proposes an algorithm for computing the expected routing costs between all pairs of nodes. This quantity is called the net flow RSP dissimilarity measure between nodes. Experimental comparisons on node clustering tasks indicate that the net flow RSP dissimilarity is competitive with other state-of-the-art dissimilarities. In the second part of the paper, it is shown how to introduce capacity constraints on edge flows, and a procedure is developed to solve this constrained problem by exploiting Lagrangian duality. These two extensions should improve significantly the scope of applications of the RSP framework.},
  archive      = {J_ISCI},
  author       = {Sylvain Courtain and Pierre Leleux and Ilkka Kivimäki and Guillaume Guex and Marco Saerens},
  doi          = {10.1016/j.ins.2020.10.005},
  journal      = {Information Sciences},
  pages        = {341-360},
  shortjournal = {Inf. Sci.},
  title        = {Randomized shortest paths with net flows and capacity constraints},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient approach for encrypting double color images
into a visually meaningful cipher image using 2D compressive sensing.
<em>ISCI</em>, <em>556</em>, 305–340. (<a
href="https://doi.org/10.1016/j.ins.2020.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient visually meaningful double color image encryption algorithm is proposed by combining 2D compressive sensing (CS) with an embedding technique. First, two color images are measured by measurement matrices in two directions to achieve simultaneous compression and encryption, in which low-dimensional matrices generated from Logistic-Sine system (LSS) are extended with Kronecker product (KP), and the resulting high-dimensional matrices optimized by singular value decomposition (SVD) are employed as measurement matrices. Second, the compressed cipher images are confused by index sequences produced by a 6D hyperchaotic system. Finally, a visually meaningful cipher image is obtained by embedding permutated cipher images into a color carrier image. The final cipher image and plain image are of the same size, which greatly reduces the storage space and transmission bandwidth. To enhance the relationship of our algorithm with plain images and prevent vulnerability to known-plaintext and chosen-plaintext attacks, SHA 256 hash values and feature parameters of plain images are combined to generate the initial values of the LSS and 6D hyperchaotic system, and these parameters are both embedded into the carrier image to avoid additional transmission and storage. Simulation results and performance analyses demonstrate the effectiveness and security of the proposed image encryption scheme .},
  archive      = {J_ISCI},
  author       = {Xiuli Chai and Haiyang Wu and Zhihua Gan and Daojun Han and Yushu Zhang and Yiran Chen},
  doi          = {10.1016/j.ins.2020.10.007},
  journal      = {Information Sciences},
  pages        = {305-340},
  shortjournal = {Inf. Sci.},
  title        = {An efficient approach for encrypting double color images into a visually meaningful cipher image using 2D compressive sensing},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Continuous sliding mode iterative learning control for
output constrained MIMO nonlinear systems. <em>ISCI</em>, <em>556</em>,
288–304. (<a href="https://doi.org/10.1016/j.ins.2020.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the time-varying output constraints tracking problem for a class of MIMO nonlinear system, where a new design of Iterative Learning Control (ILC) with adaptive sliding mode method is implemented. Firstly, to solve the unknown periodic parameters problem of MIMO nonlinear system, an ILC strategy is applied to estimate the parameters values which are difficult to be obtained accurately. Secondly, in view of unknown bounded disturbances, a continuous second-order sliding mode adaptive algorithm is utilized, where the disturbances can be estimated by the adaptive law without the upper bound knowledge. Meanwhile, the second-order sliding mode integral term is employed to suppress chattering phenomena. Then, considering the prescribed tracking performance, a novel universal Barrier Lyapunov Function (BLF) is proposed to address the constraint requirements which can change along with the time domain and the iteration domain. The stability and iterative convergence of the adaptive iterative learning sliding mode controller with time-varying constraints are proved by composite energy function (CEF). Finally, the effectiveness of the proposed algorithm is verified by simulation results.},
  archive      = {J_ISCI},
  author       = {Jie Wang and Rongli Li and Gaowei Zhang and Ping Wang and Shijie Guo},
  doi          = {10.1016/j.ins.2020.12.003},
  journal      = {Information Sciences},
  pages        = {288-304},
  shortjournal = {Inf. Sci.},
  title        = {Continuous sliding mode iterative learning control for output constrained MIMO nonlinear systems},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Output feedback MPC for uncertain delayed system and control
of a wind tunnel system. <em>ISCI</em>, <em>556</em>, 273–287. (<a
href="https://doi.org/10.1016/j.ins.2020.08.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an output feedback model predictive control (MPC) strategy for a class of uncertain systems with state delay and unknown disturbance. In order to handle the state delay, we formulate an augmented dynamic system that includes the delayed states, as well as the original system state, as the augmented state. Then, we utilize a dynamic output feedback control law, which is based on the current estimated state instead of the augmented state, for stabilizing the system. As a result, the order of the controller is much reduced. The benefits of utilizing the reduced order controller are the reduced computational burden and guaranteed recursive feasibility. We apply the proposed approach to a wind tunnel system for regulating the Mach number in the test section to the reference value. The simulation result verifies the effectiveness and practicality of the proposed approach.},
  archive      = {J_ISCI},
  author       = {Xin Zan and Zhenhua Yu and Baocang Ding and Yuanli Cai and Zhiwu Li},
  doi          = {10.1016/j.ins.2020.08.115},
  journal      = {Information Sciences},
  pages        = {273-287},
  shortjournal = {Inf. Sci.},
  title        = {Output feedback MPC for uncertain delayed system and control of a wind tunnel system},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The choquet kernel on the use of regression problem.
<em>ISCI</em>, <em>556</em>, 256–272. (<a
href="https://doi.org/10.1016/j.ins.2020.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, we have presented a new family of kernels on the basis of the discrete Choquet integral . While a naïve computation of this kernel has an exponential complexity in the number of features, we have proposed an efficient approach with computational complexity of O ( m 2 log ( m ) ) O(m2log(m)) . 1 This kernel family is able to recognize dependencies between features and moreover it can be regularized through a proper selection of q -additivity. In fact, to reduce the effect of over-fitting there is an opportunity to restrict the flexibility of kernel to a lower degree. A key feature of the Choquet integral in a data-driven way is its monotonicity, however, this representation does not consider any monotonicity constraint; hence it is versatile for other applications, too. This issue is highlighted in the experimental study. In this regard, we apply the Choquet kernel for regression task and compare the performance of the proposed kernel versus state-of-the-art support kernel-based regression methods as well as random forest.},
  archive      = {J_ISCI},
  author       = {Ali Fallah Tehrani},
  doi          = {10.1016/j.ins.2020.11.051},
  journal      = {Information Sciences},
  pages        = {256-272},
  shortjournal = {Inf. Sci.},
  title        = {The choquet kernel on the use of regression problem},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online force-directed algorithms for visualization of
dynamic graphs. <em>ISCI</em>, <em>556</em>, 223–255. (<a
href="https://doi.org/10.1016/j.ins.2020.12.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Force-directed (FD) algorithms can be used to explore relationships in social networks, visualize money markets, and analyze transaction networks. However, FD algorithms are mainly designed for visualizing static graphs in which the topology of the networks remains constant throughout the calculation. In contrast to static graphs, nodes and edges in dynamic graphs can be added or removed as time progresses. In these situations, existing FD algorithms do not scale well, since any changes in the topology will trigger these algorithms to completely restart the entire computation. To alleviate this problem, we propose a design and implementation of five online FD algorithms to visualize dynamic graphs while maintaining their native force models. The online FD algorithms developed in this paper are able to reuse the force models of existing FD algorithms without significant modifications. To evaluate the effectiveness of the proposed approach, online FD algorithms are compared against static FD algorithms for visualizing dynamic graphs. Experimental results show that among the five algorithms evaluated, the online FD algorithm achieves the best number of edge crossings and the standard deviation of edge lengths for visualizing dynamic graphs.},
  archive      = {J_ISCI},
  author       = {Se-Hang Cheong and Yain-Whar Si and Raymond K. Wong},
  doi          = {10.1016/j.ins.2020.12.069},
  journal      = {Information Sciences},
  pages        = {223-255},
  shortjournal = {Inf. Sci.},
  title        = {Online force-directed algorithms for visualization of dynamic graphs},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stereo superpixel: An iterative framework based on parallax
consistency and collaborative optimization. <em>ISCI</em>, <em>556</em>,
209–222. (<a href="https://doi.org/10.1016/j.ins.2020.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereo superpixel segmentation aims to obtain the superpixel segmentation results of the left and right views more cooperatively and consistently, rather than simply performing independent segmentation directly. Thus, the correspondence between two views should be reasonably modeled and fully considered. In this paper, we propose a left-right interactive optimization framework for stereo superpixel segmentation. Considering the disparity in stereo image pairs, we first divide the images into paired region and non-paired region, and propose a collaborative optimization scheme to coordinately refine the matched superpixels of the left and right views in an interactive manner. This is, to the best of our knowledge, the first attempt to generate stereo superpixels considering the parallax consistency. Quantitative and qualitative experiments demonstrate that the proposed framework achieves superior performance in terms of consistency and accuracy compared with single-image superpixel segmentation.},
  archive      = {J_ISCI},
  author       = {Hua Li and Runmin Cong and Sam Kwong and Chuanbo Chen and Qianqian Xu and Chongyi Li},
  doi          = {10.1016/j.ins.2020.12.031},
  journal      = {Information Sciences},
  pages        = {209-222},
  shortjournal = {Inf. Sci.},
  title        = {Stereo superpixel: An iterative framework based on parallax consistency and collaborative optimization},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Output synchronization for heterogeneous system via
semi-markov switching scheme with mode-switching delay. <em>ISCI</em>,
<em>556</em>, 194–208. (<a
href="https://doi.org/10.1016/j.ins.2020.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, output consensus for a series of heterogeneous systems under semi-markov switching topology is investigated. The scenario under consideration is that none of the graph is assumed to be connected and the mode-switching delay is existed. The main technical challenge is model and controller dismatch because of time delay. Assuming every individual system is stabilizable and detectable and mild connectivity assumption on communication topology, the coupled system without model-switching delay can achieve output synchronization by using the Lyapunov method . For the coupled systems with model-switching delay, a bounded output synchronization conclusion can be given. The existence of controller design is also investigated. By the way, we prove an exponentially stable stochastic system , in mean square , with non-vanishing perturbation can achieve uniform boundedness and ultimate boundedness. Finally, two examples are presented to verify our main theories.},
  archive      = {J_ISCI},
  author       = {Ku Du and Qichao Ma and Yu Kang and Jiahu Qin},
  doi          = {10.1016/j.ins.2020.11.038},
  journal      = {Information Sciences},
  pages        = {194-208},
  shortjournal = {Inf. Sci.},
  title        = {Output synchronization for heterogeneous system via semi-markov switching scheme with mode-switching delay},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating patch-based low-rank image restoration using
kd-forest and lanczos approximation. <em>ISCI</em>, <em>556</em>,
177–193. (<a href="https://doi.org/10.1016/j.ins.2020.12.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Patch-based low-rank approximation (PLRA) via truncated singular value decomposition is a powerful and effective tool for recovering the underlying low-rank structure in images. Generally, it first performs an approximate nearest neighbors (ANN) search algorithm to group similar patches into a collection of matrices with reshaping them as vectors. The inherent correlation among similar patches makes these matrices have a low-rank structure. Then the singular value decomposition (SVD) is used to derive a low-rank approximation of each matrix by truncating small singular values . However, the conventional implementation of patch-based low-rank image restoration suffers from high computational cost of the ANN search and full SVD. To address this limitation, we propose a fast approximation method that accelerates the computation of PLRA using multiple kd-trees and Lanczos approximation. The basic idea of this method is to exploit an index kd-tree built from patch samples of the observed image and several small kd-trees built from overlapping regions of the image to accelerate the search for similar patches, and apply the Lanczos bidiagonalization procedure to obtain a fast low-rank approximation of patch matrix without computing the full SVD. Experimental results on image denoising and inpainting tasks demonstrate the efficiency and accuracy of our method.},
  archive      = {J_ISCI},
  author       = {Qiang Guo and Yongxia Zhang and Shi Qiu and Caiming Zhang},
  doi          = {10.1016/j.ins.2020.12.066},
  journal      = {Information Sciences},
  pages        = {177-193},
  shortjournal = {Inf. Sci.},
  title        = {Accelerating patch-based low-rank image restoration using kd-forest and lanczos approximation},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modified real-value negative selection detector-based
oversampling approach for multiclass imbalance problems. <em>ISCI</em>,
<em>556</em>, 160–176. (<a
href="https://doi.org/10.1016/j.ins.2020.12.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A skewed distribution poses a major challenge in multiclass imbalanced problems and has attracted growing interest in the engineering and research communities. Conventional classifiers pose limitations in handling multiclass imbalanced data sets since they were originally designed to handle a balanced distribution. This paper proposes a modified real-value negative selection detector-based oversampling approach for the multiclass imbalance problem. Different from previous works, we have modified and introduced the traditional real-value negative selection algorithm to address the issue of the multiclass imbalance problem. First, the modified real-value negative selection technique is used to create detectors for each minority class. Then, a supervision mechanism is designed using these detectors to prevent overgeneralization. Furthermore, the method of selection weight based on crowding density and detectors is devised with the aim of reducing the within-class imbalance for each minority class. Finally, simulations were conducted on the public real-world multiclass imbalanced data sets from Knowledge Extraction based on Evolutionary Learning (KEEL) and the University of California Irvine (UCI). The experimental and statistical results have demonstrated that the proposed algorithm obtains better performance compared with seven well-known oversampling algorithms in terms of five metrics (precision, recall, F-measure, Multiclass G-mean (MG), and Multiclass Area Under the ROC (MAUC)) and four types of classifiers.},
  archive      = {J_ISCI},
  author       = {Ming Liu and Minggang Dong and Chao Jing},
  doi          = {10.1016/j.ins.2020.12.058},
  journal      = {Information Sciences},
  pages        = {160-176},
  shortjournal = {Inf. Sci.},
  title        = {A modified real-value negative selection detector-based oversampling approach for multiclass imbalance problems},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient convex optimization-based texture mapping for
large-scale 3D scene reconstruction. <em>ISCI</em>, <em>556</em>,
143–159. (<a href="https://doi.org/10.1016/j.ins.2020.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Texture mapping is a key step in large-scale 3D scene reconstruction, which can greatly enhance visual reality of the reconstructed scenes. However, existing techniques are unable to accomplish this task efficiently due to the high computational complexity of reconstructing large-scale real-world 3D scenes. In this work, we propose a new efficient convex optimization-based approach, i.e. the mesh-based continuous max-flow method, which can be easily implemented and accelerated upon a modern parallel computing platform, e.g. GPU . Particularly, an Markov Random Fields (MRF) based model, i.e. Potts model , is introduced to mathematically formulate the key specific view selection problem; we show that the challenging combinatorial optimization problem can be efficiently solved by resolving its convex relaxation , which recovers textures from images with the proposed duality-based continuous max-flow approach. In addition, visual effects of sharpness and deformation are utilized to define a criterion of evaluating texture quality effectively, and a large 3D triangular mesh is partitioned into structural components so as to reduce memory consumption of the proposed algorithm. The proposed mesh-based continuous max-flow approach for large-scale texture mapping demonstrates its outperformance over state-of-the-art methods, over large-scale public datasets, in both numerical efficiency and visual quality; meanwhile, our GPU-accelerated algorithm can yield 3D textured models with high quality from complex large-scale scenes in minutes.},
  archive      = {J_ISCI},
  author       = {Xin Sheng and Jing Yuan and Wenbing Tao and Bo Tao and Liman Liu},
  doi          = {10.1016/j.ins.2020.12.052},
  journal      = {Information Sciences},
  pages        = {143-159},
  shortjournal = {Inf. Sci.},
  title        = {Efficient convex optimization-based texture mapping for large-scale 3D scene reconstruction},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). DP-SLAM: A visual SLAM with moving probability towards
dynamic environments. <em>ISCI</em>, <em>556</em>, 128–142. (<a
href="https://doi.org/10.1016/j.ins.2020.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) systems are proposed to estimate robot poses and reconstruct 3-D map of surrounding environment. Since most of the existing SLAM systems rely on the static-world assumption, to perform them in dynamic environments still remains challenging. In this paper, we propose a novel sparse feature based visual SLAM, named as DP-SLAM, which is based on a moving probability propagation model for dynamic keypoints detection. The probability indicates the likelihood of one keypoint being located on the moving objects. Our approach combines the results of geometry constraints and semantic segmentation to track the dynamic keypoints in a Bayesian probability estimation framework. We integrate our method into the front-end of the ORB-SLAM2 system, which acts as a pre-processing stage to filter out keypoints that are associated with moving objects. Furthermore, we inpaint the frame background that has been occluded by the detected dynamic objects, which benefit some applications such as virtual and augmented reality . Experimental results on the TUM RGB-D dataset and our own sequences demonstrate that our approach can improve performance of state-of-the-art SLAM system in various challenging scenarios.},
  archive      = {J_ISCI},
  author       = {Ao Li and Jikai Wang and Meng Xu and Zonghai Chen},
  doi          = {10.1016/j.ins.2020.12.019},
  journal      = {Information Sciences},
  pages        = {128-142},
  shortjournal = {Inf. Sci.},
  title        = {DP-SLAM: A visual SLAM with moving probability towards dynamic environments},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Enhanced clustering embedded in curvilinear distance
analysis guided by pairwise constraints. <em>ISCI</em>, <em>556</em>,
111–127. (<a href="https://doi.org/10.1016/j.ins.2020.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering and dimensionality reduction have received widespread attention owing to their excellent performance when applied to data analysis. When traditional methods are used to process high-dimensional data, dimensionality reduction is performed prior before the classification or clustering, the steps of which are sequential and have low accuracy. A novel method, enhanced clustering embedded in curvilinear distance analysis (eceCDA) guided by pairwise constraints, is proposed to solve this issue. During the eceCDA procedure, unsupervised learning algorithms are used to learn the reliable pairwise constraints. The curvilinear distance between any two samples in a high-dimensional space is then computed. Next, a weight function is constructed to maintain the local topology of samples in the projection space. Finally, the pairwise curvilinear distance is projected into a low-dimensional space guided by pairwise constraints and clustering criteria . Hence, dimensionality reduction and clustering can be executed simultaneously with high accuracy. To demonstrate the superior performance of eceCDA, extensive experiments were performed on several benchmarks. The experimental results show that eceCDA outperformed other well-known clustering and dimensionality reduction algorithms .},
  archive      = {J_ISCI},
  author       = {Yanping Wu and Yinghui Zhang and Hongjun Wang and Ping Deng and Tianrui Li},
  doi          = {10.1016/j.ins.2020.12.028},
  journal      = {Information Sciences},
  pages        = {111-127},
  shortjournal = {Inf. Sci.},
  title        = {Enhanced clustering embedded in curvilinear distance analysis guided by pairwise constraints},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Curved splicing of copulas. <em>ISCI</em>, <em>556</em>,
95–110. (<a href="https://doi.org/10.1016/j.ins.2020.12.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {First, we recall the properties of the curved section of a copula that is specified by an automorphism of the unit interval. Then, inspired by the operation of diagonal splicing of two copulas, we develop the curved splicing operation, which essentially glues together different restrictions of two copulas that share the same curved section. In order to exploit this operation in practice, we propose two new classes of semilinear copulas. Applying the curved splicing operation to members of these two classes leads to two other classes of semilinear copulas.},
  archive      = {J_ISCI},
  author       = {T. Jwaid and H. De Meyer and A. Haj Ismail and B. De Baets},
  doi          = {10.1016/j.ins.2020.12.053},
  journal      = {Information Sciences},
  pages        = {95-110},
  shortjournal = {Inf. Sci.},
  title        = {Curved splicing of copulas},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel graph convolutional feature based convolutional
neural network for stock trend prediction. <em>ISCI</em>, <em>556</em>,
67–94. (<a href="https://doi.org/10.1016/j.ins.2020.12.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock trend prediction is one of the most widely investigated and challenging problems for investors and researchers. Since the convolutional neural network (CNN) was introduced to analyze financial data, many researchers have dedicated to predicting stock trend by transforming stock market data into images. However, most of the existing studies just focused on individual stock information, and ignored stock market information, such as the existing correlations between stocks. In fact, the price volatility of a stock may be affected by those of other stocks, thus, taking the stock market information into the stock trend prediction can further improve the prediction performance. In this paper, we propose a novel method for stock trend prediction using graph convolutional feature based convolutional neural network (GC–CNN) model, in which both stock market information and individual stock information are considered. Specifically, an improved graph convolutional network (IGCN) and a Dual-CNN are designed to construct GC–CNN, which can simultaneously capture stock market features and individual stock features. Six randomly selected Chinese stocks are used to demonstrate the superior performance of the proposed GC–CNN based method. The experimental analysis demonstrates that the proposed GC–CNN based method outperforms several stock trend prediction methods and stock trading strategies.},
  archive      = {J_ISCI},
  author       = {Wei Chen and Manrui Jiang and Wei-Guo Zhang and Zhensong Chen},
  doi          = {10.1016/j.ins.2020.12.068},
  journal      = {Information Sciences},
  pages        = {67-94},
  shortjournal = {Inf. Sci.},
  title        = {A novel graph convolutional feature based convolutional neural network for stock trend prediction},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Counteracting dynamical degradation of a class of digital
chaotic systems via unscented kalman filter and perturbation.
<em>ISCI</em>, <em>556</em>, 49–66. (<a
href="https://doi.org/10.1016/j.ins.2020.12.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Theoretically, any chaotic system or chaotic map has ideal complex dynamics. However, because of the finite precision of simulation software and digital devices during implementation, chaotic systems often undergo dynamical degradation, which hinders the further application of digital chaotic systems in many fields. Therefore in this paper, the method based on the perturbation and Unscented Kalman Filter (UKF) theory is designed to counteract the dynamical degradation of digital chaotic systems. Specifically, the UKF algorithm is employed to reinstate the original dynamic performance of the chaotic system, and then perturbation feedback technology is used to cause the chaotic system to obtain strong dynamic performance to resist attacks. The experimental and simulation results demonstrate that this method has good effect on improving the dynamic degradation of digital chaotic map . In addition, the corresponding pseudorandom number generator (PRNG) is constructed via this method, and its randomness is evaluated using the National Institute of Standards and Technology (NIST) SP800-22 and TestU01 test suites. By comparing with other schemes, it can be seen that this PRNG has better performance which illustrates the proposed scheme can be applied in the chaos-based cryptography and utilized in other potential applications.},
  archive      = {J_ISCI},
  author       = {Yuling Luo and Yunqi Liu and Junxiu Liu and Shunbin Tang and Jim Harkin and Yi Cao},
  doi          = {10.1016/j.ins.2020.12.065},
  journal      = {Information Sciences},
  pages        = {49-66},
  shortjournal = {Inf. Sci.},
  title        = {Counteracting dynamical degradation of a class of digital chaotic systems via unscented kalman filter and perturbation},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An MCDM integrated adaptive simulated annealing approach for
influence maximization in social networks. <em>ISCI</em>, <em>556</em>,
27–48. (<a href="https://doi.org/10.1016/j.ins.2020.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Influence Maximization (IM) problem aims to identify a small subset of nodes that have the most influence spread in a network. Although it is an NP-hard problem, the continuous increasing size of the social networks leads to a substantially higher computational complexity, and therefore, has motivated numerous researchers to explore better approaches. This paper proposes a multi-criteria decision making (MCDM) based meta-heuristic approach to solve the IM problem in social networks. An MCDM approach is utilized to select candidate nodes by eliminating less influential ones at the preliminary phase which decreases the computation cost. Thereafter, to find the optimal solution, a modified version of Simulated Annealing (SA) with an enhanced search strategy is proposed. The performance of this proposed approach is tested and verified by solving the IM problem on eight real-life social networks of different sizes and types and comparing the results with six benchmark algorithms. The experimental results indicate that the proposed algorithm has a better trade-off between the solution quality and computational run time than the other algorithms.},
  archive      = {J_ISCI},
  author       = {Tarun K. Biswas and Alireza Abbasi and Ripon K. Chakrabortty},
  doi          = {10.1016/j.ins.2020.12.048},
  journal      = {Information Sciences},
  pages        = {27-48},
  shortjournal = {Inf. Sci.},
  title        = {An MCDM integrated adaptive simulated annealing approach for influence maximization in social networks},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A matrix sampling approach for efficient SimRank
computation. <em>ISCI</em>, <em>556</em>, 1–26. (<a
href="https://doi.org/10.1016/j.ins.2020.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluating similarities between node pairs in a graph is an important task for data analytics and mining. Among various similarity measures proposed in recent years, SimRank is regarded as one of the most influential measures. However, the computation of SimRank is very expensive especially for large graphs. Although pruning technique and random walk based methods were proposed to accelerate the computation, the accuracy of SimRank score is still very low. In this paper, we propose a novel matrix random sampling approach to accelerate computation speed and reduce memory cost. The matrix random sampling technique not only guarantees the sparsity of the involved matrices, but also enhances the precision of estimated SimRank scores. Moreover, we design a fast sparse matrix–matrix multiplication technique which makes the time complexity of single-source query free of the graph size. We further exploit the Steepest Decent technique to accelerate the speed of convergence . The experimental results show our proposed algorithms outperform the state-of-the-art SimRank algorithms.},
  archive      = {J_ISCI},
  author       = {Juan Lu and Zhiguo Gong and Yiyang Yang},
  doi          = {10.1016/j.ins.2020.12.046},
  journal      = {Information Sciences},
  pages        = {1-26},
  shortjournal = {Inf. Sci.},
  title        = {A matrix sampling approach for efficient SimRank computation},
  volume       = {556},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A strong coreset algorithm to accelerate OPF as a
graph-based machine learning in large-scale problems. <em>ISCI</em>,
<em>555</em>, 424–441. (<a
href="https://doi.org/10.1016/j.ins.2020.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimum-path forest (OPF) is one of the efficient graph-based frameworks that can determine the patterns of input dataset by extracting the optimal partitions of graph obtained through encoding data into a graph. Since OPF was introduced based on simple assumptions without considering the requirements of large-scale problems, this machine learning is an effective algorithm only for a reasonable size of input datasets. To provide a scalable OPF, this study introduces a strong coreset for accelerating OPF algorithm. Applying this approach can expedite OPF procedure, especially when it is working on massive datasets. Accordingly, a novel algebra is developed to represent the problem of OPF as an optimization problem for the proposed coreset definition. A novel coreset construction algorithm that can approximate the OPF solutions is subsequently proposed in order to improve the OPF construction speed. The simulation results of diverse experiments on various benchmark datasets illustrate computation gain and superiority of the proposed algorithm in terms of the construction and classification speeds as compared to the original algorithm while displaying reliably accurate performance. The presented coreset construction algorithm performs the training and testing phases of OPF up to 6.1 and 4.9 times faster than before, respectively.},
  archive      = {J_ISCI},
  author       = {Hamid Bostani and Mansour Sheikhan and Behrad Mahboobi},
  doi          = {10.1016/j.ins.2020.10.009},
  journal      = {Information Sciences},
  pages        = {424-441},
  shortjournal = {Inf. Sci.},
  title        = {A strong coreset algorithm to accelerate OPF as a graph-based machine learning in large-scale problems},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Domain-specific meta-embedding with latent semantic
structures. <em>ISCI</em>, <em>555</em>, 410–423. (<a
href="https://doi.org/10.1016/j.ins.2020.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-embedding aims at assembling pre-trained embeddings from various sources and producing more expressively powerful word representations. Many natural language processing (NLP) tasks in a specific domain benefit from meta-embedding, especially when the task suffers from low resources. This paper proposes an unsupervised meta-embedding method that jointly models background knowledge from the source embeddings and domain-specific knowledge from the task domain. Specifically, embeddings from multiple sources for a word are dynamically aggregated to a single meta-embedding by a differentiable attention module. The embeddings derived from pre-training on a large-scale corpus provide complete background knowledge of word usage. Then, the meta-embedding is further enriched by exploring domain-specific knowledge from each task domain in two ways. First, contextual information in the raw corpus is considered to capture the semantics of words. Second, a graph representing domain-specific semantic structures is extracted from the raw corpus to highlight the relationships between salient words, then the graph is modeled by a powerful graph convolution network to effectively capture rich semantic structures among words in the task domain. Experiments conducted on two tasks, i.e., text classification and relation extraction, show that our model outputs more accurate word meta-embeddings for the task domain, compared to other state-of-the-art competitors. .},
  archive      = {J_ISCI},
  author       = {Qian Liu and Jie Lu and Guangquan Zhang and Tao Shen and Zhihan Zhang and Heyan Huang},
  doi          = {10.1016/j.ins.2020.10.030},
  journal      = {Information Sciences},
  pages        = {410-423},
  shortjournal = {Inf. Sci.},
  title        = {Domain-specific meta-embedding with latent semantic structures},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anti-collusion data auction mechanism based on smart
contract. <em>ISCI</em>, <em>555</em>, 386–409. (<a
href="https://doi.org/10.1016/j.ins.2020.10.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the uncertainty of the value of big data, it is difficult to directly give a reasonable price for big data. Auction is an effective method of distributing goods to the bidder with the highest valuation. Hence, the use of auction strategy can not only guarantee the interests of data sellers, but also conform to market principles. However, existing data auction mechanisms are centralized. It is hard to build trust among sellers, buyers and auctioneers. An open and anonymous online environment may cause entities involved in data auctions to collude to manipulate the results of data auctions. This will cause the price of auction data to fail to reach a fair and truthful level. Therefore, the first anti-collusion data auction mechanism based on smart contract is proposed. Through a well-designed anti-collusion data auction algorithm, mutual distrust and rational buyers and sellers safely participate in the data auction without a trusted third party. The data auction mechanism designed in the smart contract can effectively prevent collusion and realize the fairness and truthfulness of data auction. The webpack in the Truffle Boxes is used to implement the data auction mechanism, and the anti-collusion property of the mechanism has been verified. The source code of the smart contract has been uploaded to GitHub.},
  archive      = {J_ISCI},
  author       = {Wei Xiong and Li Xiong},
  doi          = {10.1016/j.ins.2020.10.053},
  journal      = {Information Sciences},
  pages        = {386-409},
  shortjournal = {Inf. Sci.},
  title        = {Anti-collusion data auction mechanism based on smart contract},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A clusterwise nonlinear regression algorithm for
interval-valued data. <em>ISCI</em>, <em>555</em>, 357–385. (<a
href="https://doi.org/10.1016/j.ins.2020.10.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued variables are required in data analysis since this type of data represents either the uncertainty existing in an error measurement or the natural variability of the data. Currently, methods and algorithms which aim to manage interval-valued data are very much required. Hence, this paper presents a center and range clusterwise nonlinear regression algorithm for interval-valued data. The proposed algorithm combines a k-means type algorithm with the center and range linear and nonlinear regression methods for interval-valued data, with the aim to identify both the partition of the data and the relevant regression models fitted on the center and range of the intervals simultaneously, one for each cluster. The proposed method is able to automatically select the best pair of center and range (linear and/or nonlinear) functions according to optimization criteria. A simulation study with synthetic data sets with the purpose of assessing the parameter estimation and the prediction performance of the proposed algorithm was undertaken. Finally, applications on real data sets were performed and the prediction accuracy of the proposed method was compared to the linear case. The results obtained showed that the proposed method performed well on both synthetic and real data sets.},
  archive      = {J_ISCI},
  author       = {Francisco de A.T. de Carvalho and Eufrásio de A. Lima Neto and Kassio C.F. da Silva},
  doi          = {10.1016/j.ins.2020.10.054},
  journal      = {Information Sciences},
  pages        = {357-385},
  shortjournal = {Inf. Sci.},
  title        = {A clusterwise nonlinear regression algorithm for interval-valued data},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multicriteria decision making based on bi-direction choquet
integrals. <em>ISCI</em>, <em>555</em>, 339–356. (<a
href="https://doi.org/10.1016/j.ins.2020.10.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deal with multicriteria decision making (MCDM) problems with interaction criteria, the Choquet integral (CI) is one of effective tools. This paper first proposes the reverse Choquet integral (RCI), which defines the importance of the ordered elements in an opposite principle to the CI. To show the principle of the RCI, we offer its concrete expression in view of the Möbius representation by which one can clearly see the difference and the relationship between the CI and the RCI. Then, we propose the “bi-direction Choquet integral” (BDCI), which is a convex combination of the CI and the RCI. To get the interactions of ordered coalitions comprehensively, this paper further proposes the generalized Shapley bi-direction Choquet integral (GSBDCI). Furthermore, the hybrid generalized Shapley bi-direction Choquet integral (HGSBDCI) is proposed, which defines the importance of ordered positions and the criteria with interactions simultaneously. With respect to these types of CIs, their exponent forms are also discussed. Finally, we use an application case to show the utilization of the proposed new CIs for MCDM. The proposed new Choquet integrals provide us a very useful way to deal with MCDM problems.},
  archive      = {J_ISCI},
  author       = {Fanyong Meng and Shyi-Ming Chen and Jie Tang},
  doi          = {10.1016/j.ins.2020.10.055},
  journal      = {Information Sciences},
  pages        = {339-356},
  shortjournal = {Inf. Sci.},
  title        = {Multicriteria decision making based on bi-direction choquet integrals},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Leader-follower consensus control for linear multi-agent
systems by fully distributed edge-event-triggered adaptive strategies.
<em>ISCI</em>, <em>555</em>, 314–338. (<a
href="https://doi.org/10.1016/j.ins.2020.10.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on investigates the leader-follower consensus problem for linear multi-agent systems (MASs). In order to reduce the frequency of system network communication, this paper first designs three kinds of triggering mechanisms, for the leader, the edges composed of the leader and informed followers, and the edges composed of uninformed followers, respectively. All agents in the MASs do not transmit information until the corresponding triggering mechanisms are satisfied, thus avoiding continuous communication and saving system resources. Then, two kinds of fully distributed edge-event-triggered adaptive protocols are designed to solve the leader-follower problem. The first state feedback control protocol is applicable to scenarios where all states of MASs are available. The second output feedback control protocol does not depend on the availability of the states of MASs. Moreover, under the designed triggering mechanisms and fully distributed edge-event-triggered adaptive consensus strategies, the MASs do not exhibit the Zeno behavior. Finally, two practical simulations are introduced to verify all the theoretical results obtained in this paper. Furthermore, in order to further demonstrate the advantages of the proposed methods, a comparative experiment is performed.},
  archive      = {J_ISCI},
  author       = {Juan Zhang and Huaguang Zhang and Shaoxin Sun and Zhiyun Gao},
  doi          = {10.1016/j.ins.2020.10.056},
  journal      = {Information Sciences},
  pages        = {314-338},
  shortjournal = {Inf. Sci.},
  title        = {Leader-follower consensus control for linear multi-agent systems by fully distributed edge-event-triggered adaptive strategies},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Fuzzy controller synthesis for nonlinear neutral
state-delayed systems with impulsive effects. <em>ISCI</em>,
<em>555</em>, 293–313. (<a
href="https://doi.org/10.1016/j.ins.2020.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state feedback fuzzy controller synthesis for nonlinear neutral state-delayed systems with impulsive effects is addressed. A methodology for stability analysis of the underlying systems is proposed in the framework of system augmentation . New impulse-timer-dependent Lyapunov functions based analysis techniques, including a Razumikhin-type technique and a Lyapunov functional technique, are developed allowing to reduce the conservativeness of the stability conditions. To circumvent the difficulty in designing control gain matrices, the stability conditions of the closed-loop system are formulated in terms of dilated linear matrix inequalities (LMIs). By virtue of the nice properties of the dilated LMIs , the fuzzy controller synthesis is established. Three illustrative examples are presented to demonstrate the novelty of the new stability criteria and the effectiveness of the proposed design method.},
  archive      = {J_ISCI},
  author       = {Jinsen Zhang and Wu-Hua Chen and Xiaomei Lu and Jing Wen},
  doi          = {10.1016/j.ins.2020.11.001},
  journal      = {Information Sciences},
  pages        = {293-313},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy controller synthesis for nonlinear neutral state-delayed systems with impulsive effects},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On finite-horizon h∞ state estimation for discrete-time
delayed memristive neural networks under stochastic communication
protocol. <em>ISCI</em>, <em>555</em>, 280–292. (<a
href="https://doi.org/10.1016/j.ins.2020.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the protocol-based finite-horizon H ∞ H∞ estimation problem for discrete-time memristive neural networks (MNNs) subject to time-delays and energy-bounded disturbances. With the purpose of effectively alleviating data collisions and saving energy , the stochastic communication protocol (SCP) is adopted to regulate the data transmission procedure in the sensor-to-estimator communication channel, thereby avoiding unnecessary network congestion . It is our objective to construct an H ∞ H∞ estimator ensuring a prescribed disturbance attenuation level over a finite time-horizon for the delayed MNNs under the SCP. By virtue of the Lyapunov–Krasovskii functional in combination with stochastic analysis methods, the delay-dependent criteria are established that guarantee the existence of the desired H ∞ H∞ estimator. Subsequently, the estimator gains are computed by resorting to solve a bank of convex optimization problems . Finally, the validity of the designed H ∞ H∞ estimator is demonstrated via a numerical example.},
  archive      = {J_ISCI},
  author       = {Hongjian Liu and Zidong Wang and Weiyin Fei and Jiahui Li and Fuad E. Alsaadi},
  doi          = {10.1016/j.ins.2020.11.002},
  journal      = {Information Sciences},
  pages        = {280-292},
  shortjournal = {Inf. Sci.},
  title        = {On finite-horizon h∞ state estimation for discrete-time delayed memristive neural networks under stochastic communication protocol},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of activation maps through global pooling
measurements for texture classification. <em>ISCI</em>, <em>555</em>,
260–279. (<a href="https://doi.org/10.1016/j.ins.2020.09.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We analyzed the effects of global pooling measurements on extracting relevant texture information from a given set of activation maps. Initially, using a layer-by-layer approach (GP-CNN), we experimentally demonstrated that layers at various depth levels could provide high-quality texture information. Based on this finding, we developed R ank GP-CNN, a method that performs multi-layer feature extraction. More specifically, R ank GP-CNN treats every CNN model as a vast collection of deep composite functions , where each function computes a 2D activation map for every input image. A feature ranking approach then assigns a score to each deep composite function by processing the activation maps generated for a particular dataset bank. Eventually, R ank GP-CNN uses the top-ranked deep composite functions to compute feature vectors for different texture datasets. Experiments on a dedicated classifier showed that R ank GP-CNN achieves good results and can adapt to different texture problems. Finally, we present R ank GP-3M-CNN as the version of R ank GP-CNN that considers multiple CNN models. Overall, R ank GP-3M-CNN achieves promising results with the advantage of only using the default scale of the input images.},
  archive      = {J_ISCI},
  author       = {Rayner H. M. Condori and Odemir M. Bruno},
  doi          = {10.1016/j.ins.2020.09.058},
  journal      = {Information Sciences},
  pages        = {260-279},
  shortjournal = {Inf. Sci.},
  title        = {Analysis of activation maps through global pooling measurements for texture classification},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Merging existential rules programs in multi-agent contexts
through credibility accrual. <em>ISCI</em>, <em>555</em>, 236–259. (<a
href="https://doi.org/10.1016/j.ins.2020.10.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Merging operators represent a significant tool to extract a consistent and informative view from a set of agents. The consideration of practical scenarios where some agents can be more credible than others has contributed to substantially increase the interest in developing systems working with trust models. In this context, we propose an approach to the problem of merging knowledge in a multiagent scenario where every agent assigns to other agents a value reflecting its perception on how credible each agent is. The focus of this paper is the introduction of an operator for merging Datalog ± ontologies considering agents’ credibility. We present a procedure to enhance a conflict resolution strategy by exploiting the credibility attached to a set of formulas; the approach is based on accrual functions that calculate the value of formulas according to the credibility of the agents that inform them. We show how our new operator can obtain the best-valued knowledge base among consistent bases available, according to the credibilities attached to the sources.},
  archive      = {J_ISCI},
  author       = {Cristhian A.D. Deagustini and Juan Carlos L. Teze and M. Vanina Martinez and Marcelo A. Falappa and Guillermo R. Simari},
  doi          = {10.1016/j.ins.2020.10.050},
  journal      = {Information Sciences},
  pages        = {236-259},
  shortjournal = {Inf. Sci.},
  title        = {Merging existential rules programs in multi-agent contexts through credibility accrual},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Focal points and their implications for möbius transforms
and dempster-shafer theory. <em>ISCI</em>, <em>555</em>, 215–235. (<a
href="https://doi.org/10.1016/j.ins.2020.10.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster-Shafer Theory (DST) generalizes Bayesian probability theory, offering useful additional information, but suffers from a much higher computational burden. A lot of work has been done to reduce the time complexity of information fusion with Dempster’s rule, which is a pointwise multiplication of two zeta transforms, and optimal general algorithms have been found to get the complete definition of these transforms. Yet, it is shown in this paper that the zeta transform and its inverse, the Möbius transform, can be exactly simplified, fitting the quantity of information contained in belief functions. Beyond that, this simplification actually works for any function on any partially ordered set . It relies on a new notion that we call focal point and that constitutes the smallest domain on which both the zeta and Möbius transforms can be defined. We demonstrate the interest of these general results for DST, not only for the reduction in complexity of most transformations between belief representations and their fusion, but also for theoretical purposes. Indeed, we provide a new generalization of the conjunctive decomposition of evidence and formulas uncovering how each decomposition weight is tied to the corresponding mass function.},
  archive      = {J_ISCI},
  author       = {Maxime Chaveroche and Franck Davoine and Véronique Cherfaoui},
  doi          = {10.1016/j.ins.2020.10.060},
  journal      = {Information Sciences},
  pages        = {215-235},
  shortjournal = {Inf. Sci.},
  title        = {Focal points and their implications for möbius transforms and dempster-shafer theory},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The integrated sigma-max system and its application in
target recognition. <em>ISCI</em>, <em>555</em>, 198–214. (<a
href="https://doi.org/10.1016/j.ins.2020.12.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Randomness and fuzziness are two fundamental kinds of uncertain phenomena, which can be handled respectively by probability theory (sigma system) and possibility theory (max system). For many practical problems of information processing, random uncertainty may often co-exist with fuzzy uncertainty, which reminds us to look for a novel mechanism called sigma-max hybrid uncertainty inference. This mechanism can cope with randomness and fuzziness jointly and achieve a direct fusion of heterogeneous information modeled by probability or possibility. Specifically, we are interested in two typical forms of uncertainty inference, i.e., uncertainty update equation combining heterogeneous information as well as composition rule of heterogeneous relations. Such an objective is achieved by the adoption of joint description of a random variable and a fuzzy variable, i.e., hybrid distribution of probability and possibility, which lays the foundation for connecting the two uncertainty systems of probability and possibility, and results in the integrated sigma-max system. The hybrid distribution, other than joint probability (or possibility) distribution, has a couple of special normalization requirements that are order-dependent with respective to “addition” operation over random variable and “max’ operation over fuzzy variable. The derived sigma-max inference is applied to target recognition, an example of which is simulated to demonstrate the merit of the proposed method over the classic Bayesian classifier when randomness and fuzziness are both involved.},
  archive      = {J_ISCI},
  author       = {Wei Mei and Limin Liu and Jian Dong},
  doi          = {10.1016/j.ins.2020.12.054},
  journal      = {Information Sciences},
  pages        = {198-214},
  shortjournal = {Inf. Sci.},
  title        = {The integrated sigma-max system and its application in target recognition},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble approach with external archive for multi- and
many-objective optimization with adaptive mating mechanism and two-level
environmental selection. <em>ISCI</em>, <em>555</em>, 164–197. (<a
href="https://doi.org/10.1016/j.ins.2020.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on mating and environmental selections employed, multi-objective evolutionary algorithms (MOEAs) are classified as Pareto-based, decomposition-based and indicator-based approaches that are associated with their own advantages and disadvantages. To benefit from the advantages of different MOEAs , we propose an ensemble framework (ENMOEA) in which mating and environmental selections of diverse MOEAs are combined. ENMOEA is a single-population competitive ensemble, where resource allocation to individual mating operators is done adaptively. In addition, ENMOEA employs a two-level environmental selection where constituent environmental selection operators are first applied to label solutions as “selected” and “non-selected”. Solutions “selected” by most operators are preferred for future evolution. An external archive is employed to facilitate effective usage of function evaluations and achieve a better comprise between convergence and diversity. To demonstrate generality of ENMOEA, we developed two variants: 1) specific case (ENMOEA S - combines different Pareto-based MOEAs) and 2) general case (ENMOEA G - combines Pareto-based, indicator-based and decomposition-based MOEAs). From simulation results on various test suites (DTLZ, WFG and 16 real-world problems), it is evident that ENMOEA is robust to the parameters of the constituent algorithms. In addition, it is evident that the effectiveness of ensemble improves with the diversity of the constituent algorithms.},
  archive      = {J_ISCI},
  author       = {Vikas Palakonda and Rammohan Mallipeddi and Ponnuthurai Nagaratnam Suganthan},
  doi          = {10.1016/j.ins.2020.11.040},
  journal      = {Information Sciences},
  pages        = {164-197},
  shortjournal = {Inf. Sci.},
  title        = {An ensemble approach with external archive for multi- and many-objective optimization with adaptive mating mechanism and two-level environmental selection},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Cross-class generative network for zero-shot learning.
<em>ISCI</em>, <em>555</em>, 147–163. (<a
href="https://doi.org/10.1016/j.ins.2020.12.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL) aims to recognize unseen classes when no training samples are provided for these classes. A traditional approach to solving ZSL is to generate samples of unseen classes, transforming it into a supervised task. However, the quality of these pseudo-samples is crucial for model performance. In this paper, we propose a novel network, called cross-class generative network, which includes two novel end-to-end models, to generate high-quality samples for unseen classes. Unlike previous work, our proposed models directly generate samples of unseen classes via samples of seen classes. As a result, generated samples are distributed more similarly to real samples. In addition, we propose an intra-class entropy to measure the discrepancy degree for selecting suitable source–target pairs. To the best of our knowledge, this intra-class entropy is proposed in ZSL for the first time. Our models include two versions, non-adversarial and adversarial ones, to support and explore different scenarios. We conduct extensive experiments on five benchmark datasets. A comprehensive comparison with state-of-the-art methods shows the superiority of our proposed models.},
  archive      = {J_ISCI},
  author       = {Jinlu Liu and Zhaocheng Zhang and Gang Yang},
  doi          = {10.1016/j.ins.2020.12.063},
  journal      = {Information Sciences},
  pages        = {147-163},
  shortjournal = {Inf. Sci.},
  title        = {Cross-class generative network for zero-shot learning},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient outlier detection method for data streams based
on closed frequent patterns by considering anti-monotonic constraints.
<em>ISCI</em>, <em>555</em>, 125–146. (<a
href="https://doi.org/10.1016/j.ins.2020.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In some practical applications, users pay more attention to a small part of the data that they are interested in, rather than full sets of the data elements, so it is extremely important to improve the security of this small part of the data. For the existing association-based outlier detection methods, they detect the outliers from full set of the data streams, which results in having users to wait for a long period to obtain the detection results. In contrast, most distributions of the outliers are meaningless for the users. To solve this problem, by considering user-specified anti-monotonic constraints, this paper proposes an efficient outlier detection method based on closed frequent patterns for data streams. Also, four deviation indices are designed to accurately calculate the outlier score of each transaction in the sliding window by considering more influencing factors. Then, the top k transactions with the largest outlier score are returned as outliers. Extensive experimental results show that the proposed method can accurately find the outliers from the data streams that satisfy the anti-monotonic constraints with less time cost.},
  archive      = {J_ISCI},
  author       = {Saihua Cai and Rubing Huang and Jinfu Chen and Chi Zhang and Bo Liu and Shang Yin and Ye Geng},
  doi          = {10.1016/j.ins.2020.12.050},
  journal      = {Information Sciences},
  pages        = {125-146},
  shortjournal = {Inf. Sci.},
  title        = {An efficient outlier detection method for data streams based on closed frequent patterns by considering anti-monotonic constraints},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On generalization reducts in multi-scale decision tables.
<em>ISCI</em>, <em>555</em>, 104–124. (<a
href="https://doi.org/10.1016/j.ins.2020.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world data is often organized at different levels of granularity with specified concept hierarchies. Multi-scale information tables represent such a type of data set in a hierarchical form. In this paper, we aim to focus on rule extraction in multi-scale decision tables. Unlike the case of attribute reduct, we consider a type of generalization reduct in multi-scale decision tables. This approach requires both the least number of attributes and the coarsest level of scales according to different reduct standards. The present study is conducted at the three different levels, that is, generalization reducts for objects, decision rules and multi-scale decision tables, respectively. The construction of granularity trees and the selection of cuts play a crucial role. At each level, we present various types of generalization reducts according to different requirements. The relationship between them is also investigated. Moreover, a comparative study between generalization reducts and attribute reducts is also performed. Based on the notion of generalization reducts, the procedure to extract the set of optimal decision rule in multi-scale decision tables is provided and an illustrative example is also given to show the proposed approach.},
  archive      = {J_ISCI},
  author       = {Yan-Hong She and Zhuo-Hao Qian and Xiao-Li He and Jun-Tao Wang and Ting Qian and Wen-Li Zheng},
  doi          = {10.1016/j.ins.2020.12.045},
  journal      = {Information Sciences},
  pages        = {104-124},
  shortjournal = {Inf. Sci.},
  title        = {On generalization reducts in multi-scale decision tables},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic group MCDM model with intuitionistic fuzzy set:
Perspective of alternative queuing method. <em>ISCI</em>, <em>555</em>,
85–103. (<a href="https://doi.org/10.1016/j.ins.2020.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multi-criteria decision making (DMCDM) is prevalent in real life, where the evaluations are given sequentially across time and earlier evaluations will influence later ones. Moreover, alternatives and criteria are allowed to vary with time. However, on the one hand, such dynamic change is rarely considered under the situation of group decision making. On the other hand, recent DMCDM methods just aggregate the evaluations from different periods, which can not accurately reflect the relative relation between alternatives due to constant change of alternatives and criteria. Motivated by these cases, we provide an insight with alternative queuing method (AQM) and intuitionistic fuzzy set (IFS) into dynamic group MCDM (DGMCDM), which ranks the alternatives based on preference relation. In the proposed model, we generate current weights of decision makers (DMs) by introducing induced ordered weighted averaging (IOWA) operatorwhich acts as a link among the weights collected across time. Moreover, we extend classical AQM by using fuzzy preference relation (FPR) instead of 0–1 preference relationship in paired comparison between alternatives. Additionally, a feedback mechanism is defined within the framework of extended AQM, where later FPRs will be influenced by the earlier ones as well as carried to the next period. Our method is of great effectiveness and flexibility with complicated and changeable environment, which has been demonstrated in the field of supplier selection undergoing three periods. Furthermore, we make a comparative analysis of the method with classical AQM and static MCDM.},
  archive      = {J_ISCI},
  author       = {Ran Tao and Zeyi Liu and Rui Cai and Kang Hao Cheong},
  doi          = {10.1016/j.ins.2020.12.033},
  journal      = {Information Sciences},
  pages        = {85-103},
  shortjournal = {Inf. Sci.},
  title        = {A dynamic group MCDM model with intuitionistic fuzzy set: Perspective of alternative queuing method},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-time leader-following/containment consensus for a
class of nonlinear multi-agent systems. <em>ISCI</em>, <em>555</em>,
58–84. (<a href="https://doi.org/10.1016/j.ins.2020.12.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study focuses on the fixed-time leader-following consensus problem for a class of multi-agent system with multi-dimensional nonlinear dynamics . First, the distributed static fixed-time control protocol is put forward to settle this issue. Different from the existing fixed-time control methods , the proposed control protocol is continuous such that the chattering phenomenon can be avoided. Note that the proposed static fixed-time controller is dependent on the global information of network topology . To address above issue, the fully distributed adaptive fixed-time controller is further proposed. Moreover, the results in fixed-time leader-following consensus are extended to containment consensus. And the case of directed graph is also considered. Finally, several examples are provided to illustrate the feasibility of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Yuliang Cai and Huaguang Zhang and Juan Zhang and Wei Wang},
  doi          = {10.1016/j.ins.2020.12.064},
  journal      = {Information Sciences},
  pages        = {58-84},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time leader-following/containment consensus for a class of nonlinear multi-agent systems},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative analysis of knowledge acquisition performance
in complex networks. <em>ISCI</em>, <em>555</em>, 46–57. (<a
href="https://doi.org/10.1016/j.ins.2020.12.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovery processes have been an important topic in the network science field. The exploration of nodes can be understood as the knowledge acquisition process taking place in the network, where nodes represent concepts and edges are the semantical relationships between concepts. While some studies have analyzed the performance of the knowledge acquisition process in particular network topologies , here we performed a systematic performance analysis in well-known dynamics and topologies. Several interesting results have been found. Overall, all learning curves displayed the same learning shape, with different speed rates. We also found ambiguities in the feature space describing the learning curves, meaning that the same knowledge acquisition curve can be generated in different combinations of network topology and dynamics. A surprising example of such patterns are the learning curves obtained from random and Waxman networks: despite the very distinct characteristics in terms of global structure, several curves from different models turned out to be similar. All in all, our results suggest that different learning strategies can lead to the same learning performance. From the network reconstruction point of view, however, this means that learning curves of observed sequences should be combined with other sequence features if one aims at inferring network topology from observed sequences .},
  archive      = {J_ISCI},
  author       = {Lucas Guerreiro and Filipi N. Silva and Diego R. Amancio},
  doi          = {10.1016/j.ins.2020.12.060},
  journal      = {Information Sciences},
  pages        = {46-57},
  shortjournal = {Inf. Sci.},
  title        = {A comparative analysis of knowledge acquisition performance in complex networks},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimal global algorithm for route guidance in advanced
traveler information systems. <em>ISCI</em>, <em>555</em>, 33–45. (<a
href="https://doi.org/10.1016/j.ins.2020.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced traveler information systems play essential roles in reducing traffic congestion and improving traffic efficiency. In this paper, a global algorithm for the route guidance strategy is proposed in advanced traveler information systems . Compared to the local algorithm , this global algorithm can improve the capacity and efficiency of traffic networks and also counter traffic congestion. The innovative ideas of this algorithm can be viewed mainly from three aspects. First, rather than providing a fixed path between origin and destination, the new algorithm could provide the real-time optimal route guidance information to travelers at every intersection. Moreover, because the route guidance information is based on global traffic information, the optimum global path could also be provided. Lastly, we can use this new global algorithm and apply it to many route guidance strategies. In our study, we first apply it to the congestion coefficient route guidance strategy. The simulation results demonstrate better performances of the global congestion coefficient route guidance strategy compared to that of the local congestion coefficient route guidance strategy. The advantages can be summarized as follow: (1) Critical vehicle occupancy and average flow of saturation state is doubled. (2) Critical vehicle occupancy of meta-stable state and deadlock state are raised by 2.5 2.5 times. (3) Vehicle distribution is more homogeneous. We also apply the global algorithm to the travel time route guidance strategy. Even though it brings a slightly lower average flow and a higher origin-destination travel time compared to the global congestion coefficient route guidance strategy, the global travel time route guidance strategy induces a more homogeneous vehicle distribution. Furthermore, we find that the average flow increases when information collection time period decreases, thus information should be updated in a real-time manner in efficient traffic networks.},
  archive      = {J_ISCI},
  author       = {Bokui Chen and Zhongjun Ding and Yao Wu and Jun Zhou and Yongquan Chen},
  doi          = {10.1016/j.ins.2020.10.012},
  journal      = {Information Sciences},
  pages        = {33-45},
  shortjournal = {Inf. Sci.},
  title        = {An optimal global algorithm for route guidance in advanced traveler information systems},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep multi-task representation learning method for time
series classification and retrieval. <em>ISCI</em>, <em>555</em>, 17–32.
(<a href="https://doi.org/10.1016/j.ins.2020.12.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series classification and retrieval are two important tasks of time series analysis . Existing methods solve these two tasks separately, which ignores the sharable information among different tasks. In this paper, we propose a deep multi-task representation learning method (MTRL) for time series classification and retrieval, which exploits both related supervised and unsupervised information. Specifically, supervised representation learning for classification task tries to maximize the inter-class variations and minimize the intra-class variations. Unsupervised representation learning for retrieval task aims at preserving pairwise dynamic time warp (DTW) distances. These two tasks can benefit from each other via shared networks, which consist of deep wavelet decomposition networks and residual networks . These networks can extract the information hidden in different time and frequency domains, and can achieve easier information flow from the lowest level to the highest level than traditional convolutional neural networks . Furthermore, we propose a distance-weighted sampling strategy, which focuses on the more discriminative samples to achieve high convergence speed and accuracies. Extensive experiments on UCR datasets demonstrate that MTRL outperforms the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Ling Chen and Donghui Chen and Fan Yang and Jianling Sun},
  doi          = {10.1016/j.ins.2020.12.062},
  journal      = {Information Sciences},
  pages        = {17-32},
  shortjournal = {Inf. Sci.},
  title        = {A deep multi-task representation learning method for time series classification and retrieval},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online dynamic working-state recognition through uncertain
data classification. <em>ISCI</em>, <em>555</em>, 1–16. (<a
href="https://doi.org/10.1016/j.ins.2020.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The satellite must continue working properly under different working environments and working loads. The power system is an essential component. Due to different working tasks, loads, and attitudes, a power system has many diverse working states. Therefore, it is necessary to accurately recognize the working state online for fault diagnostics and health management. However, under different working loads, measurement errors, environmental noise, environmental interference, and other uncertain factors, the output voltage value of a satellite power system has different levels of uncertainties. If these uncertainties and various working states are not considered, the recognition results can be of low quality. To address this problem and the uncertainty factors, we present an online dynamic working-state recognition system for satellite power systems based on uncertain data classification . In the system, we first explore the uncertain-data clustering center to model the working state. Then, with a slide-window processing strategy, we compute the distances between the uncertain cluster centers and the uncertain voltage data for the satellite power system online. Thus, we can obtain more accurate dynamic working-state recognition results. The evaluation results of real data demonstrate that the presented system is valid for working-state recognition and can be applied to a satellite power system.},
  archive      = {J_ISCI},
  author       = {Xiaozhen Yan and Qinghua Luo and Jianyu Sun and Zhenhua Luo and Yunsai Chen},
  doi          = {10.1016/j.ins.2020.11.022},
  journal      = {Information Sciences},
  pages        = {1-16},
  shortjournal = {Inf. Sci.},
  title        = {Online dynamic working-state recognition through uncertain data classification},
  volume       = {555},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Multiattribute decision making based on converted decision
matrices, probability density functions, and interval-valued
intuitionistic fuzzy values. <em>ISCI</em>, <em>554</em>, 313–324. (<a
href="https://doi.org/10.1016/j.ins.2020.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new multiattribute decision making method based on converted decision matrices, probability density functions and interval-valued intuitionist fuzzy values. First, it obtains the converted decision matrix from the interval-valued intuitionistic fuzzy decision matrix given by the decision maker. Then, it computes the standard deviations and the mean values of the intervals appear at each row of the converted decision matrix, respectively, by using probability density functions. Then, by using the mean values and the standard deviations of the alternatives and the converted decision matrix, it gets the z -score decision matrix. Afterwards, the optimal weights of the attributes are calculated from the interval-valued intuitionist fuzzy weights of the attributes. Finally, it computes the value of overall performance of each alternative by using the z -score decision matrix and the optimal weights of the attributes for ranking the alternatives. The proposed method can conquer the shortcomings of the existing methods for interval-valued intuitionistic fuzzy multiattribute decision making.},
  archive      = {J_ISCI},
  author       = {Kamal Kumar and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2020.12.029},
  journal      = {Information Sciences},
  pages        = {313-324},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making based on converted decision matrices, probability density functions, and interval-valued intuitionistic fuzzy values},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Construction of higher-level MDS matrices in nested SPNs.
<em>ISCI</em>, <em>554</em>, 297–312. (<a
href="https://doi.org/10.1016/j.ins.2020.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new construction of large-scale maximum distance separable (MDS) matrices which can be used in the design of block ciphers . We extend Cauchy matrices defined over a finite field and consider these matrices on a finite commutative ring. The resulting generalized Cauchy (GC) matrices retain the advantage of a maximum branch number. We investigate the properties of such matrices in this study. First, we provide a construction of GC matrices. The proposed construction guarantees that most of the (binary) entries in a GC matrix are zero, thereby reducing the search space for cheap GC matrices considerably. Second, we minimize the number of different sub-matrices in a GC matrix to make it more suitable for lookup table implementation, we call this a compact GC matrix. We then elaborate the structure of such compact GC matrices to consider all possible matrices and thus obtain the number of compact GC matrices. Finally, we consider the involutory potential of compact GC matrices. In particular, we prove that any compact GC matrix can be modified into an involutory one through a series of column-exchanging operations and a constant matrix multiplication. Through our experiment, we discover large-scale GC matrices, which can facilitate the future design of involutory component-based ciphers. Our best constructions can reduce the number of XOR gates in the higher-level diffusion layers in Hierocrypt-L1 and Hierocrypt-3 by 35.1\% and 50\%, respectively, while providing the same number of active S-boxes. Moreover, compared with the existing ones, the involutory nature of the new matrices allows for equally efficient diffusion in both encryption and decryption.},
  archive      = {J_ISCI},
  author       = {Ting Cui and Shiwei Chen and Chenhui Jin and Haoran Zheng},
  doi          = {10.1016/j.ins.2020.12.022},
  journal      = {Information Sciences},
  pages        = {297-312},
  shortjournal = {Inf. Sci.},
  title        = {Construction of higher-level MDS matrices in nested SPNs},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). A little bit flexibility on headway distribution is enough:
Data-driven optimization of subway regenerative energy. <em>ISCI</em>,
<em>554</em>, 276–296. (<a
href="https://doi.org/10.1016/j.ins.2020.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging energy-efficient management approach, the essential idea of subway regenerative energy optimization is to maximize the absorption of energy generated from train deceleration by adjusting train schedules. In the extant literature, performance evaluation and optimization rely on synthetic data (e.g., computer simulations) and train energy-efficient operation (EEO) strategy. However, when compared to real automatic train operation (ATO) data, the above-mentioned method exhibits significant errors. In this work, we develop a new optimization method driven by real ATO data for maximizing subway regenerative energy based on the following three steps: first, we provide a high-frequency ATO data-driven method for simulating the amount of regenerative energy absorption; second, we propose a concept of uniformity to measure the homogeneous degree of headway distribution; third, we formulate a headway optimization model to maximize the regenerative energy absorption under uniformity constraint. To handle the high complexity of the ATO data-driven objective function (e.g., non-monotonicity, non-convexity, multi-modality), we propose an improved genetic algorithm with multiple crossover and mutation operators to search for near-optimal solutions, in which an adaptive operator selection mechanism with reduction process on ATO data is considered for speeding up the regenerative energy simulation and optimization. The effectiveness of the proposed method is confirmed by using the real ATO data of Beijing Subway Changping line. Our numerical study reveals that, benchmarked with the uniform headway distribution (the policy that is presently in use), our proposed approach achieves a relative improvement of 7.75\% at off-peak hours and 42.44\% at peak hours for the regenerative energy absorption; and we show that such a significant performance improvement is obtained by allowing a small level of scheduling flexibility (less than 6\% relaxation on uniformity level).},
  archive      = {J_ISCI},
  author       = {Xiang Li and Bowen Zhang and Yunan Liu},
  doi          = {10.1016/j.ins.2020.12.030},
  journal      = {Information Sciences},
  pages        = {276-296},
  shortjournal = {Inf. Sci.},
  title        = {A little bit flexibility on headway distribution is enough: Data-driven optimization of subway regenerative energy},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian network based label correlation analysis for
multi-label classifier chain. <em>ISCI</em>, <em>554</em>, 256–275. (<a
href="https://doi.org/10.1016/j.ins.2020.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifier chain (CC) is a multi-label learning approach that constructs a sequence of binary classifiers according to a label order. Each classifier in the sequence is responsible for predicting the relevance of one label. When training the classifier for a label, proceeding labels will be taken as extended features. If the extended features are highly correlated to the label, the performance will be improved, otherwise, the performance will not be influenced or even degraded. How to discover label correlation and determine the label order is critical for CC approach. This paper employs Bayesian network (BN) to model the label correlations and proposes a new BN-based CC method (BNCC). Conditional entropy is used to describe the dependency relations among labels, and a BN is built up by taking nodes as labels and weights of edges as their dependency relations. A new scoring function is proposed to evaluate a BN structure, and a heuristic algorithm is introduced to optimize the BN. At last, by applying topological sorting on the nodes of the optimized BN, the label order for constructing CC model is derived. Experiments demonstrate the feasibility and effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Ran Wang and Suhe Ye and Ke Li and Sam Kwong},
  doi          = {10.1016/j.ins.2020.12.010},
  journal      = {Information Sciences},
  pages        = {256-275},
  shortjournal = {Inf. Sci.},
  title        = {Bayesian network based label correlation analysis for multi-label classifier chain},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A many-objective evolutionary algorithm with reference
points-based strengthened dominance relation. <em>ISCI</em>,
<em>554</em>, 236–255. (<a
href="https://doi.org/10.1016/j.ins.2020.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main issues for the optimization of many-objective evolutionary are about two aspects: the balance between convergence and diversity, and increasing the selection pressure toward the true Pareto-optimal front. To overcome these difficulties, a new Reference Points-based Strengthened dominance relation (RPS-dominance) is proposed and integrated into NSGA-II, named RPS-NSGA-II. It introduces a reference point set and convergence metric Cov to distinguish Pareto-equipment solutions and further stratifies them. The performance of RPS-NSGA-II is evaluated by the WFG and MaF series benchmark problems. Extensive experimental results demonstrate that RPS-NSGA-II has the competitiveness and frequently better results when compared against the main existing algorithm (five recently proposed decomposition-based MOEAs) on 90 commonly-used benchmark problems involving up to 20 objectives.},
  archive      = {J_ISCI},
  author       = {Qinghua Gu and Huayang Chen and Lu Chen and Xinhong Li and Neal N. Xiong},
  doi          = {10.1016/j.ins.2020.12.025},
  journal      = {Information Sciences},
  pages        = {236-255},
  shortjournal = {Inf. Sci.},
  title        = {A many-objective evolutionary algorithm with reference points-based strengthened dominance relation},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LBAC: A lightweight blockchain-based access control scheme
for the internet of things. <em>ISCI</em>, <em>554</em>, 222–235. (<a
href="https://doi.org/10.1016/j.ins.2020.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute-based encryption (ABE) is considered to be one of the most suitable schemes for cryptographic access control in the big data environment. But it still faces many challenges to be applied in the Internet of Things (IoT). ABE is implemented based on bilinear pairing, which is considered to be an expensive operation. However, there are lots of IoT devices with constrained resources. Proxy re-encryption methods based on the cloud are proposed to reduce computing overhead on the user side, but an untrusted cloud may give incorrect computing results to mislead users. To solve this problem, an access control scheme with lightweight decryption based on ABE and blockchain technologies is proposed. We assume that the cloud is untrusted, and guarantee the accuracy of proxy re-encryption calculation based on blockchain. In addition, how to encourage users to obtain authorization through blockchain and record access behavior on the blockchain is a problem worthy of attention. This paper proposes a user credibility incentive mechanism, which calculates the user’s credibility according to the user’s access behavior and gives a reputation score, so as to dynamically adjust the endorsement protocol. Security analysis and experimental results show that the proposed method is reliable and efficient.},
  archive      = {J_ISCI},
  author       = {Xuanmei Qin and Yongfeng Huang and Zhen Yang and Xing Li},
  doi          = {10.1016/j.ins.2020.12.035},
  journal      = {Information Sciences},
  pages        = {222-235},
  shortjournal = {Inf. Sci.},
  title        = {LBAC: A lightweight blockchain-based access control scheme for the internet of things},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution and sine cosine algorithm based novel
hybrid multi-objective approaches for numerical association rule mining.
<em>ISCI</em>, <em>554</em>, 198–221. (<a
href="https://doi.org/10.1016/j.ins.2020.12.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In association rules mining from data that have numeric-valued attributes, automatically adjusting the attribute intervals at the time of the mining process without a preprocess is very critical for preventing data loss and attribute interactions. In this paper, differential evolution and sine cosine algorithm based novel hybrid multi-objective evolutionary optimization methods are proposed for rapidly and directly mining the reduced high-quality numerical association rules by simultaneously adjusting the relevant intervals of related attributes without finding the frequent itemsets . These algorithms perform a global search and find the high-quality rules set in only one execution by modeling the rule mining task as a multi-objective problem that simultaneously meets different conflicting metrics. The algorithms proposed in this paper ensure the discovered rules to have high confidence and support and to be comprehensible. The proposed methods automate the rule mining process by directly finding the minimum intervals for the attributes and eliminating the need for minimum confidence and minimum support determined beforehand for each data set. The performances of new algorithms proposed in this study were tested with those of the state-of-the-art algorithms. The results show superiority of the proposed methods on the data sets that contain fewer attributes and higher number of instances.},
  archive      = {J_ISCI},
  author       = {Elif Varol Altay and Bilal Alatas},
  doi          = {10.1016/j.ins.2020.12.055},
  journal      = {Information Sciences},
  pages        = {198-221},
  shortjournal = {Inf. Sci.},
  title        = {Differential evolution and sine cosine algorithm based novel hybrid multi-objective approaches for numerical association rule mining},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rebalancing stochastic demands for bike-sharing networks
with multi-scenario characteristics. <em>ISCI</em>, <em>554</em>,
177–197. (<a href="https://doi.org/10.1016/j.ins.2020.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bike-sharing networks have become a carbon-emission and environmentally friendly form of transportation in recent years. However, the asymmetric demand patterns of user behaviour, both temporally and spatially, inevitably lead to an imbalance in the distribution of shared bikes in cities, thereby becoming the greatest obstacle to the networks’ development. Based on the real-world data of cycling trips, we analyse the challenging problem of imbalanced bike distribution from the entire-city perspective, establishing that the static rebalancing demand for the whole city is a stochastic variable with multi-scenario characteristics. On this basis, we develop an integer programming model to consider multiple rebalancing vehicles with time-varying rental costs, to alleviate the imbalanced bike distribution, while also analysing the intrinsic properties of such a model. We further propose a chance constraint programming model, optimising a bike-sharing network through the implementation of various genetic algorithms that employ block crossover and variable mutation operators. We reveal the inability of deterministic models in addressing the real-world problem of rebalancing demands for operational bike-sharing. In the meantime, supported with stochastic simulation, we demonstrate that the proposed approach can resolve this problem both effectively and efficiently, ensuring the delivery of a high-level bike-sharing service across an entire metropolitan city.},
  archive      = {J_ISCI},
  author       = {Guanhua Ma and Bowen Zhang and Changjing Shang and Qiang Shen},
  doi          = {10.1016/j.ins.2020.12.044},
  journal      = {Information Sciences},
  pages        = {177-197},
  shortjournal = {Inf. Sci.},
  title        = {Rebalancing stochastic demands for bike-sharing networks with multi-scenario characteristics},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid data-level ensemble to enable learning from highly
imbalanced dataset. <em>ISCI</em>, <em>554</em>, 157–176. (<a
href="https://doi.org/10.1016/j.ins.2020.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highly imbalanced class distribution has been well-recognized as a major cause of performance degradation for most supervised learning algorithms. Unfortunately, such detrimental distribution inherently occurs in various real-world applications. In this work, we developed a hybrid data-level ensemble (HD-Ensemble), which integrates ensemble learning with the union of a margin-based undersampling and diversity-enhancing oversampling. The proposed undersampling method filters out certain number of unrepresentative majority instances based on an unsupervised margin definition, while the proposed oversampling method generates diverse minority instances according to the behavior of ensemble learning. The combination of the two data-level approaches serves a twofold purpose of balancing the data distribution, and optimizing the fundamental properties (e.g., margin distribution and diversity) of the ensemble, therefore, the inferior performance caused by adopting single data-level approach can be better addressed. Targeting on binary classification task, we evaluated the HD-Ensemble on 42 highly imbalanced datasets, which exhibited a considerable variety in sample number (ranging from 129 to 20,034), feature number (ranging from 3 to 5,000) and imbalance ratio (ranging from 9.08 to 970.6). Experimental results demonstrated the performance advantages of proposed HD-Ensemble over ten other ensemble solutions.},
  archive      = {J_ISCI},
  author       = {Zhi Chen and Jiang Duan and Li Kang and Guoping Qiu},
  doi          = {10.1016/j.ins.2020.12.023},
  journal      = {Information Sciences},
  pages        = {157-176},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid data-level ensemble to enable learning from highly imbalanced dataset},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential cryptanalysis of image cipher using block-based
scrambling and image filtering. <em>ISCI</em>, <em>554</em>, 145–156.
(<a href="https://doi.org/10.1016/j.ins.2020.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, an image encryption algorithm using block-based scrambling and image filtering was proposed by Hua et al. The main idea of the encryption algorithm is to utilize image filtering to permutate and diffuse plain-images. In this paper, we analyze the security problems of the encryption algorithm in detail and break the encryption using a codebook attack. A linear relation between plain-images and cipher-images is disclosed by differential cryptanalysis. Using the linear relation, we build a codebook containing ( M × N + 1 M×N+1 ) pairs of cipher-images and the corresponding plain-images, where M × N M×N is the size of plain-images. The proposed codebook attack indicates that the encryption algorithm is insecure. To defend the codebook attack, an improved algorithm is proposed. Experimental results show that the improved algorithm not only inherits the merits of the original algorithm, but also improves security robustness against the proposed differential cryptanalysis.},
  archive      = {J_ISCI},
  author       = {Feng Yu and Xinhui Gong and Hanpeng Li and Shihong Wang},
  doi          = {10.1016/j.ins.2020.12.037},
  journal      = {Information Sciences},
  pages        = {145-156},
  shortjournal = {Inf. Sci.},
  title        = {Differential cryptanalysis of image cipher using block-based scrambling and image filtering},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiscale deep bidirectional gated recurrent neural
networks based prognostic method for complex non-linear degradation
systems. <em>ISCI</em>, <em>554</em>, 120–144. (<a
href="https://doi.org/10.1016/j.ins.2020.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable estimation of the remaining useful life (RUL) of complex engineered systems plays a vital role in avoiding undue maintenance situations while guaranteeing system safety. However, efficient tracking of RUL often gets hampered by the prerequisite for prior knowledge regarding degradation characteristics of critical components, which are not available in most cases. Additionally, machine learning techniques face difficulties in adapting and modeling degradation trends in the presence of equipment’s complex working environments. To address these issues, we present a novel data-driven feature learning approach based on a multi-scale deep bidirectional gated recurrent neural network (MDBGRU). The MDBGRU network can: i) automatically learns both local and global information in addition to temporal variations in the multivariate sensor data; ii) capture salient discriminative features characterizing the system complexity; iii) overcome the pre-expertise requirement on multiple sub-components of the system; and iv) curb shortcomings of machine learning methods. Extensive experiments are performed on the C-MAPSS dataset to evaluate the prognostic capability of the proposed method. Compared with the existing works, our network attains enhanced prediction accuracy with an overall improvement of 13.54\%, suggesting this as a new and promising RUL estimation approach.},
  archive      = {J_ISCI},
  author       = {Sourajit Behera and Rajiv Misra and Alberto Sillitti},
  doi          = {10.1016/j.ins.2020.12.032},
  journal      = {Information Sciences},
  pages        = {120-144},
  shortjournal = {Inf. Sci.},
  title        = {Multiscale deep bidirectional gated recurrent neural networks based prognostic method for complex non-linear degradation systems},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical data generator based on tree-structured stick
breaking process for benchmarking clustering methods. <em>ISCI</em>,
<em>554</em>, 99–119. (<a
href="https://doi.org/10.1016/j.ins.2020.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new variant of Hierarchical Cluster Analysis is gaining interest in the field of Machine Learning , called Object Cluster Hierarchy . Being still at an early stage of development, the lack of tools for systematic analysis of Object Cluster Hierarchies inhibits further improvement of this concept. In this paper we address this issue by proposing a generator of synthetic hierarchical data that can be used for benchmarking Object Cluster Hierarchy generation methods. The article presents a thorough empirical and theoretical analysis of the generator and provides guidance on how to control its parameters. The conducted experiments show the usefulness of the data generator capable of producing a wide range of differently structured data. Furthermore, datasets that represent the most common types of hierarchies are generated and made available to the public for benchmarking, along with the developed generator ( http://kio.pwr.edu.pl/?page_id=396 ).},
  archive      = {J_ISCI},
  author       = {Łukasz P. Olech and Michał Spytkowski and Halina Kwaśnicka and Zbigniew Michalewicz},
  doi          = {10.1016/j.ins.2020.12.020},
  journal      = {Information Sciences},
  pages        = {99-119},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical data generator based on tree-structured stick breaking process for benchmarking clustering methods},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal tracking control based on reinforcement learning
value iteration algorithm for time-delayed nonlinear systems with
external disturbances and input constraints. <em>ISCI</em>,
<em>554</em>, 84–98. (<a
href="https://doi.org/10.1016/j.ins.2020.11.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the design of an optimal tracking controller for a class of nonlinear continuous-time systems with time-delay, mismatched external disturbances and input constraints. The technique of integral reinforcement learning (IRL) is utilized for determining the control input that optimizes an objective function. To enable the usage of an estimation of the external disturbances in the recursive objective function, a disturbance observer is designed. For the derivation of the optimal control input, a Hamilton-Jacobi-Bellman (HJB) equation is employed and solved using the iterative IRL algorithm. The proposed approach guarantees that in the presence of mismatched disturbances, the output of the time-delayed nonlinear system tracks the desired trajectory with bounded error. A critic neural network is designed for the implementation of the proposed approach. The efficiency of the method is illustrated by a simulation example.},
  archive      = {J_ISCI},
  author       = {Mehdi Mohammadi and Mohammad Mehdi Arefi and Peyman Setoodeh and Okyay Kaynak},
  doi          = {10.1016/j.ins.2020.11.057},
  journal      = {Information Sciences},
  pages        = {84-98},
  shortjournal = {Inf. Sci.},
  title        = {Optimal tracking control based on reinforcement learning value iteration algorithm for time-delayed nonlinear systems with external disturbances and input constraints},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast density peaks clustering algorithm with sparse
search. <em>ISCI</em>, <em>554</em>, 61–83. (<a
href="https://doi.org/10.1016/j.ins.2020.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given a large unlabeled set of complex data, how to efficiently and effectively group them into clusters remains a challenging problem. Density peaks clustering (DPC) algorithm is an emerging algorithm, which identifies cluster centers based on a decision graph. Without setting the number of cluster centers, DPC can effectively recognize the clusters. However, the similarity between every two data points must be calculated to construct a decision graph, which results in high computational complexity . To overcome this issue, we propose a fast sparse search density peaks clustering (FSDPC) algorithm to enhance the DPC, which constructs a decision graph with fewer similarity calculations to identify cluster centers quickly. In FSDPC, we design a novel sparse search strategy to measure the similarity between the nearest neighbors of each data points. Therefore, FSDPC can enhance the efficiency of the DPC while maintaining satisfactory results. We also propose a novel random third-party data point method to search the nearest neighbors, which introduces no additional parameters or high computational complexity . The experimental results on synthetic datasets and real-world datasets indicate that the proposed algorithm consistently outperforms the DPC and other state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Xiao Xu and Shifei Ding and Yanru Wang and Lijuan Wang and Weikuan Jia},
  doi          = {10.1016/j.ins.2020.11.050},
  journal      = {Information Sciences},
  pages        = {61-83},
  shortjournal = {Inf. Sci.},
  title        = {A fast density peaks clustering algorithm with sparse search},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-modal neural machine translation with deep semantic
interactions. <em>ISCI</em>, <em>554</em>, 47–60. (<a
href="https://doi.org/10.1016/j.ins.2020.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the conventional attentional encoder-decoder framework, multi-modal neural machine translation (NMT) further incorporates spatial visual features through a separate visual attention mechanism . In this aspect, most current multi-modal NMT models first separately learn the semantic representations of text and image and then independently produce two modalities of context vectors for word predictions, neglecting their semantic interactions. In this paper, we argue that learning text-image semantic interactions is more reasonable in the sense of jointly modeling two modalities for multi-modal NMT and propose a novel multi-modal NMT model with deep semantic interactions. Specifically, our model extends the conventional multi-modal NMT by introducing the following two attention neural networks : (1) a bi-directional attention network for modeling text and image representations, where the semantic representations of text are learned by referring to the image representations, and vice versa; (2) a co-attention network for refining text and image context vectors, which first summarizes the text into a context vector, then attends it to the image for obtaining the text-aware visual context vector. The final context vector is calculated by re-attending the visual context vector to the text. Results on the Multi30k dataset for different language pairs show that our model significantly improves on the state-of-the-art baselines. We have released our code at https://github.com/DeepLearnXMU/MNMT .},
  archive      = {J_ISCI},
  author       = {Jinsong Su and Jinchang Chen and Hui Jiang and Chulun Zhou and Huan Lin and Yubin Ge and Qingqiang Wu and Yongxuan Lai},
  doi          = {10.1016/j.ins.2020.11.024},
  journal      = {Information Sciences},
  pages        = {47-60},
  shortjournal = {Inf. Sci.},
  title        = {Multi-modal neural machine translation with deep semantic interactions},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Target attack on biomedical image segmentation model based
on multi-scale gradients. <em>ISCI</em>, <em>554</em>, 33–46. (<a
href="https://doi.org/10.1016/j.ins.2020.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research shows that deep neural networks are vulnerable to adversarial examples due to the highly linear nature of deep neural networks (DNNs). Therefore, adversarial examples involve security of deep learning. However, there is a lack of research on the impact of adversarial examples on the biomedical segmentation model. Since a large part of medical image problems are segmentation problems, this paper analyzes the impact of adversarial examples on image segmentation models based on deep learning. We propose to fool the biomedical segmentation model and generate target segmentation masks with feature space perturbations and cross-entropy loss function. Different from the traditional gradient-based attack methods, which usually use the gradient of the final loss function, this paper adopts a Multi-scale Attack (MSA) method based on multi-scale gradients. Extensive experiments to attack U-Net on the ISIC skin lesion segmentation challenge dataset and the glaucoma optic disc segmentation dataset have proved that the predicted mask generated by this method has a high intersection over union(IoU) and pixel accuracy with the target mask. Besides, the L 2 L2 and L ∞ L∞ distances between the adversarial and clean examples are reduced compared with the state-of-the-art method.},
  archive      = {J_ISCI},
  author       = {Mingwen Shao and Gaozhi Zhang and Wangmeng Zuo and Deyu Meng},
  doi          = {10.1016/j.ins.2020.12.013},
  journal      = {Information Sciences},
  pages        = {33-46},
  shortjournal = {Inf. Sci.},
  title        = {Target attack on biomedical image segmentation model based on multi-scale gradients},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure fine-grained friend-making scheme based on
hierarchical management in mobile social networks. <em>ISCI</em>,
<em>554</em>, 15–32. (<a
href="https://doi.org/10.1016/j.ins.2020.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of mobile social networks (MSNs) and smart mobile devices , mobile users can easily make new social interactions with others via their smartphones. Unfortunately, users enjoy these conveniences at the cost of revealing their personal data. The inevitable release of information conflicts with increasing privacy concerns. To address this problem, we propose a hierarchical management scheme for friend matching using attributes, which aims to facilitate secure friend discovery in MSNs. The scheme involves the establishment of several attribute centers, which perform fine-grained management based on various user attributes. The user attributes are used to generate attribute sub-keys. After meeting the conditions set by the friend-making initiator, the friend-making requester combines the sub-keys into a complete decryption key and decrypts the user data file in the friend-making center. By introducing hierarchical and sorting management of attribute sub-keys, we prevent the crypto key disclosure and single point failure, which usually happens because single-authority management centers are vulnerable to attack. The security and performance of this system were analyzed and evaluated via simulations, and the results indicate that the proposed scheme is CPA-safe.},
  archive      = {J_ISCI},
  author       = {Lei Zhou and Entao Luo and Guojun Wang and Shui Yu},
  doi          = {10.1016/j.ins.2020.12.012},
  journal      = {Information Sciences},
  pages        = {15-32},
  shortjournal = {Inf. Sci.},
  title        = {Secure fine-grained friend-making scheme based on hierarchical management in mobile social networks},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Deep random walk of unitary invariance for large-scale data
representation. <em>ISCI</em>, <em>554</em>, 1–14. (<a
href="https://doi.org/10.1016/j.ins.2020.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data representation aims at learning an efficient low-dimensional representation, which is always a challenging task in machine learning and computer vision. It can largely improve the performance of specific learning tasks. Unsupervised methods are extensively applied to data representation, which considers the internal connection among data. Most of existing unsupervised models usually use a specific norm to favor certain distributions of the input data, leading to an unsustainable encouraging performance for given learning tasks. In this paper, we propose an efficient data representation method to address large-scale feature representation problems, where the deep random walk of unitary invariance is exploited for learning discriminative features. First, the data representation is formulated as deep random walk problems, where unitarily invariant norms are employed to capture diverse beneficial perspectives hidden in the data. It is embedded into a state transition matrix model, where an arbitrary number of transition steps is available for an accurate affinity evaluation. Second, data representation problems are then transformed as high-order matrix factorization tasks with unitary invariance. Third, a closed-form solution is proved for the formulated data representation problem, which may provide a new perspective for solving high-order matrix factorization problems. Finally, extensive comparative experiments are conducted in publicly available real-world data sets. In addition, experimental results demonstrate that the proposed method achieves better performance than other compared state-of-the-art approaches in terms of data clustering.},
  archive      = {J_ISCI},
  author       = {Shiping Wang and Zhaoliang Chen and William Zhu and Fei-Yue Wang},
  doi          = {10.1016/j.ins.2020.11.039},
  journal      = {Information Sciences},
  pages        = {1-14},
  shortjournal = {Inf. Sci.},
  title        = {Deep random walk of unitary invariance for large-scale data representation},
  volume       = {554},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RSMOTE: A self-adaptive robust SMOTE for imbalanced problems
with label noise. <em>ISCI</em>, <em>553</em>, 397–428. (<a
href="https://doi.org/10.1016/j.ins.2020.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced classification is an important task in supervised learning, and Synthetic Minority Over-sampling Technique (SMOTE) is the most common method to address it. However, the performance of SMOTE deteriorates in the presence of label noise. Current generalizations of SMOTE try to tackle this problem by either selecting some samples in minority class as seed samples or combining SMOTE with a certain noise filter. Unfortunately, the former approach usually introduces extra parameters difficult to be optimized, and the latter one relies heavily on the performance of certain specific noise filter. In this paper, a self-adaptive robust SMOTE, called RSMOTE, is proposed for imbalanced classification with label noise. In RSMOTE, relative density has been introduced to measure the local density of every minority sample, and the non-noisy minority samples are divided into the borderline samples and safe samples adaptively basing their distinguishing characteristics of relative density. In addition, we reweigh the number that needs to be generated by every minority samples based on its chaotic level. Furthermore, we generate new samples within in the borderline area and safe area respectively to enhance the separability of the boundary. RSMOTE does not rely on any specific noise filter nor introduce any extra parameters. The experimental results demonstrate that the proposed approach performs better than the comparison methods in terms of several metrics, including Precision, Recall, Area Under the Curve (AUC), F1-measure, and G-mean. The implementation of the proposed RSMOTE in programming language Python is available at https://github.com/syxiaa/RSMOTE.},
  archive      = {J_ISCI},
  author       = {Baiyun Chen and Shuyin Xia and Zizhong Chen and Binggui Wang and Guoyin Wang},
  doi          = {10.1016/j.ins.2020.10.013},
  journal      = {Information Sciences},
  pages        = {397-428},
  shortjournal = {Inf. Sci.},
  title        = {RSMOTE: A self-adaptive robust SMOTE for imbalanced problems with label noise},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Group decision making with incomplete q-rung orthopair
fuzzy preference relations. <em>ISCI</em>, <em>553</em>, 376–396. (<a
href="https://doi.org/10.1016/j.ins.2020.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel group decision making (GDM) method in incomplete q -rung orthopair fuzzy preference relations ( q -ROFPRs) environments. We propose an additive consistency definition, which is characterized by a q -rung orthopair fuzzy priority vector. The property of the proposed additive consistency definition is offered and a model to obtain missing judgments in incomplete q -ROFPRs is proposed. We present an approach to adjust the inconsistency for q -ROFPRs, propose a model to obtain the priority vector, and propose a method to increase consensus degrees of q -ROFPRs. Finally, we present a GDM method in incomplete q -ROFPRs environments and use two illustrative examples and some comparisons to illustrate that our method outperforms the existing methods for GDM in incomplete q -ROFPRs environments. The proposed GDM method offers us a useful way for GDM in incomplete q -ROFPRs environments.},
  archive      = {J_ISCI},
  author       = {Zhiming Zhang and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2020.10.015},
  journal      = {Information Sciences},
  pages        = {376-396},
  shortjournal = {Inf. Sci.},
  title        = {Group decision making with incomplete q-rung orthopair fuzzy preference relations},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A guided FP-growth algorithm for mining multitude-targeted
item-sets and class association rules in imbalanced data. <em>ISCI</em>,
<em>553</em>, 353–375. (<a
href="https://doi.org/10.1016/j.ins.2020.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying frequent item-sets is a popular data-mining task. It consists of finding sets of items frequently appearing in data. Yet, finding all frequent item-sets in large or dense datasets may be time-consuming, and a user may be interested merely in some specific item-sets rather than all of them. Recently, methods have been proposed for targeted item-set mining; that is to calculate the support of some item-sets of interest. Though this approach is often more suitable for real applications than traditional item-set mining approaches, performance remains an issue. To address that issue, this paper presents a novel algorithm for multitude-targeted mining, named Guided Frequent Pattern-Growth (GFP-Growth). The GFP-Growth algorithm is designed to quickly mine a given set of item-sets using a small amount of memory. This paper proves that GFP-Growth yields the exact frequency-counts for each item-set of interest. It further shows that GFP-Growth can boost the performance for several problems requiring item-set mining. We specifically study the problem of generating minority-class rules from imbalanced data and develop the Minority-Report Algorithm (MRA) that uses GFP-Growth to solve this problem efficiently. We prove several theoretical properties of MRA and present experimental results showing substantial performance gain.},
  archive      = {J_ISCI},
  author       = {Lior Shabtay and Philippe Fournier-Viger and Rami Yaari and Itai Dattner},
  doi          = {10.1016/j.ins.2020.10.020},
  journal      = {Information Sciences},
  pages        = {353-375},
  shortjournal = {Inf. Sci.},
  title        = {A guided FP-growth algorithm for mining multitude-targeted item-sets and class association rules in imbalanced data},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compressed monte carlo with application in particle
filtering. <em>ISCI</em>, <em>553</em>, 331–352. (<a
href="https://doi.org/10.1016/j.ins.2020.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian models have become very popular over the last years in several fields such as signal processing, statistics , and machine learning . Bayesian inference requires the approximation of complicated integrals involving posterior distributions . For this purpose, Monte Carlo (MC) methods, such as Markov Chain Monte Carlo and importance sampling algorithms , are often employed. In this work, we introduce the theory and practice of a Compressed MC (C-MC) scheme to compress the statistical information contained in a set of random samples. In its basic version, C-MC is strictly related to the stratification technique, a well-known method used for variance reduction purposes. Deterministic C-MC schemes are also presented, which provide very good performance. The compression problem is strictly related to the moment matching approach applied in different filtering techniques, usually called as Gaussian quadrature rules or sigma-point methods. C-MC can be employed in a distributed Bayesian inference framework when cheap and fast communications with a central processor are required. Furthermore, C-MC is useful within particle filtering and adaptive IS algorithms, as shown by three novel schemes introduced in this work. Six numerical results confirm the benefits of the introduced schemes, outperforming the corresponding benchmark methods. A related code is also provided. (The code is provided at http://www.lucamartino.altervista.org/CMC_CODE_pub_EX1.zip )},
  archive      = {J_ISCI},
  author       = {Luca Martino and Víctor Elvira},
  doi          = {10.1016/j.ins.2020.10.022},
  journal      = {Information Sciences},
  pages        = {331-352},
  shortjournal = {Inf. Sci.},
  title        = {Compressed monte carlo with application in particle filtering},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention enhanced long short-term memory network with
multi-source heterogeneous information fusion: An application to BGI
genomics. <em>ISCI</em>, <em>553</em>, 305–330. (<a
href="https://doi.org/10.1016/j.ins.2020.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent availability of enormous amounts of both data and computing power has created new opportunities for predictive modeling. This paper compiles an analytical framework based on multiple sources of data including daily trading data, online news, derivative technical indicators, and time–frequency features decomposed from closing prices. We also provide a real-life demonstration of how to combine and capitalize on all available information to predict the stock price of BGI Genomics. Moreover, we apply a long short-term memory (LSTM) network equipped with an attention mechanism to identify long-term temporal dependencies and adaptively highlight key features. We further examine the learning capabilities of the network for specific tasks, including forecasting the next day’s price direction and closing price and developing trading strategies, comparing its statistical accuracy and trading performance with those of methods based on logistic regression, support vector machine, gradient boosting decision trees, and the original LSTM model. The experimental results for BGI Genomics demonstrate that the attention enhanced LSTM model remarkably improves prediction performance through multi-source heterogeneous information fusion, highlighting the significance of online news and time–frequency features, as well as exemplifying and validating our proposed framework.},
  archive      = {J_ISCI},
  author       = {Qun Zhang and Lijun Yang and Feng Zhou},
  doi          = {10.1016/j.ins.2020.10.023},
  journal      = {Information Sciences},
  pages        = {305-330},
  shortjournal = {Inf. Sci.},
  title        = {Attention enhanced long short-term memory network with multi-source heterogeneous information fusion: An application to BGI genomics},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary algorithm and multifactorial evolutionary
algorithm on clustered shortest-path tree problem. <em>ISCI</em>,
<em>553</em>, 280–304. (<a
href="https://doi.org/10.1016/j.ins.2020.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In literature, Clustered Shortest-Path Tree Problem (CluSPT) is an NP-hard problem. Previous studies focus on approximation algorithms which search for an optimal solution in relatively large space. Thus, these algorithms consume a large amount of computational resources while the quality of obtained results is lower than expected. In order to enhance the performance of the search process, this paper proposes two different approaches which are inspired by two perspectives of analyzing the CluSPT. The first approach intuition is to narrow down the search space by reducing the original graph into a multi-graph with fewer nodes while maintaining the ability to find the optimal solution. The problem is then solved by a proposed evolutionary algorithm . This approach performs well on those datasets having small number of edges between clusters. However, the increase in the size of the datasets would cause the excessive redundant edges in multi-graph that pressurize searching for potential solutions. The second approach overcomes this limitation by breaking down the multi-graph into a set of simple graphs. Every graph in this set is corresponding to a mutually exclusive search space. From this point of view, the problem could be modeled into a bi-level optimization problem in which the search space includes two nested search spaces. Accordingly, the Nested Local Search Evolutionary Algorithm (N-LSEA) is introduced to search for the optimal solution of glscluspt, the upper level uses a simple Local Search algorithm while the lower level uses the Genetic Algorithm . Due to the neighboring characteristics of the local search step in the upper level, the lower level reduced graphs share the common traits among each others. Thus, the Multi-tasking Local Search Evolutionary Algorithm (MLSEA) is proposed to take advantages of these underlying commonalities by exploiting the implicit transfer across similar tasks of multi-tasking schemes. The improvement in experimental results over N-LSEA via this multi-tasking scheme inspires the future works to apply M-LSEA in graph-based problems, especially for those could be modeled into bi-level optimization.},
  archive      = {J_ISCI},
  author       = {Phan Thi Hong Hanh and Pham Dinh Thanh and Huynh Thi Thanh Binh},
  doi          = {10.1016/j.ins.2020.10.024},
  journal      = {Information Sciences},
  pages        = {280-304},
  shortjournal = {Inf. Sci.},
  title        = {Evolutionary algorithm and multifactorial evolutionary algorithm on clustered shortest-path tree problem},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel method for speed training acceleration of recurrent
neural networks. <em>ISCI</em>, <em>553</em>, 266–279. (<a
href="https://doi.org/10.1016/j.ins.2020.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although recurrent neural networks (RNNs) perfectly solve many difficult problems, their computational complexity significantly increases training time. Therefore, the primary problem with applying RNNs is to shorten the time needed to train and operate a network. An effective solution to this problem is to use parallel processing . In the paper, a particular approach for the Jordan network will be shown, however, the presented idea is applicable to other RNN structures. This type of network is characterized by natural parallelism , and in the paper, this feature is used to significantly accelerate the learning process. High-performance learning has been achieved using a novel parallel three-dimensional architecture. The presented solutions can be implemented in digital hardware.},
  archive      = {J_ISCI},
  author       = {Jarosław Bilski and Leszek Rutkowski and Jacek Smoląg and Dacheng Tao},
  doi          = {10.1016/j.ins.2020.10.025},
  journal      = {Information Sciences},
  pages        = {266-279},
  shortjournal = {Inf. Sci.},
  title        = {A novel method for speed training acceleration of recurrent neural networks},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differentially private data publishing for arbitrarily
partitioned data. <em>ISCI</em>, <em>553</em>, 247–265. (<a
href="https://doi.org/10.1016/j.ins.2020.10.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many models have been proposed to preserve data privacy for different data publishing scenarios. Among these models, ∊ ∊ ∊ -differential privacy is receiving increasing attention because it does not make assumptions about adversaries’ prior knowledge and can provide a rigorous privacy guarantee. Although there are numerous proposed approaches using ∊ ∊ ∊ -differential privacy to publish centralized data of a single-party, differentially private data publishing for distributed data among multiple parties has not been studied extensively. The challenge in releasing distributed data is how to protect privacy and integrity during collaborative data integration and anonymization . In this paper, we present the first differentially private solution to anonymize data from two parties with arbitrarily partitioned data in a semi-honest model. We aim at satisfying two privacy requirements: (1) the collaborative anonymization should satisfy differential privacy ; (2) one party cannot learn extra information about the other party’s data except for the final result and the information that can be inferred from the result. To meet these privacy requirements, we propose a distributed differentially private anonymization algorithm and guarantee that each step of the algorithm satisfies the definition of secure two-party computation. In addition to the security and cost analyses, we demonstrate the utility of our algorithm in classification analysis .},
  archive      = {J_ISCI},
  author       = {Rong Wang and Benjamin C.M. Fung and Yan Zhu and Qiang Peng},
  doi          = {10.1016/j.ins.2020.10.051},
  journal      = {Information Sciences},
  pages        = {247-265},
  shortjournal = {Inf. Sci.},
  title        = {Differentially private data publishing for arbitrarily partitioned data},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the existence of solutions to boundary value problems for
interval-valued differential equations under gH-differentiability.
<em>ISCI</em>, <em>553</em>, 225–246. (<a
href="https://doi.org/10.1016/j.ins.2020.10.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study first order interval-valued differential equations with the boundary value condition x ( 0 ) = α x ( T ) x(0)=αx(T) . By constructing proper operators, some sufficient conditions for the existence of solutions are provided for ⧹ α ∈ R ⧹ { 0 , 1 } α∈R⧹{0,1} , corresponding to non-periodic boundary value problems . At the end of this paper, some examples are shown to illustrate the theorems proved.},
  archive      = {J_ISCI},
  author       = {Hongzhou Wang and Rosana Rodríguez-López},
  doi          = {10.1016/j.ins.2020.10.052},
  journal      = {Information Sciences},
  pages        = {225-246},
  shortjournal = {Inf. Sci.},
  title        = {On the existence of solutions to boundary value problems for interval-valued differential equations under gH-differentiability},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Divide-and-conquer large scale capacitated arc routing
problems with route cutting off decomposition. <em>ISCI</em>,
<em>553</em>, 208–224. (<a
href="https://doi.org/10.1016/j.ins.2020.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capacitated arc routing problem is a very important problem with many practical applications. This paper focuses on the large scale capacitated arc routing problem. Traditional solution optimization approaches usually fail because of their poor scalability. The divide-and-conquer strategy has achieved great success in solving large scale optimization problems by decomposing the original large problem into smaller sub-problems and solving them separately. For arc routing, a commonly used divide-and-conquer strategy is to divide the tasks into subsets, and then solve the sub-problems induced by the task subsets separately. However, the success of a divide-and-conquer strategy relies on a proper task division, which is non-trivial due to the complex interactions between the tasks. This paper proposes a novel problem decomposition operator, named the route cutting off operator, which considers the interactions between the tasks in a sophisticated way. To examine the effectiveness of the route cutting off operator, we integrate it with two state-of-the-art divide-and-conquer algorithms, and compared with the original counterparts on a wide range of benchmark instances. The results show that the route cutting off operator can improve the effectiveness of the decomposition, and lead to significantly better results especially when the problem size is very large and the time budget is very tight.},
  archive      = {J_ISCI},
  author       = {Yuzhou Zhang and Yi Mei and Buzhong Zhang and Keqin Jiang},
  doi          = {10.1016/j.ins.2020.11.011},
  journal      = {Information Sciences},
  pages        = {208-224},
  shortjournal = {Inf. Sci.},
  title        = {Divide-and-conquer large scale capacitated arc routing problems with route cutting off decomposition},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural software vulnerability analysis using rich
intermediate graph representations of programs. <em>ISCI</em>,
<em>553</em>, 189–207. (<a
href="https://doi.org/10.1016/j.ins.2020.11.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security vulnerabilities are among the major concerns of modern software engineering . Successful results of machine learning techniques in various challenging applications have led to an emerging field of research to investigate the effectiveness of machine learning , and more recently, deep learning techniques, for the problem of software vulnerability analysis and discovery. In this paper, we explore the utilization of Graph Neural Networks as the latest trend and progress in the field of artificial neural networks . To this end, we propose an original neural vulnerability analysis approach, using customized intermediate graph representations of programs to train graph neural network models. Experimental results on a public suite of vulnerable programs show that the proposed approach is effective at the task of software vulnerability analysis. Additional empirical experiments answer complementary research questions about the proposed approach. In particular, we present experimental results for the challenging task of cross-project vulnerability analysis, with interesting insights on the capabilities of our novel approach. Furthermore, a software utility that was developed in the course of this study is also published as a further contribution to the research community.},
  archive      = {J_ISCI},
  author       = {Seyed Mohammad Ghaffarian and Hamid Reza Shahriari},
  doi          = {10.1016/j.ins.2020.11.053},
  journal      = {Information Sciences},
  pages        = {189-207},
  shortjournal = {Inf. Sci.},
  title        = {Neural software vulnerability analysis using rich intermediate graph representations of programs},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recruitment-imitation mechanism for evolutionary
reinforcement learning. <em>ISCI</em>, <em>553</em>, 172–188. (<a
href="https://doi.org/10.1016/j.ins.2020.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement learning , evolutionary algorithms and imitation learning are three principal methods to deal with continuous control tasks. Reinforcement learning is sample efficient, yet sensitive to hyperparameters settings and needs efficient exploration; Evolutionary algorithms are stable, but with low sample efficiency ; Imitation learning is both sample efficient and stable, however it requires the guidance of expert data. In this paper, we propose Recruitment-imitation Mechanism (RIM) for evolutionary reinforcement learning, a scalable framework that combines advantages of the three methods mentioned above. The core of this framework is a dual-actors and single critic reinforcement learning agent. This agent can recruit high-fitness actors from the population performing evolutionary algorithms , which instructs itself to learn from experience replay buffer. At the same time, low-fitness actors in the evolutionary population can imitate behavior patterns of the reinforcement learning agent and promote their fitness level. Reinforcement and imitation learners in this framework can be replaced with any off-policy actor-critic reinforcement learner and data-driven imitation learner. We evaluate RIM on a series of benchmarks for continuous control tasks in Mujoco. The experimental results show that RIM outperforms prior evolutionary or reinforcement learning methods. The performance of RIM’s components is significantly better than components of previous evolutionary reinforcement learning algorithm, and the recruitment using soft update enables reinforcement learning agent to learn faster than that using hard update.},
  archive      = {J_ISCI},
  author       = {Shuai Lü and Shuai Han and Wenbo Zhou and Junwei Zhang},
  doi          = {10.1016/j.ins.2020.12.017},
  journal      = {Information Sciences},
  pages        = {172-188},
  shortjournal = {Inf. Sci.},
  title        = {Recruitment-imitation mechanism for evolutionary reinforcement learning},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal improvement of the best and worst consistency levels
for interval additive preference relations. <em>ISCI</em>, <em>553</em>,
154–171. (<a href="https://doi.org/10.1016/j.ins.2020.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The best consistency index (BCI) and the worst consistency index (WCI) were introduced into interval additive preference relations (IAPRs) to guarantee that any APR within an IAPR would have a satisfactory best or worst consistency. However, the methods for controlling the BCI and WCI consistencies were not clear, and consensus reaching problems based on the BCI and WCI, which are a key issue in group decision making using IAPRs, have not yet been addressed. Therefore, to address this particular omission, this paper suggests various optimization approaches for the modeling of both consistency and consensus. First, an APR that corresponds to the worst consistency is determined using the IAPR boundary elements, after which an optimization model is introduced to improve the BCI and WCI that minimizes the amount of change. It was found that if all individual IAPRs had acceptable WCIs, the group IAPR also had an acceptable WCI for the group decision making. An optimal consensus model is also proposed to deal with the consistency and consensus. These models were found to be able to effectively manage the worst consistency in the decision process. Some numerical examples and comparison analyses are given to validate the efficiency of the developed decision models.},
  archive      = {J_ISCI},
  author       = {Songhao Shen and Xue Chen and Zhibin Wu},
  doi          = {10.1016/j.ins.2020.12.040},
  journal      = {Information Sciences},
  pages        = {154-171},
  shortjournal = {Inf. Sci.},
  title        = {Optimal improvement of the best and worst consistency levels for interval additive preference relations},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-label feature selection based on the division of label
topics. <em>ISCI</em>, <em>553</em>, 129–153. (<a
href="https://doi.org/10.1016/j.ins.2020.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label feature selection has attracted much attention from researchers and can reduce the high dimensionality of multi-label data. Previous multi-label methods consider the importance of labels equal, as a result, they choose the discriminative features based on the entire label set. In fact, there exists a latent semantic structure in the label set. Specifically, labels can be sorted into some central topics and some subordinate topics. Features regarding central topics should be chosen first and the number of them should be chosen more. To this end, we first explore the latent semantic structure according to spectral clustering. The labels are abstracted into several clusters named central clusters and subordinate clusters. Second, the importance of features with respect to the labels in each cluster is scored. Finally, we obtain the feature subset based on both the scores of features and the type of clusters. Comprehensive experiments demonstrate the superiority of the proposed method against seven state-of-the-art multi-label feature selection methods on fourteen benchmark multi-label data sets.},
  archive      = {J_ISCI},
  author       = {Ping Zhang and Wanfu Gao and Juncheng Hu and Yonghao Li},
  doi          = {10.1016/j.ins.2020.12.036},
  journal      = {Information Sciences},
  pages        = {129-153},
  shortjournal = {Inf. Sci.},
  title        = {Multi-label feature selection based on the division of label topics},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Providing reliability in recommender systems through
bernoulli matrix factorization. <em>ISCI</em>, <em>553</em>, 110–128.
(<a href="https://doi.org/10.1016/j.ins.2020.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beyond accuracy, quality measures are gaining importance in modern recommender systems , with reliability being one of the most important indicators in the context of collaborative filtering. This paper proposes Bernoulli Matrix Factorization (BeMF), which is a matrix factorization model, to provide both prediction values and reliability values. BeMF is a very innovative approach from several perspectives: a) it acts on model-based collaborative filtering rather than on memory-based filtering, b) it does not use external methods or extended architectures, such as existing solutions, to provide reliability, c) it is based on a classification-based model instead of traditional regression-based models, and d) matrix factorization formalism is supported by the Bernoulli distribution to exploit the binary nature of the designed classification model . The experimental results show that the more reliable a prediction is, the less liable it is to be wrong: recommendation quality improves after the most reliable predictions are selected. State-of-the-art quality measures for reliability have been tested, which shows that BeMF outperforms previous baseline methods and models.},
  archive      = {J_ISCI},
  author       = {Fernando Ortega and Raúl Lara-Cabrera and Ángel González-Prieto and Jesús Bobadilla},
  doi          = {10.1016/j.ins.2020.12.001},
  journal      = {Information Sciences},
  pages        = {110-128},
  shortjournal = {Inf. Sci.},
  title        = {Providing reliability in recommender systems through bernoulli matrix factorization},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing the data complexity of imbalanced datasets.
<em>ISCI</em>, <em>553</em>, 83–109. (<a
href="https://doi.org/10.1016/j.ins.2020.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced datasets are an important challenge in supervised Machine Learning (ML). According to the literature, class imbalance does not necessarily impose difficulties for ML algorithms . Difficulties mainly arise from other characteristics, such as overlapping between classes and complex decision boundaries. For binary classification tasks , calculating imbalance is straightforward, e.g., the ratio between class sizes. However, measuring more relevant characteristics, such as class overlapping, is not trivial. In the past years, complexity measures able to assess more relevant dataset characteristics have been proposed. In this paper, we investigate their effectiveness on real imbalanced datasets and how they are affected by applying different data imbalance treatments (DIT). For such, we perform two data-driven experiments: (1) We adapt the complexity measures to the context of imbalanced datasets. The experimental results show that our proposed measures assess the difficulty of imbalanced problems better than the original ones. We also compare the results with the state-of-art on data complexity measures for imbalanced datasets. (2) We analyze the behavior of complexity measures before and after applying DITs. According to the results, the difference in data complexity, in general, correlates to the predictive performance improvement obtained by applying DITs to the original datasets.},
  archive      = {J_ISCI},
  author       = {Victor H. Barella and Luís P.F. Garcia and Marcilio C.P. de Souto and Ana C. Lorena and André C.P.L.F. de Carvalho},
  doi          = {10.1016/j.ins.2020.12.006},
  journal      = {Information Sciences},
  pages        = {83-109},
  shortjournal = {Inf. Sci.},
  title        = {Assessing the data complexity of imbalanced datasets},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deterministic convergence analysis via smoothing group lasso
regularization and adaptive momentum for sigma-pi-sigma neural network.
<em>ISCI</em>, <em>553</em>, 66–82. (<a
href="https://doi.org/10.1016/j.ins.2020.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a sparse and accelerated method for Sigma-Pi-Sigma neural network training based on smoothing group lasso regularization and adaptive momentum. It is shown that group sparsity can more efficiently sparsity the network structure at the group level, and the adaptive momentum term can speed up the learning convergence during the iteration process . Also, another important contribution lies in the analysis of theoretical results. However, the group lasso regularization is not differentiable at the origin. This leads to oscillations observed in numerical experiments and poses a challenge to theoretical analysis. So, we overcome those problems by smoothing techniques. Under suitable assumptions, we strictly proved the monotonicity, and weak and strong convergence theorems of the new algorithm. Finally, the numerical experiments are presented to support our theoretical findings.},
  archive      = {J_ISCI},
  author       = {Qian Kang and Qinwei Fan and Jacek M. Zurada},
  doi          = {10.1016/j.ins.2020.12.014},
  journal      = {Information Sciences},
  pages        = {66-82},
  shortjournal = {Inf. Sci.},
  title        = {Deterministic convergence analysis via smoothing group lasso regularization and adaptive momentum for sigma-pi-sigma neural network},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hypergrid based adaptive learning method for detecting
data faults in wireless sensor networks. <em>ISCI</em>, <em>553</em>,
49–65. (<a href="https://doi.org/10.1016/j.ins.2020.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In wireless sensor networks (WSNs), data anomalies/faults often occur due to the limited resources and unreliability of sensor nodes . Many traditional anomaly detection methods are designed in a batch manner, but for the nature of streaming data in WSNs, continuous anomaly detection method is preferred. Existing methods often detect only a single type of faults but cannot detect multiple types of faults that actually are more common in the sensor data. Therefore, this paper provides a Hypergrid based Adaptive Detection of Faults (HADF) method, which adopts hypergrid and statistical analysis to recognize three types of faults in the sensor data, including outliers, stuck-at faults, and noisy faults. HADF is a distributed method running on sensor nodes , which can reduce the influence of concept drift in unstable streaming data through combining both lazy leaning and continuous learning to adaptively update its normal profile. In the experimental study, we have manually inserted different types of faults into two real-world datasets, and the results demonstrate that HADF achieves higher accuracy with reasonable efficiency for detecting the data faults than four counterpart methods.},
  archive      = {J_ISCI},
  author       = {Lingqiang Chen and Guanghui Li and Guangyan Huang},
  doi          = {10.1016/j.ins.2020.12.011},
  journal      = {Information Sciences},
  pages        = {49-65},
  shortjournal = {Inf. Sci.},
  title        = {A hypergrid based adaptive learning method for detecting data faults in wireless sensor networks},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy high-utility pattern mining in parallel and
distributed hadoop framework. <em>ISCI</em>, <em>553</em>, 31–48. (<a
href="https://doi.org/10.1016/j.ins.2020.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, high-utility itemset mining (HUIM) has received widespread attention that can emphasize more critical information than was previously possible using frequent itemset mining (FIM). Unfortunately, HUIM is very similar to FIM since the methodology determines itemsets using a binary model based on a pre-defined minimum utility threshold. Additionally, most previous works only focused on single, small datasets in HUIM, which is not realistic to any real-world scenarios today containing big data environments. In this work, the fuzzy-set theory and a MapReduce framework are both utilized to design a novel high fuzzy utility pattern mining algorithm to resolve the above issues. Fuzzy-set theory is first involved and a new algorithm called efficient high fuzzy utility itemset mining (EFUPM) is designed to discover high fuzzy utility patterns from a single machine. Two upper-bounds are then estimated to allow early pruning of unpromising candidates in the search space. To handle the large-scale of big datasets, a Hadoop-based high fuzzy utility pattern mining (HFUPM) algorithm is then developed to discover high fuzzy utility patterns based on the Hadoop framework. Experimental results clearly show that the proposed algorithms perform strongly to mine the required high fuzzy utility patterns whether in a single machine or a large-scale environment compared to the current state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Jimmy Ming-Tai Wu and Gautam Srivastava and Min Wei and Unil Yun and Jerry Chun-Wei Lin},
  doi          = {10.1016/j.ins.2020.12.004},
  journal      = {Information Sciences},
  pages        = {31-48},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy high-utility pattern mining in parallel and distributed hadoop framework},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An encrypted coverless information hiding method based on
generative models. <em>ISCI</em>, <em>553</em>, 19–30. (<a
href="https://doi.org/10.1016/j.ins.2020.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Invisibility is an important target for image steganography; however, the traditional image steganography methods inevitably leave traces of their modifications in cover images due to the process used to embed secret messages . In this paper, we propose an encrypted coverless information hiding method that transfers secret images between two different image domains using generative models . Our method includes two stages: encryption and decryption. In the encryption stage, we first embed a secret image into a public image (one domain) to obtain a synthetic image ; then, we utilize that image as the input to the first generative model F to obtain an encrypted image (another domain). Adversarial loss and an extraction module are added to improve the quality of the encrypted images generated in this stage. In the decryption stage, we design a second generative model G to reconstruct the synthetic images from the encrypted images. Finally, the secret image is separated from the reconstructed synthetic image . In our extensive experiments, we adopt the images in the MNIST dataset as the secret images , which allows us to use the recognition rate as a measure of the secret image reconstruction quality. The experimental results indicate that our method is not only able to generate quality encrypted images compared with current popular image-to-image translation methods but also possesses greater security, robustness and reconstruction ability.},
  archive      = {J_ISCI},
  author       = {Qi Li and Xingyuan Wang and Xiaoyu Wang and Bin Ma and Chunpeng Wang and Yunqing Shi},
  doi          = {10.1016/j.ins.2020.12.002},
  journal      = {Information Sciences},
  pages        = {19-30},
  shortjournal = {Inf. Sci.},
  title        = {An encrypted coverless information hiding method based on generative models},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient and high-quality pansharpening model based on
conditional random fields. <em>ISCI</em>, <em>553</em>, 1–18. (<a
href="https://doi.org/10.1016/j.ins.2020.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pansharpening fuses a low spatial resolution multi-spectral (MS) image with the corresponding panchromatic (PAN) image to obtain a high spatial resolution MS (HRMS) image. Traditional fusion methods may easily cause a spectral or spatial distortion when injecting details into an MS image. To preserve the spectral and spatial information, an efficient pansharpening model based on conditional random fields (CRFs) is proposed. With this model, a state feature function is designed to force the HRMS image filtered using a blur function to be consistent with the up-sampled MS image and retain the spectral fidelity. To obtain a proper blur function, a new filter-acquisition method is proposed for the unified CRF-based model. Meanwhile, a transition feature function is defined to enable the transition of HRMS pixels to follow the gradient of a PAN image and ensure the sharpness of the fused image. Considering the characteristics of the gradient domain, a total variation regularization is designed to make the gradient of the HRMS image sparse. Finally, the augmented Lagrangian function of the model is solved by employing an alternating direction method of the multipliers. Experiment results indicate that, compared with previous state-of-the-art pansharpening methods, the proposed method can achieve the best fusion results with high computational efficiency.},
  archive      = {J_ISCI},
  author       = {Yong Yang and Hangyuan Lu and Shuying Huang and Yuming Fang and Wei Tu},
  doi          = {10.1016/j.ins.2020.11.046},
  journal      = {Information Sciences},
  pages        = {1-18},
  shortjournal = {Inf. Sci.},
  title        = {An efficient and high-quality pansharpening model based on conditional random fields},
  volume       = {553},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image encryption using q-deformed logistic map.
<em>ISCI</em>, <em>552</em>, 352–364. (<a
href="https://doi.org/10.1016/j.ins.2020.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A chaotic image encryption algorithm based on a deformation of the logistic map is proposed. The use of a deformed chaotic map has several advantages. In particular, we are able to not only enlarge the key space size but also describe a parametric region for the selection of a key avoiding non-chaotic regions, which is a fundamental requirement for real applications. Moreover, a security analysis of the proposed algorithm shows its efficiency and robustness in resisting attacks.},
  archive      = {J_ISCI},
  author       = {María Muñoz-Guillermo},
  doi          = {10.1016/j.ins.2020.11.045},
  journal      = {Information Sciences},
  pages        = {352-364},
  shortjournal = {Inf. Sci.},
  title        = {Image encryption using q-deformed logistic map},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-way multi-attribute decision making under hesitant
fuzzy environments. <em>ISCI</em>, <em>552</em>, 328–351. (<a
href="https://doi.org/10.1016/j.ins.2020.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In decision making processes, an expert with hesitant attitudes may experience difficulties when evaluating alternatives via a single assessment value. By allowing the membership degree of an element to a set represented by several possible values, hesitant fuzzy sets (HFSs) are usually needed to address this situation. Thus, it is meaningful to put forward a kind of multi-attribute decision making (MADM) method in the hesitant fuzzy (HF) environment. In addition, three-way decision (3WD) is a decision making method by introducing the idea of non-commitments, and it can effectively reduce decision risks. In this paper, the 3WD method-based MADM with HF information is proposed. According to the information table, the membership function of an objective HFS is given. The effectiveness of the proposed method is verified by solving an infectious disease diagnosis problem. Finally, we give a comparative analysis between the proposed method and the existing HF MADM methods. Further, three experimental results show that the proposed method is reasonable and effective.},
  archive      = {J_ISCI},
  author       = {Jiajia Wang and Xueling Ma and Zeshui Xu and Jianming Zhan},
  doi          = {10.1016/j.ins.2020.12.005},
  journal      = {Information Sciences},
  pages        = {328-351},
  shortjournal = {Inf. Sci.},
  title        = {Three-way multi-attribute decision making under hesitant fuzzy environments},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating priorities from relative deviations in pairwise
comparison matrices. <em>ISCI</em>, <em>552</em>, 310–327. (<a
href="https://doi.org/10.1016/j.ins.2020.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of deriving the priority vector from a pairwise comparison matrix is at the heart of multiple-criteria decision-making problems. Existing prioritization methods mostly model the inconsistency in relative preference–the ratio of two preference weights–by allowing for a small deviation, either additively or multiplicatively. In this study, we alternatively allow for a deviation in each of the two preference weights, which we refer to as the relative deviation interconnection. Under this framework, we consider both relative additive and multiplicative deviation cases and define two types of norms capturing the magnitudes of the deviations, which gives rise to four conic programming models for minimizing the norms of the deviations. Through the model structures, we analyze the signs of the deviations. This further allows us to establish the expressiveness of our framework, which covers the logarithmic least-squares method and the goal-programming method. Using numerical examples, we show that our models perform comparably against existing prioritization methods, efficiently identify unusual and false observations, and provide further suggestions for reducing inconsistency.},
  archive      = {J_ISCI},
  author       = {Jiulong Zhang and Gang Kou and Yi Peng and Yu Zhang},
  doi          = {10.1016/j.ins.2020.12.008},
  journal      = {Information Sciences},
  pages        = {310-327},
  shortjournal = {Inf. Sci.},
  title        = {Estimating priorities from relative deviations in pairwise comparison matrices},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection and localization of biased load attacks in smart
grids via interval observer. <em>ISCI</em>, <em>552</em>, 291–309. (<a
href="https://doi.org/10.1016/j.ins.2020.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biased load attacks pose enormous security risks to smart grids, due to the characteristics of spoofing attack . To handle the risks, a novel scheme for detecting and localizing biased load attacks is developed. Firstly, an unknown input interval observer is designed to mitigate the influences of disturbances and regional interconnection information, contributing to an accurate estimation of the interval state. Secondly, considering the feature of interval residuals, a novel detection criterion is developed to eliminate the limitation resulted by the prior threshold in the existing detection techniques. In addition, a logic judgment matrix is established based on the combination of sensor set, addressing the problem of attack detection and localization under structural vulnerability. Finally, the simulation results indicate that the developed scheme can detect and localize the biased load attacks effectively. Also, the developed scheme shows superior performance than state-of-the-art techniques.},
  archive      = {J_ISCI},
  author       = {Xinyu Wang and Xiaoyuan Luo and Mingyue Zhang and Zhongping Jiang and Xinping Guan},
  doi          = {10.1016/j.ins.2020.12.027},
  journal      = {Information Sciences},
  pages        = {291-309},
  shortjournal = {Inf. Sci.},
  title        = {Detection and localization of biased load attacks in smart grids via interval observer},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-point FFT-based high capacity image steganography using
calendar based message encoding. <em>ISCI</em>, <em>552</em>, 278–290.
(<a href="https://doi.org/10.1016/j.ins.2020.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we show how to hide a maximum of 8 bits of secret data into the pixel difference value. Adjacent pixel pairs are chosen in a non-sequential manner in the spatial domain without using any seed or key. In spite of having high average embedding capacity and embedding efficiency , our algorithm can withstand visual, structural and statistical attacks. We compare our work with state-of-the-art works and also show that our work is capable of resisting the series of tests provided by the benchmark “StirMark”.},
  archive      = {J_ISCI},
  author       = {Nabanita Mukherjee (Ganguly) and Goutam Paul and Sanjoy Kumar Saha},
  doi          = {10.1016/j.ins.2020.11.044},
  journal      = {Information Sciences},
  pages        = {278-290},
  shortjournal = {Inf. Sci.},
  title        = {Two-point FFT-based high capacity image steganography using calendar based message encoding},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A nearest-neighbor search model for distance metric
learning. <em>ISCI</em>, <em>552</em>, 261–277. (<a
href="https://doi.org/10.1016/j.ins.2020.11.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning aims to deal with the data distribution by learning a suitable distance metric from the training instances. For distance metric learning, the optimization constraints can be constructed based on the similar and dissimilar instance pairs. The instance pairs are generated by selecting the nearest-neighbors for each training instance. However, most methods select the same and fixed nearest-neighbor number for different training instances, which may limit performance for learning distance metric. In this paper, we propose a nearest-neighbor search model for distance metric learning (NNS-DML), which is capable of constructing the metric optimization constraints by searching different optimal nearest-neighbor numbers for different training instances. Specifically, we formulate a nearest-neighbor search matrix to contain the nearest-neighbor correlations of all training instances. Using the search matrix, we can construct and weight the metric optimization constraints of each training instance, such that the influence of its irrelevant features for its corresponding similar and dissimilar instance pairs can be reduced. Moreover, we develop a k -free nearest-neighbor model for classification problems via the SVM solver, which can ignore the setting of k . Extensive experiments show that the proposed NNS-DML method outperforms the state-of-the-art distance metric learning methods.},
  archive      = {J_ISCI},
  author       = {Yibang Ruan and Yanshan Xiao and Zhifeng Hao and Bo Liu},
  doi          = {10.1016/j.ins.2020.11.054},
  journal      = {Information Sciences},
  pages        = {261-277},
  shortjournal = {Inf. Sci.},
  title        = {A nearest-neighbor search model for distance metric learning},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust distribution-based nonnegative matrix factorizations
for dimensionality reduction. <em>ISCI</em>, <em>552</em>, 244–260. (<a
href="https://doi.org/10.1016/j.ins.2020.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a popular dimensionality-reduction technique, nonnegative matrix factorization (NMF) has been widely researched since it is consistent with human cognitive processes in the psychology and physiology. This paper presents a novel NMF framework, called robust distribution-based NMF (RDNMF), to learn the robustly discriminative representations for data. In this RDNMF, a Kullback–Leibler divergence to measure the similarity between the data and representations is introduced, which fully preserves the geometrical structure of data. Meanwhile, this RDNMF employs the l 2 , 1 l2,1 -norm loss to reduce the influence of noise and outliers. This paper further proposes a semi-supervised RDNMF (SRDNMF) by enforcing the representations of labeled points in the same class to be aligned on the same axis. The proposed RDNMF and SRDNMF are solved by the modified multiplicative update rules. Clustering experiments on seven benchmark datasets demonstrate the effectiveness of our methods in comparison to other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Xinjun Peng and Dong Xu and De Chen},
  doi          = {10.1016/j.ins.2020.12.026},
  journal      = {Information Sciences},
  pages        = {244-260},
  shortjournal = {Inf. Sci.},
  title        = {Robust distribution-based nonnegative matrix factorizations for dimensionality reduction},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three (t,n)-secret image sharing schemes based on
homogeneous linear recursion. <em>ISCI</em>, <em>552</em>, 220–243. (<a
href="https://doi.org/10.1016/j.ins.2020.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, three novel secret image sharing schemes based on homogeneous linear recursion are introduced. Simple sharing, various methods for the recovery, small shadow image size and high resolution are some of the merits of our schemes. Moreover, shadow images generated in schemes 2 and 3 are unrevealing and are secured against attacks based on correlation of adjacent pixels , without any need to perform extra computations such as permutation or encryption, which usually were used in the previous schemes.},
  archive      = {J_ISCI},
  author       = {Sara Charoghchi and Samaneh Mashhadi},
  doi          = {10.1016/j.ins.2020.11.034},
  journal      = {Information Sciences},
  pages        = {220-243},
  shortjournal = {Inf. Sci.},
  title        = {Three (t,n)-secret image sharing schemes based on homogeneous linear recursion},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). L-SHADE-e: Ensemble of two differential evolution
algorithms originating from l-SHADE. <em>ISCI</em>, <em>552</em>,
201–219. (<a href="https://doi.org/10.1016/j.ins.2020.11.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For real parameter single objective optimization , Differential Evolution (DE) performs better than other types of population-based metaheuristic . Nevertheless, in the field of DE, it is impossible for a given combination of operators to perform well in all fitness landscapes. Practice has proved that assembling more than one combinations of operators may lead to improvement in solution. However, some DE algorithms with good performance, e.g., one of the best performers in competitions of real parameter single objective optimization among population-based metaheuristics held by the series of IEEE Congress on Evolutionary Computation - L-SHADE-EpSin, are still not involved in ensemble. Furthermore, ensemble based on similar DE algorithms is rarely reported. Based on such a background, we propose L-SHADE-E, ensemble of L-SHADE-EpSin and L-SHADE-RSP in this paper. The two constituent algorithms are both variants of L-SHADE and belong to similar DE algorithms. In our algorithm, L-SHADE-EpSin or L-SHADE-RSP is selected randomly to run at the beginning. If progress on fitness is low for generations, the other constituent algorithm takes over population immediately. Our experiments are based on the CEC 2014 and CEC 2017 benchmark test suites. Altogether, our algorithm is compared with nine DE algorithms and three population-based metaheuristics other than DE. Experimental results show that our algorithm is very competitive.},
  archive      = {J_ISCI},
  author       = {Xinxin Wang and Chengjun Li and Jiarui Zhu and Qinxue Meng},
  doi          = {10.1016/j.ins.2020.11.055},
  journal      = {Information Sciences},
  pages        = {201-219},
  shortjournal = {Inf. Sci.},
  title        = {L-SHADE-E: Ensemble of two differential evolution algorithms originating from L-SHADE},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A privacy-preserving and non-interactive federated learning
scheme for regression training with gradient descent. <em>ISCI</em>,
<em>552</em>, 183–200. (<a
href="https://doi.org/10.1016/j.ins.2020.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the extensive application of machine learning technologies has been witnessed in various fields. However, in many applications, massive data are distributively stored in multiple data owners. Meanwhile, due to the privacy concerns and communication constraints, it is difficult to bridge the data silos among data owners for training a global machine learning model. In this paper, we propose a privacy-preserving and non-interacti v e feder a ted lear n ing sch e me for regression training with gradient descent , named VANE. With VANE, multiple data owners are able to train a global linear, ridge or logistic regression model with the assistance of cloud, while their private local training data can be well protected. Specifically, we first design a secure data aggregation algorithm, with which local training data from multiple data owners can be aggregated and trained to a global model without disclosing any private information. Meanwhile, benefit from our data pre-processing method, the whole training process is non-interactive, i.e., there is no interaction between data owners and the cloud. Detailed security analysis shows that VANE can well protect the local training data of data owners. The performance evaluation results demonstrate that the training performance of our VANE is around 10 3 times faster than existing schemes.},
  archive      = {J_ISCI},
  author       = {Fengwei Wang and Hui Zhu and Rongxing Lu and Yandong Zheng and Hui Li},
  doi          = {10.1016/j.ins.2020.12.007},
  journal      = {Information Sciences},
  pages        = {183-200},
  shortjournal = {Inf. Sci.},
  title        = {A privacy-preserving and non-interactive federated learning scheme for regression training with gradient descent},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blind image quality prediction with hierarchical feature
aggregation. <em>ISCI</em>, <em>552</em>, 167–182. (<a
href="https://doi.org/10.1016/j.ins.2020.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind image quality assessment (BIQA) aims to evaluate the perceptual quality of image with no pristine image for comparison, which attracts extensive attention and is of wide applications. Research on human visual system (HVS) indicates visual perception is classically modeled as a hierarchical process. Meanwhile, empirical evidence shows that different levels of distortion generate individual degradation on hierarchical features. Although previous BIQA methods exploited different levels of feature, the degradations and correlations on hierarchical features are not detailedly analyzed. In this paper, hierarchical degradation is systematically analyzed by quantitative and qualitative experiments using interpretable hierarchical features. Additionally, as there exist strong relationships, these features cannot be simply concatenated for quality prediction. Inspired by the Bayesian brain theory, correlations among hierarchical features are thoroughly deduced with joint probability . Guided by the mathematical derivation, a new feature aggregation network (FANet) is designed to eliminate correlations for hierarchical features fusion . Finally, a novel end-to-end BIQA framework based on hierarchical feature aggregation is proposed, which eminently analyzes the degradations and correlations on hierarchical features. Experimental results on five benchmark databases show that the proposed method achieves state-of-the-art performance. Furthermore, cross-database evaluations demonstrate the generalization capability and robustness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Jinjian Wu and Wen Yang and Leida Li and Weisheng Dong and Guangming Shi and Weisi Lin},
  doi          = {10.1016/j.ins.2020.12.018},
  journal      = {Information Sciences},
  pages        = {167-182},
  shortjournal = {Inf. Sci.},
  title        = {Blind image quality prediction with hierarchical feature aggregation},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Similar but foreign: Link recommendation across communities.
<em>ISCI</em>, <em>552</em>, 142–166. (<a
href="https://doi.org/10.1016/j.ins.2020.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex networks have been widely used to model complex systems composed of interacting entities. It is possible to recommend new relationships between entities according to the network topology and the entities’ properties. The likelihood of forming a missing or potential relationship is often captured by similarity measures. As community clusters are also based on the entities’ similarities, traditional link recommendation/prediction methods naturally tend to recommend links within a community. However, potential links valuable across communities are often overlooked and may cause the problem of information cocoons. We focus on link recommendation across communities based on homogeneous and heterogeneous information networks, which aims to improve the diversity of recommender systems . We propose to solve this problem using a novel similarity calculation and heterogeneous network embedding methods. Our comprehensive experiments on real-world datasets and synthetic datasets show that our methods strike a good balance between accuracy and efficiency, while generating valuable unconventional recommendations in practical application scenarios.},
  archive      = {J_ISCI},
  author       = {Chunyao Song and Yao Ge and Tingjian Ge and Haixia Wu and Zhutian Lin and Hong Kang and Xiaojie Yuan},
  doi          = {10.1016/j.ins.2020.11.049},
  journal      = {Information Sciences},
  pages        = {142-166},
  shortjournal = {Inf. Sci.},
  title        = {Similar but foreign: Link recommendation across communities},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating nullnorms on some special classes of bounded
lattices via closure and interior operators. <em>ISCI</em>,
<em>552</em>, 118–141. (<a
href="https://doi.org/10.1016/j.ins.2020.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we introduce different methods for constructing nullnorms on some special classes of bounded lattices by using closure and interior operators. As a by-product, we obtain new classes of idempotent nullnorms. Furthermore, we give some interesting examples for a better understanding of these new classes of nullnorms. In particular, the results presented here provide different approaches to the suggestion put forward by Ouyang and Zhang in (2020).},
  archive      = {J_ISCI},
  author       = {Gül Deniz Çaylı},
  doi          = {10.1016/j.ins.2020.11.016},
  journal      = {Information Sciences},
  pages        = {118-141},
  shortjournal = {Inf. Sci.},
  title        = {Generating nullnorms on some special classes of bounded lattices via closure and interior operators},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiview clustering via exclusive non-negative subspace
learning and constraint propagation. <em>ISCI</em>, <em>552</em>,
102–117. (<a href="https://doi.org/10.1016/j.ins.2020.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview clustering partitions a set of data into groups by exploring complementary information of multiple views. The mainstream tries to project the multiview data into a commonly shared subspace and further discover the true data structure . Ideally, clusters in the subspace should share less semantics with each other so that distinct groups can be obtained while this exclusivity is not guaranteed in previous works. To this end, this paper proposes a non-negative matrix factorization based subspace learning method for exclusive multiview clustering, where the double-orthogonal constraints are imposed for the cluster exclusivity. Moreover, to boost the clustering performance, the proposed method also exploits the available labeled data and is extended into a semi-supervised manner. Particularly, by incorporating the propagated semi-supervised manifold regularizations , the limited supervised information is enriched and encoded in our method to guide the learning process. The formulated optimization problem can be solved by the derived iterative updating rules. Experimental results on seven public datasets demonstrate its promising performance against other state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Han Zhou and Hongpeng Yin and Yanxia Li and Yi Chai},
  doi          = {10.1016/j.ins.2020.11.037},
  journal      = {Information Sciences},
  pages        = {102-117},
  shortjournal = {Inf. Sci.},
  title        = {Multiview clustering via exclusive non-negative subspace learning and constraint propagation},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel lifelong learning model based on cross domain
knowledge extraction and transfer to classify underwater images.
<em>ISCI</em>, <em>552</em>, 80–101. (<a
href="https://doi.org/10.1016/j.ins.2020.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence based autonomous systems interacting with dynamic environment are required to continuously learn, accumulate and improve the learned knowledge. Currently, most artificial intelligence based systems lack this ability and work in isolated learning paradigm. Human beings follow the continuous learning process by retaining and accumulating the learnt knowledge, and by using the learnt knowledge to solve the problem at hand. In this paper, we present a lifelong learning model, to solve challenging problem of real world underwater image classification . The proposed model is capable to learn from simple problems, accumulates the learnt knowledge by continual learning and uses the learnt knowledge to solve future complex problems of the same or related domain, in a similar way as humans do. In the proposed model, firstly, a deep classification convolutional autoencoder is presented to extract spatially localized features from images by utilizing convolution filters, then a code fragment based learning classifier system , with rich knowledge encoding scheme, is proposed for knowledge representation and transfer. In order to validate the model, experiments are conducted on two underwater images datasets and one in-air images dataset. Experiments results demonstrate that the proposed method outperforms base line method and state-of-the-art convolution neural network (CNN) methods.},
  archive      = {J_ISCI},
  author       = {Muhammad Irfan and Zheng Jiangbin and Muhammad Iqbal and Muhammad Hassan Arif},
  doi          = {10.1016/j.ins.2020.11.048},
  journal      = {Information Sciences},
  pages        = {80-101},
  shortjournal = {Inf. Sci.},
  title        = {A novel lifelong learning model based on cross domain knowledge extraction and transfer to classify underwater images},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). MBSVR: Multiple birth support vector regression.
<em>ISCI</em>, <em>552</em>, 65–79. (<a
href="https://doi.org/10.1016/j.ins.2020.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the learning speed in twin support vector regression (TWSVR) is four times that in support vector regression (SVR), the computing time and fitting precision of TWSVR are limited. This paper develops multiple birth support vector regression (MBSVR), motivated by the multiple birth support vector machine (MBSVM) formulation. MBSVR constructs the final regressor from K hyperplanes, each of which is obtained by solving a small quadratic programming problem (QPP) with the associated constraints, in which all points in each of the corresponding class should be as far away as possible from its corresponding hyperplane. Since MBSVM can be seen as an extension of the twin support vector machine (TWSVM) and its computing time is less than that of TWSVM, the proposed MBSVR is also faster than TWSVR, especially when the number of classes K K is large. To verify the performance of the proposed MBSVR, it is compared with TWSVR, TSVR (another form of twin support vector regression) and SVR on several synthetic datasets and UCI datasets.},
  archive      = {J_ISCI},
  author       = {Zichen Zhang and Shifei Ding and Yuting Sun},
  doi          = {10.1016/j.ins.2020.11.033},
  journal      = {Information Sciences},
  pages        = {65-79},
  shortjournal = {Inf. Sci.},
  title        = {MBSVR: Multiple birth support vector regression},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarially learned one-class novelty detection with
confidence estimation. <em>ISCI</em>, <em>552</em>, 48–64. (<a
href="https://doi.org/10.1016/j.ins.2020.11.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given samples from a particular normal class, image novelty detection is aimed at determining whether a query sample is from the normal class. Images from this particular class are termed inliers or normal images, whereas images not belonging to the class are termed novelties. Most novelty detection approaches use deep neural networks . However, few of them are end-to-end, and state-of-the-art neural networks tend to be overconfident in their predictions. This may result in incorrect predictions and may negatively affect novelty detection. In this paper, we propose a novel model termed adversarially learned one-class novelty detection with confidence estimation for image novelty detection. The proposed model consists of a representation and a detection module, which are adversarially trained to collaboratively learn the inlier distribution. Moreover, the model uses confidence estimation so that the detection module can more effective. The proposed model is end-to-end and does not require additional calculations such as novelty scores after training. We conduct comprehensive experiments on four publicly available datasets that are commonly used for novelty detection, and the model is compared with state-of-the-art methods to demonstrate its performance.},
  archive      = {J_ISCI},
  author       = {Ying Zhang and Baohang Zhou and Xiaoke Ding and Jiawei Ouyang and Xiangrui Cai and Jinyang Gao and Xiaojie Yuan},
  doi          = {10.1016/j.ins.2020.11.052},
  journal      = {Information Sciences},
  pages        = {48-64},
  shortjournal = {Inf. Sci.},
  title        = {Adversarially learned one-class novelty detection with confidence estimation},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Pruning deep convolutional neural networks architectures
with evolution strategy. <em>ISCI</em>, <em>552</em>, 29–47. (<a
href="https://doi.org/10.1016/j.ins.2020.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, Deep Convolutional Neural Networks (DCNNs) are used to solve all kinds of problems in the field of machine learning and artificial intelligence due to their learning and adaptation capabilities. However, most successful DCNN models have a high computational complexity making them difficult to deploy on mobile or embedded platforms. This problem has prompted many researchers to develop algorithms and approaches to help reduce the computational complexity of such models. One of them is called filter pruning, where convolution filters are eliminated to reduce the number of parameters and, consequently, the computational complexity of the given model. In the present work, we propose a novel algorithm to perform filter pruning by using a Multi-Objective Evolution Strategy (MOES) algorithm, called DeepPruningES. Our approach avoids the need for using any knowledge during the pruning procedure and helps decision-makers by returning three pruned CNN models with different trade-offs between performance and computational complexity. We show that DeepPruningES can significantly reduce a model’s computational complexity by testing it on three DCNN architectures: Convolutional Neural Networks (CNNs), Residual Neural Networks (ResNets), and Densely Connected Neural Networks (DenseNets).},
  archive      = {J_ISCI},
  author       = {Francisco E. Fernandes Jr. and Gary G. Yen},
  doi          = {10.1016/j.ins.2020.11.009},
  journal      = {Information Sciences},
  pages        = {29-47},
  shortjournal = {Inf. Sci.},
  title        = {Pruning deep convolutional neural networks architectures with evolution strategy},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Splicing learning: A novel few-shot learning approach.
<em>ISCI</em>, <em>552</em>, 17–28. (<a
href="https://doi.org/10.1016/j.ins.2020.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, among most approaches for few-shot learning, there exists a default premise that a big homogeneous-annotated dataset is applied to pre-train the few-shot learning model. However, since few-shot learning approaches are always used in the domain where annotated samples are rare, it would be difficult to collect another big annotated dataset in the same domain. Therefore, we propose Splicing Learning to complete the few-shot learning task without the help of a big homogeneous-annotated dataset. Splicing Learning can increase the sample size of the few-shot set by splicing multiple original images to a spliced-image. Unlike data augmentation technologies, there is no false information on the spliced-image. Through experiments, we find that the configuration “All-splice + WSG” can achieve the best test accuracy of 90.81\%, 9.19\% better than the baseline. The performance improvement of the model can be attributed to Splicing Learning mostly and has little to do with the complexity of the CNN framework. Compared with metric learning, meta-learning, and GAN models, both of Splicing Learning and data augmentation have achieved more outstanding performance. At the same time, the combination of Splicing Learning and data augmentation can further improve the test accuracy of the model to 96.33\%. The full implementation is available at https://github.com/xiangxiangzhuyi/Splicing-learning .},
  archive      = {J_ISCI},
  author       = {Lianting Hu and Huiying Liang and Long Lu},
  doi          = {10.1016/j.ins.2020.11.028},
  journal      = {Information Sciences},
  pages        = {17-28},
  shortjournal = {Inf. Sci.},
  title        = {Splicing learning: A novel few-shot learning approach},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MetaRisk: Semi-supervised few-shot operational risk
classification in banking industry. <em>ISCI</em>, <em>552</em>, 1–16.
(<a href="https://doi.org/10.1016/j.ins.2020.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the operational risk classification problem, a critical yet challenging problem in the banking industry. In practice, banks build supervised multi-label classification models to identify the pre-defined risks using financial news sources. However, the models are often suboptimal due to the lack of labeled data and diverse combinations of risk types. To address these practical issues, we re-frame multi-label supervised operational risk classification as a semi-supervised few-shot learning problem, named MetaRisk, which can then be effectively learned using the prototypical network. We also propose a weighted scheme to help obtain accurately prototype vectors of multi-risk classes. We evaluate the proposed approach MetaRisk using a real-world operational risk classification dataset, and the results demonstrate that it outperforms a set of standard baselines. Especially, MetaRisk is capable of predicting risk types that are new to the system. We expect our work provides a direct and relevant toolkit that may assist risk officers to predict and intervene risks in the banking industry.},
  archive      = {J_ISCI},
  author       = {Fan Zhou and Xiuxiu Qi and Chunjing Xiao and Jiahao Wang},
  doi          = {10.1016/j.ins.2020.11.027},
  journal      = {Information Sciences},
  pages        = {1-16},
  shortjournal = {Inf. Sci.},
  title        = {MetaRisk: Semi-supervised few-shot operational risk classification in banking industry},
  volume       = {552},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A community detection algorithm based on graph compression
for large-scale social networks. <em>ISCI</em>, <em>551</em>, 358–372.
(<a href="https://doi.org/10.1016/j.ins.2020.10.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncovering the underlying community structure of a social network is an important task in social network analysis . To solve this problem, many community detection algorithms for the full topology of an original social network have been proposed. However, these algorithms are not very effective at analyzing large-scale social networks. To overcome this deficiency, this paper proposes a community detection algorithm based on graph compression. Specifically, a compressed graph is first obtained by iteratively merging vertices with a degree of 1 or 2 into their neighbors with a higher degree. Then, two indices, i.e., the density and quality of vertices, are defined to evaluate the probability of vertices as community seeds. By considering these two measures together, in a compressed social network, the number of communities and the corresponding initial community seeds are determined simultaneously. After obtaining the community structure of the compressed social network via seed expansion, the community results are propagated to the original social network. Extensive experiments conducted on various social networks have demonstrated the superiority of our proposal compared to several existing state-of-the-art community detection algorithms .},
  archive      = {J_ISCI},
  author       = {Xingwang Zhao and Jiye Liang and Jie Wang},
  doi          = {10.1016/j.ins.2020.10.057},
  journal      = {Information Sciences},
  pages        = {358-372},
  shortjournal = {Inf. Sci.},
  title        = {A community detection algorithm based on graph compression for large-scale social networks},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust hierarchical feature selection driven by data and
knowledge. <em>ISCI</em>, <em>551</em>, 341–357. (<a
href="https://doi.org/10.1016/j.ins.2020.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is facing great challenges brought by the enlarging label space and the inevitable noisy data. Flat feature selection methods fail to obtain a compact feature subset because of the numerous classes. In addition, these data-driven methods are sensitive to the data outliers . Fortunately, many practical tasks usually organize the classes by a hierarchical structure in a coarse-to-fine manner and can be solved by using the divide-and-conquer strategy. In this paper, we propose a hierarchical feature selection method driven by data and knowledge (HFSDK), which is robust to the data outliers and produces compact feature subsets by splitting the original large label space. Firstly, HFSDK decomposes a large-scale classification task into a group of small subclassification tasks with multiple granularities , which is driven by knowledge of the hierarchical class structure. Then, the corresponding datasets are constructed from the bottom to the top using the class labels of data, which is a data-driven process. Finally, robust and discriminative feature subsets are selected recursively for those subtasks by eliminating the data outliers and adding a semantic relation constraint. Experiments on six real-world datasets validate the superior performance of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xinxin Liu and Yucan Zhou and Hong Zhao},
  doi          = {10.1016/j.ins.2020.11.003},
  journal      = {Information Sciences},
  pages        = {341-357},
  shortjournal = {Inf. Sci.},
  title        = {Robust hierarchical feature selection driven by data and knowledge},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple kernel low-rank representation-based robust
multi-view subspace clustering. <em>ISCI</em>, <em>551</em>, 324–340.
(<a href="https://doi.org/10.1016/j.ins.2020.10.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Owing to the presence of complex noise, it is extremely challenging to learn a low-dimensional subspace structure directly from the original data. In addition, the nonlinear structure of the data makes multi-view subspace clustering more difficult. In this paper, we propose a multiple kernel low-rank representation-based robust multi-view subspace clustering method (MKLR-RMSC) that combines a learnable low-rank multiple kernel trick with co-regularization. MKLR-RMSC mainly conducts the following four tasks: 1) fully mining the complementary information provided by the different views in the feature spaces, 2) the containment of multiple low-dimensional subspaces in the feature space data, 3) allowing all view-specific representations towards a common centroid , and 4) effectively dealing with non-Gaussian noise in data. In our model, the weighted Schatten p -norm is applied to fully explore the effects of different ranks while approaching the original low-rank hypothesis. Moreover, different predefined learning kernel matrices are designed for different views, which is more conducive to mining the unique and complementary information of different views. In addition, as a robust measure, correntropy is applied in MKLR-RMSC. Our method is more effective and robust than several of the most advanced methods on six commonly used datasets.},
  archive      = {J_ISCI},
  author       = {Xiaoqian Zhang and Zhenwen Ren and Huaijiang Sun and Keqiang Bai and Xinghua Feng and Zhigui Liu},
  doi          = {10.1016/j.ins.2020.10.059},
  journal      = {Information Sciences},
  pages        = {324-340},
  shortjournal = {Inf. Sci.},
  title        = {Multiple kernel low-rank representation-based robust multi-view subspace clustering},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered consensus strategy for uncertain topological
fractional-order multiagent systems based on takagi–sugeno fuzzy models.
<em>ISCI</em>, <em>551</em>, 304–323. (<a
href="https://doi.org/10.1016/j.ins.2020.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the event-triggered consensus strategy (ETCS) for uncertain topological fractional-order multiagent systems based on Takagi–Sugeno fuzzy models. First, a novel distributed ETCS, in which the event generator only depends on the information from neighboring agents at event-triggering instants, is designed to reduce the frequency of information transmission among all agents and to ensure a positive lower bound on the interval between any two event-triggering instants for all agents. Then, by applying the fractional Lyapunov method and the designed ETCS, the consensus problem for fractional-order multiagent systems is handled with less waste of system resources compared to the previous related works. According to the proposed consensus criteria, the Zeno behavior is precluded for ETCS. Finally, numerical simulations are given to demonstrate the effectiveness of the designed event-triggered control algorithm.},
  archive      = {J_ISCI},
  author       = {Taotao Hu and Zheng He and Xiaojun Zhang and Shouming Zhong},
  doi          = {10.1016/j.ins.2020.11.005},
  journal      = {Information Sciences},
  pages        = {304-323},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered consensus strategy for uncertain topological fractional-order multiagent systems based on Takagi–Sugeno fuzzy models},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mirrored conditional random field model for object
recognition in indoor environments. <em>ISCI</em>, <em>551</em>,
291–303. (<a href="https://doi.org/10.1016/j.ins.2020.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional object recognition algorithms are based on a commonly adopted closed-set hypothesis, assuming that the knowledge given in training is complete. However, real situations are often open and nonstatic, in which case the models only obtain incomplete knowledge during the training phase. This paper proposes a new type of conditional random field (CRF) model to solve a special case of incomplete knowledge , in which the visual appearance of certain objects changes significantly between training and testing, and as a result, certain unary features (features of individual objects) extracted from red green blue-depth (RGB-D) images are no longer reliable. Mirror nodes are introduced into the architecture based on the standard CRF model to build the mirrored conditional random field (Mirror-CRF) model, which integrates two types of object nodes: original nodes and mirror nodes. The mirror nodes have no unary features, only pairwise features, which describe relationships between two objects and are more reliable than unary features for object recognition in the case of appearance variation. The experimental results show that the Mirror-CRF model reduces the influence of significant changes in the appearance of certain objects and improves the object recognition ability under the condition of incomplete knowledge.},
  archive      = {J_ISCI},
  author       = {Haotian Chen and Fengchi Sun and Jing Yuan and Yalou Huang},
  doi          = {10.1016/j.ins.2020.11.006},
  journal      = {Information Sciences},
  pages        = {291-303},
  shortjournal = {Inf. Sci.},
  title        = {Mirrored conditional random field model for object recognition in indoor environments},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Score function based on concentration degree for
probabilistic linguistic term sets: An application to TOPSIS and VIKOR.
<em>ISCI</em>, <em>551</em>, 270–290. (<a
href="https://doi.org/10.1016/j.ins.2020.10.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic linguistic term sets (PLTSs) can express the qualitative information of decision makers more accurately in the complicated linguistic setting. However, the existing comparison methods for PLTSs cannot compare some special PLTSs. To tackle this problem, a novel score function based on the concentration degree of an PLTS, called ScoreC-PLTS, is proposed. Additionally, the existing distance measures may distort the original information and lead to unreasonable results. Therefore, a novel probability splitting algorithm is proposed to preprocess PLTSs, based on which, a novel generalized hybrid distance is proposed for PLTSs. Moreover, a novel multiplicative analytic hierarchy process (MAHP) based on ScoreC-PLTS is proposed to determine the weight vector of attributes. Based on the generalized hybrid distance and MAHP, two novel TOPSIS-ScoreC-PLTS and VIKOR-ScoreC-PLTS methods are put forward to handle multi-attribute decision-making problems with PLTSs. Afterwards, an illustrative example concerning the selection of children English educational organization is solved using the proposed TOPSIS-ScoreC-PLTS and VIKOR-ScoreC-PLTS methods. In this example, four indicators are developed and the superiority of our studies is verified by comparing with the previous TOPSIS and VIKOR methods.},
  archive      = {J_ISCI},
  author       = {Mingwei Lin and Zheyu Chen and Zeshui Xu and Xunjie Gou and Francisco Herrera},
  doi          = {10.1016/j.ins.2020.10.061},
  journal      = {Information Sciences},
  pages        = {270-290},
  shortjournal = {Inf. Sci.},
  title        = {Score function based on concentration degree for probabilistic linguistic term sets: An application to TOPSIS and VIKOR},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coupling loss and self-used privileged information guided
multi-view transfer learning. <em>ISCI</em>, <em>551</em>, 245–269. (<a
href="https://doi.org/10.1016/j.ins.2020.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning builds models for the target domain by leveraging the information from another related source domain, in which the distributions of two domains are usually quite distinct. Real-world data are often characterized by multiple representations known as multi-view features. In the multi-view transfer learning field, existing methods aim to address the following two issues. Firstly, due to the distributional difference between the two domains, the classifier trained on the source domain may underperform on the target domain. Moreover, the lack of data from the target domain generally occurs in the training phase. Secondly, how to fully exploit the relations among multiple features is challenging when such multi-view representations emerge in the source and target domains. In this paper, we propose a new coupling loss and self-used privileged information guided multi-view transfer learning method (MVTL-CP). The first issue is addressed by utilizing the weighted labeled data from the source domain to learn a precise classifier for the target domain. Following the consensus and complementarity principles, we tackle the second issue by making the best use of multiple views. Furthermore, we analyze the consistency between views and the generalization capability of MVTL-CP. Comprehensive experiments confirm the effectiveness of our proposed model.},
  archive      = {J_ISCI},
  author       = {Jingjing Tang and Yiwei He and Yingjie Tian and Dalian Liu and Gang Kou and Fawaz E. Alsaadi},
  doi          = {10.1016/j.ins.2020.11.007},
  journal      = {Information Sciences},
  pages        = {245-269},
  shortjournal = {Inf. Sci.},
  title        = {Coupling loss and self-used privileged information guided multi-view transfer learning},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effects of heterogeneous impulses on synchronization of
complex-valued neural networks with mixed time-varying delays.
<em>ISCI</em>, <em>551</em>, 228–244. (<a
href="https://doi.org/10.1016/j.ins.2020.10.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates a new type of impulsive effect, namely the heterogeneous impulsive effect on the synchronization of complex-valued neural networks (CVNNs) with mixed time-varying delays. Heterogeneous impulsive effect is a unified framework of non-identical and time-varying impulses, i.e., the impulsive effect to state of each neuron is not only non-identical to each other but also distinct at different impulsive times. Here heterogeneous impulsive control is designed, which is an extension of hybrid impulsive control. The problem is studied with the following procedures. Firstly, the master–slave CVNNs are explicitly separated into two real-valued neural networks (RVNNs). Secondly, the two RVNNs are transformed into impulsive error dynamical system using the heterogeneous impulsive controller. Thirdly, the concepts of average impulsive interval (AII) and average impulsive gain (AIG) are implemented to obtain the synchronization of delayed CVNNs under heterogeneous impulsive effects. By employing a matrix measure method and extended impulsive Halanay inequality, sufficient criteria are derived to guarantee exponential synchronization of the given delayed CVNNs. The dependency of convergence rates on AIIs and AIGs is explicitly discussed. Finally, two examples are provided to show the efficiency of the proposed theoretical results.},
  archive      = {J_ISCI},
  author       = {Rakesh Kumar and Umesh Kumar and Subir Das and Jianlong Qiu and Jianquan Lu},
  doi          = {10.1016/j.ins.2020.10.064},
  journal      = {Information Sciences},
  pages        = {228-244},
  shortjournal = {Inf. Sci.},
  title        = {Effects of heterogeneous impulses on synchronization of complex-valued neural networks with mixed time-varying delays},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Double-encrypted watermarking algorithm based on cosine
transform and fractional fourier transform in invariant wavelet domain.
<em>ISCI</em>, <em>551</em>, 205–227. (<a
href="https://doi.org/10.1016/j.ins.2020.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing watermarking algorithms invariant wavelet domain are weak at resisting geometric attacks and have small embedding capacities. In this paper, a robust double-encrypted watermarking algorithm based on the fractional Fourier transform (FRFT) and discrete cosine transform (DCT) in invariant wavelet domain is proposed. A hybrid domain is obtained by applying the redistributed invariant wavelet transform (RIDWT) and cosine transform to the enlarged host image. The low-frequency and high-frequency regions of the domain have advantages against different attacks; thus, the two components are both selected for watermark embedding. To solve the false positive problem, the enlarged watermark is double-encrypted by the Arnold transform and the FRFT before a singular value decomposition is applied to it, which enhances the security of the algorithm due to the generation of more keys. Multiparameter particle swarm optimization (MP-PSO) is used to obtain the optimal embedding factors for achieving the balance between invisibility and robustness. The simulation results and comparative experiments show that the proposed algorithm exhibits high robustness under the premise of satisfying security, reliability and invisibility, especially for geometric attacks such as rotation, cropping and translation.},
  archive      = {J_ISCI},
  author       = {Yuan-Min Li and Deyun Wei and Lina Zhang},
  doi          = {10.1016/j.ins.2020.11.020},
  journal      = {Information Sciences},
  pages        = {205-227},
  shortjournal = {Inf. Sci.},
  title        = {Double-encrypted watermarking algorithm based on cosine transform and fractional fourier transform in invariant wavelet domain},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered control for nonlinear leaf spring hydraulic
actuator suspension system with valve predictive management.
<em>ISCI</em>, <em>551</em>, 184–204. (<a
href="https://doi.org/10.1016/j.ins.2020.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new control strategy with networked event-triggered force domain controller and valve opening predictive management local controller is proposed for nonlinear hysteretic leaf spring suspension system with asymmetric cylinder hydraulic actuator over actuated by multiple servo-valves. Takagi–Sugeno fuzzy approach is employed to describe this uncertainty system with experimentally evaluated nonlinear hysteretic leaf spring under consideration of asynchronous premises and transmission delays in a unified framework. For the derived nonlinear network control system, event-triggered domain controller is proposed to generate target force with linear matrix inequality approach based on Lyapunov asymptotically stability theory . The target force is tracked by hydraulic actuator with over actuated multiple servo-valves. These servo-valve openings are collaboratively regulated by predictive management local controller via solving constrained optimal nonlinear control problem. Finally, numerical simulation results are provided to verify the effectiveness and benefits of the proposed control strategy. Compared to passive and time-triggered sampled data control, the obtained results indicate that the sprung mass acceleration and suspension working space are greatly improved without sacrificing tire dynamic load. The valve opening predictive management for over actuated hydraulic actuator is successfully achieved, and simultaneously both the communication resource and actuator power consumption are significantly saved with adaptive event-triggered control strategy.},
  archive      = {J_ISCI},
  author       = {Fei Ding and Qianlong Li and Chao Jiang and Xu Han and Jie Liu and Haiping Du and Fei Lei},
  doi          = {10.1016/j.ins.2020.11.036},
  journal      = {Information Sciences},
  pages        = {184-204},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered control for nonlinear leaf spring hydraulic actuator suspension system with valve predictive management},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Binary handwriting image enhancement by directional
field-guided morphology. <em>ISCI</em>, <em>551</em>, 168–183. (<a
href="https://doi.org/10.1016/j.ins.2020.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a technique for processing handwriting images. The algorithm used in this study is an improvement to the binarisation process. The enhancement focuses on correcting damaged lines that usually arise during the binarisation process, particularly, spurious holes, discontinuities, and eroded boundaries. The presented method uses a morphogical dilation operation in which a structural element is locally adapted using the information from a directional field. The adaptation process involves a new criterion for selecting orientation and shape of a structural element that combines directional field, a coherence measure, and a circular histogram. The field was computed using gradient-based approach, and a method based on a Hessian matrix . During experiments, our method was applied to the output of selected binarisation algorithms. The experiments were conducted on grayscale signature images (from the CEDAR database) and handwriting images (from the DIBCO database). The results of the algorithm were compared to the results of standard morphological operations (dilation, erosion, opening, and closing) and median filtering . The experiments show that the proposed method achieves significant accuracy improvement (8\%–12\% for Acc, 15\%–32\% for Acc2 measures), reduces the number of unwanted artefacts, and produces images with less distortion compared to those from standard approaches.},
  archive      = {J_ISCI},
  author       = {Marcin Adamski and Kacper Sarnacki and Khalid Saeed},
  doi          = {10.1016/j.ins.2020.11.019},
  journal      = {Information Sciences},
  pages        = {168-183},
  shortjournal = {Inf. Sci.},
  title        = {Binary handwriting image enhancement by directional field-guided morphology},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-channel hybrid community detection in attributed
networks. <em>ISCI</em>, <em>551</em>, 146–167. (<a
href="https://doi.org/10.1016/j.ins.2020.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the problem of hybrid community detection in attributed networks based on the information of network topology and attributes with the aim to address the following two shortcomings of existing hybrid community detection methods. First, many of these methods are based on the assumption that network topology and attributes carry consistent information but ignore the intrinsic mismatch correlation between them. Second, network topology is typically treated as the dominant source of information, with attributes employed as the auxiliary source; the dominant effect of attributes is seldom explored or indeed considered. To address these limitations, this paper presents a novel Dual-channel Hybrid Community Detection (DHCD) method that considers the dominant effects of topology and attributes separately. The concept of transition relation between the topology and attribute clusters is introduced to explore the mismatch correlation between the two sources and learn the behavioral and content diversity of nodes. An extended overlapping community detection algorithm is introduced based on the two types of diversity. By utilizing network attributes, DHCD can simultaneously derive the community partitioning membership and corresponding semantic descriptions . The superiority of DHCD over state-of-the-art community detection methods is demonstrated on a set of synthetic and real-world networks.},
  archive      = {J_ISCI},
  author       = {Meng Qin and Kai Lei},
  doi          = {10.1016/j.ins.2020.11.010},
  journal      = {Information Sciences},
  pages        = {146-167},
  shortjournal = {Inf. Sci.},
  title        = {Dual-channel hybrid community detection in attributed networks},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). To recognize or not to recognize – a database of encrypted
images with subjective recognition ground truth. <em>ISCI</em>,
<em>551</em>, 128–145. (<a
href="https://doi.org/10.1016/j.ins.2020.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of very low quality visual data is known to be difficult. In particular, the ability of humans to recognize encrypted visual data is currently impossible to determine computationally. The human vision research community has widely studied some particular topics, such as image quality assessment or the determination of a visibility threshold, while others are still barely researched, specifically visual content recognition. To this day, there does not exist a reliable recognition index that can be employed for such tasks. In order to enable the study of human image content recognition, and in an attempt to propose a corresponding recognizability index, we build a dataset of selectively encrypted images together with subjective ground-truth about their human intelligibility. The methods of acquisition, setup, protocol, outlier detection , are described and we suggest how to calculate a recognition score as well as a recognition threshold. The performance of traditional visual quality indices to predict human visual content recognition is assessed on these data and found to be inapt to estimate recognition of visual content. Contrasting, structure based recognition indices as proposed for this task are shown to represent a promising starting point for further research. To facilitate the creation of a recognition index and to foster further research into human visual content recognition and its relation to the human visual system we will make the database publicly available.},
  archive      = {J_ISCI},
  author       = {Heinz Hofbauer and Florent Autrusseau and Andreas Uhl},
  doi          = {10.1016/j.ins.2020.11.047},
  journal      = {Information Sciences},
  pages        = {128-145},
  shortjournal = {Inf. Sci.},
  title        = {To recognize or not to recognize – a database of encrypted images with subjective recognition ground truth},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven inference modeling based on an on-line
wang-mendel fuzzy approach. <em>ISCI</em>, <em>551</em>, 113–127. (<a
href="https://doi.org/10.1016/j.ins.2020.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the modeling of continuous production process with dynamic and nonlinear characteristics, an on-line Wang-Mendel fuzzy inference model is proposed in this paper, which extracts the fuzzy rules from the raw data without prior knowledge. Considering the state of the industrial system changes dynamically online, typical data samples with support degrees are used to describe the sample distribution characteristics in each fuzzy region. With respect to online dynamic learning process, a self-evolutionary strategy with adaptive memory factors is proposed, and the fuzzy rule structures are updated gradually by a stochastic gradient descent method. For on-line updating, a loss function is constructed by considering the inference errors and the previous rule structure, in order to achieve continuous learning without forgetting the knowledge learned before. In the reasoning process, a sparse fuzzy reasoning approach is designed for extrapolating the knowledge of the fuzzy regions without sample data. To verify the effectiveness of the proposed method, chaotic time series data with noises and industrial practical data coming from a steel plant are employed for experimental analyses. The experimental results show that, the proposed method is capable of describing a variety of dynamic features and exhibiting high accuracy for the industrial data.},
  archive      = {J_ISCI},
  author       = {Yanwei Zhai and Zheng Lv and Jun Zhao and Wei Wang and Henry Leung},
  doi          = {10.1016/j.ins.2020.10.018},
  journal      = {Information Sciences},
  pages        = {113-127},
  shortjournal = {Inf. Sci.},
  title        = {Data-driven inference modeling based on an on-line wang-mendel fuzzy approach},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Multiattribute decision making based on interval-valued
intuitionistic fuzzy values, score function of connection numbers, and
the set pair analysis theory. <em>ISCI</em>, <em>551</em>, 100–112. (<a
href="https://doi.org/10.1016/j.ins.2020.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new multiattribute decision making (MADM) method based on the proposed score function of connection numbers (CNs) and the set pair analysis (SPA) theory in the interval-valued intuitionist fuzzy (IVIF) context. Firstly, we develop a score function for ranking CNs. The various notable characteristics of the proposed score function of CNs are also presented. Then, we propose a new MADM method based on interval-valued intuitionist fuzzy values (IVIFVs), the proposed score function of CNs and the SPA theory, where we convert IVIFVs into CNs and the optimal weights of attributes are calculated from the IVIF weights of attributes. Finally, the proposed MADM method is applied for MADM in the IVIF context, where the preference orders (POs) of the alternatives obtained by the proposed MADM method are compared with the ones obtained by the existing MADM methods. The proposed MADM method can overcome the drawbacks of the existing MADM methods.},
  archive      = {J_ISCI},
  author       = {Kamal Kumar and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2020.11.032},
  journal      = {Information Sciences},
  pages        = {100-112},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making based on interval-valued intuitionistic fuzzy values, score function of connection numbers, and the set pair analysis theory},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The stratic defuzzifier for discretised general type-2 fuzzy
sets. <em>ISCI</em>, <em>551</em>, 83–99. (<a
href="https://doi.org/10.1016/j.ins.2020.10.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stratification is a feature of the type-reduced set of the general type-2 fuzzy set, from which a new technique for general type-2 defuzzification , Stratic Defuzzification, may be derived. Existing defuzzification strategies are summarised. The stratified structure is described, after which the Stratic Defuzzifier is presented and contrasted experimentally for accuracy and efficiency with both the Exhaustive Method of Defuzzification (to benchmark accuracy) and the α α -Planes/Karnik–Mendel Iterative Procedure strategy, employing 5, 11, 21, 51 and 101 α α -planes. The Stratic Defuzzifier is shown to be much faster than the Exhaustive Defuzzifier. In fact the Stratic Defuzzifier and the α α -Planes/Karnik–Mendel Iterative Procedure Method are comparably speedy; the speed of execution correlates with the number of planes participating in the defuzzification process. The accuracy of the Stratic Defuzzifier is shown to be excellent. It is demonstrated to be more accurate than the α α -Planes/Karnik–Mendel Iterative Procedure Method in four of six test cases, regardless of the number of α α -planes employed. In one test case, it is less accurate than the α α -Planes/Karnik–Mendel Iterative Procedure Method, regardless of the number of α α -planes employed. In the remaining test case, the α α -Planes/Karnik–Mendel Iterative Procedure Method with 11 α α -Planes gives the most accurate result, with the Stratic Defuzzifier coming second.},
  archive      = {J_ISCI},
  author       = {Sarah Greenfield and Francisco Chiclana},
  doi          = {10.1016/j.ins.2020.10.062},
  journal      = {Information Sciences},
  pages        = {83-99},
  shortjournal = {Inf. Sci.},
  title        = {The stratic defuzzifier for discretised general type-2 fuzzy sets},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Missing value imputation in multivariate time series with
end-to-end generative adversarial networks. <em>ISCI</em>, <em>551</em>,
67–82. (<a href="https://doi.org/10.1016/j.ins.2020.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing values are inherent in multivariate time series because of multiple reasons, such as collection errors, which deteriorate the performance of follow-up analytic applications on the multivariate time series . Numerous missing value imputation methods have been proposed to mitigate the influence of missing values on multivariate time series analysis. Recently, inspired by the success of generative adversarial networks (GANs) in image generation , the GAN-2-Stage has been used to address the imputation problem with the generative model . Specifically, GAN-2-Stage employs GANs to impute the missing values. However, an extra phase is required to optimize the input random “noise” of the generator. In addition, the imputed values can be very different from real values because of the difficulty in training a GAN and the unstable generation process. Therefore, this paper proposes an end-to-end model to impute the missing values in a multivariate time series. Specifically, we introduce an encoder network into the standard GAN architecture that eliminates the input optimization phase in the GAN-2-Stage. Our generator utilizes real data during training to force the imputed values to be close to the real ones. Experiments on three real-world multivariate time series datasets demonstrate that the proposed model outperforms state-of-the-art methods in imputation tasks and downstream applications, including classification and regression.},
  archive      = {J_ISCI},
  author       = {Ying Zhang and Baohang Zhou and Xiangrui Cai and Wenya Guo and Xiaoke Ding and Xiaojie Yuan},
  doi          = {10.1016/j.ins.2020.11.035},
  journal      = {Information Sciences},
  pages        = {67-82},
  shortjournal = {Inf. Sci.},
  title        = {Missing value imputation in multivariate time series with end-to-end generative adversarial networks},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information spreading with relative attributes on signed
networks. <em>ISCI</em>, <em>551</em>, 54–66. (<a
href="https://doi.org/10.1016/j.ins.2020.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past years, network dynamics has been widely investigated in various disciplines. As a practical and convenient description for social networks, signed networks have also garnered significant attention. In this work, we study information spreading with relative attributes on signed networks, where edges are assigned positive or negative labels, describing friendly or hostile relationships. We define the attribute of information by a degree that can be either ‘good’ or ‘bad’ and assume that the spreading willingness of the information receiver depends on not only its relation with others but also the attribute of information. A pair-wise potential relation identification algorithm is designed based on the shortest path approach and structural balance theory. Both simulations on randomly signed networks and empirical experiments on real datasets show that the proposed information spreading could be approximately investigated within a local 2-order neighborhood. In addition, the ratio of potential friendly nodes with a target node is consist with network content. Finally, the propagation speed of ‘good’ information would unexpectedly slow down when the ratio of positive edges is larger than an estimated threshold. The presented model could be referred to in real social scenarios, such as product promotion, advertisement media, and rumor mongering.},
  archive      = {J_ISCI},
  author       = {Ya-Wei Niu and Cun-Quan Qu and Guang-Hui Wang and Jian-Liang Wu and Gui-Ying Yan},
  doi          = {10.1016/j.ins.2020.11.042},
  journal      = {Information Sciences},
  pages        = {54-66},
  shortjournal = {Inf. Sci.},
  title        = {Information spreading with relative attributes on signed networks},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A flexible image cipher based on orthogonal arrays.
<em>ISCI</em>, <em>551</em>, 39–53. (<a
href="https://doi.org/10.1016/j.ins.2020.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A flexible image cipher based on orthogonal arrays is proposed in this paper. Orthogonal array is a typical combinatorial configuration. It has discreteness and uniformity, which makes orthogonal array a natural candidate for cryptography. In particular, an orthogonal array can provide multiple substitution sequences and permutation maps for image cipher. To control the selection of substitution sequences and permutation maps, two public parameters are introduced in the proposed algorithm. If the parameter values vary, the substitution sequences and permutation maps will be different, then the same plaintext image corresponds to different cipher images. By the utilization of orthogonal arrays , the proposed algorithm is flexible and secure, so it is quite applicable to the complex network environment.},
  archive      = {J_ISCI},
  author       = {Ming Xu and Zihong Tian},
  doi          = {10.1016/j.ins.2020.11.029},
  journal      = {Information Sciences},
  pages        = {39-53},
  shortjournal = {Inf. Sci.},
  title        = {A flexible image cipher based on orthogonal arrays},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-dominated sorting on performance indicators for
evolutionary many-objective optimization. <em>ISCI</em>, <em>551</em>,
23–38. (<a href="https://doi.org/10.1016/j.ins.2020.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much attention has been paid to evolutionary multi-objective optimization approaches to efficiently solve real-world engineering problems with multiple conflicting objectives. However, the loss of selection pressure and the non-uniformity in the distribution of the Pareto optimal solutions in the objective space can impede both dominance-based and decomposition-based multi-objective optimizers when solving many-objective problems. In this work, we circumvent this issue by exploiting two performance indicators, and use these in an optimizer’s environmental selection via non-dominated sorting. This effectively converts the original many-objective problem into a bi-objective one. Our convergence performance criterion tries to balance the performance of individuals in different parts of the objective space. The angle between solutions on objective space is adopted to measure the diversity of each individual. Using these solutions can be separated into different layers easily, which is often not possible for the original many-objective optimization representation. The performance of the proposed method is evaluated on the DTLZ benchmark problems with up to 30 objectives, and MaF test suite with 10, 15, 20 and 30 objectives. The experimental results show that our proposed method is competitive compared to six recently proposed algorithms, especially for solving problems with a large number of objectives.},
  archive      = {J_ISCI},
  author       = {Hao Wang and Chaoli Sun and Guochen Zhang and Jonathan E. Fieldsend and Yaochu Jin},
  doi          = {10.1016/j.ins.2020.11.008},
  journal      = {Information Sciences},
  pages        = {23-38},
  shortjournal = {Inf. Sci.},
  title        = {Non-dominated sorting on performance indicators for evolutionary many-objective optimization},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exchange, adopt, evolve: Modeling the spreading of opinions
through cognition and interaction in a social network. <em>ISCI</em>,
<em>551</em>, 1–22. (<a
href="https://doi.org/10.1016/j.ins.2020.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The formation of public opinions is a complex phenomenon that revolves around the aggregation of individuals’ beliefs. To accurately capture this phenomenon, one needs to build links from individualistic experiences to personal beliefs, which evolve in a social space through information exchange and belief revision. Despite many efforts to model opinion dynamics, the role of personal experiences and beliefs has often been overlooked. In this paper, we address this issue and propose an agent-based model in a social network. We explicitly model belief acquisition as a learning process from experiences that take the form of local data sets. Agents interact through a social network and update their beliefs based on how accurately the belief reflects experiences. Through iterations of interactions, the agents are able to arrive at a unified belief. We then focus on the accuracy of the personal beliefs during their evolution and the impact of the social network structure . On a micro-level, we investigate positional attributes such as the centrality of nodes that affect belief accuracy. On a macro-level, we investigate structural features that affect the overall performance. We then investigate a method to intervene in opinion formation through expert agents. Experiments are performed on real-world and synthetic data sets, which validate a number of important structural insights.},
  archive      = {J_ISCI},
  author       = {Yanni Tang and Jiamou Liu and Wu Chen},
  doi          = {10.1016/j.ins.2020.11.043},
  journal      = {Information Sciences},
  pages        = {1-22},
  shortjournal = {Inf. Sci.},
  title        = {Exchange, adopt, evolve: Modeling the spreading of opinions through cognition and interaction in a social network},
  volume       = {551},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Statistical test criteria for sensitivity indexes of image
cryptosystems. <em>ISCI</em>, <em>550</em>, 313–328. (<a
href="https://doi.org/10.1016/j.ins.2020.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {System sensitivity is an important security evaluation aspect of image cryptosystems . On the basis of probability and statistics this paper studies in detail the theoretical-value calculation methods of sensitivity evaluation indexes of image cryptosystems: the expected values and variances of NPCR (number of pixels change rate), UACI (unified average changing intensity), and BACI (blocked average changing intensity). Also, the acceptance domains of listed indexes are discussed using the central limit theorem, and five image cryptosystems are employed to test the acceptance domains. Finally, the following conclusion is drawn: the image cryptosystem is identified as sensitive when the passing rate of the BACI index of multiple tests is higher than 50\% under the conditions that the number of samples is 100 and the significance level is α α = 0.01, or when the maximum relative error of the average values of the BACI indexes of multiple tests is less than 0.1\%.},
  archive      = {J_ISCI},
  author       = {Yong Zhang},
  doi          = {10.1016/j.ins.2020.10.026},
  journal      = {Information Sciences},
  pages        = {313-328},
  shortjournal = {Inf. Sci.},
  title        = {Statistical test criteria for sensitivity indexes of image cryptosystems},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Output feedback stabilization via nonlinear mapping for
time-varying constrained nonholonomic systems in prescribed finite time.
<em>ISCI</em>, <em>550</em>, 297–312. (<a
href="https://doi.org/10.1016/j.ins.2020.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers fixed-time stabilization using output feedback for chained-form nonholonomic systems. Notably, the distinctive features of the study are that the system under consideration is adversely affected by time-varying output constraints, and the system states are driven to zero in the prescribed finite time. A time-varying version of the nonlinear mapping is recommended to address the output constraints. The construction of a novel switched time-varying observer that has the capability of estimating the immeasurable states in fixed time enables us to devise an output feedback controller . This controller guarantees the achievement of the performance requirements by employing switching control strategy. Finally, a benchmark example is given to acknowledge the efficacy of the proposed control scheme.},
  archive      = {J_ISCI},
  author       = {Fangzheng Gao and Jiacai Huang and Xiaochun Zhu and Yuqiang Wu},
  doi          = {10.1016/j.ins.2020.10.027},
  journal      = {Information Sciences},
  pages        = {297-312},
  shortjournal = {Inf. Sci.},
  title        = {Output feedback stabilization via nonlinear mapping for time-varying constrained nonholonomic systems in prescribed finite time},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Black-box adversarial attacks by manipulating image
attributes. <em>ISCI</em>, <em>550</em>, 285–296. (<a
href="https://doi.org/10.1016/j.ins.2020.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there exist various adversarial attacking methods, most of them are performed by generating adversarial noises. Inspired by the fact that people usually set different camera parameters to obtain diverse visual styles when taking a picture, we propose the adversarial attributes, which generate adversarial examples by manipulating the image attributes like brightness, contrast, sharpness, chroma to simulate the imaging process . This task is accomplished under the black-box setting, where only the predicted probabilities are known. We formulate this process into an optimization problem . After efficiently solving this problem, the optimal adversarial attributes are obtained with limited queries. To guarantee the realistic effect of adversarial examples , we bound the attribute changes using L p Lp norm versus different p values. Besides, we also give a formal explanation for the adversarial attributes based on the linear nature of Deep Neural Networks (DNNs). Extensive experiments are conducted on two public datasets, including CIFAR-10 and ImageNet with respective to four representative DNNs like VGG16, AlexNet, Inception v3 and Resnet50 . The results show that at most 97.79\% 97.79\% of images in CIFAR-10 test dataset and 98.01\% 98.01\% of the ImageNet images can be successfully perturbed to at least one wrong class with only ⩽ ⩽ 300 queries per image on average.},
  archive      = {J_ISCI},
  author       = {Xingxing Wei and Ying Guo and Bo Li},
  doi          = {10.1016/j.ins.2020.10.028},
  journal      = {Information Sciences},
  pages        = {285-296},
  shortjournal = {Inf. Sci.},
  title        = {Black-box adversarial attacks by manipulating image attributes},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hamiltonian fuzzy graphs with application to human
trafficking. <em>ISCI</em>, <em>550</em>, 268–284. (<a
href="https://doi.org/10.1016/j.ins.2020.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bottlenecks create delay and traffic jams in interconnection networks . Allowing more paths and cycles of larger capacities can ease this problem to some extent. A path of maximum size is said to be a heavy path . In this paper, some results on heavy paths, heavy cycles and Hamilton cycles are presented. A generalization for Dirac’s theorem in graph theory is discussed in a fuzzy set up. Algorithms for the determination of heavy paths and heavy Hamilton cycles and an application of heavy paths in human trafficking are also proposed.},
  archive      = {J_ISCI},
  author       = {Shanookha Ali and Sunil Mathew and J N Mordeson},
  doi          = {10.1016/j.ins.2020.10.029},
  journal      = {Information Sciences},
  pages        = {268-284},
  shortjournal = {Inf. Sci.},
  title        = {Hamiltonian fuzzy graphs with application to human trafficking},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple images encryption based on 3D scrambling and
hyper-chaotic system. <em>ISCI</em>, <em>550</em>, 252–267. (<a
href="https://doi.org/10.1016/j.ins.2020.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growth and popularization of network and multimedia technologies have led to an increase in digital data over the internet. Most of the data is confidential and requires an efficient algorithm to securely transmit the data over the insecure channel. The paper proposes a cryptographic algorithm which can be used for securing multiple digital images over the network. The algorithm uses the concept of chaos theory and elliptic curve Elgamal cryptosystem for the generation of the cipher image and sharing of the key. A 3D image is generated using the multiple plain images and undergoes permutation and substitution phase for generation of the cipher data. Experimental results and analysis shows that the proposed algorithm has got large keyspace, desired statistical properties of cipher data and resistant to attacks.},
  archive      = {J_ISCI},
  author       = {Aasawari Sahasrabuddhe and Dolendro Singh Laiphrakpam},
  doi          = {10.1016/j.ins.2020.10.031},
  journal      = {Information Sciences},
  pages        = {252-267},
  shortjournal = {Inf. Sci.},
  title        = {Multiple images encryption based on 3D scrambling and hyper-chaotic system},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A noise-suppressing newton-raphson iteration algorithm for
solving the time-varying lyapunov equation and robotic tracking
problems. <em>ISCI</em>, <em>550</em>, 239–251. (<a
href="https://doi.org/10.1016/j.ins.2020.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Newton-Raphson iteration (NRI) algorithm is a prevalent computational methodology in many fields and can be used to solve the time-varying Lyapunov equation . However, the performance of the traditional NRI (TNRI) algorithm is severely degraded under noisy conditions. To overcome this weakness, a noise-suppressing NRI (NSNRI) algorithm is proposed in this paper. By utilizing the Kronecker product theorem, the time-varying Lyapunov equation can be transformed into a linear matrix equation . Based on that linear matrix equation , the related theoretical analyses of the convergence and the noise-suppressing property of the NSNRI algorithm under various noise conditions are provided. To verify the theoretical analyses, numerical simulations for solving the time-varying Lyapunov equation and an application to manipulator motion tracking are presented. For comparison purpose, the TNRI and two zeroing neural network (ZNN) algorithms are also introduced in these simulations. As indicated by the simulation results, the NSNRI algorithm is superior in terms of the convergence accuracy and the robustness to noise.},
  archive      = {J_ISCI},
  author       = {Guancheng Wang and Haoen Huang and Limei Shi and Chuhong Wang and Dongyang Fu and Long Jin and Xiao Xiuchun},
  doi          = {10.1016/j.ins.2020.10.032},
  journal      = {Information Sciences},
  pages        = {239-251},
  shortjournal = {Inf. Sci.},
  title        = {A noise-suppressing newton-raphson iteration algorithm for solving the time-varying lyapunov equation and robotic tracking problems},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The f-transform preprocessing for JPEG strong compression of
high-resolution images. <em>ISCI</em>, <em>550</em>, 221–238. (<a
href="https://doi.org/10.1016/j.ins.2020.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are focused on improving the JPEG compression algorithm in the cases where a high ratio compression is required. For this purpose, we propose a preprocessing based on the F-transform. We develop a new discrete version of the inverse F-transform and new hybrid image compression and decompression algorithms, which combine JPEG with the F-transform. In the compression phase, JPEG follows the direct F-transform, while in the decompression phase, the methods are performed in the opposite order, and the new inverse F-transform is applied. We justify and illustrate on high-resolution benchmarks three main advantages of the proposed combination over the pure JPEG. We performed 504600 compressions using 15 different qualities, and for each selected quality it was confirmed that the proposed approach has compression 4 times stronger and the SSIM quality is 1.6 times higher than the pure JPEG. Finally, we propose an easy way to use the new compression software in the current JPEG standard.},
  archive      = {J_ISCI},
  author       = {Irina Perfilieva and Petr Hurtik},
  doi          = {10.1016/j.ins.2020.10.033},
  journal      = {Information Sciences},
  pages        = {221-238},
  shortjournal = {Inf. Sci.},
  title        = {The F-transform preprocessing for JPEG strong compression of high-resolution images},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective prediction intervals for wind power forecast
based on deep neural networks. <em>ISCI</em>, <em>550</em>, 207–220. (<a
href="https://doi.org/10.1016/j.ins.2020.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power forecast is playing a significant role in the operation and dispatch of modern power systems . Compared with traditional point forecast methods, interval forecast is able to quantify uncertainties effectively. Unfortunately, the stochastic and intermittent nature of wind power has brought significant challenges to get high quality prediction intervals (PIs). In this paper, a novel interval forecast model based on long short-term memory neural networks (LSTM) is proposed to construct PIs with the lower and upper bound estimation method. Besides, an improved PI evaluation criterion is proposed by considering the estimation error of PIs. Moreover, a multi-objective optimization framework is proposed to investigate the relationship between PI estimation error and average width. To tune the parameters of LSTM, the widely used non-dominated fast sort genetic algorithm is further improved by introducing the competitive learning mechanism. The effectiveness of the proposed model and algorithm is demonstrated by a series of experiments based on a real world wind power dataset.},
  archive      = {J_ISCI},
  author       = {Min Zhou and Bo Wang and Shudong Guo and Junzo Watada},
  doi          = {10.1016/j.ins.2020.10.034},
  journal      = {Information Sciences},
  pages        = {207-220},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective prediction intervals for wind power forecast based on deep neural networks},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Command filtered finite-time control for nonlinear systems
with state constraints and its application to TCP network.
<em>ISCI</em>, <em>550</em>, 189–206. (<a
href="https://doi.org/10.1016/j.ins.2020.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies the issue of finite-time tracking control for a class of nonlinear systems with state constraints. By means of command filtered backstepping technique, finite-time theory and Barrier Lyapunov Functions (BLF), a novel finite-time command filtered backstepping approach is presented to guarantee the finite-time convergence of tracking errors. The new proposed method can not only reduce the complexity of computation of the conventional backstepping control and compensate filtered errors by Dynamic Surface Control (DSC), but also can guarantee that the state variables are restricted in compact bounding sets. Moreover, the proposed controller is designed and applied to Transmission Control Protocol/Active Queue Management (TCP/AQM) network systems, which guarantees the practical boundedness of all the signals in the closed-loop system. Finally, the effectiveness and practicability of the developed control strategy are validated by a TCP network simulation example.},
  archive      = {J_ISCI},
  author       = {Kun Wang and Xiaoping Liu and Yuanwei Jing},
  doi          = {10.1016/j.ins.2020.10.035},
  journal      = {Information Sciences},
  pages        = {189-206},
  shortjournal = {Inf. Sci.},
  title        = {Command filtered finite-time control for nonlinear systems with state constraints and its application to TCP network},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leader recommend operators selection strategy for a
multiobjective evolutionary algorithm based on decomposition.
<em>ISCI</em>, <em>550</em>, 166–188. (<a
href="https://doi.org/10.1016/j.ins.2020.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The decomposition-based multi-objective evolutionary algorithm (MOEA/D) shows strong performance in solving complex multi-objective problems (MOPs), wherein evolutionary operators have great influence on the search ability. Appropriate operators can greatly improve the performance of MOEA/D. However, one omnipotent operator usually cannot handle all different MOPs very well. According to the characteristics of the problems, the operators that adapt to the problems are also different. This paper proposes an adaptive operator selection strategy called Leader Recommend Operator Selection (LROS). We construct an operator pool consisting of Simulated Binary Crossover (SBX) and three operators of Differential Evolution (DE). Meanwhile, we divide the entire evolutionary process into several stages, and each stage is divided into Part 1 and Part 2. In Part 1 of each stage, we use a subset of individuals to test the performance of each operator in the operator pool and choose the best performance. In Part 2, we adopt the best performing operator selected in Part 1 to generate offspring, meanwhile we verify the actual quality of these offspring to decide in the next stage whether to continue using this operator to generate offspring or to choose a more suitable operator. Experimental results demonstrate the effectiveness of LROS.},
  archive      = {J_ISCI},
  author       = {Zeyuan Yan and Yanyan Tan and Wei Zheng and Lili Meng and Huaxiang Zhang},
  doi          = {10.1016/j.ins.2020.10.036},
  journal      = {Information Sciences},
  pages        = {166-188},
  shortjournal = {Inf. Sci.},
  title        = {Leader recommend operators selection strategy for a multiobjective evolutionary algorithm based on decomposition},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A ranking model of z-mixture-numbers based on the ideal
degree and its application in multi-attribute decision making.
<em>ISCI</em>, <em>550</em>, 145–165. (<a
href="https://doi.org/10.1016/j.ins.2020.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Z-number has a great advantage in describing uncertain information. Since Zadeh proposed Z-number, scholars have combined the Z-number with multi-attribute decision making (MADM). However, the problem of having both continuous and discrete attributes in practical MADM is rarely mentioned in the existing methods. To solve this problem, first, we propose the concept of Z-mixture-numbers and propose a new ranking model based on the idea of the ideal degree. Next, after analyzing the correlation coefficient between attributes, we propose the Z-multi-attribute decision making weighting method based on the correlation coefficient . Moreover, the Z mixture induced ordered weighted averaging (ZMIOWA) operator and the Z mixture combined weighted averaging aggregation operator (ZMCWAA) are put forward to solve the MADM problems in which continuous and discrete attributes exist simultaneously. Finally, we propose a MADM method with Z-mixture-numbers and take an example of the sharing car venture capital problem to illustrate its feasibility. It overcomes the previously unsolved problem of Z-numbers’ continuous-discrete mixed MADM.},
  archive      = {J_ISCI},
  author       = {Sidong Xian and Jiahui Chai and Tangjin Li and Jie Huang},
  doi          = {10.1016/j.ins.2020.10.038},
  journal      = {Information Sciences},
  pages        = {145-165},
  shortjournal = {Inf. Sci.},
  title        = {A ranking model of Z-mixture-numbers based on the ideal degree and its application in multi-attribute decision making},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved clustering algorithms for image segmentation based
on non-local information and back projection. <em>ISCI</em>,
<em>550</em>, 129–144. (<a
href="https://doi.org/10.1016/j.ins.2020.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate image segmentation is a prerequisite to conducting an image analysis task, and the complexity stemming from the semantic diversity plays a pivotal role in image segmentation . Existing algorithms employed different types of information in the process of segmentation to improve the robustness. However, these algorithms were characterized by a tradeoff between noise removal and detail retention; this is because it is difficult to distinguish image artifacts from details. This paper proposes an improved image segmentation schema and presents two improved clustering algorithms , in which self-similarity and back projection are considered simultaneously to enhance the robustness. With the aid of self-similarity, non-local information is fully exploited, while the original information can be retained by back projection . Extensive experiments on various types of images demonstrate that our algorithms can balance noise restraining and detail retention to improve the adaptation of complex images in segmentation.},
  archive      = {J_ISCI},
  author       = {Xiaofeng Zhang and Yujuan Sun and Hui Liu and Zhongjun Hou and Feng Zhao and Caiming Zhang},
  doi          = {10.1016/j.ins.2020.10.039},
  journal      = {Information Sciences},
  pages        = {129-144},
  shortjournal = {Inf. Sci.},
  title        = {Improved clustering algorithms for image segmentation based on non-local information and back projection},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Residual implications on lattice l of intuitionistic truth
values based on powers of continuous t-norms. <em>ISCI</em>,
<em>550</em>, 109–128. (<a
href="https://doi.org/10.1016/j.ins.2020.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residual implications are a special class of implications on the lattice L L of intuitionistic truth values which possess interesting theoretical and practical properties. Many studies have investigated the properties of the types of implications on L L and established the relationships among them. In this paper, the powers of the continuous t-norms T T on L L are introduced, and their properties studied. A new type of implication on L L , termed the T T -power based implication, is derived from the powers of the continuous t-norms T T , as denoted by I I T IIT and satisfies certain properties of the residual implications defined on the interval [0, 1] under certain conditions. Some important properties are analyzed. These results collectively reveal that they do not intersect the most well-known classes of fuzzy implications. Finally, we investigate the solutions of some Boolean-like laws for I I T IIT .},
  archive      = {J_ISCI},
  author       = {Vishnu Singh and Radko Mesiar and Bapi Dutta and Mark Goh},
  doi          = {10.1016/j.ins.2020.10.040},
  journal      = {Information Sciences},
  pages        = {109-128},
  shortjournal = {Inf. Sci.},
  title        = {Residual implications on lattice l of intuitionistic truth values based on powers of continuous t-norms},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy rating scales: Does internal consistency of a
measurement scale benefit from coping with imprecision and individual
differences in psychological rating? <em>ISCI</em>, <em>550</em>,
91–108. (<a href="https://doi.org/10.1016/j.ins.2020.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Measuring psychological variables (attitudes, opinions, perceptions, feelings, etc.) there is a need for rating scales coping with both the natural imprecision and individual differences. In this respect, the so-called fuzzy rating scales have been introduced as a doubly continuous instrument allowing to capture both imprecision and individual differences. Aiming to show the advantages of using fuzzy rating scales in the setting of questionnaires, the extended Cronbach α α is considered to quantify the internal consistency associated with constructs involving fuzzy rating scale-based items. This extended tool allows us to draw interesting conclusions, the main one supporting the use of fuzzy rating scales instead of standard ones (namely, Likert type, visual analogue, and even fuzzy linguistic scales). Although general theoretical conclusions could not be drawn, unequivocal majority trends can be stated from simulation-based and real-life examples.},
  archive      = {J_ISCI},
  author       = {María Asunción Lubiano and Antonio L. García-Izquierdo and María Ángeles Gil},
  doi          = {10.1016/j.ins.2020.10.042},
  journal      = {Information Sciences},
  pages        = {91-108},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy rating scales: Does internal consistency of a measurement scale benefit from coping with imprecision and individual differences in psychological rating?},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Incremental fuzzy probability decision-theoretic approaches
to dynamic three-way approximations. <em>ISCI</em>, <em>550</em>, 71–90.
(<a href="https://doi.org/10.1016/j.ins.2020.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a special model of three-way decision, three-way approximations in the fuzzy probability space can be interpreted, represented, and implemented as dividing the universe into three pair-wise disjoint regions, i.e., the positive, negative and boundary regions, which are transformed from the fuzzy membership grades with respect to the fuzzy concept. To consider the temporality and uncertainty of data simultaneously, this paper focuses on the integration of dynamics and fuzziness in the context of three-way approximations. We analyze and investigate three types of fuzzy conditional probability functions based on the fuzzy T -norm operators. Besides, we introduce the matrix-based fuzzy probability decision-theoretic models to dynamic three-way approximations based on the principle of least cost. Subsequently, to solve the time-consuming computational problem, we design the incremental algorithms by the updating strategies of matrices when the attributes evolve over time. Finally, a series of comparative experiments is reported to demonstrate and verify the performance of proposed models.},
  archive      = {J_ISCI},
  author       = {Xin Yang and Dun Liu and Xibei Yang and Keyu Liu and Tianrui Li},
  doi          = {10.1016/j.ins.2020.10.043},
  journal      = {Information Sciences},
  pages        = {71-90},
  shortjournal = {Inf. Sci.},
  title        = {Incremental fuzzy probability decision-theoretic approaches to dynamic three-way approximations},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust generative classifier against transfer attacks
based on variational auto-encoders. <em>ISCI</em>, <em>550</em>, 57–70.
(<a href="https://doi.org/10.1016/j.ins.2020.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are vulnerable to adversarial examples. Even under black-box setting that is without access to the target model, transfer-based attacks can easily fool the DNNs. To alleviate this problem, we propose a robust classification model against transfer attacks based on the framework of variational Auto-Encoders (VAEs) which are probabilistic generative models and have been successfully used to a large mount of tasks. Specifically, our model simulates the data generative process with several multivariate Gaussian distributions and DNNs: (1) We assume that the latent embedding generated by an encoder (a DNN) of each category corresponds to a multivariate Gaussian distribution. (2) A decoder (a DNN) is proposed to decodes the latent embedding into an observable. (3) Theoretical analysis illustrates that our model can predict data’s labels by maximizing the lower bound on the log-likelihood for each category utilizing Bayes’ theorem with excellent robustness against transfer attacks. Inference in our model is done in a variational way so the Stochastic Gradient Variational Bayes (SGVB) estimator and reparamerization trick can be utilized to optimize the evidence lower bound (ELBO). The experiments with quantitative comparisons show that our approach reaches state-of-the-art with significantly better robustness.},
  archive      = {J_ISCI},
  author       = {Chen Zhang and Zhuo Tang and Youfei Zuo and Kenli Li and Keqin Li},
  doi          = {10.1016/j.ins.2020.10.044},
  journal      = {Information Sciences},
  pages        = {57-70},
  shortjournal = {Inf. Sci.},
  title        = {A robust generative classifier against transfer attacks based on variational auto-encoders},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HIBOG: Improving the clustering accuracy by ameliorating
dataset with gravitation. <em>ISCI</em>, <em>550</em>, 41–56. (<a
href="https://doi.org/10.1016/j.ins.2020.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an important technology applied in many fields. Most researchers focus on only clustering algorithms when they want more accurate results. However, this is not an optimal strategy because each algorithm has its unique advantages and disadvantages. Furthermore, a given algorithm cannot get satisfactory results on all datasets. In this paper, focusing on datasets, a method called HIBOG is proposed to improve the clustering accuracy by ameliorating datasets with gravitation. HIBOG can help many clustering algorithms acquire better results on more datasets by ameliorating datasets so that similar objects get closer and dissimilar objects separate further apart. As a result, ameliorated datasets are friendlier to many clustering algorithms than original datasets. Though datasets are diverse, HIBOG can cope with the diversity to some extent due to its robustness to high dimensional datasets, Gaussian distribution datasets, shaped datasets, and datasets with high overlap clusters. We have conducted numerous experiments on real-world datasets to verify the effectiveness of HIBOG . The experiments demonstrated that HIBOG successfully improves the accuracy of different clustering algorithms, and accuracy increases by an average of 113.4\% (except maximum and minimum). Moreover, compared with other similar methods, HIBOG improves much higher clustering accuracy and dramatically shortens the running time. At the same time, we conducted 360 experiments, each of which selected different parameter values. The experiments show that most values enable HIBOG to ameliorate datasets, and HIBOG has strong robustness to the parameter adjustment.},
  archive      = {J_ISCI},
  author       = {Qi Li and Shuliang Wang and Chuanfeng Zhao and Boxiang Zhao and Xin Yue and Jing Geng},
  doi          = {10.1016/j.ins.2020.10.046},
  journal      = {Information Sciences},
  pages        = {41-56},
  shortjournal = {Inf. Sci.},
  title        = {HIBOG: Improving the clustering accuracy by ameliorating dataset with gravitation},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel joint biomedical event extraction framework via
two-level modeling of documents. <em>ISCI</em>, <em>550</em>, 27–40. (<a
href="https://doi.org/10.1016/j.ins.2020.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology, the amount of textual data generated in biomedical field becomes larger and larger. Biomedical event extraction , which is a fundamental information extraction task, has gained a growing interest in biomedical community. Although researchers have proposed various approaches to this task, the performance is still undesirable since previous approaches fail to model biomedical documents effectively. In this paper, we propose an end-to-end framework for document-level joint biomedical event extraction . To better capture the complex relationships among contexts in biomedical documents, a two-level modeling approach is introduced for biomedical documents. More specifically, the dependency-based GCN and hypergraph are used to model local context and global context in each biomedical document, respectively. In addition, a fine-grained interaction mechanism is proposed to model effectively the interaction between local and global contexts to learn better contextualized representations for biomedical event extraction. Comprehensive experiments on two widely used datasets are conducted and the results demonstrate the effectiveness of the proposed framework over state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Weizhong Zhao and Jinyong Zhang and Jincai Yang and Tingting He and Huifang Ma and Zhixin Li},
  doi          = {10.1016/j.ins.2020.10.047},
  journal      = {Information Sciences},
  pages        = {27-40},
  shortjournal = {Inf. Sci.},
  title        = {A novel joint biomedical event extraction framework via two-level modeling of documents},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new fractional one dimensional chaotic map and its
application in high-speed image encryption. <em>ISCI</em>, <em>550</em>,
13–26. (<a href="https://doi.org/10.1016/j.ins.2020.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaos theory has been widely used in the design of image encryption schemes . Some low-dimensional chaotic maps have been proved to be easily predictable because of their small chaotic space. On the other hand, high-dimensional chaotic maps have a larger chaotic space. However, their structures are too complicated, and consequently, they are not suitable for real-time image encryption . Motivated by this, we propose a new fractional one-dimensional chaotic map with a large chaotic space. The proposed map has a simple structure and a high chaotic behavior in an extensive range of its control parameters values. Several chaos theoretical tools and tests have been carried out to analyze and prove the proposed map’s high chaotic behavior. Moreover, we use the proposed map in the design of a novel real-time image encryption scheme. In this new scheme, we combine the substitution and permutation stages to simultaneously modify both of the pixels’ positions and values. The merge of these two stages and the use of the new simple one-dimensional chaotic map significantly increase the proposed scheme’s security and speed. Besides, the simulation and experimental analysis prove that the proposed scheme has high performances.},
  archive      = {J_ISCI},
  author       = {Mohamed Zakariya Talhaoui and Xingyuan Wang},
  doi          = {10.1016/j.ins.2020.10.048},
  journal      = {Information Sciences},
  pages        = {13-26},
  shortjournal = {Inf. Sci.},
  title        = {A new fractional one dimensional chaotic map and its application in high-speed image encryption},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conditional random fields as message passing mechanism in
anchor-free network for multi-scale pedestrian detection. <em>ISCI</em>,
<em>550</em>, 1–12. (<a
href="https://doi.org/10.1016/j.ins.2020.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many deep learning detectors have been proposed to address the scale variation issue in pedestrian detection. However, it is still far from being fully solved because most of these detectors handle the issue by directly fusing multiple extracted features with the weighted average or concatenation. Therefore, this paper designs a novel and effective anchor-free network (namely MPAF-Net) for multi-scale pedestrian detection. Specifically, we first improve Res2Net as our backbone network by designing a novel bottleneck block to make the proposed detector has a strong multi-scale representation ability for pedestrians. Furthermore, based on Conditional Random Fields (CRFs), the multi-scale features obtained from three different feature pyramid levels of backbone network are refined with a designed message passing mechanism. By doing so, the complementary information from the features at other scales can be dynamically passed to enhance the scale-specific feature. Finally, pedestrian detection is simplified as a straightforward center and scale prediction task by performing convolution on the concatenation of refined multi-scale convolution features. This way, the proposed MPAF-Net can be trained in an end-to-end fashion. Experimental results show that MPAF-Net achieves state-of-the-art performance on CityPersons, Caltech, and CrowdHuman benchmarks.},
  archive      = {J_ISCI},
  author       = {Qiming Li and Hua Qiang and Jun Li},
  doi          = {10.1016/j.ins.2020.10.049},
  journal      = {Information Sciences},
  pages        = {1-12},
  shortjournal = {Inf. Sci.},
  title        = {Conditional random fields as message passing mechanism in anchor-free network for multi-scale pedestrian detection},
  volume       = {550},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Random walk based distributed representation learning and
prediction on social networking services. <em>ISCI</em>, <em>549</em>,
328–346. (<a href="https://doi.org/10.1016/j.ins.2020.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social Networking Services (SNSs) provide online platforms for users with two kinds of behavior: user-user social behavior (e.g., following a user, making friends with others) and user-item consumption behavior (e.g., rating, showing likeness, clicking, giving thumbs up to items). With the increasing popularity of SNSs and demand for SNS features, predicting potential social links and recommending preferable items to users have become two hot research lines. However, previous works either modeled just one of these two kinds of behaviors in isolation or only considered the observed user behavior data. In fact, social scientists have long recognized that the user-user and user-item behaviors have a mutual reinforcement effect. On the one hand, the two behaviors have correlations, and they can influence each other. On the other hand, due to the sparsity of the observed user behavior data, the user behavior prediction performance is far from satisfactory, although, using two types of behavioral data at the same time can mitigate the sparsity problem. These two problems remains open: how to better model the correlation of user-user social and user-item consumption activities and how to mitigate the data sparsity issue. In this paper, we propose a random walk based distributed representation learning model to jointly predict these behaviors on SNSs. Specifically, we first construct a joint behavior graph that combines the two behaviors, with the edges denoting the sparse observed user behavior data. Then, we adopt a random walk to capture higher-order relationships between users and items. After that, we utilize a distributed learning approach to embed both users and items into a latent space. In this way, the behavior prediction tasks are transformed into similarity calculations in the latent space. Finally, extensive experimental results using two real-world datasets demonstrate the effectiveness of our proposed approach on the two behavior prediction tasks.},
  archive      = {J_ISCI},
  author       = {Junwei Li and Le Wu and Richang Hong and Jinkui Hou},
  doi          = {10.1016/j.ins.2020.10.045},
  journal      = {Information Sciences},
  pages        = {328-346},
  shortjournal = {Inf. Sci.},
  title        = {Random walk based distributed representation learning and prediction on social networking services},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Random expansion method for the generation of complex
cellular automata. <em>ISCI</em>, <em>549</em>, 310–327. (<a
href="https://doi.org/10.1016/j.ins.2020.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex behaviors in cellular automata have been widely developed in recent years to generate and analyze automata that produce space-moving patterns or gliders that interact in a periodic background. This type of automata has been frequently found either by conducting an exhaustive search or through a meticulous construction of the evolution rule. In this study, the specification of cellular automata with complex behaviors was obtained by utilizing randomly generated specimens. In particular, it was proposed that a cellular automaton of n states should be specified at random and then extended to another automaton with a higher number of states so that the original automaton operates as a periodic background where the additional states serve to define the gliders. Moreover, this study presents an explanation of this method. Furthermore, the random way of defining complex cellular automata was studied by using mean-field approximations for various states and local entropy measures. This specification was refined with a genetic algorithm to obtain specimens of a higher degree of complexity. By adopting this methodology, it was possible to generate complex automata with hundreds of states, demonstrating the fact that randomly defined local interactions with multiple states can construct complexity.},
  archive      = {J_ISCI},
  author       = {Juan Carlos Seck-Tuoh-Mora and Norberto Hernandez-Romero and Joselito Medina-Marin and Genaro J. Martinez and Irving Barragan-Vite},
  doi          = {10.1016/j.ins.2020.11.041},
  journal      = {Information Sciences},
  pages        = {310-327},
  shortjournal = {Inf. Sci.},
  title        = {Random expansion method for the generation of complex cellular automata},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast stepwise regression based on multidimensional indexes.
<em>ISCI</em>, <em>549</em>, 288–309. (<a
href="https://doi.org/10.1016/j.ins.2020.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an approach to efficiently construct stepwise regression models in a very high dimensional setting using a multidimensional index. The approach is based on an observation that the collections of available predictor variables often remain relatively stable and many models are built based on the same predictors. Example scenarios include data warehouses against which multiple ad hoc analytical models are built or collections of publicly available open data which remain relatively fixed and are used as a source of predictor variables for many models. We propose an approach where the user simply provides a target variable and the algorithm uses a pre-built multidimensional index to automatically select predictors from millions of available variables, yielding results identical to standard stepwise regression , but an order of magnitude faster. The algorithm has been tested on the large statistical database available from Eurostat, and has been demonstrated to produce interpretable and accurate models. We demonstrate experimentally that our approach produces results that are significantly better than other approaches to modeling with ultra-high dimensional data. Finally, we discuss potential pitfalls such as the presence of highly correlated variables, and show how they can be overcome.},
  archive      = {J_ISCI},
  author       = {Barbara Żogała-Siudem and Szymon Jaroszewicz},
  doi          = {10.1016/j.ins.2020.11.031},
  journal      = {Information Sciences},
  pages        = {288-309},
  shortjournal = {Inf. Sci.},
  title        = {Fast stepwise regression based on multidimensional indexes},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective evolutionary clustering for large-scale
dynamic community detection. <em>ISCI</em>, <em>549</em>, 269–287. (<a
href="https://doi.org/10.1016/j.ins.2020.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research of dynamic community detection is becoming increasingly popular since it can disclose how the community structures change over time in dynamic networks. Evolutionary clustering is often utilized for the goal and has achieved some success, however, still has some major drawbacks: (1) The absence of error correction may lead to the result-drifting problem and the error accumulation problem; (2) The NP-hardness of modularity based community detection makes it low efficiency to get an exact solution. In this paper, an efficient and effective multi-objective method, namely DYN-MODPSO, is proposed, and where the traditional evolutionary clustering framework and the particle swarm algorithm are modified and enhanced, respectively. The main contributions include that: (1) A novel strategy, namely the recent future reference, is devised for the initial clustering result correction to make the dynamic community detection more effective; (2) The traditional particle swarm algorithm is improved and integrated with the evolutionary clustering framework by profitably exploiting the proposed strategy; (3) The de-redundant random walk based population initialization is proposed to diversify the individuals in a quality-guaranteed way. Furthermore, the multi-individual crossover operator and the improved interference operator are carefully designed to keep the solution from local optimization . Extensive experiments conducted on the real and the synthetic dynamic networks manifest that the proposed DYN-MODPSO outperforms the competitors in terms of both effectiveness and efficiency.},
  archive      = {J_ISCI},
  author       = {Ying Yin and Yuhai Zhao and He Li and Xiangjun Dong},
  doi          = {10.1016/j.ins.2020.11.025},
  journal      = {Information Sciences},
  pages        = {269-287},
  shortjournal = {Inf. Sci.},
  title        = {Multi-objective evolutionary clustering for large-scale dynamic community detection},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A minimum adjustment consensus framework with compromise
limits for social network group decision making under incomplete
information. <em>ISCI</em>, <em>549</em>, 249–268. (<a
href="https://doi.org/10.1016/j.ins.2020.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In consensus-based social network group decision making (SN-GDM) problems, experts tend to refuse modifications if they exceed the limit of their maximum compromise, which may lead to a failed consensus. However, few consensus models have addressed the compromise limit behaviors in SN-GDM. In this paper, we propose a minimum adjustment consensus framework with compromise limits for SN-GDM under incomplete information. First, a two-stage transformation method is proposed to indirectly estimate the social influence based on the preference orderings of experts, and experts’ weights are obtained from the constructed social network using social network analysis techniques. Then, a nonlinear optimization model based on social influence is developed to complete incomplete preferences. After obtaining the experts’ weights and completed preferences, we present a novel feedback mechanism to facilitate the consensus-reaching. The feedback mechanism establishes a minimum adjustment model with compromise limits to generate recommendations for inconsistent experts. Finally, an illustrative example and a comparative study are conducted to show the validity and advantages of the proposed consensus framework.},
  archive      = {J_ISCI},
  author       = {Yuxiang Yuan and Dong Cheng and Zhili Zhou},
  doi          = {10.1016/j.ins.2020.11.014},
  journal      = {Information Sciences},
  pages        = {249-268},
  shortjournal = {Inf. Sci.},
  title        = {A minimum adjustment consensus framework with compromise limits for social network group decision making under incomplete information},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards efficient canonical polyadic decomposition on sunway
many-core processor. <em>ISCI</em>, <em>549</em>, 221–248. (<a
href="https://doi.org/10.1016/j.ins.2020.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Canonical Polyadic Decomposition (CPD) is one of the most popular tensor decomposition methods and plays an important role in big data analysis. For sparse tensor, the major computation procedure in CPD, which is known as matricized tensor times Khatri-Rao product (MTTKRP), exhibits discontinuous memory access and turns to be the performance bottleneck from achieving high performance on emerging processor architectures. In this paper, we propose swCPD , an efficient CPD implementation on the many-core Sunway processor. The swCPD accelerates the optimization algorithms dominating the performance of MTTKRP, including Alternating Least Squares (ALS), Gradient Descent (GD) and Randomized Block Sampling (RBS), as well as the latest fast Levenberg–Marquardt (fLM++) and Generalized Canonical Polyadic Decomposition with Stochastic Gradient Descent (GCP-SGD). The main idea adopted in swCPD is a hierarchical partitioning mechanism. From the computation perspective, the 64 Computation Processing Elements (CPEs) in a Sunway processor are divided into eight groups , with each group containing seven workers and one controller . From the data perspective, we partition the sparse tensor into different granularities, which are blocks , bands and tiles . Moreover, we develop a communication mechanism through register communication for cooperation between CPEs. We evaluate the implementation of swCPD with both synthesized and real-world datasets. The experiment results show that each optimized algorithm in swCPD achieves better performance than corresponding algorithms adopted in cutting-edge CPD implementations.},
  archive      = {J_ISCI},
  author       = {Ming Dun and Yunchun Li and Qingxiao Sun and Hailong Yang and Wei Li and Zhongzhi Luan and Lin Gan and Guangwen Yang and Depei Qian},
  doi          = {10.1016/j.ins.2020.11.013},
  journal      = {Information Sciences},
  pages        = {221-248},
  shortjournal = {Inf. Sci.},
  title        = {Towards efficient canonical polyadic decomposition on sunway many-core processor},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New framework for person-independent facial expression
recognition combining textural and shape analysis through new feature
extraction approach. <em>ISCI</em>, <em>549</em>, 200–220. (<a
href="https://doi.org/10.1016/j.ins.2020.10.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic facial expression recognition (FER) has been extensively studied owing to its wide range of applications, such as in e-learning platforms used to automatically collect the feedback of students regarding a particular content and to help children with autism have a better understanding of their environment. Owing to the advances made in the fields of machine learning and computational devices, researchers are developing more accurate and robust facial expression recognition frameworks. In this paper, we propose a completely new framework for person-independent FER based on combining textural and shape features from 49 detected landmarks in an input facial image . The shape information is extracted using the histogram of oriented gradients (HOG) applied on a binary patch generated by interpolating the locations of the 49 detected landmarks. The textural information is computed from 49 sub-images, each centered on one landmark, using a new handcrafted descriptor that we also propose herein and is referred to as Orthogonal and Parallel-based Directions Generic Quad Map Binary Patterns (OPD-GQMBP). OPD-GQMBP encodes the relevant information based on the orthogonality and parallelism of the geometries to select the prominent pixels within a n × n n×n neighborhood. The proposed framework outperforms many previous state-of-the-art methods including deep-learning-based approaches on five widely used benchmarks: CK+, KDEF, JAFFE, Oulu-Casia VIS, and RaFD, through the Leave-One-Subject-Out evaluation protocol. In addition, the superiority of the OPD-GQMBP descriptor is fairly proven against 10 deep features (e.g., VGG, ResNets, DenseNet, GoogeLeNet, and Inception) and 12 recent and powerful LBP variants.},
  archive      = {J_ISCI},
  author       = {M. Kas and Y. El merabet and Y. Ruichek and R. Messoussi},
  doi          = {10.1016/j.ins.2020.10.065},
  journal      = {Information Sciences},
  pages        = {200-220},
  shortjournal = {Inf. Sci.},
  title        = {New framework for person-independent facial expression recognition combining textural and shape analysis through new feature extraction approach},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decomposition-based co-evolutionary algorithm for
interactive multiple objective optimization. <em>ISCI</em>,
<em>549</em>, 178–199. (<a
href="https://doi.org/10.1016/j.ins.2020.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel co-evolutionary algorithm for interactive multiple objective optimization , named CIEMO/D. It aims at finding a region in the Pareto front that is highly relevant to the Decision Maker (DM). For this reason, CIEMO/D asks the DM, at regular intervals, to compare pairs of solutions from the current population and uses such preference information to bias the evolutionary search. Unlike the existing interactive evolutionary algorithms dealing with just a single population, CIEMO/D co-evolves a pool of subpopulations in a steady-state decomposition-based evolutionary framework. The evolution of each subpopulation is driven by the use of a different preference model. In this way, the algorithm explores various regions in the objective space, thus increasing the chances of finding DM’s most preferred solution. To improve the pace of the evolutionary search, CIEMO/D allows for the migration of solutions between different subpopulations. It also dynamically alters the subpopulations’ size based on compatibility between the incorporated preference models and the decision examples supplied by the DM. The extensive experimental evaluation reveals that CIEMO/D can successfully adjust to different DM’s decision policies. We also compare CIEMO/D with selected state-of-the-art interactive evolutionary hybrids that make use of the DM’s pairwise comparisons , demonstrating its high competitiveness.},
  archive      = {J_ISCI},
  author       = {Michał K. Tomczyk and Miłosz Kadziński},
  doi          = {10.1016/j.ins.2020.11.030},
  journal      = {Information Sciences},
  pages        = {178-199},
  shortjournal = {Inf. Sci.},
  title        = {Decomposition-based co-evolutionary algorithm for interactive multiple objective optimization},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FM-ECG: A fine-grained multi-label framework for ECG image
classification. <em>ISCI</em>, <em>549</em>, 164–177. (<a
href="https://doi.org/10.1016/j.ins.2020.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, increasingly more methods are proposed to automatically detect the abnormalities in Electrocardiography (ECG). Despite their success on public golden standard datasets, two challenges hinder the adoption of existing methods on real-world clinical ECG data in practice. To start with, most methods are designed based on digital signal data while most ECG data in the hospital are stored as images. Additionally, they ignore the correlation among different abnormal cardiac patterns and hence cannot detect multiple abnormalities at the same time. To practically address these challenges, we propose a Fine-grained Multi-label ECG ( FM-ECG ) framework to effectively detect the abnormalities from the real clinical ECG data in the following two aspects. Firstly, we propose to directly detect the abnormalities on the ECG images via a weakly supervised fine-grained classification mechanism, which can discover the potential discriminative parts and adaptively fuse them via image-level annotations only. Secondly, we take the ECG label dependencies into consideration by inferencing with a recurrent neural network (RNN). Experimental results on two real-world large-scale ECG datasets prove the capability of FM-ECG comparing with other state-of-the-art methods in ECG abnormally detection. Moreover, visualization analyses on attention parts show that meaningful spatial attention can be effectively learned by FM-ECG .},
  archive      = {J_ISCI},
  author       = {Nan Du and Qing Cao and Li Yu and Nathan Liu and Erheng Zhong and Zizhu Liu and Ying Shen and Kang Chen},
  doi          = {10.1016/j.ins.2020.10.014},
  journal      = {Information Sciences},
  pages        = {164-177},
  shortjournal = {Inf. Sci.},
  title        = {FM-ECG: A fine-grained multi-label framework for ECG image classification},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution with adaptive mutation strategy based
on fitness landscape analysis. <em>ISCI</em>, <em>549</em>, 142–163. (<a
href="https://doi.org/10.1016/j.ins.2020.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, many different differential evolution (DE) variants have been proposed to solve real-world optimization problems . However, the performance of them is largely determined by the selection of the mutation strategy, an approach to choose favorable mutation strategy when solving various optimization problems has attracted increasing attention recently. In this paper, we propose a DE with an adaptive mutation operator based on fitness landscape (FLDE). The application of fitness landscape to DE requires three stages. First, we analyzed the fitness landscape features of each benchmark training function, a total of 45 benchmark functions are taken from CEC2014 and 2015. Then, the relationship between three mutation strategies and fitness landscape features is trained by random forest (RF) offline. Finally, the trained RF is used to predict which mutation strategy should be utilized to perform mutation operator for each problem during the evolutionary process. Besides, a historical memory parameter adaption mechanism and population size linear reduction are applied to the FLDE. The CEC2017 benchmark set is utilized to perform the experiments, and five well-known DE variant algorithms are compared with the FLDE algorithm. The experimental results attest that the proposed FLDE algorithm is highly competitive with the other five DE algorithms .},
  archive      = {J_ISCI},
  author       = {Zhiping Tan and Kangshun Li and Yi Wang},
  doi          = {10.1016/j.ins.2020.11.023},
  journal      = {Information Sciences},
  pages        = {142-163},
  shortjournal = {Inf. Sci.},
  title        = {Differential evolution with adaptive mutation strategy based on fitness landscape analysis},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fitness-based adaptive differential evolution algorithm.
<em>ISCI</em>, <em>549</em>, 116–141. (<a
href="https://doi.org/10.1016/j.ins.2020.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of differential evolution (DE) mainly depends on its breeding offspring strategy (i.e., trial vector generation strategies and associated control parameters). To take full advantage of several effective breeding offspring strategies proposed in recent years, a fitness-based adaptive differential evolution algorithm (FADE) is proposed in this paper. In FADE, the entire population is split into multiple small-sized swarms, and three popular breeding strategies are saved in an archive which can be utilized by the multiple swarms. In each generation, different individuals in a same swarm adaptively select their own breeding strategy from the archive based on their fitness. With the adaptive breeding strategy, the individuals in a same swarm can exhibit distinct search behaviors . Moreover, the population size can be adaptively adjusted during the evolutionary process according to the performance of the best individual. Based on the adaptive population size, computational resources can be rationally assigned in different evolutionary stages, and then to satisfy diverse requirements of different fitness landscapes. The comprehensive performance of FADE is extensively evaluated by comparisons between it and other eight state-of-art DE variants based on CEC2013 and CEC2017 test suites as well as seven real applications. In addition, the effectiveness and efficiency of the newly introduced adaptive strategies are further confirmed by a set of experiments.},
  archive      = {J_ISCI},
  author       = {Xuewen Xia and Ling Gui and Yinglong Zhang and Xing Xu and Fei Yu and Hongrun Wu and Bo Wei and Guoliang He and Yuanxiang Li and Kangshun Li},
  doi          = {10.1016/j.ins.2020.11.015},
  journal      = {Information Sciences},
  pages        = {116-141},
  shortjournal = {Inf. Sci.},
  title        = {A fitness-based adaptive differential evolution algorithm},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Co-clustering algorithms for distributional data with
automated variable weighting. <em>ISCI</em>, <em>549</em>, 87–115. (<a
href="https://doi.org/10.1016/j.ins.2020.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the co-clustering of distribution-valued data, that is, the simultaneous partitioning of rows and columns of an input data table, the elements of which are distributions (or histograms) representing aggregate data. The first proposed method extends the double k-means algorithm to distributional data. The L 2 L2 Wasserstein distance, also known as Mallow’s distance, is used to compare distributions. To consider the different relevance of the variables characterizing the clusters, four variants of adaptive distributional double k-means are proposed. Accordingly, in the co-clustering procedure, an additional step is introduced to compute the relevance weights associated with the variables. In particular, each of the four algorithms provides i) a set of weights for the variables; ii) different sets of weights for the variables, one for each cluster (cluster-wise); iii) a double set of weights for the variables according to the decomposition of the L 2 L2 Wasserstein distance into two components; iv) different double sets of weights for the variables and distance components, one for each cluster (cluster-wise). Applications using simulated and real data demonstrate the effectiveness of the proposed algorithms and the contribution of the relevance weights to the co-clustering procedure according to the structure of the data.},
  archive      = {J_ISCI},
  author       = {Francisco de A.T. De Carvalho and Antonio Balzanella and Antonio Irpino and Rosanna Verde},
  doi          = {10.1016/j.ins.2020.11.018},
  journal      = {Information Sciences},
  pages        = {87-115},
  shortjournal = {Inf. Sci.},
  title        = {Co-clustering algorithms for distributional data with automated variable weighting},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Attribute reduction with fuzzy rough self-information
measures. <em>ISCI</em>, <em>549</em>, 68–86. (<a
href="https://doi.org/10.1016/j.ins.2020.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fuzzy rough set is one of the most effective methods for dealing with the fuzziness and uncertainty of data. However, in most cases this model only considers the information provided by the lower approximation of a decision when it is used to attribute reduction . In a realistic environment, the uncertainty of information is related to lower approximation as well as upper approximation. In this study, we construct four kinds of uncertainty measures by combining fuzzy rough approximations with the concept of self-information. These uncertainty measures can be employed to evaluate the classification ability of attribute subsets . The relationships between these measures are discussed in detail. It is proven that the fourth measure, called relative decision self-information, is better for attribute reduction than the other measures because it considers both the lower and upper approximations of a fuzzy decision. The proposed measures are generalizations of classical measures based on fuzzy rough sets. Finally, we have designed a greedy algorithm for attribute reduction. We validate the effectiveness of the proposed method by comparing the experimental results for efficiency and accuracy with those of three other algorithms using fundamental data.},
  archive      = {J_ISCI},
  author       = {Changzhong Wang and Yang Huang and Weiping Ding and Zehong Cao},
  doi          = {10.1016/j.ins.2020.11.021},
  journal      = {Information Sciences},
  pages        = {68-86},
  shortjournal = {Inf. Sci.},
  title        = {Attribute reduction with fuzzy rough self-information measures},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting anomalies in business process event logs using
statistical leverage. <em>ISCI</em>, <em>549</em>, 53–67. (<a
href="https://doi.org/10.1016/j.ins.2020.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The presence of anomalous information in a business process event log, such as missing, duplicated or swapped events, hampers the possibility of extracting useful insights from event log analysis. A number of approaches exist in the literature to detect anomalous cases in event logs based on different paradigms, such as probabilistic, distance-based or reconstruction-based anomaly detection . This paper proposes a novel method for anomaly detection in event logs based on the information-theoretic paradigm, which has not been considered before in event log anomaly detection. In particular, we propose an anomaly score for cases of a process based on statistical leverage and three different methods to set the anomaly detection threshold. The proposed approach does not require large data sets to train machine learning models, which are necessary for instance in reconstruction-based approaches. The proposed approach shows remarkable anomaly detection capability in experiments conducted using publicly available event logs in respect of existing methods in the literature. One of the proposed anomaly detection thresholds also shows to handle variable case anomaly ratios more effectively than other methods in the literature.},
  archive      = {J_ISCI},
  author       = {Jonghyeon Ko and Marco Comuzzi},
  doi          = {10.1016/j.ins.2020.11.017},
  journal      = {Information Sciences},
  pages        = {53-67},
  shortjournal = {Inf. Sci.},
  title        = {Detecting anomalies in business process event logs using statistical leverage},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Big-data-driven pre-stack seismic intelligent inversion.
<em>ISCI</em>, <em>549</em>, 34–52. (<a
href="https://doi.org/10.1016/j.ins.2020.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seismic inversion is an image formation process for the spatial structures and physical properties of underground rock strata according to the seismic data observed on the surface or in wells under the constraints of known geological laws and drilling and logging data. It is an important component of geophysical inversion. The inversion of reservoir parameters using seismic data is a non-linear problem. Therefore, the use of linear or quasi-linear methods to solve this problem makes it easy to fall into local optimal solutions . In contrast, intelligent optimisation algorithms based on the global optimum have strong local and global optimisation abilities and good convergence. Thus, they can improve the calculation efficiency and are suitable for geophysical inversion problems with multiple parameters and multiple extremums. In this study, the pre-stack seismic inversion problem is considered as the research object. According to the non-linear characteristics of the problem, the pre-stack seismic intelligent inversion method with a hybrid genetic algorithm is proposed, which solves the problems for which the standard genetic algorithm may easily fall into local optimums, resulting in an indistinct inversion effect, especially an unsatisfactory optimisation effect for density parameters. The experimental results show that the inversion parameters fit well with the theoretical model logging curve. In view of the high data volume in inversion, a new parallel strategy is proposed and combined with the MapReduce framework. This strategy can reduce the operating time while maintaining the diversity of the population. The strategy is implemented on the Hadoop platform and its effectiveness is verified.},
  archive      = {J_ISCI},
  author       = {Xuesong Yan and Mingzhao Zhang and Qinghua Wu},
  doi          = {10.1016/j.ins.2020.11.012},
  journal      = {Information Sciences},
  pages        = {34-52},
  shortjournal = {Inf. Sci.},
  title        = {Big-data-driven pre-stack seismic intelligent inversion},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reversible data hiding method for multi-histogram point
selection based on improved crisscross optimization algorithm.
<em>ISCI</em>, <em>549</em>, 13–33. (<a
href="https://doi.org/10.1016/j.ins.2020.10.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional prediction error expansion (PEE)-based reversible data hiding (RDH) schemes focus on generating a sharp prediction error histogram (PEH) in order to increase embedding performance, but they neglect the influence of local complexity on embedding performance. When the PEH is partitioned into multiple sub-histograms by means of the local complexity, the embedding performance can be increased by excluding the embedding of data in the sub-histograms located in the texture regions. However, multiple sub-histograms also cause a problem about how to identify the optimal embedding points that can achieve the best visual quality for a given payload. Violent iteration is often used in RDH schemes to traverse all possible values of the embedding points in order to identify the optimal points. Therefore, we conclude that violent iteration is a very time-consuming method and that it leads to unacceptable computational complexity . The traditional multiple sub-histogram methods usually reduce the solution space (i.e., all possible combinations of the embedding points) to decrease the computational complexity . However, the solution that is obtained from the aforementioned methods may significantly deviate from the global optimal solution . Instead of shrinking the solution space by abandoning most solutions, we improve the crisscross optimization algorithm in order to search for the optimal solution in the global solution space. In this paper, the K-means clustering algorithm is used to classify all prediction errors into multiple categories according to the local complexity. Each category would generate a PEH. Subsequently, the problem of selecting the embedding points of multiple sub-histograms is transformed into a typical and multi-choice knapsack problem . The improved crisscross optimization algorithm is used to determine the approximate optimal solution. The experimental results showed that our scheme provided effective performance.},
  archive      = {J_ISCI},
  author       = {Shaowei Weng and Wenlong Tan and Bo Ou and Jeng-Shyang Pan},
  doi          = {10.1016/j.ins.2020.10.063},
  journal      = {Information Sciences},
  pages        = {13-33},
  shortjournal = {Inf. Sci.},
  title        = {Reversible data hiding method for multi-histogram point selection based on improved crisscross optimization algorithm},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A negative transfer approach to person re-identification via
domain augmentation. <em>ISCI</em>, <em>549</em>, 1–12. (<a
href="https://doi.org/10.1016/j.ins.2020.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite recent remarkable progress, person re-identification (ReID) still suffers from a shortage of annotated training data. To deal with this problem, there has been a boost of interest in developing various data augmentation methods. In this paper, we are devoted to developing an end-to-end joint representation learning framework for the ReID task on the basis of a novel data augmentation strategy. Specifically, we regard the original training dataset as a source domain and generate the counterpart augmented domains through image channel shuffling. Accordingly, we design a symmetric classification network for ReID learning. By investigating the domain-level and identity-level relationship between domains, we use the idea of negative transfer and structural consistency to optimize the network for learning discriminative feature embeddings. Comprehensive experiments on some benchmark datasets demonstrate the effectiveness and robustness of our proposed approach. Source code is released at: https://github.com/flychen321/negative_transfer_reid .},
  archive      = {J_ISCI},
  author       = {Feng Chen and Nian Wang and Jun Tang and Dong Liang},
  doi          = {10.1016/j.ins.2020.11.004},
  journal      = {Information Sciences},
  pages        = {1-12},
  shortjournal = {Inf. Sci.},
  title        = {A negative transfer approach to person re-identification via domain augmentation},
  volume       = {549},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Why you should stop predicting customer churn and start
using uplift models. <em>ISCI</em>, <em>548</em>, 497–515. (<a
href="https://doi.org/10.1016/j.ins.2019.12.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uplift modeling has received increasing interest in both the business analytics research community and the industry as an improved paradigm for predictive analytics for data-driven operational decision-making. The literature, however, does not provide conclusive empirical evidence that uplift modeling outperforms predictive modeling . Case studies that directly compare both approaches are lacking, and the performance of predictive models and uplift models as reported in various experimental studies cannot be compared indirectly since different evaluation measures are used to assess their performance. Therefore, in this paper, we introduce a novel evaluation metric called the maximum profit uplift (MPU) measure that allows assessing the performance in terms of the maximum potential profit that can be achieved by adopting an uplift model. This measure, developed for evaluating customer churn uplift models, extends the maximum profit measure for evaluating customer churn prediction models. While introducing the MPU measure, we describe the generally applicable liftup curve and liftup measure for evaluating uplift models as counterparts of the lift curve and lift measure that are broadly used to evaluate predictive models. These measures are subsequently applied to assess and compare the performance of customer churn prediction and uplift models in a case study that applies uplift modeling to customer retention in the financial industry. We observe that uplift models outperform predictive models and lead to improved profitability of retention campaigns.},
  archive      = {J_ISCI},
  author       = {Floris Devriendt and Jeroen Berrevoets and Wouter Verbeke},
  doi          = {10.1016/j.ins.2019.12.075},
  journal      = {Information Sciences},
  pages        = {497-515},
  shortjournal = {Inf. Sci.},
  title        = {Why you should stop predicting customer churn and start using uplift models},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Objective function-based rough membership c-means
clustering. <em>ISCI</em>, <em>548</em>, 479–496. (<a
href="https://doi.org/10.1016/j.ins.2020.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hard C-means (HCM) is one of the most widely used partitive clustering methods and was extended to rough C-means (RCM) by referencing to the perspective of rough set theory to deal with the certain, possible, and uncertain belonging of object to clusters. Furthermore, rough set C-means (RSCM) and rough membership C-means (RMCM) have been proposed as clustering models on an approximation space considering the granularity of the universe (object space) based on binary relations . Although these rough set-based C-means methods are practical, they are not formulated based on objective functions, but are built on heuristic schemes. Objective function-based methods can be a basis for discussion of the validity of clustering and further theoretical developments. In this paper, we propose a novel RMCM framework, which is called RMCM version 2 (RMCM2), based on an objective function. The objective function is designed to derive the same updating rule for cluster centers as in RMCM. We demonstrate the characteristics of RMCM2 by visualizing cluster boundaries on a grid point dataset. Furthermore, we verify the clustering performance of RMCM2 through numerical experiments by using real-world datasets.},
  archive      = {J_ISCI},
  author       = {Seiki Ubukata and Akira Notsu and Katsuhiro Honda},
  doi          = {10.1016/j.ins.2020.10.037},
  journal      = {Information Sciences},
  pages        = {479-496},
  shortjournal = {Inf. Sci.},
  title        = {Objective function-based rough membership C-means clustering},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pattern classification with evolving long-term cognitive
networks. <em>ISCI</em>, <em>548</em>, 461–478. (<a
href="https://doi.org/10.1016/j.ins.2020.08.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an interpretable neural system—termed Evolving Long-term Cognitive Network—for pattern classification. The proposed model was inspired by Fuzzy Cognitive Maps , which are interpretable recurrent neural networks for modeling and simulation . The network architecture is comprised of two neural blocks: a recurrent input layer and an output layer. The input layer is a Long-term Cognitive Network that gets unfolded in the same way as other recurrent neural networks, thus producing a sort of abstract hidden layers. In our model, we can attach meaningful linguistic labels to each neuron since the input neurons correspond to features in a given classification problem and the output neurons correspond to class labels. Moreover, we propose a variant of the backpropagation learning algorithm to compute the required parameters. This algorithm includes two new regularization components that are aimed at obtaining more interpretable knowledge representations. The numerical simulations using 58 datasets show that our model achieves higher prediction rates when compared with traditional white boxes while remaining competitive with the black boxes. Finally, we elaborate on the interpretability of our neural system using a proof of concept .},
  archive      = {J_ISCI},
  author       = {Gonzalo Nápoles and Agnieszka Jastrzębska and Yamisleydi Salgueiro},
  doi          = {10.1016/j.ins.2020.08.058},
  journal      = {Information Sciences},
  pages        = {461-478},
  shortjournal = {Inf. Sci.},
  title        = {Pattern classification with evolving long-term cognitive networks},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transfer learning based countermeasure against label
flipping poisoning attack. <em>ISCI</em>, <em>548</em>, 450–460. (<a
href="https://doi.org/10.1016/j.ins.2020.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies indicate that a classifier is vulnerable in an adversarial environment. The label flipping attack aims to mislead the training process. Some countermeasures have been proposed, but are usually designed for a particular classifier only, or may cause information loss. This study aims to investigate a generic model which fully utilizes the contaminated samples in learning. We assume a small untainted dataset is obtained from an application in addition to a contaminated dataset. The adversarial learning problem is formulated as transfer learning in which the influence of contaminated samples is reduced by only extracting the information similar to the untainted samples from the contaminated set using transfer learning . Our study considers a popular method, TrAdaBoost, and indicates that its performance is closely related to the initialized weights of samples. A initialization method is devised specifically for an adversarial setting to avoid assigning a large weight to the contaminated samples. The experimental results confirm that TrAdaBoost extracts only the benign knowledge from the contaminated set successfully. Moreover, our proposed initialization method significantly enhances the robustness of the model. This study presents a promising direction using transfer learning to defend against poisoning attacks.},
  archive      = {J_ISCI},
  author       = {Patrick P.K. Chan and Fengzhi Luo and Zitong Chen and Ying Shu and Daniel S. Yeung},
  doi          = {10.1016/j.ins.2020.10.016},
  journal      = {Information Sciences},
  pages        = {450-460},
  shortjournal = {Inf. Sci.},
  title        = {Transfer learning based countermeasure against label flipping poisoning attack},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantum resistant key-exposure free chameleon hash and
applications in redactable blockchain. <em>ISCI</em>, <em>548</em>,
438–449. (<a href="https://doi.org/10.1016/j.ins.2020.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technologies have attracted a large amount of attention recently, with immutability as a basic property. However, it is often desired to allow editing a transaction or a block in a controlled way. Chameleon hash function , with enhanced collision-resistance property, has recently found to be an important tool to construct redactable blockchain. This means that the traditional key-exposure free (double-trapdoor) constructions are unsuitable for the applications here. Although single-trapdoor key-exposure free chameleon hash functions naturally satisfy enhanced collision-resistance, they are very rare, and none is based on quantum-resistant assumptions. In this paper, we propose two single-trapdoor key-exposure free chameleon hash functions based on lattice , without/with lattice trapdoors respectively, and show their applications in redactable blockchain. Our constructions do not need heavy cryptographic tools, such as encryption and NIZK, therefore are more compact and computational efficient than schemes following Ateniese et al.’s generic transformation framework of PKE+NIZK. Moreover, we introduce two mechanisms in order to prevent the misuse of redaction functionality in blockchain. We present a fully distributed key management mechanism for the first scheme, and solve the redaction-misuse problem which remains in blockchains using Ateniese et al.’s generic framework. We also suggest the voting strategy when applying our second scheme. Finally, we show how to efficiently integrate our chameleon hash with any blockchain technologies, with only minor changes to the current blockchains in use. For extend interests, our proposed chameleon hash functions are also suitable for constructing quantum-resistant chameleon signatures and off-line/on-line signatures.},
  archive      = {J_ISCI},
  author       = {Chunhui Wu and Lishan Ke and Yusong Du},
  doi          = {10.1016/j.ins.2020.10.008},
  journal      = {Information Sciences},
  pages        = {438-449},
  shortjournal = {Inf. Sci.},
  title        = {Quantum resistant key-exposure free chameleon hash and applications in redactable blockchain},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PPCL: Privacy-preserving collaborative learning for
mitigating indirect information leakage. <em>ISCI</em>, <em>548</em>,
423–437. (<a href="https://doi.org/10.1016/j.ins.2020.09.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Collaborative learning and related techniques such as federated learning, allow multiple clients to train a model jointly while keeping their datasets at local. Secure Aggregation in most existing works focus on protecting model gradients from the server. However, an dishonest user could still easily get the privacy information from the other users. It remains a challenge to propose an effective solution to prevent information leakage against dishonest users. To tackle this challenge, we propose a novel and effective privacy-preserving collaborative machine learning scheme, targeting at preventing information leakage agains adversaries. Specifically, we first propose a privacy-preserving network transformation method by utilizing Random-Permutation in Software Guard Extensions(SGX), which protects the model parameters from being inferred by a curious server and dishonest clients. Then, we apply Partial-Random Uploading mechanism to mitigate the information inference through visualizations. To further enhance the efficiency, we introduce network pruning operation and employ it to accelerate the convergence of training. We present the formal security analysis to demonstrate that our proposed scheme can preserve privacy while ensuring the convergence and accuracy of secure aggregation. We conduct experiments to show the performance of our solution in terms of accuracy and efficiency. The experimental results show that the proposed scheme is practical.},
  archive      = {J_ISCI},
  author       = {Hongyang Yan and Li Hu and Xiaoyu Xiang and Zheli Liu and Xu Yuan},
  doi          = {10.1016/j.ins.2020.09.064},
  journal      = {Information Sciences},
  pages        = {423-437},
  shortjournal = {Inf. Sci.},
  title        = {PPCL: Privacy-preserving collaborative learning for mitigating indirect information leakage},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid interval type-2 semi-supervised possibilistic fuzzy
c-means clustering and particle swarm optimization for satellite image
analysis. <em>ISCI</em>, <em>548</em>, 398–422. (<a
href="https://doi.org/10.1016/j.ins.2020.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although satellite images can provide more information about the earth’s surface in a relatively short time and over a large scale, they are affected by observation conditions and the accuracy of the image acquisition equipment. The objects on the images are often not clear and uncertain, especially at their borders. The type-1 fuzzy set based fuzzy clustering technique allows each data pattern to belong to many different clusters through membership function (MF) values, which can handle data patterns with unclear and uncertain boundaries well. However, this technique is quite sensitive to noise, outliers, and limitations in handling uncertainties. To overcome these disadvantages, we propose a hybrid method encompassing interval type-2 semi-supervised possibilistic fuzzy c-means clustering (IT2SPFCM) and Particle Swarm Optimization (PSO) to form the proposed IT2SPFCM-PSO. We experimented on some satellite images to prove the effectiveness of the proposed method. Experimental results show that the IT2SPFCM-PSO algorithm gives accuracy from 98.8\% to 99.39\% and is higher than that of other matching algorithms including SFCM, SMKFCM, SIIT2FCM, PFCM, SPFCM-W, SPFCM-SS, and IT2SPFCM. Analysis of the results by indicators PC-I, CE-I, D-I, XB-I, t -I, and MSE also showed that the proposed method gives better results in most experiments.},
  archive      = {J_ISCI},
  author       = {Dinh Sinh Mai and Long Thanh Ngo and Le Hung Trinh and Hani Hagras},
  doi          = {10.1016/j.ins.2020.10.003},
  journal      = {Information Sciences},
  pages        = {398-422},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid interval type-2 semi-supervised possibilistic fuzzy c-means clustering and particle swarm optimization for satellite image analysis},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel multi-scale fusion framework for detail-preserving
low-light image enhancement. <em>ISCI</em>, <em>548</em>, 378–397. (<a
href="https://doi.org/10.1016/j.ins.2020.09.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel multi-scale fusion framework for low-illumination image enhancement, which effectively enhances images taken under various low-light conditions. Based on the high dynamic range imaging technique, we first employ a novel remapping function to generate a sequence of artificial multi-exposure images. The generated sequence of images ensures that the contrast of each intensity interval of the input image is enhanced at least once. Then three fusion-relevant features, namely, exposure, global contrast and local contrast, are selected as the weight maps. Combined with the weight maps, a pyramid fusion scheme is introduced to do a layer-by-layer integration of the different frequency bands of the image layer by layer. In addition, a strategy for extracting details from the original image is designed, which effectively maintains the detail information without causing colour distortions. The framework is very efficient and suitable for mobile devices because most of the calculations are at the pixel-level. Extensive experiments have shown that the proposed approach yields comparable and better performances in comparisons with the state-of-the-art competing techniques in both qualitative and quantitative evaluations .},
  archive      = {J_ISCI},
  author       = {Yadong Xu and Cheng Yang and Beibei Sun and Xiaoan Yan and Minglong Chen},
  doi          = {10.1016/j.ins.2020.09.066},
  journal      = {Information Sciences},
  pages        = {378-397},
  shortjournal = {Inf. Sci.},
  title        = {A novel multi-scale fusion framework for detail-preserving low-light image enhancement},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Selecting green third party logistics providers for a
loss-averse fourth party logistics provider in a multiattribute reverse
auction. <em>ISCI</em>, <em>548</em>, 357–377. (<a
href="https://doi.org/10.1016/j.ins.2020.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing winner determination models tend to overlook the sustainable attributes of third party logistics (3PL) providers. This paper investigates a novel green winner determination problem that has several features, including (i) the sustainable attributes with conflicting and interactive properties of potential 3PLs, and (ii) the loss-averse behavior with an internal reference point of a fourth party logistics (4PL) provider. For the attributes with a combination of crisp data, interval numbers and intuitionistic 2-tuple linguistic terms, we integrate the prospect theory (PT) and Choquet integral with the “benefits, opportunities, costs and risks (BOCR)” framework to propose a novel PTC-BOCR solution method. Numerical experiments are conducted to illustrate the effectiveness and applicability of PTC-BOCR by comparing it with some known methods. Comparison analysis indicates that PTC-BOCR is robust with respect to the variance of 3PLs’ attribute values, while behavioral parameter analysis reveals that the loss-averse behavior of the 4PL is intensified as the difference of 3PLs varies. Managerial insights are also drawn for green 3PLs to win the auction. This study is a significant extension of traditional decision-making methods, which could benefit the realization of a sustainable logistics system in a cost-effective way for 4PLs.},
  archive      = {J_ISCI},
  author       = {Xiaohu Qian and Shu-Cherng Fang and Mingqiang Yin and Min Huang and Xin Li},
  doi          = {10.1016/j.ins.2020.09.011},
  journal      = {Information Sciences},
  pages        = {357-377},
  shortjournal = {Inf. Sci.},
  title        = {Selecting green third party logistics providers for a loss-averse fourth party logistics provider in a multiattribute reverse auction},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A periodic iterative learning scheme for finite-iteration
tracking of discrete networks based on FlexRay communication protocol.
<em>ISCI</em>, <em>548</em>, 344–356. (<a
href="https://doi.org/10.1016/j.ins.2020.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the finite-iteration tracking of discrete networks is analyzed by designing a new kind of periodic iterative learning control (ILC) strategy. In the proposed ILC scheme, the FlexRay communication protocol with both static and dynamic segments is introduced in the design. The design has the advantage to reduce the communication channel bandwidth load and hence improve the performance of finite-iteration tracking. This paper provides the first integrating approach to iterative learning design based on the dynamic capability of FlexRay communication channels, and can be generalized to other learning process in network control design. Simulation results are shown to clarify the effectiveness of the obtained criteria, and demonstrate that the proposed periodic ILC scheme performs better than the traditional ILC schemes.},
  archive      = {J_ISCI},
  author       = {Wenjun Xiong and Daniel W.C. Ho and Shifan Wen},
  doi          = {10.1016/j.ins.2020.10.017},
  journal      = {Information Sciences},
  pages        = {344-356},
  shortjournal = {Inf. Sci.},
  title        = {A periodic iterative learning scheme for finite-iteration tracking of discrete networks based on FlexRay communication protocol},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Exploiting the potentialities of features for speech
emotion recognition. <em>ISCI</em>, <em>548</em>, 328–343. (<a
href="https://doi.org/10.1016/j.ins.2020.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, studies on speech signals have increasingly paid attention to emotional information. The most challenging aspect in speech emotion recognition (SER) is choosing the optimal speech feature representation. According to the statistical analysis, the roles of each speech feature differ under different emotions, indicating that different features have different abilities in distinguishing emotions. This study proposes an emotional-category based feature weighting (ECFW) method, which aims at finding the prominence of each feature under different emotions and applying this prominence as priori knowledge . Furthermore, previous studies have paid little attention to matching the relationship between speech features and models. This study argues that different combinations of models and features result in large differences in the performance of SER, which are evaluated by several experiments. Features must be modeled with appropriate approaches to extract the most valuable information for emotional representation. Then, the best combinations of features and models are selected to test our method. The method is applied on three commonly used speech emotion databases, IEMOCAP, MASC, and EMO-DB. The results show that ECFW significantly improves the performance of SER tasks.},
  archive      = {J_ISCI},
  author       = {Dongdong Li and Yijun Zhou and Zhe Wang and Daqi Gao},
  doi          = {10.1016/j.ins.2020.09.047},
  journal      = {Information Sciences},
  pages        = {328-343},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting the potentialities of features for speech emotion recognition},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detectability vverification of probabilistic boolean
networks. <em>ISCI</em>, <em>548</em>, 313–327. (<a
href="https://doi.org/10.1016/j.ins.2020.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We in this paper study the current-state estimation problem of probabilistic Boolean networks with output observations. First, we propose the concepts of three fundamental categories of detectability in the context of PBNs based on the different purposes, which are periodic detectability , (periodic) k -detectability, and (periodic) d -detectability. Second, utilizing the semi-tensor product technique, we create a uniform methodology for the verification of all the aforementioned categories of detectability. Accordingly, several necessary and sufficient verification criteria are derived. All results obtained in this paper are numerically tractable since they avoid the graph-based symbolic manipulations. Finally, several examples modeled by the same PBN are provided to instantiate the correctness and effeteness of the obtained results.},
  archive      = {J_ISCI},
  author       = {Xiao-Guang Han and Wen-Dong Yang and Xiao-Yan Chen and Zhi-Wu Li and Zeng-Qiang Chen},
  doi          = {10.1016/j.ins.2020.10.019},
  journal      = {Information Sciences},
  pages        = {313-327},
  shortjournal = {Inf. Sci.},
  title        = {Detectability vverification of probabilistic boolean networks},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fusion of heterogeneous attention mechanisms in multi-view
convolutional neural network for text classification. <em>ISCI</em>,
<em>548</em>, 295–312. (<a
href="https://doi.org/10.1016/j.ins.2020.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid proliferation of user generated content has given rise to large volumes of text corpora. Increasingly, scholars, researchers, and organizations employ text classification to mine novel insights for high-impact applications. Despite their prevalence, conventional text classification methods rely on labor-intensive feature engineering efforts that are task specific, omit long-term relationships, and are not suitable for the rapidly evolving domains. While an increasing body of deep learning and attention mechanism literature aim to address these issues, extant methods often represent text as a single view and omit multiple sets of features at varying levels of granularity . Recognizing that these issues often result in performance degradations , we propose a novel Spatial View Attention Convolutional Neural Network (SVA-CNN). SVA-CNN leverages an innovative and carefully designed set of multi-view representation learning , a combination of heterogeneous attention mechanisms and CNN-based operations to automatically extract and weight multiple granularities and fine-grained representations. Rigorously evaluating SVA-CNN against prevailing text classification methods on five large-scale benchmark datasets indicates its ability to outperform extant deep learning-based classification methods in both performance and training time for document classification , sentiment analysis , and thematic identification applications. To facilitate model reproducibility and extensions, SVA-CNN’s source code is also available via GitHub.},
  archive      = {J_ISCI},
  author       = {Yunji Liang and Huihui Li and Bin Guo and Zhiwen Yu and Xiaolong Zheng and Sagar Samtani and Daniel D. Zeng},
  doi          = {10.1016/j.ins.2020.10.021},
  journal      = {Information Sciences},
  pages        = {295-312},
  shortjournal = {Inf. Sci.},
  title        = {Fusion of heterogeneous attention mechanisms in multi-view convolutional neural network for text classification},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information synergy entropy based multi-feature information
fusion for the operating condition identification in aluminium
electrolysis. <em>ISCI</em>, <em>548</em>, 275–294. (<a
href="https://doi.org/10.1016/j.ins.2020.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the multi-feature fusion via information synergy entropy (ISE) based interval intuitionistic fuzzy (IIF) technique for order preference by similarity to ideal solution , the paper propose a method to identify the operating condition identification in a complex environment. In this method, the evaluation information contained in the decision matrices is characterized by an IIF number, and the related attribute weights are incompletely known. First, the ISE concept is proposed to calculate the weight of each attribute value which is used to construct a weighted collective decision matrix. Both intuitionistic and fuzzy information are incorporated into the matrix to describe the uncertainty in the IIF sets to improve the decision accuracy. Next, an improved Euclidean distance is used to calculate the degree of relative closeness so as to rank the decision alternatives, which can overcome the drawback of division by zero. Then the superheat identification is used as a case study to illustrate optimal operating condition determination of aluminium electrolysis cell. Experimental results have demonstrated the validity and applicability of the proposed operating condition determination algorithm.},
  archive      = {J_ISCI},
  author       = {Zuguo Chen and Ming Lu and Yimin Zhou and Chaoyang Chen},
  doi          = {10.1016/j.ins.2020.07.031},
  journal      = {Information Sciences},
  pages        = {275-294},
  shortjournal = {Inf. Sci.},
  title        = {Information synergy entropy based multi-feature information fusion for the operating condition identification in aluminium electrolysis},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finding influential communities in networks with multiple
influence types. <em>ISCI</em>, <em>548</em>, 254–274. (<a
href="https://doi.org/10.1016/j.ins.2020.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies on the influential community model have discovered communities that contain highly influential members. There are many types of metrics that describe the influences of objects in networks. Existing methods, however, search for influential communities based on only one influence type without comprehensively considering other influence types. In this paper, we propose an efficient influential community search method that finds the top- γ γ most influential communities across multiple influence criteria. The influences are modeled as multi-dimensional vectors, where each dimension represents an influence type. To rank communities properly, we utilize the top- γ γ dominating query concept for multi-dimensional point data. Extensive experiments demonstrate that the proposed method effectively finds influential communities based on multiple influence types and is orders of magnitude faster than a baseline solution.},
  archive      = {J_ISCI},
  author       = {Jung Hyuk Seo and Myoung Ho Kim},
  doi          = {10.1016/j.ins.2020.10.011},
  journal      = {Information Sciences},
  pages        = {254-274},
  shortjournal = {Inf. Sci.},
  title        = {Finding influential communities in networks with multiple influence types},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Membership-function-dependent stability analysis and local
controller design for t–s fuzzy systems: A space-enveloping approach.
<em>ISCI</em>, <em>548</em>, 233–253. (<a
href="https://doi.org/10.1016/j.ins.2020.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For Takagi–Sugeno (T–S) fuzzy systems, relaxed stability conditions are obtained by more effectively enveloping the trajectory of the membership functions (MFs) in a unified space of MF. Considering an open-loop T–S fuzzy system, the system premise variables operation domain can be divided into a series of subdomains . Based on an MF unified space extremum calculation technique, the MFs extremum values in each premise variable corresponding to the unified space subdomain are calculated. With these extremes, a tight local convex polyhedron enveloping the MF trajectory is constructed in each subdomain. Thus, linear matrix inequality (LMI) stability conditions are derived via a piecewise Lyapunov function . Then, a state-feedback local controller is designed to close the system loop . From a geometric viewpoint, MF extremum enveloping and piecewise linear-approximation methods are both utilized to achieve relaxed stability and robustness conditions. Finally, several examples are adopted to illustrate the metrics of the proposed approaches.},
  archive      = {J_ISCI},
  author       = {Hua Zheng and Wen-Bo Xie and Hak-Keung Lam and Likui Wang},
  doi          = {10.1016/j.ins.2020.09.043},
  journal      = {Information Sciences},
  pages        = {233-253},
  shortjournal = {Inf. Sci.},
  title        = {Membership-function-dependent stability analysis and local controller design for T–S fuzzy systems: A space-enveloping approach},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Privacy-preserving and verifiable online crowdsourcing with
worker updates. <em>ISCI</em>, <em>548</em>, 212–232. (<a
href="https://doi.org/10.1016/j.ins.2020.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a novel problem-solving paradigm, crowdsourcing has been emerged aiming at performing truthful data aggregation and addressing problems that are hard for one organization. However, in reality, these answers submitted by distributed workers can be regarded as their intellectual properties because of professional skills and intensive computation overhead. Besides, it may contain highly sensitive information and should not be directly released without protection. Besides, the worker skill estimation is only considered into plaintext scenario but no longer suitable to ciphertext setting. To address these challenges, we propose a novel privacy-preserving and verifiable online crowdsourcing protocol (PVOC) for workers in the same group while preserving their answers privacy. Besides, PVOC also supports worker dynamic adding and revocation for different classification tasks with a minimum computation overhead. Finally, we introduce a verification mechanism to identify and update the worker skills of participants. Thus, since no decryption operations are involved in PVOC, our design is efficient and lightweight. Security analysis demonstrates that PVOC can guarantee the workers’ privacy without accuracy loss. Furthermore, we evaluate and show its effectiveness and practicability on three real datasets MNIST, CIFAR-10 and CIFAR-100.},
  archive      = {J_ISCI},
  author       = {Xiaoyu Zhang and Xiaofeng Chen and Hongyang Yan and Yang Xiang},
  doi          = {10.1016/j.ins.2020.10.010},
  journal      = {Information Sciences},
  pages        = {212-232},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving and verifiable online crowdsourcing with worker updates},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LPQ++: A discriminative blur-insensitive textural descriptor
with spatial-channel interaction. <em>ISCI</em>, <em>548</em>, 191–211.
(<a href="https://doi.org/10.1016/j.ins.2020.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective texture categorization plays an important role in effective visual recognition. Despite noticeable progress in this area, blurred-texture recognition remains a challenge. As a key reason for this, existing well-established visual descriptors (e.g., local binary patterns and deep convolutional feature) generally cannot ensure an insensitivity to blur, exhibiting a considerable decrease in performance under clear to blurring conditions. To alleviate this, we propose a discriminative blur-insensitive textural descriptor, referred to as local phase quantization plus plus (LPQ++). The main idea is to establish spatial-channel interactions between the normalized blur-insensitive feature maps yielded by a short-term Fourier transform (STFT) to enhance the descriptive power while maintaining the insensitivity to blur. In particular, spatial interactions executed within the specific STFT feature map capture the spatial correlations between neighboring points. Meanwhile, the column-wise channel interactions among the STFT feature maps help differentiate the edge and flat areas in the images; this is crucial for effective texture characterization under blurring conditions. To enable blurred texture description under dense sampling conditions, LPQ++ is extracted by calculating the spatial-channel gradient orientation histogram and embedding it into the Fisher vector . Experiments conducted on three difficult texture datasets demonstrate the effectiveness of LPQ++ for blurred-texture categorization. Our code is open-source and available at https://github.com/hustzhzhu/LPQplusplus.},
  archive      = {J_ISCI},
  author       = {Zihao Zhu and Yang Xiao and Shuai Li and Zhiguo Cao and Zhiwen Fang and Joey Tianyi Zhou},
  doi          = {10.1016/j.ins.2020.10.006},
  journal      = {Information Sciences},
  pages        = {191-211},
  shortjournal = {Inf. Sci.},
  title        = {LPQ++: A discriminative blur-insensitive textural descriptor with spatial-channel interaction},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved i-nice clustering algorithm based on density peaks
mechanism. <em>ISCI</em>, <em>548</em>, 177–190. (<a
href="https://doi.org/10.1016/j.ins.2020.09.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Masud et al. [M. A. Masud, J. Z. Huang, C. H. Wei, et al. I-nice: A new approach for identifying the number of clusters and initial cluster centres. Information Sciences 466 (2018) 129–151] proposed a parameter-free clustering algorithm , named I-nice, which can identify the number of clusters and initial cluster centres using observation points. Although the experiment presented good clustering performance of I-nice, there are two inherent limitations that can be further improved. One is that I-niceSO is sensitive to the position of the observation point, and the other is that the number of nearest neighbours affects the determination of high-density areas in I-niceMO. Inspired by density peaks clustering, we propose a density-peaks-based I-nice (I-niceDP) clustering algorithm to improve the existing I-nice clustering algorithm. In I-niceDP, we use density peaks to determine the number of clusters and cluster centres in the components of the gamma mixture model rather than the k -nearest neighbours method. The comparative results using I-niceSO and I-niceMO indicate that I-niceDP can more accurately identify the number of clusters and initial cluster centres for datasets with large cluster numbers. Furthermore, I-niceDP obtains higher normalised mutual information values in comparison with seven other clustering algorithms. The experimental results demonstrate the feasibility and effectiveness of the I-niceDP clustering algorithm.},
  archive      = {J_ISCI},
  author       = {Yulin He and Yingyan Wu and Honglian Qin and Joshua Zhexue Huang and Yi Jin},
  doi          = {10.1016/j.ins.2020.09.068},
  journal      = {Information Sciences},
  pages        = {177-190},
  shortjournal = {Inf. Sci.},
  title        = {Improved I-nice clustering algorithm based on density peaks mechanism},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobility and marginal gain based content caching and
placement for cooperative edge-cloud computing. <em>ISCI</em>,
<em>548</em>, 153–176. (<a
href="https://doi.org/10.1016/j.ins.2020.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing demand of users for video streaming services has brought huge challenges to the streaming media service system. The cooperative edge-cloud computing architecture that combines cloud computing and edge computing can effectively reduce the burden on streaming media service systems. The streaming content caching under the cooperative edge-cloud computing architecture is important to improve the quality of user service. Based on this, this paper proposed a cache strategy based on user mobility and content popularity. In this cache strategy, the Markov model is used to describe the user mobility, the multiple linear regression model is used for content popularity prediction, and the content caching operation is performed according to the user mobility and the content popularity. To reduce the load of edge servers and further improve the quality of user service, this paper proposed a content placement strategy based on marginal gain. In this content placement strategy, a content placement problem is established by considering the content access latency and the content placement cost. Then a content placement algorithm based on marginal gain is proposed to solve the content placement problem. The content placement operation is performed by analyzing the marginal gain brought by placing the contents on edge servers to achieve the optimal performance of content placement. The experimental results show that the proposed strategies can effectively improve the performance in terms of the cache hit ratio, the content access latency, the storage cost and the remote data access cost.},
  archive      = {J_ISCI},
  author       = {Chunlin Li and Mingyang Song and Chongchong Yu and Youlong Luo},
  doi          = {10.1016/j.ins.2020.09.016},
  journal      = {Information Sciences},
  pages        = {153-176},
  shortjournal = {Inf. Sci.},
  title        = {Mobility and marginal gain based content caching and placement for cooperative edge-cloud computing},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive XACML access policies for heterogeneous distributed
IoT environments. <em>ISCI</em>, <em>548</em>, 135–152. (<a
href="https://doi.org/10.1016/j.ins.2020.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the access control issue for the comprehensive and distributed Internet of Things (IoT) environments. The typical eXtensible Access Control Markup Language (XACML) which implements the sophisticated access conditions in XML files, is widely used to guarantee access control decisions for the distributed IoT environments. To the best of our knowledge, the typical XACML-based access control schemes never consider the authentication run-time parameters. Moreover, the access control schemes that are mainly based on the typical XACML cannot secure themselves against some kinds of attacks, such as the Masquerade attack. Also, those schemes are not secure in opposition to Man-in-the-Middle (MITM) attack. Therefore, this paper proposes an adaptive XACML scheme that extends the typical XACML by integrating an access code generation and verification schemes for heterogeneous distributed IoT environments. Our adaptive XACML scheme considers some sensitive authentication run-time parameters before authorizing the user. Moreover, our scheme is proven secure against the Masquerade attack and MITM attack through hashing the generated access code using Message Digest Algorithm-5 (MD5) and Secure Hash Algorithm-1 (SHA-1) Checksum Utility . The experimental analysis of many different configurations supports the efficacy and efficiency of our adaptive XACML. It also shows exceptional compatibility and performance with different implementations. The processing time comparison between our adaptive XACML and Typical XACML, has shown that there is a low time overhead when using our adaptive XACML. This processing time overhead is nothing compared to the extra features that have been achieved in excess of the typical XACML and the security against Masquerade and MITM attacks. Therefore, our adaptive XACML scheme has the capability to be applied in various distinct distributed environments not only IoT.},
  archive      = {J_ISCI},
  author       = {Khaled Riad and Jieren Cheng},
  doi          = {10.1016/j.ins.2020.09.051},
  journal      = {Information Sciences},
  pages        = {135-152},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive XACML access policies for heterogeneous distributed IoT environments},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EGC: Entropy-based gradient compression for distributed deep
learning. <em>ISCI</em>, <em>548</em>, 118–134. (<a
href="https://doi.org/10.1016/j.ins.2020.05.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increase of volume of training data and scale of network models, distributed deep learning is becoming more and more popular, which employs multiple workers to train a single model. However, communication among workers has been always a major challenge, because it may cause large time latency and bandwidth consumption. In this paper, we propose an entropy-based gradient compression (EGC) mechanism to reduce communication overhead. EGC selects the gradients communicated based on the entropy of the gradient items, which can achieve a high compression ratio without sacrificing accuracy. More importantly, EGC is a general and flexible mechanism that can be adopted in different distributed training algorithms . Accordingly, we propose three EGC-based training algorithms for different scenarios, i.e., EGC-DSGD for decentralized training, EGC-PS for centralized training, and EGC-FL for federated training. To improve the accuracy of these algorithms, we also adopt associated mechanisms, including automatic learning rate correction, momentum correction and residuals accumulation. We prove the convergence of EGC by analysis and evaluate its performance by experiments. Eight models are trained using popular public datasets (including MNIST, CIFAR-10, Tiny ImageNet and Penn Treebank) for the tasks of image classification and language modeling. The experimental results show that, compared with existing works, the EGC based algorithms can achieve roughly 1000 times gradient compression ratio while keeping the accuracy similar or even higher.},
  archive      = {J_ISCI},
  author       = {Danyang Xiao and Yuan Mei and Di Kuang and Mengqiang Chen and Binbin Guo and Weigang Wu},
  doi          = {10.1016/j.ins.2020.05.121},
  journal      = {Information Sciences},
  pages        = {118-134},
  shortjournal = {Inf. Sci.},
  title        = {EGC: Entropy-based gradient compression for distributed deep learning},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Fuzzy approximation-based adaptive finite-time control for
nonstrict feedback nonlinear systems with state constraints.
<em>ISCI</em>, <em>548</em>, 101–117. (<a
href="https://doi.org/10.1016/j.ins.2020.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper solves the adaptive fuzzy finite-time control (AFFTC) problem for nonstrict feedback nonlinear systems with state constraints. Different from the recently works that mainly focus on the C 0 C0 finite-time design scheme, in our context, an innovative C 1 C1 AFFTC method is created by combining the fuzzy approximation with backstepping technique. The singularity problem existing the traditional finite-time scheme is skillfully tackled by creating the smooth switch function. The barrier Lyapunov function is exploited to make all states maintain the predefined regions. By means of Lyapunov stability analysis , the devised AFFTC can make all error signals converge into a small neighborhood of the zero in a finite time. Finally, simulation results illustrate the validity of the designed method.},
  archive      = {J_ISCI},
  author       = {Yongchao Liu and Qidan Zhu and Ning Zhao and Lipeng Wang},
  doi          = {10.1016/j.ins.2020.09.042},
  journal      = {Information Sciences},
  pages        = {101-117},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy approximation-based adaptive finite-time control for nonstrict feedback nonlinear systems with state constraints},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal sensor attacks in cyber-physical systems with
round-robin protocol. <em>ISCI</em>, <em>548</em>, 85–100. (<a
href="https://doi.org/10.1016/j.ins.2020.09.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the stealthy attack problem in cyber-physical systems (CPSs) under the scheduling effects of the Round-Robin protocol (RRP), where the transmission order of the sensor nodes is modeled as a periodic function and only one node is allowed to access the shared communication channel at each time instant. The adoption of the RRP can efficiently avoid data collisions, while it makes the existing innovation-based stealthy attack strategies invalid. Thus, the aim is to design an attack strategy under the protocol-induced behaviors to maximize the attack effect and remain strictly stealthy simultaneously. Different from the existing results, where only single-sensor application scenarios were considered, multi-sensor ones with limited bandwidth are investigated in this work. A new attack model is proposed to overcome the protocol-introduced effects, which utilizes only part of the historical and the current innovations at each time instant. Based on the attack model, the stealthy condition is obtained and converted into the form of linear matrix inequality (LMI). Then, the error covariance under the attack and the RRP is derived to quantify the attack effect. Subsequently, the optimal attack strategy is obtained by solving a semi-definite programming (SDP) problem. Finally, simulations are performed to demonstrate the results.},
  archive      = {J_ISCI},
  author       = {Xiao-Guang Zhang and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2020.09.071},
  journal      = {Information Sciences},
  pages        = {85-100},
  shortjournal = {Inf. Sci.},
  title        = {Optimal sensor attacks in cyber-physical systems with round-robin protocol},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid-triggered-based security controller design for
networked control system under multiple cyber attacks. <em>ISCI</em>,
<em>548</em>, 69–84. (<a
href="https://doi.org/10.1016/j.ins.2020.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the hybrid-triggered security control design for the networked control system (NCS) under multiple cyber attacks . A hybrid-triggered scheme (HTS) is introduced to mitigate the burden of the network transmission. Besides, a new model of multiple cyber attacks is built by simultaneously considering deception attacks and DoS attacks. In addition, A novel NCS model based on multiple cyber attacks is established with the hybrid-triggered scheme. Then, based on Lyapunov stability theory, criteria for guaranteeing the closed-loop system stability and achieving hybrid-triggered security controller design are derived. Finally, an illustrative example is given to validate the usefulness of the theoretical results.},
  archive      = {J_ISCI},
  author       = {Jie Cao and Da Ding and Jinliang Liu and Engang Tian and Songlin Hu and Xiangpeng Xie},
  doi          = {10.1016/j.ins.2020.09.046},
  journal      = {Information Sciences},
  pages        = {69-84},
  shortjournal = {Inf. Sci.},
  title        = {Hybrid-triggered-based security controller design for networked control system under multiple cyber attacks},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian regression and classification using gaussian
process priors indexed by probability density functions. <em>ISCI</em>,
<em>548</em>, 56–68. (<a
href="https://doi.org/10.1016/j.ins.2020.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce the notion of Gaussian processes indexed by probability density functions for extending the Matérn family of covariance functions . We use some tools from information geometry to improve the efficiency and the computational aspects of the Bayesian learning model. We particularly show how a Bayesian inference with a Gaussian process prior (covariance parameters estimation and prediction) can be put into action on the space of probability density functions . Our framework has the capacity of classifiying and infering on data observations that lie on nonlinear subspaces. Extensive experiments on multiple synthetic, semi-synthetic and real data demonstrate the effectiveness and the efficiency of the proposed methods in comparison with current state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {A. Fradi and Y. Feunteun and C. Samir and M. Baklouti and F. Bachoc and J-M Loubes},
  doi          = {10.1016/j.ins.2020.09.027},
  journal      = {Information Sciences},
  pages        = {56-68},
  shortjournal = {Inf. Sci.},
  title        = {Bayesian regression and classification using gaussian process priors indexed by probability density functions},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Microaggregation heuristic applied to statistical disclosure
control. <em>ISCI</em>, <em>548</em>, 37–55. (<a
href="https://doi.org/10.1016/j.ins.2020.09.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dissemination of microdata by public institutions, especially National Statistical Offices (NSOs), and data sharing between public and private organizations and the academia are of undeniable importance today. However, very important ethical and legal aspects related to privacy protection, whether for an individual or a company, often restrict this cooperation. In this sense, the methods of Statistical Disclosure Control (SDC), or, more specifically, microaggregation techniques, offer an alternative to enable the dissemination and sharing of microdata through the control of disclosure risk. In this article, we propose a new heuristic method that adopts concepts from Biased Random Key Genetic Algorithm (BRKGA) metaheuristic and present a comparative study with well-known microaggregation methods. Computational simulations show that the proposed method consistently outperforms other methods in terms of simultaneously reducing information loss and disclosure risk. In addition, the proposed method allows the adopting or even combining of any information loss and disclosure risk metrics. This feature delivers great flexibility and much more control to the privacy protection process.},
  archive      = {J_ISCI},
  author       = {Augusto César Fadel and Luiz Satoru Ochi and José André de Moura Brito and Gustavo Silva Semaan},
  doi          = {10.1016/j.ins.2020.09.069},
  journal      = {Information Sciences},
  pages        = {37-55},
  shortjournal = {Inf. Sci.},
  title        = {Microaggregation heuristic applied to statistical disclosure control},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust data simulation technique to improve early
detection performance of a classifier in control chart pattern
recognition systems. <em>ISCI</em>, <em>548</em>, 18–36. (<a
href="https://doi.org/10.1016/j.ins.2020.09.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quality control process is essential in maintaining the stability of production systems and proactively detecting abnormalities that may result in high mechanical and labor costs. In this study, a new data simulation strategy was devised to improve the early prediction performance (EPP) of an algorithm. Traditional control chart data simulation methods work based on creating abnormal patterns consisting of only abnormal signals. However, a classifier trained with data samples consisting of only abnormal data signals may fail to early detect abnormality in a real-time production line, in which abnormal signals is obscured by volume of normal signals. From this perspective, training a model by imitating real-world cases can improve the performance of an algorithm in terms of early detection of an abnormality. Normal and abnormal patterns were simulated by implementing a new approach called Mix Ratio Data Simulation (MRDS). The proposed methodology MRDS is compared with the customary data simulation method under the predefined scenarios in terms of EPP. The findings indicated that changing the way of simulating dataset increases the EEP of the machine-learning algorithm regardless of abnormality types and parameters.},
  archive      = {J_ISCI},
  author       = {Ramazan Ünlü},
  doi          = {10.1016/j.ins.2020.09.059},
  journal      = {Information Sciences},
  pages        = {18-36},
  shortjournal = {Inf. Sci.},
  title        = {A robust data simulation technique to improve early detection performance of a classifier in control chart pattern recognition systems},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Link prediction based on feature representation and fusion.
<em>ISCI</em>, <em>548</em>, 1–17. (<a
href="https://doi.org/10.1016/j.ins.2020.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction is one of the core problems in social network analysis . Considering the complexity of features in social networks, we propose a link prediction method based on feature representation and fusion. Firstly, based on the sparseness and high-dimensionality of network structure, network embedding is applied to represent the network structure as low-dimensional vectors, which identifies the spatial relationships and discovers the relevance among users. Second, owing to the diversity and complexity of text semantics, the user text is converted into vectors by word embedding models. As user behaviors can reflect the dynamic change of links, a time decay function is introduced to process the text vector to quantify the impact of user text on link establishment . Meanwhile, to simplify the complexity, we choose the top- k relevant users for each user. Finally, due to the attention mechanism can improve the expression of user’s interests in text information, a link prediction method with attention-based convolutional neural network is proposed. By fusing and mining structural and text features, the purpose of synthetically predict link is finally achieved. Experimental results show that the proposed model can effectively improve the performance of link prediction.},
  archive      = {J_ISCI},
  author       = {Yunpeng Xiao and Rui Li and Xingyu Lu and Yanbing Liu},
  doi          = {10.1016/j.ins.2020.09.039},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Link prediction based on feature representation and fusion},
  volume       = {548},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized combination rule for evidential reasoning
approach and dempster–shafer theory of evidence. <em>ISCI</em>,
<em>547</em>, 1201–1232. (<a
href="https://doi.org/10.1016/j.ins.2020.07.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Dempster–Shafer (DS) theory of evidence can combine evidence with one parameter. The evidential reasoning (ER) approach is an extension of DS theory that can combine evidence with two parameters (weights and reliabilities). However, it has three infeasible aspects: reliability dependence, unreliability effectiveness, and intergeneration inconsistency. This study aimed to establish a generalized combination (GC) rule with both weight and reliability, where ER and DS can be viewed as two particular cases, and the problems of infeasibility of the parameters can be solved. In this paper, the infeasibilities of ER are analyzed, and a generalized discounting method is introduced to reasonably discount the belief distributions of the evidence using both the weight and the reliability. A GC rule is then constructed to combine evidence by means of the orthogonal sum operation, and the corresponding theorems and corollaries are provided. Finally, the superiority of the GC rule is shown through numerical comparisons and discussion, and an illustrative example is provided to demonstrate its applicability.},
  archive      = {J_ISCI},
  author       = {Yuan-Wei Du and Jiao-Jiao Zhong},
  doi          = {10.1016/j.ins.2020.07.072},
  journal      = {Information Sciences},
  pages        = {1201-1232},
  shortjournal = {Inf. Sci.},
  title        = {Generalized combination rule for evidential reasoning approach and Dempster–Shafer theory of evidence},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inclusion and similarity measures for interval-valued fuzzy
sets based on aggregation and uncertainty assessment. <em>ISCI</em>,
<em>547</em>, 1182–1200. (<a
href="https://doi.org/10.1016/j.ins.2020.09.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of measuring the degree of inclusion and similarity between interval-valued fuzzy sets. We propose a new idea for constructing indicators of inclusion and similarity measures based on the precedence relation, aggregation and uncertainty assessment. Furthermore, we examine selected properties of the suggested measures and their interactions. Finally, we discuss several similarity measures that appear in the literature and compare them with our novel approach.},
  archive      = {J_ISCI},
  author       = {Barbara Pękala and Krzysztof Dyczkowski and Przemysław Grzegorzewski and Urszula Bentkowska},
  doi          = {10.1016/j.ins.2020.09.072},
  journal      = {Information Sciences},
  pages        = {1182-1200},
  shortjournal = {Inf. Sci.},
  title        = {Inclusion and similarity measures for interval-valued fuzzy sets based on aggregation and uncertainty assessment},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Local discriminant coding based convolutional feature
representation for multimodal finger recognition. <em>ISCI</em>,
<em>547</em>, 1170–1181. (<a
href="https://doi.org/10.1016/j.ins.2020.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with unimodal biometrics systems, multimodal systems can effectively improve the recognition performance in accuracy and security. However, exploring a robust feature representation approach suitable for multiple modalities remains a crucial and challenging problem in the personal authentication community. In this paper, we proposed a discriminant local coding based convolutional neural network (LC-CNN) for multimodal finger recognition by fusing fingerprint, finger-vein, and finger-knuckle-print traits. Specifically, for each tri-modal finger images, we first presented a weighted local gradient coding (WLGC) operator to enhance the discriminant characteristics and formed the local coding layer (LC-layer) by reconstructing the WLGC operator with a bank of predefined convolution layers. Then, we established a simple yet effective LC-CNN model to extract deeper tri-modal finger features. Finally, the extracted feature vectors of three modalities are concatenated and input into a Support Vector Machine (SVM) for image classification. Experimental results demonstrate that the proposed method achieves a stable, highly accurate, and robust performance in multimodal finger recognition.},
  archive      = {J_ISCI},
  author       = {Shuyi Li and Bob Zhang and Shuping Zhao and Jinfeng Yang},
  doi          = {10.1016/j.ins.2020.09.045},
  journal      = {Information Sciences},
  pages        = {1170-1181},
  shortjournal = {Inf. Sci.},
  title        = {Local discriminant coding based convolutional feature representation for multimodal finger recognition},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fractal sorting matrix and its application on chaotic image
encryption. <em>ISCI</em>, <em>547</em>, 1154–1169. (<a
href="https://doi.org/10.1016/j.ins.2020.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article creatively proposes a class of sorting matrices with fractal characteristics, named the fractal sorting matrix (FSM), and introduces its iterative calculation method. The FSM is irregular, self-similar and infinitely iterative. Notably, scrambling images or information based on this new cluster of matrices can effectively improve encryption algorithm security. Then, the article presents a new method of global pixel diffusion with two chaotic sequences , which offers good security and high encryption efficiency. Based on the FSM and global chaotic pixel diffusion, this paper constructs a more efficient and secure chaotic image encryption algorithm than other approaches. According to experimental comparison, the proposed algorithm is faster and has a higher pass rate associated with the local Shannon entropy. The data in the antidifferential attack test are closer to the theoretical values and smaller in data fluctuation, and the images obtained from the cropping and noise attacks are clearer. Therefore, the proposed algorithm shows better security and resistance to various attacks.},
  archive      = {J_ISCI},
  author       = {Yongjin Xian and Xingyuan Wang},
  doi          = {10.1016/j.ins.2020.09.055},
  journal      = {Information Sciences},
  pages        = {1154-1169},
  shortjournal = {Inf. Sci.},
  title        = {Fractal sorting matrix and its application on chaotic image encryption},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). An efficient scheduling algorithm for dataflow architecture
using loop-pipelining. <em>ISCI</em>, <em>547</em>, 1136–1153. (<a
href="https://doi.org/10.1016/j.ins.2020.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dataflow architecture has native advantages in achieving high instruction parallelism and power efficiency for today’s emerging applications such as high performance computing and deep neural network . In dataflow computing, the execution of instructions is driven by data, so the data transfer efficiency of the network on chip (NoC) is a key factor affecting performance. However, the NoC performance degrades due to the increasing use of multicast communications in many applications. The existing dataflow architecture instruction scheduling algorithms do not optimize multicast communication between the instruction and its successor instructions, so the routing paths of many multicast packets have forks which cause bandwidth waste and potential network congestion . We propose a sharing path awareness (SPA) algorithm to optimize multicast communication in the dataflow architecture. The algorithm shares the routing paths from the instruction to its child node to reduce the NoC bandwidth waste through the instruction scheduler. For applications using software iteration, we further extend the loop optimization to the SPA algorithm to sufficiently exploit instruction-level parallelism . Compared with the state-of-the-art algorithm, we show that the SPA algorithm achieves 20.21\% average performance improvement and 15.11\% energy consumption reduction for our experimental workloads.},
  archive      = {J_ISCI},
  author       = {Yi Li and Meng Wu and Xiaochun Ye and Wenming Li and Rui Xue and Da Wang and Hao Zhang and Dongrui Fan},
  doi          = {10.1016/j.ins.2020.09.029},
  journal      = {Information Sciences},
  pages        = {1136-1153},
  shortjournal = {Inf. Sci.},
  title        = {An efficient scheduling algorithm for dataflow architecture using loop-pipelining},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dig users’ intentions via attention flow network for
personalized recommendation. <em>ISCI</em>, <em>547</em>, 1122–1135. (<a
href="https://doi.org/10.1016/j.ins.2020.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately forecasting user’s purchase intention over time is a huge challenge for personalized recommend systems, of which a critical problem is how to model the changes of user preference and temporal correlation of items. In this paper, aiming at addressing this question, we first introduce attention flow network to model users’ purchase records by leveraging attention flow that describes the changing process of purchase intention. Then based on the attention flow network and individuals’ attention flows, we propose a novel personalized recommendation algorithm named Attention Flow Network based Personalized Recommendation (AFNPR). Our method integrates all the purchase sequences of users into a weighted attention flow network, and recommends items based on transition probabilities related to attention flow network with user’s attention decay, which is efficient in linear time. The experiments demonstrate its superior performance on several real datasets.},
  archive      = {J_ISCI},
  author       = {Yan Chen and Yongfang Dai and Xiulong Han and Yi Ge and Hong Yin and Ping Li},
  doi          = {10.1016/j.ins.2020.09.007},
  journal      = {Information Sciences},
  pages        = {1122-1135},
  shortjournal = {Inf. Sci.},
  title        = {Dig users’ intentions via attention flow network for personalized recommendation},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient policy evaluation engine for XACML policy
management. <em>ISCI</em>, <em>547</em>, 1105–1121. (<a
href="https://doi.org/10.1016/j.ins.2020.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, XACML (eXtensible Access Control Markup Language) has been widely used in the development of various applications, especially Web services. The evaluation time of a PDP (Policy Decision Point) grows significantly when the PDP loads a large-scale policy set coded in XACML. In order to improve the PDP evaluation performance, we propose an optimized policy evaluation engine, namely XDLEngine, and make the following contributions. First, XDLEngine has an advantage in the process of handling a large-scale policy set, and innovatively adopts the LDA (Latent Dirichlet Allocation) topic model to cluster policies. Second, according to the clustering results of the LDA model, we digitize and vectorize all rules in policy sets, which facilitates the rule matching. Third, the cosine similarity is introduced to classify the rules under each topic, which greatly reduces the number of comparisons in the process of rule matching and improves the matching efficiency of XDLEngine. Finally, due to the independence between different topics, we use a multi-threaded parallel search in the process of rule matching, which significantly lowers the evaluation time of XDLEngine. The experimental results show that when the number of requests reaches 20,000, the evaluation time of XDLEngine for a practical large-scale policy set with 120,000 rules is approximately 2.48\%, 3.47\% and 3.68\% of that of the Sun PDP, XEngine and HPEngine, respectively.},
  archive      = {J_ISCI},
  author       = {Fan Deng and Zhenhua Yu and Wenjing Liu and Xiaoqing Luo and Yu Fu and Ben Qiang and Chaoyang Xu and Zhiwu Li},
  doi          = {10.1016/j.ins.2020.08.044},
  journal      = {Information Sciences},
  pages        = {1105-1121},
  shortjournal = {Inf. Sci.},
  title        = {An efficient policy evaluation engine for XACML policy management},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy best-worst method based on triangular fuzzy numbers
for multi-criteria decision-making. <em>ISCI</em>, <em>547</em>,
1080–1104. (<a href="https://doi.org/10.1016/j.ins.2020.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new fuzzy best-worst method (BWM) based on triangular fuzzy numbers for multi-criteria decision-making (MCDM). Aimed at the Best-to-Others vector and the Others-to-Worst vector in the form of triangular fuzzy numbers, this paper regards consistency equations as fuzzy equations. The derivation of optimal fuzzy weights of criteria is formulated as a fuzzy decision-making problem, where a mathematical programming model is constructed to derive optimal fuzzy weights of criteria to build a normalized triangular fuzzy weight vector. Then, we propose four linear programming models based on the obtained mathematical programming model for the optimistic decision maker, the pessimistic decision maker and the neutral decision maker, respectively. Through a proper selection of the values of tolerance parameters, each of the linear programming models certainly has a unique global optimal solution. Moreover, this paper proposes the concept of fuzzy consistency index and the concept of fuzzy consistency ratio. Several application examples are used to validate the proposed fuzzy BWM. The proposed fuzzy BWM provides us with a very useful way for MCDM in fuzzy environments.},
  archive      = {J_ISCI},
  author       = {Jiuying Dong and Shuping Wan and Shyi-Ming Chen},
  doi          = {10.1016/j.ins.2020.09.014},
  journal      = {Information Sciences},
  pages        = {1080-1104},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy best-worst method based on triangular fuzzy numbers for multi-criteria decision-making},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advantages of direct input-to-output connections in neural
networks: The elman network for stock index forecasting. <em>ISCI</em>,
<em>547</em>, 1066–1079. (<a
href="https://doi.org/10.1016/j.ins.2020.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Elman neural network (ElmanNN) is well-known for its capability of processing dynamic information, which has led to successful applications in stock forecasting. In this paper, we introduce direct input-to-output connections (DIOCs) into the ElmanNN and show that the proposed Elman neural network with DIOCs (Elman-DIOCs) significantly out-performs the original ElmanNN without such DIOCs. Four different global stock indices, i.e., the Shanghai Stock Exchange (SSE) Composite Index, the Korea Stock Price Index (KOSPI), the Nikkei 225 Index (Nikkei225), and the Standard &amp; &amp;#x26; Poor’s 500 Index (SPX), are used to demonstrate the affecacy of the Elman-DIOCs in time-series prediction. We systematically evaluate 8 models, depending whether or not there are hidden layer biases, whether or not there are output layer biases, and whether or not there are DIOCs. The experimental results show that DIOCs lead to much better prediction accuracy, while requiring fewer than a half of the hidden neurons. Take the SPX index, for example - the root mean squared error (RMSE) and the mean absolute error (MAE) of the Elman-DIOCs are improved by 44.2\% 44.2\% and 41.1\% 41.1\% , respectively, compared to the ElmanNN, and 65.6\% 65.6\% and 60.8\% 60.8\% , respectively, compared to the multi-layer perceptron (MLP). We argue that (1) DIOCs can always help to improve accuracy, while reducing network complexity and computational burden, as long as the problem at hand (either regression or classification) has linear components, and (2) most real-world applications contain linear components. Therefore DIOCs will be almost always beneficial in any types of neural networks for classification or regression. We also point out that in rare cases where the problem at hand is entirely nonlinear, DIOCs should not be used.},
  archive      = {J_ISCI},
  author       = {Yaoli Wang and Lipo Wang and Fangjun Yang and Wenxia Di and Qing Chang},
  doi          = {10.1016/j.ins.2020.09.031},
  journal      = {Information Sciences},
  pages        = {1066-1079},
  shortjournal = {Inf. Sci.},
  title        = {Advantages of direct input-to-output connections in neural networks: The elman network for stock index forecasting},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hardware-aware CPU power measurement based on the
power-exponent function model for cloud servers. <em>ISCI</em>,
<em>547</em>, 1045–1065. (<a
href="https://doi.org/10.1016/j.ins.2020.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy consumption of cloud servers accounts for about 25\% of the total energy of cloud data centers . Reducing and optimizing this energy consumption is thus extremely important in energy saving in cloud data centers . Power model is fundamental in energy efficiency optimization scheduling for cloud computing . However, systems and tools for power measurement in the cloud computing environment are relatively scarce, and power models of cloud servers cannot keep up with the times. Therefore, we propose a new CPU power model named power-exponent function model (PEFM) is proposed, which provides higher accuracy in estimating the CPU power of the latest cloud servers than the current linear, polynomial and power function models. A novel hardware-aware CPU power measurement (HCPM) is also proposed, that can select an appropriate CPU power model through the launch year of CPU without power model training. For validating the efficacy of PEFM and HCPM, a set of experiments including OpenStack cluster experiment, based on a distributed energy meter (DEM) implemented by our team were conducted. The experimental results indicate that the proposed PEFM and HCPM not only improve the accuracy of CPU power estimation in cloud servers in cloud environment, but also reduce the difficulty of model training and simplify system deployment.},
  archive      = {J_ISCI},
  author       = {Weiwei Lin and Tianhao Yu and Chongzhi Gao and Fagui Liu and Tengyue Li and Simon Fong and Yongxiang Wang},
  doi          = {10.1016/j.ins.2020.09.033},
  journal      = {Information Sciences},
  pages        = {1045-1065},
  shortjournal = {Inf. Sci.},
  title        = {A hardware-aware CPU power measurement based on the power-exponent function model for cloud servers},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-subject data augmentation for target subject semantic
decoding with deep multi-view adversarial learning. <em>ISCI</em>,
<em>547</em>, 1025–1044. (<a
href="https://doi.org/10.1016/j.ins.2020.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional magnetic resonance imaging (fMRI) is widely used in the field of brain semantic decoding. However, as fMRI data acquisition is time-consuming and expensive, the number of samples is usually small in the existing fMRI datasets. It is difficult to build an accurate brain decoding model for a subject with insufficient fMRI data. The majority of semantic decoding methods focus on designing predictive model with limited samples, while less attention is paid to fMRI data augmentation . Leveraging data from related but different subjects can be regarded as a new strategy to improve the performance of predictive model. There are two challenges when using information from different subjects: 1) feature mismatch; 2) distribution mismatch. In this paper, we propose a multi-subject fMRI data augmentation method to address the above two challenges, which can improve the decoding accuracy of the target subject. Specifically, the subject information can be translated from one to another by using multiple subject-specific encoders, decoders and discriminators. The encoder maps each subject to a shared latent space, solving the feature mismatch problem. The decoders and discriminators form multiple generative adversarial network architectures, which solves the distribution mismatch problem. Meanwhile, to ensure that the representation of the latent space preserves information of the input space, our method not only minimizes the local data reconstruction loss, but also preserves the sparse reconstruction (semantic) relation over the whole dataset of the input space. Extensive experiments on three fMRI datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Dan Li and Changde Du and Shengpei Wang and Haibao Wang and Huiguang He},
  doi          = {10.1016/j.ins.2020.09.012},
  journal      = {Information Sciences},
  pages        = {1025-1044},
  shortjournal = {Inf. Sci.},
  title        = {Multi-subject data augmentation for target subject semantic decoding with deep multi-view adversarial learning},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inference approach based on petri nets. <em>ISCI</em>,
<em>547</em>, 1008–1024. (<a
href="https://doi.org/10.1016/j.ins.2020.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An inference approach is proposed by formulating reasoning processes as particular evolutions of Petri nets . It can be used to design an intelligent agent that executes tasks in a given environment. First, a symbol Petri net is defined to represent a Boolean variable describing a distinct aspect of an environment. Second, a propositional logic sentence in a conjunctive normal form , which may express some background knowledge or a sequence of percepts made by an agent, is formulated as a linear constraint , called as a semantic constraint. Third, an algorithm is constructed to design monitor places enforcing semantic constraints on symbol Petri nets , and its resultant net is called a knowledge Petri net representing relevant knowledge. Fourth, a reasoning algorithm is presented based on a newly defined transition-firing rule of the knowledge Petri net, and can be used to infer or reveal hidden facts. The proposed inference algorithm is efficient since its time computational complexity is proven to be polynomial with respect to the number of Boolean variables. The wumpus world problem is taken as an example to illustrate and verify it.},
  archive      = {J_ISCI},
  author       = {JiLiang Luo and KaiCheng Tan and HuaiJu Luo and MengChu Zhou},
  doi          = {10.1016/j.ins.2020.09.023},
  journal      = {Information Sciences},
  pages        = {1008-1024},
  shortjournal = {Inf. Sci.},
  title        = {Inference approach based on petri nets},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic convergence analysis of the stochastic
particle swarm optimization model without the stagnation assumption.
<em>ISCI</em>, <em>547</em>, 996–1007. (<a
href="https://doi.org/10.1016/j.ins.2020.08.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a stochastic optimization algorithm , it is more reasonable for particle swarm optimization (PSO) to study the probabilistic convergence. In this study, we analyze its convergence with probability 1 using the theory of probabilistic metric space . Firstly, we assume that the personal best of the particle and global best of the particle swarm are updated during the run; however, we do not assume that the personal best of the particle and global best of the particle swarm must be independent of the position of the particle. Such an assumption is more pragmatic and could be implemented in all PSO variants. Then, we develop a stochastic recurrence relation of the state of a particle under this assumption. Finally, we derive a sufficient condition that ensures the stochastic PSO algorithm is τ-convergent with probability 1. In addition, we analyze the impact of the parameters in the unstable range on the individual iterations. Although these parameters could not guarantee the long-term convergence, their impact significantly influences the exploration ability of PSO; thus, it is crucial to understand them. Based on this analysis, we propose a novel strategy for balancing the exploitation and exploration abilities of the PSO algorithm.},
  archive      = {J_ISCI},
  author       = {Difeng Hu and Xudong Qiu and Ying Liu and Xiangyang Zhou},
  doi          = {10.1016/j.ins.2020.08.072},
  journal      = {Information Sciences},
  pages        = {996-1007},
  shortjournal = {Inf. Sci.},
  title        = {Probabilistic convergence analysis of the stochastic particle swarm optimization model without the stagnation assumption},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical multi-view context modelling for 3D object
classification and retrieval. <em>ISCI</em>, <em>547</em>, 984–995. (<a
href="https://doi.org/10.1016/j.ins.2020.09.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in 3D sensors and 3D modelling software have led to big 3D data. 3D object classification and retrieval are becoming important but challenging tasks. One critical problem for them is how to learn the discriminative multi-view visual characteristics. To address it, we proposes a hierarchical multi-view context modelling method (HMVCM). It consists of four key modules. First, the module of view-level context learning is designed to learn visual context features with respect to individual views and their neighbours. This module can imitate the human need to look back and forth to identify and compare the discriminative parts of individual 3D objects based on a joint convolutional neural network (CNN) and bidirectional long short-term memory (Bi-LSTM) network. Then, a multi-view grouping module is introduced to split views into several groups based on their visual appearance. A raw group-level representation can be obtained by the weighted sum of the view-level descriptors. Furthermore, we employ the Bi-LSTM to exploit the context among adjacent groups to generate group-wise context features. Finally, all group-wise context features are fused into a compact 3D object descriptor according to their significance. Extensive experiments on ModelNet10, ModelNet40 and ShapeNetCore55 demonstrate the superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {An-An Liu and Heyu Zhou and Weizhi Nie and Zhenguang Liu and Wu Liu and Hongtao Xie and Zhendong Mao and Xuanya Li and Dan Song},
  doi          = {10.1016/j.ins.2020.09.057},
  journal      = {Information Sciences},
  pages        = {984-995},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical multi-view context modelling for 3D object classification and retrieval},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Many-objective evolutionary algorithm based on relative
non-dominance matrix. <em>ISCI</em>, <em>547</em>, 963–983. (<a
href="https://doi.org/10.1016/j.ins.2020.09.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various evolutionary algorithms have been proposed for tackling many-objective optimization problems over the past three decades. However, these algorithms still suffer from the loss of selection pressures due to the existence of dominance resistance. To tackle this issue, this paper proposes a relative non-dominance matrix, based on which a fitness formula is defined. Empirical analyses show that solutions with smaller fitness values are likely to dominate more other solutions in the future evolutionary process, and play a vital role in enhancing the convergence toward to the true Pareto fronts . Additionally, to further ensure the diversity, k -means clustering strategy is combined with the relative non-dominance matrix for a new design of the environmental selection, where parameter k in the clustering strategy is adjusted adaptively. The proposed algorithm is extensively tested with four state-of-art algorithms on WFG, MaF and DTLZ test suites. Empirical comparisons demonstrate the competitiveness of the proposed algorithm regarding to the convergence, diversity and spread.},
  archive      = {J_ISCI},
  author       = {Maoqing Zhang and Lei Wang and Weian Guo and Wuzhao Li and Dongyang Li and Bo Hu and Qidi Wu},
  doi          = {10.1016/j.ins.2020.09.061},
  journal      = {Information Sciences},
  pages        = {963-983},
  shortjournal = {Inf. Sci.},
  title        = {Many-objective evolutionary algorithm based on relative non-dominance matrix},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DsNet: Dual stack network for detecting diabetes mellitus
and chronic kidney disease. <em>ISCI</em>, <em>547</em>, 945–962. (<a
href="https://doi.org/10.1016/j.ins.2020.08.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetes mellitus and chronic kidney disease are two severe chronic diseases in the world, affecting the quality of a patient’s life. However, detecting these two diseases often applies professional medical techniques such as a Fasting Plasma Glucose test and estimating the glomerular filtration rate (eGFR) measurement, which usually requires a blood test. Given the various inconveniences and risks in existing conventional diagnostic approaches, noninvasive healthcare systems based on intelligent electronic detection/prevention are preferred. To achieve this goal, we propose a progressively trainable network, i.e., dual stack network (DsNet), to distinguish patients with chronic kidney disease, diabetes mellitus from healthy people simultaneously through analyzing the facial images of candidates. The first stack subnetwork extracts high-level representative features from the facial images effectively. While the second stack subnetwork can further analyze the extracted high-level features from the first stack subnetwork, before classifying the two diseases from healthy individuals simultaneously. Extensive experiments on a dataset with 229 healthy samples, 236 diabetes, and 200 chronic kidney disease patients show that our proposed method generated the F1-score of 95.33\%, 98.17\%, and 94.67\% for detecting chronic kidney disease, diabetes, and healthy samples respectively. Our proposed DsNet achieves significant improvements compared with other traditional noninvasive detection approaches.},
  archive      = {J_ISCI},
  author       = {Qi Zhang and Jianhang Zhou and Bob Zhang and Enhua Wu},
  doi          = {10.1016/j.ins.2020.08.074},
  journal      = {Information Sciences},
  pages        = {945-962},
  shortjournal = {Inf. Sci.},
  title        = {DsNet: Dual stack network for detecting diabetes mellitus and chronic kidney disease},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Partial-neurons-based state estimation for delayed neural
networks with state-dependent noises under redundant channels.
<em>ISCI</em>, <em>547</em>, 931–944. (<a
href="https://doi.org/10.1016/j.ins.2020.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the partial-neurons-based state estimation problem is studied for a class of delayed neural networks with state-dependent noises under redundant channels. For the purpose of improving the success rate of the data transmission from the sensor to the estimator, the redundant-channel-based transmission mechanism is considered. The main aim of the addressed problem is to design a state estimator to estimate the neurons’ state by use of a small fraction of the sensor measurements. With the help of the Lyapunov stability theory , a sufficient condition is provided to ensure that the estimation error dynamics is exponentially mean-square bounded. The desired estimator gain is acquired by minimizing an asymptotic upper bound of the estimation error. Finally, a numerical simulation is carried out to demonstrate the usefulness of the presented estimator design scheme.},
  archive      = {J_ISCI},
  author       = {Shuai Liu and Zidong Wang and Bo Shen and Guoliang Wei},
  doi          = {10.1016/j.ins.2020.08.047},
  journal      = {Information Sciences},
  pages        = {931-944},
  shortjournal = {Inf. Sci.},
  title        = {Partial-neurons-based state estimation for delayed neural networks with state-dependent noises under redundant channels},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consensus of large-scale group decision making in social
network: The minimum cost model based on robust optimization.
<em>ISCI</em>, <em>547</em>, 910–930. (<a
href="https://doi.org/10.1016/j.ins.2020.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, large-scale group decision making (LSGDM) in social network comes into being. In the practical consensus of LSGDM, the unit adjustment cost of experts is difficult to obtain and may be uncertain. Therefore, the purpose of this paper is to propose a consensus model based on robust optimization. This paper focuses on LSGDM, considering the social relationship between experts. In the presented model, an expert clustering method, combining trust degree and relationship strength, is used to classify experts with similar opinions into subgroups. A consensus index, reflecting the harmony degree between experts, is devised to measure the consensus level among experts. Then, a minimum cost model based on robust optimization is proposed to solve the robust optimization consensus problem. Subsequently, a detailed consensus feedback adjustment is presented. Finally, a case study and comparative analysis are provided to verify the validity and advantage of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yanling Lu and Yejun Xu and Enrique Herrera-Viedma and Yefan Han},
  doi          = {10.1016/j.ins.2020.08.022},
  journal      = {Information Sciences},
  pages        = {910-930},
  shortjournal = {Inf. Sci.},
  title        = {Consensus of large-scale group decision making in social network: The minimum cost model based on robust optimization},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerated learning algorithms of general fuzzy min-max
neural network using a novel hyperbox selection rule. <em>ISCI</em>,
<em>547</em>, 887–909. (<a
href="https://doi.org/10.1016/j.ins.2020.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a method to accelerate the training process of general fuzzy min-max neural network. The purpose is to reduce the unsuitable hyperboxes selected as the potential candidates of the expansion step of existing hyperboxes to cover a new input pattern in the online learning algorithms or candidates of the hyperbox aggregation process in the agglomerative learning algorithms. Our proposed approach is based on the mathematical formulas to form a new solution aiming to remove the hyperboxes which are certain not to satisfy expansion or aggregation conditions, and in turn decreasing the training time of learning algorithms. The efficiency of the proposed method is assessed over a number of widely used data sets. The experimental results indicated the significant decrease in training time of proposed approach for both online and agglomerative learning algorithms. Notably, the training time of the online learning algorithms is reduced from 1.2 to 12 times when using the proposed method, while the agglomerative learning algorithms are accelerated from 7 to 37 times on average.},
  archive      = {J_ISCI},
  author       = {Thanh Tung Khuat and Bogdan Gabrys},
  doi          = {10.1016/j.ins.2020.08.046},
  journal      = {Information Sciences},
  pages        = {887-909},
  shortjournal = {Inf. Sci.},
  title        = {Accelerated learning algorithms of general fuzzy min-max neural network using a novel hyperbox selection rule},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A differential evolution based feature combination selection
algorithm for high-dimensional data. <em>ISCI</em>, <em>547</em>,
870–886. (<a href="https://doi.org/10.1016/j.ins.2020.08.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature combination selection is used in object classification to select complementary features that can produce a powerful combination. One active area of selecting feature combinations is genome-wide association studies (GWAS). However, selecting feature combinations from high-dimensional GWAS data faces a serious issue of high computational complexity . In this paper, a fast evolutionary optimization method named search-history-guided differential evolution (HGDE) is proposed to deal with the problem. This method applies the search history memorized in a binary space partitioning tree to enhance its power for selecting feature combinations. We perform a comparative study on the proposed HGDE algorithm and other state-of-the-art algorithms using synthetic datasets , and later employ the HGDE algorithm in experiments on a real age-related macular degeneration dataset. The experimental results show that this proposed algorithm has superior performance in the selection of feature combinations. Moreover, the results provide a reference for studying the functional mechanisms of age-related macular degeneration.},
  archive      = {J_ISCI},
  author       = {Boxin Guan and Yuhai Zhao and Ying Yin and Yuan Li},
  doi          = {10.1016/j.ins.2020.08.081},
  journal      = {Information Sciences},
  pages        = {870-886},
  shortjournal = {Inf. Sci.},
  title        = {A differential evolution based feature combination selection algorithm for high-dimensional data},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Attention guided for partial domain adaptation.
<em>ISCI</em>, <em>547</em>, 860–869. (<a
href="https://doi.org/10.1016/j.ins.2020.08.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to effectively extract feature representations from unlabeled samples from the target domain is critical for unsupervised domain adaptation , specific for partial domain adaptation where source label space is a super-space of target label space, as it helps reduce large performance gap due to domain shift or domain bias. In this paper, a novel partial domain adaptation method named Multiple Self-Attention Networks (MSAN) based on adversarial learning is proposed. Unlike most existing partial domain adaptation methods which only focus on high-level features, MSAN focuses on effective high-level context features and low-level structural features from unlabeled target data with the help of labeled source data. Specifically, we present multiple self-attention network, a general approach to learning more fine-grained and transferable features in a manner of gradual feature enhancement so that domain shift can be relatively decreased to boost the model generalization power. Comprehensive experiments on Office-31 and Office-Home datasets demonstrate that the proposed approach significantly improves upon representation partial domain adaptation methods to yield state-of-the-art results for various partial transfer tasks.},
  archive      = {J_ISCI},
  author       = {Changchun Zhang and Qingjie Zhao},
  doi          = {10.1016/j.ins.2020.08.103},
  journal      = {Information Sciences},
  pages        = {860-869},
  shortjournal = {Inf. Sci.},
  title        = {Attention guided for partial domain adaptation},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A problem-specific non-dominated sorting genetic algorithm
for supervised feature selection. <em>ISCI</em>, <em>547</em>, 841–859.
(<a href="https://doi.org/10.1016/j.ins.2020.08.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS), which plays an important role in classification tasks, has been recently studied as a multi-objective optimization problem (MOP). In this paper, we consider minimizing three objectives of FS and propose a problem-specific non-dominated sorting genetic algorithm (PS-NSGA). In PS-NSGA, an accuracy-preferred domination operator is applied, which makes the individual with higher classification accuracy in the population more likely to survive. And a quick bit mutation is used, which breaks through the limitation of traditional bit string mutation and increases the efficiency. In addition, a mutation-retry operator and a combination operator are designed to make our algorithm converge faster and better. At last, a solution selection strategy is developed to determine the most proper feature subset from the obtained Pareto solutions. Experimental results on 15 real-world high-dimensional datasets demonstrate that our proposed algorithm can achieve competitive classification accuracy while obtaining a smaller size of feature subset compared with some state-of-the-art evolutionary and traditional FS algorithms.},
  archive      = {J_ISCI},
  author       = {Yu Zhou and Wenjun Zhang and Junhao Kang and Xiao Zhang and Xu Wang},
  doi          = {10.1016/j.ins.2020.08.083},
  journal      = {Information Sciences},
  pages        = {841-859},
  shortjournal = {Inf. Sci.},
  title        = {A problem-specific non-dominated sorting genetic algorithm for supervised feature selection},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DNA sequence reconstruction based on innovated hybridization
technique of probabilistic cellular automata and particle swarm
optimization. <em>ISCI</em>, <em>547</em>, 828–840. (<a
href="https://doi.org/10.1016/j.ins.2020.08.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DNA sequence reconstruction is a challenging research problem in the computational biology field. The evolution of the DNA is too complex to be characterized by a few parameters. Therefore, there is a need for a modeling approach for analyzing DNA patterns. In this paper, we proposed a novel framework for DNA pattern analysis. The proposed framework consists of two main stages. The first stage is for analyzing the DNA sequences evolution, whereas the other stage is for the reconstruction process. We utilized cellular automata (CA) rules for analyzing and predicting the DNA sequence. Then, a modified procedure for the reconstruction process is introduced, which is based on the Probabilistic Cellular Automata (PCA) integrated with Particle Swarm Optimization (PSO) algorithm. This integration makes the proposed framework more efficient and achieves optimum transition rules. Our innovated model leans on the hypothesis that mutations are probabilistic events. As a result, their evolution can be simulated as a PCA model . The main objective of this paper is to analyze various DNA sequences to predict the changes that occur in DNA during evolution (mutations). We used a similarity score as a fitness measure to detect symmetry relations , which is appropriate for numerous extremely long sequences. Results are given for the CpG-methylation-deamination processes, which are regions of DNA where a guanine nucleotide follows a cytosine nucleotide in the linear sequence of bases. The DNA evolution is handled as the evolved colored paradigms. Therefore, incorporating probabilistic components help to produce a tool capable of foretelling the likelihood of specific mutations. Besides, it shows their capabilities in dealing with complex relations.},
  archive      = {J_ISCI},
  author       = {Wesam M. Elsayed and Mohammed Elmogy and B.S. El-Desouky},
  doi          = {10.1016/j.ins.2020.08.102},
  journal      = {Information Sciences},
  pages        = {828-840},
  shortjournal = {Inf. Sci.},
  title        = {DNA sequence reconstruction based on innovated hybridization technique of probabilistic cellular automata and particle swarm optimization},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Morphogenetic systems for resource bounded computation and
modeling. <em>ISCI</em>, <em>547</em>, 814–827. (<a
href="https://doi.org/10.1016/j.ins.2020.08.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A further exploration is presented of recent approaches to morphogenetic processes where geometry and form are fundamental primitives. Prior bottom-up approaches in morphogenetic modeling usually target a specific biological process aiming for optimal fidelity. We take a novel, more integrative and more abstract view of these phenomena and aim at properties such as (computational) universality, homeostasis, self-reproduction or self-healing, in both living and artificial evolving systems with explicit geometric 3D arrangements. We refine the recently introduced model of M systems (for morphogenetic systems ) that leverages certain constructs in membrane computing and DNA self-assembly. The model is still based on local interactions of simple atomic components under explicit geometric constraints given by their shapes and spatial arrangements. We demonstrate two types of capabilities of the extended models. First, they are computationally universal in the Turing sense because they can simulate Turing machines very efficiently, with only a linear slowdown factor. Furthermore, they have the theoretical capability to probabilistically solve NP -hard problems in polynomial time . Second, more importantly, they unfold to exhibit certain macro-properties characteristic of living organisms (particularly, the ability of self-assembly of complex structures, self-reproduction and self-healing) as global properties observable at the macro-level, without explicit programming of these properties beyond simple rules of interaction. Besides providing a new theoretical background for this type of model, we provide quantitative evidence of these properties in a simple cell-like M system model. These results have been obtained using an M system simulator and visualizer that is available as open source software for further research in this area.},
  archive      = {J_ISCI},
  author       = {Petr Sosík and Max Garzon and Vladimír Smolka and Jan Drastík},
  doi          = {10.1016/j.ins.2020.08.073},
  journal      = {Information Sciences},
  pages        = {814-827},
  shortjournal = {Inf. Sci.},
  title        = {Morphogenetic systems for resource bounded computation and modeling},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble learning based on approximate reducts and bootstrap
sampling. <em>ISCI</em>, <em>547</em>, 797–813. (<a
href="https://doi.org/10.1016/j.ins.2020.08.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning is an effective approach for improving the generalization ability of base classifiers . To generate a set of accurate and diverse base classifiers , different data perturbation schemes have been proposed. For instance, Bagging perturbs the training data via bootstrap sampling. However, when a stable learning algorithm (e.g., KNN , Naive Bayes) is used to train base classifiers, the sole perturbation on the training data may not produce diverse base classifiers. In this paper, by using the attribute reduction technology in rough sets, a multi-modal perturbation-based algorithm (called ‘E _ _ EARBS’) is proposed for the ensemble of base classifiers. E _ _ EARBS simultaneously perturbs the feature space, training data and learning parameters, where the relative decision entropy(RDE)-based approximate reducts are used to perturb the feature space, and bootstrap sampling is used to perturb the training data. Experimental results show that E _ _ EARBS can provide competitive solutions for ensemble learning.},
  archive      = {J_ISCI},
  author       = {Feng Jiang and Xu Yu and Junwei Du and Dunwei Gong and Youqiang Zhang and Yanjun Peng},
  doi          = {10.1016/j.ins.2020.08.069},
  journal      = {Information Sciences},
  pages        = {797-813},
  shortjournal = {Inf. Sci.},
  title        = {Ensemble learning based on approximate reducts and bootstrap sampling},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A distributed sensor-fault detection and diagnosis framework
using machine learning. <em>ISCI</em>, <em>547</em>, 777–796. (<a
href="https://doi.org/10.1016/j.ins.2020.08.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this work is to design a sensor-fault detection and diagnosis system for the Internet of Things and Cyber-Physical Systems. The challenge is, however, achieving this objective within the limited computation, memory, and energy resources of the sensors. More importantly, the detection of faults is time-sensitive, whereas the diagnosis does not necessarily need to be fast. We propose a distributed sensor-fault detection and diagnosis system based on machine learning algorithms where the fault detection block is implemented in the sensor in order to achieve output immediately after data collection. This block consists of an auto-encoder to transform the input signal into a lower-dimensional feature vector, which is then provided to a Support Vector Machine (SVM) for classification as normal or faulty. Once detected, fault diagnosis is performed at a central node, such as a network server, to reduce the computational load on the sensor. In this work, a Fuzzy Deep Neural Network (FDNN) is used for diagnosis to provide further information, such as the type of fault. Here, the input propagates through a deep neural network and a fuzzy representation process. The output of these two components is then fused through densely connected layers. This multi-modal technique learns high-level representations in the data that are missed by conventional methods. To assess the performance of the proposed model, we utilize data obtained from a healthy temperature-to-voltage converter that are then injected with five types of fault: drift, bias, precision degradation, spike, and stuck faults. The performance from fault detection is analyzed in terms of detection accuracy, area under the ROC curve (AUC-ROC), false positive rate, and F1 score. Furthermore, the efficiency of fault diagnosis is shown by the classification accuracy parameter. The experimental results show the efficiency of the proposed fuzzy learning-based model over classic neuro-fuzzy and non-fuzzy learning approaches.},
  archive      = {J_ISCI},
  author       = {Sana Ullah Jan and Young Doo Lee and In Soo Koo},
  doi          = {10.1016/j.ins.2020.08.068},
  journal      = {Information Sciences},
  pages        = {777-796},
  shortjournal = {Inf. Sci.},
  title        = {A distributed sensor-fault detection and diagnosis framework using machine learning},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). D4Net: De-deformation defect detection network for non-rigid
products with large patterns. <em>ISCI</em>, <em>547</em>, 763–776. (<a
href="https://doi.org/10.1016/j.ins.2020.05.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect detection is one of the key steps in quality control in manufacturing industries. Distinguishing unwanted defects and acceptable deformation for non-rigid products with large patterns is a challenging yet rarely researched task. In this work, a de-deformation defect detection network (D4Net) is proposed to detect defects of a non-rigid product with deformation in a given image and its corresponding reference image. The proposed method focuses on differences between high-level semantic features extracted from the deep neural network to emphasize the region of possible defects. In training, a marginal loss is proposed to improve the separability between defects and deformation in images with large patterns. Experimental results show that the D4Net yields the best performances of 96.9\%\% accuracy and 91.7\%\% F-measure in a real industrial dataset consisting of 67K images of lace fabric with large patterns from a worldwide top-10 lace fabric manufacturing company. This validates the effectiveness of the proposed method in industrial applications.},
  archive      = {J_ISCI},
  author       = {Xuemiao Xu and Jiaxing Chen and Huaidong Zhang and Wing W.Y. Ng},
  doi          = {10.1016/j.ins.2020.05.050},
  journal      = {Information Sciences},
  pages        = {763-776},
  shortjournal = {Inf. Sci.},
  title        = {D4Net: De-deformation defect detection network for non-rigid products with large patterns},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive fault estimation for cyber-physical systems with
intermittent DoS attacks. <em>ISCI</em>, <em>547</em>, 746–762. (<a
href="https://doi.org/10.1016/j.ins.2020.08.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the problem of fault estimation (FE) for cyber-physical systems (CPSs) modeled by interconnected systems . Under denial-of-service (DoS) attacks, the measurement transmission over the communication network is interrupted, which leads to the infeasibility of the existing FE methods. To overcome this difficulty, a novel switching-type FE scheme is proposed. More specifically, a sequence of adaptive observers and an algorithm are constructed to provide the estimates with improved estimation accuracy, and the observer gain matrices are switched to be zero to discard the outdated measurements under DoS attacks. Therefore, the estimation performance is effectively enhanced in the normal case, and a quantitative description of the estimation error divergence rate is given in the attack status. Compared with the existing results, the interconnections among subsystems are fully considered to improve the estimation accuracy, and in the disturbance-free case, it is proven that the mean sequence of the estimate errors converges to zero. Finally, some simulation results are provide to verify the theoretical findings.},
  archive      = {J_ISCI},
  author       = {Jing-Jing Yan and Guang-Hong Yang},
  doi          = {10.1016/j.ins.2020.08.086},
  journal      = {Information Sciences},
  pages        = {746-762},
  shortjournal = {Inf. Sci.},
  title        = {Adaptive fault estimation for cyber-physical systems with intermittent DoS attacks},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view spectral clustering for uncertain objects.
<em>ISCI</em>, <em>547</em>, 723–745. (<a
href="https://doi.org/10.1016/j.ins.2020.08.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the machine learning and pattern recognition fraternity, uncertain data clustering is an essential job because uncertainty in data makes the clustering process more difficult. Recently, multi-view clustering is gaining more attention towards data miners for certain data because it produces good results compared to grouping based on a single viewpoint. In uncertain data clustering, similarity measure plays an imperative role. However, state-of-the-art similarity measures suffer from several limitations. For example, when two distributions of two uncertain data are heavily overlapped in locations, then Geometric similarity measure alone is not sufficient. On the other hand, similarity measure based on probability distribution is not enough when two uncertain data are not closed to each other or completely separated. In this study, induced kernel distance and Jeffrey-divergence are fused by the degree of overlap concerning each view of a dataset to construct a self-adaptive mixture similarity measure (SAM). The SAM is further used with pairwise co-regularization in multi-view spectral clustering for grouping uncertain data. The proof of convergence of the objective function of the proposed clustering algorithm is also presented in this study. All the experiments are carried out on nine real-world deterministic datasets, three real-life and one synthetic uncertain datasets. Nine real-world deterministic datasets are further converted into uncertain datasets before executing all the clustering algorithms. Experimental results illustrate that the proposed algorithm outperforms nine state-of-the-art methods. The comparison is made using five clustering evaluation metrics. The proposed method is also tested using null hypothesis significance tests.},
  archive      = {J_ISCI},
  author       = {Krishna Kumar Sharma and Ayan Seal},
  doi          = {10.1016/j.ins.2020.08.080},
  journal      = {Information Sciences},
  pages        = {723-745},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view spectral clustering for uncertain objects},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view gaussian processes with posterior consistency.
<em>ISCI</em>, <em>547</em>, 710–722. (<a
href="https://doi.org/10.1016/j.ins.2020.08.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gaussian processes (GPs) are powerful tools for regression and classification tasks, and have been used widely in various fields of machine learning. However, GPs are barely applied directly to the scenario of multi-view learning so far. In this paper, we propose two kinds of multi-view GPs frameworks called MVGP1 and MVGP2 with posterior consistency, which combine multiple views by regularizing the marginal likelihood. Utilizing the posterior distribution consistency criterion, the MVGP1 is first presented. Then to further improve classification accuracy, we present the MVGP2, in which we introduce a trade-off parameter to govern the relative importance of the likelihood term compared with the regularization term. The MVGP1 significantly reduces the training time of the multi-view GPs with acceptable performance on the accuracy, and the MVGP2 achieves state-of-the-art classification performance. Experimental results on multiple real-world classification data sets show the effectiveness of the proposed frameworks.},
  archive      = {J_ISCI},
  author       = {Shiliang Sun and Xuli Sun and Qiuyang Liu},
  doi          = {10.1016/j.ins.2020.08.077},
  journal      = {Information Sciences},
  pages        = {710-722},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view gaussian processes with posterior consistency},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network-based evidential three-way theoretic model for
large-scale group decision analysis. <em>ISCI</em>, <em>547</em>,
689–709. (<a href="https://doi.org/10.1016/j.ins.2020.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social relationships are critical to the group decision-making (GDM) process, especially for large-scale scenarios. Conventional GDM models have several drawbacks when applied to large-scale GDM problems. In this paper, we propose an evidential three-way theoretic model for large-scale group decision analysis based on the introduction of ego networks. A similarity matrix of all individuals is obtained after ego network generation via social network feature extraction . Rough and smooth detection are then conducted in the framework of three-way decisions. Specifically, the degree of organizational influence is analyzed based on the generated basic probability assignments (BPAs), and the individuals are divided into several organizations. After an opinion collection process, preference evolution is implemented via a social influence network (SIN) technique and a fuzzy preference relation (FPR) model. Then, the global final scores of all the alternatives are obtained using an aggregation process. Finally, we conduct a simulation experiment to illustrate the entire procedure. Based on a comparison of related methods, we believe that the proposed method can reasonably solve real-world large-scale group decision-making (LSGDM) problems and has good practicability and effectiveness.},
  archive      = {J_ISCI},
  author       = {Zeyi Liu and Xiao He and Yong Deng},
  doi          = {10.1016/j.ins.2020.08.042},
  journal      = {Information Sciences},
  pages        = {689-709},
  shortjournal = {Inf. Sci.},
  title        = {Network-based evidential three-way theoretic model for large-scale group decision analysis},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). SMKFC-ER: Semi-supervised multiple kernel fuzzy clustering
based on entropy and relative entropy. <em>ISCI</em>, <em>547</em>,
667–688. (<a href="https://doi.org/10.1016/j.ins.2020.08.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study aimed to present a new algorithm called Semi-supervised Multiple Kernel Fuzzy Clustering based on Entropy and Relative entropy (SMKFC-ER) by focusing on external knowledge related to the labeled data. In the proposed method, entropy coefficient and relative entropy divergence measure are applied instead of fuzzifier for unsupervised section and the geometric distance measure for semi-supervised section respectively, by emphasizing on combining unsupervised and semi-supervised sections explicitly. The use of relative entropy and entropy in the objective function results in sharing more consistent concepts for the semi-supervised section, controlling the fuzziness of the extracted clusters, and determining the kernel weights regularly for the unsupervised section. Finally, using relative entropy with entropy simultaneously derives a closed-form solution. The performance and supremacy of the proposed method on non-spherical synthetic and real-world datasets are shown by comparing unsupervised and semi-supervised fuzzy clustering methods .},
  archive      = {J_ISCI},
  author       = {Fariba Salehi and Mohammad Reza Keyvanpour and Arash Sharifi},
  doi          = {10.1016/j.ins.2020.08.094},
  journal      = {Information Sciences},
  pages        = {667-688},
  shortjournal = {Inf. Sci.},
  title        = {SMKFC-ER: Semi-supervised multiple kernel fuzzy clustering based on entropy and relative entropy},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interval type-2 fuzzy sets improved by simulated annealing
for locating the electric charging stations. <em>ISCI</em>,
<em>547</em>, 641–666. (<a
href="https://doi.org/10.1016/j.ins.2020.08.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric vehicles are the key to facilitating the transition to low-carbon ‘green’ transport. However, there are concerns with their range and the location of the charging stations which delay a full-fledged adoption of their use. Hence, the electric charging infrastructure in a given region is critical to mitigating those concerns. In this study, an interval type-2 fuzzy set based multi-criteria decision-making method is introduced for selecting the best location for electric charging stations. This method is improved by Simulated Annealing obtaining the best configuration of the parameters of the interval type-2 membership functions along with two different aggregation operators; linguistic weighted sum and average. The proposed overall reusable multi-stage solution approach is applied to a real-world public transport problem of the municipal bus company in Istanbul. The results indicate that the approach indeed improves the model, capturing the associated uncertainties embedded in the interval type-2 membership functions better, leading to a more effective fuzzy system. The experts confirm those observations and that Simulated Annealing improved interval type-2 fuzzy method achieves more reliable results for selecting the best sites for the electric bus charging stations.},
  archive      = {J_ISCI},
  author       = {Seda Türk and Muhammet Deveci and Ender Özcan and Fatih Canıtez and Robert John},
  doi          = {10.1016/j.ins.2020.08.076},
  journal      = {Information Sciences},
  pages        = {641-666},
  shortjournal = {Inf. Sci.},
  title        = {Interval type-2 fuzzy sets improved by simulated annealing for locating the electric charging stations},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse graph based self-supervised hashing for scalable
image retrieval. <em>ISCI</em>, <em>547</em>, 622–640. (<a
href="https://doi.org/10.1016/j.ins.2020.08.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, learning-based image hashing techniques have elicited wide interest among researchers because they can be applied in high-dimensional data such as videos and images. Supervised hashing techniques can achieve a satisfactory retrieval performance, but are excessively reliant on label information, resulting in the appearance of unsupervised hashing methods. However, existing unsupervised hashing methods often fail to obtain effective similarity information from the training set; this causes a large degradation in their retrieval performance. Some pseudo label-based methods partially alleviate this problem, but are sensitive to the pre-defined number of categories. Therefore, in this paper, we mainly discuss a solution to the above-mentioned problems regarding image hashing. We propose a sparse graph based self-supervised hashing method in which a sparse graph is constructed, which not only circumvents the requirement of a predefined number of categories as compared with pseudo label-based methods, but also significantly reduces the memory demand compared with a dense graph-based method. In addition, we also exploit a self-supervised reconstruction constraint to further preserve the semantic information. These items are combined in a linear manner and optimized using an iterative strategy. Four representative datasets, including two single-label and two multi-label datasets, are employed to evaluate our method. The results, based on multiple metrics, show that our method can outperform other state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Weiwei Wang and Haofeng Zhang and Zheng Zhang and Li Liu and Ling Shao},
  doi          = {10.1016/j.ins.2020.08.092},
  journal      = {Information Sciences},
  pages        = {622-640},
  shortjournal = {Inf. Sci.},
  title        = {Sparse graph based self-supervised hashing for scalable image retrieval},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blockchain-based multi-party proof of assets with privacy
preservation. <em>ISCI</em>, <em>547</em>, 609–621. (<a
href="https://doi.org/10.1016/j.ins.2020.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are a number of requirements associated with cryptocurrency transactions, and one such requirement is to preserve the privacy in proof of assets for multiple parties. Specifically, multi-party proof of assets assures one that a large number of guarantors control sufficient assets that satisfy the lender’s predefined value, for example in credit guarantee transactions. However, privacy-preserving multi-party proof of assets for cryptocurrency transactions remains challenging to achieve. This paper introduces a novel concept of privacy-preserving multi-party proof of assets for cryptocurrency transactions, where the proof process does not disclose their cryptocurrency addresses and individual holding. We formalize both the system model and the security model, and present a concrete protocol. Finally, we show that the proposed protocol is provably secure and efficient.},
  archive      = {J_ISCI},
  author       = {Huaqun Wang and Debiao He and Kim-Kwang Raymond Choo and Xi Chen},
  doi          = {10.1016/j.ins.2020.08.050},
  journal      = {Information Sciences},
  pages        = {609-621},
  shortjournal = {Inf. Sci.},
  title        = {Blockchain-based multi-party proof of assets with privacy preservation},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time works well: Dynamic time warping based on time
weighting for time series data mining. <em>ISCI</em>, <em>547</em>,
592–608. (<a href="https://doi.org/10.1016/j.ins.2020.08.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic time warping is one of the most important similarity measurement methods for time series data mining. Owing to the different influence of various time points , an extension of dynamic time warping based on time weight analysis is proposed, where the weights of pairs of time points from two series can be automatically calculated through measuring how far the history time points are from the latest ones. The time weights of the matching pairs in the warping path obtained by dynamic time warping represent the importance of the corresponding time points and will make different contributions to the accumulated cost matrix . The hierarchical clustering results in various types of time series data , including UCI data and financial stock exchange data, demonstrate that time works wonders, and different history time points have different influence on the contribution of the minimal distance between two time series. Compared to state-of-the-art methods, the proposed technique takes the time factor into consideration and can be advantageously used for similarity measurement in time series data mining.},
  archive      = {J_ISCI},
  author       = {Hailin Li},
  doi          = {10.1016/j.ins.2020.08.089},
  journal      = {Information Sciences},
  pages        = {592-608},
  shortjournal = {Inf. Sci.},
  title        = {Time works well: Dynamic time warping based on time weighting for time series data mining},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new robust fuzzy clustering validity index for imbalanced
data sets. <em>ISCI</em>, <em>547</em>, 579–591. (<a
href="https://doi.org/10.1016/j.ins.2020.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining the number of clusters of a data set, which is usually evaluated by a clustering validity index (CVI), is a significant issue in clustering analysis. While several CVIs have been proposed, the imperfect clustering results of the fuzzy c-means (FCM) clustering algorithm on imbalanced data sets may affect their decisions. To address this problem, the impact of imperfect clustering results on the traditional CVI is first analyzed, and it is found that the distance between two imbalanced clusters becomes closer, which will subsequently impact the separation metric. Inspired by this, a new fuzzy CVI called the imbalanced index (IMI) is proposed in this paper. IMI is the ratio of the fuzzy compactness and separation metrics. The main characteristic of IMI is the new definition of the separation metric, in which the imbalance ratio of two clusters is used to enlarge the distance between their centers. IMI is then employed to evaluate the clustering results of FCM on a variety of data sets, and is compared with several well-known CVIs. The experimental results demonstrate that IMI is robust to the imperfect clustering results of FCM caused by imbalanced data distributions and achieves superior performance as compared to other CVIs.},
  archive      = {J_ISCI},
  author       = {Yun Liu and Yanfang Jiang and Tao Hou and Fu Liu},
  doi          = {10.1016/j.ins.2020.08.041},
  journal      = {Information Sciences},
  pages        = {579-591},
  shortjournal = {Inf. Sci.},
  title        = {A new robust fuzzy clustering validity index for imbalanced data sets},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding adversarial robustness via critical attacking
route. <em>ISCI</em>, <em>547</em>, 568–578. (<a
href="https://doi.org/10.1016/j.ins.2020.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are vulnerable to adversarial examples which are generated by inputs with imperceptible perturbations. Understanding adversarial robustness of DNNs has become an important issue, which would for certain result in better practical deep learning applications. To address this issue, we try to explain adversarial robustness for deep models from a new perspective of critical attacking route, which is computed by a gradient-based influence propagation strategy. Similar to rumor spreading in social networks, we believe that adversarial noises are amplified and propagated through the critical attacking route. By exploiting neurons’ influences layer by layer, we compose the critical attacking route with neurons that make the highest contributions towards model decision. In this paper, we first draw the close connection between adversarial robustness and critical attacking route, as the route makes the most non-trivial contributions to model predictions in the adversarial setting. By constraining the propagation process and node behaviors on this route, we could weaken the noise propagation and improve model robustness. Also, we find that critical attacking neurons are useful to evaluate sample adversarial hardness that images with higher stimulus are easier to be perturbed into adversarial examples.},
  archive      = {J_ISCI},
  author       = {Tianlin Li and Aishan Liu and Xianglong Liu and Yitao Xu and Chongzhi Zhang and Xiaofei Xie},
  doi          = {10.1016/j.ins.2020.08.043},
  journal      = {Information Sciences},
  pages        = {568-578},
  shortjournal = {Inf. Sci.},
  title        = {Understanding adversarial robustness via critical attacking route},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing gene expression programming based on space
partition and jump for symbolic regression. <em>ISCI</em>, <em>547</em>,
553–567. (<a href="https://doi.org/10.1016/j.ins.2020.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving a symbolic regression problem, the gene expression programming (GEP) algorithm could fall into a premature convergence which terminates the optimization process too early, and may only reach a poor local optimum. To address the premature convergence problem of GEP, we propose a novel algorithm named SPJ-GEP, which can maintain the GEP population diversity and improve the accuracy of the GEP search by allowing the population to jump efficiently between segmented subspaces. SPJ-GEP first divides the space of mathematical expressions into k subspaces that are mutually exclusive. It then creates a subspace selection method that combines the multi-armed bandit and the ∊ -greedy strategy to choose a jump subspace. In this way, the analysis is made on the population diversity and the range of the number of subspaces. The analysis results show that SPJ-GEP does not significantly increase the computational complexity of time and space than classical GEP methods. Besides, an evaluation is conducted on a set of standard SR benchmarks. The evaluation results show that the proposed SPJ-GEP keeps a higher population diversity and has an enhanced accuracy compared with three baseline GEP methods.},
  archive      = {J_ISCI},
  author       = {Qiang Lu and Shuo Zhou and Fan Tao and Jake Luo and Zhiguang Wang},
  doi          = {10.1016/j.ins.2020.08.061},
  journal      = {Information Sciences},
  pages        = {553-567},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing gene expression programming based on space partition and jump for symbolic regression},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection against randomly occurring complex attacks on
distributed state estimation. <em>ISCI</em>, <em>547</em>, 539–552. (<a
href="https://doi.org/10.1016/j.ins.2020.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of digitization and intelligence of information technology, cyber attacks tend to be much more complicated and intelligent, which can disrupt the normal system operation if no any protection mechanism is implemented. Motivated by the security problem of industrial control system , we study secure estimation problem in which sensors are exposed to hostile communication environment, where the attacker can randomly launch either DoS attacks or data integrity attacks. We design a distributed estimator equipped with a statistical learning based detector for each sensor over wireless sensor network , and derive an optimal gain for the estimator. Moreover, we investigate the relationship between false rate and the chosen confident level of the detector, we also demonstrate the influence of sliding window of the detector on the estimation performance and show the existence of an optimal scaling parameter corresponding to the best estimation performance. Finally, we prove the effectiveness and feasibility of the proposed estimator by some numerical examples.},
  archive      = {J_ISCI},
  author       = {Wen Yang and Xinting Zhang and Weijie Luo and Zongyu Zuo},
  doi          = {10.1016/j.ins.2020.08.008},
  journal      = {Information Sciences},
  pages        = {539-552},
  shortjournal = {Inf. Sci.},
  title        = {Detection against randomly occurring complex attacks on distributed state estimation},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transfer learning-based one-class dictionary learning for
recommendation data stream. <em>ISCI</em>, <em>547</em>, 526–538. (<a
href="https://doi.org/10.1016/j.ins.2020.08.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation system has attracted growing attention in machine learning and data mining . In addition, one-class learning has been proposed to build a predictive classifier mainly based on the preferred data, and has been verified to be an efficient method for recommendation system. In this paper, we propose a novel recommendation model called transfer learning-based one-class dictionary learning for recommendation data stream (DOC-SVM), which incorporates transfer learning and discriminative dictionary learning into one-class data stream learning. The proposed method can reduce the effect of the uncertain data on the classifier and transfer knowledge from the recent historical chunk to the current chunk to construct a predictive classifier for the current chunk. We then propose an iterative framework to solve the optimization function , and obtain the predictive classifier for the current chunk. Extensive experiments has been conducted and the results show that the proposed method can deliver better performance than the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Haoxin Xie and Bo Liu and Yanshan Xiao},
  doi          = {10.1016/j.ins.2020.08.091},
  journal      = {Information Sciences},
  pages        = {526-538},
  shortjournal = {Inf. Sci.},
  title        = {Transfer learning-based one-class dictionary learning for recommendation data stream},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure synchronization of stochastic complex networks
subject to deception attack with nonidentical nodes and internal
disturbance. <em>ISCI</em>, <em>547</em>, 514–525. (<a
href="https://doi.org/10.1016/j.ins.2020.08.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at exploring the mean-square bounded synchronization of clustered stochastic systems under deception attack which is a ubiquitous phenomenon in cyber-physical network. Actually, when controllers in network send controlling signal to physical plants, controller-to-actuator channel may be injected with wrong signal by malicious hackers intending to destroy the system’s performance. To describe attacker’s behavior, some random variables are introduced to describe whether the cluster’s channel is attacked or not in the controlled moment. Meanwhile, it has been proved that pinning impulsive control is effective to offset both stochastic effect and attack effect, where the nodes with bigger error will be chosen to be pinned in impulsive instants. By applying Gronwall-Bellman inequality and Lyapunov method on stochastic network , several kinds of mean-square bounded synchronization criteria based on pinning impulsive strategy are derived in terms of algebraic conditions and some reasonable assumptions. Finally, some numerical simulations are presented to illustrate the effectiveness of the theoretical results in this paper.},
  archive      = {J_ISCI},
  author       = {Jianwen Feng and Jiaming Xie and Jingyi Wang and Yi Zhao},
  doi          = {10.1016/j.ins.2020.08.085},
  journal      = {Information Sciences},
  pages        = {514-525},
  shortjournal = {Inf. Sci.},
  title        = {Secure synchronization of stochastic complex networks subject to deception attack with nonidentical nodes and internal disturbance},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal discriminative feature and dictionary learning for
image set classification. <em>ISCI</em>, <em>547</em>, 498–513. (<a
href="https://doi.org/10.1016/j.ins.2020.08.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image set classification has drawn increasing attention and it has been widely applied to many real-life domains. Due to the existence of multiple images in a set, which contain various view appearance changes, image set classification is a rather challenging task. One potential solution is to learn powerful representations from multiple images to decrease the intra-class diversity and enlarge the inter-class separation. In this paper, we propose an optimal discriminative feature and dictionary learning (ODFDL) method, which attempts to learn a feature mapping matrix and a dictionary such that in the mapped feature space the inter-class sparse reconstruction error of data is maximized and the intra-class sparse reconstruction error is minimized. This learning strategy enforces the learned sparse representations from image sets have large inter-class separation and small intra-class scatter. Furthermore, to better exploit the non-linear information of data from different image sets, we also present two non-linear ODFDL methods, termed Kernel-ODFDL and Hierarchy-ODFDL to further improve the classification performance. Experiments on five commonly used image sets exhibit that our approaches are comparable with many state-of-the-arts.},
  archive      = {J_ISCI},
  author       = {Guoqing Zhang and Junchuan Yang and Yuhui Zheng and Zhiyuan Luo and Jinglin Zhang},
  doi          = {10.1016/j.ins.2020.08.066},
  journal      = {Information Sciences},
  pages        = {498-513},
  shortjournal = {Inf. Sci.},
  title        = {Optimal discriminative feature and dictionary learning for image set classification},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Towards real-time demand-aware sequential POI
recommendation. <em>ISCI</em>, <em>547</em>, 482–497. (<a
href="https://doi.org/10.1016/j.ins.2020.08.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next point-of-interest (POI) recommendation has gained growing attention in recent years due to the emergence of location-based social networks (LBSN) services. Most existing approaches focus on learning user’s preferences to POIs from check-in records and recommend a POI to visit next given his/her previously visited POIs. However, the user’s visiting behavior is not only driven by user preferences in real-world scenarios. The real-time demand is another crucial factor to determine the user’s visiting behaviors, which is usually neglected in established approaches. In this paper, we propose a new next point-of-interest (POI) recommendation method, called DSPR, by exploring user’s preferences and real-time demand simultaneously. To model the real-time demand, different kinds of contextual information are exploited, such as absolute time, POI–POI transition time/distance, and the types of POIs. By incorporating user’s preferences, these contextual factors are further modeled and learned automatically with an attention-based recurrent neural network model to support the final next POI recommendation. Experiments on three real-world check-in datasets show that DSPR has better recommendation performance compared with many state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Honglian Wang and Peiyan Li and Yang Liu and Junming Shao},
  doi          = {10.1016/j.ins.2020.08.088},
  journal      = {Information Sciences},
  pages        = {482-497},
  shortjournal = {Inf. Sci.},
  title        = {Towards real-time demand-aware sequential POI recommendation},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered adaptive control for multiple high-speed
trains with deception attacks in bottleneck sections. <em>ISCI</em>,
<em>547</em>, 470–481. (<a
href="https://doi.org/10.1016/j.ins.2020.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an event-triggered adaptive control strategy for multiple high-speed trains (MHSTs) with deception attacks in bottleneck sections. Firstly, the high-speed trains in the bottleneck section are mapped onto the same railway line. Then, the effect of deception attacks and the state information transmitted from leader train subject to deception attacks are introduced. In order to maintain safety operation, the position and speed limitations of high-speed trains are established as state constraints. An event-triggered adaptive control strategy consisting of adaptive controller, adaption laws, and event-triggered condition is designed to realize the cooperative control for MHSTs subject to deception attacks, state and input constraints. The stability and string stability of the proposed multi-train system is proved by applying the Lyapunov function method. Finally, a simulation example is given to show the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Hui Zhao and Xue-Wu Dai},
  doi          = {10.1016/j.ins.2020.08.012},
  journal      = {Information Sciences},
  pages        = {470-481},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered adaptive control for multiple high-speed trains with deception attacks in bottleneck sections},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and analysis of a decision intelligent system based
on enzymatic numerical technology. <em>ISCI</em>, <em>547</em>, 450–469.
(<a href="https://doi.org/10.1016/j.ins.2020.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A P system is a finite, discrete and distributed model with a parallel-layered and net structure. The enzymatic numerical P system (ENPS) has enzyme-like variables that allow each membrane to host more than one production function, and it has been widely used in economics and controllers for autonomous mobile robots . Although the ENPS has shown powerful abilities in numerical calculation, as a decisional process, it had not been able to express its mechanism of evolution, and the existing P system has a limited ability to process the assigned cells in different evolutions. Furthermore, the present decision models have a limited ability to process large-scale decisional tasks. To set up the decisional P system theory and render the existing ENPS more flexible, we present a restriction enzyme to found a conditional enzymatic numerical P system. In this system, we present a series of decisional enzymes and rebuild the structures of cells to achieve a decisional mechanism. Finally, we verify the validation and efficiency of our model by simulating experiments. To the best of our knowledge, we are proposing a decisional P system for the first time, and the results show that this system is very logical and efficiently processes large-scale decisional tasks. Indeed, the conditional enzymatic numerical P system could achieve prior results more quikly by a factor of 188.28, and a decision tree based on DENPS is the 119.85 times faster than the general serial framework.},
  archive      = {J_ISCI},
  author       = {Shanchen Pang and Tong Ding and XiaoBing Mao and Neal N. Xiong},
  doi          = {10.1016/j.ins.2020.07.033},
  journal      = {Information Sciences},
  pages        = {450-469},
  shortjournal = {Inf. Sci.},
  title        = {Design and analysis of a decision intelligent system based on enzymatic numerical technology},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed approach for computing rough set approximations
of big incomplete information systems. <em>ISCI</em>, <em>547</em>,
427–449. (<a href="https://doi.org/10.1016/j.ins.2020.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The size of information gathered from real world applications today is staggering. To make matters worse, this information may also be incomplete, due to errors in measurement or lack of discipline. The two phenomena give rise to a big incomplete information system (IIS). The processing of a big IIS is difficult because of its two problems, big size and incompleteness, and the present work introduces an approach that addresses both. Specifically, we develop an efficient rough set theoretic (RST) algorithm to compute the approximation space of the IIS, which addresses the incompleteness problem. Then we distribute the computational chores of the algorithm using the MapReduce framework, which addresses the size problem. The approach is explained fully, and a detailed illustrative example is provided. For validation and performance analysis, the approach has been implemented and tested on four publicly-accessible big IISs for many metrics including sizeup, scaleup, and speedup. The experimental results attest to its validity, accuracy and efficiency. A comparison test with similar approaches shows that it has superior performance.},
  archive      = {J_ISCI},
  author       = {Ahmed Hamed and Ahmed Sobhy and Hamed Nassar},
  doi          = {10.1016/j.ins.2020.08.049},
  journal      = {Information Sciences},
  pages        = {427-449},
  shortjournal = {Inf. Sci.},
  title        = {Distributed approach for computing rough set approximations of big incomplete information systems},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An incremental density-based clustering framework using
fuzzy local clustering. <em>ISCI</em>, <em>547</em>, 404–426. (<a
href="https://doi.org/10.1016/j.ins.2020.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel incremental density-based clustering framework using the one-pass scheme, named Fuzzy Incremental Density-based Clustering (FIDC). Employing one-pass clustering in which each data point is processed once and discarded, FIDC can process large datasets with less computation time and memory, compared to its density-based clustering counterparts. Fuzzy local clustering is employed in local clusters assignment process to reduce clustering inconsistencies from one-pass clustering. To improve the clustering performance and simplify the parameter choosing process, the modified valley seeking algorithm is used to adaptively determine the outlier thresholds for generating the final clusters. FIDC can operate in both traditional and stream data clustering . The experimental results show that FIDC outperforms state-of-the-art algorithms in both clustering modes.},
  archive      = {J_ISCI},
  author       = {Sirisup Laohakiat and Vera Sa-ing},
  doi          = {10.1016/j.ins.2020.08.052},
  journal      = {Information Sciences},
  pages        = {404-426},
  shortjournal = {Inf. Sci.},
  title        = {An incremental density-based clustering framework using fuzzy local clustering},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonconvex regularizer and latent pattern based robust
regression for face recognition. <em>ISCI</em>, <em>547</em>, 384–403.
(<a href="https://doi.org/10.1016/j.ins.2020.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nuclear norm based matrix regression (NMR) approaches have yielded encouraging recognition results in the presence of image-level noise. However, NMR methods have two shortcomings. One is that test samples are directly used in the reconstruction process, and this may degrade recognition performance, especially when the samples are severely corrupted by noise. The other is that these methods exploit the nuclear norm to characterize low-rank structural information of residual images, which may lead to suboptimal solutions. To overcome these two deficiencies, we present a robust regression model that coalesces a nonconvex regularizer with a latent pattern (NRLPR). The latent pattern is essentially obtained by removing noise from a test sample, and therefore it can be closer to the reconstructed sample than the test sample. Furthermore, the nonconvex regularizer penalizes larger values less while penalizing smaller values more, accordingly, it can efficiently approximate the rank function. Additionally, we integrate the iteratively reweighted least squares method and the alternating direction method of multipliers to devise an efficient iterative algorithm (IR-ADMM) for NRLPR. Meanwhile, a nonconvex function is used for the design of the classifier. Finally, numerous experiments demonstrate the superiority of the proposed methods over state-of-the-art approaches for handling structural and mixed noise.},
  archive      = {J_ISCI},
  author       = {Xiaoshuang Sang and Hong Lu and Qinghua Zhao and Faen Zhang and Jianfeng Lu},
  doi          = {10.1016/j.ins.2020.08.016},
  journal      = {Information Sciences},
  pages        = {384-403},
  shortjournal = {Inf. Sci.},
  title        = {Nonconvex regularizer and latent pattern based robust regression for face recognition},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast human motion transfer based on a meta network.
<em>ISCI</em>, <em>547</em>, 367–383. (<a
href="https://doi.org/10.1016/j.ins.2020.08.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper proposes a new approach to the task of unsupervised human motion style transfer which transforms the style of an unlabeled input human motion into the style of another unlabeled motion sequence and preserves the behavior of the primitive motion at the same time. For supervised stylistic motion transfer task, constructing a database including a large quantity of training sample pairs is expensive and tedious for artists. Therefore, we focus on unsupervised methods . However, recent works need to retrain a network for each new character with different styles, which is a time-consuming and resource-intensive process. To tackle this problem, we utilize a meta network which builds a direct-mapping from the style motion sequence to the transformation network, namely, producing a corresponding motion transformation network in the meta network by a feed-forward propagation. The model transfers multiple styles of motion clips to different motions and generates natural stylized motions in real-time without a re-training for every style. Besides, our model can transfer styles between two movements depending on different skeletons. We also explore important features of the transfer network manifold by interpolation between the hidden states from meta network. Experiments validate the flexibility and effectiveness of our data-driven model.},
  archive      = {J_ISCI},
  author       = {Jian Pan and Huaijiang Sun and Yue Kong},
  doi          = {10.1016/j.ins.2020.08.060},
  journal      = {Information Sciences},
  pages        = {367-383},
  shortjournal = {Inf. Sci.},
  title        = {Fast human motion transfer based on a meta network},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Graph cells: Top-k structural-textual aggregated query over
information networks. <em>ISCI</em>, <em>547</em>, 354–366. (<a
href="https://doi.org/10.1016/j.ins.2020.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph OLAP aggregated analysis in information networks has been extensively studied. However, previous works have neglected to integrate the structural information into this kind of query and ignored the influence of enough textual information in graph aggregation operations. In this paper, we propose a novel OLAP query called top-k structural-textual aggregated graph cell query to analyze the information data. According to the given keywords, this query is to find top-k structural-textual aggregated graph cells in text-rich multidimensional information networks. Under the conditions of matching attribution values in a portion of dimensions, a graph cell is defined as a subgraph of the network. It only contains documents of all included vertices in this subgraph. To distinguish the importance of different graph cells, we firstly design a dominating number-based threshold testing and a flexible ranking function integrating the text similarity with the query and the structural size to obtain k most relevant graph cells. Then, we propose a new hybrid index structure and a filtering-and-verification framework, which includes an efficient search algorithm and several pruning and bounding techniques. Finally, we verify the effectiveness and efficiency of the proposed methods through extensive experiments.},
  archive      = {J_ISCI},
  author       = {Yishu Wang and Ye Yuan and Guoren Wang and Yuliang Ma},
  doi          = {10.1016/j.ins.2020.08.057},
  journal      = {Information Sciences},
  pages        = {354-366},
  shortjournal = {Inf. Sci.},
  title        = {Graph cells: Top-k structural-textual aggregated query over information networks},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive bibliometric analysis of uncertain group
decision making from 1980 to 2019. <em>ISCI</em>, <em>547</em>, 328–353.
(<a href="https://doi.org/10.1016/j.ins.2020.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertain group decision making (UGDM) has been a hot research direction over the years. In this paper, according to VOS viewer and CiteSpace, we make a comprehensive bibliometric analysis of UGDM during the last four decades, namely from 1980 to 2019. After data preprocessing , 4,887 publications related to UGDM are obtained from the Web of Science (WoS). Considering numbers, citations and cooperation of publications, general analysis is explored on the basis of bibliometric indicators at the levels of countries/regions, institutions and authors. In order to investigate the development of UGDM, we present cooperation network in the whole period of time and the dynamic networks during the four sub-periods. After that, some deep researches are conducted by bibliometric analysis , such as burst detection analysis, co-occurrence analysis, timeline view analysis and bibliographic coupling analysis. Based on which, further discussions are provided, including current challenges and possible directions. Finally, some main findings are summarized from three aspects, and the advantages and disadvantages of methods in this paper are concluded. This paper explores the hot topics and development trends of UGDM, which offers an important reference for future research.},
  archive      = {J_ISCI},
  author       = {Xinxin Wang and Zeshui Xu and Shun-Feng Su and Wei Zhou},
  doi          = {10.1016/j.ins.2020.08.036},
  journal      = {Information Sciences},
  pages        = {328-353},
  shortjournal = {Inf. Sci.},
  title        = {A comprehensive bibliometric analysis of uncertain group decision making from 1980 to 2019},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A new unified image encryption algorithm based on a lifting
transformation and chaos. <em>ISCI</em>, <em>547</em>, 307–327. (<a
href="https://doi.org/10.1016/j.ins.2020.07.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image encryption is one of the most effective means to ensure the security of image information in network communications. A new unified image encryption system with identical encryption and decryption algorithms was proposed in this paper. In this system, an external key and the Hénon map are used to generate the equivalent secret keys. Then, a kind of lifting-like transformation is employed to diffuse the image information to fulfill the image encryption. On the computer configured with i7-9750H CPU, the unified image cryptosystem realized by C# program has the encryption/decryption speed of 59 Mbps. Meanwhile the proposed cryptosystem possesses strong sensitivities of secret key, plain image and ciphered image for the maximum relative error of their test indexes is only 0.55\%. Thus the proposed can be used as a candidate scheme of network image information security.},
  archive      = {J_ISCI},
  author       = {Yong Zhang},
  doi          = {10.1016/j.ins.2020.07.058},
  journal      = {Information Sciences},
  pages        = {307-327},
  shortjournal = {Inf. Sci.},
  title        = {A new unified image encryption algorithm based on a lifting transformation and chaos},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simultaneous learning coefficient matrix and affinity graph
for multiple kernel clustering. <em>ISCI</em>, <em>547</em>, 289–306.
(<a href="https://doi.org/10.1016/j.ins.2020.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the effectiveness of handling non-linear data and avoiding kernel customization, multiple kernel clustering (MKC) has been widely investigated and achieved promising results for challenging non-linear clustering tasks. Generally, the existing MKC methods mainly consist of first learning a coefficient matrix by leveraging multiple kernel learning (MKL) and sample self-expressiveness property, and then constructing an affinity graph relying on this coefficient matrix to accomplish spectral clustering. However, the quality of the affinity matrix (graph) is largely determined by the learned coefficient matrix, thus the two independent steps are not conducive to learn an optimal affinity graph. To tackle this problem, in this paper, we propose a new MKC method that uses one-step learning scheme rather than two-step learning scheme to learn an affinity graph, termed SLMKC. Specifically, SLMKC bridges the relationship between the affinity matrix and coefficient matrix by an adaptive local structure learning strategy, so it can simultaneously learn both in a mutual promotion manner. Furthermore, a self-weighted MKL strategy is introduced to learn an optimal consensus kernel, which can avoid selecting a specific kernel function and tuning its associated parameters. Extensive experiments validate that our SLMKC outperforms the state-of-the-art MKC competitors significantly.},
  archive      = {J_ISCI},
  author       = {Zhenwen Ren and Haoyun Lei and Quansen Sun and Chao Yang},
  doi          = {10.1016/j.ins.2020.08.056},
  journal      = {Information Sciences},
  pages        = {289-306},
  shortjournal = {Inf. Sci.},
  title        = {Simultaneous learning coefficient matrix and affinity graph for multiple kernel clustering},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two-stage three-way enhanced technique for ensemble learning
in inclusive policy text classification. <em>ISCI</em>, <em>547</em>,
271–288. (<a href="https://doi.org/10.1016/j.ins.2020.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of the social economy, small and medium-sized enterprises (SMEs) play a vital role in promoting economic development. Multiple local governments in China are developing policy recommended platforms in order to help SMEs better understand the inclusive policy. However, these online platforms manually extract the key information from the inclusive policy texts, which takes a lot of time and causes low efficiency. The policy text is composed of some paragraphs and each paragraph corresponds to a topic. When we classify the paragraphs into different topics, there exists a decision risk of text misclassification . Therefore, we design two-stage based three-way enhanced technique to automatically classify these text paragraphs into the predefined categories. At the first stage, by using ensemble learning algorithms , we construct an ensemble convolution neural network (CNN) model in order to ensure the generalization ability and stability of text classification results. Meanwhile, we develop a new weight determination method to integrate the prediction results of all base classifiers according to the accuracy and classification confidence. With the help of three-way decisions (3WD), we assign the samples with poor resolution to the boundary area for secondary classification, which can reduce the decision risk. At the second stage, in order to classify the boundary region samples and improve the overall classification results , we further utilize traditional machine learning method as the secondary classifier. Finally, we develop some comparison experiments to verify our proposed method. The experimental results show that the two-stage three-way enhanced classification framework is valid and obtains a better performance. Our proposed method can effectively support the designment of policy recommended platforms and serve SMEs.},
  archive      = {J_ISCI},
  author       = {Decui Liang and Bochun Yi},
  doi          = {10.1016/j.ins.2020.08.051},
  journal      = {Information Sciences},
  pages        = {271-288},
  shortjournal = {Inf. Sci.},
  title        = {Two-stage three-way enhanced technique for ensemble learning in inclusive policy text classification},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). M-BPR: A novel approach to improving BPR for recommendation
with multi-type pair-wise preferences. <em>ISCI</em>, <em>547</em>,
255–270. (<a href="https://doi.org/10.1016/j.ins.2020.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we examine the two assumptions of the Bayesian personalized ranking (BPR), a well-known pair-wise method for one-class collaborative filtering (OCCF): (1) a user with the same degree of negative preferences for all her unrated items; and (2) a user always preferring her rated items to all her unrated items. We claim that (A1) and (A2) cause recommendation errors because they do not always hold in practice. To address these problems, we first define fine-grained multi-type pair-wise preferences (PPs), which are more sophisticated than the single-type PP used in BPR. Then, we propose a novel pair-wise approach called M-BPR, which exploits multi-type PPs together in learning users’ more detailed preferences. Furthermore, we refine M-BPR by employing the concept of item groups to reduce the uncertainty of a user’s a single item-level preference. Through extensive experiments using four real-life datasets, we demonstrate that our approach addresses the problems of the original BPR effectively and also outperforms seven state-of-the-art OCCF ( i.e. , four pair-wise and three point-wise) methods significantly.},
  archive      = {J_ISCI},
  author       = {Yeon-Chang Lee and Taeho Kim and Jaeho Choi and Xiangnan He and Sang-Wook Kim},
  doi          = {10.1016/j.ins.2020.08.027},
  journal      = {Information Sciences},
  pages        = {255-270},
  shortjournal = {Inf. Sci.},
  title        = {M-BPR: A novel approach to improving BPR for recommendation with multi-type pair-wise preferences},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Approximate nonparametric quantile regression in
reproducing kernel hilbert spaces via random projection. <em>ISCI</em>,
<em>547</em>, 244–254. (<a
href="https://doi.org/10.1016/j.ins.2020.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparametric quantile regression is a commonly used nonlinear quantile model. One general and popular approach is based on the use of kernels within a reproducing kernel Hilbert space (RKHS) framework, with the smoothing splines estimation as a special case. However, when the sample size n is large, the computational burden is heavy. Motivated by the recent advances in random projection for kernel nonparametric (mean) ridge regression (KRR), we consider an m -dimensional random projection approach for kernel quantile regression (KQR) with m ≪ n m≪n . We establish a theoretical result showing that the sketched KQR still achieves the minimax convergence rate when m is at least as large as the effective statistical dimension of the problem. Some Monte Carlo studies are carried out for illustration purposes.},
  archive      = {J_ISCI},
  author       = {Fode Zhang and Rui Li and Heng Lian},
  doi          = {10.1016/j.ins.2020.08.039},
  journal      = {Information Sciences},
  pages        = {244-254},
  shortjournal = {Inf. Sci.},
  title        = {Approximate nonparametric quantile regression in reproducing kernel hilbert spaces via random projection},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Double hierarchy hesitant fuzzy linguistic entropy-based
TODIM approach using evidential theory. <em>ISCI</em>, <em>547</em>,
223–243. (<a href="https://doi.org/10.1016/j.ins.2020.07.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Double hierarchy hesitant fuzzy linguistic term sets (DHHFLTSs) can describe hesitation more accurately and reasonably than other linguistic representation models by adding a second hierarchy hesitant fuzzy linguistic term set. The Dempster–Shafer evidence theory (DSET) can minimize the loss of evaluation information in denoting and fusing uncertain information, and TODIM (an acronym in Portuguese for interactive and multi-criteria decision making) can consider the loss aversion behavior of decision makers (DMs). Considering their unique advantages, in this study, we propose a novel multiple criteria group decision-making method based on DSET and TODIM under the DHHFLTSs. First, we improve the cumulative functions and distance measure of DHHFLTSs. Next, we apply DSET to fuse double hierarchy hesitant fuzzy linguistic (DHHFL) information provided by a group of experts and obtain an evidence matrix consisting of belief degrees and DHHFLTSs. Then, we use the TODIM method to address the evidence matrix based on improved cumulative functions and distance measures to obtain the final ranking results. Finally, a weight determination model is constructed based on information entropy in the scenario of completely unknown weights. The newly proposed method reduces the loss of evaluation information and also considers the loss aversion behavior of DMs. Furthermore, an application example of a postgraduate course evaluation is used to demonstrate the effectiveness and rationality of the proposed method. Additionally, we compare the proposed method with other existing methods to further demonstrate the advantages of the proposed method.},
  archive      = {J_ISCI},
  author       = {Peide Liu and Mengjiao Shen and Fei Teng and Baoying Zhu and Lili Rong and Yushui Geng},
  doi          = {10.1016/j.ins.2020.07.062},
  journal      = {Information Sciences},
  pages        = {223-243},
  shortjournal = {Inf. Sci.},
  title        = {Double hierarchy hesitant fuzzy linguistic entropy-based TODIM approach using evidential theory},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EARC: Evidential association rule-based classification.
<em>ISCI</em>, <em>547</em>, 202–222. (<a
href="https://doi.org/10.1016/j.ins.2020.07.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extension of classical fuzzy rule-based classification, the belief rule-based classification is a promising technique for handling hybrid information with multiple uncertainties in real-world applications. However, the antecedent structure of each resultant rule is fixed and hence may cause overfitting in small instance cases, while some resultant rules are also redundant due to the similarity of neighboring rules. Here, an evidential association rule-based classification method, called EARC, is developed by integrating evidential association rule mining and classification to obtain an accurate and compact classification model . First, new measures of evidential support and confidence are proposed to represent rule interestingness. Then, a three-stage rule mining algorithm is developed to generate a set of evidential classification association rules, including Apriori-based frequent fuzzy itemsets searching for discovering all possible antecedents, evidential consequents deriving in the belief function framework, and reliable rule extracting with measures of evidential support and confidence. Further, to make the classification efficient, the procedures of rule prescreening and rule selection are presented for deleting redundant rules and obtaining an accurate classifier, respectively. At last, an improved belief reasoning process is presented for classifying each input instance by combining the top K activated rules. Experimental results based on real-world datasets demonstrate the superiority of the proposed method on classification accuracy and interpretability .},
  archive      = {J_ISCI},
  author       = {Xiaojiao Geng and Yan Liang and Lianmeng Jiao},
  doi          = {10.1016/j.ins.2020.07.067},
  journal      = {Information Sciences},
  pages        = {202-222},
  shortjournal = {Inf. Sci.},
  title        = {EARC: Evidential association rule-based classification},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). D.c. Programming for sparse proximal support vector
machines. <em>ISCI</em>, <em>547</em>, 187–201. (<a
href="https://doi.org/10.1016/j.ins.2020.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Proximal support vector machine (PSVM), as a variant of support vector machine (SVM), is to generate a pair of non-parallel hyperplanes for classification. Although PSVM is one of the powerful classification tools, its ability on feature selection is still weak. To overcome this defect, we introduce ℓ 0 ℓ0 -norm regularization in PSVM which enables PSVM to select important features and remove redundant features simultaneously for classification. This PSVM is called as a sparse proximal support vector machine (SPSVM). Due to the presence of ℓ 0 ℓ0 -norm, the resulting optimization problem of SPSVM is neither convex nor smooth and thus, is difficult to solve. In this paper, we introduce a continuous nonconvex function to approximate ℓ 0 ℓ0 -norm, and propose a novel difference of convex functions algorithms (DCA) to solve SPSVM. The main merit of the proposed method is that all subproblems are smooth and admit closed form solutions. The effectiveness of the proposed method is illustrated by theoretical analysis as well as some numerical experiments on both simulation datasets and real world datasets.},
  archive      = {J_ISCI},
  author       = {Guoquan Li and Linxi Yang and Zhiyou Wu and Changzhi Wu},
  doi          = {10.1016/j.ins.2020.08.038},
  journal      = {Information Sciences},
  pages        = {187-201},
  shortjournal = {Inf. Sci.},
  title        = {D.C. programming for sparse proximal support vector machines},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaboratively augmented UIP – filtered RIP with relevancy
mapping for personalization of web search. <em>ISCI</em>, <em>547</em>,
163–186. (<a href="https://doi.org/10.1016/j.ins.2020.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized information retrieval has become more crucial and challenging in today’s time, as every user is demanding information according to their own perspectives. To achieve personalization, this paper proposes a methodology with a focus on the selection of an effective composition corresponding to various supporting modules of a personalization methodology. Collaborative tagging can be quite helpful in constructing User Interest Profile (UIP) and Resource Illustration Profile (RIP). The proposed methodology also focuses on UIP augmentation using multiple strategies; and a novel approach has also been designed to handle outlier tags which caused ambiguity in collective RIP. Even a good UIP and RIP alone cannot create an efficient personalization methodology; they also require a suitable mapping with user’s query requirement. Therefore, in the proposed methodology, the fuzzy satisfaction requirement-based novel mapping functions have been designed to measure query relevance score and user interest relevance score for a web resource. These scores have been further used to calculate the post-relevance score of a web resource after a suitable trade-off. Experiments using the del.icio.us dataset show that the proposed methodology has outperformed each and every baseline by a considerable margin.},
  archive      = {J_ISCI},
  author       = {Shubham Goel and Ravinder Kumar},
  doi          = {10.1016/j.ins.2020.08.001},
  journal      = {Information Sciences},
  pages        = {163-186},
  shortjournal = {Inf. Sci.},
  title        = {Collaboratively augmented UIP – filtered RIP with relevancy mapping for personalization of web search},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GGA: A modified genetic algorithm with gradient-based local
search for solving constrained optimization problems. <em>ISCI</em>,
<em>547</em>, 136–162. (<a
href="https://doi.org/10.1016/j.ins.2020.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last few decades, genetic algorithms (GAs) demonstrated to be an effective approach for solving real-world optimization problems . However, it is known that, in presence of a huge solution space and many local optima, GAs cannot guarantee the achievement of global optimality . In this work, in order to make GAs more effective in finding the global optimal solution , we propose a hybrid GA which combines the classical genetic mechanisms with the gradient-descent (GD) technique for local searching and constraints management. The basic idea is to exploit the GD capability in finding local optima to refine search space exploration and to place individuals in areas that are more favorable for achieving convergence. This confers to GAs the capability of escaping from the discovered local optima, by progressively moving towards the global solution. Experimental results on a set of test problems from well-known benchmarks showed that our proposal is competitive with other more complex and notable approaches, in terms of solution precision as well as reduced number of individuals and generations.},
  archive      = {J_ISCI},
  author       = {Gianni D’Angelo and Francesco Palmieri},
  doi          = {10.1016/j.ins.2020.08.040},
  journal      = {Information Sciences},
  pages        = {136-162},
  shortjournal = {Inf. Sci.},
  title        = {GGA: A modified genetic algorithm with gradient-based local search for solving constrained optimization problems},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Transfer learning based intrusion detection scheme for
internet of vehicles. <em>ISCI</em>, <em>547</em>, 119–135. (<a
href="https://doi.org/10.1016/j.ins.2020.05.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new type of network, the types of attack in the Internet of Vehicles (IoV) are constantly emerging and changing. Consequently, the machine learning based intrusion detection model has to update to cope with new attacks. However, existing machine learning based IoV intrusion detection schemes require large amounts of labeled data to complete model updates. For new attacks, the IoV cloud is also difficult to identify in time, which requires a lot of labor and time cost in IoV. To solve above issue, this paper employs transfer learning and proposes two model update schemes based on whether the IoV cloud can timely provide a small amount of labeled data for a new attack. The first one is the cloud-assisted update scheme where the IoV cloud can provide a small amount of data. And the second one is the local update scheme where the IoV cloud cannot provide any labeled data timely. In this paper, the local update scheme obtains pseudo label of the unlabeled data in new attacks via pre-classifies and uses the pseudo-labeled data for multiple rounds of transfer learning . Then the vehicle can complete the update without obtaining any labeled data through the IoV cloud. The experimental results show that compared with the existing method, our two schemes have improved the detection accuracy by at least 23\%.},
  archive      = {J_ISCI},
  author       = {Xinghua Li and Zhongyuan Hu and Mengfan Xu and Yunwei Wang and Jianfeng Ma},
  doi          = {10.1016/j.ins.2020.05.130},
  journal      = {Information Sciences},
  pages        = {119-135},
  shortjournal = {Inf. Sci.},
  title        = {Transfer learning based intrusion detection scheme for internet of vehicles},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DFM: A parameter-shared deep fused model for knowledge base
question answering. <em>ISCI</em>, <em>547</em>, 103–118. (<a
href="https://doi.org/10.1016/j.ins.2020.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, Knowledge Base Question Answering (KBQA) is an important research topic in the fields of information retrieval (IR) and natural language processing (NLP). The most common questions asked on the Web are simple questions, which can be answered by a single relational fact in a knowledge base (KB). However, answering simple questions automatically remains a challenging task in the IR and NLP research communities. Based on a review of various studies and a detailed analysis, we surmise that these challenges are primarily related to the following concerns: (1) how to effectively access a large-scale KB; and (2) how to effectively reduce the gap between NL questions and the structured semantics in a KB. Most previous studies have considered these as separate and independent subtasks, subject detection and predicate matching. Here, we propose a deep fused model that combines subject detection and predicate matching under a unified framework. Specifically, we employ a subject detection model to recognize the subject entity in a question, and a multilevel semantic model to learn the semantic representations for questions and predicates. These models share parameters, and can be trained jointly. We evaluated the proposed method on both English and Chinese KBQA datasets. The experimental results demonstrate that the proposed approach significantly outperforms state-of-the-art systems when applied to both datasets.},
  archive      = {J_ISCI},
  author       = {Guangyou Zhou and Zhiwen Xie and Zongfu Yu and Jimmy Xiangji Huang},
  doi          = {10.1016/j.ins.2020.08.037},
  journal      = {Information Sciences},
  pages        = {103-118},
  shortjournal = {Inf. Sci.},
  title        = {DFM: A parameter-shared deep fused model for knowledge base question answering},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed adaptive security consensus control for a class
of multi-agent systems under network decay and intermittent attacks.
<em>ISCI</em>, <em>547</em>, 88–102. (<a
href="https://doi.org/10.1016/j.ins.2020.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the distributed adaptive security consensus control problem of a class of nonlinear multi-agent systems subject to network decay and intermittent attacks. The network communication is decayed and intermittently attacked by attackers, which may result in loss of transmission effectiveness and communication outage, respectively. A distributed adaptive consensus control strategy is firstly developed to ensure bounded consensus of the nonlinear multi-agent systems in the case of normal networks. Then, a novel adaptive neural network (NN)-based observer is proposed to observe decayed and intermittent transmission signals of networks in such a way to recover the original signals. Based on the adaptive control and NN-based observer schemes, distributed security control strategies are developed to achieve the bounded consensus of the multi-agent systems under the influence of network decay and intermittent attacks. The efficiency of the designed adaptive security control strategies are illustrated by a multiple coupled nonlinear forced pendulum system .},
  archive      = {J_ISCI},
  author       = {Xiaozheng Jin and Shaoyu Lü and Chao Deng and Mohammed Chadli},
  doi          = {10.1016/j.ins.2020.08.013},
  journal      = {Information Sciences},
  pages        = {88-102},
  shortjournal = {Inf. Sci.},
  title        = {Distributed adaptive security consensus control for a class of multi-agent systems under network decay and intermittent attacks},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning a consensus affinity matrix for multi-view
clustering via subspaces merging on grassmann manifold. <em>ISCI</em>,
<em>547</em>, 68–87. (<a
href="https://doi.org/10.1016/j.ins.2020.07.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrative multi-view subspace clustering aims to partition observed samples into underlying clusters through fusing representative subspace information from different views into a latent space. The clustering performance relies on the accuracy of sample affinity measurement. However, existing approaches leverage the subspace representation of each view and overlook the learning of appropriate sample affinities. This paper proposes to learn a consensus affinity directly by merging subspace representations of different views on a Grassmann manifold while maintaining their geometric structures across these views. The proposed method not only preserves the structure of the most informative individual view, but also discovers a latent common structure across all views. The associated constrained optimization problem is solved using the alternating direction method of multipliers . Extensive experiments on synthetic and real-world datasets show that the proposed method outperforms several state-of-the-art multi-view subspace clustering methods . The affinity matrix obtained by our method can extract highly representative and latent common information to enhance the clustering performance.},
  archive      = {J_ISCI},
  author       = {Wentao Rong and Enhong Zhuo and Hong Peng and Jiazhou Chen and Haiyan Wang and Chu Han and Hongmin Cai},
  doi          = {10.1016/j.ins.2020.07.059},
  journal      = {Information Sciences},
  pages        = {68-87},
  shortjournal = {Inf. Sci.},
  title        = {Learning a consensus affinity matrix for multi-view clustering via subspaces merging on grassmann manifold},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Distributed set-membership filtering for discrete-time
systems subject to denial-of-service attacks and fading measurements: A
zonotopic approach. <em>ISCI</em>, <em>547</em>, 49–67. (<a
href="https://doi.org/10.1016/j.ins.2020.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A distributed set-membership filter is designed for a kind of systems with unknown but bounded (UBB) noises over wireless sensor networks . The Denial-of-Service (DoS) attacks and the fading effects on the sensor measurements are taken into account simultaneously. To reveal the fluctuations of network environment, the coefficients of the fading channels are described by uncertain variables which take values over an interval. The objective of this paper is to estimate the desired sets involving actual states of the plant by implementing the consistency tests among the state sets, the measured outputs and the neighbor information. A recursive scheme on zonotopes involving the real system state is established in light of the zonotopic method, where an outer approximation of the exact uncertain set is performed. Moreover, based on the proposed outer approximation minimization criterion, an optimization issue is proposed to seek the parameters of the intersection zonotope. Finally, two illustrative simulations are utilised to state the feasibility of the proposed filter.},
  archive      = {J_ISCI},
  author       = {Xin Li and Guoliang Wei and Licheng Wang},
  doi          = {10.1016/j.ins.2020.07.041},
  journal      = {Information Sciences},
  pages        = {49-67},
  shortjournal = {Inf. Sci.},
  title        = {Distributed set-membership filtering for discrete-time systems subject to denial-of-service attacks and fading measurements: A zonotopic approach},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A theory of incremental compression. <em>ISCI</em>,
<em>547</em>, 28–48. (<a
href="https://doi.org/10.1016/j.ins.2020.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ability to find short representations, i.e. to compress data, is crucial for many intelligent systems. We present a theory of incremental compression showing that arbitrary data strings, that can be described by a set of features, can be compressed by searching for those features incrementally, which results in a partition of the information content of the string into a complete set of pairwise independent pieces. The description length of this partition turns out to be close to optimal in terms of the Kolmogorov complexity of the string. Exploiting this decomposition, we introduce ALICE – a computable ALgorithm for Incremental ComprEssion – and derive an expression for its time complexity. Finally, we show that our concept of a feature is closely related to Martin-Löf randomness tests, thereby formalizing the meaning of “property” for computable objects.},
  archive      = {J_ISCI},
  author       = {Arthur Franz and Oleksandr Antonenko and Roman Soletskyi},
  doi          = {10.1016/j.ins.2020.08.035},
  journal      = {Information Sciences},
  pages        = {28-48},
  shortjournal = {Inf. Sci.},
  title        = {A theory of incremental compression},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weights for short quartic boolean functions. <em>ISCI</em>,
<em>547</em>, 18–27. (<a
href="https://doi.org/10.1016/j.ins.2020.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Boolean function in n variables is 2-rotation symmetric if it is invariant under even powers of ρ ( x 1 , … , x n ) = ( x 2 , … , x n , x 1 ) ρ(x1,…,xn)=(x2,…,xn,x1) , but not under the first power (ordinary rotation symmetry); we call such a function a 2-function. A 2-function is called monomial rotation symmetric (MRS) if it is generated by applying powers of ρ 2 ρ2 to a single monomial . If the quartic MRS 2-function in 2 n 2n variables has a monomial x 1 x q x r x s x1xqxrxs , then we use the notation 2 - ( 1 , q , r , s ) 2 n 2-(1,q,r,s)2n for the function. A detailed theory of equivalence of quartic MRS 2-functions in 2 n 2n variables was given in a 2020 paper by Cusick, Cheon and Dougan. This theory divides naturally into two classes, called mf 1 mf1 and mf 2 mf2 in the paper. Next to describing the equivalence classes, the second major problem is giving details of the linear recursions that the Hamming weights for any sequence of functions 2 - ( 1 , q , r , s ) 2 n 2-(1,q,r,s)2n (with q q&amp;lt;r&amp;lt;s , say), n = s , s + 1 , … n=s,s+1,… can be shown to satisfy. This problem was solved for the mf 1 mf1 case only in the 2020 paper. In this paper the problem for the mf 2 mf2 case is solved, using new ideas about short functions, as defined in this paper. These short functions are also of independent interest, and further results about them are in the paper.},
  archive      = {J_ISCI},
  author       = {Thomas W. Cusick and Younhwan Cheon},
  doi          = {10.1016/j.ins.2020.07.019},
  journal      = {Information Sciences},
  pages        = {18-27},
  shortjournal = {Inf. Sci.},
  title        = {Weights for short quartic boolean functions},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reference-point-based multi-objective optimization algorithm
with opposition-based voting scheme for multi-label feature selection.
<em>ISCI</em>, <em>547</em>, 1–17. (<a
href="https://doi.org/10.1016/j.ins.2020.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification is a machine learning task to construct a model for assigning an entity in the dataset to two or more class labels. In order to improve the performance of multi-label classification, a multi-objective feature selection algorithm has been proposed in this paper. Feature selection as a preprocessing task for Multi-label classification problems aims to choose a subset of relevant features. Selecting a small number of high-quality features decreases the computational cost and at the same time maximizes the classification performance. However extreme decreasing the number of features causes the failure of classification. As a result, feature selection has two conflicting objectives, namely, minimizing the classification error and minimizing the number of selected features. This paper proposes a multi-objective optimization algorithm to tackle the multi-label feature selection. The task is to find a set of solutions (a subset of features) in a sophisticated large-scale search space using a reference-based multi-objective optimization method. The proposed algorithm utilizes an opposition-based binary operator to generate more diverse solutions. Injection of extreme point of the Pareto-front is another component of the algorithm which aims to find feature subsets with less classification error . The proposed method is compared with two other existing methods on eight multi-label benchmark datasets. The experimental results show that the proposed method outperforms existing algorithms in terms of various multi-objective evaluation measures, such as Hyper-volume indicator, Pure diversity, Two-set coverage, and Pareto-front proportional contribution. The proposed method leads to get a set of well-distributed trade-off solutions which reach less classification error in comparing with competitors, even with the fewer number of features.},
  archive      = {J_ISCI},
  author       = {Azam Asilian Bidgoli and Hossein Ebrahimpour-Komleh and Shahryar Rahnamayan},
  doi          = {10.1016/j.ins.2020.08.004},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Reference-point-based multi-objective optimization algorithm with opposition-based voting scheme for multi-label feature selection},
  volume       = {547},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient single-pair all-shortest-path query processing for
massive dynamic networks. <em>ISCI</em>, <em>546</em>, 1306–1327. (<a
href="https://doi.org/10.1016/j.ins.2020.08.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The single-pair all-shortest-path problem is to find all possible shortest paths, given a single source-destination pair in a graph. Due to the lack of efficient algorithms for single-pair all-shortest-path problem, many applications used diverse types of modifications to the existing shortest-path algorithms such as Dijkstra’s algorithm. Such approaches can facilitate the analysis of medium-sized static networks, but the heavy computational cost impedes their use for massive and dynamic real-world networks. In this paper, we present a novel single-pair all-shortest-path algorithm, which performs well on massive networks as well as dynamic networks. The efficiency of our algorithm stems from novel 2-hop label-based query processing on large-size networks. For dynamic networks, we also demonstrate how to incrementally maintain all shortest paths in 2-hop labels, which allows our algorithm to handle the topological changes of dynamic networks such as insertion or deletion of edges. We carried out experiments on real-world large datasets, and the results confirms the effectiveness of our algorithms for the single-pair all-shortest-path computation and the incremental maintenance of 2-hop labels.},
  archive      = {J_ISCI},
  author       = {Sun Geol Baek and Sungkil Lee and Young Ik Eom},
  doi          = {10.1016/j.ins.2020.08.111},
  journal      = {Information Sciences},
  pages        = {1306-1327},
  shortjournal = {Inf. Sci.},
  title        = {Efficient single-pair all-shortest-path query processing for massive dynamic networks},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attribute based diversification of seeds for targeted
influence maximization. <em>ISCI</em>, <em>546</em>, 1273–1305. (<a
href="https://doi.org/10.1016/j.ins.2020.08.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Embedding diversity into knowledge discovery is important: the patterns mined will be more novel, more meaningful, and broader. Surprisingly, in the classic problem of influence maximization in social networks, relatively little study has been devoted to diversity and its integration into the objective function of an influence maximization method. In this work, we propose the integration of a categorical-based notion of seed diversity into the objective function of a targeted influence maximization problem. In this respect, we assume that the users of a social network are associated with a categorical dataset where each tuple expresses the profile of a user according to a predefined schema of categorical attributes. Upon this assumption, we design a class of monotone submodular functions specifically conceived for determining the diversity of the subset of categorical tuples associated with the seed users to be discovered. This allows us to develop an efficient approximate method, with a constant-factor guarantee of optimality . More precisely, we formulate the attribute-based diversity-sensitive targeted influence maximization problem under the state-of-the-art reverse influence sampling framework, and we develop a method, dubbed ADITUM , that ensures a ∊ ( 1 - 1 / e - ∊ ) (1-1/e-∊) -approximate solution under the general triggering diffusion model . Extensive experimental evaluation based on real-world networks as well as synthetically generated data has shown the meaningfulness and uniqueness of our proposed class of set diversity functions and of the ADITUM algorithm, also in comparison with methods that exploit numerical-attribute-based diversity and topology-driven diversity in influence maximization.},
  archive      = {J_ISCI},
  author       = {Antonio Caliò and Andrea Tagarelli},
  doi          = {10.1016/j.ins.2020.08.093},
  journal      = {Information Sciences},
  pages        = {1273-1305},
  shortjournal = {Inf. Sci.},
  title        = {Attribute based diversification of seeds for targeted influence maximization},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature grouping and selection: A graph-based approach.
<em>ISCI</em>, <em>546</em>, 1256–1272. (<a
href="https://doi.org/10.1016/j.ins.2020.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current feature selection techniques are focused on the incremental inclusion or exclusion of single individual features with respect to the candidate feature subset(s). The use of such approaches, where only the individual inclusion/exclusion of features is considered, means that information such as the collaborative contribution or correlation between features may be lost. The result is that the final selected feature subset may contain high levels of inter-feature redundancy, assuming that the key information embedded in the original feature set can still be retained. To address this problem, a general framework based on graph processing and three-way mutual information metrics is proposed in this paper that works by clustering similar features into groups, from which representative features are then drawn. Two different feature selection techniques based on this framework are presented: one by straightforward selection of representative features from the resulting feature groups and the other via a music-inspired metaheuristic search. Comparative experimental evaluation against traditional feature selection techniques over a diverse range of 20 benchmark datasets demonstrates the efficacy of the proposed approach. With these implementations, significant performance gains can be made in terms of classification accuracy in general and dimensionality reduction in particular while retaining feature semantics and considerably lessening the redundancy in the returned feature subsets.},
  archive      = {J_ISCI},
  author       = {Ling Zheng and Fei Chao and Neil Mac Parthaláin and Defu Zhang and Qiang Shen},
  doi          = {10.1016/j.ins.2020.09.022},
  journal      = {Information Sciences},
  pages        = {1256-1272},
  shortjournal = {Inf. Sci.},
  title        = {Feature grouping and selection: A graph-based approach},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of fuzzy system-fuzzy neural network-backstepping
control for complex robot system. <em>ISCI</em>, <em>546</em>,
1230–1255. (<a href="https://doi.org/10.1016/j.ins.2020.08.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the control problem of complex robot system with uncertainties and disturbances is addressed. Fuzzy system-fuzzy neural network-backstepping control (FS-FNN-BSC) system is proposed, which can guarantee the accurate, stable and efficient control. First, the general dynamics model of robot is introduced briefly. Then, the design procedure of backstepping control (BSC) technique is presented, to make the best of the advantages of fuzzy system (FS) and fuzzy neural network (FNN) and compromise the accuracy and efficiency, the FS is adopted to approximate the modeling information, and the FNN is utilized to approximate and predict the non-modeling information, and the FS-FNN-BSC system is constructed. Moreover, based on the Lyapunov stability theorem , the stability of the FS-FNN-BSC is proved. To illustrate the correctness, practicality and generality of the proposed control method , the FS-FNN-BSC system is applied to the series robot (KUKA robot) and the parallel robot (Delta robot). And the superiority of the proposed FS-FNN-BSC strategy is highlighted by quantitative comparison with the existing intelligent control methods.},
  archive      = {J_ISCI},
  author       = {Kunming Zheng and Qiuju Zhang and Youmin Hu and Bo Wu},
  doi          = {10.1016/j.ins.2020.08.110},
  journal      = {Information Sciences},
  pages        = {1230-1255},
  shortjournal = {Inf. Sci.},
  title        = {Design of fuzzy system-fuzzy neural network-backstepping control for complex robot system},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discovering high utility-occupancy patterns from uncertain
data. <em>ISCI</em>, <em>546</em>, 1208–1229. (<a
href="https://doi.org/10.1016/j.ins.2020.10.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely known that there is a lot of useful information hidden in big data, leading to a new saying that “data is money.” Thus, it is prevalent for individuals to mine crucial information for utilization in many real-world applications. In the past, studies have considered frequency. Unfortunately, doing so neglects other aspects, such as utility, interest, or risk. Thus, it is sensible to discover high-utility itemsets (HUIs) in transaction databases while utilizing not only the quantity but also the predefined utility. To find patterns that can represent the supporting transaction, a recent study was conducted to mine high utility-occupancy patterns whose contribution to the utility of the entire transaction is greater than a certain value. Moreover, in realistic applications, patterns may not exist in transactions but be connected to an existence probability . In this paper, a novel algorithm, called H igh- U tility- O ccupancy P attern M ining in U ncertain databases (UHUOPM), is proposed. The patterns found by the algorithm are called P otential H igh U tility O ccupancy P atterns (PHUOPs). This algorithm divides user preferences into three factors, including support, probability , and utility occupancy. To reduce memory cost and time consumption and to prune the search space in the algorithm as mentioned above, probability-utility-occupancy list (PUO-list) and probability-frequency-utility table (PFU-table) are used, which assist in providing the downward closure property. Furthermore, an original tree structure , called support count tree (SC-tree), is constructed as the search space of the algorithm. Finally, substantial experiments were conducted to evaluate the performance of proposed UHUOPM algorithm on both real-life and synthetic datasets , particularly in terms of effectiveness and efficiency.},
  archive      = {J_ISCI},
  author       = {Chien-Ming Chen and Lili Chen and Wensheng Gan and Lina Qiu and Weiping Ding},
  doi          = {10.1016/j.ins.2020.10.001},
  journal      = {Information Sciences},
  pages        = {1208-1229},
  shortjournal = {Inf. Sci.},
  title        = {Discovering high utility-occupancy patterns from uncertain data},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A performance based method for information acquisition in
engineering design under multi-parameter uncertainty. <em>ISCI</em>,
<em>546</em>, 1186–1207. (<a
href="https://doi.org/10.1016/j.ins.2020.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty pertaining to multiple parameters is a critical issue in designing complex systems. Whether or not to acquire more information to reduce uncertainty, and how to acquire information are the meta -level decisions to be made. Key challenges in making such decisions are that there are multiple information sources to choose from, and the cost of information as well as its effects on the overall design utility are different. To address these challenges, a performance-based stepwise information acquisition method is proposed. In the proposed method, the utility-based compromise Decision Support Problem construct is used to formulate design decisions to maximize the overall utility. For meta -level decisions, a performance index is developed for selecting the most appropriate information in each acquisition trial. The index is an integration of the improvement potential of the overall utility, the sensitivity of each ranged parameter, and the cost of the acquired information. Advantages of this proposed method are: 1) sensitivity-efficiency ensures that acquired information is invested on the critical parameters which avoids ineffective information acquisition ; 2) cost-efficiency ensures that every acquisition is cost-efficient which avoids budget overruns. The efficacy of this method is demonstrated using the design of a hot rod rolling process. It is shown in the results that the performance-based method leads to an 8–45\% larger drop of improvement potential compared to the random method.},
  archive      = {J_ISCI},
  author       = {Zhenjun Ming and Anand Balu Nellippallil and Guoxin Wang and Yan Yan and Janet K. Allen and Farrokh Mistree},
  doi          = {10.1016/j.ins.2020.09.034},
  journal      = {Information Sciences},
  pages        = {1186-1207},
  shortjournal = {Inf. Sci.},
  title        = {A performance based method for information acquisition in engineering design under multi-parameter uncertainty},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recommender systems based on generative adversarial
networks: A problem-driven perspective. <em>ISCI</em>, <em>546</em>,
1166–1185. (<a href="https://doi.org/10.1016/j.ins.2020.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems (RS) now play a very important role in the online lives of people as they serve as personalized filters for users to find relevant items from a sea of options. Owing to their effectiveness, RS have been widely employed in our daily life. However, despite their empirical successes, these systems still suffer from two limitations: data noise and data sparsity . In recent years, generative adversarial networks (GANs) have garnered increased interest in many fields due to their strong capacity to learn complex real data distributions. Their abilities to enhance RS by tackling the above challenges have also been demonstrated in numerous studies. In general, two lines of research have been conducted, and their common ideas can be summarized as follows: (1) for the data noise issue, adversarial perturbations and adversarial sampling-based training often serve as a solution; (2) for the data sparsity issue, data augmentation—implemented by capturing the distribution of real data under the minimax framework—is the primary coping strategy. To gain a comprehensive understanding of these research efforts, we review the corresponding studies and models, organizing them from a problem-driven perspective. More specifically, we propose a taxonomy of these models, along with their detailed descriptions and advantages. Finally, we elaborate on several open issues and current trends in GAN-based RS.},
  archive      = {J_ISCI},
  author       = {Min Gao and Junwei Zhang and Junliang Yu and Jundong Li and Junhao Wen and Qingyu Xiong},
  doi          = {10.1016/j.ins.2020.09.013},
  journal      = {Information Sciences},
  pages        = {1166-1185},
  shortjournal = {Inf. Sci.},
  title        = {Recommender systems based on generative adversarial networks: A problem-driven perspective},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Preference-inspired coevolutionary algorithm with active
diversity strategy for multi-objective multi-modal optimization.
<em>ISCI</em>, <em>546</em>, 1148–1165. (<a
href="https://doi.org/10.1016/j.ins.2020.09.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-objective multi-modal optimization problems have recently received increasing attention in the field of evolutionary computation. Addressing such problems is not easy for existing evolutionary multi-objective algorithms (EMOAs) since they require finding solutions with good convergence and diversity in both objective and decision spaces. This study therefore proposes a new algorithm, namely, the preference-inspired coevolutionary algorithm (PICEAg) with an active diversity strategy, to deal with multi-objective multi-modal optimization problems. The proposed algorithm, denoted as MMPICEAg, adopts the popular coevolutionary framework of PICEAg and introduces a diversity-aware fitness assignment and a double-diversity archive update strategy to promote diversity in objective and decision spaces simultaneously. The performance of MMPICEAg is compared with that of three general EMOAs as well as four state-of-the-art multi-modal EMOAs. The comparison results on three sets of widely used benchmarks clearly demonstrate the effectiveness of MMPICEAg for multi-objective multi-modal optimization.},
  archive      = {J_ISCI},
  author       = {Rui Wang and Wubin Ma and Mao Tan and Guohua Wu and Ling Wang and Dunwei Gong and Jian Xiong},
  doi          = {10.1016/j.ins.2020.09.075},
  journal      = {Information Sciences},
  pages        = {1148-1165},
  shortjournal = {Inf. Sci.},
  title        = {Preference-inspired coevolutionary algorithm with active diversity strategy for multi-objective multi-modal optimization},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Fuzzy factorization machine. <em>ISCI</em>, <em>546</em>,
1135–1147. (<a href="https://doi.org/10.1016/j.ins.2020.09.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rational and accurate classification cannot be achieved without considering both the historical information and domain knowledge. We propose fuzzy factorization machine (fuzzy FM) to integrate fuzzy set theory and factorization machine techniques for knowledge-enhanced classification. Each instance is assigned a membership through experts&#39; estimations, and the instance’s contribution to the objective function is weighted by its membership instead of the equal penalty in the standard FM. By adopting differentiated weighting strategies, we propose two variants of fuzzy FM: unilaterally weighted fuzzy FM (UFFM) and bilaterally weighted fuzzy FM (BFFM). In BFFM, each instance may not be fully assigned to one of two classes for better classification of imbalanced data, while in UFFM, each instance can only be assigned to one class. A set of membership generation approaches is summarized to quantify experts’ prior estimations. We introduce solving methods based on stochastic gradient descent for UFFM and BFFM. Experiments on real credit datasets demonstrate that the proposed fuzzy FM models can yield better rational classification than previous baselines (including the standard FM). The proposed fuzzy FM is a generic machine learning framework that can be applied to various rational classification tasks.},
  archive      = {J_ISCI},
  author       = {Jiandong Zhou and Qingpeng Zhang and Xiang Li},
  doi          = {10.1016/j.ins.2020.09.067},
  journal      = {Information Sciences},
  pages        = {1135-1147},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy factorization machine},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). LAQP: Learning-based approximate query processing.
<em>ISCI</em>, <em>546</em>, 1113–1134. (<a
href="https://doi.org/10.1016/j.ins.2020.09.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The querying on big data is a challenging task due to the rapid growth of data amount. Approximate query processing (AQP) is a way to meet the requirement of fast response. In this paper, we propose a learning-based AQP method called the LAQP. The LAQP builds an error model learned from the historical queries to predict the sampling-based estimation error of each new query. It makes a combination of the sampling-based AQP, the pre-computed aggregations and the learned error model to provide high-accurate query estimations with a small off-line sample. The experimental results demonstrated that our LAQP outperforms the sampling-based AQP, the pre-aggregation-based AQP and the most recent learning-based AQP method.},
  archive      = {J_ISCI},
  author       = {Meifan Zhang and Hongzhi Wang},
  doi          = {10.1016/j.ins.2020.09.070},
  journal      = {Information Sciences},
  pages        = {1113-1134},
  shortjournal = {Inf. Sci.},
  title        = {LAQP: Learning-based approximate query processing},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing a large and unobtainable relationship graph using
a streaming activity graph. <em>ISCI</em>, <em>546</em>, 1097–1112. (<a
href="https://doi.org/10.1016/j.ins.2020.09.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The availability of large-scale data about interactions of social media users allows the study of complex human behavior. Graphs are typically employed to represent user interactions, but several algorithms become impractical for analyzing large graphs. Hence, it can be useful to analyze a small sub-graph instead in a practice known as graph sampling. However, if the graph is unobtainable, for example, due to privacy limitations, graph sampling is impossible. We introduce an innovative algorithm for representing a large unobtainable graph of user relationships such as Facebook friendships, using a streaming graph of user activity that can include, for example, wall posts on Facebook. We applied different methods of the proposed algorithm to two large datasets. The results show that averages and distribution statistics of nodes in a large, unobtainable relationship graph are well represented by a graph of about 20\% of the size of the unobtainable graph. Finally, we apply the proposed algorithm to identify influencers in an unobtainable graph by analyzing a representative graph. We find that 63\% to 76\% of identified influencers in the representative graph act as influencers in the unobtainable graph, suggesting that the developed algorithm can effectively capture properties of the unobtainable graph.},
  archive      = {J_ISCI},
  author       = {Alon Bartal and Gilad Ravid},
  doi          = {10.1016/j.ins.2020.09.063},
  journal      = {Information Sciences},
  pages        = {1097-1112},
  shortjournal = {Inf. Sci.},
  title        = {Analyzing a large and unobtainable relationship graph using a streaming activity graph},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical community structure preserving approach for
network embedding. <em>ISCI</em>, <em>546</em>, 1084–1096. (<a
href="https://doi.org/10.1016/j.ins.2020.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding aims to map the topological proximities of all nodes in a network into a low-dimensional representation space. Previous studies mainly focus on preserving the within-layer structure of the network (such as first-order proximities, second-order proximities, and community structure). However, many complex networks present a hierarchical organization, often in the form of a hierarchy community structure. How to effectively preserve the within-layer structure and the hierarchical community structure under multi-granularity is a meaningful and still tough task. Inspired by Granular Computing , which is a problem-solving concept deeply rooted in human thinking ability to perceive the real world under multi-granularity, we propose a unified network embedding framework by preserving both the within-layer structure and the hierarchical community structure of the network under multi-granularity, named as Hierarchical Community structure preserving approach for Network Embedding (HCNE). Firstly, different granular networks from fine to coarse are constructed by network granulation which reveals the hierarchical community structure of the original network. Secondly, from coarse to fine, finer networks inherit the embedding of coarse-grained networks as good initialization embedding in the refinement process so that the embedding preserved both the within-layer structure and the hierarchical community structure of the network under multi-granularity. Finally, the learned embedding of each node fed into downstream tasks, including multi-label classification and network visualization. Experimental results demonstrate that HCNE significantly outperforms other state-of-the-art methods. Meanwhile, we intuitively show the effectiveness of HCNE on network visualization which can preserve both the within-layer structure and the hierarchical community structure of the network under multi-granularity.},
  archive      = {J_ISCI},
  author       = {Zhen Duan and Xian Sun and Shu Zhao and Jie Chen and Yanping Zhang and Jie Tang},
  doi          = {10.1016/j.ins.2020.09.053},
  journal      = {Information Sciences},
  pages        = {1084-1096},
  shortjournal = {Inf. Sci.},
  title        = {Hierarchical community structure preserving approach for network embedding},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-plane colour image encryption using a two-dimensional
logistic tent modular map. <em>ISCI</em>, <em>546</em>, 1063–1083. (<a
href="https://doi.org/10.1016/j.ins.2020.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chaotic systems are suitable for image encryption owing to their numerous intrinsic characteristics. However, chaotic maps and algorithmic structures employed in many existing chaos-based image encryption algorithms exhibit various shortcomings. To overcome these, in this study, we first construct a two-dimensional logistic tent modular map (2D-LTMM) and then develop a new colour image encryption algorithm (CIEA) using the 2D-LTMM, which is referred to as the LTMM-CIEA. Compared with the existing chaotic maps used for image encryption, the 2D-LTMM has a fairly wide and continuous chaotic range and more uniformly distributed trajectories. The LTMM-CIEA employs cross-plane permutation and non-sequential diffusion to obtain the diffusion and confusion properties. The cross-plane permutation concurrently shuffles the row and column positions of pixels within the three colour planes, and the non-sequential diffusion method processes the pixels in a secret and random order. The main contributions of this study are the construction of the 2D-LTMM to overcome the shortcomings of existing chaotic maps and the development of the LTMM-CIEA to concurrently encrypt the three colour planes of images. Simulation experiments and security evaluations show that the 2D-LTMM outperforms recently developed chaotic maps, and the LTMM-CIEA outperforms several state-of-the-art image encryption algorithms in terms of security.},
  archive      = {J_ISCI},
  author       = {Zhongyun Hua and Zhihua Zhu and Shuang Yi and Zheng Zhang and Hejiao Huang},
  doi          = {10.1016/j.ins.2020.09.032},
  journal      = {Information Sciences},
  pages        = {1063-1083},
  shortjournal = {Inf. Sci.},
  title        = {Cross-plane colour image encryption using a two-dimensional logistic tent modular map},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Join cardinality estimation by combining operator-level deep
neural networks. <em>ISCI</em>, <em>546</em>, 1047–1062. (<a
href="https://doi.org/10.1016/j.ins.2020.09.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Join cardinality estimation is fundamental to cost-based query optimizers . The state-of-the-art deep learning based join cardinality estimation methods do not fully take the structure of a query plan into account and lack of data information about joins, causing significant performance degradation when the number of joins in a query increases. In this paper, we propose CAPE, a join cardinality estimation method combining operator-level deep neural networks . CAPE introduces two operator-level deep neural networks for selection operators and join operators, as well as an output deep neural network that maps the intermediate representations to join cardinality estimates. Given the query plan rooted at a join operator, CAPE generates a plan-level deep neural network by combining operator-level deep neural networks. In this way, CAPE can handle arbitrary query plans with simple operator-level deep neural networks rather than a single complicated model. In addition, we introduce join-crossing sampling information to detect join-crossing correlations. Experiments are conducted on a dataset constructed from the IMDb dataset, and the experimental results show that CAPE is significantly better than the state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Ling Chen and Heqing Huang and Donghui Chen},
  doi          = {10.1016/j.ins.2020.09.065},
  journal      = {Information Sciences},
  pages        = {1047-1062},
  shortjournal = {Inf. Sci.},
  title        = {Join cardinality estimation by combining operator-level deep neural networks},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Decomposition-based evolutionary algorithm with automatic
estimation to handle many-objective optimization problem. <em>ISCI</em>,
<em>546</em>, 1030–1046. (<a
href="https://doi.org/10.1016/j.ins.2020.08.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many-objective optimization problems (MaOPs), the decomposition-based algorithms are widely used since they have promising performances in maintaining the diversity of solutions. However, few studies have been reported on how to utilize relationships between subproblems to promote global convergence. To fill this gap, we develop an automatic estimation mechanism based on the modified Ant Colony Algorithm to assist the co-evolution between subproblems, where two species of ants are designed. The working-ants execute local exploitation by recording the information of subproblems. The command-ants control global exploration by adjusting co-evolution between working-ants. Moreover, the automatic estimation mechanism is expanded into three modes to verify the more efficient one, and they are embedded separately in the decomposition-based algorithm to construct the combined algorithms. The proposed algorithms are compared with five state-of-the-art algorithms on multiple test suites. The experimental results show that the proposed algorithms perform comparably or better than all referenced algorithms. Given the better performance of the proposed algorithms, it is evident that the hybrid mechanism may be a potential manner to handle MaOPs.},
  archive      = {J_ISCI},
  author       = {Chunliang Zhao and Yuren Zhou and Zefeng Chen},
  doi          = {10.1016/j.ins.2020.08.084},
  journal      = {Information Sciences},
  pages        = {1030-1046},
  shortjournal = {Inf. Sci.},
  title        = {Decomposition-based evolutionary algorithm with automatic estimation to handle many-objective optimization problem},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual robust regression for pattern classification.
<em>ISCI</em>, <em>546</em>, 1014–1029. (<a
href="https://doi.org/10.1016/j.ins.2020.09.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear regression-based and extended methods have been widely used in pattern classification. These methods can be roughly divided into two categories: reconstruction error-based methods and discriminative methods . The reconstruction error-based methods search the target label by learning the representation coefficients to compute the minimal reconstruction error. The goal of the discriminative methods is to learn the projection matrix to predict the target label of the image. To combine the advantages of these two kinds of regression-based methods, this paper presents a dual robust regression framework (DualRR) for pattern classification. In the training stage, a double low-rank robust regression model (DLR) is proposed to learn the projection matrix . In DLR, low-rank robust regression motivates us to model the data as the sum of a low-rank clean data and sparse noise matrix. The low-rank is further used to constrain the projection matrix to enhance the discriminative performance. In the testing stage, the proposed framework employs a robust regression representation model to learn the optimal representation coefficients and obtain the reconstruction sample to approximate the test sample. We thus apply the reconstruction sample to search the classification label by using the projection matrix learned in the training stage. Extensive experiments are conducted on six public available databases, namely, LFW, FRGC, CUHK Sketch, PolyU Palm, NUST-RF and Caltech 101, demonstrating the merits of the proposed model over state-of-the-art regression-based classification methods.},
  archive      = {J_ISCI},
  author       = {Jianjun Qian and Shumin Zhu and Wai Keung Wong and Hengmin Zhang and Zhihui Lai and Jian Yang},
  doi          = {10.1016/j.ins.2020.09.062},
  journal      = {Information Sciences},
  pages        = {1014-1029},
  shortjournal = {Inf. Sci.},
  title        = {Dual robust regression for pattern classification},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-expert visual tracking using hierarchical
convolutional feature fusion via contextual information. <em>ISCI</em>,
<em>546</em>, 996–1013. (<a
href="https://doi.org/10.1016/j.ins.2020.09.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the literature, numerous techniques have proposed to enhance the performance of tracking the visual objects and each method has its own merits and demerits. For instance, the existing tracking methods may lack in performance due to external disturbances that include background clutter, occlusion, and scale variations. In this article, we propose a multi-expert tracking framework that exploits feature fusion and contextual information of the target to improve the tracking accuracy and robustness. Specifically, we constitute an expert group by ensembling the features extracted from deep convolutional neural networks with different properties. Besides, each expert belonging to the constituted group helps to track target in all frames and the best expert with maximum robustness score is selected in each frame. Then, the contextual information of the target is introduced into the correlation filter to improve performance under complex interference. In addition, to further improve efficiency, more experts can be generated by fusing different type of features which leads to more robustness. Moreover, an adaptive model update strategy is introduced into the correlation filter to discriminate the unreliable samples effectively. Finally, extensive experimental results on OTB2013, OTB2015, TempleColor128 and UAVDT datasets demonstrate that the proposed method performs favourably against state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Sathishkumar Moorthy and Young Hoon Joo},
  doi          = {10.1016/j.ins.2020.09.060},
  journal      = {Information Sciences},
  pages        = {996-1013},
  shortjournal = {Inf. Sci.},
  title        = {Multi-expert visual tracking using hierarchical convolutional feature fusion via contextual information},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating the number of clusters in a ranking data context.
<em>ISCI</em>, <em>546</em>, 977–995. (<a
href="https://doi.org/10.1016/j.ins.2020.09.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces two methods for estimating the number of clusters specially designed to identify the number of groups in a finite population of objects or items ranked by several judges under the assumption that these judges belong to a homogeneous population. The proposed methods are both based on a hierarchical version of the classical Plackett–Luce model in which the number of clusters is set as an additional parameter. These methods do not require continuous score data to be available or restrict the number of clusters to be greater than one or less than the total number of objects, thereby enabling their application in a wide range of scenarios. The results of a large simulation study suggest that the proposed methods outperform well-established methodologies (Calinski &amp; Harabasz, gap, Hartigan, Krzanowski &amp; Lai, jump, and silhouette) as well as some recently proposed approaches (instability, quantization error modeling, slope, and utility). They realize the highest percentages of correct estimates of the number of clusters and the smallest errors compared with these well-established methodologies. We illustrate the proposed methods by analyzing a ranking dataset obtained from Formula One motor racing.},
  archive      = {J_ISCI},
  author       = {Wilson Calmon and Mariana Albi},
  doi          = {10.1016/j.ins.2020.09.056},
  journal      = {Information Sciences},
  pages        = {977-995},
  shortjournal = {Inf. Sci.},
  title        = {Estimating the number of clusters in a ranking data context},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view feature transfer for click-through rate
prediction. <em>ISCI</em>, <em>546</em>, 961–976. (<a
href="https://doi.org/10.1016/j.ins.2020.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate prediction is an important method for online advertising and marketing evaluations. However, for environmental reasons, there is a scarcity and imbalance in the advertising data available. We found that a feature transfer can be applied in a transfer learning method to obtain potential connections from less relevant advertisement data. Considering the complexity and diverse features of advertisement data, a feature transfer cannot allow researchers to discover the relationships among such features within the advertisement data. Therefore, we propose a click-through rate method based on a multi-view feature transfer (MFT). MFT divides the data into common and selected features during the data pretreatment process. It then combines the important feature vectors obtained using a Laplacian matrix with the common features obtained during the pretreatment process to form groups of views. Therefore, combining feature transfer matrix with mutli-view clustering is an innovation of the CTR data prediction process. In our experiments, the MFT model achieved good results. Experiments on a large number of datasets of different sizes and the application of three evaluation indicators show that the MFT method delivers excellent prediction results using the transfer relationships among the characteristics of an advertising dataset, and its performance is better than that of many other advertising click-through rate prediction methods.},
  archive      = {J_ISCI},
  author       = {Dan Jiang and Rongbin Xu and Xin Xu and Ying Xie},
  doi          = {10.1016/j.ins.2020.09.005},
  journal      = {Information Sciences},
  pages        = {961-976},
  shortjournal = {Inf. Sci.},
  title        = {Multi-view feature transfer for click-through rate prediction},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secure state estimation for systems under mixed
cyber-attacks: Security and performance analysis. <em>ISCI</em>,
<em>546</em>, 943–960. (<a
href="https://doi.org/10.1016/j.ins.2020.08.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the state estimation for cyber-physical systems (CPSs) whose communication channels are subject to mixed denial-of-service (DoS) and false data injection (FDI) attacks. Cyber-attacks compromise the security and privacy of sensor and communication information. Unlike systems subject to only one single type of attacks (either DoS or FDI attacks), systems under mixed attacks will make the implementation of the optimal state estimation infeasible. We first obtain the optimal estimator for CPSs under mixed cyber-attacks. The optimal estimator consists of an exponentially growing number of components, and thus its computation effort exponentially grows in time. To efficiently compute the optimal estimate, we propose an approximate estimator by using the generalized pseudo-Bayesian algorithm. We prove that for a stable system, both the optimal estimator and the proposed approximate estimator are secure; and theoretically characterize the boundedness of the distance between the optimal and the approximate estimates. A simulation example is presented to illustrate the effectiveness of the proposed methods in guaranteeing secure state estimation when the privacy of sensor and communication information is at the risk of mixed cyber-attacks.},
  archive      = {J_ISCI},
  author       = {Hong Lin and James Lam and Zheng Wang},
  doi          = {10.1016/j.ins.2020.08.124},
  journal      = {Information Sciences},
  pages        = {943-960},
  shortjournal = {Inf. Sci.},
  title        = {Secure state estimation for systems under mixed cyber-attacks: Security and performance analysis},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Access control encryption without sanitizers for internet of
energy. <em>ISCI</em>, <em>546</em>, 924–942. (<a
href="https://doi.org/10.1016/j.ins.2020.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing popularity of Internet of Energy (IoE), more and more physical devices connected to IoE depend on the information system for energy control and coordination. Under this condition, how to achieve information flow control in IoE becomes a great challenge. Access control encryption (ACE) is a promising technology to address the problem. However, existing ACE requires a centralized sanitizer, hindering its successful application in IoE. In this paper, we construct a new kind of ACE without sanitizers for IoE. We first construct a basic ACE scheme based on number-theoretic assumptions (i.e., DBDH assumption), and this scheme can control not only what users can read but also what they can write. To resist against the quantum attacks, we further construct a more secure ACE scheme based on learning with errors (LWE). We formally prove that our proposed two ACE schemes are secure under the proposed security definition, and we also evaluate the applicability and the efficiency of them in experiments.},
  archive      = {J_ISCI},
  author       = {Peng Wang and Tao Xiang and Xiaoguo Li and Hong Xiang},
  doi          = {10.1016/j.ins.2020.09.004},
  journal      = {Information Sciences},
  pages        = {924-942},
  shortjournal = {Inf. Sci.},
  title        = {Access control encryption without sanitizers for internet of energy},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Verifiable single-server private information retrieval from
LWE with binary errors. <em>ISCI</em>, <em>546</em>, 897–923. (<a
href="https://doi.org/10.1016/j.ins.2020.08.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Private Information Retrieval (PIR) allows a client to privately retrieve some data from a public database. There exist two types of PIR: (computational) Single-server PIR (SPIR) and (information-theoretic) multi-server PIR. In this paper, we focus on exploring SPIR. We first propose a simple and efficient additively-homomorphic encryption scheme of which privacy is based on the learning with binary errors assumption that is known as an interesting candidate for practical lattice-based cryptography. Then, according to our proposed homomorphic encryption scheme , we give a Verifiable (single/multi-bit) SPIR (VSPIR) scheme for the single-query case under the malicious server model. To the best of our knowledge, our proposal is the first practical non-interactive VSPIR scheme employing an efficient probabilistic proof that can discover the forged result with overwhelming probability . The corresponding communication complexity and computational complexity are comparable with those of some typical SPIR schemes. Moreover, we extend our single-query VSPIR scheme to construct a non-interactive multi-query solution. In particular, the corresponding communication complexity and computational complexity are the same as those of the single-query scheme. Finally, we provide detailed implementation results to confirm efficiency of our proposals.},
  archive      = {J_ISCI},
  author       = {Liang Zhao and Xingfeng Wang and Xinyi Huang},
  doi          = {10.1016/j.ins.2020.08.071},
  journal      = {Information Sciences},
  pages        = {897-923},
  shortjournal = {Inf. Sci.},
  title        = {Verifiable single-server private information retrieval from LWE with binary errors},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explainable time–frequency convolutional neural network for
microseismic waveform classification. <em>ISCI</em>, <em>546</em>,
883–896. (<a href="https://doi.org/10.1016/j.ins.2020.08.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geological hazards caused by rock failure severely threaten the safety of underground projects, and thus microseismic monitoring systems have been deployed to monitor the rock mass stability. However, due to implicit subseries patterns and sparse distinguishing features, automatic discrimination of the microseismic waveforms of rock fracturing remains a great challenge. Deep neural networks offer powerful learning ability, but the unexplainability of the neural network carries substantial risks to decision-making in safety warning. To this end, we propose an explainable convolutional neural network XTF-CNN that supplies both excellent classification performance and explainability. XTF-CNN consists of two major modules: 1) a dual-channel classification module that learns microseismic features from both the time and frequency domains and 2) an explanation module that demonstrates fine-grained and comprehensible results. Experiments are conducted using microseismic wave-forms collected from a deep tunnel project. The results indicate that XTF-CNN achieves superior classification performance over rival methods and significant comprehensibility.},
  archive      = {J_ISCI},
  author       = {Xin Bi and Chao Zhang and Yao He and Xiangguo Zhao and Yongjiao Sun and Yuliang Ma},
  doi          = {10.1016/j.ins.2020.08.109},
  journal      = {Information Sciences},
  pages        = {883-896},
  shortjournal = {Inf. Sci.},
  title        = {Explainable time–frequency convolutional neural network for microseismic waveform classification},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Securing wireless relaying communication for dual unmanned
aerial vehicles with unknown eavesdropper. <em>ISCI</em>, <em>546</em>,
871–882. (<a href="https://doi.org/10.1016/j.ins.2020.08.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) face a lot of security challenges due to the openness of their wireless communication. In this paper, we investigate how to improve the security of wireless communication when the UAV is utilized as a wireless relay. We consider a new scenario where the dual UAVs are employed cooperatively to transmit confidential information and an eavesdropper whose actual position is unknown attempts to eavesdrop on the information illegally. We propose an optimization problem for the average secrecy rate under multiple constraints. The optimization problem we proposed is non-convex and complicated. We design an iterative algorithm that jointly optimizes the trajectories and transmit power to make the average secrecy rate maximized via the block coordinate descent and successive convex approximation techniques. The feasibility of this method is verified by numerical simulation.},
  archive      = {J_ISCI},
  author       = {Weiwei Xu and Heng Zhang and Xianghui Cao and Ruilong Deng and Hongran Li and Jian Zhang},
  doi          = {10.1016/j.ins.2020.08.107},
  journal      = {Information Sciences},
  pages        = {871-882},
  shortjournal = {Inf. Sci.},
  title        = {Securing wireless relaying communication for dual unmanned aerial vehicles with unknown eavesdropper},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Locality-constrained sparse representation for hyperspectral
image classification. <em>ISCI</em>, <em>546</em>, 858–870. (<a
href="https://doi.org/10.1016/j.ins.2020.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse representation has been in a widespread use in hyperspectral image (HSI) classification task . The samples to be classified can be linearly represented with a few samples from the same class. However, when samples from different classes are highly correlated with each other, it makes the classification task challenging. To solve this problem, we take the Euclidean distance information between the training samples and testing samples into consideration to construct a new dictionary for sparse representation. That is, we propose a locality-constrained sparse representation classifier (LSRC) in this paper. First, the K-nearest neighbour (KNN) algorithm is applied to the training data set to form a locality-constrained dictionary by excluding the samples separated from testing samples in the Euclidean space . Then, the sparse coding is applied to the testing sample with the formed dictionary via class dependent orthogonal matching pursuit (OMP) algorithm which utilizes the class label information. Finally, by using the minimal residual rule within all catergories, we can obtain class label of the testing sample. Experiments based on the chosen three hyperspectral datasets prove that our proposed LSRC outperforms other popular classifiers.},
  archive      = {J_ISCI},
  author       = {Yuanshu Zhang and Yong Ma and Xiaobing Dai and Hao Li and Xiaoguang Mei and Jiayi Ma},
  doi          = {10.1016/j.ins.2020.09.009},
  journal      = {Information Sciences},
  pages        = {858-870},
  shortjournal = {Inf. Sci.},
  title        = {Locality-constrained sparse representation for hyperspectral image classification},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CNN-based encoder-decoder networks for salient object
detection: A comprehensive review and recent advances. <em>ISCI</em>,
<em>546</em>, 835–857. (<a
href="https://doi.org/10.1016/j.ins.2020.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural network (CNN)-based encoder-decoder models have profoundly inspired recent works in the field of salient object detection (SOD). With the rapid development of encoder-decoder models with respect to most pixel-level dense prediction tasks, an empirical study still does not exist that evaluates performance by applying a large body of encoder-decoder models on SOD tasks. In this paper, instead of limiting our survey to SOD methods, a broader view is further presented from the perspective of fundamental architectures of key modules and structures in CNN-based encoder-decoder models for pixel-level dense prediction tasks. Moreover, we focus on performing SOD by leveraging deep encoder-decoder models, and present an extensive empirical study on baseline encoder-decoder models in terms of different encoder backbones, loss functions, training batch sizes, and attention structures. Moreover, state-of-the-art encoder-decoder models adopted from semantic segmentation and deep CNN-based SOD models are also investigated. New baseline models that can outperform state-of-the-art performance were discovered. In addition, these newly discovered baseline models were further evaluated on three video-based SOD benchmark datasets. Experimental results demonstrate the effectiveness of these baseline models on both image- and video-based SOD tasks. This empirical study is concluded by a comprehensive summary which provides suggestions on future perspectives.},
  archive      = {J_ISCI},
  author       = {Yuzhu Ji and Haijun Zhang and Zhao Zhang and Ming Liu},
  doi          = {10.1016/j.ins.2020.09.003},
  journal      = {Information Sciences},
  pages        = {835-857},
  shortjournal = {Inf. Sci.},
  title        = {CNN-based encoder-decoder networks for salient object detection: A comprehensive review and recent advances},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reinforcement learning approach for dynamic
multi-objective optimization. <em>ISCI</em>, <em>546</em>, 815–834. (<a
href="https://doi.org/10.1016/j.ins.2020.08.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Multi-objective Optimization Problem (DMOP) is emerging in recent years as a major real-world optimization problem receiving considerable attention. Tracking the movement of Pareto front efficiently and effectively over time has been a central issue in solving DMOPs. In this paper, a reinforcement learning-based dynamic multi-objective evolutionary algorithm, called RL-DMOEA, which seamlessly integrates reinforcement learning framework and three change response mechanisms, is proposed for solving DMOPs. The proposed algorithm relocates the individuals based on the severity degree of environmental changes, which is estimated through the corresponding changes in the objective space of their decision variables. When identifying different severity degree of environmental changes, the proposed RL-DMOEA approach can learn better evolutionary behaviors from environment information, based on which apply the appropriate response mechanisms. Specifically, these change response mechanisms including the knee-based prediction, center-based prediction and indicator-based local search, are devised to promote both convergence and diversity of the algorithm under different severity of environmental changes. To verify this idea, the proposed RL-DMOEA is evaluated on CEC 2015 test problems involving various problem characteristics. Empirical studies on chosen state-of-the-art designs validate that the proposed RL-DMOEA is effective in addressing the DMOPs.},
  archive      = {J_ISCI},
  author       = {Fei Zou and Gary G. Yen and Lixin Tang and Chunfeng Wang},
  doi          = {10.1016/j.ins.2020.08.101},
  journal      = {Information Sciences},
  pages        = {815-834},
  shortjournal = {Inf. Sci.},
  title        = {A reinforcement learning approach for dynamic multi-objective optimization},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving data and model quality in crowdsourcing using
cross-entropy-based noise correction. <em>ISCI</em>, <em>546</em>,
803–814. (<a href="https://doi.org/10.1016/j.ins.2020.08.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing services provide a fast, efficient, and cost-effective approach to obtaining labeled data, particularly for human-like tasks. In a crowdsourcing scenario, after ground truth inference methods have been employed to obtain integrated instance labels, label noise remains present in the integrated labels. Label noise handling techniques can then be implemented to mitigate the effects of this noise. In this study, we propose a Cross-Entropy-based Noise Correction (CENC) method for crowdsourcing. CENC uses the entropies of the label distributions generated from multiple noisy label sets to filter noisy instances. It then exploits the cross-entropies between each possible true class probability distribution and each predicted class probability distribution to rectify the noisy instances. Using both simulated benchmark data and real-world crowdsourced data, we show that CENC outperforms all other existing state-of-the-art noise correction methods.},
  archive      = {J_ISCI},
  author       = {Wenqiang Xu and Liangxiao Jiang and Chaoqun Li},
  doi          = {10.1016/j.ins.2020.08.117},
  journal      = {Information Sciences},
  pages        = {803-814},
  shortjournal = {Inf. Sci.},
  title        = {Improving data and model quality in crowdsourcing using cross-entropy-based noise correction},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid intelligent model for acute hypotensive episode
prediction with large-scale data. <em>ISCI</em>, <em>546</em>, 787–802.
(<a href="https://doi.org/10.1016/j.ins.2020.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acute hypotensive episode (AHE) is a common serious postoperative complication in ICU, which may raise multiple system failure (especially of cardiac and respiratory kinds), and even cause death. Timely and effective clinical intervention is obviously vital to the saving of patients. AHE detection involves physiological time-series monitoring, processing and prediction technologies , which can offer insights to neuroscientists, biologists, and even provide support for clinicians. This paper presents a hybrid artificial intelligence model combined with CEEMDAN (complete ensemble empirical mode decomposition with adaptive noise, a typical method for physiological signal decomposition), deep learning , multiple gene expression programming and fuzzy expert system for AHE detection. In this paper, the physiological signal is selected from a benchmark dataset, for example MIMIC-II (Multiparameter Intelligent Monitoring in Intensive Care II), which collects large scale real patients’ data for clinical research. In the hybrid model, a typical signal decomposition method is employed for AHE signal processing, and an autoencoder based deep neural network is established for feature extraction. Finally, a reliable and explainable classifier is presented by fusing gene expression programming and the fuzzy method. Experimental results based on real data set demonstrate that the proposed method outperforms state-of-the-art AHE detection methods by achieving the prediction accuracy of 88.14\% in 2866 records.},
  archive      = {J_ISCI},
  author       = {Dazhi Jiang and Geng Tu and Donghui Jin and Kaichao Wu and Cheng Liu and Lin Zheng and Teng Zhou},
  doi          = {10.1016/j.ins.2020.08.033},
  journal      = {Information Sciences},
  pages        = {787-802},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid intelligent model for acute hypotensive episode prediction with large-scale data},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive perception-oriented network for single image
super-resolution. <em>ISCI</em>, <em>546</em>, 769–786. (<a
href="https://doi.org/10.1016/j.ins.2020.08.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, it has been demonstrated that deep neural networks can significantly improve the performance of single image super-resolution (SISR). Numerous studies have concentrated on raising the quantitative quality of super-resolved (SR) images. However, these methods that target PSNR maximization usually produce blurred images at large upscaling factor. The introduction of generative adversarial networks (GANs) can mitigate this issue and show impressive results with synthetic high-frequency textures. Nevertheless, these GAN-based approaches always have a tendency to add fake textures and even artifacts to make the SR image of visually higher-resolution. In this paper, we propose a novel perceptual image super-resolution method that progressively generates visually high-quality results by constructing a stage-wise network. Specifically, the first phase concentrates on minimizing pixel-wise error, and the second stage utilizes the features extracted by the previous stage to pursue results with better structural retention. The final stage employs fine structure features distilled by the second phase to produce more realistic results. In this way, we can maintain the pixel, and structural level information in the perceptual image as much as possible. It is useful to note that the proposed method can build three types of images in a feed-forward process. Also, we explore a new generator that adopts multi-scale hierarchical features fusion . Extensive experiments on benchmark datasets show that our approach is superior to the state-of-the-art methods. Code is available at https://github.com/Zheng222/PPON .},
  archive      = {J_ISCI},
  author       = {Zheng Hui and Jie Li and Xinbo Gao and Xiumei Wang},
  doi          = {10.1016/j.ins.2020.08.114},
  journal      = {Information Sciences},
  pages        = {769-786},
  shortjournal = {Inf. Sci.},
  title        = {Progressive perception-oriented network for single image super-resolution},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based synchronization control for complex networks
against asynchronous attacks. <em>ISCI</em>, <em>546</em>, 753–768. (<a
href="https://doi.org/10.1016/j.ins.2020.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the framework of cyber-physical systems (CPSs), this paper investigates the secure synchronization control problem of complex networks against asynchronous attacks. Different from the previous works that considered either connection attack on network connections or denial-of-service (DoS) attack in control (controller-to-actuator) channels, the asynchronous case of both types of attacks in complex networks is taken into account here. Besides, to overcome the difficulty that system states are not available for controllers, the pinning-nodes-based observer is designed to estimate all system states only using the measurements of pinning nodes rather than all ones. Such an observer is very realistic, especially for large-scale complex systems. By establishing a piecewise Lyapunov function , the secure synchronization criteria of complex networks under the considered asynchronous attacks are obtained. Finally, a numerical example and its simulations are exhibited to confirm the availability of the developed theoretical outcomes.},
  archive      = {J_ISCI},
  author       = {Dan Liu and Dan Ye},
  doi          = {10.1016/j.ins.2020.08.018},
  journal      = {Information Sciences},
  pages        = {753-768},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based synchronization control for complex networks against asynchronous attacks},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-time adaptive fuzzy control for uncertain strict
feedback switched systems. <em>ISCI</em>, <em>546</em>, 742–752. (<a
href="https://doi.org/10.1016/j.ins.2020.08.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of fuzzy logic adaptive fixed-time control for nonlinear switched system . Different from existing research results on fixed-time control, the system functions are completely uncertain in this paper. The approximation error will cause Lyapunov function not to be negative definite. To address this problem, a new criterion of fixed-time stability is developed at first. Based on this fixed-time theory, a fuzzy logic control method is proposed by using backstepping technique. The proposed adaptive laws in this paper do not satisfy a series of linear differential equations but nonlinear ones. Simulation results verify the feasibility of presented algorithms.},
  archive      = {J_ISCI},
  author       = {Yumei Sun and Lei Zhang},
  doi          = {10.1016/j.ins.2020.08.059},
  journal      = {Information Sciences},
  pages        = {742-752},
  shortjournal = {Inf. Sci.},
  title        = {Fixed-time adaptive fuzzy control for uncertain strict feedback switched systems},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection, estimation, and compensation of false data
injection attack for UAVs. <em>ISCI</em>, <em>546</em>, 723–741. (<a
href="https://doi.org/10.1016/j.ins.2020.08.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The safety issues of unmanned aerial vehicles (UAVs) are ever increasing in focus due to the vulnerability to attack. This paper investigates the safety problem for UAVs under the false data injection attack (FDIA) through wireless data link. First, the attack characteristics and influencing factors of FDIA are explicitly analyzed. Thus, the models of FDIA can be established. Second, attack detection mechanism is proposed. The average power of received signals and the residual of the authentication signals are utilized to detect whether the system is attacked. Third, to compensate the effect of FDIA on the control system, the FDIA impact on UAV dynamics is formulated and attack observers are developed accordingly. Finally, simulation examples are presented to illustrate the effectiveness of the proposed methods.},
  archive      = {J_ISCI},
  author       = {Yapei Gu and Xiang Yu and Kexin Guo and Jianzhong Qiao and Lei Guo},
  doi          = {10.1016/j.ins.2020.08.055},
  journal      = {Information Sciences},
  pages        = {723-741},
  shortjournal = {Inf. Sci.},
  title        = {Detection, estimation, and compensation of false data injection attack for UAVs},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-aspect renewable energy forecasting. <em>ISCI</em>,
<em>546</em>, 701–722. (<a
href="https://doi.org/10.1016/j.ins.2020.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing presence of renewable energy plants has created new challenges such as grid integration, load balancing and energy trading , making it fundamental to provide effective prediction models. Recent approaches in the literature have shown that exploiting spatio-temporal autocorrelation in data coming from multiple plants can lead to better predictions. Although tensor models and techniques are suitable to deal with spatio-temporal data, they have received little attention in the energy domain. In this paper, we propose a new method based on the Tucker tensor decomposition , capable of extracting a new feature space for the learning task. For evaluation purposes, we have investigated the performance of predictive clustering trees with the new feature space, compared to the original feature space, in three renewable energy datasets. The results are favorable for the proposed method, also when compared with state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Roberto Corizzo and Michelangelo Ceci and Hadi Fanaee-T and Joao Gama},
  doi          = {10.1016/j.ins.2020.08.003},
  journal      = {Information Sciences},
  pages        = {701-722},
  shortjournal = {Inf. Sci.},
  title        = {Multi-aspect renewable energy forecasting},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diversity based selection for many-objective evolutionary
optimisation problems with constraints. <em>ISCI</em>, <em>546</em>,
665–700. (<a href="https://doi.org/10.1016/j.ins.2020.08.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces a novel many-objective evolutionary method, with a diversity-based selection operator and aims to fill the “gaps” in the Pareto Front approximation and to increase its spread. It shows, that guiding the evolution process towards the least explored parts of a space increases overall diversity, but can also lead to increased convergence. A set of experiments is carried out on a many-objective Multi-Skill Resource-Constrained Project Scheduling Problem and a bi-objective Travelling Thief Problem. Both of those problems comprise two interwoven subproblems . Separate optimal solutions to the subproblems do not guarantee the optimal solution to the entire problem. Moreover, it shows that the existing diversity mechanism does not work well in combinatorial spaces, where the domain of each objective has a different size. The results indicate that a novel selection operator circumvents this issue. A set of Quality Measures is used to describe the desirable features of Pareto Front approximation : convergence, uniformity, and spread. The experiments are followed by a set of visualizations. Along with a set of Quality Measures, they give an insight into the characteristics of the method. The paper is concluded by a thorough theoretical analysis and possible directions for future work.},
  archive      = {J_ISCI},
  author       = {Paweł B. Myszkowski and Maciej Laszczyk},
  doi          = {10.1016/j.ins.2020.08.118},
  journal      = {Information Sciences},
  pages        = {665-700},
  shortjournal = {Inf. Sci.},
  title        = {Diversity based selection for many-objective evolutionary optimisation problems with constraints},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). APTMalInsight: Identify and cognize APT malware based on
system call information and ontology knowledge framework. <em>ISCI</em>,
<em>546</em>, 633–664. (<a
href="https://doi.org/10.1016/j.ins.2020.08.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {APT attacks have posed serious threats to the security of cyberspace nowadays which are usually tailored for specific targets. Identification and understanding of APT attacks remains a key issue for society. Attackers often utilize malware as the weapons to launch cyber-attacks. For this reason, detecting APT malware and gaining an insight of its malicious behaviors can strengthen the power to understand and counteract APT attacks. Based on the above motivation, this paper proposes a novel APT malware detection and cognition framework named APTMalInsight aiming at identifying and cognizing APT malware by leveraging system call information and ontology knowledge. We systematically study APT malware and extracts dynamic system call information to describe its behavioral characteristics. With respect to the established feature vectors, the APT malware can be detected and clustered into their belonging families accurately. Furthermore, a horizontal comparison between APT malware and the traditional malware is conducted from the perspective of behavior types, to understand the behavioral characteristics of APT malware in depth. On the above basis, the ontology model is introduced to construct the APT malware knowledge framework to represent its typical malicious behaviors, thereby implementing the systematic cognition of APT malware and providing contextual understanding of APT attacks. The evaluation results based on real APT malware samples demonstrate that the detection and clustering accuracy can reach up to 99.28\% and 98.85\% respectively. In addition, APTMalInsight supplies an effective cognition framework for APT malware and enhances the capability to understand APT attacks.},
  archive      = {J_ISCI},
  author       = {Weijie Han and Jingfeng Xue and Yong Wang and Fuquan Zhang and Xianwei Gao},
  doi          = {10.1016/j.ins.2020.08.095},
  journal      = {Information Sciences},
  pages        = {633-664},
  shortjournal = {Inf. Sci.},
  title        = {APTMalInsight: Identify and cognize APT malware based on system call information and ontology knowledge framework},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A common characterization for migrative uni-nullnorms.
<em>ISCI</em>, <em>546</em>, 627–632. (<a
href="https://doi.org/10.1016/j.ins.2020.08.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uni-nullnorms generalize both uninorms and nullnorms. In this paper, we investigate the migrative property for uni-nullnorms. We give a common characterization for the α α -migrative uni-nullnorms over a fixed uni-nullnorm, which generalizes and unifies characterizations for migrative uninorms and migrative nullnorms to some extent.},
  archive      = {J_ISCI},
  author       = {Feng Sun and Xiao-bing Qu},
  doi          = {10.1016/j.ins.2020.08.108},
  journal      = {Information Sciences},
  pages        = {627-632},
  shortjournal = {Inf. Sci.},
  title        = {A common characterization for migrative uni-nullnorms},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fabric defect detection via low-rank decomposition with
gradient information and structured graph algorithm. <em>ISCI</em>,
<em>546</em>, 608–626. (<a
href="https://doi.org/10.1016/j.ins.2020.08.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The low rank decomposition model shows the potential of fabric defect detection , in which a matrix is decomposed into a sparse matrix representing the defect free region (background) and identifying the defect area (foreground). However, there are still two shortcomings. Firstly, when the texture of defect image has high gradient feature, the sparse matrix obtained by the existing model still retains a large number of edges of undetected regions. Secondly, due to the imprecision of prior information, most models will misjudge the defect free points around the defect block when dealing with the small defect area or the defect area containing multiple cycles. In order to solve these problems, this paper proposes a fabric defect detection method based on low rank decomposition of gradient information and structured graph algorithm : 1) structured graphics algorithm, according to the characteristics of fabric defect image , fabric defect image is divided into defect free block with local feature and defect damage period. 2) In the merging process, an adaptive threshold is set according to the number of cycles contained in the current block to encourage intra lattice merging and prevent the merging of defective blocks and surrounding non defective blocks. 3) The defect prior information calculated from the segmentation results is used to guide matrix decomposition to weaken the defect free region and highlight the defect area under the sparse term. We evaluated our model on a standard database and compared it with the four latest methods. The total TPR and fpr of this method are 87.3\% and 1.21\% respectively on box, star and point databases, which is the best performance.},
  archive      = {J_ISCI},
  author       = {Boshan Shi and Jiuzhen Liang and Lan Di and Chen Chen and Zhenjie Hou},
  doi          = {10.1016/j.ins.2020.08.100},
  journal      = {Information Sciences},
  pages        = {608-626},
  shortjournal = {Inf. Sci.},
  title        = {Fabric defect detection via low-rank decomposition with gradient information and structured graph algorithm},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A discrete cosine transform-based query efficient attack on
black-box object detectors. <em>ISCI</em>, <em>546</em>, 596–607. (<a
href="https://doi.org/10.1016/j.ins.2020.05.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are being widely used in almost every field of computing and information processing. The advantages offered by these models are unparalleled, however, similar to any other computing discipline, they are also vulnerable to security threats. A compromised deep neural network can significantly impact its robustness and accuracy. In this work, we present a novel targeted attack method against state-of-the-art object detection models YOLO v3 and AWS Rekognition in a black-box environment. We present an improved attack method using Discrete Cosine Transform based on boundary attack plus plus mechanism, and apply it on attacking object detectors offline and online. By querying the victim detection models along with transforming the images from the spatial domain into the frequency domain, we ensure that any specified object in an image can be successfully recognized as any other desired class by YOLO v3 and AWS Rekognition. The results prove that our method has significant boosting effects on boundary attacks in offline and online object detection systems.},
  archive      = {J_ISCI},
  author       = {Xiaohui Kuang and Xianfeng Gao and Lianfang Wang and Gang Zhao and Lishan Ke and Quanxin Zhang},
  doi          = {10.1016/j.ins.2020.05.089},
  journal      = {Information Sciences},
  pages        = {596-607},
  shortjournal = {Inf. Sci.},
  title        = {A discrete cosine transform-based query efficient attack on black-box object detectors},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reliable observer-based finite-time h∞ control for networked
nonlinear semi-markovian jump systems with actuator fault and parameter
uncertainties via dynamic event-triggered scheme. <em>ISCI</em>,
<em>546</em>, 573–595. (<a
href="https://doi.org/10.1016/j.ins.2020.08.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the observer-based finite-time H ∞ H∞ control problem for networked nonlinear semi-Markovian jump systems (SMJSs) with actuator fault, parameter uncertainties and partly unknown transition rates via an improved dynamic event-triggered scheme (DETS). In comparison with traditional dynamic event-triggered scheme, the observer-based improved dynamic event-triggered scheme which is not restricted by real system states and could save more network resources is firstly proposed in this paper. Then, a more general actuator fault model is considered and the reliable observer-based state feedback controller is designed. Sufficient conditions are proposed to guarantee the closed-loop system is stochastically finite-time bounded with a prescribed H ∞ H∞ disturbance attenuation level. Lastly, two simulation examples are given to affirm the validity of the results obtained in this paper.},
  archive      = {J_ISCI},
  author       = {Xiaowu Mu and Xin Li and Jianyin Fang and Xihui Wu},
  doi          = {10.1016/j.ins.2020.08.098},
  journal      = {Information Sciences},
  pages        = {573-595},
  shortjournal = {Inf. Sci.},
  title        = {Reliable observer-based finite-time h∞ control for networked nonlinear semi-markovian jump systems with actuator fault and parameter uncertainties via dynamic event-triggered scheme},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximizing positive influence in competitive social
networks: A trust-based solution. <em>ISCI</em>, <em>546</em>, 559–572.
(<a href="https://doi.org/10.1016/j.ins.2020.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks provide convenience for users to propagate ideas, products, opinions, and many other items that compete with different items for influence spread. How to accurately model the spread of competitive influence is still a challenging problem. Almost all reported methods ignore the effect of trust relationships in the spread of competitive influence. Maximizing competitive influence aims to detect the top- k positive or negative influential users in social networks with competing cascades. However, finding an optimal solution to this problem is NP-hard. This study focuses on exploring the above three issues by devising a trust-based solution. First, we established a new model of trust-based competitive influence diffusion that simulates the spread of positive and negative influence. Second, we estimated trust values via generalized network flows and used these values to calculate influence probabilities . Finally, we developed an efficient algorithm of trust-based competitive influence maximization through a heuristic pruning method. Extensive comparisons have been conducted on synthetic and real-world datasets. The effectiveness and efficiency of our approach are verified by analyzing the spread of competitive influence and the time complexity of detecting seed sets. Moreover, our approach is more practical than other baselines on real-world social networks.},
  archive      = {J_ISCI},
  author       = {Feng Wang and Jinhua She and Yasuhiro Ohyama and Wenjun Jiang and Geyong Min and Guojun Wang and Min Wu},
  doi          = {10.1016/j.ins.2020.09.002},
  journal      = {Information Sciences},
  pages        = {559-572},
  shortjournal = {Inf. Sci.},
  title        = {Maximizing positive influence in competitive social networks: A trust-based solution},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid acceleration strategy for nonparallel support
vector machine. <em>ISCI</em>, <em>546</em>, 543–558. (<a
href="https://doi.org/10.1016/j.ins.2020.08.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonparallel support vector machine is a binary classifier which has better sparsity and classification performance than other support vector machine models. However, it works slowly. Although sample selection is an effective acceleration approach, it will disturb the accuracy. Fortunately, another recently emerging screening method could speedup the solving process and keeps the accuracy unchanged. Motivated by the above research, a novel two-stage hybrid screening rule based on variational inequality and duality gap is proposed in this paper. It can reduce the scale of dual problem by deleting more redundant samples. Then, a better acceleration effect will be obtained. Meanwhile, it is still a safe method which means that the optimal solution remains unchanged. Moreover, Shrinking technique is embedded into the fast iterative algorithm DCDM to get further speedup. Thus the hybrid method can reduce the size of the problem, and accelerate the solving process greatly. Numerical experiments on ten benchmark data sets and a real Chinese red wine data set are conducted to verify the effectiveness of our hybrid acceleration strategy.},
  archive      = {J_ISCI},
  author       = {Weichen Wu and Yitian Xu and Xinying Pang},
  doi          = {10.1016/j.ins.2020.08.067},
  journal      = {Information Sciences},
  pages        = {543-558},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid acceleration strategy for nonparallel support vector machine},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Random projection-based auxiliary information can improve
tree-based nearest neighbor search. <em>ISCI</em>, <em>546</em>,
526–542. (<a href="https://doi.org/10.1016/j.ins.2020.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nearest neighbor search using random projection trees has recently been shown to achieve superior performance, in terms of better accuracy while retrieving less number of data points, compared to locality sensitive hashing based methods. However, to achieve acceptable nearest neighbor search accuracy for large scale applications, where number of data points and/or number of features can be very large, it requires users to maintain, store and search through large number of such independent random projection trees, which may be undesirable for many practical applications. To address this issue, in this paper we present different search strategies to improve nearest neighbor search performance of a single random projection tree. Our approach exploits properties of single and multiple random projections, which allows us to store meaningful auxiliary information at internal nodes of a random projection tree as well as to design priority functions to guide the search process that results in improved nearest neighbor search performance. Empirical results on multiple real world datasets show that our proposed method significantly improves nearest neighbor search accuracy of a single tree compared to baseline methods .},
  archive      = {J_ISCI},
  author       = {Omid Keivani and Kaushik Sinha},
  doi          = {10.1016/j.ins.2020.08.054},
  journal      = {Information Sciences},
  pages        = {526-542},
  shortjournal = {Inf. Sci.},
  title        = {Random projection-based auxiliary information can improve tree-based nearest neighbor search},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-based resilient filtering for stochastic nonlinear
systems via innovation constraints. <em>ISCI</em>, <em>546</em>,
512–525. (<a href="https://doi.org/10.1016/j.ins.2020.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the problem of event-based resilient filtering for a class of stochastic nonlinear systems subject to the impact of outliers. The transmitted data governed by an event-based communication protocol could suffer from malicious attacks due mainly to the network unreliability, which gives rise to the phenomena of outliers or abnormal values. A factitious saturation constraint on innovations is carried out to remove these abnormal data in the designed filter in order to improve the filtering reliability. Furthermore, a gain variation is also taken into account to realize the resilient requirement of the designed filtering scheme. By virtue of the Lyapunov stability theory , a sufficient condition is derived to check the ultimate boundedness of filtering error dynamics in mean-square sense. Furthermore, an analytic formula of the desired filter gain and the ultimate bound of filtering errors are obtained through the utilization of matrix inequality techniques. Finally, some simulation results are provided to illustrate the superiority of the developed filtering scheme.},
  archive      = {J_ISCI},
  author       = {Ying Sun and Derui Ding and Hongli Dong and Hongjian Liu},
  doi          = {10.1016/j.ins.2020.08.007},
  journal      = {Information Sciences},
  pages        = {512-525},
  shortjournal = {Inf. Sci.},
  title        = {Event-based resilient filtering for stochastic nonlinear systems via innovation constraints},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BIOFUSE: A framework for multi-biometric fusion on
biocryptosystem level. <em>ISCI</em>, <em>546</em>, 481–511. (<a
href="https://doi.org/10.1016/j.ins.2020.08.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biometric cryptosystems or biocryptoystems are gaining prominence for cryptographic key generation, encryption and biometric template protection. However, the most popular state-of-the-art biocryptosystems- fuzzy commitment and fuzzy vault are prone to multiple security attacks. Recently proposed multi-biometric cryptosystems improve security and enhance recognition performance. They perform the fusion of multi-biometric characteristics with either a single biocryptosystem or independently accessed, multiple biocryptosystems. An attack on any of the involved biocryptosystems can weaken the security of the whole system. In our paper, we propose a multi-biometric fusion framework- BIOFUSE, that combines fuzzy commitment and fuzzy vault using the format-preserving encryption scheme . BIOFUSE makes it improbable for an attacker to get unauthorized access to the system without impersonation of all the biometric inputs of the genuine user at the same instant. We present 4 most basic ways of constructing BIOFUSE and found only 1 named S-BIOFUSE ( S 3 S3 ) as a secure design. We compare the recognition performance of the proposed scheme with existing multi-biometric cryptosystems on various databases. The results show 0.98 0.98 true match rate at 0.01 0.01 false match rate on a virtual IITD-DB1 database that indicates that our proposed work achieves significantly good recognition performance while providing high security.},
  archive      = {J_ISCI},
  author       = {Donghoon Chang and Surabhi Garg and Mohona Ghosh and Munawar Hasan},
  doi          = {10.1016/j.ins.2020.08.065},
  journal      = {Information Sciences},
  pages        = {481-511},
  shortjournal = {Inf. Sci.},
  title        = {BIOFUSE: A framework for multi-biometric fusion on biocryptosystem level},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the derivatives of set functions in matrix
representation. <em>ISCI</em>, <em>546</em>, 469–480. (<a
href="https://doi.org/10.1016/j.ins.2020.08.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formalises the operations on capacities in matrix algebra framework. Various quantities that characterise the importance of the inputs and their dependencies are expressed through capacity derivatives, obtained through matrix–vector multiplication. Many relations between the set functions derivatives are established and found to be the consequences of the Divergence Theorem . New formulas for Shapley values and nonmodularity indices are found. The sums of the Shapley interaction indices are found to be related to lower order derivatives at the top and bottom elements of the respective power sets. The presented methods simplify many calculations and will facilitate efficient software implementations and applications of the capacity-based decision making methods .},
  archive      = {J_ISCI},
  author       = {Gleb Beliakov},
  doi          = {10.1016/j.ins.2020.08.113},
  journal      = {Information Sciences},
  pages        = {469-480},
  shortjournal = {Inf. Sci.},
  title        = {On the derivatives of set functions in matrix representation},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust sparse coding via self-paced learning for data
representation. <em>ISCI</em>, <em>546</em>, 448–468. (<a
href="https://doi.org/10.1016/j.ins.2020.08.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse coding (SC), due to its thorough theoretical property and outstanding effectiveness, is attracting more and more attention in various data representation and data mining applications. However, the optimization of most existing sparse coding algorithms are non-convex and thus prone to become stuck into bad local minima under the framework of alternative optimization, especially when there are many outliers and noisy data. To enhance the learning robustness, in this study, we will present an unified framework named Self - Paced Sparse Coding (SPSC), which gradually includes data into the learning process of SC from easy ones to complex ones by incorporating self-paced learning methodology. It implements a soft instance selection accordingly rather than a heuristic hard strategy sample selection. We also generalize the self-paced learning schema into different levels of dynamic selection on instances, features and elements respectively. Further, we show an optimization algorithm to solve it and a theoretical explanation to analyze the effectiveness of it. Extensive experimental results on the real-world clean image datasets and images with two kinds of corruptions demonstrate the remarkable robustness of the proposed method for high dimensional data representation on image clustering and reconstruction tasks over the state-of-the-arts.},
  archive      = {J_ISCI},
  author       = {Xiaodong Feng and Sen Wu},
  doi          = {10.1016/j.ins.2020.08.097},
  journal      = {Information Sciences},
  pages        = {448-468},
  shortjournal = {Inf. Sci.},
  title        = {Robust sparse coding via self-paced learning for data representation},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertain database retrieval with measure – based belief
function attribute values under intuitionistic fuzzy set. <em>ISCI</em>,
<em>546</em>, 436–447. (<a
href="https://doi.org/10.1016/j.ins.2020.08.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertain database retrieval with measure-based belief function attribute values can resolve concerns of database retrieval and decision making, particularly in the circumstances of classical fuzzy set, which has an assuring perspective. However, how to implement the design to explore the things based on the intuitionistic fuzzy set (IFS) in an ambiguous database is yet an open problem. This paper addresses the issues of database retrieval based on the uncertain database with the things related to IFS. In the design, a query associated with each attribute of the objects is located in terms of IFS. Based on the gathered data, the “plausibilities (Pl)” and “beliefs (Bel)” measures are measured for each attribute and then aggregated with the cooperation of the Choquet integral (CI) operator. The “satisfaction degree” of the query in the form of an interval is circumscribed as [Bel, Pl]. The defuzzified value of this interval is affirmed with the aid of golden rule representative value, to link these satisfaction degrees. Hence, the appearance of the stated algorithm is more trustworthy than the others under an unpredictable environment. The description of the asserted algorithm is illustrated with an application correlated to the library database.},
  archive      = {J_ISCI},
  author       = {Yige Xue and Yong Deng and Harish Garg},
  doi          = {10.1016/j.ins.2020.08.096},
  journal      = {Information Sciences},
  pages        = {436-447},
  shortjournal = {Inf. Sci.},
  title        = {Uncertain database retrieval with measure – based belief function attribute values under intuitionistic fuzzy set},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AI-HydRa: Advanced hybrid approach using random forest and
deep learning for malware classification. <em>ISCI</em>, <em>546</em>,
420–435. (<a href="https://doi.org/10.1016/j.ins.2020.08.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extremely diffused architecture of the Internet enables the propagation of malware and presents a significant challenge for the development of defenses against such malware propagation. Although machine learning-based malware detection models can improve approaches in response to this problem, their detection rates vary according to their features and classification methods. Single machine learning approaches for malware detection can vary in effectiveness according to the suitability of their classifiers despite the use of an appropriate training dataset. Some classifiers result in high detection rates with a malicious training dataset but have low detection rates with a benign training dataset, and false positive rates are particularly dependent on the use of appropriate classifiers. In this paper, we propose a machine learning-based hybrid decision model that can achieve a high detection rate with a low false positive rate. This hybrid model combines a random forest and a deep learning model using 12 hidden layers to determine malware and benign files, respectively. This model also includes certain proposed voting rules to make final decisions. In an experiment involving 6,395 atypical samples, this hybrid decision model achieved a higher detection rate (85.1\% and standard deviation of 0.006) than that of the prior model (65.5\%) without voting rules.},
  archive      = {J_ISCI},
  author       = {Suyeon Yoo and Sungjin Kim and Seungjae Kim and Brent Byunghoon Kang},
  doi          = {10.1016/j.ins.2020.08.082},
  journal      = {Information Sciences},
  pages        = {420-435},
  shortjournal = {Inf. Sci.},
  title        = {AI-HydRa: Advanced hybrid approach using random forest and deep learning for malware classification},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Region-edge-based active contours driven by hybrid and local
fuzzy region-based energy for image segmentation. <em>ISCI</em>,
<em>546</em>, 397–419. (<a
href="https://doi.org/10.1016/j.ins.2020.08.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper raises a region-edge-based active contour driven by the hybrid and local fuzzy region-based energy to segment images with high noise and intensity inhomogeneity . The energy functional consists of region energy and edge energy. The region energy is made up of hybrid fuzzy region term and local fuzzy region term. Its aim is to motivate initial contour to move toward the exact object boundary. What’s more, it is proved to be convex and ensures the segmentation results independent of initialization. The hybrid fuzzy region term can balance the importance of the object and background while the local fuzzy region term by incorporating spatial and local information can decrease the effect of intensity inhomogeneity in given images. The edge energy is used to regularize the pseudo level set function (LSF) and maintain the appearance of the smoothness during the curve evolution . Inspired by the fuzzy energy-based active contour (FEAC), a more direct and simpler method is developed to calculate the difference between the old and new energy functions to update the pseudo LSF during the curve evolution . Experimental results on synthetic and real images with high noise and intensity inhomogeneity show that the proposed model can obtain better performance than the state-of-the-art active contour models. The code is available at: https://github.com/fangchj2002/HLFRA .},
  archive      = {J_ISCI},
  author       = {Jiangxiong Fang and Huaxiang Liu and Liting Zhang and Jun Liu and Hesheng Liu},
  doi          = {10.1016/j.ins.2020.08.078},
  journal      = {Information Sciences},
  pages        = {397-419},
  shortjournal = {Inf. Sci.},
  title        = {Region-edge-based active contours driven by hybrid and local fuzzy region-based energy for image segmentation},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gorthaur-EXP3: Bandit-based selection from a portfolio of
recommendation algorithms balancing the accuracy-diversity dilemma.
<em>ISCI</em>, <em>546</em>, 378–396. (<a
href="https://doi.org/10.1016/j.ins.2020.08.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, real-world pervasive computing applications increasingly face multi-objective problems. This is the case for recommendation systems where, from a user’s view point, recommended items must be both accurate and diverse. In recent years, model-based recommendation systems like those relying on Multi-Armed Bandit algorithms have been extensively studied. They are known to ensure theoretical guarantees of global accuracy. Nevertheless, despite these guarantees, the existing algorithms obtain different results depending on the application or on the dataset they operate on. Hence, when one needs to integrate such solutions, they should first be thoroughly evaluated to ensure the chosen method is efficient for the dynamic and potentially non-stationary nature of the target environments. However, human-based evaluations cost in time and money. Here, we propose a novel algorithm portfolio approach, Gorthaur-EXP3 aiming at automatically selecting the optimal algorithms which best maximise global accuracy and diversity of recommendations according to a predefined trade-off. Our method uses the EXP3 bandit algorithm which ensures a continuous exploration and a systematic exploitation of the best algorithm to apply in each situation it encounters. Gorthaur-EXP3 is an extension of the original Gorthaur method, which uses a roulette wheel selection, and obtains better results in most experimental cases.},
  archive      = {J_ISCI},
  author       = {Nicolas Gutowski and Tassadit Amghar and Olivier Camp and Fabien Chhel},
  doi          = {10.1016/j.ins.2020.08.106},
  journal      = {Information Sciences},
  pages        = {378-396},
  shortjournal = {Inf. Sci.},
  title        = {Gorthaur-EXP3: Bandit-based selection from a portfolio of recommendation algorithms balancing the accuracy-diversity dilemma},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-adaptive and deformable convolutional modules for
dynamic scene deblurring. <em>ISCI</em>, <em>546</em>, 368–377. (<a
href="https://doi.org/10.1016/j.ins.2020.08.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate two aspects of network architecture design for dynamic scene deblurring: (1) Learning blur characteristics and their location in dynamic scenes, which corresponds to learning what and where to attend in the channel and spatial axes, respectively. In this regard, we design an attention-adaptive module (AAM), the innovation of which is that it adaptively determines the arrangement of channel and spatial attention modules (i.e., sequentially or in parallel). Ablation experiments verified the effectiveness of the AAM by incorporating it into existing deblurring convolutional neural network (CNN) architectures. (2) Intuitively, geometric variations are widely observed in objects in dynamic scenes because different spatial regions are blurred by different motion kernels. However, owing to the fixed geometric structures in their modules, regular CNNs fail to adapt to these variations. Accordingly, we propose a deformable convolutional module (DCM) to handle geometric variations. Preliminary experiments demonstrated that incorporating the AAM and DCM into existing deblurring models can significantly improve performance. Moreover, it was empirically verified that an encoder–decoder ResBlock network incorporating the proposed modules compares favorably with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Lei Chen and Quansen Sun and Fanhai Wang},
  doi          = {10.1016/j.ins.2020.08.105},
  journal      = {Information Sciences},
  pages        = {368-377},
  shortjournal = {Inf. Sci.},
  title        = {Attention-adaptive and deformable convolutional modules for dynamic scene deblurring},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighted pointwise prediction method for dynamic
multiobjective optimization. <em>ISCI</em>, <em>546</em>, 349–367. (<a
href="https://doi.org/10.1016/j.ins.2020.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction methods are useful tools for dynamic multiobjective optimization (DMO), especially if the changes roughly follow some patterns. Multi-model prediction methods, in particular, may capture different types of change patterns; however, they should address two issues. First, they should define a similarity measure that can correctly find the corresponding Pareto-optimal solutions in two successive time steps. Second, they should be reasonably robust to input errors. This study introduces a new information-sharing strategy to improve the robustness of multi-model prediction methods in which each prediction model utilizes some information from the individual models of adjacent solutions. An adaptive scheme based on the relative distribution of population members is also proposed to utilize this information properly. The efficacy of this strategy in improving the robustness of the multi-model prediction method is demonstrated. Furthermore, this study introduces a similarity metric and thoroughly analyzes it alongside some of the commonly used similarity metrics for DMO. A weighted pointwise prediction method (WPPM) for DMO is then developed using the formulated information-sharing strategy and the proposed variable-based similarity metric. WPPM is compared with other well-known prediction methods on the CEC2018 test suite for DMO, with the numerical results revealing the superiority of WPPM.},
  archive      = {J_ISCI},
  author       = {Ali Ahrari and Saber Elsayed and Ruhul Sarker and Daryl Essam and Carlos A. Coello Coello},
  doi          = {10.1016/j.ins.2020.08.015},
  journal      = {Information Sciences},
  pages        = {349-367},
  shortjournal = {Inf. Sci.},
  title        = {Weighted pointwise prediction method for dynamic multiobjective optimization},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Users’ mobility enhances information diffusion in online
social networks. <em>ISCI</em>, <em>546</em>, 329–348. (<a
href="https://doi.org/10.1016/j.ins.2020.07.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online social networks have gradually changed the way that people exchange information as increasingly more people spread information via social networks. Most of the prior literature about propagation dynamics stresses static networks. Actually, owing to the openness of the network environment, users can freely enter and leave social networks. Therefore, we consider users’ mobility and establish the information diffusion model called the in-out-Unacquired-Acquired-Rejected in online social networks. Specifically, we derive the information diffusion system using mean field theory. From theoretical analysis, the propagation threshold R 0 R0 of the information diffusion system is obtained. We prove that if R 0 R0&amp;lt;1 , then the information-free equilibrium of the model is globally asymptotically stable and if R 0 &gt; 1 R0&amp;gt;1 , then the information is permanently diffused. By means of numerical simulations using Sina Weibo, this paper verifies the theoretical analysis and the simulation results show that the larger the value of R 0 R0 , the better the information diffusion effect in online social networks. Moreover, users’ mobility increases the connections among users and further expands the information diffusion. In addition, comparative experiments with the susceptible-infected-recovered (SIR) model also illustrate the applicability of our information diffusion model.},
  archive      = {J_ISCI},
  author       = {Yanan Wang and Jun Wang and Haiying Wang and Ruilin Zhang and Ming Li},
  doi          = {10.1016/j.ins.2020.07.061},
  journal      = {Information Sciences},
  pages        = {329-348},
  shortjournal = {Inf. Sci.},
  title        = {Users’ mobility enhances information diffusion in online social networks},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A scheduling approach with uncertainties in generation and
consumption for converter gas system in steel industry. <em>ISCI</em>,
<em>546</em>, 312–328. (<a
href="https://doi.org/10.1016/j.ins.2020.06.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linz–Donawitz converter gas (LDG) is a class of significant secondary energy in steel enterprises, and its adequate recycling can help save energy, reduce emission and improve profit. Aiming at the scheduling problem with uncertainties in both gas generation and consumption, a three-layer-causal-network-based approach for LDG system is proposed in this study. Two causality-based methods by employing causal exception estimation and working condition clustering are designed to construct the prediction intervals (PIs) of the gas generation and consumption flows respectively. Given that the surplus or shortage range of the LDG that can keep the tank levels balance can be calculated, a three-layer causal network of “generation-storage-consumption” is established to describe and evaluate the scheduling rules. Then, the solution is finally optimized based on the objective function and its corresponding constraints constructed by the safety, environmental and economic indicators. To verify the performance of the proposed method, the experiments by using real-world data coming from a steel plant are carried out, where the manual approach and the existing mixed-integer-linear-programming-based one in literature are also employed as comparative ones. The results indicate that the proposed method is capable of providing superior performance for such an industrial application.},
  archive      = {J_ISCI},
  author       = {Feng Jin and Jun Zhao and Ying Liu and Wei Wang and Qingshan Xu},
  doi          = {10.1016/j.ins.2020.06.063},
  journal      = {Information Sciences},
  pages        = {312-328},
  shortjournal = {Inf. Sci.},
  title        = {A scheduling approach with uncertainties in generation and consumption for converter gas system in steel industry},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). DRSL: Deep relational similarity learning for cross-modal
retrieval. <em>ISCI</em>, <em>546</em>, 298–311. (<a
href="https://doi.org/10.1016/j.ins.2020.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval aims to retrieve relevant samples across different media modalities. Existing cross-modal retrieval approaches are contingent on learning common representations of all modalities by assuming that an equal amount of information exists in different modalities. However, since the quantity of information among cross-modal samples is unbalanced and unequal, it is inappropriate to directly match the obtained modality-specific representations across different modalities in a common space. In this paper, we propose a new method called Deep Relational Similarity Learning (DRSL) for cross-modal retrieval. Unlike existing approaches, the proposed DRSL aims to effectively bridge the heterogeneity gap of different modalities by directly learning the natural pairwise similarities instead of explicitly learning a common space. DRSL is a deep hybrid framework that integrates the relation networks module for relation learning, capturing the implicit nonlinear distance metric. To the best of our knowledge, DRSL is the first approach that incorporates relation networks into the cross-modal learning scenario. Comprehensive experimental results show that the proposed DRSL model achieves state-of-the-art results in cross-modal retrieval tasks on four widely-used benchmark datasets, i.e. , Wikipedia, Pascal Sentences, NUS-WIDE-10K, and XMediaNet.},
  archive      = {J_ISCI},
  author       = {Xu Wang and Peng Hu and Liangli Zhen and Dezhong Peng},
  doi          = {10.1016/j.ins.2020.08.009},
  journal      = {Information Sciences},
  pages        = {298-311},
  shortjournal = {Inf. Sci.},
  title        = {DRSL: Deep relational similarity learning for cross-modal retrieval},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered guaranteed cost consensus control for
second-order multi-agent systems based on observers. <em>ISCI</em>,
<em>546</em>, 283–297. (<a
href="https://doi.org/10.1016/j.ins.2020.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the event-triggered guaranteed cost consensus problem is considered for second-order multi-agent systems whose system states are unmeasurable. First, an observer-based distributed event-triggered condition is presented. The triggering time series for each agent is different, and the controller with a time-varying delay is updated only at the triggered times, which can reduce the communication time effectively. Second, using the event-triggered condition and the Lyapunov method , several sufficient conditions are obtained to achieve the guaranteed cost output feedback consensus. Moreover, for each event-triggered interval, a positive lower bound can be calculated, leading to the avoidance of Zeno behaviors. Third, appropriate controller and observer gains can be designed using the linear matrix inequality technique, which is verified through numerical simulations.},
  archive      = {J_ISCI},
  author       = {Yiping Luo and Xing Xiao and Jinde Cao and Anping Li and Guohan Lin},
  doi          = {10.1016/j.ins.2020.08.010},
  journal      = {Information Sciences},
  pages        = {283-297},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered guaranteed cost consensus control for second-order multi-agent systems based on observers},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A geometry constrained dictionary learning method for
industrial process monitoring. <em>ISCI</em>, <em>546</em>, 265–282. (<a
href="https://doi.org/10.1016/j.ins.2020.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven process monitoring methods have attracted great attention due to the case that it can provide an efficient way to cope with the industrial process without the need of first-principle models. The local information that results from the reaction process often influences the process monitoring result. Unfortunately, this local information is usually ignored in the data-driven process monitoring method. In this paper, a geometry constrained dictionary learning (GCDL) method is proposed to address the above problem. By exploiting the underlying characteristics and simultaneously holding the local geometrical information, the GCDL method leads to a balance between the reconstructive item and the discriminative item. Inspired by the manifold method, the GCDL method can provide discriminative sparse coding, which means that samples that belong to the same class will share similar sparse coding. It is in accordance with the fact that the samples of different categories often reside on different subspaces embedded in a high-dimensional feature space. The effectiveness of the proposed method is evaluated through two numerical simulation cases, a continuous stirred tank reactor (CSTR) case and a real industrial aluminum electrolysis process. Extensive experimental results reveal that the proposed method shows better performance by taking the local geometrical information into consideration.},
  archive      = {J_ISCI},
  author       = {Keke Huang and Haofei Wen and Han Liu and Chunhua Yang and Weihua Gui},
  doi          = {10.1016/j.ins.2020.08.025},
  journal      = {Information Sciences},
  pages        = {265-282},
  shortjournal = {Inf. Sci.},
  title        = {A geometry constrained dictionary learning method for industrial process monitoring},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An efficient anti-quantum lattice-based blind signature for
blockchain-enabled systems. <em>ISCI</em>, <em>546</em>, 253–264. (<a
href="https://doi.org/10.1016/j.ins.2020.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blockchain technology has a tendency to make revolutionary changes for all walks of life with its public, distributed, decentration and unforgeable characteristics. However, with the rapid development of the quantum computer , many extant cryptographic algorithms applied in blockchain-enabled systems are vulnerable to the quantum attacks. In this paper, an anti-quantum blind signature scheme based on the lattice assumption has been proposed. As lattice cryptography is the main candidate algorithm in post-quantum cryptosystems and the blind signature scheme is widely used in e-cash and voting for creating untraceable payment system, which are more suitable for privacy preserving in blockchain-enabled systems. In the proposed scheme, the bimodal Gaussian distribution , Reject sampling and other technologies have been used to improve the security and efficiency. Then, the proposed blind signature can satisfy the properties of blindness and one-more unforgeability, and it also can prove to be safe in the random oracle model . Moreover, the efficiency analysis and comparison results show that the proposed scheme is more efficient than the similar literatures and has a more stabilized signature size than other cryptosystems .},
  archive      = {J_ISCI},
  author       = {Chaoyang Li and Yuan Tian and Xiubo Chen and Jian Li},
  doi          = {10.1016/j.ins.2020.08.032},
  journal      = {Information Sciences},
  pages        = {253-264},
  shortjournal = {Inf. Sci.},
  title        = {An efficient anti-quantum lattice-based blind signature for blockchain-enabled systems},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dissipativity analysis and synthesis for positive roesser
systems under the switched mechanism and takagi-sugeno fuzzy rules.
<em>ISCI</em>, <em>546</em>, 234–252. (<a
href="https://doi.org/10.1016/j.ins.2020.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the dissipativity analysis and controller design for a class of T-S fuzzy positive systems which are described by the Roesser model. First, sufficient conditions obtained by utilizing the minimum dwell time method and co-positive Lyapunov function approach are given to guarantee the considered system is 2-D ( ζ,η )- α -dissipative. Then via the state feedback fuzzy controller and the static output feedback fuzzy controller, criteria are also presented under which the resulting closed-loop systems are positive and 2-D ( ζ,η )- α -dissipative. Moreover, the explicit design schemes for the desired controller parameters are also presented in the form of linear programming. Finally, a simple illustrative example is provided to show the validity of the approach outlined in this article.},
  archive      = {J_ISCI},
  author       = {Jinling Wang and Jinling Liang and Cheng-Tang Zhang},
  doi          = {10.1016/j.ins.2020.08.034},
  journal      = {Information Sciences},
  pages        = {234-252},
  shortjournal = {Inf. Sci.},
  title        = {Dissipativity analysis and synthesis for positive roesser systems under the switched mechanism and takagi-sugeno fuzzy rules},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Robust gain-scheduling static output-feedback h∞ control of
vehicle lateral stability with heuristic approach. <em>ISCI</em>,
<em>546</em>, 220–233. (<a
href="https://doi.org/10.1016/j.ins.2020.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a velocity-dependent static output-feedback control method to improve the vehicle lateral stability and handling performance. The uncertainties of longitudinal velocity , tire cornering stiffness and actuator saturation are taken into account. Considering the unmeasurable state in practice, a robust gain-scheduling output-feedback H ∞ H∞ controller is designed based on the measurable velocity. By employing a two-stage heuristic approach , the output-feedback controller gain is obtained based on the state-feedback controller gain, which would be more favorable in application. The simulation results with two steering maneuvers indicate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Pengxu Li and Panshuo Li and Jing Zhao and Bin Zhang},
  doi          = {10.1016/j.ins.2020.08.023},
  journal      = {Information Sciences},
  pages        = {220-233},
  shortjournal = {Inf. Sci.},
  title        = {Robust gain-scheduling static output-feedback h∞ control of vehicle lateral stability with heuristic approach},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monodirectional tissue p systems with channel states.
<em>ISCI</em>, <em>546</em>, 206–219. (<a
href="https://doi.org/10.1016/j.ins.2020.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tissue P systems with channel states are non-deterministic bio-inspired computing devices that evolve by the interchange of objects among regions, determined by the existence of some special objects on channels called states . However, in cellular biology, the movement of molecules across a membrane is transported from high to low concentration, inspired by this biological fact, in this paper, a variant of P systems , named monodirectional tissue P systems with channel states , where communication happens between two given regions only in one direction, is considered. We show that monodirectional tissue P systems using two cells are universal if a maximal length 1 for each symport rule and any number of states or a maximal length 2 for each symport rule and 4 states are combined. Universality result is also achieved by monodirectional tissue P systems with 5 states, any number of cells and a maximal length 1 for each symport rule. Besides, computational efficiency of monodirectional tissue P systems is analyzed when cell division rules are incorporated, and a solution to the Boolean satisfiability problem (the SAT problem) is provided by such systems using a maximal length 2 for each symport rule.},
  archive      = {J_ISCI},
  author       = {Bosheng Song and Xiangxiang Zeng and Alfonso Rodríguez-Patón},
  doi          = {10.1016/j.ins.2020.08.030},
  journal      = {Information Sciences},
  pages        = {206-219},
  shortjournal = {Inf. Sci.},
  title        = {Monodirectional tissue p systems with channel states},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of stealthy false data injection attacks against
networked control systems via active data modification. <em>ISCI</em>,
<em>546</em>, 192–205. (<a
href="https://doi.org/10.1016/j.ins.2020.06.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the design and detection problems of stealthy false data injection (FDI) attacks against networked control systems from the different perspectives of an attacker and a defender, respectively. First, a Kalman filter-based output tracking control system is presented, where stealthy FDI attacks are designed for its feedback and forward channels so as to destroy the system performance while bypassing a traditional residual-based detector. Second, to successfully detect such two-channel stealthy attacks, an active data modification scheme is proposed, by which the measurement and control data are amended before transmitting them through communication networks. Theoretical analysis is then carried out for both ideal and practical cases to evaluate the effectiveness of the detection scheme. An interesting finding is that the attacks designed based on a false model obtained from those modified data can remain stealthy. Finally, simulation results are provided to validate the proposed attack design and detection schemes.},
  archive      = {J_ISCI},
  author       = {Zhong-Hua Pang and Lan-Zhi Fan and Jian Sun and Kun Liu and Guo-Ping Liu},
  doi          = {10.1016/j.ins.2020.06.074},
  journal      = {Information Sciences},
  pages        = {192-205},
  shortjournal = {Inf. Sci.},
  title        = {Detection of stealthy false data injection attacks against networked control systems via active data modification},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Achieving low-entropy secure cloud data auditing with file
and authenticator deduplication. <em>ISCI</em>, <em>546</em>, 177–191.
(<a href="https://doi.org/10.1016/j.ins.2020.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud data auditing with file and authenticator deduplication can not only check the integrity of cloud data, but also reduce the cloud’s storage overhead significantly. In this paper, we propose a cloud data auditing scheme supporting file and authenticator deduplication . To the best of our knowledge, the proposed scheme is the first practical one that truly achieves low-entropy security. For the file with low-entropy, the malicious cloud cannot forge any authenticator to pass the auditing verification. The proposed scheme is user-friendly. Users do not need to keep interacting with the Third Party Auditor (TPA) in the auditing phase. We give the detailed security proof to show that the proposed scheme is secure. Comprehensive experiments show the efficiency of our scheme.},
  archive      = {J_ISCI},
  author       = {Xiang Gao and Jia Yu and Wen-Ting Shen and Yan Chang and Shi-Bin Zhang and Ming Yang and Bin Wu},
  doi          = {10.1016/j.ins.2020.08.021},
  journal      = {Information Sciences},
  pages        = {177-191},
  shortjournal = {Inf. Sci.},
  title        = {Achieving low-entropy secure cloud data auditing with file and authenticator deduplication},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair hierarchical secret sharing scheme based on smart
contract. <em>ISCI</em>, <em>546</em>, 166–176. (<a
href="https://doi.org/10.1016/j.ins.2020.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Secret sharing has a number of practical applications in network-based scenarios, such as key transfer protocols, attribute-based encryption and secure multiparty computation. However, existing secret sharing schemes cannot efficiently achieve fairness. They either rely on a trusted third party or require multiple rounds of communication. In this paper, we propose the first decentralized and fair hierarchical threshold secret sharing (HTSS) scheme using blockchain. In the scheme, secret shares are distributed to different levels of parties, and any authorized subset of parties can obtain the secret. We leverage a smart contract to force all participants to commit to the secret shares; otherwise, the committer either reveals his secret share within a certain time frame or pays a fine. Thus, unlike previous HTSS schemes, the participants can reconstruct the secret fairly using Birkhoff interpolation without a trusted party and complete the computation in one round. We formally prove that our scheme is secure. We evaluate the performance of the scheme by implementing our scheme on Ethereum’s official test network. Our experiments show that our scheme can run reasonably fast and is practical.},
  archive      = {J_ISCI},
  author       = {En Zhang and Ming Li and Siu-Ming Yiu and Jiao Du and Jun-Zhe Zhu and Gang-Gang Jin},
  doi          = {10.1016/j.ins.2020.07.032},
  journal      = {Information Sciences},
  pages        = {166-176},
  shortjournal = {Inf. Sci.},
  title        = {Fair hierarchical secret sharing scheme based on smart contract},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised classification via simultaneous label and
discriminant embedding estimation. <em>ISCI</em>, <em>546</em>, 146–165.
(<a href="https://doi.org/10.1016/j.ins.2020.07.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph-based semi-supervised learning has recently proved to be a powerful paradigm for processing and mining large datasets. The main advantage relies on the fact that these methods can be useful in propagating a small set of known labels to a large set of unlabeled data . However, the lack of labeled data in real applications may affect the semi-supervised learning’s performance. This paper introduces a new semi-supervised framework for simultaneous linear feature extraction and label propagation. The proposed method simultaneously estimates a discriminant transformation, as well as the unknown label, by exploiting both labeled and unlabeled data . The learning model’s unknowns are to be estimated by integrating two types of graph-based smoothness constraints. The resulting semi-supervised model is expected to learn more discriminative information. Experiments are conducted on nine public image datasets. These experimental results show that the proposed method’s performance can be better than that of many state-of-the-art graph-based semi-supervised algorithms.},
  archive      = {J_ISCI},
  author       = {F. Dornaika and A. Baradaaji and Y. El Traboulsi},
  doi          = {10.1016/j.ins.2020.07.065},
  journal      = {Information Sciences},
  pages        = {146-165},
  shortjournal = {Inf. Sci.},
  title        = {Semi-supervised classification via simultaneous label and discriminant embedding estimation},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixed-noise robust face super-resolution through
residual-learning based error suppressed nearest neighbor
representation. <em>ISCI</em>, <em>546</em>, 121–145. (<a
href="https://doi.org/10.1016/j.ins.2020.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The conventional face super-resolution (SR) methods are highly sensitive to noise because of signal conversion error, bit error in transmission, heat, and illumination effects in the camera sensor. This paper proposes a new position-patch based face SR method, namely RLENR, which effectively enhances the low-resolution (LR) facial images impaired with heavy mixed (Gaussian and impulse) noise. Firstly, it suppresses the impulse noise (IN) from the LR face image by utilizing the PCA oriented mate face and the matrix having pixel-wise noise details. Subsequently, it minimizes the effect of Gaussian noise (GN) by incorporating the residual-learning to update the LR training set. Meanwhile, it hallucinates the respective LR face using the updated LR training set. Here, the residual means reconstruction error occurred by the GN . It employs the sparse set of similar patches from the training samples to generate the optimal weights for LR patch representation. Thus, the method simultaneously achieves both the sparsity and locality to recover vital information of the face. The results of extensive experiments on standard facial image dataset, real-world face image dataset, and surveillance face images confirm that the RLENR method quantitatively and visually outperforms state-of-the-art face SR methods.},
  archive      = {J_ISCI},
  author       = {Surendra Nagar and Ankush Jain and Pramod Kumar Singh and Ajay Kumar},
  doi          = {10.1016/j.ins.2020.08.002},
  journal      = {Information Sciences},
  pages        = {121-145},
  shortjournal = {Inf. Sci.},
  title        = {Mixed-noise robust face super-resolution through residual-learning based error suppressed nearest neighbor representation},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimal (∊,δ)-differentially private learning of
distributed deep fuzzy models. <em>ISCI</em>, <em>546</em>, 87–120. (<a
href="https://doi.org/10.1016/j.ins.2020.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces a privacy-preserving framework for distributed deep fuzzy learning. Assuming training data as private, the problem of learning of local deep fuzzy models is considered in a distributed setting under differential privacy framework. A local deep fuzzy model, formed by a composition of a finite number of Takagi-Sugeno type fuzzy filters, is learned using variational Bayesian inference . This paper suggests an optimal ∊ ( ∊ , δ ) (∊,δ) -differentially private noise adding mechanism that results in multi-fold reduction in noise magnitude over the classical Gaussian mechanism and thus leads to an increased utility for a given level of privacy. Further, the robustness feature, offered by the rule-based fuzzy systems, is leveraged to alleviate the effect of added data noise on the utility. An architecture for distributed form of differentially private learning is suggested where a privacy wall separates the private local training data from the globally shared data, and fuzzy sets and fuzzy rules are used to aggregate robustly the local deep fuzzy models for building the global model. The privacy wall uses noise adding mechanisms to attain differential privacy for each participant’s private training data and thus the adversaries have no direct access to the training data.},
  archive      = {J_ISCI},
  author       = {Mohit Kumar and Michael Rossbory and Bernhard A. Moser and Bernhard Freudenthaler},
  doi          = {10.1016/j.ins.2020.07.044},
  journal      = {Information Sciences},
  pages        = {87-120},
  shortjournal = {Inf. Sci.},
  title        = {An optimal (∊,δ)-differentially private learning of distributed deep fuzzy models},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fuzzy appraisal model for affective agents adapted to
cultural environments using the pleasure and arousal dimensions.
<em>ISCI</em>, <em>546</em>, 74–86. (<a
href="https://doi.org/10.1016/j.ins.2020.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Humans use rather vague and imprecise words to express emotions. Therefore, fuzzy logic allows computational affective models to use emotions in the same way that human beings express them. However, people from different cultures and languages assign different meanings to the same emotion word. Unfortunately, there are still no affective computing models that really take these two factors into consideration. In this paper, we propose a fuzzy model of appraisal for multi-agent systems that is adapted to Spanish-speakers. Our methodology has two steps. First, the agent evaluates an event using a set of fuzzy appraisal rules that returns a fuzzy emotion. Then, a defuzzification process returns the Pleasure and Arousal dimensions of the emotion that will be internally represented as a vector in a two-dimensional space. This vector is used to update the agent’s mood according to the agent’s personality. The agent can express this internal emotional state using a fuzzification process that translates the agent’s mood into a fuzzy emotion. This fuzzification process uses the results of an experiment to generate a fuzzy emotion that is adapted to the cultural environment in which the agent is located. This methodology can be easily adapted to other languages.},
  archive      = {J_ISCI},
  author       = {Joaquin Taverner and Emilio Vivancos and Vicente Botti},
  doi          = {10.1016/j.ins.2020.08.006},
  journal      = {Information Sciences},
  pages        = {74-86},
  shortjournal = {Inf. Sci.},
  title        = {A fuzzy appraisal model for affective agents adapted to cultural environments using the pleasure and arousal dimensions},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Logical foundations of knowledge-based recommender systems:
A unifying spectrum of alternatives. <em>ISCI</em>, <em>546</em>, 60–73.
(<a href="https://doi.org/10.1016/j.ins.2020.07.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this paper is to provide logical foundations for knowledge-based recommender systems , for which, unlike other problem solving tasks, a comprehensive formalization is not yet available. This goal is justified by the need to compare recommenders based on the way they use knowledge to generate recommendations and, consequently, on the underlying semantics of the recommendation process itself. Moreover, since the here adopted logical formalization has been borrowed from other tasks such as diagnosis, many interesting results and opportunities can be transposed from such tasks to recommendation. While we do not aim at proposing a new recommendation generation technique, we believe that our formalization will be the basis for unifying different approaches to knowledge-based recommendation, revealing their semantics and offering a conceptual framework to compare them. In fact, the framework covers different variations of knowledge-based recommendation, such as context-aware, constraints-based, package and group recommendation, as well as recommendation based on negative preferences.},
  archive      = {J_ISCI},
  author       = {Federica Cena and Luca Console and Fabiana Vernero},
  doi          = {10.1016/j.ins.2020.07.075},
  journal      = {Information Sciences},
  pages        = {60-73},
  shortjournal = {Inf. Sci.},
  title        = {Logical foundations of knowledge-based recommender systems: A unifying spectrum of alternatives},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of adaptive reliability importance
sampling-based extended domain PSO on single mode failure in reliability
engineering. <em>ISCI</em>, <em>546</em>, 42–59. (<a
href="https://doi.org/10.1016/j.ins.2020.07.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The failures of mechanical structure featuring high nonlinearity, non-normal and non-independent are implicit function and small-probability events. This normally results in low computational efficient and accuracy for gradient algorithm scenario, which can hardly calculate models for large complex structure and flexible systems. To deal with the above constraints, an efficient and accurate reliability numerical method named adaptive reliability index importance sampling-based extended domain PSO (ARIIS-EDPSO) is proposed to combine the reliability numerical simulation and the particle swarm optimization (PSO) algorithm. The reliability index and limit state equation in ARIIS-EDPSO are regarded as the objective function and the constraint function. The Nataf transformation is adopted to complete the conversion process from an original variable space to an independent standard normal space, which only requires the marginal probability density function and the correlation coefficient among the random variables . To verify the effectiveness of the proposed ARIIS-EDPSO, experimental studies are conducted with five case studies. The results indicate that the constraint conflict function obtained via ARIIS-EDPSO is smaller than that is obtained via the other methods, and its convergence can be guaranteed. Also, the accuracy of the ARIIS-EDPSO is superior to the other methods for nonlinear reliability calculation. Furthermore, the ARIIS-EDPSO can accurately predict the failure probability . This approach exhibits advantageous global search ability, high efficiency and high accuracy in solving constrained reliability engineering problems.},
  archive      = {J_ISCI},
  author       = {Bin Bai and Zhiwei Guo and Ce Zhou and Wei Zhang and Junyi Zhang},
  doi          = {10.1016/j.ins.2020.07.069},
  journal      = {Information Sciences},
  pages        = {42-59},
  shortjournal = {Inf. Sci.},
  title        = {Application of adaptive reliability importance sampling-based extended domain PSO on single mode failure in reliability engineering},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable and redactable blockchain with update and
anonymity. <em>ISCI</em>, <em>546</em>, 25–41. (<a
href="https://doi.org/10.1016/j.ins.2020.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-of-Things (IoT) envisions communications between heterogeneous devices and utilization of the associated data for smart decision making. Blockchain bridges the gap between widely-distributed IoT devices and the need for a universal trust-layer. When applying blockchain for IoT, some concerns can arise. Among them, scalability is a crucial factor because it decides whether blockchain can keep empowering IoT in the long term. According to a recent survey by Ali et al., some newly launched blockchains are suffering from powerful attacks (e.g. 51\% attack) when the computing pool is small, and the number of participated nodes is inadequate (USENIX 2016). To ensure the scalability of initially-deployed blockchains, a proper countermeasure is important to be devised. Ateniese et al. proposed the notion of the redactable blockchain (EuroS&amp;P 2017) which allows block history to be rewritten by using chameleon hash. However, the distribution and management of trapdoor key is crucial for the scalability of chameleon hash as well as redactable blockchain. To deal with the above problems, we propose two cryptographic schemes as the new theoretic tools for blockchain redaction: time updatable chameleon hash (TUCH) and linkable-and-redactable ring signature (LRRS). The use of TUCH and LRRS schemes enables redaction to take place scalably and anonymously where the spontaneous ring is generated for redaction, which costs little expenditures to rewrite a block content. Specifically, the redaction will be processed without assigning and splitting trapdoor key among multiple users in a complex way, and achieve transaction anonymity for users. What is more, we briefly instantiate how to build a redactable blockchain with update and anonymity (SRB) with our proposed TUCH and LRRS. While security analysis confirms that our proposals are theoretically secure, the experimental results show that our proposals are efficient for implementation purposes.},
  archive      = {J_ISCI},
  author       = {Ke Huang and Xiaosong Zhang and Yi Mu and Fatemeh Rezaeibagha and Xiaojiang Du},
  doi          = {10.1016/j.ins.2020.07.016},
  journal      = {Information Sciences},
  pages        = {25-41},
  shortjournal = {Inf. Sci.},
  title        = {Scalable and redactable blockchain with update and anonymity},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DI-mondrian: Distributed improved mondrian for satisfaction
of the l-diversity privacy model using apache spark. <em>ISCI</em>,
<em>546</em>, 1–24. (<a
href="https://doi.org/10.1016/j.ins.2020.07.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the extraction of useful patterns, the collected data should be distributed to and shared with analyzers. This, however, creates problems and challenges for the individual with respect to their privacy and identity. In this paper, the Mondrian multidimensional anonymization method was developed and improved for satisfaction of the l -diversity privacy model, and it has been presented in a distributed fashion within the Apache Spark framework. Since one of the major challenges in data privacy is the tradeoff between privacy and data utility, the presented method focuses on information loss and classifier evaluation criteria. Therefore, the cut dimension was selected using the coefficient of variation and information gain criteria, and the cut points were chosen dynamically, which led to a decrease in the information loss parameter and an improvement in the classifier performance evaluation criteria such as accuracy and FMeasure compared to the previous algorithms in the literature. The processing speed is 100 times higher in Spark than in the Hadoop framework. Consequently, the proposed method was presented in a distributed fashion based on RDDs programming within Apache Spark framework. This will resolve the problem of speed in large-scale data anonymization as it exists in the previous Hadoop-based algorithms. The results of the experiments performed on the numerical datasets demonstrate the improvements made by the proposed method.},
  archive      = {J_ISCI},
  author       = {Farough Ashkouti and Keyhan khamforoosh and Amir Sheikhahmadi},
  doi          = {10.1016/j.ins.2020.07.066},
  journal      = {Information Sciences},
  pages        = {1-24},
  shortjournal = {Inf. Sci.},
  title        = {DI-mondrian: Distributed improved mondrian for satisfaction of the L-diversity privacy model using apache spark},
  volume       = {546},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LIG-doctor: Efficient patient trajectory prediction using
bidirectional minimal gated-recurrent networks. <em>ISCI</em>,
<em>545</em>, 813–827. (<a
href="https://doi.org/10.1016/j.ins.2020.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The interest for patient trajectory prediction, a sort of computer-aided medicine, has steadily increased with the pace of artificial intelligence innovation. Notwithstanding, the design of effective systems able to predict clinical outcomes based on the history of a patient is far from trivial. Works so far are based on neural architectures with low performance, especially when using low-cardinality datasets; alternatively, complex inference approaches are hard to reproduce and/or extrapolate as they are designed for very specific circumstances. We introduce LIG-Doctor, an artificial neural network architecture based on two Minimal Gated Recurrent Unit networks functioning in a bidirectional parallel manner, benefiting from temporal events both forward and backward. In comparison to state-of-the-art works, consistent improvements were achieved in prognosis prediction, as assessed with metrics Recall@k, Precision@k, F1-score, and AUC-ROC. Besides the detailed delineation of our architecture, a sequence of experiments is reported with insights that progressively guided design decisions to inspire future works on similar problems. Our results shall contribute to the improvement of computer-aided medicine and, more generally, to processes related to the design of neural network architectures.},
  archive      = {J_ISCI},
  author       = {Jose F. Rodrigues-Jr and Marco A. Gutierrez and Gabriel Spadon and Bruno Brandoli and Sihem Amer-Yahia},
  doi          = {10.1016/j.ins.2020.09.024},
  journal      = {Information Sciences},
  pages        = {813-827},
  shortjournal = {Inf. Sci.},
  title        = {LIG-doctor: Efficient patient trajectory prediction using bidirectional minimal gated-recurrent networks},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data clustering via cooperative games: A novel approach and
comparative study. <em>ISCI</em>, <em>545</em>, 791–812. (<a
href="https://doi.org/10.1016/j.ins.2020.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Arguably, the main purpose of cluster analysis is to develop algorithms to reveal natural groupings (clusterings) over a set of data points based on their similarity. On the other hand, the focus of cooperative game theory (CGT) is to study the formation of groups (coalitions) of decision makers (players) and ways to split the resulting income among them. Due to the conceptual similitude between these fields, algorithms rooted in CGT have recently emerged for tackling the data clustering problem. In this work, we revisit two such algorithms, one based on cluster prototypes ( Biobjective Game Clustering – BiGC) and the other based on dense regions of data points ( Density-Restricted Agglomerative Clustering – DRAC). We also present a novel partitional clustering algorithm , referred to as HGC (after Hedonic Game based Clustering ), which is grounded on theoretical results stemming from the subclass of hedonic games. Two HGC versions are investigated, which differ in the order of the players in the game, and a detailed factorial simulation study is reported to analyze how sensitive they are to three relevant factors, namely number of clusters, number of features, and noise level. Besides, a heuristic to calibrate the value of HGC’s single control parameter (viz., the number of nearest neighbors of each point) is provided, so as to yield high-quality partitions. To compare the performance of the CGT algorithms, a series of experiments were conducted on UCI and gene-expression data sets, the majority of which being high dimensional. Overall, the results measured by 10 external validation indices evidence that HGC is usually more stable and effective than DRAC and BiGC. They also show that HGC is very competitive (sometimes, considerably better) to well-known clustering algorithms/variants (specifically, k -means, k -means++, affinity propagation, two variants of hierarchical clustering, and the density peak clustering algorithm). Remarkably, HGC could fully recover the true clustering structures for two gene-expression data sets.},
  archive      = {J_ISCI},
  author       = {André L.V. Coelho and Nelson C. Sandes},
  doi          = {10.1016/j.ins.2020.09.018},
  journal      = {Information Sciences},
  pages        = {791-812},
  shortjournal = {Inf. Sci.},
  title        = {Data clustering via cooperative games: A novel approach and comparative study},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ground truthing from multi-rater labeling with three-way
decision and possibility theory. <em>ISCI</em>, <em>545</em>, 771–790.
(<a href="https://doi.org/10.1016/j.ins.2020.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, Machine Learning (ML) has attracted wide interest as aid for decision makers in complex domains, such as medicine. Although domain experts are typically aware of the intrinsic uncertainty around it, the issue of Ground Truth (GT) quality has scarcely been addressed in the ML literature. GT quality is regularly assumed to be adequate, regardless of the number and skills of raters involved in data annotation. These factors can, however, potentially have a severe negative impact on the reliability of ML models. In this article we study the influence of GT quality, in terms of number of raters, their expertise, and their agreement level, on the performance of ML models. We introduce the concept of reduction : computational procedures by which to produce single-target GT from multi-rater settings. We propose three reductions, based on three-way decision , possibility theory , and probability theory . We provide characterizations of these reductions from the perspective of learning theory and propose two ML algorithms . We report the result of experiments, on both real-world medical and synthetic datasets , showing that GT quality strongly impacts on the performance of ML models, and that the proposed algorithms can better handle this form of uncertainty compared with state-of-the-art approaches.},
  archive      = {J_ISCI},
  author       = {Andrea Campagner and Davide Ciucci and Carl-Magnus Svensson and Marc Thilo Figge and Federico Cabitza},
  doi          = {10.1016/j.ins.2020.09.049},
  journal      = {Information Sciences},
  pages        = {771-790},
  shortjournal = {Inf. Sci.},
  title        = {Ground truthing from multi-rater labeling with three-way decision and possibility theory},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and analyzing cascading failures for internet of
things. <em>ISCI</em>, <em>545</em>, 753–770. (<a
href="https://doi.org/10.1016/j.ins.2020.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network survivability is one of the key challenges that the Internet of Things (IoTs) has to deal with, and cascading failures are one of the main bottlenecks affecting the network survivability of the IoTs. In this work, we fully considered the real characteristics of IoTs systems ( i.e., data aggregation and link heterogeneity), and proposed a realistic cascading model based on the layered architecture of the IoTs. In this model, the cascading process of the IoTs is driven by the overload events of relay nodes , base stations and communication links. To help the IoTs improve network survivability, a load-oriented layout scheme for base stations is presented. Through extensive simulations, the soundness of the proposed cascading model and the effectiveness of the proposed layout scheme have been verified, and some meaningful findings are obtained: there is a fully tolerance parameter space for the capacity expansion of network components, and when the expansion coefficients are in this space, the removal of a single network component will not trigger cascading failures ; compared with removing other types of network components individually, removing base stations is more likely to trigger cascading failures; in addition to capacity expansion, deploying more base stations can also significantly improve network survivability.},
  archive      = {J_ISCI},
  author       = {Xiuwen Fu and Yongsheng Yang},
  doi          = {10.1016/j.ins.2020.09.054},
  journal      = {Information Sciences},
  pages        = {753-770},
  shortjournal = {Inf. Sci.},
  title        = {Modeling and analyzing cascading failures for internet of things},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cloud-aided privacy-preserving multi-dimensional data
comparison protocol. <em>ISCI</em>, <em>545</em>, 739–752. (<a
href="https://doi.org/10.1016/j.ins.2020.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the emergence of mobile social networks, users can make friends or negotiate projects at any time and anywhere in social communities through their mobile devices (such as smartphones, iPads). The two sides of making friends or cooperation want to know the comparison results between each other in many aspects. Aiming at the requirements of these interactive applications in social networks and considering the limited-resource setting of mobile users, in this paper, we propose a cloud-aided privacy-preserving multi-dimensional data comparison protocol. We introduce a novel comparison method for two multi-dimensional data. Because of the blinded processing trick in our comparison method and the Paillier encryption, the proposed protocol can realize our comparison method without revealing users’ data and the comparison results. Besides, a fog device and a cloud server conduct most of the computations. Furthermore, users pack their multi-dimensional data into one data using Horner Rule, making finishing the comparison of two multi-dimensional data through one-round system communication . Therefore, the presented protocol can significantly lower the computation and communication costs of the system, especially that of the user-side. Security analysis is inducted to validate security properties. Moreover, performance evaluations illustrate the computation and communication efficiency of the proposed protocol.},
  archive      = {J_ISCI},
  author       = {Hua Shen and Mingwu Zhang and Hao Wang and Fuchun Guo and Willy Susilo},
  doi          = {10.1016/j.ins.2020.09.052},
  journal      = {Information Sciences},
  pages        = {739-752},
  shortjournal = {Inf. Sci.},
  title        = {A cloud-aided privacy-preserving multi-dimensional data comparison protocol},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-based word embeddings using artificial bee colony
algorithm for aspect-level sentiment classification. <em>ISCI</em>,
<em>545</em>, 713–738. (<a
href="https://doi.org/10.1016/j.ins.2020.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering that most popular models solving aspect-level sentiment classification problems mainly focus on designing complicated neural networks to scale the importance of each word in the sentence, this paper addresses this problem from the view of semantic space. Motivated by the fact that the senses of a word can be sophisticatedly embedded into the semantic space using a distributed representation, this paper hypothesizes that each sense of a word can be represented by one or more specific dimensions, and thus the target of aspect-level sentiment classification can be simplified into searching the related dimensions for the aspects and sentiments concerned. Particularly, an Attention Vector ( ATV ) based on attention mechanism is designed for each aspect in terms of a specific task, which involves two sub-vectors, i.e., a Dimension Attention Vector ( DATV ) and a Sentiment Attention Vector ( SATV ). The DATV determines the significances of different dimensions based on their correlations with an aspect ; and the SATV allocates weights for the attributes of words, which are decided by sentiment polarities and part-of-speech (PoS) tagging. Given a sub-dataset related to an aspect , the ATV will be optimized by an Artificial Bee Colony (ABC) algorithm with a Support Vector Machine (SVM) classifier, the objective of which is to maximize classification accuracy . Intrinsically, the DATV can reduce the ambiguity existing in polysemy, meanwhile, the SATV is an auxiliary means for the optimization of the DATV , which can help eliminate the misunderstandings caused by antonyms. Then, the optimized DATV will be applied on a Convolutional Neural Network (CNN) model via simply scaling the pretrained word embeddings as inputs (named as ATV-CNN model). Experimental results show that the ATV-CNN model can have substantial advantages when compared with state-of-the-art models.},
  archive      = {J_ISCI},
  author       = {Ming Zhang and Vasile Palade and Yan Wang and Zhicheng Ji},
  doi          = {10.1016/j.ins.2020.09.038},
  journal      = {Information Sciences},
  pages        = {713-738},
  shortjournal = {Inf. Sci.},
  title        = {Attention-based word embeddings using artificial bee colony algorithm for aspect-level sentiment classification},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighted co-association rate-based laplacian regularized
label description for semi-supervised regression. <em>ISCI</em>,
<em>545</em>, 688–712. (<a
href="https://doi.org/10.1016/j.ins.2020.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoothness regularization derives the optimal regression function by minimizing the squared loss combined with a smoothness regularizer that restricts the variation of the function within a neighboring region. Thus, the regression function can effectively accommodate intrinsic data structures , and prediction performance can be improved when the label information is insufficient. In this study, we propose a weighted co-association rate-based Laplacian regularized label description algorithm. In the proposed algorithm, we define a regression function by combining weighted co-association rates and a label descriptive function. We use the weighted co-association rate, computed by summarizing various clustering solutions, to depict the data structure. The label descriptive function identifies a latent label distribution, and hence helps the regression function to accurately involve as much true label information as possible. To derive the optimal label descriptive function, we apply the smoothness regularizer to label descriptive function. Experiments were conducted on various benchmark datasets to examine the properties of the proposed algorithms, and the results were compared with those of the existing methods. The experimental results confirm that the proposed algorithm outperforms the previous methods.},
  archive      = {J_ISCI},
  author       = {Jaehong Yu and Youngdoo Son},
  doi          = {10.1016/j.ins.2020.09.015},
  journal      = {Information Sciences},
  pages        = {688-712},
  shortjournal = {Inf. Sci.},
  title        = {Weighted co-association rate-based laplacian regularized label description for semi-supervised regression},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization on data offloading ratio of designed caching in
heterogeneous mobile wireless networks. <em>ISCI</em>, <em>545</em>,
663–687. (<a href="https://doi.org/10.1016/j.ins.2020.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Caching context at small base stations (SBSs) is a prospective approach to relieve backhaul pressure. Numerous prior arts focus on caching strategy by separately considering user mobility and wireless interference, which are two inherent characteristics of heterogeneous mobile wireless networks. Unlike these existing works, we consider the influences of both characteristics together on caching strategy by adopting data offloading ratio (DOR) as a performance metric, which reflects the utilization of resources of SBSs. Here, we will focus on two caching models, namely short length coded caching (SLC) and long length coded caching (LLC), to avoid the repetition of index of file segments in SLC. First, we derive explicit expressions of DOR under LLC and SLC in environments with both characteristics (Scenario-A). The maximization of DORs are then investigated and near optimal solutions are obtained in this NP-hard problem. Second, a degraded environment that only considers user mobility (Scenario-B) is investigated, where the near optimal solutions are obtained by submodular expressions with linear complexity. Finally, simulations firmly support the necessity of combining both characteristics. Specifically, the DORs of our caching strategies under LLC and SLC in Scenario-A are increased by 30\% 30\% on average in comparison to the state of the art.},
  archive      = {J_ISCI},
  author       = {Chenhao Ying and Xudong Wang and Yuan Luo},
  doi          = {10.1016/j.ins.2020.09.017},
  journal      = {Information Sciences},
  pages        = {663-687},
  shortjournal = {Inf. Sci.},
  title        = {Optimization on data offloading ratio of designed caching in heterogeneous mobile wireless networks},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed mining of time-faded heavy hitters.
<em>ISCI</em>, <em>545</em>, 633–662. (<a
href="https://doi.org/10.1016/j.ins.2020.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present P2PTFHH (Peer-to-Peer Time-Faded Heavy Hitters) which, to the best of our knowledge, is the first distributed algorithm for mining time-faded heavy hitters on unstructured P2P networks . P2PTFHH is based on the FDCMSS (Forward Decay C ount -M in S pace -S aving ) sequential algorithm, and efficiently exploits an averaging gossip protocol by merging in each interaction the involved peers’ underlying data structures . We formally prove the convergence and correctness properties of our distributed algorithm and show that it is fast and simple to implement. Extensive experimental results, executed on both synthetic and real datasets, confirm that P2PTFHH retains the extreme accuracy and error bound provided by FDCMSS whilst showing excellent scalability. Our contributions are threefold: (i) we prove that the averaging gossip protocol can be used jointly with our augmented sketch data structure for mining time-faded heavy hitters; (ii) we prove the error bounds on frequency estimation; (iii) we experimentally prove that P2PTFHH is extremely accurate and fast, allowing near real time processing of large datasets.},
  archive      = {J_ISCI},
  author       = {Marco Pulimeno and Italo Epicoco and Massimo Cafaro},
  doi          = {10.1016/j.ins.2020.09.048},
  journal      = {Information Sciences},
  pages        = {633-662},
  shortjournal = {Inf. Sci.},
  title        = {Distributed mining of time-faded heavy hitters},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An automatic clustering technique for query plan
recommendation. <em>ISCI</em>, <em>545</em>, 620–632. (<a
href="https://doi.org/10.1016/j.ins.2020.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The query optimizer is responsible for identifying the most efficient Query Execution Plans (QEP’s). The distributed database relations may be kept in several places. These results in a dramatic increase in the number of alternative query’ plans. The query optimizer cannot exhaustively explore the alternative query plans in a vast search space at reasonable computational costs. Henceforth, reusing the previously generated plans instead of generating new plans for new queries is an efficient technique for query processing . To improve the accuracy of clustering, we’ve rewritten the queries to standardize their structures. Furthermore, TF representation schema has been used to convert the queries into vectors. In this paper, we’ve introduced a multi-objective automatic query plan recommendation method, a combination of incremental DBSCAN and NSGA-II. The quality of the results of incremental DBSCAN has been influenced by Minpts (minimum points) and Eps (epsilon). Two cluster validity indices, Dunn index and Davies–Bouldin index, have simultaneously been optimized to calculate the goodness of an answer. Comparative results have been shown against the incremental DBSCAN and K-means regarding an external cluster validity index, namely, the ARI . By comparing different types of query workloads , we’ve found that the introduced method outperforms the other well-known approaches.},
  archive      = {J_ISCI},
  author       = {Elham Azhir and Nima Jafari Navimipour and Mehdi Hosseinzadeh and Arash Sharifi and Aso Darwesh},
  doi          = {10.1016/j.ins.2020.09.037},
  journal      = {Information Sciences},
  pages        = {620-632},
  shortjournal = {Inf. Sci.},
  title        = {An automatic clustering technique for query plan recommendation},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Determination of journeys order based on graph’s wiener
absolute index with bipolar fuzzy information. <em>ISCI</em>,
<em>545</em>, 608–619. (<a
href="https://doi.org/10.1016/j.ins.2020.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the existence of two opposite sided opinions in bipolar fuzzy graphs, the positive and negative communication between all pair of vertices always may not be strong. So, the connectivity sustain is one of the major important part in a bipolar fuzzy network system. First, Wiener index for a bipolar fuzzy graph is introduced and explained their properties. Second, the terms Wiener absolute index is created based on the total accurate connectivity between all the pair of vertices and in the whole bipolar fuzzy graph. Third, the behavior of Wiener absolute index is visualized in several bipolar fuzzy graphs like bipolar fuzzy forest, bridge, and tree. Fourth, a comparative discussion between connectivity index and Wiener index in bipolar fuzzy graphs are established. Finally, an application of all these thought is displayed in regular journeys from the city Paris to Brest.},
  archive      = {J_ISCI},
  author       = {Soumitra Poulik and Ganesh Ghorai},
  doi          = {10.1016/j.ins.2020.09.050},
  journal      = {Information Sciences},
  pages        = {608-619},
  shortjournal = {Inf. Sci.},
  title        = {Determination of journeys order based on graph’s wiener absolute index with bipolar fuzzy information},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to utilize auxiliary reviews for recommendation.
<em>ISCI</em>, <em>545</em>, 595–607. (<a
href="https://doi.org/10.1016/j.ins.2020.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Review-based recommender systems represent users and items with reviews associated with them. As such, the recommender systems are highly dependent on the number of reviews, which is usually few in number. Thus, they produce inaccurate recommendations to users who rarely wrote reviews. An approach to generate better recommendations for the cold-start users is to augment the scarce reviews using other reviews, which are called auxiliary reviews. In this work, we address two research questions when leveraging auxiliary reviews: 1) How to find important auxiliary reviews? 2) How to combine the auxiliary reviews with their original reviews?, and propose a method that l earns to u tilize a uxiliary r eviews (LUAR) to tackle these questions. LUAR learns to automatically focus on important auxiliary reviews from data via neural attention mechanism . For the review combination issue, a self-attentive module in LUAR combines auxiliary reviews and original reviews considering their level of contribution. The module dynamically computes the level of contribution of each review based on its relative importance compared to others. Experimental results show that LUAR outperforms the state-of-the-art review-based recommender systems on 7 real-world datasets. Qualitative analyses also show that LUAR can accurately focus on important auxiliary reviews.},
  archive      = {J_ISCI},
  author       = {Dongmin Hyun and Chanyoung Park and Junsu Cho and Hwanjo Yu},
  doi          = {10.1016/j.ins.2020.09.025},
  journal      = {Information Sciences},
  pages        = {595-607},
  shortjournal = {Inf. Sci.},
  title        = {Learning to utilize auxiliary reviews for recommendation},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introduction of ABCEP as an automatic programming method.
<em>ISCI</em>, <em>545</em>, 575–594. (<a
href="https://doi.org/10.1016/j.ins.2020.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic programming is a branch of artificial intelligence that presents each solution as a mathematical formula based on heuristic mechanisms. In this study, artificial bee colony expression programming (ABCEP) is presented, which is combined simultaneously with expression programming. By using expression sharing to generate new solutions, the proposed method can minimize certain deficiencies of artificial bee colony programming, such as weak convergence and high locality. A total number of 15 real-world regression benchmark functions was used to evaluate the performance of the proposed model. For comparison purposes, successful run percentage, mean best cost, convergence performance, and run time of ABCEP were compared to those of other tested automatic programming algorithms, including artificial bee colony programming, gene expression programming, genetic programming , and quick artificial bee colony programming. A Wilcoxon signed-rank test was also done to compare the behavior of the algorithms. Additionally, the accuracy of all algorithms was then evaluated using three real-world practical benchmarks. The results indicate that the predictions generated by ABCEP are better than those obtained by other control algorithms based on successful runs, mean fitness values, and convergence rate.},
  archive      = {J_ISCI},
  author       = {Masood Nekoei and Seyed Amirhossein Moghaddas and Emadaldin Mohammadi Golafshani and Amir H. Gandomi},
  doi          = {10.1016/j.ins.2020.09.020},
  journal      = {Information Sciences},
  pages        = {575-594},
  shortjournal = {Inf. Sci.},
  title        = {Introduction of ABCEP as an automatic programming method},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving the robustness of recursive consequent parameters
learning in evolving neuro-fuzzy systems. <em>ISCI</em>, <em>545</em>,
555–574. (<a href="https://doi.org/10.1016/j.ins.2020.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last 15 to 20 years, evolving (neuro-) fuzzy systems (E(N) FS) have enjoyed more and more attraction in the context of data stream mining and modeling processes. This is because they can be updated on the fly in a single-pass sample-wise manner and are able to perform autonomous changes of the models on structural level in order to react onto process drifts. A wide variety of evolving (neuro-) fuzzy systems approaches have been proposed in order to handle data stream mining and modeling processes by dynamically updating the rule structure and antecedents. The current denominator in the update of the consequent (output weight) parameters is the usage of the recursive (fuzzily weighted) least squares estimator (R(FW) LS) , as being applied in almost all E(N) FS approaches. In this paper, we propose and examine alternative variants for consequent parameter updates, namely multi-innovation RFWLS , recursive correntropy and especially recursive weighted total least squares (RWTLS) . Multi-innovation RFWLS guarantees more stability in the update whenever structural changes (i.e. changes in the antecedents) in the E(N) FS are performed. This is because rule membership degrees are actualized on (a portion of) past samples and properly integrated in each update step. Recursive correntropy addresses the problematic of outliers by down-weighing the influence of higher errors in the parameter updates. Recursive weighted total least squares also takes into account a possible noise level in the input variables (and not solely in the target variable as done in RFWLS). The approaches are compared with standard RFWLS i.) on three data stream regression problems from practical applications, which are affected by noise levels and where one embeds a known drift, and ii.) on a time-series based forecasting problem. The results based on accumulated prediction error trends over time indicate that RFWLS can be largely outperformed by the proposed alternative variants, and this with even lower sensitivity on various data noise levels. So, the proposed variants could be worth of being further considered as promising and serious alternatives.},
  archive      = {J_ISCI},
  author       = {Edwin Lughofer},
  doi          = {10.1016/j.ins.2020.09.026},
  journal      = {Information Sciences},
  pages        = {555-574},
  shortjournal = {Inf. Sci.},
  title        = {Improving the robustness of recursive consequent parameters learning in evolving neuro-fuzzy systems},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy squareness: A new approach for measuring a shape.
<em>ISCI</em>, <em>545</em>, 537–554. (<a
href="https://doi.org/10.1016/j.ins.2020.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we define a new fuzzy squareness measure to quantify how much a given fuzzy shape matches a fuzzy square. The new fuzzy shape-based measure is naturally defined and theoretically well-founded, resulted in that its behavior can be understood and predicted in advance. It runs through the interval ( 0 , 1 ] (0,1] and takes the maximum value equals 1 if and only if the shape measured is a fuzzy square. The new fuzzy squareness measure is also invariant to similarity transformations. Several various experiments to illustrate the behavior of the new measure, and to verify all the theoretically proven results are also shown. Effectiveness and usefulness of the new fuzzy squareness measure are demonstrated in the tasks of object classification performed on three large well-known modern image datasets such as MPEG-7 CE-1, Swedish Leaf, and Portuguese Leaves datasets.},
  archive      = {J_ISCI},
  author       = {Vladimir Ilić and Nebojša M. Ralević},
  doi          = {10.1016/j.ins.2020.09.030},
  journal      = {Information Sciences},
  pages        = {537-554},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy squareness: A new approach for measuring a shape},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential stabilization and non-fragile sampled-date
dissipative control for uncertain time-varying delay t-s fuzzy systems
with state quantization. <em>ISCI</em>, <em>545</em>, 513–536. (<a
href="https://doi.org/10.1016/j.ins.2020.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of exponential dissipation stability of T-S fuzzy system with state quantization is studied by using non-fragile sampled-data control. First, A Lyapunov-Krasovskii function containing all sampled-data and quantization information is constructed. Second, the better results can be obtained by using the integral inequality and the Newton Leibniz formula. In addition, a dissipative controller for non-fragile sampled-data is designed. Finally, The reasonable examples illustrate the significant improvement and value of this paper.},
  archive      = {J_ISCI},
  author       = {Pengyi Tang and Yuechao Ma},
  doi          = {10.1016/j.ins.2020.09.036},
  journal      = {Information Sciences},
  pages        = {513-536},
  shortjournal = {Inf. Sci.},
  title        = {Exponential stabilization and non-fragile sampled-date dissipative control for uncertain time-varying delay T-S fuzzy systems with state quantization},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Natural partial order induced by a commutative, associative
and idempotent function. <em>ISCI</em>, <em>545</em>, 499–512. (<a
href="https://doi.org/10.1016/j.ins.2020.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the natural partial order of commutative, associative, idempotent functions, covering as a special case t-norms, t-conorms, uninorms and nullnorms on bounded lattices . Unlike other approaches known in the literature, where the order induced by a given function is defined with respect to the original order on the given bounded lattice, we use original ideas of Hartwig, Nambooripad and Mitsch and define the natural partial order on an arbitrary set without connection to any order. We show that the natural partial order induced by any commutative, associative, idempotent function F corresponds to a meet semi-lattice and that F ( x , y ) F(x,y) can be expressed by the meet of x and y with respect to the natural partial order. This result can be used for an easy verification of the associativity of a commutative, idempotent function. Further, in some special cases we show the necessary and the sufficient conditions for such a function to be non-decreasing in each coordinate. We show that the natural meet semi-lattice connects the ordinal sum in the sense of Clifford and the ordinal sum in the sense of Birkhoff. An example of an ordinal sum of functions (which need not to be idempotent) on a horizontal sum lattice is also introduced.},
  archive      = {J_ISCI},
  author       = {Andrea Mesiarová-Zemánková},
  doi          = {10.1016/j.ins.2020.09.028},
  journal      = {Information Sciences},
  pages        = {499-512},
  shortjournal = {Inf. Sci.},
  title        = {Natural partial order induced by a commutative, associative and idempotent function},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A benefit-to-cost ratio based approach for portfolio
selection under multiple criteria with incomplete preference
information. <em>ISCI</em>, <em>545</em>, 487–498. (<a
href="https://doi.org/10.1016/j.ins.2020.08.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefit-to-cost ratio (BCR) measuring is a useful approach for selecting portfolios of projects when they are evaluated applying multiple and conflicting criteria. A multiattribute value function can be used to measure the benefit of each project, which allows one to evaluate the BCRs, rank projects, and select them according to the available budget. However, here, there is a significant difficulty associated with the inaccuracy in the values of criteria scaling constants, which may not be exactly known by decision makers (DMs). Considering this, the present work is directed at overcoming this difficulty by developing a BCR-based model for selecting portfolios under incomplete information about criteria scaling constants. During the elicitation process , DMs answer questions on preferences by considering tradeoffs amongst criteria. The provided information is converted into inequalities forming a space of criteria weights. These inequalities serve as constraints for linear programming models, which are processed to find dominance relations between projects, considering their BCRs. The process is supported by developed computing tools. The formation of a portfolio of research and development projects, which are to be executed by a Brazilian electric energy utility, is presented to illustrate the paper results and their practical applicability.},
  archive      = {J_ISCI},
  author       = {Eduarda Asfora Frej and Petr Ekel and Adiel Teixeira de Almeida},
  doi          = {10.1016/j.ins.2020.08.119},
  journal      = {Information Sciences},
  pages        = {487-498},
  shortjournal = {Inf. Sci.},
  title        = {A benefit-to-cost ratio based approach for portfolio selection under multiple criteria with incomplete preference information},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Double-layer-clustering differential evolution multimodal
optimization by speciation and self-adaptive strategies. <em>ISCI</em>,
<em>545</em>, 465–486. (<a
href="https://doi.org/10.1016/j.ins.2020.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal optimization aims to find and maintain as many global and local optima of a function as possible. Niching techniques based on multi-populations and clustering proved to be efficient for tackling multimodal optimization problems . The main focus of this work is to enhance the diversity of the population and improve the global search ability to locate more optima. A Double-Layer-Clustering Speciation Differential Evolution (DLCSDE) algorithm for multimodal optimization is proposed. We also show how the DLCSDE can be improved by integrating with a self-adaptive strategy to form the Self-adaptive DLCSDE (SDLCSDE). Based on speciation, first layer clustering divides the entire population into multiple subpopulations to locate global and local optima. The seeds from each species then form a sub-population to search globally during the second layer clustering to find peaks missed during the first layer clustering search process. To test the performance, both DLCSDE and SDLCSDE are compared with 17 state-of-art niching algorithms on 29 multimodal problems with different dimensions. The experiment results demonstrate that both the proposed algorithms outperform or perform comparably to the 17 niching algorithms on all the test functions.},
  archive      = {J_ISCI},
  author       = {Qingxue Liu and Shengzhi Du and Barend Jacobus van Wyk and Yanxia Sun},
  doi          = {10.1016/j.ins.2020.09.008},
  journal      = {Information Sciences},
  pages        = {465-486},
  shortjournal = {Inf. Sci.},
  title        = {Double-layer-clustering differential evolution multimodal optimization by speciation and self-adaptive strategies},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting relational tag expansion for dynamic user profile
in a tag-aware ranking recommender system. <em>ISCI</em>, <em>545</em>,
448–464. (<a href="https://doi.org/10.1016/j.ins.2020.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A tag-aware recommender system (TRS) presents the challenge of tag sparsity in a user profile. Previous work focuses on expanding similar tags and does not link the tags with corresponding resources, therefore leading to a static user profile in the recommendation. In this article, we have proposed a new social tag expansion model (STEM) to generate a dynamic user profile to improve the recommendation performance. Instead of simply including most relevant tags, the new model focuses on the completeness of a user profile through expanding tags by exploiting their relations and includes a sufficient set of tags to alleviate the tag sparsity problem. The novel STEM-based TRS contains three operations: (1) Tag cloud generation discovers potentially relevant tags in an application domain; (2) Tag expansion finds a sufficient set of tags upon original tags; and (3) User profile refactoring builds a dynamic user profile and determines the weights of the extended tags in the profile. We analysed the STEM property in terms of recommendation accuracy and demonstrated its performance through extensive experiments over multiple datasets. The analysis and experimental results showed that the new STEM technique was able to correctly find a sufficient set of tags and to improve the recommendation accuracy by solving the tag sparsity problem. At this point, this technique has consistently outperformed state-of-art tag-aware recommendation methods in these extensive experiments.},
  archive      = {J_ISCI},
  author       = {Yinghui Pan and Yongfeng Huo and Jing Tang and Yifeng Zeng and Bilian Chen},
  doi          = {10.1016/j.ins.2020.09.001},
  journal      = {Information Sciences},
  pages        = {448-464},
  shortjournal = {Inf. Sci.},
  title        = {Exploiting relational tag expansion for dynamic user profile in a tag-aware ranking recommender system},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient human motion prediction using temporal
convolutional generative adversarial network. <em>ISCI</em>,
<em>545</em>, 427–447. (<a
href="https://doi.org/10.1016/j.ins.2020.08.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human motion prediction from its historical poses is an essential task in computer vision; it is successfully applied for human-machine interaction and intelligent driving. Recently, significant progress has been made with variants of RNNs or LSTMs. Despite alleviating the vanishing gradient problem, the chain RNN often leads to deformities and convergence to the mean pose because of its low ability to capture long-term dependencies. To address these problems, in this paper, we propose a temporal convolutional generative adversarial network (TCGAN) to forecast high-fidelity future poses. The TCGAN uses hierarchical temporal convolution to model the long-term patterns of human motion effectively. In contrast to RNNs, the hierarchical convolution structure has recently proved to be a more efficient method for sequence-to-sequence learning in computational complexity, the number of model parameters, and parallelism. Besides, instead of traditional GANs, spectral normalization (SN) is embedded in the model to alleviate mode collapse. Compared with typical recurrent methods, the proposed model is feedforward and can produce the future poses in real-time. Extensive experiments on various human activity analysis benchmarks ( i.e. , H3.6M, CMU, and 3DPW MoCap) demonstrate that the model consistently outperforms the state-of-the-art methods in terms of accuracy and visualization for short-term and long-term predictions.},
  archive      = {J_ISCI},
  author       = {Qiongjie Cui and Huaijiang Sun and Yue Kong and Xiaoqian Zhang and Yanmeng Li},
  doi          = {10.1016/j.ins.2020.08.123},
  journal      = {Information Sciences},
  pages        = {427-447},
  shortjournal = {Inf. Sci.},
  title        = {Efficient human motion prediction using temporal convolutional generative adversarial network},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ordered fuzzy random variables: Definition and the concept
of normality. <em>ISCI</em>, <em>545</em>, 415–426. (<a
href="https://doi.org/10.1016/j.ins.2020.08.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of fuzzy random variable combines two sources of uncertainty: randomness and fuzziness, whereas the model of ordered fuzzy numbers provides a representation of inaccurate quantitative data, and is an alternative to the standard fuzzy numbers model proposed by Zadeh. This paper develops the model of ordered fuzzy numbers by defining the concept of fuzzy random variables for these numbers, called further ordered fuzzy random variables. Thanks to the well-defined arithmetic of ordered fuzzy numbers (existence of neutral and opposite elements) and the introduced ordered fuzzy random variables; it becomes possible to construct fully fuzzy stochastic time series models such as e.g., the autoregressive model or the GARCH model in the form of classical equations, which can be estimated using the least-squares or the maximum likelihood method. Furthermore, the concept of normality of ordered fuzzy random variables and the method to generate pseudo-random ordered fuzzy variables with normal distribution are introduced.},
  archive      = {J_ISCI},
  author       = {Adam Marszałek and Tadeusz Burczyński},
  doi          = {10.1016/j.ins.2020.08.120},
  journal      = {Information Sciences},
  pages        = {415-426},
  shortjournal = {Inf. Sci.},
  title        = {Ordered fuzzy random variables: Definition and the concept of normality},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new approach for classifying coronavirus COVID-19 based on
its manifestation on chest x-rays using texture features and neural
networks. <em>ISCI</em>, <em>545</em>, 403–414. (<a
href="https://doi.org/10.1016/j.ins.2020.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the recent challenge that humanity is facing against COVID-19, several initiatives have been put forward with the goal of creating measures to help control the spread of the pandemic. In this paper we present a series of experiments using supervised learning models in order to perform an accurate classification on datasets consisting of medical images from COVID-19 patients and medical images of several other related diseases affecting the lungs. This work represents an initial experimentation using image texture feature descriptors , feed-forward and convolutional neural networks on newly created databases with COVID-19 images. The goal was setting a baseline for the future development of a system capable of automatically detecting the COVID-19 disease based on its manifestation on chest X-rays and computerized tomography images of the lungs.},
  archive      = {J_ISCI},
  author       = {Sergio Varela-Santos and Patricia Melin},
  doi          = {10.1016/j.ins.2020.09.041},
  journal      = {Information Sciences},
  pages        = {403-414},
  shortjournal = {Inf. Sci.},
  title        = {A new approach for classifying coronavirus COVID-19 based on its manifestation on chest X-rays using texture features and neural networks},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The PAN and MS image fusion algorithm based on adaptive
guided filtering and gradient information regulation. <em>ISCI</em>,
<em>545</em>, 381–402. (<a
href="https://doi.org/10.1016/j.ins.2020.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, with the improvement in the accuracy of remote sensing image classification and target recognition, the feature level fusion technology of remote sensing images has attracted much attention and become a research hotspot. However, this kind of fusion technology is not as mature as pixel-level fusion technology, and there are still many problems to be solved. This paper proposes a multi-spectral (MS) and panchromatic (PAN) image fusion algorithm based on adaptive textural feature extraction and information injection regulation. The fusion algorithm includes two stages. The first stage extracts the textural details of high-resolution PAN images . In this stage, based on the sensitivity of the remote sensing images to the gray-level co-occurrence matrix (GLCM), an adaptive guided filter (AGIF) scheme for remote sensing images based on the GLCM is proposed. The feature information of the textures and details of the PAN image was fully extracted. The second stage injects the extracted feature information of the PAN image into an MS image. In this stage, a decision map based on the MS image gradient domain and a weighted matrix based on the gradient entropy measure were proposed in order to, respectively, realize the adaptability of the feature injection location selection and regulate the intensity of the injected information to the MS image. This ensures the rationality of the injection of the textural information and avoids noise, patches and other information interference. The proposed algorithm has the advantages of fully extracting the textural features of high-resolution PAN images , adaptively adjusting the injection position and intensity when injecting the feature information into an MS image, and providing the fused image with clear features. On the premise of effectively maintaining the spectral information quality, the spatial resolution of the fused image is improved. A large number of simulation experiments verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xianghai Wang and Shifu Bai and Zhi Li and Yuanqi Sui and Jingzhe Tao},
  doi          = {10.1016/j.ins.2020.09.006},
  journal      = {Information Sciences},
  pages        = {381-402},
  shortjournal = {Inf. Sci.},
  title        = {The PAN and MS image fusion algorithm based on adaptive guided filtering and gradient information regulation},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Change-point detection based on adjusted shape context cost
method. <em>ISCI</em>, <em>545</em>, 363–380. (<a
href="https://doi.org/10.1016/j.ins.2020.08.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change-point problems which originated from the field of quality control have become an important area of research. Although existing methods have been successful in detecting change-points, most of them require the underlying data to follow a specific distribution. Heuristically speaking, those methods only perform well when the data set is hypothesised to follow a normal distribution . In this paper, instead of traditional statistical inference , we propose a new algorithm from a shape perspective, which provides a more robust approach to addressing change-point problems. Our new algorithm will define a novel statistic based on shape context , a rich local shape descriptor , to replace the CUSUM test statistic considered by traditional methods. In addition, some areas which do not have change-points are abandoned through segmentation and screening, reducing computational complexity and increasing available storage. At the same time, we introduce the idea of peak recognition, which increases the robustness and effectiveness of the detection. The experimental results demonstrate that the proposed algorithm significantly outperforms some other methods with regard to accuracy and efficiency, especially when a longer time series is under study. We include analyses of two real-world data sets which demonstrate the practical effectiveness of this algorithm.},
  archive      = {J_ISCI},
  author       = {Qijing Yan and Youbo Liu and Shuangzhe Liu and Tiefeng Ma},
  doi          = {10.1016/j.ins.2020.08.112},
  journal      = {Information Sciences},
  pages        = {363-380},
  shortjournal = {Inf. Sci.},
  title        = {Change-point detection based on adjusted shape context cost method},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Near-optimal large-scale k-medoids clustering.
<em>ISCI</em>, <em>545</em>, 344–362. (<a
href="https://doi.org/10.1016/j.ins.2020.08.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-medoids (k-median) problem is one of the best known unsupervised clustering problems . Due to its complexity, finding high-quality solutions for huge-scale datasets remains extremely challenging. The application of many approaches finding optimal or quality solutions is limited to only small and medium-size instances. On the other hand, many parallel, distributed algorithms that can handle huge-scale datasets usually provide very poor solutions. In this paper, we develop a first parallel, distributed primal–dual heuristic algorithm for the k-medoids problem. Its main component is a very efficient parallel subgradient column generation that solves a Lagrangian dual problem and finds a tight bound on solution quality. High-quality solutions are then produced by a parallel core selection technique. We considerably reduce computational burden and memory load by employing a nearest neighbor strategy to approximate the dissimilarity matrix . We demonstrate that our algorithm finds very close to optimal solutions, confirmed by the tightness of dual bounds, of instances that are much larger than those considered in the literature to date. Our experiments include clustering large-scale collections of face images into several thousand of clusters. We show that our approach outperforms parallel improved versions of the most popular k-medoids clustering algorithms , achieving nearly linear parallel speedup.},
  archive      = {J_ISCI},
  author       = {Anton V. Ushakov and Igor Vasilyev},
  doi          = {10.1016/j.ins.2020.08.121},
  journal      = {Information Sciences},
  pages        = {344-362},
  shortjournal = {Inf. Sci.},
  title        = {Near-optimal large-scale k-medoids clustering},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linearly augmented real-time 4D expressional face capture.
<em>ISCI</em>, <em>545</em>, 331–343. (<a
href="https://doi.org/10.1016/j.ins.2020.08.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalised 3D face creation has always been a hot topic in the computer vision community. Many methods have been proposed including the statistic model, the non-rigid registration and high-end depth acquisition equipment. However, in practical applications, those existing methods still have their own limitations. For example, the performance of the statistic model-based methods highly depends on the generality of the pre-trained statistic model; the non-rigid registration based methods are sensitive to the quality of input data; the high-end equipment-based methods are less able to be popularised due to the expensive equipment costs; the deep learning-based methods can only perform well if proper training data provided for the target domain, and require GPU for better performance. To this end, this paper presents an adaptive template augmented method that can automatically obtain a personalised 4D facial modelling only using a consumer-grade device. The noisy data from such a cheap device are well handled. The whole process consists of a series of linear solutions and can be achieved in real-time for online processing only based on the CPU computation on a laptop. There is no constraint nor complex operation required by the proposed method. No additional time-consumptive pre- or post-processing for the personalisation is needed. Comparisons against several existing methods demonstrate the superiority of the proposed method.},
  archive      = {J_ISCI},
  author       = {Shu Zhang and Hui Yu and Ting Wang and Junyu Dong and Tuan D. Pham},
  doi          = {10.1016/j.ins.2020.08.099},
  journal      = {Information Sciences},
  pages        = {331-343},
  shortjournal = {Inf. Sci.},
  title        = {Linearly augmented real-time 4D expressional face capture},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive algorithm for dealing with data stream evolution
and singularity. <em>ISCI</em>, <em>545</em>, 312–330. (<a
href="https://doi.org/10.1016/j.ins.2020.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of representative features for multi-source and massive data streams, from which implicit knowledge is mined, has become a research hotspot in the era of rapid development of data industry. In response to the weak adaptability of traditional algorithms, an adaptive algorithm GNG-L is proposed based on growing neural gas (GNG) for monitoring and tracking the drift and singularity of real-time data stream in non-stationary environments, which includes three mechanisms, namely weight adaptation, neuron deletion and generation. Firstly, the mechanism of weight adaptation is proposed by analyzing the changes of the local characteristics for data streams, which ensures the network topology is adjusted accurately and quickly. Secondly, the adaptive deletion mechanism removes neural nodes that are no longer updated due to the evolution of data streams. Finally, the generation mechanism is trigged when the new feature of data stream evolution needs to be described in new regions of the feature space. The proposed model has been validated based on a number of data sets, and the results show that the algorithm proposed in this paper can effectively track changes of data sets in non-stationary environments.},
  archive      = {J_ISCI},
  author       = {Yong-ming Wu and Lin-sheng Chen and Shao-bo Li and Jia-dui Chen},
  doi          = {10.1016/j.ins.2020.07.010},
  journal      = {Information Sciences},
  pages        = {312-330},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive algorithm for dealing with data stream evolution and singularity},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural network-based finite-time adaptive tracking control
of nonstrict-feedback nonlinear systems with actuator failures.
<em>ISCI</em>, <em>545</em>, 298–311. (<a
href="https://doi.org/10.1016/j.ins.2020.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time adaptive fault-tolerant tracking control for nonstrict-feedback nonlinear systems (NSFNSs) is investigated. To avoid the problem of “complexity explosion”, a novel finite-time command filter is introduced to generate command signals and their derivatives. The fractional order error compensation mechanism (ECM) is designed to quickly compensate the effect of filter error. By combining the approximation abilities of neural networks and command filtered backstepping (CFB) approach, a finite-time adaptive control strategy is established. It guarantees that the output tracking error approaches to a sufficiently small region of the original point within finite-time, and all signals of the closed-loop system are finite-time semi-globally uniformly ultimately bounded (SGUUB). Finally, two simulation examples are supplied to verify the effectiveness of the proposed control method .},
  archive      = {J_ISCI},
  author       = {Guozeng Cui and Wei Yang and Jinpeng Yu},
  doi          = {10.1016/j.ins.2020.08.024},
  journal      = {Information Sciences},
  pages        = {298-311},
  shortjournal = {Inf. Sci.},
  title        = {Neural network-based finite-time adaptive tracking control of nonstrict-feedback nonlinear systems with actuator failures},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). H∞ delayed tracking protocol design of nonlinear singular
multi-agent systems under markovian switching topology. <em>ISCI</em>,
<em>545</em>, 280–297. (<a
href="https://doi.org/10.1016/j.ins.2020.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The consensus tracking of singular multi-agent systems (MASs) with Lipschitz-type nonlinearities and exogenous disturbances is researched in this paper. Governed by a Markov chain , the network interaction randomly switches in a directed graph set, where the directed spanning tree is not contained in each graph while exists in the union rooting at the leader node. By utilizing a collection of in-neighbors’ information that involves communication delay, the intention is to design a protocol such that the resultant consensus error system is stochastic admissible with an H ∞ H∞ disturbance attenuation level. Based on algebraic graph theory, stochastic admissibility analysis and linear matrix inequality (LMI) technique, tracking consistency is first regulated in the concerned MAS by considering the case of completely known transition probabilities . Then, thanks to a group of free-connection weighting matrices, the obtained result is extended to the case that transition probabilities are partially known. Finally, the theoretical analysis is confirmed by some numerical examples.},
  archive      = {J_ISCI},
  author       = {Xiangli Jiang and Guihua Xia and Zhiguang Feng and Zhengyi Jiang},
  doi          = {10.1016/j.ins.2020.08.020},
  journal      = {Information Sciences},
  pages        = {280-297},
  shortjournal = {Inf. Sci.},
  title        = {H∞ delayed tracking protocol design of nonlinear singular multi-agent systems under markovian switching topology},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on recent advances in security and
privacy-preserving techniques of distributed networked systems.
<em>ISCI</em>, <em>545</em>, 277–279. (<a
href="https://doi.org/10.1016/j.ins.2020.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_ISCI},
  author       = {Qing-Long Han and Lei Ding and Xiaohua Ge},
  doi          = {10.1016/j.ins.2020.08.014},
  journal      = {Information Sciences},
  pages        = {277-279},
  shortjournal = {Inf. Sci.},
  title        = {Special issue on recent advances in security and privacy-preserving techniques of distributed networked systems},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multicopy provable data possession scheme supporting data
dynamics for cloud-based electronic medical record system.
<em>ISCI</em>, <em>545</em>, 254–276. (<a
href="https://doi.org/10.1016/j.ins.2020.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of big data, there are several insuperable research challenges in establishing Electronic Medical Record (EMR) for updating massive data with traditional methods. It is an attractive option to create the cloud-based EMR system, since cloud provides elastic and affordable data storage and management services. However, once the medical records are uploaded into the cloud, the owner will lose the control over the data, and sensitive contents might be accessed or modified by unauthorized entities. To address this issue, we propose a multicopy provable data possession for cloud-based EMR systems, which ensures the integrity and privacy of EMR data. In particular, to achieve data updates, we design a novel dynamic structure that improves the Merkle Hash Tree for multicopy storage, which achieves full dynamics efficiently and safely. Moreover, a random masking technique is employed in our proposal to generate distinguishable replica blocks of one block. Our construction prevents a verifier from obtaining medical records from challenge responses, but also eliminates exposing the content to unauthorized entities. Our security analysis shows that our scheme is provably secure . Evaluation experiments demonstrate that the proposal has lower communication and computation costs in comparison with the existing schemes.},
  archive      = {J_ISCI},
  author       = {Lei Zhou and Anmin Fu and Yi Mu and Huaqun Wang and Shui Yu and Yinxia Sun},
  doi          = {10.1016/j.ins.2020.08.031},
  journal      = {Information Sciences},
  pages        = {254-276},
  shortjournal = {Inf. Sci.},
  title        = {Multicopy provable data possession scheme supporting data dynamics for cloud-based electronic medical record system},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Randomized non-linear PCA networks. <em>ISCI</em>,
<em>545</em>, 241–253. (<a
href="https://doi.org/10.1016/j.ins.2020.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {PCANet is an unsupervised Convolutional Neural Network (CNN), which uses Principal Component Analysis (PCA) to learn convolutional filters . One drawback of PCANet is that linear PCA cannot capture nonlinear structures within data. To address this problem, a straightforward approach is utilizing kernel methods by equipping the PCA method in PCANet with a kernel function . However, this practice leads to a network having cubic complexity with respect to the number of training image patches. In this paper, we propose a network called Randomized Nonlinear PCANet (RNPCANet), which uses an explicit kernel PCA to learn the convolutional filters . Although RNPCANet utilizes kernel methods for nonlinear processing of data, using kernel approximation techniques to define an explicit feature space in each stage, we theoretically show that the complexity of this model is not much higher than that of PCANet. We also show that our method links PCANets to Convolutional Kernel Networks (CKNs) as the proposed model maps the patches to a kernel feature space similar to CKNs. We evaluate our model on image recognition tasks including Coil-20, Coil-100, ETH-80, Caltech-101, MNIST, and C-Cube datasets. The experimental results show that the proposed method has superiority over PCANet and CKNs in terms of recognition accuracy.},
  archive      = {J_ISCI},
  author       = {Mohammadreza Qaraei and Saeid Abbaasi and Kamaledin Ghiasi-Shirazi},
  doi          = {10.1016/j.ins.2020.08.005},
  journal      = {Information Sciences},
  pages        = {241-253},
  shortjournal = {Inf. Sci.},
  title        = {Randomized non-linear PCA networks},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained learning performance prediction via adaptive
sparse self-attention networks. <em>ISCI</em>, <em>545</em>, 223–240.
(<a href="https://doi.org/10.1016/j.ins.2020.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) techniques have shown good potential in building favorable predictive models in e-learning environments. It is important to build a DL-based, fine-grained student performance prediction model to predict students’ outcomes and learning status at every stage of their course, rather than merely predicting the students’ final score and drop-out rate, which is referred to as coarse-grained performance. In this paper, we tackle the problem of fine-grained student performance prediction in an online course using DL-based long sequence generation by formulating the students’ feature as a matrix where elements in certain parts are missing. We propose an adaptive sparse self-attention network to generate the missing values and simultaneously predict the fine-grained performance. The matrix representation of the features facilitates position-wise feature selection, which helps to find the most correlated components from the past learning stage, leading to an embedding with both the original features and their spatial relationships. We build a deep neural network model with several sparse self-attention layers stacked together to achieve sequence generation. Experimental studies on three real-world datasets from different e-learning platforms demonstrate the effectiveness and advantages of our proposed method.},
  archive      = {J_ISCI},
  author       = {Xizhe Wang and Xiaoyong Mei and Qionghao Huang and Zhongmei Han and Changqin Huang},
  doi          = {10.1016/j.ins.2020.08.017},
  journal      = {Information Sciences},
  pages        = {223-240},
  shortjournal = {Inf. Sci.},
  title        = {Fine-grained learning performance prediction via adaptive sparse self-attention networks},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Double-quantified linguistic variable. <em>ISCI</em>,
<em>545</em>, 207–222. (<a
href="https://doi.org/10.1016/j.ins.2020.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regarding the natural language representation, there are two main methods, namely, the linguistic variable and multi-granularity linguistic term set. Although these two techniques are big achievements in the natural language representation researches, there are still some challenges: 1) the linguistic variable cannot handle the probability information, and 2) the multi-granularity linguistic term set cannot handle the negative words and incomplete probability information. To bridge these research gaps, this study proposes the double-quantified linguistic variable to quantify the natural language from two aspects: membership degree and probability. Firstly, we compare the linguistic variable with the multi-granularity linguistic term set and identify the differences and shortages of them. Based on these analyses, the double-quantified linguistic variable as a quintuple is introduced and every part of the double-quantified linguistic variable is explained in detail. After that, the basic operations and comparison method of the double-quantified linguistic variables are given. This study ends with some concluding remarks and future research directions.},
  archive      = {J_ISCI},
  author       = {Lisheng Jiang and Huchang Liao},
  doi          = {10.1016/j.ins.2020.08.026},
  journal      = {Information Sciences},
  pages        = {207-222},
  shortjournal = {Inf. Sci.},
  title        = {Double-quantified linguistic variable},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cryptanalysis and improvement of a reversible data-hiding
scheme in encrypted images by redundant space transfer. <em>ISCI</em>,
<em>545</em>, 188–206. (<a
href="https://doi.org/10.1016/j.ins.2020.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a reversible data hiding scheme by redundant space transfer has been proposed by Liu et al. In this scheme, the encryption process consists of bit plane disordering, sub-block position disordering and different-time Arnold transform in each sub-block. Then, the additional data is embedded into the LSB planes of the encrypted image by compressing the redundant space. However, to transfer the redundancy of the plain image into encrypted image, this scheme essentially just performs three types of disorder operations, which is vulnerable to security analysis. In this paper, we firstly demonstrate that the encryption method of this scheme can be broken by chosen-plaintext attack (CPA). Furthermore, in order to achieve the resistance against CPA, we introduce 2-D Logistic-adjusted-sine map (2D-LASM) to produce the encryption sequences with the control parameters generated from the plain image. Apart from that, we also improve the sparse matrix compression to achieve a superior embedding capacity. Extensive experiments and analyses demonstrate that the proposed scheme outperforms the original one in terms of both security and embedding capacity.},
  archive      = {J_ISCI},
  author       = {Yanping Xiang and Di Xiao and Rui Zhang and Jia Liang and Ran Liu},
  doi          = {10.1016/j.ins.2020.08.019},
  journal      = {Information Sciences},
  pages        = {188-206},
  shortjournal = {Inf. Sci.},
  title        = {Cryptanalysis and improvement of a reversible data-hiding scheme in encrypted images by redundant space transfer},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards secure and practical consensus for blockchain based
VANET. <em>ISCI</em>, <em>545</em>, 170–187. (<a
href="https://doi.org/10.1016/j.ins.2020.07.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The massive adoption of the blockchain-based distributed framework has made it possible to store and transmit Vehicular Ad Hoc Network (VANET) application data transparently, securely, and without a central control point of trust. Introducing an efficient and scalable consensus mechanism, which is one of the most crucial components in the blockchain-based VANET application, is still an open research challenge, given the features related to high mobility vehicular network and resource constraint devices in vehicles. Considering the efficiency, fairness and scalability issues of state-of-the-art consensus protocols like Proof of Work (PoW), Proof of Stake (PoS) and Practical Byzantine Fault Tolerant (PBFT), in this paper we propose a new technique called Proof of Driving (PoD), to randomize the selection of honest miners for generating the blocks efficiently for blockchain-based VANET applications. Additionally, we introduce a filtering technique based on Service Standard Score ( S c Sc ) of the vehicular miner nodes to detect and eliminate the malicious nodes. Our proposed technique achieves an efficient and fair selection of miners in a blockchain-based VANET application (for example, ride-sharing) and it makes PBFT consensus adaptable in a vast public vehicular network. The proposed method also addresses the efficiency and fairness issues caused by PoW and PoS, respectively. Our extensive experimental results reflect that the proposed method is efficient as well as scalable and, more importantly, achieves smaller consensus sets with higher quality to eliminate the malicious vehicle nodes from participating in consensus. Finally, the security analysis shows that the proposed method is secure and fault-tolerant against various attacks.},
  archive      = {J_ISCI},
  author       = {Sowmya Kudva and Shahriar Badsha and Shamik Sengupta and Ibrahim Khalil and Albert Zomaya},
  doi          = {10.1016/j.ins.2020.07.060},
  journal      = {Information Sciences},
  pages        = {170-187},
  shortjournal = {Inf. Sci.},
  title        = {Towards secure and practical consensus for blockchain based VANET},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy logic-based integral sliding mode control of
multi-area power systems integrated with wind farms. <em>ISCI</em>,
<em>545</em>, 153–169. (<a
href="https://doi.org/10.1016/j.ins.2020.07.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of the study is to design the fuzzy-based integral sliding mode control , which resolves the stability issues of multi-area interconnected power systems (MAIPS) integrated with wind farm (WF) involving the delays. The contribution can be categorized into two sections. Firstly, the dynamical characteristics of the power system are acquired various factors such as output from the wind generator, the existence of time-delays. The derived model becomes nonlinear due to WF integration and complications occur during the stability analysis. In such a situation, the Takagi–Sugeno (T-S) fuzzy approach is employed to approximate the nonlinear model into linear sub-models. However, the nonlinearities of WF can be linearized at a certain operating point which does not ensure the accuracy of the model. Secondly, to ensure stable performance, the suitable controller scheme becomes necessary and different types of control algorithms are available in the literature for the conventional power system model. This study focuses on designing the controller that copes with the T-S fuzzy model. We design a fuzzy-based integral sliding mode load frequency control (FISMLFC) controller and theoretically validate their performance by utilizing the Lyapunov stability theory and linear matrix inequalities (LMIs). Further, two-area MAIPS is simulated under the experimental values and their results are provided.},
  archive      = {J_ISCI},
  author       = {Prakash Mani and Young Hoon Joo},
  doi          = {10.1016/j.ins.2020.07.076},
  journal      = {Information Sciences},
  pages        = {153-169},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy logic-based integral sliding mode control of multi-area power systems integrated with wind farms},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Community answer generation based on knowledge graph.
<em>ISCI</em>, <em>545</em>, 132–152. (<a
href="https://doi.org/10.1016/j.ins.2020.07.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community Question Answering (CQA) has become an indispensable way for modern people to share and acquire knowledge. It allows users to ask questions, which will be answered by experienced users enthusiastically. By recording user operation logs, CQA has accumulated a large amount of valuable and complex data. However, askers must wait (usually for a long time) until other expert users answer their questions on social platforms. This will seriously affect the user experience. In this paper, we propose a Community Answer Generation method based on the Knowledge Graph, called CAGKG, to generate natural language answers automatically. Firstly, we extract the core phrases of posts to represent their semantics relations. Then, we model the user&#39;s knowledge background based on their action records. Finally, we query knowledge entities in a knowledge graph based on user background and question semantics, then convert them into natural language answers. Besides, we proposed a Phrase-based Answers Semantic Similarity Evaluation indicator, called PASSE, which focuses on the semantic similarity between texts instead of literal matching. To the best of our knowledge, it is the first work that utilizes the user knowledge and text semantics to improve the performance of CQA. Experiments on four real datasets (Stack Overflow, Super User, Mathematics, and Quora) show that CAGKG is superior to the state-of-the-art question answering frameworks. Compared with other answer evaluation indicators, PASSE is a promising indicator for evaluating semantic similarity.},
  archive      = {J_ISCI},
  author       = {Yongliang Wu and Shuliang Zhao},
  doi          = {10.1016/j.ins.2020.07.077},
  journal      = {Information Sciences},
  pages        = {132-152},
  shortjournal = {Inf. Sci.},
  title        = {Community answer generation based on knowledge graph},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). View synthesis-based light field image compression using a
generative adversarial network. <em>ISCI</em>, <em>545</em>, 118–131.
(<a href="https://doi.org/10.1016/j.ins.2020.07.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light field (LF) imaging has generated considerable interest owing to its ability to capture both spatial and angular information of light rays simultaneously. However, the extremely large volume of data associated with LF imaging poses challenges to both data storage and transmission. This study addresses this issue by proposing a view synthesis-based LF image compression method using a generative adversarial network (GAN). The primary basis of compression relies on the fact that adjacent sub-aperture images (SAIs) are highly correlated. Accordingly, only sparsely sampled SAIs are transmitted and the others are reconstructed at the decoder side . The proposed sparse SAI sampling method enhances the quality of reconstructed SAIs by considering a fair trade-off between the number of SAIs available for use as priors in the synthesis process and SAI redundancy. The quality of reconstructed SAIs is further enhanced by a GAN-based SAI synthesis method , where the synthesis procedure is broken into disparity estimation and un-sampled SAI estimation components, and the adversarial nature of the jointly trained generative and discriminative networks results in a more accurate generative model . Furthermore, more texture details can be preserved in the synthesized SAIs by adopting a loss function in the GAN model based on perceptual quality . Extensive experimental results demonstrate the superiority of the proposed method relative to several other state-of-the-art compression methods in terms of standard quality metrics and the perceptual quality of the synthetic SAIs at the decoder side .},
  archive      = {J_ISCI},
  author       = {Deyang Liu and Xinpeng Huang and Wenfa Zhan and Liefu Ai and Xin Zheng and Shulin Cheng},
  doi          = {10.1016/j.ins.2020.07.073},
  journal      = {Information Sciences},
  pages        = {118-131},
  shortjournal = {Inf. Sci.},
  title        = {View synthesis-based light field image compression using a generative adversarial network},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resilient observer-based control for cyber-physical systems
under denial-of-service attacks. <em>ISCI</em>, <em>545</em>, 102–117.
(<a href="https://doi.org/10.1016/j.ins.2020.07.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of resilient observer-based control for cyber-physical systems with multiple transmissions under Denial-of-Service (DoS) attacks. Instead of adopting the existing static output feedback controller , an observer-based controller is adopted. First, based on the property that the dwell-time of DoS is bounded, an interval partition technique is introduced to reduce the conservatism of stability analysis. Second, sufficient conditions for the desired observer-based controller is provided in terms of linear matrix inequalities (LMIs). Based on the obtained conditions, a resilient observer-based controller design strategy is provided to improve the resilience against DoS . Finally, a numerical example is given to show the effectiveness of the proposed interval partition technique and observer-based controller. It is shown that that more intensive DoS attacks can be tolerated.},
  archive      = {J_ISCI},
  author       = {Chun-Lei Zhang and Guang-Hong Yang and An-Yang Lu},
  doi          = {10.1016/j.ins.2020.07.070},
  journal      = {Information Sciences},
  pages        = {102-117},
  shortjournal = {Inf. Sci.},
  title        = {Resilient observer-based control for cyber-physical systems under denial-of-service attacks},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correntropy-based metric for robust twin support vector
machine. <em>ISCI</em>, <em>545</em>, 82–101. (<a
href="https://doi.org/10.1016/j.ins.2020.07.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes a robust distance metric that is induced by correntropy based on Laplacian kernel. The proposed metric satisfies the properties that distance metric must have. Moreover, we demonstrate important properties of the proposed metric such as robustness, boundedness, non-convexity and approximation behaviors. The proposed metric includes and extends the traditional metrics such as L 0 L0 -norm and L 1 L1 -norm metrics. Following that we apply the proposed metric to twin support vector machine classification (TSVM), and then a new robust TSVM algorithm (called RCTSVM) is built to reduce the influence of noise and outliers. The proposed RCTSVM inherits the advantages of TSVM and improves the robustness. However, the non-convexity of the proposed model makes it difficult to optimize. A continuous optimization method is developed to solve the RCTSVM. The problem is converted into difference of convex (DC) programming, and the corresponding DC algorithm (DCA) converges linearly. Compared with the traditional algorithms, numerical experiments under different noise setting and evaluation criteria show that the proposed RCTSVM has robustness to noise and outliers in most cases, which demonstrates the feasibility and effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Chao Yuan and Liming Yang and Ping Sun},
  doi          = {10.1016/j.ins.2020.07.068},
  journal      = {Information Sciences},
  pages        = {82-101},
  shortjournal = {Inf. Sci.},
  title        = {Correntropy-based metric for robust twin support vector machine},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A trustworthiness-based vehicular recruitment scheme for
information collections in distributed networked systems. <em>ISCI</em>,
<em>545</em>, 65–81. (<a
href="https://doi.org/10.1016/j.ins.2020.07.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of high mobility, large number of vehicles are utilized to achieve timely and quality-based information in the smart Internet of Things , which has formulated into a dynamic Distributed Networked Systems (DNS). However, designing a vehicular recruitment scheme to enhance a security-based DNS is challenging since it is hard to judge trustworthiness values of vehicular sensors. Therefore, in this paper, a novel vehicular trust evaluation scheme is proposed to analyze and supervise the data collected by vehicular sensors with a trust and low-cost style. To obtain vehicular trusts, the proposed scheme that considers time factor and gap between sensed data and real data is designed to calculate trustworthiness of vehicles. Moreover, sensing data in the vehicle sparse regions has more contributions because of its rareness. Thus, to inspire vehicles to sense data in the vehicle sparse regions , a trustworthiness-based gradient pricing method is designed to pay rewards for the vehicular sensors. Finally, with real vehicular GPS datasets, simulation results demonstrate that the proposed scheme can improve accuracy rate of data sensing by 37.72\% and can improve data quality by 76.95\%. By incentive pricing method, coverage ratio of data sensing is improved by 13.1\%. In general, performances of the proposed scheme can be improved by 19. 39\% to 22.32\% approximately. Future works focus on improving information security by advanced machine learning methods in the dynamic DNS.},
  archive      = {J_ISCI},
  author       = {Ting Li and Anfeng Liu and Neal N. Xiong and Shaobo Zhang and Tian Wang},
  doi          = {10.1016/j.ins.2020.07.052},
  journal      = {Information Sciences},
  pages        = {65-81},
  shortjournal = {Inf. Sci.},
  title        = {A trustworthiness-based vehicular recruitment scheme for information collections in distributed networked systems},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Supplier’s goal setting considering sustainability: An
uncertain dynamic data envelopment analysis based benchmarking model.
<em>ISCI</em>, <em>545</em>, 44–64. (<a
href="https://doi.org/10.1016/j.ins.2020.07.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the growing awareness of balancing the economy, the society and the environment, there has been an increased focus on goal setting under sustainable context. However, underperforming suppliers may set impractical goals that are difficult to achieve in the short term due to the poor information analysis, which could cause benchmarking difficulties. Therefore, rather than focusing on a single ultimate goal, this paper developed an implementable goal sequence for which a dynamic Data Envelopment Analysis based benchmarking model was developed as a multi-period process. The indicators that could not be directly measured using numerical values were incorporated into the model as fuzzy numbers, and based on efficiencies, the suppliers were divided into several layers. A method that identified supplier attractiveness and progress was then introduced to select the most appropriate goal in each layer for the goal sequence. A numerical example is provided that illustrated the feasibility and efficacy of the proposed method to successfully identify the inefficient suppliers and determine a goal sequence that had three attainable goals. The sensitivity analysis and comparisons revealed that the proposed model avoided selecting period-inefficient suppliers and provided a better benchmarking process.},
  archive      = {J_ISCI},
  author       = {Xiaoyang Zhou and Linzi Li and Haoyu Wen and Xin Tian and Shouyang Wang and Benjamin Lev},
  doi          = {10.1016/j.ins.2020.07.074},
  journal      = {Information Sciences},
  pages        = {44-64},
  shortjournal = {Inf. Sci.},
  title        = {Supplier’s goal setting considering sustainability: An uncertain dynamic data envelopment analysis based benchmarking model},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Three-way decision on information tables. <em>ISCI</em>,
<em>545</em>, 25–43. (<a
href="https://doi.org/10.1016/j.ins.2020.07.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The model of three-way decision on two universes generalizes various two-universe models of rough sets, and it is in fact defined on 0–1 tables, i.e. binary information tables. This paper generalizes the model of three-way decision from 0–1 tables to general information tables. The framework of three-way decision on general information tables is presented and the connection of existing related models is investigated. In our models, every element in the set of objects is assigned to a value and we can construct a tri-partition of the object set according to a pair of thresholds. We present a fundamental result of the models, which induces two concepts: the fundamental sequence and pair. On the one hand, the fundamental result shows that there exist finitely many pairs of thresholds. That is, we need only to consider the case of finitely many tri-partitions. On the other hand, it describes how the positive region varies based on thresholds and induces a concept of positive region tower. Finally, we evaluate these finite tri-partitions by the weighted entropy, which is a new measure defined as a variant of information entropy. An optimal tri-partition can be obtained according to weighted entropies of the finite tri-partitions.},
  archive      = {J_ISCI},
  author       = {Xiaonan Li and Xuan Wang and Bingzhen Sun and Yanhong She and Lu Zhao},
  doi          = {10.1016/j.ins.2020.07.064},
  journal      = {Information Sciences},
  pages        = {25-43},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision on information tables},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiregional co-evolutionary algorithm for dynamic
multiobjective optimization. <em>ISCI</em>, <em>545</em>, 1–24. (<a
href="https://doi.org/10.1016/j.ins.2020.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic multiobjective optimization problems (DMOPs) require Evolutionary algorithms (EAs) to track the time-dependent Pareto-optimal front (PF) or Pareto-optimal set (PS), and provide diversified solutions. Thus, a multiregional co-evolutionary dynamic multiobjective optimization algorithm (MRCDMO) is proposed based on the combination of a multiregional prediction strategy (MRP) and a multiregional diversity maintenance mechanism (MRDM). To accurately predict the moving trend of PS, a series of center points in different subregions is used to build a difference model to estimate the new location of center points when an environmental change is detected. To promote the diversity of the population, some diverse individuals are generated within the subregion of the next predicted PS. These two parts of solutions make up the population under a new environment. The performance of our proposed method is validated by comparison with four state-of-the-art EAs on 12 test functions. Experimental results demonstrate that the proposed algorithm can effectively cover the changing PF and efficiently predict the location of the moving PS.},
  archive      = {J_ISCI},
  author       = {Xuemin Ma and Jingming Yang and Hao Sun and Ziyu Hu and Lixin Wei},
  doi          = {10.1016/j.ins.2020.07.009},
  journal      = {Information Sciences},
  pages        = {1-24},
  shortjournal = {Inf. Sci.},
  title        = {Multiregional co-evolutionary algorithm for dynamic multiobjective optimization},
  volume       = {545},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Output consensus for switched multi-agent systems with
bumpless transfer control and event-triggered communication.
<em>ISCI</em>, <em>544</em>, 585–598. (<a
href="https://doi.org/10.1016/j.ins.2020.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers output consensus for a class of switched multi-agent systems with bumpless transfer control and event-triggered communication. For switched multi-agent systems, all the subsystems of each agent are allowed to be instabilizabled. For the bumpless transfer performance, we suppress control bumps at switching instants, and completely exclude control bumps at triggering instants by constructing a dynamic compensator. Besides, by designing an event-triggered rule, the communication cost is reduced and the positive lower bound between the consecutive triggering instants is guaranteed. Under the co-design of the switching law, bumpless transfer control and event-triggered rule, sufficient conditions guaranteeing output consensus are presented. The effectiveness of the result is validated by an example.},
  archive      = {J_ISCI},
  author       = {Yajing Ma and Zhanjie Li and Jun Zhao},
  doi          = {10.1016/j.ins.2020.09.040},
  journal      = {Information Sciences},
  pages        = {585-598},
  shortjournal = {Inf. Sci.},
  title        = {Output consensus for switched multi-agent systems with bumpless transfer control and event-triggered communication},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Target redirected regression with dynamic neighborhood
structure. <em>ISCI</em>, <em>544</em>, 564–584. (<a
href="https://doi.org/10.1016/j.ins.2020.08.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Least squares regression (LSR) has attracted widespread attention in the fields of statistics, machine learning, and pattern recognition. However, it utilizes strict zero-one regression targets, which leads to inferior performance on classification tasks. Furthermore, LSR ignores the local manifold structures of data and lacks robustness. To address these issues, this paper proposes a general regression framework called RLRR, where a low-rank constraint is imposed on regression matrices to explore the underlying correlation structures of classes. Strict zero-one regression targets are redirected to more feasible variable matrices for the purpose of margin amplification of different classes. Additionally, rather than using a pre-constructed weighted graph, the proposed framework dynamically updates the neighborhood structures of data to preserve original manifold structures. By utilizing this framework as a general platform, we developed two dynamic neighborhood-structure-based regression models called RLRRM and RLRRP. RLRRM integrates a reconstruction error minimization term into the proposed RLRR framework, whereas RLRRP aims to preserve the local geometric structures of data in a low-dimensional subspace. Both RLRRM and RLRRP use the ℓ 2 , 1 ℓ2,1 -norm penalty to replace the traditional F -norm penalty for the projection matrix for the sake of self-adaptive feature selection. Instead of directly solving the resultant optimization problems with non-convex constraints, we adopt the variable-splitting and penalty techniques to derive an equivalent solution. Analysis of the corresponding convergence and computational complexity characteristics is also presented. Extensive experiments on several well-known datasets demonstrate the promising performance of the proposed models.},
  archive      = {J_ISCI},
  author       = {Jianglin Lu and Jingxu Lin and Zhihui Lai and Hailing Wang and Jie Zhou},
  doi          = {10.1016/j.ins.2020.08.062},
  journal      = {Information Sciences},
  pages        = {564-584},
  shortjournal = {Inf. Sci.},
  title        = {Target redirected regression with dynamic neighborhood structure},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active learning bayesian support vector regression model for
global approximation. <em>ISCI</em>, <em>544</em>, 549–563. (<a
href="https://doi.org/10.1016/j.ins.2020.08.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning techniques have received much attention in many areas for regression and classification tasks. In this paper, two new support vector regression (SVR) models, namely, least-square SVR and ε- SVR, are developed under the Bayesian inference framework with a square loss function and a ε -insensitive squared one respectively. In this framework, a Gaussian process prior is assigned to the regression function, and maximum posterior estimate of this function results in a support vector regression problem. The proposed method provides point-wise probabilistic prediction while keeps the structural risk minimization principle, and it allows us to determine the optimal hyper-parameters by maximizing Bayesian model evidence. Based on the Bayesian SVR model, an active learning algorithm is developed, and new training points are selected adaptively based on a learning function to update the SVR model progressively. Numerical results reveal that the developed two Bayesian SVR models are very promising for constructing accurate regression model for problems with diverse characteristics, especially for medium and high dimensional problems.},
  archive      = {J_ISCI},
  author       = {Kai Cheng and Zhenzhou Lu},
  doi          = {10.1016/j.ins.2020.08.090},
  journal      = {Information Sciences},
  pages        = {549-563},
  shortjournal = {Inf. Sci.},
  title        = {Active learning bayesian support vector regression model for global approximation},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mining local periodic patterns in a discrete sequence.
<em>ISCI</em>, <em>544</em>, 519–548. (<a
href="https://doi.org/10.1016/j.ins.2020.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Periodic frequent patterns are sets of events or items that periodically appear in a sequence of events or transactions. Many algorithms have been designed to identify periodic frequent patterns in data. However, most assume that the periodic behavior of a pattern does not change much over time. To address this limitation, this paper proposes to discover a novel type of periodic patterns in a sequence of events or transactions, called Local Periodic Patterns (LPPs) which are patterns (sets of events) that have a periodic behavior in some non predefined time-intervals. A pattern is said to be a local periodic pattern if it appears regularly and continuously in some time-interval(s). Two novel measures are proposed to assess the periodicity and frequency of patterns in time-intervals. The maxSoPer ( maximal period of spillovers ) measure allows detecting time-intervals of variable lengths where a pattern is continuously periodic, while the minDur ( minimal duration ) measure ensures that those time-intervals have a minimum duration. To discover all LPPs, the paper presents three efficient algorithms. An experimental evaluation on real datasets shows that the proposed algorithms are efficient and can provide useful patterns that cannot be found using traditional periodic pattern mining algorithms.},
  archive      = {J_ISCI},
  author       = {Philippe Fournier-Viger and Peng Yang and Rage Uday Kiran and Sebastian Ventura and José María Luna},
  doi          = {10.1016/j.ins.2020.09.044},
  journal      = {Information Sciences},
  pages        = {519-548},
  shortjournal = {Inf. Sci.},
  title        = {Mining local periodic patterns in a discrete sequence},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-way decision with co-training for partially labeled
data. <em>ISCI</em>, <em>544</em>, 500–518. (<a
href="https://doi.org/10.1016/j.ins.2020.08.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The theory of three-way decision plays an important role in decision making and knowledge reasoning. However, little attention has been paid to the problem of learning from partially labeled data with three-way decision. In this paper, we propose a three-way co-decision model for partially labeled data. More specifically, the problem of attribute reduction for partially labeled data is first investigated, and two semi-supervised attribute reduction algorithms based on novel confidence discernibility matrix are proposed. Then, a three-way co-decision model is introduced to classify unlabeled data into useful, useless, and uncertain data, and the model is iteratively retrained on the carefully selected useful data to improve its performance. Moreover, we theoretically analyze the effectiveness of the proposed model. The experimental results conducted on UCI data sets demonstrate that the proposed model is promising, and even compares favourably with the single supervised classifier trained on all training data with true labels.},
  archive      = {J_ISCI},
  author       = {Can Gao and Jie Zhou and Duoqian Miao and Jiajun Wen and Xiaodong Yue},
  doi          = {10.1016/j.ins.2020.08.104},
  journal      = {Information Sciences},
  pages        = {500-518},
  shortjournal = {Inf. Sci.},
  title        = {Three-way decision with co-training for partially labeled data},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compact structure for sparse undirected graphs based on a
clique graph partition. <em>ISCI</em>, <em>544</em>, 485–499. (<a
href="https://doi.org/10.1016/j.ins.2020.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressing real-world graphs has many benefits such as improving or enabling the visualization in small memory devices, graph query processing, community search, and mining algorithms. This work proposes a novel compact representation for real sparse and clustered undirected graphs . The approach lists all the maximal cliques by using a fast algorithm and defines a clique graph based on its maximal cliques. Further, the method defines a fast and effective heuristic for finding a clique graph partition that avoids the construction of the clique graph. Finally, this partition is used to define a compact representation of the input graph. The experimental evaluation shows that this approach is competitive with the state-of-the-art methods in terms of compression efficiency and access times for neighbor queries, and that it recovers all the maximal cliques faster than using the original graph. Moreover, the approach makes it possible to query maximal cliques, which is useful for community detection.},
  archive      = {J_ISCI},
  author       = {Felipe Glaria and Cecilia Hernández and Susana Ladra and Gonzalo Navarro and Lilian Salinas},
  doi          = {10.1016/j.ins.2020.09.010},
  journal      = {Information Sciences},
  pages        = {485-499},
  shortjournal = {Inf. Sci.},
  title        = {Compact structure for sparse undirected graphs based on a clique graph partition},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FAPS: A fair, autonomous and privacy-preserving scheme for
big data exchange based on oblivious transfer, ether cheque and smart
contracts. <em>ISCI</em>, <em>544</em>, 469–484. (<a
href="https://doi.org/10.1016/j.ins.2020.08.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making plays an increasing important role in our digitalized society, and hence the need for trustworthy data. For example, in a traditional trading process , a trusted middle person generally helps to arbitrate any dispute between two or more parties involved in the trading. However, having such a trusted middle person can be labor-intensive, increases transaction costs, and lacks fairness during arbitration due to the subjectivity of the middle person. While we can avoid the need for a middle person using smart contract-based approaches, there are other limitations (e.g., fairness and privacy preservation) that need to be addressed. In this paper, we present a fair scheme for big data exchanging that allows buyers and sellers to autonomously and fairly complete transactions, without involving any third-party middle person. Specifically, our scheme uses smart contracts and oblivious transfer protocol, in combination with our proposed Ether cheque system. Smart contracts are used to achieve transaction fairness, autonomy and trading timing control. The oblivious transfer protocol helps us to preserve the privacy of transactions. We use Ether cheque to improve the fairness of the transaction and make the transaction more convenient. Also, our proposed approach can facilitate the identification of a cheating party.},
  archive      = {J_ISCI},
  author       = {Tiantian Li and Wei Ren and Yuexin Xiang and Xianghan Zheng and Tianqing Zhu and Kim-Kwang Raymond Choo and Gautam Srivastava},
  doi          = {10.1016/j.ins.2020.08.116},
  journal      = {Information Sciences},
  pages        = {469-484},
  shortjournal = {Inf. Sci.},
  title        = {FAPS: A fair, autonomous and privacy-preserving scheme for big data exchange based on oblivious transfer, ether cheque and smart contracts},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent tutoring system for supporting active
learning: A case study on predictive parsing learning. <em>ISCI</em>,
<em>544</em>, 446–468. (<a
href="https://doi.org/10.1016/j.ins.2020.08.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The way in which people learn and institutions teach is changing due to the ever-increasing impact of technology. People access the Internet anywhere, anytime and request online training. This has brought about the creation of numerous online learning platforms which offer comprehensive and effective educational solutions which are 100\% online. These platforms benefit from intelligent tutoring systems that help and guide students through the learning process, emulating the behavior of a human tutor. However, these systems give the student little freedom to experiment with the knowledge of the subject, that is, they do not allow him/her to propose and carry out tasks on his/her own initiative. They are very restricted systems in term of what the student can do, as the tasks are defined in advance. An intelligent tutoring system is proposed in this paper to encourage students to learn through experimentation, proposing tasks on their own initiative, which involves putting into use all the skills, abilities tools and knowledge needed to successfully solve them. This system has been designed developed and applied for learning predictive parsing techniques and has been used by Computer Science students during four academic courses to evaluate its suitability for improving the student’s learning process.},
  archive      = {J_ISCI},
  author       = {J.J. Castro-Schez and C. Glez-Morcillo and J. Albusac and D. Vallejo},
  doi          = {10.1016/j.ins.2020.08.079},
  journal      = {Information Sciences},
  pages        = {446-468},
  shortjournal = {Inf. Sci.},
  title        = {An intelligent tutoring system for supporting active learning: A case study on predictive parsing learning},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). A novel ensemble deep learning model with dynamic error
correction and multi-objective ensemble pruning for time series
forecasting. <em>ISCI</em>, <em>544</em>, 427–445. (<a
href="https://doi.org/10.1016/j.ins.2020.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decade, deep learning models have shown to be promising tools for time series forecasting. However, owing to significant differences in the volatility characteristics among different types of time series data , it is difficult for an individual deep learning model to maintain robust forecasting performance. In this study, a novel ensemble deep learning model is proposed to achieve accurate and stable time series forecasting. First, a boosting deep learning method based on extended AdaBoost algorithm is proposed for generating various basic predictors. These basic predictors are further enhanced through a new dynamic error correction method. A stacking-based ensemble method that employs kernel ridge regression as the meta-predictor is then used to combine the basic predictors to produce the ultimate forecasting results. To increase forecasting accuracy and stability, an enhanced multi-population non-dominated sorting genetic algorithm-II is proposed for ensemble pruning. Finally, the forecasting performance of the proposed model is verified through the use of three different types of real-world time series data (i.e., PM 2.5 concentration, wind speed, and electricity price). The experimental results showed that the proposed model is superior to other baseline models in dealing with time series forecasting tasks.},
  archive      = {J_ISCI},
  author       = {Shuai Zhang and Yong Chen and Wenyu Zhang and Ruijun Feng},
  doi          = {10.1016/j.ins.2020.08.053},
  journal      = {Information Sciences},
  pages        = {427-445},
  shortjournal = {Inf. Sci.},
  title        = {A novel ensemble deep learning model with dynamic error correction and multi-objective ensemble pruning for time series forecasting},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning smooth representations with generalized softmax for
unsupervised domain adaptation. <em>ISCI</em>, <em>544</em>, 415–426.
(<a href="https://doi.org/10.1016/j.ins.2020.08.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation aims at training accurate classifiers in a target domain by utilizing the data in a different but related source domain, which has made great progress in many aspects. Most of existing methods try to match the moments of data by mapping them to feature space, either first or second moment, so as to match the distribution. Despite their appeal, such models often fail to guarantee the obtained features can be well-classified. In this paper, we propose generalized softmax and smooth regularization to extract features and adapt classifiers simultaneously. Considering label matrix as special features, generalized softmax has more tolerance to the diversity of samples belonging to the same class. Smoothness regularization guarantees stronger robustness between target features and decision boundary. Finally, we evaluate our method on several standard benchmark datasets. Empirical evidence shows that the proposed method is comparable or superior to existing methods, and the same results based on two classification schemes indicate that the smoothness regularization is effective.},
  archive      = {J_ISCI},
  author       = {Chao Han and Yu Lei and Yu Xie and Deyun Zhou and Maoguo Gong},
  doi          = {10.1016/j.ins.2020.08.075},
  journal      = {Information Sciences},
  pages        = {415-426},
  shortjournal = {Inf. Sci.},
  title        = {Learning smooth representations with generalized softmax for unsupervised domain adaptation},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault tolerant sampled-data h∞ control for networked control
systems with probabilistic time-varying delay. <em>ISCI</em>,
<em>544</em>, 395–414. (<a
href="https://doi.org/10.1016/j.ins.2020.08.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the problem of fault-tolerant sampled-data H ∞ H∞ control for a networked control system with random time delays and actuator faults is investigated. Stochastic variables conforming with the Bernoulli distribution are considered to depict random time delays. A state feedback sampled-data controller is designed to ensure the asymptotical stability and H ∞ H∞ performance of the resulting closed-loop system. By applying the Lyapunov–Krasovskii stability theory and the reciprocally convex combination lemma, a stability criterion for a random time-varying delay system is developed that guarantees the designed controller can satisfy the requirements of stability and maneuverability . The desired controller gain is then found based on the linear matrix inequalities . Finally, as a real application, a quarter-vehicle suspension system model is provided to demonstrate the benefits and validity of the proposed control law.},
  archive      = {J_ISCI},
  author       = {Fang Fang and Haotian Ding and Yajuan Liu and Ju H. Park},
  doi          = {10.1016/j.ins.2020.08.063},
  journal      = {Information Sciences},
  pages        = {395-414},
  shortjournal = {Inf. Sci.},
  title        = {Fault tolerant sampled-data h∞ control for networked control systems with probabilistic time-varying delay},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Label constrained convolutional factor analysis for
classification with limited training samples. <em>ISCI</em>,
<em>544</em>, 372–394. (<a
href="https://doi.org/10.1016/j.ins.2020.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly addresses the statistical classification robust to small training data size. We develop a label constrained convolutional factor analysis (LCCFA) model, which unifies the factor analysis (FA), convolution operation and supervised learning. In the LCCFA model, each dictionary atom is used as a small-sized convolution kernel with the goal of learning the observations’ basic structures, which have highly shared characteristics among all observed data. This property enables the proposed method to describe data with fewer dictionary atoms than the FA model and reduces the model complexity. Consequently, the classification performance of the LCCFA model can be improved in the case of limited training samples. Meanwhile, the proposed model also projects the weight vectors of dictionary atoms to their class labels to constrain the learning of parameters. The difference in weight vectors from different classes increases due to the label constraint, thereby offering the potential to enhance the inter-class separability of statistical models. Additionally, the efficient parameter estimation is implemented via variational Bayesian (VB) algorithm. Experimental results on several benchmark datasets and measured radar high-resolution range profile (HRRP) data show that our method outperforms other related models in terms of small sample classification.},
  archive      = {J_ISCI},
  author       = {Jian Chen and Lan Du and Yuchen Guo},
  doi          = {10.1016/j.ins.2020.08.048},
  journal      = {Information Sciences},
  pages        = {372-394},
  shortjournal = {Inf. Sci.},
  title        = {Label constrained convolutional factor analysis for classification with limited training samples},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective and efficient top-k query processing over
incomplete data streams. <em>ISCI</em>, <em>544</em>, 343–371. (<a
href="https://doi.org/10.1016/j.ins.2020.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, efficient and effective stream processing has become increasingly important in many real-world applications such as sensor data monitoring, network intrusion detection, IP network traffic analysis, and so on. In practice, stream data often encounter the problem of having some data attributes missing, due to reasons such as packet losses, network congestion/failure, and so on. In such a scenario, it is rather important, yet challenging, to accurately and efficiently monitor top- k objects over incomplete data stream, which may potentially indicate some dangerous and critical security events (e.g., fire, network intrusion, or denial-of-service attack). In this paper, we formally define the problem of top- k query over incomplete data stream (Top k -iDS), which continuously detects top- k objects with the highest ranking scores over an incomplete data stream. Due to unique characteristics such as incompleteness and stream processing, we propose a cost-model-based data imputation approach, design effective pruning strategies to reduce the Topk-iDS search space, and carefully devise dynamically updated data synopses to facilitate Top k -iDS query processing. We also propose an efficient algorithm to perform the data imputation and incremental Topk-iDS computation at the same time. Finally, through extensive experiments, we evaluate the efficiency and effectiveness of our proposed Topk-iDS query answering approach over both real and synthetic data sets..},
  archive      = {J_ISCI},
  author       = {Weilong Ren and Xiang Lian and Kambiz Ghazinour},
  doi          = {10.1016/j.ins.2020.08.011},
  journal      = {Information Sciences},
  pages        = {343-371},
  shortjournal = {Inf. Sci.},
  title        = {Effective and efficient top-k query processing over incomplete data streams},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mirco-earthquake source depth detection using machine
learning techniques. <em>ISCI</em>, <em>544</em>, 325–342. (<a
href="https://doi.org/10.1016/j.ins.2020.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrimination of mirco-earthquake on source depth plays an important role in the field of micro-seismic monitoring. Conventional machine learning methods for data classification rely on carefully hand-engineered features that are vulnerable to low signal-to-noise ratio. Convolutional neural networks (CNNs) demonstrate some merits in dealing with structured data modelling where a set of meaningful features can be automatically extracted from sample learning. This paper explores the use of machine learning techniques for discrimination between deep and shallow mirco-seismic events. A benchmarked dataset including 444 micro-earthquakes from an underground cavern collapse in South Louisiana is employed for performance evaluation in this study, where several feature-based classifiers are compared against the CNN classifier. Empirical results show that the deep learning method outperforms the conventional classification techniques in discriminating the source depth.},
  archive      = {J_ISCI},
  author       = {De-He Yang and Xin Zhou and Xiu-Ying Wang and Jian-Ping Huang},
  doi          = {10.1016/j.ins.2020.07.045},
  journal      = {Information Sciences},
  pages        = {325-342},
  shortjournal = {Inf. Sci.},
  title        = {Mirco-earthquake source depth detection using machine learning techniques},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A spatiotemporal hierarchical attention mechanism-based
model for multi-step station-level crowd flow prediction. <em>ISCI</em>,
<em>544</em>, 308–324. (<a
href="https://doi.org/10.1016/j.ins.2020.07.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-step station-level crowd flow prediction (Ms-SLCFP) is to predict the count of people that would depart from or arrive at subway/bus/bike stations in multiple future consecutive time periods. By providing a long term view, it benefits the decision making in related applications, such as public safety, traffic management, etc. However, performing Ms-SLCFP is challenging as complicated spatiotemporal correlations are formed among stations due to the flowing crowd. Besides, the crowd flow at a single station fluctuates a lot though the regularity is obvious at the regional level. To tackle such issues, we propose a deep neural networks-based model with spatiotemporal hierarchical attention mechanisms , called ST-HAttn for short, for Ms-SLCFP. The notable contributions are that ST-HAttn performs attention mechanisms (AM) in two ways: 1) implementing AM at both station level and regional level; 2) implementing AM to explicitly model the pairwise correlations of station-region instead of station-station. The intuition is to alleviate the negative impact on Ms-SLCFP due to the fluctuation of the crowd flow at the station level. Verified on three real-world datasets, ST-HAttn outperforms the state-of-the-art methods in terms of Ms-SLCFP.},
  archive      = {J_ISCI},
  author       = {Yirong Zhou and Jun Li and Hao Chen and Ye Wu and Jiangjiang Wu and Luo Chen},
  doi          = {10.1016/j.ins.2020.07.049},
  journal      = {Information Sciences},
  pages        = {308-324},
  shortjournal = {Inf. Sci.},
  title        = {A spatiotemporal hierarchical attention mechanism-based model for multi-step station-level crowd flow prediction},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Particle filtering for a class of cyber-physical systems
under round-robin protocol subject to randomly occurring deception
attacks. <em>ISCI</em>, <em>544</em>, 298–307. (<a
href="https://doi.org/10.1016/j.ins.2020.07.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the particle filtering problem is studied for a class of general nonlinear cyber-physical systems with non-Gaussian noises under Round-Robin protocol (RRP) subject to the randomly occurring deception attacks. In order to prevent the data from collisions and alleviate the communication overhead for the shared network with limited resources, the RRP is introduced in the sensor-to-filter channel to schedule the multiple sensors with a predefined transmission order. Under the RRP, only one sensor can be granted the access to the shared channel for measurement transmission at each time instant. A Bernoulli-distributed stochastic variable is utilized to describe the characteristic of random occurrence of deception attacks initiated by the adversaries. A RRP-based particle filtering algorithm is developed by establishing a modified likelihood function, where the statistical property of the randomly occurring deception attacks is exploited and the RRP-induced effect on the filter design is reflected. Finally, an illustrative example regarding the target tracking problem is provided to verify the feasibility and effectiveness of the developed particle filtering scheme.},
  archive      = {J_ISCI},
  author       = {Weihao Song and Zidong Wang and Jianan Wang and Jiayuan Shan},
  doi          = {10.1016/j.ins.2020.07.047},
  journal      = {Information Sciences},
  pages        = {298-307},
  shortjournal = {Inf. Sci.},
  title        = {Particle filtering for a class of cyber-physical systems under round-robin protocol subject to randomly occurring deception attacks},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel fuzzy rough set model with fuzzy neighborhood
operators. <em>ISCI</em>, <em>544</em>, 266–297. (<a
href="https://doi.org/10.1016/j.ins.2020.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is not widely acknowledged that none of existing fuzzy β β -neighborhood operators satisfies the reflexivity when β ≠ 1 β≠1 . To overcome this shortcoming, four types of fuzzy β β -neighborhood operators are redefined, which shows that two redefined operators are reflexive. By means of fuzzy logical operators, the ( I , T ) (I,T) -fuzzy rough set (ITFRS) model based on the reflexive fuzzy β β -neighborhood operators is constructed in this paper. By combining ITFRS models with the classical TOPSIS method, a new decision-making method is proposed to handle multi-criteria decision-making (MCDM) problems under uncertain and fuzzy environments, where the distance between two intuitionistic fuzzy sets (IFSs) is expressed by an intuitionistic fuzzy number (IFN). Meanwhile, both numerical examples with different types of data are given to explain the feasibility of the proposed method and its effectiveness is also illustrated by a comparative analysis. Finally, the stability of the proposed method is further verified based on an experimental analysis in a real-life MCDM problem.},
  archive      = {J_ISCI},
  author       = {Jin Ye and Jianming Zhan and Weiping Ding and Hamido Fujita},
  doi          = {10.1016/j.ins.2020.07.030},
  journal      = {Information Sciences},
  pages        = {266-297},
  shortjournal = {Inf. Sci.},
  title        = {A novel fuzzy rough set model with fuzzy neighborhood operators},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous information fusion: Combination of multiple
supervised and unsupervised classification methods based on belief
functions. <em>ISCI</em>, <em>544</em>, 238–265. (<a
href="https://doi.org/10.1016/j.ins.2020.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real-life machine learning applications, a common problem is that raw data ( e.g. remote sesning data) is sometimes inaccessible due to confidentiality and privacy constrains of corporations, making classification methods arduous to work in the supervised context. Moreover, even though raw data is accessible, limited labeled samples can also seriously affect supervised methods. Recently, supervised and unsupervised classification (clustering) results related to specific applications are published by more and more organizations. Therefore, combination of supervised classification and clustering results has gained increasing attention to improve the accuracy of supervised predictions. Incorporating clustering results with supervised classifications at the output level can help to lessen the recline on information at the raw data level, so that is pertinent to improve the accuracy for the applications when raw data is inaccessible or training samples are limited. We focus on the combination of multiple supervised classification and clustering results at the output level based on belief functions for three purposes: (1) to improve the accuracy of classification when raw data is inaccessible or training samples are highly limited; (2) to reduce uncertain and imprecise information in the supervised results; and (3) to study how supervised classification and clustering results affect the combination at the output level. Our contributions consist of a transformation method to transfer heterogeneous information into the same frame, and an iterative fusion strategy to retain most of the trustful information in multiple supervised classification and clustering results.},
  archive      = {J_ISCI},
  author       = {Na Li and Arnaud Martin and Rémi Estival},
  doi          = {10.1016/j.ins.2020.07.039},
  journal      = {Information Sciences},
  pages        = {238-265},
  shortjournal = {Inf. Sci.},
  title        = {Heterogeneous information fusion: Combination of multiple supervised and unsupervised classification methods based on belief functions},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability analysis of cyclic switched linear systems: An
average cycle dwell time approach. <em>ISCI</em>, <em>544</em>, 227–237.
(<a href="https://doi.org/10.1016/j.ins.2020.07.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stability problem of switched linear systems with a class of cyclic switching signals is investigated. Firstly, a new concept of average cycle dwell time (ACDT) is introduced to relax the conservativeness of cycle dwell time that is extensively used in the literature. In addition, the ACDT is further extended to stable cyclic switching sequence dependent average cycle dwell time (S-ACDT) and unstable cyclic switching sequence dependent average cycle dwell time (U-ACDT). Secondly, the stability criteria for cyclic switched linear (or nonlinear) systems with ACDT or both S-ACDT and U-ACDT are derived by resorting to a technique that uses multiple Lyapunov functions . Both cyclic switched linear systems and cyclic switched nonlinear systems which contain all stable subsystems or partly stable subsystems are studied. Finally, a numerical example is given to demonstrate the feasibility of the proposed techniques.},
  archive      = {J_ISCI},
  author       = {Tao Sun and Tao Liu and Xi-Ming Sun},
  doi          = {10.1016/j.ins.2020.07.053},
  journal      = {Information Sciences},
  pages        = {227-237},
  shortjournal = {Inf. Sci.},
  title        = {Stability analysis of cyclic switched linear systems: An average cycle dwell time approach},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ship-unloading scheduling optimization for a steel plant.
<em>ISCI</em>, <em>544</em>, 214–226. (<a
href="https://doi.org/10.1016/j.ins.2020.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A ship-unloading scheduling problem (SUSP), also called “sequencing ship” problem arising from a large steel plant with bulk material port is studied in this paper. Raw materials such as iron ore, coal and stone are transported to the steel plant by ships. Each ship has an expected departure time based on a contract between the steel plant and ship-owner. If the steel plant cannot effectively schedule the unloading operation of the ship to make it leave the port before its expected departure time, a demurrage penalty cost which increases with the delay will be charged to the steel plant by the ship-owner. SUSP is to find an optimal schedule for these raw material ships so as to minimize the total demurrage costs within a given planning time horizon. The problem is formulated as a mixed integer programming , and can be regarded as a flexible job shop scheduling problem, where the ships are regarded as the jobs and the belt conveyors as the machines. A column generation approach is proposed for solving the optimization model. The computational results on the real-world data obtained from the steel plant are compared with CPLEX to verify the effectiveness and merits of the proposed model and solution. The proposed optimization technique has great potential to be applied in the steel plant, and it may save 20 million of CNY caused by the delay cost per year.},
  archive      = {J_ISCI},
  author       = {Zhen Gao and Defeng Sun and Ren Zhao and Yun Dong},
  doi          = {10.1016/j.ins.2020.07.029},
  journal      = {Information Sciences},
  pages        = {214-226},
  shortjournal = {Inf. Sci.},
  title        = {Ship-unloading scheduling optimization for a steel plant},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synthetic sample generation for label distribution learning.
<em>ISCI</em>, <em>544</em>, 197–213. (<a
href="https://doi.org/10.1016/j.ins.2020.07.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) is a general learning framework that assigns an instance to a distribution over a set of labels rather than a single label or multiple labels. Current LDL methods have proven their effectiveness in many machine learning applications. As of the first formulation of the LDL problem, numerous studies have been carried out that apply the LDL methodology to various real-life problem solving. Others have focused more specifically on the proposal of new algorithms. The purpose of this article is to start addressing the LDL problem as of the data pre-processing stage. The baseline hypothesis is that, due to the high dimensionality of existing LDL data sets, it is very likely that this data will be incomplete and/or that poor data quality will lead to poor performance once applied to the learning algorithms. In this paper, we propose an oversampling method, which creates a superset of the original dataset by creating new instances from existing ones. Then, we apply already existing algorithms to the pre-processed training set in order to validate the effcacy of our method. The effectiveness of the proposed SSG-LDL is verified on several LDL datasets, showing significant improvements to the state-of-the-art LDL methods.},
  archive      = {J_ISCI},
  author       = {Manuel González and Julián Luengo and José-Ramón Cano and Salvador García},
  doi          = {10.1016/j.ins.2020.07.071},
  journal      = {Information Sciences},
  pages        = {197-213},
  shortjournal = {Inf. Sci.},
  title        = {Synthetic sample generation for label distribution learning},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid deep meta-ensemble networks with application in
electric utility industry load forecasting. <em>ISCI</em>, <em>544</em>,
183–196. (<a href="https://doi.org/10.1016/j.ins.2020.07.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many industrial applications concern the forecasting of large quantities of related time series. This paper presents a novel hybrid modeling framework, named as Hybrid Deep Meta-Ensemble Networks (HDME-Nets), which combines local and global forecasts using meta-ensemble technology. The proposed framework can be used to generate multiple steps ahead of point and interval forecasts for a large number of time series concurrently. Our proposed framework is composed of four modules: a set of local forecasters that model each time series individually, a global forecaster that captures cross-sectional patterns with data pooling, a feature learner that extracts features from each time series in a supervised fashion, and a meta-combiner that combines the local and global forecasts according to the extracted features. The local forecasters are fitted firstly, and the other three modules are integrated seamlessly into one neural network, which is then jointly trained with a common objective measured with a custom loss function. Through testing two public available electric utility load datasets, we find that the proposed method can achieve improved forecasting performance compared against some state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Shaohui Ma},
  doi          = {10.1016/j.ins.2020.07.054},
  journal      = {Information Sciences},
  pages        = {183-196},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid deep meta-ensemble networks with application in electric utility industry load forecasting},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Triple-based graph neural network for encoding event units
in graph reasoning problems. <em>ISCI</em>, <em>544</em>, 168–182. (<a
href="https://doi.org/10.1016/j.ins.2020.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays graph neural networks have achieved excellent performance on many graph-based tasks such as abstract meaning representation (AMR) text generation and graph reasoning. Graph-based models often calculate the information flow by nodes and their associated edges. But node-based or edge-based calculation can not reflect the strong relation between every two nodes as triples, which actually act as event units in graph reasoning tasks. Considering triples (a triple means an edge and its two nodes in our model) as basic calculation units is more suitable for relation-based graphs and event-reasoning tasks. We thus propose a novel structure called triple-based graph neural network and directly perform triple-based neural calculation on interrelated triples. Experimental results on babi 16, babi 19, wikisql and our own proposed genealogy dataset show that our model significantly outperforms other strong alternatives.},
  archive      = {J_ISCI},
  author       = {Hao Tang and Donghong Ji and Qiji Zhou},
  doi          = {10.1016/j.ins.2020.07.036},
  journal      = {Information Sciences},
  pages        = {168-182},
  shortjournal = {Inf. Sci.},
  title        = {Triple-based graph neural network for encoding event units in graph reasoning problems},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning robust affinity graph representation for multi-view
clustering. <em>ISCI</em>, <em>544</em>, 155–167. (<a
href="https://doi.org/10.1016/j.ins.2020.06.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, an increasingly pervasive trend in real-word applications is that the data are collected from multiple sources or represented by multiple views. Owing to the powerful ability of affinity graph in capturing the structural relationships among samples, constructing a robust and meaningful affinity graph has been extensively studied, especially in spectral clustering tasks. However, conventional spectral clustering extended to multi-view scenarios cannot obtain the satisfactory performance due to the presence of noise and the heterogeneity among different views. In this paper, we propose a robust affinity graph learning framework to deal with this issue. First, we employ an improved feature selection algorithm that integrates the advantages of hypergraph embedding and sparse regression to select significant features such that more robust graph Laplacian matrices for various views on this basis can be constructed. Second, we model hypergraph Laplacians as points on a Grassmann manifold and propose a Consistent Affinity Graph Learning (CAGL) algorithm to fuse all views. CAGL aims to learn a latent common affinity matrix shared by all Laplacian matrices by taking both the clustering quality evaluation criterion and the view consistency loss into account. We also develop an alternating descent algorithm to optimize the objective function of CAGL. Experiments on five publicly available datasets demonstrate that our proposed method obtains promising results compared with state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Peiguang Jing and Yuting Su and Zhengnan Li and Liqiang Nie},
  doi          = {10.1016/j.ins.2020.06.068},
  journal      = {Information Sciences},
  pages        = {155-167},
  shortjournal = {Inf. Sci.},
  title        = {Learning robust affinity graph representation for multi-view clustering},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A shadowed set-based TODIM method and its application to
large-scale group decision making. <em>ISCI</em>, <em>544</em>, 135–154.
(<a href="https://doi.org/10.1016/j.ins.2020.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective tool to describe the fuzziness of qualitative information, the shadowed sets have received increasing attention. By establishing reasonable compromise between qualitative information and quantitative membership grades , the shadowed sets provide a new way to model linguistic variables . In this paper, we propose an extended TODIM method based on shadowed sets to solve large-scale group decision making problems with linguistic information . First, considering the linguistic terms cannot be directly computed, a codebook used to model linguistic terms is constructed with shadowed sets by the data-driven and the percentile method. Next, to improve the decision efficiency, a shadowed set-based clustering model is proposed to cluster the decision makers on the basis of new similarity measure and the Louvain algorithm. Then, we propose a new decision-making method by taking into account the decision makers’ psychological behavior which has a vital influence on the decision results. Finally, we utilize a case study about assembly factory site selection to illustrate the feasibility of the proposed method, meanwhile comparison, parameter discussion and sensitivity analysis are also conducted to verify the superiority and the efficiency.},
  archive      = {J_ISCI},
  author       = {Shifan He and Xiaohong Pan and Yingming Wang},
  doi          = {10.1016/j.ins.2020.07.028},
  journal      = {Information Sciences},
  pages        = {135-154},
  shortjournal = {Inf. Sci.},
  title        = {A shadowed set-based TODIM method and its application to large-scale group decision making},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). GraphLSHC: Towards large scale spectral hypergraph
clustering. <em>ISCI</em>, <em>544</em>, 117–134. (<a
href="https://doi.org/10.1016/j.ins.2020.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hypergraph is popularly used for describing multi-relationships among objects in a unified manner, and spectral clustering is regarded as one of the most effective algorithms for partitioning those objects (vertices) into different communities. However, the traditional spectral clustering for hypergraph (HC) incurs expensive costs in terms of both time and space. In this paper, we propose a framework called GraphLSHC to tackle the scalability problem faced by the large scale hypergraph spectral clustering. In our solution, the hypergraph used in GraphLSHC is expanded into a general format to capture complicated higher-order relationships. Moreover, GraphLSHC is capable to simultaneously partition both vertices and hyperedges according to the “eigen-trick”, which provides an approach for reducing the computational complexity of the clustering. To improve the performance further, several hyperedge-based sampling techniques are proposed, which can supplement the sampled matrix with the whole graph information . We also give a theoretical guarantee for the error boundary of the supplement. Several experiments show the superiority of the proposed framework over the state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Yiyang Yang and Sucheng Deng and Juan Lu and Yuhong Li and Zhiguo Gong and Leong Hou U and Zhifeng Hao},
  doi          = {10.1016/j.ins.2020.07.018},
  journal      = {Information Sciences},
  pages        = {117-134},
  shortjournal = {Inf. Sci.},
  title        = {GraphLSHC: Towards large scale spectral hypergraph clustering},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prescribed performance based model-free adaptive sliding
mode constrained control for a class of nonlinear systems.
<em>ISCI</em>, <em>544</em>, 97–116. (<a
href="https://doi.org/10.1016/j.ins.2020.06.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To tackle the trajectory tracking problem and achieve high control accuracy in many actual nonlinear systems with unknown dynamics, a novel prescribed performance based model-free adaptive sliding mode constrained control (SMCC) strategy is studied which relies on the input/output data of plant rather than the specific model information via a pseudo partial derivative (PPD) parameter. Firstly, two approaches are introduced for PPD estimation, i.e., an observer-based adaptive algorithm, and an algorithm based on the stochastic configuration network approximating the controlled plant model, upon which the realtime control including PPD construction are carried out. Then, the prescribed performance is introduced in the model-free adaptive SMCC scheme as a prescribed range for the output tracking error. Meanwhile, an anti-windup compensation signal is employed to suppress the actuator saturation that commonly exists in many actual nonlinear systems. In addition, the stability analysis of the control system is presented to verify the rationality of the prescribed performance. Finally, simulations are carried out for both a linear induction motor and a battery energy storage system to demonstrate the effectiveness of the proposed control strategy.},
  archive      = {J_ISCI},
  author       = {Weiming Zhang and Dezhi Xu and Bin Jiang and Tinglong Pan},
  doi          = {10.1016/j.ins.2020.06.061},
  journal      = {Information Sciences},
  pages        = {97-116},
  shortjournal = {Inf. Sci.},
  title        = {Prescribed performance based model-free adaptive sliding mode constrained control for a class of nonlinear systems},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient approach to identify social disseminators for
timely information diffusion. <em>ISCI</em>, <em>544</em>, 78–96. (<a
href="https://doi.org/10.1016/j.ins.2020.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, motivated by many practical applications such as viral marketing, researchers have paid significant attention to the circulation of information on social networks. The influential nodes that can influence the largest part of social networks are an essential topic in social network analysis . Most present solutions address the issue of discovering the influential nodes that could maximize influence effectiveness rather than minimize the cost of the information diffusion . In this paper, we investigate the circulation of emergency information, such as timely production promotion or disaster information, through a social network. These are real-life problems that have a significant effect in a very short time. We focus on how to minimize the total cost for all users in a specific social network to receive such information. We propose an efficient k-best social disseminator discovering algorithm in which the total diffusion cost on spreading timely information for each user in this social network is minimized.},
  archive      = {J_ISCI},
  author       = {Lien-Fa Lin and Yung-Ming Li},
  doi          = {10.1016/j.ins.2020.07.040},
  journal      = {Information Sciences},
  pages        = {78-96},
  shortjournal = {Inf. Sci.},
  title        = {An efficient approach to identify social disseminators for timely information diffusion},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive decision making method with copula bayesian
network for location selection. <em>ISCI</em>, <em>544</em>, 56–77. (<a
href="https://doi.org/10.1016/j.ins.2020.07.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel multi-criteria decision making approach based on an adaptive copula Bayesian network (CBN) model is proposed to effectively handle complex dependence problems under uncertainty. Specifically, the Bayesian network is used to merge various criteria in a model and graphically describe cause-effect relationships. The copula is incorporated to construct joint distributions of variables by specifying marginal distributions and copula functions separately. Regarding the practical value, the constructed model can adjust to changeable conditions to provide adaptive suggestions in view of diverse disciplines. The effectiveness of the proposed approach is verified in a case study about choosing the most suitable location of the pedestrian overhead bridge (POB) to install lift facilities in Singapore. Firstly, three criteria and ten relevant influential factors concerning the sustainable aspect are derived from a combination of expert knowledge and statistical data. Then, a proper CBN model is developed under the consideration of these determined criteria and factors, aiming to predict the constructability index for alternative locations statistically. Finally, the correlation analysis and CBN inference are performed to evaluate and identify the ideal location in a data-driven manner. Furthermore, results from the proposed CBN-based approach are compared against the traditional Technique for Order Preference by Similarity to an Ideal Solution (TOPSIS) to illustrate its advantages in representing dependency, modeling uncertainty, fusing information, and reducing subjectivity.},
  archive      = {J_ISCI},
  author       = {Yue Pan and Limao Zhang and Jiale Koh and Yong Deng},
  doi          = {10.1016/j.ins.2020.07.063},
  journal      = {Information Sciences},
  pages        = {56-77},
  shortjournal = {Inf. Sci.},
  title        = {An adaptive decision making method with copula bayesian network for location selection},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knee based multimodal multi-objective evolutionary algorithm
for decision making. <em>ISCI</em>, <em>544</em>, 39–55. (<a
href="https://doi.org/10.1016/j.ins.2020.07.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many advanced multimodal multi-objective evolutionary algorithms (MMOEAs) have been presented to solve multimodal multi-objective optimization problems (MMOPs). However, most of these approaches struggle not only to find the entire Pareto sets and Pareto front , but also ignoring the problem of Multi-Criteria Decision Making (MCDM) to be handled at a later stage. As a matter of fact, it is a very eclectic and challenging burden for decision makers to choose some trade-off optimal solutions from an enormous collection of non-dominated Pareto-optimal individuals. In this paper, we propose a knee based evolutionary algorithm , named MMO-EvoKnee, which incorporates MCDM strategy into solving MMOPs . The proposed algorithm is designed to search for a complete set of global knee solutions instead of an entire Pareto front and Pareto sets. Firstly, the EvoKnee Selection is adopted to find target global knee solutions and boundary individuals. Secondly, the Knee Multimodal Solutions Selection focuses on decision space exploitation to obtain well-converged multiple Pareto-optimal knee solutions. Thirdly, the Maximum Spanning Subset Selection is designed to accurately identify a complete number of knee solutions from overcrowded Pareto regions. Fourthly, the Boundary Multimodal Solutions Selection can find and maintain well-diversified and well-converged boundary solutions. As a result, MMO-EvoKnee can consistently find all knee solutions of interest quickly, and it relieves the burden for decision makers. Finally, the performance of the proposed algorithm is evaluated on thirteen benchmark MMOPs. The experiment results clearly show that the proposed MMO-EvoKnee provides a competitive edge over the chosen state-of-the-art MMOEAs.},
  archive      = {J_ISCI},
  author       = {Kai Zhang and Chaonan Shen and Juanjuan He and Gary G. Yen},
  doi          = {10.1016/j.ins.2020.07.057},
  journal      = {Information Sciences},
  pages        = {39-55},
  shortjournal = {Inf. Sci.},
  title        = {Knee based multimodal multi-objective evolutionary algorithm for decision making},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). No-wait two-stage flowshop problem with multi-task
flexibility of the first machine. <em>ISCI</em>, <em>544</em>, 25–38.
(<a href="https://doi.org/10.1016/j.ins.2020.06.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the creation of intelligent management systems in hospitals, efficient resource arrangement is essential. Motivated by a real-world scenario in hospitals, we introduce the no-wait two-stage flowshop scheduling problem with the first-stage machine having multi-task flexibility. In this problem, each job has two operations which are processed in order on a two-stage flowshop without preemption and time delay between or on machines. The multi-task flexibility allows the first-stage machine to process the second-stage operations. The goal is to minimize the maximum completion time of all jobs. To the best of our knowledge, this is a pioneering work on this problem. We discover several novel structural properties, based on which we present a linear-time combinatorial algorithm with an approximation ratio 13 8 138 . This problem and its variants can find many other meaningful applications in modern manufacturing systems , such as the robot cell scheduling with computer numerical control machines or printed circuit boards . The idea behind our algorithm may inspire more practical algorithms.},
  archive      = {J_ISCI},
  author       = {Jianming Dong and Hong Pan and Cunkui Ye and Weitian Tong and Jueliang Hu},
  doi          = {10.1016/j.ins.2020.06.052},
  journal      = {Information Sciences},
  pages        = {25-38},
  shortjournal = {Inf. Sci.},
  title        = {No-wait two-stage flowshop problem with multi-task flexibility of the first machine},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Spatiotemporal chaos in improved cross coupled map lattice
and its application in a bit-level image encryption scheme.
<em>ISCI</em>, <em>544</em>, 1–24. (<a
href="https://doi.org/10.1016/j.ins.2020.07.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an improved cross coupled map lattice (CCML) which is derived from CCML is proposed. The experimental analysis of CCML shows that it exhibits weak or even lose chaotic behaviors in a large range of parameters. To enhance its chaotic performance, the new model changes the internal chaotic map of CCML from the logistics map to the tent map and introduces the module operations to limit the obtained value. The theoretical analysis and experimental results prove that the proposed model has a broad chaotic regime over an extensive range of system parameters, positive Lyapunov exponents, higher information entropies and lower mutual information values when compared to CCML, which are highly suitable for chaos-based image encryption . Moreover, this paper applies that model on a bit-level image encryption scheme. The algorithm consists of three main operations: the generation of secret keys, confusion and diffusion operations that can break the limitation of row and column. To confirm the novel algorithm&#39;s effectiveness and safety against the common types of attacks, many experiments are done and security analyses are discussed. It demonstrates the good chaos of the proposed model from the aspect of encryption performance.},
  archive      = {J_ISCI},
  author       = {Mingxu Wang and Xingyuan Wang and Tingting Zhao and Chuan Zhang and Zhiqiu Xia and Nianmin Yao},
  doi          = {10.1016/j.ins.2020.07.051},
  journal      = {Information Sciences},
  pages        = {1-24},
  shortjournal = {Inf. Sci.},
  title        = {Spatiotemporal chaos in improved cross coupled map lattice and its application in a bit-level image encryption scheme},
  volume       = {544},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention based consistent semantic learning for micro-video
scene recognition. <em>ISCI</em>, <em>543</em>, 504–516. (<a
href="https://doi.org/10.1016/j.ins.2020.05.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-videos are one of the most popular multimedia forms in mobile internet domain, and scene recognition is important for micro-video semantic analyses and understanding. Compared with traditional videos, scene recognition in micro-videos is subject to content inconsistency for the same scene owing to the subjectivity of photographers. Moreover, the importance of frames for semantic representation differs in the same micro-video. These phenomenons limit micro-video scene recognition. To address these issues, in this paper, attention-based consistent semantic learning (ACSL) is proposed for micro-video scene recognition; this consists of a two-branch framework combined with an attention mechanism for the maintenance of the semantic consistency within classes. The experiments conducted in this study on multiple datasets revealed that the proposed ACSL achieves a better performance than other video scene recognition methods.},
  archive      = {J_ISCI},
  author       = {Jie Guo and Xiushan Nie and Yuling Ma and Kashif Shaheed and Inam Ullah and Yilong Yin},
  doi          = {10.1016/j.ins.2020.05.064},
  journal      = {Information Sciences},
  pages        = {504-516},
  shortjournal = {Inf. Sci.},
  title        = {Attention based consistent semantic learning for micro-video scene recognition},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rough video conceptualization for real-time event
precognition with motion entropy. <em>ISCI</em>, <em>543</em>, 488–503.
(<a href="https://doi.org/10.1016/j.ins.2020.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article defines a new methodology for pre-recognition of events with object motion analysis in a video without any prior knowledge. This unsupervised application is named as ‘conceptualization’. This conceptualization technique is also tested with real-time video data in an internet of things (IoT) architecture. The merits of rough sets in the framework of granular computing are explored to execute the task. The proposed method is designed for the video sequences that are acquired by simple static RGB sensors. Here the video sequences are granulated with our newly defined ‘motion granules’ and then those are modeled as rough sets over this granulation for moving object/ background estimation. Video conceptualization is performed afterwards by quantifying the approximation with a new measure, namely, motion entropy. The values obtained by this measure reflect the amount of uncertainty present in the motion of each individual moving object which enables precognition of events. The effectiveness of the proposed method is verified with extensive experiments in identifying the different motion patterns present in a video sequence. The frames with possibilities of events present therein are identified with this analysis. Both offline and real-time sequences are used for this verification. An IoT architecture is formed to test the proposed algorithm with physical devices in identifying the frames containing possible events.},
  archive      = {J_ISCI},
  author       = {Debarati B. Chakraborty and Sankar K. Pal},
  doi          = {10.1016/j.ins.2020.09.021},
  journal      = {Information Sciences},
  pages        = {488-503},
  shortjournal = {Inf. Sci.},
  title        = {Rough video conceptualization for real-time event precognition with motion entropy},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LUNAR: Cellular automata for drifting data streams.
<em>ISCI</em>, <em>543</em>, 467–487. (<a
href="https://doi.org/10.1016/j.ins.2020.08.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of fast data streams, real-time machine learning has become a challenging task, demanding many processing resources. In addition, they can be affected by the concept drift effect, by which learning methods have to detect changes in the data distribution and adapt to these evolving conditions. Several emerging paradigms such as the so-called Smart Dust, Utility Fog, or Swarm Robotics are in need for efficient and scalable solutions in real-time scenarios, and where usually computing resources are constrained. Cellular automata , as low-bias and robust-to-noise pattern recognition methods with competitive classification performance, meet the requirements imposed by the aforementioned paradigms mainly due to their simplicity and parallel nature. In this work we propose LUNAR , a streamified version of cellular automata devised to successfully meet the aforementioned requirements. LUNAR is able to act as a real incremental learner while adapting to drifting conditions. Furthermore, LUNAR is highly interpretable, as its cellular structure represents directly the mapping between the feature space and the labels to be predicted. Extensive simulations with synthetic and real data will provide evidence of its competitive behavior in terms of classification performance when compared to long-established and successful online learning methods.},
  archive      = {J_ISCI},
  author       = {Jesus L. Lobo and Javier Del Ser and Francisco Herrera},
  doi          = {10.1016/j.ins.2020.08.064},
  journal      = {Information Sciences},
  pages        = {467-487},
  shortjournal = {Inf. Sci.},
  title        = {LUNAR: Cellular automata for drifting data streams},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noisy label tolerance: A new perspective of partial
multi-label learning. <em>ISCI</em>, <em>543</em>, 454–466. (<a
href="https://doi.org/10.1016/j.ins.2020.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial Multi-Label learning (PML) aims to learn from training data where each example is associated with a set of candidate labels, among which only a subset of them is correct. The major challenge of PML lies in that the training procedure is prone to be misled by the label noise. To address this problem, nearly all existing PML methods focus on solely label disambiguation, i.e., dislodging the noisy labels from the candidate label set and then utilizing the remaining credible labels for model induction. However, these remaining “credible” labels may be incorrectly identified, which thereby would have a huge adverse impact on the subsequent model induction. In this paper, in contrary to the above label disambiguation strategy, we propose a simple yet effective N oisy l A bel T olerated p A rtial multi-label L earning (NATAL) method, where the labeling information is considered to be precise while the feature information is assumed to be missing. Using our proposed method, the task of PML can be re-interpreted as a Feature Completion problem, and the desired prediction model can be directly induced from the completed feature together with all candidate labels. Extensive experimental results on various data sets clearly demonstrate the effectiveness of our proposed approach.},
  archive      = {J_ISCI},
  author       = {Gengyu Lyu and Songhe Feng and Yidong Li},
  doi          = {10.1016/j.ins.2020.09.019},
  journal      = {Information Sciences},
  pages        = {454-466},
  shortjournal = {Inf. Sci.},
  title        = {Noisy label tolerance: A new perspective of partial multi-label learning},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based event triggering h∞ LFC for multi-area power
systems under DoS attacks. <em>ISCI</em>, <em>543</em>, 437–453. (<a
href="https://doi.org/10.1016/j.ins.2020.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the observer-based predictive event-triggered load frequency control (LFC) for a multi-area power system in a smart grid incorporating electric vehicles (EVs) under denial-of-service (DoS) attacks. The DoS attacks were launched in control channels with long duration to block the data transmission process and interrupt the LFC command. This situation becomes even more severe with the integration of EVs in the multi-area power system . The control design formulates the LFC problem as a disturbance attenuation problem in the presence of both long-duration DoS attacks and external disturbances . First, an event-triggering scheme was developed based on the observer in the presence of DoS attacks. Second, a model-based predictive control approach was presented. Then, by using the Lyapunov theory, stability for the multi-area power system with EVs was derived under consideration of the long-duration DoS attacks. Moreover, two algorithms were provided to obtain the model predictive event-triggered control (MPETC) parameters, LFC gains, and control of DoS attacks simultaneously. Finally, a simulation of a two-area power system with EVs was studied to illustrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Md Musabbir Hossain and Chen Peng},
  doi          = {10.1016/j.ins.2020.07.042},
  journal      = {Information Sciences},
  pages        = {437-453},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based event triggering h∞ LFC for multi-area power systems under DoS attacks},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Multi-value private information retrieval with colluding
databases via trace functions. <em>ISCI</em>, <em>543</em>, 426–436. (<a
href="https://doi.org/10.1016/j.ins.2020.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A classic t -private PIR (private information retrieval) scheme allows a user to retrieve one out of n values from k communicating replicated databases while any t of the k databases cannot identify the value being retrieved. However, in reality, the user may be more interested in retrieving multiple values simultaneously. This paper is devoted to the PIR problem with m retrieved values and k databases against t colluding databases ( t -private MPIR) in the context of information-theoretic security. The relationship m ⩽ w ( k - t ) m⩽w(k-t) is derived, where w is the largest average amount of information got by the user from each of the k databases. When w = 1 w=1 , via trace functions in finite fields, a t -private MPIR scheme retrieving m = k - t m=k-t values is presented with the complexity O ( log n ) O(logn) . Our scheme provides a lower complexity than those in the literature (the best known complexity for general t and k is a fractional power function of n ).},
  archive      = {J_ISCI},
  author       = {Yueting Li and Yanxun Chang and Minquan Cheng and Tao Feng},
  doi          = {10.1016/j.ins.2020.07.006},
  journal      = {Information Sciences},
  pages        = {426-436},
  shortjournal = {Inf. Sci.},
  title        = {Multi-value private information retrieval with colluding databases via trace functions},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiattribute decision making using probability density
functions and transformed decision matrices in interval-valued
intuitionistic fuzzy environments. <em>ISCI</em>, <em>543</em>, 410–425.
(<a href="https://doi.org/10.1016/j.ins.2020.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a new method for multiattribute decision making (MADM) using probability density functions and the transformed decision matrix (TDMx) of the decision matrix (DMx) offered by the decision maker (DM) in interval-valued intuitionistic fuzzy (IVIF) environments. First, it gets the TDMx of the DMx given by the DM. Then, it computes the average value of the interval-valued intuitionistic fuzzy values (IVIFVs) appearing at each column of the TDMx. Then, it calculates the variance of each IVIFV in the TDMx. Then, it computes the standard deviation (SD) of the IVIFVs appearing at each column of the TDMx. Then, based on the obtained TDMx, the obtained average value of the IVIFVs appearing at each column of the TDMx, and the obtained SD of the IVIFVs appearing at each column of the TDMx, it gets the z -score DMx. Then, each attribute’s IVIF weight is transformed into a crisp weight between zero and one. Finally, each alternative’s weighted score is calculated using the z -score DMx and each attribute’s transformed crisp weight. The larger the weighted score of an alternative, the better the preference order (PO) of the alternative. It can overcome the shortcomings of the existing MADM methods .},
  archive      = {J_ISCI},
  author       = {Xin-Yao Zou and Shyi-Ming Chen and Kang-Yun Fan},
  doi          = {10.1016/j.ins.2020.07.002},
  journal      = {Information Sciences},
  pages        = {410-425},
  shortjournal = {Inf. Sci.},
  title        = {Multiattribute decision making using probability density functions and transformed decision matrices in interval-valued intuitionistic fuzzy environments},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resilient adaptive control of switched nonlinear
cyber-physical systems under uncertain deception attacks. <em>ISCI</em>,
<em>543</em>, 398–409. (<a
href="https://doi.org/10.1016/j.ins.2020.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the problem of resilient adaptive dynamic surface control against uncertain sensor and actuator deception attacks for a class of switched nonlinear cyber-physical systems. The concerned system dynamics suffer from both unknown switching mechanisms and more general nonlinearities . Furthermore, it is our aim to deal with deception attacks as adversaries can corrupt sensor and control data, resulting the conventional error surfaces inaccessible for feedback control design. To this end, we construct sensor attack compensators to mitigate the effects caused by the sensor attacks. In addition, neural networks are utilized to approximate the nonlinear terms and compensate the state-dependent actuator attacks. Then, we construct a common Lyapunov function and propose a dynamic surface-based resilient adaptive strategy, under which the equilibrium point of the resulted closed-loop system is semi-globally uniformly ultimately bounded under arbitrary switchings. Finally, we provide a continuously stirred tank reactor system under uncertain deception attacks to validate the effectiveness of the proposed control method.},
  archive      = {J_ISCI},
  author       = {Zhanjie Li and Jun Zhao},
  doi          = {10.1016/j.ins.2020.07.022},
  journal      = {Information Sciences},
  pages        = {398-409},
  shortjournal = {Inf. Sci.},
  title        = {Resilient adaptive control of switched nonlinear cyber-physical systems under uncertain deception attacks},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). DeepEmLAN: Deep embedding learning for attributed networks.
<em>ISCI</em>, <em>543</em>, 382–397. (<a
href="https://doi.org/10.1016/j.ins.2020.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network embedding aims to learn the low-dimensional representations for the components in the network while maximally preserving the structure and inherent properties. Its efficiency has been proved in various real-world applications. However, most existing studies on attributed networks cannot explore both the multi-typed attributes and the semantic relationships flexibly. To address the above problem, we propose a deep model based embedding learning method for attributed networks, named DeepEmLAN. It can smoothly project different types of attributed information into the same semantic space through a deep attention model, while maintaining the topological structures . Furthermore, we design a heuristic combining strategy to generate the final embeddings, which makes the nodes sharing more neighbors, similar text-enriched or labeled attributes closer in the representational space. To demonstrate the potential of the proposed DeepEmLAN, we evaluate its performance on the challenging tasks of node classification and network reconstruction. The experimental results on several real datasets have shown that DeepEmLAN outperforms competitive state-of-the-art methods significantly.},
  archive      = {J_ISCI},
  author       = {Zhongying Zhao and Hui Zhou and Chao Li and Jie Tang and Qingtian Zeng},
  doi          = {10.1016/j.ins.2020.07.001},
  journal      = {Information Sciences},
  pages        = {382-397},
  shortjournal = {Inf. Sci.},
  title        = {DeepEmLAN: Deep embedding learning for attributed networks},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A weighted distributed predictor-feedback control synthesis
for interconnected time delay systems. <em>ISCI</em>, <em>543</em>,
367–381. (<a href="https://doi.org/10.1016/j.ins.2020.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper investigates the control design of interconnected time delay systems by means of distributed predictor-feedback delay compensation approaches and event-triggered mechanism. The idea behind delay compensation is to counteract the negative effects of delays in the control-loop by feeding back future predictions of the system state. Nevertheless, an exact prediction of the overall system state vector cannot be obtained providing that each system has only knowledge of their local data regarding the system model and state variables. Consequently, predictor-feedback delay compensation may lose effectiveness if the coupling between subsystems is sufficiently strong. To circumvent this drawback, the proposed distributed predictor-feedback control incorporates extra degree of freedom for control synthesis by introducing new weighting factors for each local prediction term. The design of the weighting factors is addressed, together with the event-triggered parameters, by an algorithm based on Linear Matrix Inequalities (LMI) and the Cone Complementarity Linearization (CCL). Simulation results are provided to show the achieved improvements and validate the effectiveness of the proposed method, even in the case that other control strategies fail to stabilize the closed-loop system.},
  archive      = {J_ISCI},
  author       = {Antonio González},
  doi          = {10.1016/j.ins.2020.07.011},
  journal      = {Information Sciences},
  pages        = {367-381},
  shortjournal = {Inf. Sci.},
  title        = {A weighted distributed predictor-feedback control synthesis for interconnected time delay systems},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self directed learning based workload forecasting model for
cloud resource management. <em>ISCI</em>, <em>543</em>, 345–366. (<a
href="https://doi.org/10.1016/j.ins.2020.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workload prediction plays a vital role in intelligent resource scaling and load balancing that maximize the economic growth of cloud service providers as well as users’ quality of experience (QoE). Numerous approaches have been discovered to estimate the future workload and machine learning is being widely used to improve the forecast accuracy. This paper presents a self directed workload forecasting method (SDWF) that captures the forecasting error trend by computing the deviation in recent forecasts and applies it to enhance the accuracy of further predictions. The model utilizes an improved heuristic approach based on the blackhole phenomena for the training of neurons. The efficacy of the proposed method is evaluated over six different real world data traces. The accuracy of the model is compared with existing models that use different state-of-art approaches including deep learning , differential evolution and back propagation . The maximum relative reduction in mean squared forecast error is observed up to 99.99\% compared with existing methods. In addition, the statistical analysis is also carried out using Friedman and Wilcoxon signed rank tests to validate the efficacy of the proposed forecasting model .},
  archive      = {J_ISCI},
  author       = {Jitendra Kumar and Ashutosh Kumar Singh and Rajkumar Buyya},
  doi          = {10.1016/j.ins.2020.07.012},
  journal      = {Information Sciences},
  pages        = {345-366},
  shortjournal = {Inf. Sci.},
  title        = {Self directed learning based workload forecasting model for cloud resource management},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Opacity of networked discrete event systems. <em>ISCI</em>,
<em>543</em>, 328–344. (<a
href="https://doi.org/10.1016/j.ins.2020.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opacity is an important information-flow property, which is used to characterize whether or not the secrets of system have been leaked to the intruders. Over the past ten years, opacity of discrete event systems (DESs) modeled as automata and Petri nets have been well investigated under the assumption that the communication channels between systems and intruders are perfect. However, in networked discrete event systems (NDESs), the DESs run in a shared network, and the communication delays and losses are inevitable usually. In this paper, we investigate the problems of opacity in the framework of NDESs. We formulate four kinds of opacity for NDESs, including current-state opacity, initial-state opacity, initial-final-state opacity, and K -step opacity. We also present the verification algorithms for these notions. We extend the notions of opacity in classical DESs, that is, if the communication delays and losses disappear, then these new notions would reduce to their classical counterparts. A number of examples are provided to illustrate the results obtained.},
  archive      = {J_ISCI},
  author       = {Jingkai Yang and Weilin Deng and Daowen Qiu and Cheng Jiang},
  doi          = {10.1016/j.ins.2020.07.017},
  journal      = {Information Sciences},
  pages        = {328-344},
  shortjournal = {Inf. Sci.},
  title        = {Opacity of networked discrete event systems},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid distributed batch-stream processing approach for
anomaly detection. <em>ISCI</em>, <em>543</em>, 309–327. (<a
href="https://doi.org/10.1016/j.ins.2020.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Batch and stream processing are separately and efficiently applied in many applications. However, some newer data-driven applications such as the Internet of Things and cloud computing call for hybrid processing approaches in order to handle the speed and accuracy required for processing such complex data. In this paper, we propose a Hybrid Distributed Batch-Stream (HDBS) architecture for anomaly detection in real-time data. The hybrid architecture , while benefiting from the accuracy provided by batch processing, also enjoys the speed and real-time features of stream processing. In the proposed architecture, our focus is on the algorithmic aspects of hybrid processing including the interaction models between batch and stream processing units, the characteristics of batch and stream machine learning algorithms and the principles of merging the results of different processing units. The driving idea of such combination is that the results of batch and stream processing units are complementary with each other, as one of them constructs accurate models based on previous data, and the other one is capable of processing new stream data in real-time. Furthermore, we propose a generalized version of the HDBS with respect to its algorithms and communication policy levels. In the generalized HDBS architecture, we address the various aspects of the interaction between the batch and stream processing units, and the merging operations to produce the final results. the evaluations of the proposed architecture using various criteria (accuracy, space complexity, and time complexity) demonstrate that the accuracy of the proposed method is higher than the accuracy of the batch processing methods, its time complexity is also similar to one of the stream processing methods and much less than the batch processing methods, which makes our proposed architecture an efficient and practical solution for real-time anomaly detection .},
  archive      = {J_ISCI},
  author       = {Boshra Pishgoo and Ahmad Akbari Azirani and Bijan Raahemi},
  doi          = {10.1016/j.ins.2020.07.026},
  journal      = {Information Sciences},
  pages        = {309-327},
  shortjournal = {Inf. Sci.},
  title        = {A hybrid distributed batch-stream processing approach for anomaly detection},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VisGraphNet: A complex network interpretation of
convolutional neural features. <em>ISCI</em>, <em>543</em>, 296–308. (<a
href="https://doi.org/10.1016/j.ins.2020.07.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose and investigate the use of visibility graphs to model the feature map of a neural network. Initially devised for studies on complex networks, we employ this type of model for classification of texture images. An alternative viewpoint provided by these graphs over the original data motivates this work. Experiments evaluate the performance of our method using four benchmark databases, namely, KTHTIPS-2b, FMD, UIUC, and UMD and in a practical problem, which is the identification of plant species using scanned images of their leaves. Our method was competitive with other state-of-the-art approaches both in terms of classification accuracy and computational time. Results confirm the potential of techniques used for data analysis in different contexts to give more meaningful interpretation to the use of neural networks in texture classification.},
  archive      = {J_ISCI},
  author       = {Joao B. Florindo and Young-Sup Lee and Kyungkoo Jun and Gwanggil Jeon and Marcelo K. Albertini},
  doi          = {10.1016/j.ins.2020.07.050},
  journal      = {Information Sciences},
  pages        = {296-308},
  shortjournal = {Inf. Sci.},
  title        = {VisGraphNet: A complex network interpretation of convolutional neural features},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered reinforcement learning h∞ control design for
constrained-input nonlinear systems subject to actuator failures.
<em>ISCI</em>, <em>543</em>, 273–295. (<a
href="https://doi.org/10.1016/j.ins.2020.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, a novel input-constrained H ∞ H∞ fault-tolerant control approach is developed by using sliding mode control technology and event-triggered reinforcement learning (RL) algorithm. To reduce or even eliminate the impacts of the time-varying actuator failures , a properly sliding mode control strategy is proposed for the controlled system, while the event-triggered H ∞ H∞ control scheme is established via RL algorithm for the equivalent sliding mode dynamics. By utilizing a single neural network (NN), the Hamilton–Jacobi–Bellman (HJB) equation can be solved approximately, thereby gaining time-triggered worst-case disturbance law, as well as event-triggered optimal control policy. Besides, it is unnecessary to given a initial stabilizing control input in the learning process of neural networks (NNs) in this paper. Moreover, the Lyapunov stability principle is applied to guarantee that the controlled system is uniformly ultimately bounded (UUB). Finally, to verify the feasibility and efficient performance of the developed approach, three simulations are carried out.},
  archive      = {J_ISCI},
  author       = {Yuling Liang and Huaguang Zhang and Jie Duan and Shaoxin Sun},
  doi          = {10.1016/j.ins.2020.07.055},
  journal      = {Information Sciences},
  pages        = {273-295},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered reinforcement learning h∞ control design for constrained-input nonlinear systems subject to actuator failures},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretable duplicate question detection models based on
attention mechanism. <em>ISCI</em>, <em>543</em>, 259–272. (<a
href="https://doi.org/10.1016/j.ins.2020.07.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there exist growing concerns about the interpretability of deep learning models . While few of these models have been applied to a duplicate question detection task, which aims at finding semantically equivalent question pairs of question answering forum. In this paper, based on an attention mechanism , we propose two modularized interpretable deep neural network models for such tasks. During the word precessing procedure, a filter operation is employed to enhance the relevant information contained in the pre-trained word embeddings . Regarding the word matching and sentence representation process, vanilla attention and structured attention mechanisms are utilized, respectively. Benefiting from the interpretability of attention techniques, our models can illustrate how the words match between sentence pairs and what aspects of the sentences are extracted to have an effect on the final decision. The attention visualization furnishes us with detailed representation at word and sentence level. And experimental results show that our models are comparable with other reported models.},
  archive      = {J_ISCI},
  author       = {Qifeng Zhou and Xiang Liu and Qing Wang},
  doi          = {10.1016/j.ins.2020.07.048},
  journal      = {Information Sciences},
  pages        = {259-272},
  shortjournal = {Inf. Sci.},
  title        = {Interpretable duplicate question detection models based on attention mechanism},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing artificial bee colony algorithm with multi-elite
guidance. <em>ISCI</em>, <em>543</em>, 242–258. (<a
href="https://doi.org/10.1016/j.ins.2020.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial bee colony (ABC) algorithm is a relatively new paradigm of swarm intelligence based optimization technique, which has attracted a lot of attention for its simple structure and good performance. For some complex optimization problems, however, the performance of ABC is challenged due to its solution search equation that has strong explorative ability but poor exploitative ability. To solve this defect, in this work, we propose an improved ABC algorithm by using multi-elite guidance, which has the benefits of utilizing valuable information from elite individuals to guide search while without losing population diversity. First, we construct an elite group by selecting some elite individuals, and then introduce two improved solution search equations into the employed bee phase and onlooker bee phase based on the elite group, respectively. Last, we develop a modified neighborhood search operator by utilizing the elite group as well, which aims to achieve a better tradeoff between explorative and exploitative abilities. To verify our approach, 50 well-known test functions and one real-world optimization problem are used in the experiments, including 22 scalable basic test functions and 28 complex CEC2013 test functions. Seven different well-established ABC variants are involved in the comparison and the results show that our approach can achieve better or at least comparable performance on most of the test functions.},
  archive      = {J_ISCI},
  author       = {Xinyu Zhou and Jiaxin Lu and Junhong Huang and Maosheng Zhong and Mingwen Wang},
  doi          = {10.1016/j.ins.2020.07.037},
  journal      = {Information Sciences},
  pages        = {242-258},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing artificial bee colony algorithm with multi-elite guidance},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A face recognition framework based on a pool of techniques
and differential evolution. <em>ISCI</em>, <em>543</em>, 219–241. (<a
href="https://doi.org/10.1016/j.ins.2020.06.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face Recognition (FR) systems are still facing significant challenges when different image issues, such as variation of illumination, pose, expression, and occlusion, are present in captured images. In many situations, it is only possible to obtain One Sample Per Person (OSPP) for training, representing a challenging real-world condition. The proposed FR framework is defined by an optimizer and a pool of preprocessing and feature extraction techniques. The approach makes a pool of techniques available to the optimizer, that can seek the best set of strategies, and tune its parameters. In this work, the FR framework uses the well-known Differential Evolution algorithm as an optimizer, denominated as FR-DE. Two experimental methodologies are employed to assess the performance of the proposed FR-DE framework. First, it is employed a standard dataset separation, and the Yale Extended B dataset is used, which presents severe illumination variation conditions. The second experimental methodology considers the OSPP problem with illumination and poses variations. Also, two well-known datasets are employed, named CMU-PIE and FERET. The proposed approach is compared with some state-of-art algorithms. The comparative analysis suggests that the proposed framework is competitive and suitable for FR systems.},
  archive      = {J_ISCI},
  author       = {Guilherme Felippe Plichoski and Chidambaram Chidambaram and Rafael Stubs Parpinelli},
  doi          = {10.1016/j.ins.2020.06.054},
  journal      = {Information Sciences},
  pages        = {219-241},
  shortjournal = {Inf. Sci.},
  title        = {A face recognition framework based on a pool of techniques and differential evolution},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Privacy-preserving point-of-interest recommendation based on
geographical and social influence. <em>ISCI</em>, <em>543</em>, 202–218.
(<a href="https://doi.org/10.1016/j.ins.2020.07.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate a privacy-preserving problem for point-of-interest (POI) recommendation system for rapidly growing location-based social networks (LBSNs). The LBSN-based recommendation algorithms usually consider three factors: user similarity, social influence between friends and geographical influence in. The LBSN-based recommendation system first needs to collect relevant information of users and then provide them with potentially interesting contents. However, sensitive information of users may be leaked when the recommendation is provided. In this article, we focus on preventing user’s privacy from disclosure upon geographical location and friend relationship factors. We propose a geographical location privacy-preserving algorithm (GLP) that achieves 〈 r , h 〉 〈r,h〉 -privacy and present a friend relationship privacy-preserving algorithm (FRP) through adding Laplacian distributed noise for fusing the user trusts. Subsequently, we integrate the GLP and FRP algorithms into a general recommendation system and build a privacy-preserving recommendation system. The novel system enjoys the privacy guarantee under the metric differential entropy through theoretical analysis. Experimental results demonstrate a good trade-off between privacy and accuracy of the proposed recommendation system.},
  archive      = {J_ISCI},
  author       = {Yongfeng Huo and Bilian Chen and Jing Tang and Yifeng Zeng},
  doi          = {10.1016/j.ins.2020.07.046},
  journal      = {Information Sciences},
  pages        = {202-218},
  shortjournal = {Inf. Sci.},
  title        = {Privacy-preserving point-of-interest recommendation based on geographical and social influence},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based adaptive event-triggered sliding mode control
of saturated nonlinear networked systems with cyber-attacks.
<em>ISCI</em>, <em>543</em>, 180–201. (<a
href="https://doi.org/10.1016/j.ins.2020.06.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates an observer-based adaptive event-triggered sliding mode control (SMC) problem for nonlinear networked systems subject to actuator and sensor saturation with cyber-attacks. First, an improved adaptive event triggering scheme is put forward to reduce the frequency of data communication between the networked system components, and thus the potential communication cost. It is revealed that the proposed scheme can achieve superior performance over some existing ones in terms of a significant reduction of events. Second, to simplify the design of the sliding surface, an observer with cyber-attacks is designed, which is used to estimate the system state. The state error system and sliding mode dynamics are then established as a closed-loop system accounting for the concurrent effects of cyber-attacks, saturation constraints. Furthermore, by making use of the Lyapunov-Krasovskii functional, sufficient criterions for guaranteeing both ultimately bounded stability and asymptotic stability of the closed-loop system with prescribed performance are derived. The reachability of sliding mode surface can be ensured by a sliding mode controller . Finally, a numerical example is used to show the effectiveness and superiority of proposed method.},
  archive      = {J_ISCI},
  author       = {Long Zhang and Ge Guo},
  doi          = {10.1016/j.ins.2020.06.073},
  journal      = {Information Sciences},
  pages        = {180-201},
  shortjournal = {Inf. Sci.},
  title        = {Observer-based adaptive event-triggered sliding mode control of saturated nonlinear networked systems with cyber-attacks},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MINE: A framework for dynamic regressor selection.
<em>ISCI</em>, <em>543</em>, 157–179. (<a
href="https://doi.org/10.1016/j.ins.2020.07.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic Regressor Selection (DRS) techniques aim to select the most competent regressors from an ensemble per test pattern. So, for each test pattern, only a subset of the most competent regressors are used to estimate its target value. Hence, the central issue in DRS techniques is how to define the competence of the regressors which is usually defined using a single measure, such as the performance of the regressor in the local region of the feature space around the test pattern, called the region of competence. However, no single measure is the best for any task. In this work, we present the Meta INtEgration (MINE) framework that selects and combines the most competent regressors from an ensemble during the evaluation of a given test pattern. MINE uses different measures extracted from the region of competence as a criterion for the selection and combination of the regressors. In contrast to traditional combination schemes where all the regressors are weighted to produce the final answer, MINE selects the best regressors per pattern on-the-fly and combines them to predict the value of the test pattern. Comprehensive experiments on 20 regression datasets show that MINE compares favorably to literature techniques.},
  archive      = {J_ISCI},
  author       = {Thiago J.M. Moura and George D.C. Cavalcanti and Luiz S. Oliveira},
  doi          = {10.1016/j.ins.2020.07.056},
  journal      = {Information Sciences},
  pages        = {157-179},
  shortjournal = {Inf. Sci.},
  title        = {MINE: A framework for dynamic regressor selection},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Certificateless two-party authenticated key agreement scheme
for smart grid. <em>ISCI</em>, <em>543</em>, 143–156. (<a
href="https://doi.org/10.1016/j.ins.2020.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart grid is a fully automated power transmission network . It monitors and controls each user and grid node to ensure bidirectional flow of information and power between all nodes. It is an important issue that how to achieve secure sharing of information among numerous communicating agents in the smart grid environments . Authenticated key agreement (AKA) is a good option to enable secure communication between the smart meter and utility. In recent years, several AKA schemes have been put forward for smart grid environments . There are two shortcomings in these schemes: First, they are constructed from traditional public key infrastructure (PKI) or identity based cryptography (IBC), so they suffer from certificate management problem or key escrow problem. Second, the security proofs of these schemes were done in the random oracle model(ROM). It is well known, a cryptographic scheme proven to be secure in ROM is not necessarily safe in practical applications. In this paper, we present a certificateless two-party authenticated key agreement (CL2PAKA) scheme for smart grids, then provide the security proofs in the standard model. Our scheme does not require pairing operations and requires only four scale multiplication operations, so it is more efficient than previous ones.},
  archive      = {J_ISCI},
  author       = {Lunzhi Deng and Ronghai Gao},
  doi          = {10.1016/j.ins.2020.07.025},
  journal      = {Information Sciences},
  pages        = {143-156},
  shortjournal = {Inf. Sci.},
  title        = {Certificateless two-party authenticated key agreement scheme for smart grid},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A distributed networked system for secure publicly
verifiable self-tallying online voting. <em>ISCI</em>, <em>543</em>,
125–142. (<a href="https://doi.org/10.1016/j.ins.2020.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For successful electronic voting (e-voting), it is critically important to ensure the security, privacy and verifiability of all steps. This paper uses Intel Software Guard Extensions (SGX) to achieve these goals and provide protection against malicious adversaries with administrative access. We introduce a Distributed SGX Networked System (DSGXNS). It connects one or several SGXs and the bulletin board of the election. We propose and investigate a DSGXNS-based secure, publicly verifiable and self-tallying online voting protocol. Each cast vote is uploaded to the DSGXNS via a secure communication channel built after a remote attestation. The validity of submissions is verified inside the SGX enclaves and legitimate votes are encrypted there. For end-to-end voter verification, a new encryption mechanism is proposed. It prevents confidentiality breaches and enables everyone to verify the validity of submissions and the outcome, which can be self-tallied using a homomorphic property. It maintains confidentiality because even the system administrators or malicious adversaries gaining administrative access cannot read data in the SGX enclaves. Every voter can verify all steps of the election and tally the cast ballots. Our theoretical analysis and experiments show that the protocol is secure and efficient.},
  archive      = {J_ISCI},
  author       = {Xuechao Yang and Xun Yi and Andrei Kelarev and Fengling Han and Junwei Luo},
  doi          = {10.1016/j.ins.2020.07.023},
  journal      = {Information Sciences},
  pages        = {125-142},
  shortjournal = {Inf. Sci.},
  title        = {A distributed networked system for secure publicly verifiable self-tallying online voting},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mean-square consensus for heterogeneous multi-agent systems
with probabilistic time delay. <em>ISCI</em>, <em>543</em>, 112–124. (<a
href="https://doi.org/10.1016/j.ins.2020.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the delay-dependent consensus problem of heterogeneous multi-agent systems over directed topology. The heterogeneous dynamics consisting of both first-order and second-order agents with random time delay are considered. New distributed control protocols based on the probability distribution of time delay are proposed for the leader-following and leaderless systems. By adopting matrix theory , Lyapunov-Krasovskii function and stochastic analysis , some less conservative conditions for the mean-square consensus are established over directed fixed topology and switching topologies . Moreover, the larger upper bounds of time delay are obtained. Finally, several simulations are presented to illustrate the obtained results.},
  archive      = {J_ISCI},
  author       = {Fenglan Sun and Xiaogang Liao and Jürgen Kurths},
  doi          = {10.1016/j.ins.2020.07.021},
  journal      = {Information Sciences},
  pages        = {112-124},
  shortjournal = {Inf. Sci.},
  title        = {Mean-square consensus for heterogeneous multi-agent systems with probabilistic time delay},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cryptanalysis and improvement of “game theoretic security of
quantum bit commitment.” <em>ISCI</em>, <em>543</em>, 106–111. (<a
href="https://doi.org/10.1016/j.ins.2020.06.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Zhou et al. proposed a quantum bit commitment (QBC) protocol by using Bell states. In this paper, we propose a cryptanalysis strategy for the protocol and demonstrate that the sender can successfully change her commitment without being detected by the recipient with a probability 1 - ( 1 / 2 ) n 1-(1/2)n , where n is the number of rounds in executing the protocol. Hence, the protocol does not meet the binding property which shows its insecurity. In order to overcome the shortcomings, we propose an improved version of the protocol. The analysis illustrates that the improvement meets the security requirements.},
  archive      = {J_ISCI},
  author       = {Hao Cao and Wenping Ma and Liangdong Lü and Ge Liu and Xiaoxue Liu and Wenyang Sun},
  doi          = {10.1016/j.ins.2020.06.055},
  journal      = {Information Sciences},
  pages        = {106-111},
  shortjournal = {Inf. Sci.},
  title        = {Cryptanalysis and improvement of “Game theoretic security of quantum bit commitment”},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient list based mining of high average utility patterns
with maximum average pruning strategies. <em>ISCI</em>, <em>543</em>,
85–105. (<a href="https://doi.org/10.1016/j.ins.2020.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High average utility pattern mining is the concept proposed to complement drawbacks of high utility pattern mining by considering lengths of patterns along with the utilities of the patterns. High average utility pattern mining should be able to gratify the anti-monotone property like other pattern mining techniques. Many high average utility pattern mining studies to satisfy the anti-monotone property have been proposed in order to improve various upper-bounds because the performance of pattern mining can be improved efficiently by satisfying the anti-monotone property. Although those upper-bounds can effectively reduce the search space, they still take a lot of cost to calculate all unpromising patterns or cannot find them in advance. Therefore, in this paper, a novel high average utility pattern mining approach is proposed by employing two novel upper-bounds called tight maximum average utility upper-bound and maximum remaining average utility upper-bound. Moreover, a newly suggested list-based structure, TA-List, is designed to adopt two pruning strategies. The proposed technique can efficiently extract high average utility patterns by reducing search space. To evaluate the performance of the proposed method, various experiments using real and synthetic datasets are conducted in terms of runtime, memory usage and scalability and the proposed approach is compared with the state-of-the-art high average utility pattern mining algorithms. The results of experiments show that the suggested algorithm has better performance with regard to runtime, memory usage and scalability.},
  archive      = {J_ISCI},
  author       = {Heonho Kim and Unil Yun and Yoonji Baek and Jongseong Kim and Bay Vo and Eunchul Yoon and Hamido Fujita},
  doi          = {10.1016/j.ins.2020.07.043},
  journal      = {Information Sciences},
  pages        = {85-105},
  shortjournal = {Inf. Sci.},
  title        = {Efficient list based mining of high average utility patterns with maximum average pruning strategies},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reachability problem in non-uniform cellular automata.
<em>ISCI</em>, <em>543</em>, 72–84. (<a
href="https://doi.org/10.1016/j.ins.2020.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the CREP (Configuration REachability Problem) for non-uniform cellular automata (CAs). The cells of non-uniform CAs, we have considered here, can use different Wolfram’s rules to generate their next states. We report an algorithm which decides whether or not a configuration of a given (non-uniform) cellular automaton is reachable from another configuration. We develop a characterization tool, named Reachability tree , is used to develop theories and the decision algorithm for the CREP. Though the worst case complexity of the algorithm is exponential in time and space, but the average performance is very good.},
  archive      = {J_ISCI},
  author       = {Sumit Adak and Sukanya Mukherjee and Sukanta Das},
  doi          = {10.1016/j.ins.2020.07.034},
  journal      = {Information Sciences},
  pages        = {72-84},
  shortjournal = {Inf. Sci.},
  title        = {Reachability problem in non-uniform cellular automata},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). General-purpose hierarchical optimisation of machine
learning pipelines with grammatical evolution. <em>ISCI</em>,
<em>543</em>, 58–71. (<a
href="https://doi.org/10.1016/j.ins.2020.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces Hierarchical Machine Learning Optimisation (HML-Opt), an AutoML framework that is based on probabilistic grammatical evolution. HML-Opt has been designed to provide a flexible framework where a researcher can define the space of possible pipelines to solve a specific machine learning problem, which can range from high-level decisions about representation and features to low-level hyper-parameter values. The evaluation of HML-Opt is presented via two different case studies, both of which demonstrate that it is competitive with existing AutoML tools on a variety of benchmarks. Furthermore, HML-Opt can be applied to novel problems, such as knowledge extraction from natural language text, whereas other techniques are insufficiently flexible to capture the complexity of these scenarios. The source code for HML-Opt is available online for the research community.},
  archive      = {J_ISCI},
  author       = {Suilan Estevez-Velarde and Yoan Gutiérrez and Yudivián Almeida-Cruz and Andrés Montoyo},
  doi          = {10.1016/j.ins.2020.07.035},
  journal      = {Information Sciences},
  pages        = {58-71},
  shortjournal = {Inf. Sci.},
  title        = {General-purpose hierarchical optimisation of machine learning pipelines with grammatical evolution},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability analysis of takagi–sugeno systems using a switched
fuzzy lyapunov function. <em>ISCI</em>, <em>543</em>, 43–57. (<a
href="https://doi.org/10.1016/j.ins.2020.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a switched fuzzy Lyapunov function approach is proposed to analyze the stability of continuous-time Takagi–Sugeno fuzzy systems. The results are established by exploring properties of the membership functions. The key point is that the time derivatives of the membership functions are represented as a finite polytope and less conservative linear matrix inequalities are obtained. Numerical examples illustrate the efficiency of the new stabilizing conditions.},
  archive      = {J_ISCI},
  author       = {Leandro J. Elias and Flávio A. Faria and Rayza Araujo and Vilma A. Oliveira},
  doi          = {10.1016/j.ins.2020.07.020},
  journal      = {Information Sciences},
  pages        = {43-57},
  shortjournal = {Inf. Sci.},
  title        = {Stability analysis of Takagi–Sugeno systems using a switched fuzzy lyapunov function},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing firefly algorithm with courtship learning.
<em>ISCI</em>, <em>543</em>, 18–42. (<a
href="https://doi.org/10.1016/j.ins.2020.05.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The firefly algorithm (FA) is a nature-inspired heuristic optimization algorithm based on the luminescence and attraction behavior of fireflies. Although the FA can effectively solve complex optimization problems , it suffers from premature convergence because of its simple full attraction model. However, in nature, fireflies exhibit luminous behavior to attract mates. The attractiveness between fireflies of opposite sexes depends not only on the light intensity they emit, but also on their individual size, location, and other factors. In the original FA, all fireflies are assumed to be the same, i.e., they have no gender-based difference, which is not true biologically. Therefore, in this paper, we proposed a novel courtship learning (CL) framework to enhance the performance of the FA. In the proposed framework, the population is divided into female and male subpopulations. The female archiving mechanism is adopted to select excellent fireflies, which are assumed to be female fireflies. When the selected male firefly emits light that is less bright than that of the current firefly, a female individual will be selected from the female archive to guide the movement of the selected male firefly. Comprehensive experiments are conducted on the CEC 2013 benchmark set and the proposed CL framework is integrated with other advanced FA variants to verify its effects. Experimental results confirm that the proposed framework significantly enhances the performance of the original FA and advanced FA variants.},
  archive      = {J_ISCI},
  author       = {Hu Peng and Wenhua Zhu and Changshou Deng and Zhijian Wu},
  doi          = {10.1016/j.ins.2020.05.111},
  journal      = {Information Sciences},
  pages        = {18-42},
  shortjournal = {Inf. Sci.},
  title        = {Enhancing firefly algorithm with courtship learning},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memory-event-trigger-based secure control of cloud-aided
active suspension systems against deception attacks. <em>ISCI</em>,
<em>543</em>, 1–17. (<a
href="https://doi.org/10.1016/j.ins.2020.06.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of memory-based event-triggered fuzzy control for cloud-aided active suspension systems (ASSs) against deception attacks. A novel memory-based event-triggered mechanism (ETM) which is sensitive to deception attacks is proposed. Compared to the general ETM, the system under the memory-based ETM has a higher average data releasing rate during deception attacks and external disturbance . Therefore, a better suspension performance of the cloud-aided ASS can be obtained. Meanwhile, the system without deception attacks can maintain a lower average data releasing rate, thereby reducing the occupation of the network resource. Moreover, such a memory-based ETM can mitigate the occurrence of wrong triggering event that is generated by some abrupt variation of the input of ETM. Sufficient conditions that guarantee the desired performance of cloud-aided ASSs are derived. Finally, an example of quarter-vehicle suspension system is provided to verify the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Xiang Sun and Zhou Gu and Fan Yang and Shen Yan},
  doi          = {10.1016/j.ins.2020.06.059},
  journal      = {Information Sciences},
  pages        = {1-17},
  shortjournal = {Inf. Sci.},
  title        = {Memory-event-trigger-based secure control of cloud-aided active suspension systems against deception attacks},
  volume       = {543},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple local 3D CNNs for region-based prediction in smart
cities. <em>ISCI</em>, <em>542</em>, 476–491. (<a
href="https://doi.org/10.1016/j.ins.2020.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In smart cities, region-based prediction (e.g. traffic flow and electricity flow) is of great importance to city management and public safety, and it remains a daunting challenge that involves complicated spatial-temporal-related factors such as weather, holidays, events, etc. Region-based forecasting aims to predict the future situation for regions in a city based on historical data. In the existing literature, the state-of-the-art method solve region-based problems with long short-term memory (LSTM) algorithms that extract the temporal view and local convolutional neural network (CNN) algorithms that extract the spatial view (local spatial correlation via local CNN). In this paper, we propose a deep learning-based method for region-based prediction for smart cities. First, we divide the cities into regions based on the space dimension and model the situation of the cities in 3D volumes. Based on the constructed 3D volumes, we design a model called multiple local 3D CNN spatial-temporal residual networks (LMST3D-ResNet) for region-based prediction in smart cities. LMST3D-ResNet can extract multiple temporal dependencies (including trend, period and closeness) for local regions and then predict the future citywide activities according to the learned multiple spatial-temporal features. LMST3D-ResNet can also combine the spatial-temporal features with external factors. LMST3D-ResNet includes 3D CNNs and ResNet mechanisms for processing spatial-temporal information. In particular, 3D CNNs have the ability to model 3-dimensional information due to 3D convolution and 3D pooling operations, while ResNet enables the connection of the convolutional neural network across layers to obtain a deeper network structure. Specifically, in our proposed model, a novel region-based information extraction mechanism and an end-to-end multiple spatial-temporal dependency learning structure are designed for local regions. Extensive experimental results on two datasets, i.e., MLElectricity and BJTaxi demonstrate the superior performance of our proposed method over the exisiting state-of-the-art methods.},
  archive      = {J_ISCI},
  author       = {Yibi Chen and Xiaofeng Zou and Kenli Li and Keqin Li and Xulei Yang and Cen Chen},
  doi          = {10.1016/j.ins.2020.06.026},
  journal      = {Information Sciences},
  pages        = {476-491},
  shortjournal = {Inf. Sci.},
  title        = {Multiple local 3D CNNs for region-based prediction in smart cities},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A process mining algorithm to mixed multiple-concurrency
short-loop structures. <em>ISCI</em>, <em>542</em>, 453–475. (<a
href="https://doi.org/10.1016/j.ins.2020.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process mining is a technique that can discover and enhance business processes by extracting knowledge from the event logs generated in information systems. A mixed multiple-concurrency short-loop structure is a frequently appearing structure in business processes. It cannot be mined accurately (or well) from incomplete logs by existing methods to the best of our knowledge. In this paper, an AlphaMining algorithm is proposed to discover mixed multiple-concurrency short-loop structures via Petri nets . First, the activities are matched with a triangular two-degree loop or a quadrilateral two-degree loop. Then, two kinds of short-loop structures are identified from the incomplete logs. Algorithms are proposed to correctly construct models with multiple-concurrency short-loop structures. Finally, the proposed method is integrated as a plug-in into an open-source process mining tool named ProM. The correctness and effectiveness of the proposed method are verified by experiments.},
  archive      = {J_ISCI},
  author       = {HongWei Sun and Wei Liu and Liang Qi and YuYue Du and Xiaojun Ren and XinYing Liu},
  doi          = {10.1016/j.ins.2020.07.003},
  journal      = {Information Sciences},
  pages        = {453-475},
  shortjournal = {Inf. Sci.},
  title        = {A process mining algorithm to mixed multiple-concurrency short-loop structures},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of stabilized polynomial-based ensemble fuzzy neural
networks based on heterogeneous neurons and synergy of multiple
techniques. <em>ISCI</em>, <em>542</em>, 425–452. (<a
href="https://doi.org/10.1016/j.ins.2020.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, a novel category of polynomial-based ensemble fuzzy neural networks (PEFNNs) are proposed. The study is focused on the development of advanced design methodologies to improve the performance (prediction accuracy) of the model when dealing with nonlinear regression problems . In contrast to the conventional fuzzy polynomial-based models, we adopt a hybrid network structure composed of heterogeneous neurons. The first layer of PEFNNs consists of fuzzy regular polynomial neurons optimized by clustering method . In the consecutive layers, we engage two types of polynomial neurons, which are selected and optimized by evolutionary algorithms . Moreover, an enhanced topology based on fuzzy module and enhanced interconnection (FM&amp;EI) is designed to strengthen the characteristics of fuzzy feature information as well as increase the number and diversity of neurons. Multiple techniques are used synergistically to reinforce the performance of PEFNNs. First, a coefficient-based performance compromise algorithm (CPC) is designed to select neurons by considering the performance and complexity of the neuron. Second, L 2 -norm regularization is considered to improve the performance of the model. Third, evolutionary algorithm is employed to adjust the structural parameters of PEFNNs. Furthermore, FM&amp;EI and hybrid network structure which consist of heterogeneous neurons are considered as one of the multiple approaches to construct the ensemble model. The performance and stability of PEFNNs are evaluated with a diversity of datasets. A thorough comparative analysis also is covered.},
  archive      = {J_ISCI},
  author       = {Congcong Zhang and Sung-Kwun Oh and Zunwei Fu},
  doi          = {10.1016/j.ins.2020.07.008},
  journal      = {Information Sciences},
  pages        = {425-452},
  shortjournal = {Inf. Sci.},
  title        = {Design of stabilized polynomial-based ensemble fuzzy neural networks based on heterogeneous neurons and synergy of multiple techniques},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Overlap and grouping functions on complete lattices.
<em>ISCI</em>, <em>542</em>, 406–424. (<a
href="https://doi.org/10.1016/j.ins.2020.06.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Paiva et al. introduced the concepts of lattice-valued overlap and quasi-overlap functions, and showed the migrativity, homogeneity and other properties of (quasi-) overlap functions on bounded lattices. In this paper, we continue to consider this research topic and study overlap and grouping functions on complete lattices in order to extend the continuity of these two operators from the unit closed interval to the lattices status by using join-preserving and meet-preserving properties of binary operators on complete lattices . More precisely, firstly, we introduce the notion of overlap functions on complete lattices and give two construction methods of them. Secondly, we show some basic properties of overlap functions on complete lattices. In particular, we introduce the concept of ( ∧ , ∨ ) (∧,∨) -combination of overlap functions and extend the notions of migrativity and homogeneity of overlap functions on bounded lattices to the so-called ( α , B , C ) (α,B,C) -migrativity and ( B , C ) (B,C) -homogeneity of overlap functions on complete lattices, respectively, where α α belongs to the complete lattice and B and C are two binary operators on the complete lattice , and then we focus on these properties along with the cancellation law of overlap functions on complete lattices. Finally, we give an analogous discussion for grouping functions on complete lattices.},
  archive      = {J_ISCI},
  author       = {Junsheng Qiao},
  doi          = {10.1016/j.ins.2020.06.075},
  journal      = {Information Sciences},
  pages        = {406-424},
  shortjournal = {Inf. Sci.},
  title        = {Overlap and grouping functions on complete lattices},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy modeling of boiler efficiency in power plants.
<em>ISCI</em>, <em>542</em>, 391–405. (<a
href="https://doi.org/10.1016/j.ins.2020.06.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Boiler efficiency, an important index that participates in adjusting the combustion process in the boiler, usually cannot be evaluated in real time due to the time-consuming detection process of unburned carbon content in fly ash and cinder. In this paper, we adopt a data-driven soft computing method for measuring the boiler efficiency by incorporating offline fuzzy modeling and online operations. The uncertainty and the non-real-time property of the indirect method are analyzed quantitatively and qualitatively. An improved fuzzy rule extraction method is applied in a 600 MW power plant for boiler efficiency evaluation and real-time control.},
  archive      = {J_ISCI},
  author       = {Y.F. Wang and M.X. Wang and Y. Liu and L. Yin and X.R. Zhou and J.F. Xu and X.Y. Zhang},
  doi          = {10.1016/j.ins.2020.06.064},
  journal      = {Information Sciences},
  pages        = {391-405},
  shortjournal = {Inf. Sci.},
  title        = {Fuzzy modeling of boiler efficiency in power plants},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed event-triggered control for multi-agent systems
under intermittently random denial-of-service attacks. <em>ISCI</em>,
<em>542</em>, 380–390. (<a
href="https://doi.org/10.1016/j.ins.2020.06.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the event-triggered consensus problem for multi-agent systems (MASs) under intermittently random denial-of-service (IRDoS) attacks. The IRDoS attack compromises communication networks when the attacker is at active periods. Then, the distributed event-triggered controller is designed to achieve the consensus objective, and each agent’s communications towards neighbors are interrupted by the IRDoS attack with a certain probability when the triggered instants are at active periods of attackers. Furthermore, the sufficient conditions on the attack duration and successful probability , under which the designed control protocol guarantees secure consensus of MASs, are proposed. Finally, the effectiveness of the distributed event-triggered controller under a class of IRDoS attack is illustrated with a numerical example.},
  archive      = {J_ISCI},
  author       = {Tian-Yu Zhang and Dan Ye},
  doi          = {10.1016/j.ins.2020.06.070},
  journal      = {Information Sciences},
  pages        = {380-390},
  shortjournal = {Inf. Sci.},
  title        = {Distributed event-triggered control for multi-agent systems under intermittently random denial-of-service attacks},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficiently mining maximal co-locations in a spatial
continuous field under directed road networks. <em>ISCI</em>,
<em>542</em>, 357–379. (<a
href="https://doi.org/10.1016/j.ins.2020.06.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting useful spatial co-location patterns from urban service facilities can help planners allocate limited resources effectively. These facilities are mostly distributed within man-made spatial fields with road-network constraints. To promote urban-space adaptivity, co-location algorithms for this network circumstance have been designed with distance decay effects and topological relationships of roads. However, these algorithms neglect the traffic direction, which affects the accuracy of the results. Moreover, the efficiency problem is more severe than with the traditional algorithm (i.e., no constraints). To address these problems, we propose an efficient maximal co-location mining algorithm with directed road-network constraints and spatial-continuity consideration (CMDS). To improve the accuracy, we design a network-based prevalence index, combined with both distance decay effects and road direction interference, to measure the significance of a pattern. To promote the execution speed, we use a key-node-separating approach and an improved shortest-path batch task for the co-location mining process. The experiments with both the synthetic and real datasets show that the CMDS algorithm is more efficient and accurate than the state-of-the-art network co-location when applied to problems in an urban space.},
  archive      = {J_ISCI},
  author       = {Xiaojing Yao and Xufeng Jiang and Dacheng Wang and Lina Yang and Ling Peng and Tianhe Chi},
  doi          = {10.1016/j.ins.2020.06.057},
  journal      = {Information Sciences},
  pages        = {357-379},
  shortjournal = {Inf. Sci.},
  title        = {Efficiently mining maximal co-locations in a spatial continuous field under directed road networks},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). HNS: Hierarchical negative sampling for network
representation learning. <em>ISCI</em>, <em>542</em>, 343–356. (<a
href="https://doi.org/10.1016/j.ins.2020.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network representation learning (NRL) aims at modeling network graph by encoding vertices and edges into a low-dimensional space. These learned representations can be used for subsequent applications, such as vertex classification and link prediction. Negative Sampling (NS) is the most widely used method for boosting the performance of NRL. However, most of the existing work only randomly draws negative samples based on vertex frequencies, i.e., the vertices with higher frequency are more likely to be drawn, which ignores the situation that the sampled one may not be a true negative sample, thus, lead to undesirable embeddings. In this paper, we propose a new negative sampling method, called Hierarchical Negative Sampling (HNS), which is able to model the latent structures of vertices and learn the relations among them. During sampling, HNS can draw more appropriate negative samples and thereby obtain better performance on network embeddings. Firstly, we theoretically demonstrate the superiority of HNS over NS. And then we use experimental results to show that our proposed method outperforms the state-of-the-art models on vertex classification tasks at different training scales in real-world networks.},
  archive      = {J_ISCI},
  author       = {Junyang Chen and Zhiguo Gong and Wei Wang and Weiwen Liu},
  doi          = {10.1016/j.ins.2020.07.015},
  journal      = {Information Sciences},
  pages        = {343-356},
  shortjournal = {Inf. Sci.},
  title        = {HNS: Hierarchical negative sampling for network representation learning},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An effective recommendation model based on deep
representation learning. <em>ISCI</em>, <em>542</em>, 324–342. (<a
href="https://doi.org/10.1016/j.ins.2020.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender system has recently attracted a lot of attention in the information service community. Currently, most recommendation models use deep neural networks to learn user preferences for items and make the final recommendations. However, these current models have not effectively captured the deep semantic features of users and items and have not fully used the auxiliary information of the items. This may result in unsatisfactory recommendations for users’ projects. In order to solve the above problem, in this paper, a novel recommendation model called RM-DRL (Recommendation Model based on Deep Representation Learning) was proposed. It mainly consists of two modules: Information Preprocessing and Feature Representation. The former generates the user’s primitive feature vectors and the items used in the latter. The latter consists of two phases: Representation Learning for Item Features (RL-IF) and Representation Learning for User Features (RL-UF). The RL-IF takes the primitive feature vectors of the item as input and uses a multi-layer Convolutional Neural Network (CNN) to learn to accurately produce the semantic feature vector of the item through multi-task learning. In RL-UF, the user primitive feature vectors and semantic feature vectors of the user preference history, and the positive and negative items were taken as input, and a novel Attention-Integrated Gated Recurrent Unit (AIGRU) neural network was proposed to learn to accurately produce user semantic feature vector. After the Feature Representation module converges, the semantic feature vectors of the users and the items can be used to calculate the users’ preferences on the items via vector dot product. Extensive experiments on five real-world datasets show that RM-DRL remarkably outperforms state-of-the-art baselines in solving the recommendation problem.},
  archive      = {J_ISCI},
  author       = {Juan Ni and Zhenhua Huang and Jiujun Cheng and Shangce Gao},
  doi          = {10.1016/j.ins.2020.07.038},
  journal      = {Information Sciences},
  pages        = {324-342},
  shortjournal = {Inf. Sci.},
  title        = {An effective recommendation model based on deep representation learning},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discussing discrete 2-uninorms using lower and upper ordinal
sums. <em>ISCI</em>, <em>542</em>, 317–323. (<a
href="https://doi.org/10.1016/j.ins.2020.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of aggregation functions, called 2-uninorms, was introduced by Akella to bring uninorms and nullnorms into a common framework. In this article, a class of corresponding discrete aggregation operations, called discrete 2-uninorms, is introduced, and the structure of discrete 2-uninorms is described by means of lower and upper ordinal sums .},
  archive      = {J_ISCI},
  author       = {Zhudeng Wang and Wenwen Zong and Yong Su},
  doi          = {10.1016/j.ins.2020.07.027},
  journal      = {Information Sciences},
  pages        = {317-323},
  shortjournal = {Inf. Sci.},
  title        = {Discussing discrete 2-uninorms using lower and upper ordinal sums},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Distributed-ensemble stacked autoencoder model for
non-linear process monitoring. <em>ISCI</em>, <em>542</em>, 302–316. (<a
href="https://doi.org/10.1016/j.ins.2020.06.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining whether a fault occurs locally or globally is highly important for large-scale industrial processes involving multiple operating units. Moreover, the complex non-linearity among process variables is a prominent feature of modern industries. This paper proposes a distributed-ensemble stacked autoencoder (DE-SAE) model based on deep learning technology for monitoring non-linear, large-scale, multi-unit processes. First, the deep features of the variables involved in each operating unit are extracted with the stacked autoencoder (SAE) to represent the essential structure of the unit. Two statistics are separately constructed using the deep features and the reconstruction error for detecting the faults in local units. Subsequently, the deep representations of the variables from each operating unit are modeled with the SAE to extract the global information for global monitoring. The proposed DE-SAE model uses deep learning techniques to solve the complex non-linear relationships in industrial processes, while considering their local and global information. Therefore, the method can explain the monitoring results better. Experimental results obtained from the numerical simulation and Tennessee-Eastman process confirm the feasibility and superiority of this method.},
  archive      = {J_ISCI},
  author       = {Zhichao Li and Li Tian and Qingchao Jiang and Xuefeng Yan},
  doi          = {10.1016/j.ins.2020.06.062},
  journal      = {Information Sciences},
  pages        = {302-316},
  shortjournal = {Inf. Sci.},
  title        = {Distributed-ensemble stacked autoencoder model for non-linear process monitoring},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An artificial moment method for conflict resolutions with
robots being close to their targets. <em>ISCI</em>, <em>542</em>,
286–301. (<a href="https://doi.org/10.1016/j.ins.2020.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An Artificial Moment Method (AMM) is proposed for conflict resolution of swarm robots with path planning tasks, where some robots are in narrow passages and close to their targets while many other robots need to pass through the passages. In the AMM, an algorithm based on key companion candidates and their weight times is presented first for key companions of the robots close to their targets. As such, other robots, even with different motion directions, can bypass the robots in a more reasonable manner. Then, two new algorithms are presented for attractive points and attractive angles of robots or to modify the obtained attractive angles. The existing artificial moment motion controller is also improved. Consequently, the negative effects of robots on each other are decreased, and conflicts between robots can be resolved more easily. Simulations indicate that compared with existing AMMs, the proposed one can yield better solutions in complex situations.},
  archive      = {J_ISCI},
  author       = {Wangbao Xu and Xiaoping Liu and Xuebo Chen and Qiubai Sun},
  doi          = {10.1016/j.ins.2020.06.040},
  journal      = {Information Sciences},
  pages        = {286-301},
  shortjournal = {Inf. Sci.},
  title        = {An artificial moment method for conflict resolutions with robots being close to their targets},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Robust and discriminative zero-watermark scheme based on
invariant features and similarity-based retrieval to protect large-scale
DIBR 3D videos. <em>ISCI</em>, <em>542</em>, 263–285. (<a
href="https://doi.org/10.1016/j.ins.2020.06.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Digital rights management (DRM) of depth-image-based rendering (DIBR) 3D video is an emerging area of research. Existing schemes for DIBR 3D video cause video distortions, are vulnerable to severe signal and geometric attacks, cannot protect 2D frames and depth maps independently, or have difficulty handling large-scale videos. To address these issues, a novel zero-watermark scheme based on invariant features and similarity-based retrieval to protect DIBR 3D video (RZW-SR) is proposed in this study. In RZW-SR, invariant features are extracted to generate master and ownership shares to provide distortion-free, robust and discriminative copyright identification under various attacks. Different from conventional zero-watermark schemes, our proposed scheme stores features and ownership shares correlatively and designs a similarity-based retrieval phase to provide effective solutions for large-scale videos. In addition, flexible mechanisms based on attention-based fusion are designed to protect 2D frames and depth maps, either independently or simultaneously. The experimental results demonstrate that RZW-SR has superior DRM performance compared to existing schemes. First, RZW-SR can obtain the ownership shares relevant to a particular 3D video precisely and reliably for effective copyright identification of large-scale videos. Second, RZW-SR ensures lossless, precise, reliable and flexible copyright identification for 2D frames and depth maps of 3D videos.},
  archive      = {J_ISCI},
  author       = {Xiyao Liu and Yifan Wang and Ziqiang Sun and Lei Wang and Rongchang Zhao and Yuesheng Zhu and Beiji Zou and Yuqian Zhao and Hui Fang},
  doi          = {10.1016/j.ins.2020.06.066},
  journal      = {Information Sciences},
  pages        = {263-285},
  shortjournal = {Inf. Sci.},
  title        = {Robust and discriminative zero-watermark scheme based on invariant features and similarity-based retrieval to protect large-scale DIBR 3D videos},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group consensus via pinning control for a class of
heterogeneous multi-agent systems with input constraints. <em>ISCI</em>,
<em>542</em>, 247–262. (<a
href="https://doi.org/10.1016/j.ins.2020.05.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies group consensus for a class of heterogeneous multi-agent systems (HMASs), where the dynamics of agents are described by single and double integrators. First, under the case that all the agents’ control inputs are bounded and the second-order agents’ velocity information cannot be obtained, we design controllers with a grouping and pinning scheme by introducing an auxiliary function. With the help of Lyapunov theory, it is proved that an HMAS with some pinning agents can achieve group consensus asymptotically under an undirected connected topology and the final states of all agents can converge to the desired consensus values. Furthermore, we investigate group consensus for an HMAS under multiple communication constraints, where the dynamics of the second-order agents are represented by linear and Euler–Lagrange (EL) nonlinear dynamics. Two control protocols and group consensus criteria are also provided to guarantee that the HMAS with or without uncertain parameters can reach group consensus. Finally, two simulation examples illustrate the obtained results.},
  archive      = {J_ISCI},
  author       = {Xiaobo Li and Zhenhua Yu and Zhiwu Li and Naiqi Wu},
  doi          = {10.1016/j.ins.2020.05.085},
  journal      = {Information Sciences},
  pages        = {247-262},
  shortjournal = {Inf. Sci.},
  title        = {Group consensus via pinning control for a class of heterogeneous multi-agent systems with input constraints},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient hierarchical surrogate-assisted differential
evolution for high-dimensional expensive optimization. <em>ISCI</em>,
<em>542</em>, 228–246. (<a
href="https://doi.org/10.1016/j.ins.2020.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Surrogate-assisted evolutionary algorithms have gained increasingly attention due to the promising search capabilities for solving computationally expensive optimization problems . However, when dealing with high-dimensional expensive optimization problems , the effectiveness of surrogate-assisted algorithms deteriorates drastically. In this paper, a novel and efficient hierarchical surrogate-assisted differential evolution (EHSDE) algorithm is proposed towards high-dimensional expensive optimization problems. To balance the exploration and exploitation during the optimization process, EHSDE utilizes a hierarchical framework. In the first phase, the best and the most uncertain offspring are identified respectively. The best offspring is prescreened by a global surrogate model which is built by using a radial basis function network with all the sample points, while the most uncertain offspring is built by the Euclidean distance between offspring and existing sample points. Subsequently, two local surrogate models, which are built by using the most promising sample points and the sample points surrounding the current best solution respectively, are utilized to accelerate the convergence speed. Moreover, experimental studies are conducted on the benchmark functions from 20D to 100D and on an oil reservoir production optimization problem. The results show that the proposed method is effective and efficient for most benchmark functions and for the production optimization problem compared with other state-of-the-art algorithms.},
  archive      = {J_ISCI},
  author       = {Guodong Chen and Yong Li and Kai Zhang and Xiaoming Xue and Jian Wang and Qin Luo and Chuanjin Yao and Jun Yao},
  doi          = {10.1016/j.ins.2020.06.045},
  journal      = {Information Sciences},
  pages        = {228-246},
  shortjournal = {Inf. Sci.},
  title        = {Efficient hierarchical surrogate-assisted differential evolution for high-dimensional expensive optimization},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cy: Chaotic yolo for user intended image encryption and
sharing in social media. <em>ISCI</em>, <em>542</em>, 212–227. (<a
href="https://doi.org/10.1016/j.ins.2020.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media is an inseparable part of our daily life where we post and share photos and media related to our life and in some cases we intend to share them between specific people. This intended and cherry picked sharing of media needs a better solution rather than simply picking users. Some social media platforms do not restrict other users from sharing timeline posts of others; meaning, one can simply forward a post from another person to a third one and no data preservation has been applied. In most cases we do not intend to secure the whole media and only important parts of it are intended to be secured. In this work we propose a novel method based on YoloV3 object detection and chaotic image encryption to overcome the issue of user intended data preservation in social media platforms . Our proposed method is capable of both automatic image encryption on full or user selected regions. Statistical and cryptographic analysis show superiority of our method compared to other state-of-the-art methods while it keeps the speed as high as possible for online and realtime use cases.},
  archive      = {J_ISCI},
  author       = {Meysam Asgari-Chenaghlu and Mohammad-Reza Feizi-Derakhshi and Narjes Nikzad-Khasmakhi and Ali-Reza Feizi-Derakhshi and Majid Ramezani and Zoleikha Jahanbakhsh-Nagadeh and Taymaz Rahkar-Farshi and Elnaz Zafarani-Moattar and Mehrdad Ranjbar-Khadivi and Mohammad-Ali Balafar},
  doi          = {10.1016/j.ins.2020.07.007},
  journal      = {Information Sciences},
  pages        = {212-227},
  shortjournal = {Inf. Sci.},
  title        = {Cy: Chaotic yolo for user intended image encryption and sharing in social media},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FaultFace: Deep convolutional generative adversarial network
(DCGAN) based ball-bearing failure detection method. <em>ISCI</em>,
<em>542</em>, 195–211. (<a
href="https://doi.org/10.1016/j.ins.2020.06.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure detection is employed in the industry to improve system performance and reduce costs due to unexpected malfunction events. So, a good dataset of the system is desirable for designing an automated failure detection system . However, industrial process datasets are unbalanced and contain little information about failure behavior due to the uniqueness of these events and the high cost for running the system just to get information about the undesired behaviors . For this reason, performing correct training and validation of automated failure detection methods is challenging. This paper proposes a methodology called FaultFace for failure detection on Ball-Bearing joints for rotational shafts using deep learning techniques to create balanced datasets. The FaultFace methodology uses 2D representations of vibration signals denominated faceportraits obtained by time–frequency transformation techniques. From the obtained faceportraits, a Deep Convolutional Generative Adversarial Network is employed to produce new faceportraits of the nominal and failure behaviors to get a balanced dataset. A Convolutional Neural Network is trained for fault detection employing the balanced dataset. The FaultFace methodology is compared with other deep learning techniques to evaluate its performance in for fault detection with unbalanced datasets. Obtained results show that FaultFace methodology has a good performance for failure detection for unbalanced datasets.},
  archive      = {J_ISCI},
  author       = {Jairo Viola and YangQuan Chen and Jing Wang},
  doi          = {10.1016/j.ins.2020.06.060},
  journal      = {Information Sciences},
  pages        = {195-211},
  shortjournal = {Inf. Sci.},
  title        = {FaultFace: Deep convolutional generative adversarial network (DCGAN) based ball-bearing failure detection method},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel binary differential evolution algorithm for knapsack
problems. <em>ISCI</em>, <em>542</em>, 177–194. (<a
href="https://doi.org/10.1016/j.ins.2020.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The capability of the conventional differential evolution algorithm to solve optimization problems in continuous spaces has been well demonstrated and documented in the literature. However, differential evolution has been commonly considered inapplicable for several binary/permutation-based real-world problems because of its arithmetic reproduction operator. Moreover, many limitations of the standard differential evolution algorithm, such as slow convergence and becoming trapped in local optima, have been defined. In this paper, a novel technique which makes a simple differential evolution algorithm suitable and very effective for solving binary-based problems, such as binary knapsack ones, is proposed. It incorporates new components, such as representations of solutions, a mapping method and a diversity technique. Also, a new efficient fitness evaluation approach for calculating and, at the same time, repairing knapsack candidate solutions, is introduced. To assess the performance of this new algorithm, four datasets with a total of 44 instances of binary knapsack problems are considered. Its performance and those of 22 state-of-the-art algorithms are compared, with the experimental results demonstrating its superiority in terms of both the quality of solutions and computational times. It is also capable of finding new solutions which are better than the current best ones for five large knapsack problems.},
  archive      = {J_ISCI},
  author       = {Ismail M. Ali and Daryl Essam and Kathryn Kasmarik},
  doi          = {10.1016/j.ins.2020.07.013},
  journal      = {Information Sciences},
  pages        = {177-194},
  shortjournal = {Inf. Sci.},
  title        = {Novel binary differential evolution algorithm for knapsack problems},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian personalized ranking based on multiple-layer
neighborhoods. <em>ISCI</em>, <em>542</em>, 156–176. (<a
href="https://doi.org/10.1016/j.ins.2020.06.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are widely used on the Internet as tools for data analysis, processing and discovery. Traditional recommendation algorithms mostly exploit rating information in a simple way while ignoring some hidden information in ratings, thus restricting recommendation performance. This hidden information in ratings, such as similarities between rated items and items unrated by the same user, can unveil the relationships between users and items by using multiple layers to help find the preferences of users. To focus on this hidden information, we propose a new Bayesian Personalized Ranking algorithm based on multiple-layer neighborhoods (BPRN). We divide items into different sets based on the analysis of user-item relevance and give an order for the sets. Then, we use BPRN to obtain the fine-grained order of items in different sets and finally generate a personalized, sorted list for each user. We have used five real-world datasets to test the accuracy of BPRN and compare its performance with state-of-the-art models. Experiments show that our algorithm greatly improves the accuracy of the recommendation results. In addition, our algorithm distinctly alleviates the problems of data sparsity and cold-start users.},
  archive      = {J_ISCI},
  author       = {Yutian Hu and Fei Xiong and Shirui Pan and Xi Xiong and Liang Wang and Hongshu Chen},
  doi          = {10.1016/j.ins.2020.06.067},
  journal      = {Information Sciences},
  pages        = {156-176},
  shortjournal = {Inf. Sci.},
  title        = {Bayesian personalized ranking based on multiple-layer neighborhoods},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Callback2Vec: Callback-aware hierarchical embedding for
mobile application. <em>ISCI</em>, <em>542</em>, 131–155. (<a
href="https://doi.org/10.1016/j.ins.2020.06.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although numerous embedding approaches have been proposed for code representation of mobile applications, insufficient attention has been paid to its essential running nature: event-driven . As a result, the contextual semantics of event-driven callbacks re hardly captured. Existing solutions either discard the information of event callbacks such as their sequences, or simply treat event callbacks as ordinary APIs. Both of the solutions deviate from the actual running behavior of the applications and thus suffer from critical information loss of the callback contexts. To address the problem, in this paper, a callback based hierarchical embedding approach Callback2Vec is proposed, in which ordinary APIs and callbacks are distinguished and tackled at different levels in a top-down fashion. As such, the contextual semantics of callbacks can be reasonably represented by the embedding vectors. In particular, a fine-grained callback-sequence-generation algorithm is devised to capture the running behavior of callbacks. To evaluate the representation capability of Callback2Vec, a systematic analysis targeting at the embedding results is conducted, whereby the conventional embedding characteristics are rigorously investigated and new implications are identified. Of significance, the proposed embedding approach has been validated to be capable of providing novel solutions for typical downstream applications, through comprehensive experiments with large scale public datasets.},
  archive      = {J_ISCI},
  author       = {Chenkai Guo and Dengrong Huang and Naipeng Dong and Jianwen Zhang and Jing Xu},
  doi          = {10.1016/j.ins.2020.06.058},
  journal      = {Information Sciences},
  pages        = {131-155},
  shortjournal = {Inf. Sci.},
  title        = {Callback2Vec: Callback-aware hierarchical embedding for mobile application},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A privacy-preserving public integrity check scheme for
outsourced EHRs. <em>ISCI</em>, <em>542</em>, 112–130. (<a
href="https://doi.org/10.1016/j.ins.2020.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud storage as an emerging technology has already drawn people’s attention and hospitals and medical institutions increasingly begin to outsource their huge electronic health records (EHRs) to cloud. Since EHRs always involve lots of sensitive privacy, it is necessary to protect the confidentiality and privacy of EHRs. Meanwhile, existing works do not consider that combining classified storage with special data structures to improve the efficiency of integrity check for outsourced EHRs. In this paper, we propose an efficient integrity check scheme for classified EHRs. First, our scheme not only protects the privacy of category information for EHRs, but also ensures the EHRs themselves. Second, we improve the performance of lookup and data updating dramatically by deploying adjustable-capacity cuckoo filter with a linked list, which is a container storing the EHRs’ ciphertexts and verification metadata. Third, we implement our scheme in a more practical way by extending batch auditing of EHRs from single category to multi-category. The provable update for the cloud service provider and the third-party auditor after updating EHRs is also guaranteed. Finally, the security of our scheme is proven, and numerical analyses and simulation experiments show that our scheme is efficient.},
  archive      = {J_ISCI},
  author       = {Yuan Su and Yanping Li and Kai Zhang and Bo Yang},
  doi          = {10.1016/j.ins.2020.06.043},
  journal      = {Information Sciences},
  pages        = {112-130},
  shortjournal = {Inf. Sci.},
  title        = {A privacy-preserving public integrity check scheme for outsourced EHRs},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RCSMOTE: Range-controlled synthetic minority over-sampling
technique for handling the class imbalance problem. <em>ISCI</em>,
<em>542</em>, 92–111. (<a
href="https://doi.org/10.1016/j.ins.2020.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Synthetic Minority Over-Sampling Technique (SMOTE) is one of the most well known methods to solve the unequal class distribution problem in imbalanced datasets. However, it has three shortcomings: 1) it may cause the over-generalization problem due to over-sampling of noisy samples, 2) over-sampling of uninformative samples, and 3) increasing the overlaps between different classes around the class boundaries. In this research, an improved SMOTE-based method, namely Range-Controlled SMOTE (RCSMOTE), which targets all three problems simultaneously, is proposed. In order to cope with the two first problems, a sample categorization scheme is applied to identify the minor samples that are proper for over-sampling. In order to mitigate the third problem, an improved sample generation process is proposed which generates the synthetic samples considering an accurately calculated safe range. This range is calculated based on the characteristics of the input data in order to provide us a safe over-sampling region for each dimension in the feature space. The extracted range is used to control the location of the new synthetic samples in data space and prevents the penetration of them into the majority class regions. Experiments conducted on various datasets, confirm that the RCSMOTE overcomes the above-mentioned problems of SMOTE.},
  archive      = {J_ISCI},
  author       = {Paria Soltanzadeh and Mahdi Hashemzadeh},
  doi          = {10.1016/j.ins.2020.07.014},
  journal      = {Information Sciences},
  pages        = {92-111},
  shortjournal = {Inf. Sci.},
  title        = {RCSMOTE: Range-controlled synthetic minority over-sampling technique for handling the class imbalance problem},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered predictive control for networked control
systems with DoS attacks. <em>ISCI</em>, <em>542</em>, 71–91. (<a
href="https://doi.org/10.1016/j.ins.2020.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new model-based event-triggered predictive control (MB-ETPC) protocol to stabilize networked control systems (NCSs) subject to denial-of-service (DoS) attacks. Firstly, we introduce two kinds of DoS attack models, which are applied to sensor-to-controller and controller-to-actuator communication channels, then we give the corresponding schemes according to the different DoS attacks. Secondly, on the premise of ensuring the stability of NCSs, the mechanism can not only reduce the pressure of network bandwidth , but also can effectively compensate for the negative impact of DoS attacks on system performance. Next, considering the existence of DoS attacks and communication delays, we construct a closed-loop system model, which combines the model-based network control systems, the predictive control scheme and the event-triggered control (ETC) scheme all together. Based on the model, the sufficient condition of NCSs stability is given in the form of linear matrix inequalities (LMIs) by using Lyapunov theory method. Finally, two illustrative simulation examples are presented to demonstrate the effectiveness of the proposed method.},
  archive      = {J_ISCI},
  author       = {Yurou Deng and Xiuxia Yin and Songlin Hu},
  doi          = {10.1016/j.ins.2020.07.004},
  journal      = {Information Sciences},
  pages        = {71-91},
  shortjournal = {Inf. Sci.},
  title        = {Event-triggered predictive control for networked control systems with DoS attacks},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Describing hierarchy of concept lattice by using matrix.
<em>ISCI</em>, <em>542</em>, 58–70. (<a
href="https://doi.org/10.1016/j.ins.2020.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Concept lattices (also called Galois lattices) are complete ones with the hierarchical order relation of the formal concepts defined by a formal context or Galois connection. In this paper, we present a new of method describing a hierarchy of a finite concept lattice by using a matrix. Given a finite concept lattice L , we introduce Scott topology σ ( L ) on L and choose an order of a unique minimal base for σ ( L ). Then, there is a one-to-one correspondence between the finite topological space ( L , σ ( L )) and a proper square matrix with integral entries; thus we obtain a hierarchy-matrix describing the hierarchy of the concept lattice. We explain how to get the information of the hierarchy from the hierarchy-matrix and discuss the relation between the hierarchy-matrix and the Hasse diagram . Since the hierarchy-matrix allowed us to store the information of hierarchy of the concept lattice, we believe that any software autonomously understand the information of hierarchy of the concepts from the hierarchy-matrix.},
  archive      = {J_ISCI},
  author       = {Chol Hong Pak and Jin Hong Kim and Myong Guk Jong},
  doi          = {10.1016/j.ins.2020.05.020},
  journal      = {Information Sciences},
  pages        = {58-70},
  shortjournal = {Inf. Sci.},
  title        = {Describing hierarchy of concept lattice by using matrix},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). K-mnv-rep: A k-type clustering algorithm for matrix-object
data. <em>ISCI</em>, <em>542</em>, 40–57. (<a
href="https://doi.org/10.1016/j.ins.2020.06.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In matrix-object data, an object (or a sample) is described by more than one feature vector (record) and all of those feature vectors are responsible for the observed classification of the object. A task for matrix-object data is to cluster it into a set of groups by analyzing and utilizing the information of feature vectors. Matrix-object data are widespread in many real applications. Previous studies typically address data sets that an object is generally represented by a feature vector, which may be violated in many real-world tasks. In this paper, we propose a k -multi-numeric-values-representatives (abbr. k -Mnv-Rep) algorithm to cluster numeric matrix-object data. In this algorithm, a new dissimilarity measure between two numeric matrix-objects is defined and a new heuristic method of updating cluster centers is given. Furthermore, we also propose a k -multi-values-representatives (abbr. k -Mv-Rep) algorithm to cluster hybrid matrix-object data. The two proposed algorithms break the limitations of the previous studies, and can be applied to address matrix-object data sets that exist widely in many real-world tasks. The benefits and effectiveness of the two algorithms are shown by some experiments on real and synthetic data sets.},
  archive      = {J_ISCI},
  author       = {Liqin Yu and Fuyuan Cao and Xiao-Zhi Gao and Jing Liu and Jiye Liang},
  doi          = {10.1016/j.ins.2020.06.071},
  journal      = {Information Sciences},
  pages        = {40-57},
  shortjournal = {Inf. Sci.},
  title        = {K-mnv-rep: A k-type clustering algorithm for matrix-object data},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Extreme clustering – a clustering method via density
extreme points. <em>ISCI</em>, <em>542</em>, 24–39. (<a
href="https://doi.org/10.1016/j.ins.2020.06.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peak clustering, a density based clustering method , has shown remarkable performance in clustering analysis of data . In reality, peak clustering suffers from two major drawbacks: (i) when the difference in cluster sample density is significant, it becomes difficult for peak clustering to find cluster centres in low density clusters. (ii) in some cases, it will incorrectly detect many normal points as noises. In this paper, we propose a new extreme clustering method to overcome the drawbacks of peak clustering. The theme of extreme clustering is to identify density extreme points to find cluster centres. In addition, a noise detection module is also introduced to identify noisy data points from the clustering results . As a result, the extreme clustering is robust to datasets with different density distributions. Experiments and validations, on over 40 datasets, show that extreme clustering can not only inherit the cluster validity of peak clustering, but also overcome its shortages with significant performance gain. Case studies on real-world haze analysis also demonstrate the performance of extreme clustering method in finding some main haze origins in a Chinese city.},
  archive      = {J_ISCI},
  author       = {Shuliang Wang and Qi Li and Chuanfeng Zhao and Xingquan Zhu and Hanning Yuan and Tianru Dai},
  doi          = {10.1016/j.ins.2020.06.069},
  journal      = {Information Sciences},
  pages        = {24-39},
  shortjournal = {Inf. Sci.},
  title        = {Extreme clustering – a clustering method via density extreme points},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential dynamic event recommendation in event-based
social networks: An upper confidence bound approach. <em>ISCI</em>,
<em>542</em>, 1–23. (<a
href="https://doi.org/10.1016/j.ins.2020.06.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there have been some platforms that have focused on recommending commodities or events to users using event-based social networks (EBSNs). Some studies have attempted to find the optimal recommendation sequence of these items, assuming that the sequence stops once the user accepts one recommendation or the item list runs out. However, in reality, social media platforms will not stop recommending different commodities or social events to users until the user becomes bored and abandons the platform. Since it is 5 to 25 times more difficult to attract a new user than to retain an old one, 1 it would be helpful if the platform could determine when to stop making recommendations. In this work, we investigate the problem of sequential dynamic event recommendation with feedback (SDERF), where the platform continues recommending events even when the user has accepted one that is satisfactory. We first model the SDERF problem and provide two variants, namely, an online learning model with/without contextual information. Then, we apply an upper confidence bound (UCB) approach with an expected regret polynomial in the number of events and rounds. Finally, we evaluate the performance of our proposed algorithms using both real and synthetic datasets .},
  archive      = {J_ISCI},
  author       = {Yuan Liang and Chunlin Huang and Xiuguo Bao and Ke Xu},
  doi          = {10.1016/j.ins.2020.06.047},
  journal      = {Information Sciences},
  pages        = {1-23},
  shortjournal = {Inf. Sci.},
  title        = {Sequential dynamic event recommendation in event-based social networks: An upper confidence bound approach},
  volume       = {542},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
