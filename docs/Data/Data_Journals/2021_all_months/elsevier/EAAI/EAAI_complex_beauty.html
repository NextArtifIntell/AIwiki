<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>EAAI_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="eaai---362">EAAI - 362</h2>
<ul>
<li><details>
<summary>
(2021). Deep stackelberg heuristic dynamic programming for frequency
regulation of interconnected power systems considering flexible energy
sources. <em>EAAI</em>, <em>106</em>, 104508. (<a
href="https://doi.org/10.1016/j.engappai.2021.104508">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flexible energy sources (FESs) could refuse to execute the generation commands (GCs) if the benefits fell short of their expectations when applying traditional automatic generation control methods, this problem leads to frequency instability and the waste of scheduling resources. Accordingly, a deep Stackelberg heuristic dynamic programming (DSHDP) is proposed for the frequency regulation and power dispatch of smart generation control (SGC). Firstly, the heuristic deep dynamic programming, whose networks are replaced by three deep neural networks, can be trained offline by historical data to fit the optimal performance index. Then, the GCs can be optimized through an online updating strategy for stabilizing the frequency of interconnected power systems. To maximize the benefits of FESs further, an improved SGC framework based on the Stackelberg game is built to let FESs play games with conventional power plants in a fair environment. Finally, the optimal GCs can be distributed by the Nash equilibrium to obtain higher profits than traditional methods, and the control accuracy is increased indirectly. Two cases, i.e., IEEE two-area power system and six-area power system based on China Southern Power Grid (CSPG), are provided to verify the superiority of the DSHDP. The results indicate that the excellent flexibility and stability of the proposed algorithm in complex power systems containing renewable energy and FESs. Totally, the frequency deviation obtained by DSHDP is reduced by up to 59.38%, while the total profit of FESs rises by up to 67.47% when compared with the other seven representative algorithms.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Yunzhi Wu},
  doi          = {10.1016/j.engappai.2021.104508},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104508},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep stackelberg heuristic dynamic programming for frequency regulation of interconnected power systems considering flexible energy sources},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wavelet frequency tensor applied to temporary environments
in discrete spaces to obtain mobility patterns. Use case in the
detection of routes in a territory. <em>EAAI</em>, <em>106</em>, 104507.
(<a href="https://doi.org/10.1016/j.engappai.2021.104507">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of frequency tensors for the representation of discrete time series information through wavelet transformations offers a methodology that allows the application of classification methods that result in the detection of mobility patterns in a geographical area. The use case focuses on a territory from which the geolocation of anonymized mobile device identifiers is extracted to aggregate its frequencies in order to ensure personal privacy. Furthermore, the kind of datasets we used in our study were treated with other methods to ensure that the identifiers for a same user change over time. Nowadays, this form of data treatment is implemented using a continuous process in smartcity platforms, first by anonymizing and second by changing the seed of the encryption method. Where the suggested technique is applied, a cluster analysis is performed, by which subsets or routes of the movements between the different points studied are obtained.},
  archive      = {J_EAAI},
  author       = {Dani Marchuet and Javi Palanca and Vicent Botti},
  doi          = {10.1016/j.engappai.2021.104507},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104507},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wavelet frequency tensor applied to temporary environments in discrete spaces to obtain mobility patterns. use case in the detection of routes in a territory},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Failure mode and effect analysis: A three-way decision
approach. <em>EAAI</em>, <em>106</em>, 104505. (<a
href="https://doi.org/10.1016/j.engappai.2021.104505">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Failure mode and effect analysis (FMEA), as a powerful and effective risk assessment tool in reliability and safety analysis, has been extensively applied in different fields to enhance the reliability of a system. However, the traditional FMEA method has exposed some significant defects in practical applications. Furthermore, the risk ranking of failure modes is not convenient for subsequent maintenance strategies, and the interactions between risk criteria are not considered in most multiple criteria decision making (MCDM)-based methods. In this paper, we construct a novel FMEA model based on criteria importance through the inter-criteria correlation (CRITIC) method and three-way decisions to improve the performance of the conventional FMEA method and aid making a maintenance plan. Firstly, we introduce the decision-theoretic rough sets (DTRSs) into an interval 2-tuple linguistic (I2TL) environment to define interval 2-tuple linguistic decision-theoretic rough sets (I2TLDTRSs). Secondly, the CRITIC method is employed to calculate the weight of risk criteria. Thirdly, the conditional probability is obtained by a similarity-based method with the help of the ideas of the TOPSIS approach, and a relative loss function is designed by introducing risk avoidance coefficient. Fourthly, the classification of failure modes is derived according to the three-way decision rules. Finally, two numerical examples of the train door system are given to verify the effectiveness and practicality of the presented model. The presented model both extends the theory and application of three-way decisions and provides a solution beneficial for making a maintenance strategy to reduce the risk of failure modes.},
  archive      = {J_EAAI},
  author       = {Jiang-Hong Zhu and Zhen-Song Chen and Bin Shuai and Witold Pedrycz and Kwai-Sang Chin and Luis Martínez},
  doi          = {10.1016/j.engappai.2021.104505},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104505},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Failure mode and effect analysis: A three-way decision approach},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning applications in power system fault
diagnosis: Research advancements and perspectives. <em>EAAI</em>,
<em>106</em>, 104504. (<a
href="https://doi.org/10.1016/j.engappai.2021.104504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Newer generation sources and loads are posing new challenges to the conventional power system protection schemes. Adaptive and intelligent protection methodology, based on advanced measurement techniques and intelligent fault diagnosis such as machine learning (ML), is found to be useful to meet these challenges. A large number of research works are reported on ML-based power system fault diagnosis. However, ML techniques are evolving at a very fast pace, and an inclusive, as well as state-of-the-art review on ML-based power system fault diagnosis, is not available in the literature. Given this need and growing trend towards ML, the study presented in this paper aims to provide a comprehensive review of ML-based power system fault diagnosis. At first, efforts have been made to enlist the issues present in conventional fault diagnosis which led to the popularity of ML techniques. Also, a baseline framework and workflow for ML-based fault diagnosis are presented. Next, various unsupervised and supervised learning techniques have been discussed separately which have been used by several researchers for fault diagnosis. The discussion throughout is supported with tabulated facts for fault detection, classification and localization works with techniques used, different simulation tools used, and their application system. The advantages and disadvantages of all the techniques of fault diagnosis have also been discussed which will help the readers in the selection of techniques for their research. A brief review of reinforcement learning and transfer learning is also given as they are gaining popularity in power system-related studies and have the potential to be used for fault diagnosis. Finally, the research trends, some key issues, and directions for future research have been highlighted.},
  archive      = {J_EAAI},
  author       = {Rachna Vaish and U.D. Dwivedi and Saurabh Tewari and S.M. Tripathi},
  doi          = {10.1016/j.engappai.2021.104504},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104504},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Machine learning applications in power system fault diagnosis: Research advancements and perspectives},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An effective hybrid meta-heuristic for flexible flow shop
scheduling with limited buffers and step-deteriorating jobs.
<em>EAAI</em>, <em>106</em>, 104503. (<a
href="https://doi.org/10.1016/j.engappai.2021.104503">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses a flexible flow shop scheduling problem considering limited buffers and step-deteriorating jobs, where there are multiple non-identical parallel machines. A mixed integer programming model is proposed, with the criterion of minimizing the makespan and total tardiness simultaneously. To handle this problem, an effective hybrid meta-heuristic algorithm, named GVNSA, is developed based on genetic algorithm (GA), variable neighborhood search (VNS) and simulated annealing (SA). In the algorithm, with a two-dimensional matrix encoding scheme, the NEH (Nawaz–Enscore–Ham) heuristic and bottleneck elimination method are implemented to determine the initial population. A three-level rolling translation approach is designed for decoding. To balance the exploration and exploitation abilities, three effective steps are executed: 1) partial matching crossover and mutation strategy based on multiple neighborhood search structures are imposed on the GA operators; 2) a VNS with SA is introduced to re-optimize some individuals from GA, where four neighborhood structures are constructed; 3) a modified CDS (Campbell–Dudek–Smith) heuristic is embedded to disturb population in the mid-iteration. Numerical experiments are carried out on test problems with different scales. Computational results demonstrate that the proposed GVNSA can obtain higher quality solutions in comparison with other heuristics and meta-heuristics existing in literature.},
  archive      = {J_EAAI},
  author       = {Qian-Qian Zheng and Yu Zhang and Hong-Wei Tian and Li-Jun He},
  doi          = {10.1016/j.engappai.2021.104503},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104503},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective hybrid meta-heuristic for flexible flow shop scheduling with limited buffers and step-deteriorating jobs},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Natural gas consumption behavior of companies by clustering
analysis. <em>EAAI</em>, <em>106</em>, 104502. (<a
href="https://doi.org/10.1016/j.engappai.2021.104502">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have still consumed natural gas as a restricted source of energy in our daily life. Moreover, the consumption of natural gas energy will continue to increase by the year. Although many studies have focused on electrical energy consumption, natural gas is another significant energy source that can be examined. Since companies consume much more gas, their gas consumption data are examined in this study. The study contributes to the literature by applying intuitionistic fuzzy c-means (IFCM) methodology to the natural gas industry. The main motivation and advantage of the methodology is two-fold. Because of its fuzziness, one data point can be assigned into more than one cluster, similar to real-world cases. Because of its intuitionistic side, it considers membership, non-membership and hesitant degrees. These two strengths of IFCM improves the clustering accuracy. IFCM clustering was used to arrange the companies with respect to the consumption amount to increase the understandability because 1049 companies’ consumption data were collected. A calendar view was developed to visualize the consumption amounts in the clusters. The changes in consumption amounts were presented in different weather temperatures. Whereas some clustered companies were directly affected by temperature changes, others were not affected. The companies in the clusters were analyzed with respect to two main criteria: regularity and complexity. The findings showed while high levels in routine are related to manufacturing companies, high complexity level is an indicator of being active in the service industry.},
  archive      = {J_EAAI},
  author       = {Onur Dogan},
  doi          = {10.1016/j.engappai.2021.104502},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104502},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Natural gas consumption behavior of companies by clustering analysis},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DTaxa: An actor–critic for automatic taxonomy induction.
<em>EAAI</em>, <em>106</em>, 104501. (<a
href="https://doi.org/10.1016/j.engappai.2021.104501">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic taxonomy induction is a challenging task in the field of natural language understanding (NLU) and information retrieval (IR) because it requires machine learning and understanding the is-a relation (i.e. hypernym relation) between term pairs. Therefore, the deep taxa (DTaxa) based on the actor–critic algorithm framework is designed to deal with the aforementioned problems in this paper. The agent in the DTaxa regards the taxonomy induction process as the sequential decision steps so that the agent can take the operation of a term as an action via the policy network to jointly optimize hypernym detection and hypernym organization. Meanwhile, the DTaxa obtains a stable performance from the experiences buffered in the memory. In order to verify the effectiveness of the DTaxa for the automatic taxonomy induction, two experiments are performed on the all bottomed-out full subtrees extracted from WordNet 3.0 and the English environment and science taxonomies in the SemEval-2016 task 13, respectively. The proposed method outperforms these existing methods and achieves state-of-the-art among most metrics.},
  archive      = {J_EAAI},
  author       = {Yongming Han and Yanwei Lang and Minjie Cheng and Zhiqiang Geng and Guofei Chen and Tao Xia},
  doi          = {10.1016/j.engappai.2021.104501},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104501},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {DTaxa: An actor–critic for automatic taxonomy induction},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emergency fault affected wide-area automatic generation
control via large-scale deep reinforcement learning. <em>EAAI</em>,
<em>106</em>, 104500. (<a
href="https://doi.org/10.1016/j.engappai.2021.104500">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When a complex large power system is in an emergency, the conventional discrete emergency control strategy implemented will cause excess load or derivative accidents like line power overload, thereby raising the operation risk. To overcome the problems of excessive/insufficient regulation and subsequent accidents in the above context, this paper proposes a wide area automatic generation control (WA-AGC) framework, which integrates the emergency control strategy and a performance-based frequency regulation market mechanism. According to the frequency status of the power system, WA-AGC divides the AGC into four intervals, emergency AGC (EAGC), conventional AGC (CAGC), AGC transition and optimal power flow (OPF). These four together realize a comprehensive optimization of frequency and system stability as well as economy Based on the above framework, a swarm agent exploration distributed multiple delayed deep policy gradient algorithm (SAE-MD3) is developed, which uses multiple explorers with different exploration strategies for distributed optimization. In addition, several technologies are introduced to prevent Q value overestimation and generate a more robust optimal AGC strategy. Afterward, the effectiveness and feasibility of WA-AGC are verified through the simulations of an IEEE-9 two-area system and an IEEE-118 two-area system. Compared to conventional AGC strategies, the WA-AGC algorithm reduces the constraint violation time of the power line by 92.06% and the power generation cost by 0.27% as well as improves the CPS1 index by 0.04%.},
  archive      = {J_EAAI},
  author       = {Jiawen Li and Tao Yu and Xiaoshun Zhang},
  doi          = {10.1016/j.engappai.2021.104500},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104500},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emergency fault affected wide-area automatic generation control via large-scale deep reinforcement learning},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple graph regularized semi-supervised nonnegative
matrix factorization with adaptive weights for clustering.
<em>EAAI</em>, <em>106</em>, 104499. (<a
href="https://doi.org/10.1016/j.engappai.2021.104499">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional multiple graph regularized nonnegative matrix factorization (NMF) techniques have shown good performance in image clustering applications. However, existing multiple graph regularized NMF methods are unsupervised learning methods which fail to take full advantage of priori information. To solve this issue, this paper develops a novel multiple graph regularized NMF method, namely the multiple graph regularized semi-supervised NMF with adaptive weights (MSNMF), to capture the discriminative data representation. Specifically, the MSNMF method combines the limited supervised information in the form of pairwise constraints, into multiple graph regularization, and propagates the pairwise constraints from the constrained data samples to the unconstrained data samples. Moreover, convergence, connection with the gradient descent method, and computational cost of the proposed method are studied. The relationships between MSNMF and some typical NMF methods are also discussed. Experimental results on eight practical image datasets have shown that the MSNMF method can obtain better clustering results than several related NMF methods.},
  archive      = {J_EAAI},
  author       = {Kexin Zhang and Xuezhuan Zhao and Siyuan Peng},
  doi          = {10.1016/j.engappai.2021.104499},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104499},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple graph regularized semi-supervised nonnegative matrix factorization with adaptive weights for clustering},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel domain adaptive deep recurrent network for
multivariate time series prediction. <em>EAAI</em>, <em>106</em>,
104498. (<a
href="https://doi.org/10.1016/j.engappai.2021.104498">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series prediction has attracted growing interest in many research fields. Recently, deep learning has been applied to multivariate time series prediction and has achieved encouraging results. However, in real-world scenarios, the insufficient data of multivariate time series at the beginning of the observation causes the deep learning model unable to exert its expected performance. Furthermore, there is the distribution discrepancy between different multivariate time series caused by many factors, making it unfeasible to reuse existing data or models directly. Therefore, a novel Domain Adaptive Deep Recurrent Network (DADRN) is proposed for multivariate time series prediction with insufficient data, which transferring the knowledge of the target-related time series (source domain) to the target time series (target domain) by minimizing distribution mismatch in the feature sharing space. The DADRN automatically learns the temporal dependence of predictive time series and the dynamic dependencies between multiple time variables through the deep recurrent neural network. Besides, a special transfer learning method, domain adaptation, is embedded in the constructed deep recurrent network to reduce the distribution discrepancy between different domains. The proposed domain independence strategy and domain weighted loss further enhance the DADRN’s transfer learning capability by improving the distribution estimation of the target domain and balancing the network’s learning on two domains. The reasonable combination of deep recurrent network and domain adaptation endows DADRN with favorable transfer learning capability, and its effectiveness is demonstrated by the experimental results on two real-world datasets.},
  archive      = {J_EAAI},
  author       = {Tao Yang and Xia Yu and Ning Ma and Yuhang Zhao and Hongru Li},
  doi          = {10.1016/j.engappai.2021.104498},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104498},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel domain adaptive deep recurrent network for multivariate time series prediction},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel virtual sample generation using conditional GAN for
developing soft sensor with small data. <em>EAAI</em>, <em>106</em>,
104497. (<a
href="https://doi.org/10.1016/j.engappai.2021.104497">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In terms of data-driven soft sensing modeling of industrial processes, it is practically necessary to collect sufficient process data. Unfortunately, sometimes only few samples are available as a result of physical restrictions and time costs, resulting in insufficient data and incomplete data representative. It is increasingly important and urgent to deal with the small data problem in developing soft sensors. To handle those practical issues, a new virtual sample generation approach based on conditional generative adversarial network (CGAN-VSG) is proposed. In the proposed CGAN-VSG approach, the local outlier factor (LOF) is first integrated with the K-means++ algorithm to find the scarcity regions of small data along output space. Secondly, a couple of output samples of interest that match the overall output trend are generated to fill up the scarcity regions. Third, CGAN is utilized to produce corresponding input samples with those generated output samples of interest. Finally, lots of virtual inputs and outputs are obtained to enhance the accuracy of data-driven soft sensor with small data. To validate the superior of the proposed CGAN-VSG approach, standard functions are firstly selected to investigate into the quality of generated input and output virtual samples. In addition, a real-world application of a cascade reaction process named high-density polyethylene (HDPE) is carried out. Simulation results suggest that the presented CGAN-VSG approach is superior to several other state-of-the-art methods, such as TTD, MTD and bootstrap, in the term of accuracy.},
  archive      = {J_EAAI},
  author       = {Qun-Xiong Zhu and Kun-Rui Hou and Zhong-Sheng Chen and Zi-Shu Gao and Yuan Xu and Yan-Lin He},
  doi          = {10.1016/j.engappai.2021.104497},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104497},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Novel virtual sample generation using conditional GAN for developing soft sensor with small data},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approach combining a new weight initialization method and
constructive algorithm to configure a single feedforward neural network
for multi-class classification. <em>EAAI</em>, <em>106</em>, 104495. (<a
href="https://doi.org/10.1016/j.engappai.2021.104495">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new method for initializing weights in a Feedforward Neural Network (FNN) with a single hidden layer combined with a constructive approach to define the number of hidden units associated with the best classification performance. The strategy consists of defining an initial number of hidden units according to the classification problem, the linearization of the whole network around an equilibrium point and the determination of the initial weights and bias through the maximum approximation of the linearized model to the Optimal Linear Classifier (OLC) whose solution can be obtained analytically. The constructive algorithm comprises a gradual increase in the number of hidden units in such a way that at each training only the weights and bias associated with the new hidden units are initiated randomly while the weights and bias obtained from previous training are used as initial guesses. Additionally, the constructive algorithm seeks to ensure that the loss function of the trained networks decreases with the successive additions of hidden units. The proposed approach (Weight Initialization based on the Linearization of the Whole Neural Network combined with a new Constructive Algorithm, WILWNN-CA) is applied to synthetic and real datasets widely used as benchmark for multi-class classification problems. The comparison with conventional random weight initialization and other approaches involving different network topologies (and initialization strategies) shows that the proposed method is efficient and capable of providing success rates (correct classification rates) higher or similar to those achieved with existing methods.},
  archive      = {J_EAAI},
  author       = {Cristiano Hora Fontes and Marcelo Embiruçu},
  doi          = {10.1016/j.engappai.2021.104495},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104495},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An approach combining a new weight initialization method and constructive algorithm to configure a single feedforward neural network for multi-class classification},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A synchronized heterogeneous autoencoder with feature-level
and label-level knowledge distillation for the recommendation.
<em>EAAI</em>, <em>106</em>, 104494. (<a
href="https://doi.org/10.1016/j.engappai.2021.104494">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by the success of deep learning techniques, there are numerous deep learning models developed for recommender systems. User-oriented autoencoder (UAE) and item-oriented autoencoder (IAE) are two typical approaches developed for the recommendation by learning features from items or users respectively. Existing works demonstrate that IAE model outperforms UAE model for rating prediction tasks, while UAE model outperforms IAE model for top-N recommendation task. This fact motivates us to develop a new synchronized heterogeneous autoencoder (SHAE) for top-N recommendation by considering both features learned by IAE and UAE models. Especially, we develop two novel heterogeneous knowledge distillation methods in feature-level and label-level to build relations between IAE and UAE models. Compared with matrix factorization approaches, our methods are more efficient with acceptable computational complexity for the recommendation. We conduct comprehensive experiments on public datasets to compare with several state-of-the-art approaches. Experimental results demonstrate that the proposed method significantly outperforms other comparisons for top-N recommendation tasks.},
  archive      = {J_EAAI},
  author       = {Yiteng Pan and Fazhi He and Xiaohu Yan and Haoran Li},
  doi          = {10.1016/j.engappai.2021.104494},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104494},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A synchronized heterogeneous autoencoder with feature-level and label-level knowledge distillation for the recommendation},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kernel optimization using conformal maps for the minimal
complexity machine. <em>EAAI</em>, <em>106</em>, 104493. (<a
href="https://doi.org/10.1016/j.engappai.2021.104493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Minimal Complexity Machine (MCM) is a kernel-based learning model that can learn very sparse models that yield comparable or better performance than Support Vector Machines (SVMs). However, kernel optimization for the MCM has not yet been explored. It has been shown in prior work that a data dependent kernel helps improve generalization. We show results on data dependent optimized kernels for the MCM and a large-scale MCM variant. Results on benchmark datasets demonstrate both model sparsity and improved generalization.},
  archive      = {J_EAAI},
  author       = {Skyler Badge and Sumit Soman and Suresh Chandra and Jayadeva},
  doi          = {10.1016/j.engappai.2021.104493},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104493},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Kernel optimization using conformal maps for the minimal complexity machine},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Early detection and classification of internal leakage in
boom actuator of mobile hydraulic machines using SVM. <em>EAAI</em>,
<em>106</em>, 104492. (<a
href="https://doi.org/10.1016/j.engappai.2021.104492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile hydraulic machines are used in various operations like construction, material handling and mining. High powers to weight ratio and manoeuvrability in rough terrains are striking features that help in edging out their electrical and mechanical counterparts. Internal leakage in hydraulic actuators is a faulty condition frequently observed in hydraulic machines. Internal leakage in the actuator affects the system’s dynamic performance and decreases its energy efficiency. Also, internal leakage is apparent only when the leakage is extreme and the actuator stops responding to command signals. Thus, detecting internal leakage in its early stages is a difficult task. Early detection and corrective action save energy, reduce component degradation, and reduce machine downtime. There are many existing techniques for internal leakage detection of hydraulic actuators, but they are intended for actuators working in a laboratory environment. The main focus of this paper is to present a practical method for early detection of internal leakage fault present in boom actuator of mobile hydraulic machines by analysing the machine work-cycle data with minimum hardware. The method trains and validates a Support Vector Machine (SVM) classifier using pressure and boom angle displacement signals. The time-series signals are processed using ’event-based’ feature extraction method. The binary version of Particle Swarm Optimisation is used for feature selection. The trained classifier can detect and classify internal leakage faults with more than 95% accuracy, which is sufficient for taking appropriate preventive maintenance steps on time.},
  archive      = {J_EAAI},
  author       = {Joseph T. Jose and J. Das and Santosh Kr. Mishra and Gyan Wrat},
  doi          = {10.1016/j.engappai.2021.104492},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104492},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Early detection and classification of internal leakage in boom actuator of mobile hydraulic machines using SVM},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A flexible deep learning-aware framework for travel time
prediction considering traffic event. <em>EAAI</em>, <em>106</em>,
104491. (<a
href="https://doi.org/10.1016/j.engappai.2021.104491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Travel time is an important signal to measure the performance of transportation systems. However, urban traffic forecasting is still a challenging task due to the complicated nonlinear nature of urban traffic and the impact of abnormal traffic event. In this study, we propose a flexible deep learning-aware framework which is composed by integrating multiple components with a sequence-to-sequence (Seq2Seq) model as the main body. Specifically, we incorporate a newly designed hybrid adjacency matrix of graph convolution network and temporal attention mechanism to flexibly capture spatio-temporal dynamics accordingly. In addition, we design a responsive algorithm to obtain the latent representation of traffic event by applying stacked denoising autoencoder. We then conduct the baseline model comparison and ablation experiments to evaluate our model performance with real-word datasets. The results indicate that our method outperforms baselines and the fusion of traffic event data can improve prediction accuracy. Moreover, the case study and sensitivity analysis also have a reference value to the practical application of traffic prediction task.},
  archive      = {J_EAAI},
  author       = {Miao Xu and Hongfei Liu},
  doi          = {10.1016/j.engappai.2021.104491},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104491},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A flexible deep learning-aware framework for travel time prediction considering traffic event},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning-based radio function deployment
for secure and resource-efficient NG-RAN slicing. <em>EAAI</em>,
<em>106</em>, 104490. (<a
href="https://doi.org/10.1016/j.engappai.2021.104490">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network functions virtualization is a prominent technology for next-generation radio access network (NG-RAN) slicing to achieve customization for various vertical services, such as auto-manufacturing and auto-driving. However, when virtualized radio function blocks with different security levels of services share a common server to achieve network resource-saving, a co-resident threat is exposed due to the lack of physical isolation. Therefore, designing a secure and efficient NG-RAN slicing strategy is necessary but difficult, especially for such distributed networks in which different tenants have distinct network bandwidth and security level requirements. To this end, we first formulate this slicing problem as an ILP model called Secure isolation and resource Efficiency-oriented Multi-Objective NG-RAN Slicing (SEMONS). However, the SEMONS is not practical for online execution due to its high computational complexity. Then, we propose a secure and efficient RAN slicing method for fast online execution based on a deep reinforcement learning (DRL) framework. The Wolpertinger policy algorithm is leveraged to train the agent in the DRL framework, which combines the deep deterministic policy gradient with the K-Nearest-Neighbor algorithm to reduce the size of the exploration space. Then the training complexity is reduced, and the learning results are optimized. Extensive simulation results show that the DRL framework can obtain the near-optimal secure and efficient NG-RAN slicing strategies compared to the SEMONS model, with only 6% target deviation on average, and it also outperforms the greedy baseline algorithm by 14.5%.},
  archive      = {J_EAAI},
  author       = {Pengfei Zhu and Jiawei Zhang and Yuming Xiao and Jiabin Cui and Lin Bai and Yuefeng Ji},
  doi          = {10.1016/j.engappai.2021.104490},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104490},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning-based radio function deployment for secure and resource-efficient NG-RAN slicing},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HMMN: Online metric learning for human re-identification via
hard sample mining memory network. <em>EAAI</em>, <em>106</em>, 104489.
(<a href="https://doi.org/10.1016/j.engappai.2021.104489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective metric learning is important in various applications, especially for re-identification. Compared with most existing re-identification methods which are not suitable for a real-time update mode, we exploit a novel memory-based strategy for mining hard triplets in online metric learning. This strategy is realized with an end-to-end deep learning based framework using an external memory pool. Our proposed pipeline is able to explicitly provide hard negative and positive samples to generate effective triplets, which are important for online metric learning due to the representative triplets could provide distinctive information to help understand the concept of metric learning between categories. In addition, a “focal-triplet loss” function is proposed to deal with the lack of positive or negative samples for one anchor, and the imbalance between easy and hard triplets for mini-batch. Experimental results on Market-1501, CUHK03 and DukeMTMC-reID demonstrate the effectiveness of our method, and its performance even outperforms that of some existing offline methods.},
  archive      = {J_EAAI},
  author       = {Pengcheng Han and Qing Li and Cunbao Ma and Shibiao Xu and Shuhui Bu and Yong Zhao and Ke Li},
  doi          = {10.1016/j.engappai.2021.104489},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104489},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HMMN: Online metric learning for human re-identification via hard sample mining memory network},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised cycle optimization learning for single-view
depth and camera pose with kalman filter. <em>EAAI</em>, <em>106</em>,
104488. (<a
href="https://doi.org/10.1016/j.engappai.2021.104488">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a general cycle optimization framework with a Kalman filter (KF) module for single-view depth prediction and camera pose estimation. The framework designs a KF module based on measurement noise estimated from networks without supervision to reduce the noise of pose parameters and optimizes the DepthNet architecture to add a new upconvolutional module and a decoder structure to overcome the gradient locality and adjust the mode of multi-task coupling. All modules are integrated to construct a cycle optimization strategy as the core of this paper for overall performance improvement. Experimental results on the KITTI dataset show that the cycle optimization framework greatly improves the performance of the original framework and is better than other improvements on the same original framework; single-view depth prediction and camera pose estimation achieve state-of-the-art performance compared with existing methods under the same or comparable structure.},
  archive      = {J_EAAI},
  author       = {Tianhao Gu and Zhe Wang and Ziqiu Chi and Yiwen Zhu and Wenli Du},
  doi          = {10.1016/j.engappai.2021.104488},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104488},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised cycle optimization learning for single-view depth and camera pose with kalman filter},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). STENet: A hybrid spatio-temporal embedding network for human
trajectory forecasting. <em>EAAI</em>, <em>106</em>, 104487. (<a
href="https://doi.org/10.1016/j.engappai.2021.104487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a hybrid spatio-temporal embedding network (named as STENet) for human trajectory forecasting, which is built upon a GAN-based hierarchical framework. Differently from traditional approaches that only use LSTM for trajectory modeling, we exploit the 1D Convolutional Neural Network (1D-CNN) to embed position features at multiple temporal scales. Moreover, we propose a two-stage graph attention mechanism, which can better describe mutual interactions among pedestrians in the crowd. Additionally, group influences at every time step are taken into account as well. The overall framework is designed using a hierarchical manner, and trained using the Wasserstein distance. We carry out our experiments on the ETH and the UCY datasets. The corresponding results demonstrate the effectiveness of the proposed framework.},
  archive      = {J_EAAI},
  author       = {Bo Zhang and Chengzhi Yuan and Tao Wang and Hongbo Liu},
  doi          = {10.1016/j.engappai.2021.104487},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104487},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {STENet: A hybrid spatio-temporal embedding network for human trajectory forecasting},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive structure network-based multiscale feature
fusion for object detection in real-time application. <em>EAAI</em>,
<em>106</em>, 104486. (<a
href="https://doi.org/10.1016/j.engappai.2021.104486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based target detection techniques have already made a wide-range impact on our daily life. Currently, a feature pyramid is a widely utilized technique for multiscale target detection, the effectiveness of the technique has already been proved. Nevertheless, in the pyramid structure, problems, such as multiscale feature alignment, model turmoil after fusion, feature redundancy, and no-local feature fusion, exist. In this paper, we propose a novel progressive structure network to solve the aforementioned problems. The proposed structure contains three modules: multiscale feature alignment fusion, different scale channels &amp; spatial location adaptive weighted fusion, and multiscale global and local feature fusion. The proposed structure is capable of fusing information from different feature layers more effectively. Subsequently, the semantic gaps among different scales can be reduced. Furthermore, the proposed structure can maintain the stability of the detection network and its performance has been proved by comparing with other state-of-art feature fusion method. The proposed progressive network structure has also been applied to actual target detection tasks and the practical application effectiveness of our method has been verified.},
  archive      = {J_EAAI},
  author       = {Haifeng Wang and Lvjiyuan Jiang and Qian Zhao and Hao Li and Kai Yan and Yang Yang and Songlin Li and Yungang Zhang and Lianliu Qiao and Cuilian Fu and Hong Yin and Yun Hu and Haibin Yu},
  doi          = {10.1016/j.engappai.2021.104486},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104486},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Progressive structure network-based multiscale feature fusion for object detection in real-time application},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring variable-length features (motifs) for predicting
binding sites through interpretable deep neural networks. <em>EAAI</em>,
<em>106</em>, 104485. (<a
href="https://doi.org/10.1016/j.engappai.2021.104485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transcription factor binding sites (TFBS) and RNA-binding proteins (RBP) plays a key role in gene regulation, transcription, RNA editing. Identifying and locating these potential sites is essential for detecting pathogenic variation in many biological processes. Some portions of binding sites are recognized by biological experiments that are time-intensive and expensive. Many computational approaches are considered as possible alternative solutions and few deep learning methods are recently developed for fast and accurate prediction of binding sites. Although existing approaches achieve competent performance, many methods requires specialized feature set and moreover interpretability remains challenging. To overcome these problems, we propose an interpretable deep learning technique called protein binding variable pattern predictor (PBVPP), which uses a wide variety of experimental data and performance metrics to predict binding sites. The novelty of our proposed method is based on three key factors: (i) PBVPP along with its variant has the capability to extract vital features from large-scale genomic sequences obtained by high throughput technology to predict the occurrence of TFBS and RBP sites. (ii) The proposed interpretable model reveals how to mine vital features, and also extract variable length patterns for accurate prediction of binding sites. (iii) The obtained motifs are validated against the TFBSshape DNA (JASPAR) database’s known target motifs. The proposed model has shown an improvement of 5.88%, 5.01% over state-of-the-art methods in terms of receiver operating curve for TFBS, RBP and also shown tremendous improvement of 60% in precision recall curve for TFBS prediction.},
  archive      = {J_EAAI},
  author       = {Chandra Mohan Dasari and Santhosh Amilpur and Raju Bhukya},
  doi          = {10.1016/j.engappai.2021.104485},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104485},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploring variable-length features (motifs) for predicting binding sites through interpretable deep neural networks},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards dense people detection with deep learning and depth
images. <em>EAAI</em>, <em>106</em>, 104484. (<a
href="https://doi.org/10.1016/j.engappai.2021.104484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes a novel DNN-based system, named PD3net , that detects multiple people from a single depth image, in real time. The proposed neural network processes a depth image and outputs a likelihood map in image coordinates, where each detection corresponds to a Gaussian-shaped local distribution, centered at each person’s head. This likelihood map encodes both the number of detected people as well as their position in the image, from which the 3D position can be computed. The proposed DNN includes spatially separated convolutions to increase performance, and runs in real-time with low budget GPUs. We use synthetic data for initially training the network, followed by fine tuning with a small amount of real data. This allows adapting the network to different scenarios without needing large and manually labeled image datasets. Due to that, the people detection system presented in this paper has numerous potential applications in different fields, such as capacity control, automatic video-surveillance, people or groups behavior analysis, healthcare or monitoring and assistance of elderly people in ambient assisted living environments. In addition, the use of depth information does not allow recognizing the identity of people in the scene, thus enabling their detection while preserving their privacy. The proposed DNN has been experimentally evaluated and compared with other state-of-the-art approaches, including both classical and DNN-based solutions, under a wide range of experimental conditions. The achieved results allows concluding that the proposed architecture and the training strategy are effective, and the network generalize to work with scenes different from those used during training. We also demonstrate that our proposal outperforms existing methods and can accurately detect people in scenes with significant occlusions.},
  archive      = {J_EAAI},
  author       = {David Fuentes-Jimenez and Cristina Losada-Gutierrez and David Casillas-Perez and Javier Macias-Guarasa and Daniel Pizarro and Roberto Martin-Lopez and Carlos A. Luna},
  doi          = {10.1016/j.engappai.2021.104484},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104484},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards dense people detection with deep learning and depth images},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algorithmically-consistent deep learning frameworks for
structural topology optimization. <em>EAAI</em>, <em>106</em>, 104483.
(<a href="https://doi.org/10.1016/j.engappai.2021.104483">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topology optimization has emerged as a popular approach to refine a component’s design and increase its performance. However, current state-of-the-art topology optimization frameworks are compute-intensive, mainly due to multiple finite element analysis iterations required to evaluate the component’s performance during the optimization process. Recently, machine learning (ML)-based topology optimization methods have been explored by researchers to alleviate this issue. However, previous ML approaches have mainly been demonstrated on simple two-dimensional applications with low-resolution geometry. Further, current methods are based on a single ML model for end-to-end prediction, which requires a large dataset for training. These challenges make it non-trivial to extend current approaches to higher resolutions. In this paper, we develop deep learning-based frameworks consistent with traditional topology optimization algorithms for 3D topology optimization with a reasonably fine (high) resolution. We achieve this by training multiple networks, each learning a different step of the overall topology optimization methodology, making the framework more consistent with the topology optimization algorithm. We demonstrate the application of our framework on both 2D and 3D geometries. The results show that our approach predicts the final optimized design better (5.76 × reduction in total compliance MSE in 2D; 2.03 × reduction in total compliance MSE in 3D) than current ML-based topology optimization methods.},
  archive      = {J_EAAI},
  author       = {Jaydeep Rade and Aditya Balu and Ethan Herron and Jay Pathak and Rishikesh Ranade and Soumik Sarkar and Adarsh Krishnamurthy},
  doi          = {10.1016/j.engappai.2021.104483},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104483},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Algorithmically-consistent deep learning frameworks for structural topology optimization},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IDM-SPS: Identifying driver module with somatic mutation,
PPI network and subcellular localization. <em>EAAI</em>, <em>106</em>,
104482. (<a
href="https://doi.org/10.1016/j.engappai.2021.104482">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mutation profiles together with prior knowledge such as interactions between genes/proteins provide abundant critical information for the identification of driver modules, which is very important for analyzing mutational heterogeneity in human cancers. Due to the negative effects of inevitable false positive interactions in the PPI network, subcellular localization data are exerted to filter out them firstly, and somatic mutation profiles are used to weight the retained interactions. Five novel recombination operators are introduced basing on the vertex degrees and the edge weights in the PPI network, and a parthenogenetic algorithm is devised for solving the presented identification model which takes into account network connectivity, mutual exclusivity, coverage, and hops between genes within a module. Extensive experimental results indicate that compared with two state-of-the-art computational methods Hotnet2 and MEXCOwalk, the proposed method exhibits competitive performance in most cases in terms of recovering known cancer genes, providing modules that have satisfied coverage and mutual exclusivity, and are enriched for mutations in specific cancer types. Many identified gene sets are involved in known signaling pathways, most of the implicated genes are oncogenes or tumor suppressors previously reported in the literature. In addition, the proposed method does identify many cancer related genes missed by methods Hotnet2 and MEXCOwalk, including some recognized genes covering many types of cancers but having low mutation frequency.},
  archive      = {J_EAAI},
  author       = {Jingli Wu and Jifan Yang and Gaoshi Li and Jinyan Wang},
  doi          = {10.1016/j.engappai.2021.104482},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104482},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IDM-SPS: Identifying driver module with somatic mutation, PPI network and subcellular localization},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A conditional-weight joint relevance metric for feature
relevancy term. <em>EAAI</em>, <em>106</em>, 104481. (<a
href="https://doi.org/10.1016/j.engappai.2021.104481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an important preprocessing operation in the fields of machine learning and data mining. Information theory is widely used in feature selection methods because it can measure linear and nonlinear correlations among variables. Traditional information theory-based feature selection methods intend to maximize feature relevancy while minimizing feature redundancy. However, previous feature selection methods focus on either the effect of candidate features or the effect of already-selected features on the feature relevancy. In fact, both candidate features and already-selected features offer important classification information in the design of feature relevancy term. To avoid this problem, we extract useful classification information from joint mutual information to design a novel feature relevancy term named Conditional-Weight Joint Relevance (CWJR). Based on CWJR, we propose a novel feature selection method named Feature Selection considering Conditional-Weight Joint Relevance (CWJR-FS). Additionally, to distinguish the differences between our method and previous methods, we divide information theory-based feature selection methods into two categories: linear-based feature selection methods and nonlinear-based feature selection methods. Finally, our method is compared to seven linear-based methods and four nonlinear-based methods on 19 benchmark data sets. The experimental results demonstrate that CWJR-FS outperforms the compared methods in terms of the average classification accuracy, AUC and F1 score.},
  archive      = {J_EAAI},
  author       = {Ping Zhang and Wanfu Gao and Juncheng Hu and Yonghao Li},
  doi          = {10.1016/j.engappai.2021.104481},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104481},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A conditional-weight joint relevance metric for feature relevancy term},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective gradient optimizer approach-based weighted
multi-view clustering. <em>EAAI</em>, <em>106</em>, 104480. (<a
href="https://doi.org/10.1016/j.engappai.2021.104480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement of technology has enabled the availability of a large amount of data from different sources. In such multi-view datasets, each view provides a particular representation for data objects and produces different partitions. Weighted Multi-view clustering approaches aim to find a suitable consensus clustering taking into consideration both the incompatibility between views and the relevance of features in each view. In this paper, a multi-objective weighted, Multi-view clustering method is presented based on gradient based optimizer. In the developed algorithm, a set of objective functions is considered that optimize the feature weights simultaneously in each view and the cluster centers that provide the optimal partitioning. Each candidate solution in our proposed method is evaluated by the weighted within-cluster compactness of the partitioning obtained from a single view and by the global weighted between-cluster dispersion among the partitioning provided by all views and the negative entropy among all clusters. To validate the clustering performance of developed approach, nine multi-view datasets with different statistical properties were used in this study. In addition, a real-world multi-omics data which contains four multi-omics datasets for cancer subtype discovery with three levels of omics data were considered. Experimental results demonstrate the ability of the new method to generate better clustering results than six popular multi-objective optimizers and ten state-of-the-art multi-view methods according to three measures, which are clustering accuracy, rand index, and normalized mutual information.},
  archive      = {J_EAAI},
  author       = {Salima Ouadfel and Mohamed Abd Elaziz},
  doi          = {10.1016/j.engappai.2021.104480},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104480},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective gradient optimizer approach-based weighted multi-view clustering},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Many-objective gradient-based optimizer to solve optimal
power flow problems: Analysis and validations. <em>EAAI</em>,
<em>106</em>, 104479. (<a
href="https://doi.org/10.1016/j.engappai.2021.104479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing energy demand and environmental consciousness provoke the conventional single-objective optimization framework no longer satisfies new power system planning and control requirements. The number of optimization objectives being considered in power system optimization is increasing, necessitating the development of many-objective Optimal Power Flow (OPF) problems and the development of solution methods. In this paper, the fitness functions for the Many-Objective OPF (MaO-OPF) problem have been formulated, and a new Many-Objective Gradient-Based Optimizer (MaOGBO) based on reference point strategy is proposed to solve the MaO-OPF problem. The objectives of the MaO-OPF problem is to minimize the Reactive Power Loss (RPL), Active Power Loss (APL), Voltage Magnitude Deviation (VMD), Voltage Stability Indicator (VSI), Total Emission (TE), and the Total Fuel Cost (TFC) by satisfying different complex equality and inequality constraints. In the proposed MaOGBO, a reference point strategy is employed to acquire evenly spread Pareto -optimal solutions in each objective space. In order to improve the effectiveness of Pareto solutions, a mixed-multi-constraint handling approach is also implemented. In order to deal with the complex non-linear constraints, the process utilizes both the repair technique and penalty function. Besides, a fuzzy-based membership function strategy is also applied to locate the Best Compromise Solution (BCS) from the Pareto -optimal analytical solution. In order to validate the effectiveness of the proposed MaOGBO, DTLZ and MaF benchmark test suites are considered. In addition, a standard Institute of Electrical and Electronics Engineers (IEEE) bus test systems, such as IEEE-30/IEEE-57/IEEE-118 with different case studies, are also considered to assess the performance of the proposed algorithm. The obtained results are compared with other state-of-the-art algorithms, and the proposed MaOGBO proves the superiority over other competitors for most of the selected problems, including MaO-OPF. Finally, the proposed MaOGBO is also validated on large-scale Algerian 59-bus power systems and proved its superiority in handling realistic systems. This research is further supported up with extra online service and guidance at https://premkumarmanoharan.wixsite.com/mysite .},
  archive      = {J_EAAI},
  author       = {M. Premkumar ( Ph.D. ) and Pradeep Jangir ( Ph.D. ) and R. Sowmya and Rajvikram Madurai Elavarasan},
  doi          = {10.1016/j.engappai.2021.104479},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104479},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Many-objective gradient-based optimizer to solve optimal power flow problems: Analysis and validations},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Secured communication using efficient artificial neural
synchronization. <em>EAAI</em>, <em>106</em>, 104478. (<a
href="https://doi.org/10.1016/j.engappai.2021.104478">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an efficient artificial neural group synchronization is proposed for secured neural key exchange over public channels. To share the key over a public network, two Artificial Neural Networks (ANNs) are coordinated by mutual learning. The primary issue of neural coordination is assessing the synchronization of two parties’ ANNs in the absence of weights from the other. There is a delay in coordination measurement in existing techniques, which affects the confidentiality of neural coordination. Furthermore, research into the mutual learning of a cluster of ANNs is limited. This paper introduces a mutual learning methodology for measuring the entire synchronization of the set of ANNs quickly and efficiently. The measure of coordination is determined by the frequency with which the two networks have had the same outcome in prior rounds. When a particular threshold is reached, the hash is used to decide whether all networks are properly coordinated. The modified methodology uses has value of the weight vectors to achieve full coordination between two communicating entities. This technique has several advantages, including (1) Generation of session key via complete binary tree-based group mutual neural synchronization of ANNs over the public channel. (2) Unlike existing methods, the suggested method allows two communication entities to recognize full coordination faster. (3) Brute force, geometric, impersonation, and majority attacks are all considered in this proposed scheme. Tests to validate the performance of the proposed methodology are carried out, and the results show that the proposed methodology outperforms similar approaches already in use.},
  archive      = {J_EAAI},
  author       = {Arindam Sarkar and Mohammad Zubair Khan and Abdulfattah Noorwali},
  doi          = {10.1016/j.engappai.2021.104478},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104478},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Secured communication using efficient artificial neural synchronization},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). UP-tree &amp; UP-mine: A fast method based on upper bound
for frequent pattern mining from uncertain data. <em>EAAI</em>,
<em>106</em>, 104477. (<a
href="https://doi.org/10.1016/j.engappai.2021.104477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, frequent pattern mining from uncertain data has been actively researched in data mining. There are numerous exact and upper bound-based approaches for uncertain frequent pattern mining. Exact-based algorithms may produce a large data structure and need time-consuming calculations and upper bound-based algorithms may produce many false positives. As a result, these algorithms demand much time and memory. There have been efforts to resolve the problem of upper bound-based algorithms, however, all of these methods only try to tighten the upper bound of expected support for long patterns. This is while pruning infrequent short patterns has a greater impact on reducing the false positives. To overcome these drawbacks, in this paper an efficient method based on upper bound is proposed for mining uncertain frequent patterns. The proposed method uses a new T ightened u pper bound to expected support of p atterns (Tup) which has a significant effect on reducing the number of false positives by tightening the upper bound of expected support and early pruning of infrequent 2-itemsets and their supersets. Comprehensive experimental results show that the proposed method reduces memory consumption in most cases and dramatically improves the performance of exact and upper bound-based methods in terms of runtime and scalability for dense and sparse uncertain data.},
  archive      = {J_EAAI},
  author       = {Razieh Davashi},
  doi          = {10.1016/j.engappai.2021.104477},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104477},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {UP-tree &amp; UP-mine: A fast method based on upper bound for frequent pattern mining from uncertain data},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The object-oriented dynamic task assignment for unmanned
surface vessels. <em>EAAI</em>, <em>106</em>, 104476. (<a
href="https://doi.org/10.1016/j.engappai.2021.104476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the task assignment and guidance issues of unmanned surface vessels (USVs) interception. When the USVs formation is invaded by some moving objects during its escort, it is necessary for the unmanned systems to assign defenders to prevent attackers approaching the vulnerable target in antagonistic scenarios. This action requires efficient guidance and task assignment strategies. With this in mind, this paper presents the Integral Proportional Navigation Guidance (IPNG) with Tabu Dynamic Consensus-Based Auction Algorithm (TDCBAA) in marine interception scenario. First, IPNG is introduced in the interception game considering the USV kinematic model, which can effectively reduce the individual interception time. Second, a new bidding function is designed for moving objects interception with the consideration of the attackers’ types, positions and interception time. Finally, a TDCBAA is designed to solve the task assignment subproblem, resulting in a shorter overall interception time and a higher interception success rate. Simulations demonstrate that the proposed algorithm can optimize the allocation of defenders in real-time and intercept the attackers more quickly compared with other classical algorithms, which is more suitable in situations where attackers are approaching from all directions.},
  archive      = {J_EAAI},
  author       = {Bin Du and Yu Lu and Xiaotong Cheng and Weidong Zhang and Xuesong Zou},
  doi          = {10.1016/j.engappai.2021.104476},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104476},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The object-oriented dynamic task assignment for unmanned surface vessels},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matching images and texts with multi-head attention network
for cross-media hashing retrieval. <em>EAAI</em>, <em>106</em>, 104475.
(<a href="https://doi.org/10.1016/j.engappai.2021.104475">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cross-media hashing retrieval generally encodes multimedia data into a common binary hash space, which can effectively measure the correlation between samples from different modalities. However, in the cross-media retrieval, supervised methods require a lot of manual labels, which leads to the problem of high labor in practical application. Simultaneously, most unsupervised methods do not achieve good results by preserving the correlation between or within modalities. To attack these problems and further improve retrieval performance, this paper proposes an unsupervised cross-media hashing retrieval method based on multi-head attention network, which contains rich semantic information to match images and texts better. Specifically, we make use of a multi-head attention network for generating binary hash code better. At the same time, an auxiliary similarity matrix is constructed to integrate the original neighborhood information from different modalities. Therefore, this method can capture the potential relationships between inter-modal and intra-modal correlations. Furthermore, the method is unsupervised and requires no additional semantic labels, so it has the potential to achieve large-scale cross-media retrieval. In addition, two strategies of batch normalization and replacing hash code generation functions are adopted to optimize the model, and two loss functions are designed to make the performance of our method exceed that of many supervised cross-media hashing retrieval methods. Experiments on three baseline datasets show that our method performs much better than many state-of-the-art methods. The results demonstrate the effectiveness and superiority of our method.},
  archive      = {J_EAAI},
  author       = {Zhixin Li and Xiumin Xie and Feng Ling and Huifang Ma and Zhiping Shi},
  doi          = {10.1016/j.engappai.2021.104475},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104475},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Matching images and texts with multi-head attention network for cross-media hashing retrieval},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential evolution-based weighted soft majority voting
for crowdsourcing. <em>EAAI</em>, <em>106</em>, 104474. (<a
href="https://doi.org/10.1016/j.engappai.2021.104474">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing has attracted considerable attention in recent years. A large amount of labeled data can be obtained efficiently and cheaply from the crowdsourcing platform. Obviously, the labeling quality of crowd workers directly influences the quality of the labeled data. Although a small amount of label integration strategies have recently noticed the differences in the quality of crowd workers labeling different instances, which just utilize the statistical characteristics of multiple noisy labels to estimate the quality of crowd workers and thus are rough and sub-optimal. In addition, they can only deal with binary classification problems, which restricts the practical applications of crowdsourcing. To simultaneously solve these two issues, we propose three differential evolution-based weighted soft majority voting strategies for multi-class classification. In our proposed strategies, we exploit a differential evolution (DE) algorithm to estimate the quality of crowd workers labeling different instances by minimizing the Error, Gini and Entropy of weighted multiple noisy labels. Extensive experimental results on simulated and real-world datasets show that our proposed strategies significantly outperform all the other existing state-of-the-art label integration strategies.},
  archive      = {J_EAAI},
  author       = {Fangna Tao and Liangxiao Jiang and Chaoqun Li},
  doi          = {10.1016/j.engappai.2021.104474},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104474},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Differential evolution-based weighted soft majority voting for crowdsourcing},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale iterative refinement network for RGB-d salient
object detection. <em>EAAI</em>, <em>106</em>, 104473. (<a
href="https://doi.org/10.1016/j.engappai.2021.104473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extensive research leveraging RGB-D information has been exploited in salient object detection. However, salient visual cues appear in various scales and resolutions of RGB images due to semantic gaps at different feature levels. Meanwhile, similar salient patterns are available in cross-modal depth images as well as multi-scale versions. Cross-modal fusion and multi-scale refinement are still an open problem in RGB-D salient object detection task. In this paper, we begin by introducing top-down and bottom-up iterative refinement architecture to leverage multi-scale features, and then devise attention based fusion module (ABF) to address on cross-modal correlation. We conduct extensive experiments on seven public datasets. The experimental results show the effectiveness of our devised method.},
  archive      = {J_EAAI},
  author       = {Ze-yu Liu and Jian-wei Liu and Xin Zuo and Ming-fei Hu},
  doi          = {10.1016/j.engappai.2021.104473},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104473},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-scale iterative refinement network for RGB-D salient object detection},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensor completion using patch-wise high order hankelization
and randomized tensor ring initialization. <em>EAAI</em>, <em>106</em>,
104472. (<a
href="https://doi.org/10.1016/j.engappai.2021.104472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, tensor completion (TC), namely high-order extension of matrix completion, has aroused widespread attention. Many priors have been investigated turning the ill-posed TC problem into a well-posed one. The typical methods, however, either perform suboptimally due to missing consideration of appropriate priors, or suffer from overly complicated models by combining too many constraints. In this study, we go deeper by providing a detailed analysis on the rank properties in patch-wise and Hankel cases, figuring out both these two ingredients ensure stricter low-rank prior. This prompts us to design a resultful yet simple TC method using patch-wise and multi-way tensor extension. Specifically, strict low-rank property can be guaranteed in the formulated tensors and this is achieved without requiring any neighborhood setting. Moreover, to approximate the intrinsic rank of the Hankelized tensor, tensor ring decomposition is introduced after deeply comparing its superiority over other high-order decomposition techniques. The proposed method can be efficiently solved using alternating least squares (ALS) approach. Furthermore, a randomized tensor ring approximation is presented for fast initialization. Experimental results on color image inpainting demonstrate that the proposed method can generate better recovery performance compared with state-of-the-art low-rank related competitors, especially in cases of quite limited known pixels, e.g., 10%.},
  archive      = {J_EAAI},
  author       = {Jianwei Zheng and Mengjie Qin and Honghui Xu and Yuchao Feng and Peijun Chen and Shengyong Chen},
  doi          = {10.1016/j.engappai.2021.104472},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104472},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tensor completion using patch-wise high order hankelization and randomized tensor ring initialization},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human gaze-aware attentive object detection for ambient
intelligence. <em>EAAI</em>, <em>106</em>, 104471. (<a
href="https://doi.org/10.1016/j.engappai.2021.104471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding human behavior and the surrounding environment is essential for realizing ambient intelligence (AmI), for which eye gaze and object information are reliable cues. In this study, the authors propose a novel human gaze-aware attentive object detection framework as an elemental technology for AmI. The proposed framework detects users’ attentive objects and shows more precise and robust performance against object-scale variations. A novel Adaptive-3D-Region-of-Interest (Ada-3D-RoI) scheme is designed as a front-end module, and scalable detection network structures are proposed to maximize cost-efficiency. The experiments show that the detection rate is improved up to 97.6% on small objects (14.1% on average), and it is selectively tunable with a tradeoff between accuracy and computational complexity. In addition, the qualitative results demonstrate that the proposed framework detects a user’s single object-of-interest only, even when the target object is occluded or extremely small. Complementary matters for follow-up study are presented as suggestions to extend the results of the proposed framework to further practical AmI applications. This study will help develop advanced AmI applications that demand a higher-level understanding of scene context and human behavior such as human–robot symbiosis, remote-/autonomous control, and augmented/mixed reality.},
  archive      = {J_EAAI},
  author       = {Dae-Yong Cho and Min-Koo Kang},
  doi          = {10.1016/j.engappai.2021.104471},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104471},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human gaze-aware attentive object detection for ambient intelligence},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Auxiliary model-based multi-innovation PSO identification
for wiener–hammerstein systems with scarce measurements. <em>EAAI</em>,
<em>106</em>, 104470. (<a
href="https://doi.org/10.1016/j.engappai.2021.104470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many actual systems, it is often difficult to obtain complete input and output data. Thus, the problem of scarce measurements usually appears in the identification of these systems. This article investigates the parameter estimation of Wiener–Hammerstein systems with scarce measurements. A Wiener–Hammerstein system comprises an input linear unit, a nonlinear unit, and an output linear unit. The nonlinear unit in this paper is described by the saturation and dead-zone characteristics respectively. To solve the incomplete data problem caused by scarce measurements, the auxiliary model is applied. Then the auxiliary model-based improved particle swarm optimization (PSO) algorithm is derived. Furthermore, the multi-innovation technology is introduced to improve the convergence speed and estimation accuracy, and the auxiliary model-based multi-innovation improved PSO is proposed. Finally, the simulations of two numerical examples and the application of the turntable servo system indicate that the proposed multi-innovation method is applicable to Wiener–Hammerstein models with scarce measurements, the estimation accuracy and convergence speed are greatly improved.},
  archive      = {J_EAAI},
  author       = {Tiancheng Zong and Junhong Li and Guoping Lu},
  doi          = {10.1016/j.engappai.2021.104470},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104470},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Auxiliary model-based multi-innovation PSO identification for Wiener–Hammerstein systems with scarce measurements},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble learning for large-scale crowd flow prediction.
<em>EAAI</em>, <em>106</em>, 104469. (<a
href="https://doi.org/10.1016/j.engappai.2021.104469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kumbh Mela festival is the largest mass gathering in the world that is celebrated every three years. In 2016, it attracted over 70 million people to Ujjain, India. The Mahakal temple is the “heart” of the festival that attracts a huge number of pilgrims and needs to accommodate with massive crowds. These types of events pose significant safety challenges as large-scale mass gatherings are often associated with risks such as crowd crushes. There have been a number of serious incidents documented in recent history such as the Hajj crush at Mina, Mecca, Saudi Arabia (2006 and 2015), the Lame Horse crush during a fire at Perm, Russia (2009), the Love Parade disaster at Duisburg, Germany (2010), and the Kumbh Mela stampede at Allahabad, Uttar Pradesh, India (2013) to name a few. Safety assurance at events of such tremendous size is closely connected with crowd control and understanding the general behaviour of the crowd. One of the basic challenges in understanding crowd dynamics is being able to predict crowd flows at a particular location based on past/present flows from another location. There are several existing methods and models used to predict and manage crowd flow. In this paper, we introduce a novel method for short-term crowd flow prediction and show that it decreases the prediction error by 13% as compared to existing methods. The model is based on ensemble learning where we demonstrate that a combination of complementary methods with different a-priory assumptions can create better estimations. Utilizing a unique data set derived from CCTV camera recordings of pilgrims that we collected during the Kumbh Mela 2016 festival, we tested different methods from artificial intelligence and computational modelling, such as simple shift of time-series (time-shift), agent-based modelling, machine learning methods, and show how combinations of these different methods as an ensemble provide synergy to obtain better predictions. Our results demonstrate that agent-based modelling, when combined with other models, provides better predictive power especially in complex scenarios. These results point to something fundamental about the information contained within and generated by these methods. We anticipate that our research could be a starting point for further research of informational synergetic aspects of models and predictors.},
  archive      = {J_EAAI},
  author       = {Vladislav Karbovskii and Michael Lees and Alva Presbitero and Alexey Kurilkin and Daniil Voloshin and Ivan Derevitskii and Andrey Karsakov and Peter M.A. Sloot},
  doi          = {10.1016/j.engappai.2021.104469},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104469},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ensemble learning for large-scale crowd flow prediction},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Achieving security and privacy in federated learning
systems: Survey, research challenges and future directions.
<em>EAAI</em>, <em>106</em>, 104468. (<a
href="https://doi.org/10.1016/j.engappai.2021.104468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) allows a server to learn a machine learning (ML) model across multiple decentralized clients that privately store their own training data. In contrast with centralized ML approaches, FL saves computation to the server and does not require the clients to outsource their private data to the server. However, FL is not free of issues. On the one hand, the model updates sent by the clients at each training epoch might leak information on the clients’ private data. On the other hand, the model learnt by the server may be subjected to attacks by malicious clients; these security attacks might poison the model or prevent it from converging. In this paper, we first examine security and privacy attacks to FL and critically survey solutions proposed in the literature to mitigate each attack. Afterwards, we discuss the difficulty of simultaneously achieving security and privacy protection. Finally, we sketch ways to tackle this open problem and attain both security and privacy.},
  archive      = {J_EAAI},
  author       = {Alberto Blanco-Justicia and Josep Domingo-Ferrer and Sergio Martínez and David Sánchez and Adrian Flanagan and Kuan Eeik Tan},
  doi          = {10.1016/j.engappai.2021.104468},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104468},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Achieving security and privacy in federated learning systems: Survey, research challenges and future directions},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction of crime rate in urban neighborhoods based on
machine learning. <em>EAAI</em>, <em>106</em>, 104460. (<a
href="https://doi.org/10.1016/j.engappai.2021.104460">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the impact of crime on the lives of residents has increased, there are a number of methods for predicting where crime will occur. They tend to explore only the association established between a single factor and the distribution of crime. In order to more accurately and quickly visualize and predict crime distribution in different neighborhoods, and to provide a basis for security planning and design by planning designers, this paper uses GAN neural networks to build a prediction model of city floor plans and corresponding crime distribution maps. We take Philadelphia as the research sample, use more than 2 million crime information of Philadelphia from 2006 to 2018 to draw the crime hotspot distribution map, and collect the corresponding map of Philadelphia, and train the model for predicting the crime rate of the city with more than two thousand sets of one-to-one corresponding images as the training set. When the training is complete, a floor plan can be fed directly to the model, and the model will immediately feed back a hotspot map reflecting the crime distribution. Using the untrained Philadelphia data as the test set, the model can accurately predict crime concentration areas and the predicted crime concentration areas are similar to the concentration areas considered in previous studies. With the feedback from the model, the city layout can be adjusted and the crime rate can be greatly reduced when the simulated city planner tunes into the city plan. In addition the ideas in this paper can be applied as a set of methodologies to predict other relevant urban characteristic parameters and visualize them.},
  archive      = {J_EAAI},
  author       = {Jingyi He and Hao Zheng},
  doi          = {10.1016/j.engappai.2021.104460},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104460},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction of crime rate in urban neighborhoods based on machine learning},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Designing a sustainable–resilient disaster waste management
system under hybrid uncertainty: A case study. <em>EAAI</em>,
<em>106</em>, 104459. (<a
href="https://doi.org/10.1016/j.engappai.2021.104459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increase in the number of natural disasters and the significant amounts of waste generated in these events, having a comprehensive framework for its management in the recovery and response phases of disaster is necessary. Hence, this research investigates the disaster waste management problem by simultaneous consideration of sustainability and resiliency. In this regard, a multi-objective mathematical model is presented to minimize total costs, environmental impacts, and transportation risks while maximizing social impacts and resilience of the logistics system. Since uncertainty is an integral part of disaster conditions, the research problem formulates the fuzzy robust stochastic optimization model under the hybrid uncertainty. Then, a real-world case study is studied in Golestan province, Iran. Afterward, transportation risks are calculated by adopting the fuzzy failure mode and effects analysis (FMEA) method, and then the proposed model is solved by a hybrid algorithm based on the multi-choice goal programming method and particle swarm optimization algorithm (PSO). Eventually, sensitivity analyses on some important model parameters are conducted, and practical managerial/theoretical implications are presented. The obtained results show the efficiency and performance of the model and the developed hybrid algorithm.},
  archive      = {J_EAAI},
  author       = {Zakie Mamashli and Sina Nayeri and Reza Tavakkoli-Moghaddam and Zeinab Sazvar and Nikbakhsh Javadian},
  doi          = {10.1016/j.engappai.2021.104459},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104459},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Designing a sustainable–resilient disaster waste management system under hybrid uncertainty: A case study},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task support vector machine with pinball loss.
<em>EAAI</em>, <em>106</em>, 104458. (<a
href="https://doi.org/10.1016/j.engappai.2021.104458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the boom in machine learning, support vector machine (SVM) is widely employed in pattern recognition. However, most of SVM models concentrate on single-task learning, multi-task learning has been largely neglected. Compared with single-task learning, multi-task learning can achieve a good performance for each task by mining the shared information among tasks. In addition, loss function also plays an important role in the accuracy of SVM. Inspired by multi-task learning and the SVM with pinball loss (pin-SVM), we propose two novel multi-task support vector machines with pinball loss for binary classification, named as MTL-pin-SVM I and MTL-pin-SVM II. Both methods maximize the quantile distance for each task, which realizes less sensitive to noise and more stable for re-sampling. Moreover, MTL-pin-SVM II can use different combinations of kernel functions for different tasks, which can get better performance than other multi-task models by choosing the suitable combinations of kernel functions for different tasks. And they include the multi-task SVM with hinge loss as their special cases, which are denoted as MTL-C-SVM I and MTL-C-SVM II. The extensive experiments on multi-task datasets fully validate the validity of the proposed models.},
  archive      = {J_EAAI},
  author       = {Yunhao Zhang and Jiajun Yu and Xinyi Dong and Ping Zhong},
  doi          = {10.1016/j.engappai.2021.104458},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104458},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-task support vector machine with pinball loss},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating the parameters of parametric lifetime
distributions through an efficient acceptance–rejection sampler.
<em>EAAI</em>, <em>106</em>, 104457. (<a
href="https://doi.org/10.1016/j.engappai.2021.104457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The three-parameter (3-p) Weibull distribution is an extremely important distribution to characterise the statistical behaviour of a large number of real world phenomenons. It is also useful as a failure model in analysing the reliability of different types of mechanical and electrical components/systems. Successful applications of the distribution rely on an accurate estimation of its three parameters because it directly affects the reliability and lifetime analysis. Due to the intricate system of nonlinear equations and the complexity of the likelihood function, derivative-based optimisation methods may fail to converge. Thus, an efficient and effective method for estimating the parameters of the model is important from the practical viewpoint. In this paper, an optimisation scheme based on an acceptance–rejection (AR) mechanism coupled with an elegant nested sampling (NS) technique is proposed to tackle this problem. The idea is to gradually approach the region of optimal solutions through an efficient sampling technique and a reweighting scheme. The AR-NS algorithm allows a good exploration of the parameter space and converges towards higher likelihood regions by decreasing progressively a pre-specified tolerance threshold. The proposed approach gives the entire distributions of the optimal estimates rather than a single point estimates. To demonstrate the practicality and the efficiency of the proposed approach, numerous numerical examples using simulated data and real-world engineering cases will be given. The obtained results show that the AR-NS algorithm is a suitable method for estimating the parameters of lifetime distributions using different distances.},
  archive      = {J_EAAI},
  author       = {Anis Ben Abdessalem},
  doi          = {10.1016/j.engappai.2021.104457},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104457},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Estimating the parameters of parametric lifetime distributions through an efficient acceptance–rejection sampler},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey on digital video forensics: Taxonomy,
challenges, and future directions. <em>EAAI</em>, <em>106</em>, 104456.
(<a href="https://doi.org/10.1016/j.engappai.2021.104456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the explosive advancements in smartphone technology, video uploading/downloading has become a routine part of digital social networking. Video contents contain valuable information as more incidents are being recorded now than ever before. In this paper, we present a comprehensive survey on information extraction from video contents and forgery detection. In this context, we review various modern techniques such as computer vision and different machine learning (ML) algorithms including deep learning (DL) proposed for video forgery detection. Furthermore, we discuss the persistent general, resource, legal, and technical challenges, as well as challenges in using DL for the problem at hand, such as the theory behind DL, CV, limited datasets, real-time processing, and the challenges with the emergence of ML techniques used with the Internet of Things (IoT)-based heterogeneous devices. Moreover, this survey presents prominent video analysis products used for video forensics investigation and analysis. In summary, this survey provides a detailed and broader investigation about information extraction and forgery detection in video contents under one umbrella, which was not presented yet to the best of our knowledge.},
  archive      = {J_EAAI},
  author       = {Abdul Rehman Javed and Zunera Jalil and Wisha Zehra and Thippa Reddy Gadekallu and Doug Young Suh and Md. Jalil Piran},
  doi          = {10.1016/j.engappai.2021.104456},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104456},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive survey on digital video forensics: Taxonomy, challenges, and future directions},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A status-relevant blocks fusion approach for operational
status monitoring. <em>EAAI</em>, <em>106</em>, 104455. (<a
href="https://doi.org/10.1016/j.engappai.2021.104455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with massive data, one-off processing without distinction is not conducive to reducing data and model complexity, and many potentially valuable local details are ignored. The decision fusion of partition blocks, such as Dempster–Shafer (DS) evidence theory, opens the gate to differentiated analysis of data. However, DS evidence theory has problems that conflict factor K cannot accurately measure conflict and counter-intuitive results can be produced in response to high-conflict evidences. Therefore, a status-relevant blocks fusion approach for operational status monitoring is proposed in this research, with three main contributions: Firstly, a status-relevant modules and blocks selection strategy based on expert knowledge and wrapper model is proposed, which reduces data complexity and improves the ability to capture local effective information. Secondly, a personalized hybrid solution is designed to implement data compression, timing analysis, and models update to cope with the scale inconsistency, temporal correlation, and dynamic characteristics of equipment operating data. Finally, a conflict measurement and management strategy combining supervised and unsupervised (CMMS-SUS) is proposed to identify and revise high-conflict evidences from different blocks to eliminate the concerns of DS evidence theory. Then, Dempster’s combination rule is used to fuse the low-conflict evidences without correction or the high-conflict evidences after correction. Furthermore, a realistic shield tunnel case in China is used to demonstrate the feasibility and effectiveness of this approach.},
  archive      = {J_EAAI},
  author       = {Fulin Gao and Shuai Tan and Hongbo Shi and Zheng Mu},
  doi          = {10.1016/j.engappai.2021.104455},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104455},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A status-relevant blocks fusion approach for operational status monitoring},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated test case generation for path coverage by using
grey prediction evolution algorithm with improved scatter search
strategy. <em>EAAI</em>, <em>106</em>, 104454. (<a
href="https://doi.org/10.1016/j.engappai.2021.104454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated test case generation for path coverage (ATCG-PC), as an important task in software testing, aims to achieve the highest path coverage of a tested program by using as little computational overhead as possible. In ATCG-PC, “similar paths are usually executed by similar test cases” is a problem-specific knowledge which was touched by a handful of researchers but still underutilized. Inspired by the problem-specific knowledge, this paper designs a local search strategy by improving a scatter search strategy, and then proposes a grey prediction evolution algorithm with the improved scatter search strategy for ATCG-PC. Here, the improved scatter search strategy could obtain two feasible test cases by exploiting a dimension of a test case covering a certain path. The proposed algorithm is constructed by importing the improved scatter search strategy to the end of the reproduction operation of the grey prediction evolution algorithm holding strong exploration ability. Grey prediction evolution algorithm is first applied to solve ATCG-PC. The performance of the proposed algorithm is evaluated on six fog computing benchmark programs and six natural language processing benchmark programs. The experimental results demonstrate that the proposed algorithm can achieve the highest path coverage with the fewer test cases and running time than some state-of-the-art algorithms.},
  archive      = {J_EAAI},
  author       = {Gaocheng Cai and Qinghua Su and Zhongbo Hu},
  doi          = {10.1016/j.engappai.2021.104454},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104454},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automated test case generation for path coverage by using grey prediction evolution algorithm with improved scatter search strategy},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-objective bat algorithm with a novel competitive
mechanism and its application in controller tuning. <em>EAAI</em>,
<em>106</em>, 104453. (<a
href="https://doi.org/10.1016/j.engappai.2021.104453">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the complexity of multi-objective optimization scenarios, both convergence and diversity of optimization algorithms are put forward higher requirements, but the harmony between the two has not been completely resolved, especially in controller tuning issues. To address this challenge, a novel competitive mechanism-based multi-objective bat algorithm is proposed in this paper. Firstly, based on a pairwise competition strategy, a competitive bat algorithm is designed as a candidate evolution strategy that promotes the population to converge quickly without cumbersome external archives. Furthermore, to avoid premature convergence, the genetic algorithm is utilized to diversity the swarm. Secondly, a designed tribal competition mechanism achieves a dynamical adjusting of evolution strategies according to maturity. Thence, the proposed algorithm can effectively balance the convergence and diversity through the adaptive complementation of multiple evolution strategies. Finally, experiments on benchmark functions illustrate that the proposed algorithm statistically outperforms the compared 12 state-of-the-art algorithms on at least 15 out of 19 instances. Besides, the proposed algorithm is used to solve multi-objective tuning problems of two widely used controllers in a laboratory-developed permanent magnet synchronous motor system. Comparison with 4 representative algorithms verifies its effectiveness and practicality in real-life multi-objective optimization problems.},
  archive      = {J_EAAI},
  author       = {Hu Li and Bao Song and Xiaoqi Tang and Yuanlong Xie and Xiangdong Zhou},
  doi          = {10.1016/j.engappai.2021.104453},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104453},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-objective bat algorithm with a novel competitive mechanism and its application in controller tuning},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A belief hellinger distance for d–s evidence theory and its
application in pattern recognition. <em>EAAI</em>, <em>106</em>, 104452.
(<a href="https://doi.org/10.1016/j.engappai.2021.104452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer (D–S) evidence theory has been studied and applied broadly, owing to its advantage of effectively handling uncertainty problems in multisource information fusion. But under the circumstance of the body of evidences are highly conflicting, the result of evidence fusion is not so satisfactory even counter-intuitive. In order to conquer the flaw, a newly defined belief Hellinger distance is presented to quantify the discrepancy between evidences in D–S evidence theory. The belief Hellinger distance takes the number of the possible hypotheses into account, thus allowing it to provide a more rational and telling approach for dissimilarity measure between evidences. In addition, through strictly proven, the belief Hellinger distance meets the properties of boundedness, nondegeneracy, symmetry and satisfaction of triangle inequality, which is to say it is a true metric. On the basis of newly defined belief Hellinger distance, a new multisource information fusion method is well-designed. What is more, an iris dataset-based and a motor rotor fault diagnosis application are implemented to verify the new proposed distance measurement and the multisource information fusion method has an extensive practicality, effectiveness and applicability.},
  archive      = {J_EAAI},
  author       = {Chaosheng Zhu and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2021.104452},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104452},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A belief hellinger distance for D–S evidence theory and its application in pattern recognition},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantum deep reinforcement learning for rotor side converter
control of double-fed induction generator-based wind turbines.
<em>EAAI</em>, <em>106</em>, 104451. (<a
href="https://doi.org/10.1016/j.engappai.2021.104451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control performance of conventional analytic algorithms for double-fed induction generator-based wind turbines is a fixed feature, which needs to be optimized by optimization processes. To avoid the optimization processes and update control strategies online, this paper proposes an online control algorithm based on the quantum process, deep belief networks, and reinforcement learning for double-fed induction generator-based wind turbines. The proposed approach is named quantum deep reinforcement learning, consisting of deep belief networks, one reinforcement learning framework, and multiple subsidiary reinforcement learning parts with quantum processes. The quantum deep reinforcement learning can update the control strategy online with general initialization for dynamic systems, avoid optimal local solutions, and predict the next systemic states of double-fed induction generator-based wind turbines. The proportional–integral–derivative, fractional-order proportional–integral–derivative, active disturbance rejection controller, reinforcement learning, and the quantum deep reinforcement learning are compared under four cases, i.e., variable wind speed with step magnitude, variable wind speed with sine magnitude, voltage dropout of power grids, and both variable wind speed with random magnitude and voltage dropout of power grids. Consequently, the proposed quantum deep reinforcement learning can obtain better control performance for double-fed induction generator-based wind turbines with smaller integrated absolute error, integral squared error, and integrated time-weighted absolute error of the control error than other compared methods.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Lichun Chen and Dongduan Liu and Xiao Huang and Fang Gao},
  doi          = {10.1016/j.engappai.2021.104451},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104451},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Quantum deep reinforcement learning for rotor side converter control of double-fed induction generator-based wind turbines},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Octonion continuous orthogonal moments and their
applications in color stereoscopic image reconstruction and
zero-watermarking. <em>EAAI</em>, <em>106</em>, 104450. (<a
href="https://doi.org/10.1016/j.engappai.2021.104450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous orthogonal moments (COMs) are a type of effective image features widely used in various fields of image processing. However, most of the existing COMs are used for processing flat images and are not suitable for color stereoscopic images. For this reason, this paper first proposes an octonion theory applicable to color stereoscopic images, all color components of color stereoscopic images are coded by using the imaginary part of octonion, and all color components are processed as a whole, and the internal relations among all components are preserved. Then this paper combines the octonion theory with COMs to propose the octonion continuous orthogonal moments (OCOMs). The OCOMs fully reflect and retain the specific correlations between the left- and right-view components of color stereoscopic images, and provide good image description capability. Experimental results show that OCOMs have strong stability and good reconstruction performance when processing color stereoscopic images. Compared with other zero-watermarking methods, the zero-watermarking method embedded by OCOMs has stronger robustness.},
  archive      = {J_EAAI},
  author       = {Chunpeng Wang and Qixian Hao and Bin Ma and Xiaoming Wu and Jian Li and Zhiqiu Xia and Hongling Gao},
  doi          = {10.1016/j.engappai.2021.104450},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104450},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Octonion continuous orthogonal moments and their applications in color stereoscopic image reconstruction and zero-watermarking},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-layer aggregation model with effective consistency for
large-scale gaussian process regression. <em>EAAI</em>, <em>106</em>,
104449. (<a
href="https://doi.org/10.1016/j.engappai.2021.104449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To scale full Gaussian process (GP) to large-scale data sets, aggregation models divide the dataset into independent subsets for factorized training, and then aggregate predictions from distributed experts. Some aggregation models have been able to produce consistent predictions which converge to the latent function when data size approaches infinity. However, these consistent predictions will become ineffective due to the limited subset size of experts. Oriented by the transition from theory to practice, the key idea is using Generalized Robust Bayesian Committee Machine (GRBCM) with corrective function to replace experts of Generalized Product of Experts (GPoE) which focuses on global information, in order to get rid of the limitation of the experts’ size. Such a nested two-layer structure enables the proposed Generalized Product of Generalized Robust Bayesian Committee Machine (GPoGRBCM) to provide effective predictions on large-scale datasets and to inherit virtues of aggregations, e.g., a slightly flawed Bayesian inference framework, distributed/parallel computing. Furthermore, we perform comparisons of GPoGRBCM against the state-of-the-art aggregation models on one toy example and six real-world datasets with up to more than 3 million training points, showing dramatic performance improvement on scalability, capability, controllability, and robustness.},
  archive      = {J_EAAI},
  author       = {Wengsheng Wang and Changkai Zhou},
  doi          = {10.1016/j.engappai.2021.104449},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104449},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A two-layer aggregation model with effective consistency for large-scale gaussian process regression},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust optimization of the continuous annealing process
based on a novel multi-objective dragonfly algorithm. <em>EAAI</em>,
<em>106</em>, 104448. (<a
href="https://doi.org/10.1016/j.engappai.2021.104448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the large fluctuations in system and low efficiency caused by disturbance factors in the continuous annealing process, we established a robust multi-objective optimization model. Finding an optimal parameter setting scheme making the strip quality and capacity utilization more stable and robust is the fundamental task. For this problem, we first proposed a new robust index that combines the standard deviation and average value for guiding the model. Second, Multi-objective Dragonfly Algorithm based on Adventure Circuitous (ACMODA) is employed to solve the model. To improve the search efficiency of the algorithm, an Adventure Circuitous strategy is adopted. The strategy enables the individuals to search for new breakthroughs basing on the weight cross-combination hybrid flight pattern when disturbance intense. The experimental results basing on the test functions show that the proposed index can evaluate the robustness precisely and ACMODA can effectively improve the convergence performance comparing with others. Experimental results basing on actual industrial problems show that ACMODA can effectively solve the robust optimization problem in the continuous annealing process.},
  archive      = {J_EAAI},
  author       = {Huixin Tian and Chang Yuan and Kun Li},
  doi          = {10.1016/j.engappai.2021.104448},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104448},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust optimization of the continuous annealing process based on a novel multi-objective dragonfly algorithm},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neonatal dataset and benchmark for non-contact neonatal
heart rate monitoring based on spatio-temporal neural networks.
<em>EAAI</em>, <em>106</em>, 104447. (<a
href="https://doi.org/10.1016/j.engappai.2021.104447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The digital revolution of noncontact physiological signal monitoring in clinical and home health care is underway, and deep learning techniques are incredibly popular. Camera-based physiological signal monitoring for adults has made considerable progress in recent years. However, most of existing methods and datasets are developed for adult subjects, and until now, there has been no neonatal public database that is collected for developing deep learning method. Thus, in this paper, we introduce a large-scale newborn baby database, named NBHR (newborn baby heart rate estimation database), to fill the abovementioned knowledge gap. A total of 9.6 h of clinical videos (1130 videos totaling 921 GB) and reference vital signs are recorded from 257 infants at 0–6 days old. The facial videos and corresponding synchronized physiological signals, including photoplethysmograph information, heart rate, and oxygen saturation level, are recorded in our database. This large-scale database could be used to develop deep learning methods to estimate heart rate or oxygen saturation levels. Furthermore, a multitask deep learning method, called NBHRnet, is proposed to estimate heart rate based on the NBHR database, and the model is succinct that it can be deployed on a computer without GPUs. The experimental results indicate that NBHRnet yields competitive performance in predicting infant heart rate, with a mean absolute error of 3.97 bpm and a mean absolute percentage error of 3.28%; additionally, it can estimate heart rate almost instantaneously (2 s/60 frames). Our datasets are freely publicly available by request.},
  archive      = {J_EAAI},
  author       = {Bin Huang and Weihai Chen and Chun-Liang Lin and Chia-Feng Juang and Yuanping Xing and Yanting Wang and Jianhua Wang},
  doi          = {10.1016/j.engappai.2021.104447},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {11},
  pages        = {104447},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A neonatal dataset and benchmark for non-contact neonatal heart rate monitoring based on spatio-temporal neural networks},
  volume       = {106},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inertial load classification of low-cost electro-mechanical
systems under dataset shift with fast end of line testing.
<em>EAAI</em>, <em>105</em>, 104446. (<a
href="https://doi.org/10.1016/j.engappai.2021.104446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a rationale for designing a machine learning algorithm under dataset shift. In particular, we focus on the classification of the inertial load of low-cost Electro-Mechanical Actuators (EMAs) into several weight categories. In these low-cost settings, due to uncertainties in the manufacturing process, raw materials and usage, even if the EMA part number is the same, its serial numbers (i.e. items or exemplars) may show different physical behaviors. Thus, a learning model trained on data from a set of items can perform poorly when applied to other ones. The proposed solution comprises tailored normalization and cross validation procedures for training the classifier, along with suitable End Of Line (EOL) experiments for the characterization of a new produced EMA item. The approach is experimentally validated on the classification of the mass of sliding gates, using only measurements available on the gate EMA.},
  archive      = {J_EAAI},
  author       = {Nicholas Valceschini and Mirko Mazzoleni and Fabio Previdi},
  doi          = {10.1016/j.engappai.2021.104446},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104446},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inertial load classification of low-cost electro-mechanical systems under dataset shift with fast end of line testing},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature-refined box particle filtering for autonomous
vehicle localisation with OpenStreetMap. <em>EAAI</em>, <em>105</em>,
104445. (<a
href="https://doi.org/10.1016/j.engappai.2021.104445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle localisation is an important and challenging task in achieving autonomous driving. This work presents a box particle filter framework for vehicle self-localisation in the presence of sensor and map uncertainties. The proposed feature-refined box particle filter incorporates line features extracted from a multi-layer Light Detection And Ranging (LiDAR) sensor and information from OpenStreetMap to estimate vehicle states. A particle weight balance strategy is incorporated to account for the OpenStreetMap positional inaccuracy, which is assessed by comparing it to a high definition road map. The performance of the proposed framework is evaluated on a LiDAR dataset and compared with box particle filter variants. Experimental results show that the proposed framework achieves respectively 10% and 53% localisation performance improvement with reduced box volumes of 25% and 41%, when compared with the state-of-the-art interval analysis based box regularisation particle filter and the box particle filter.},
  archive      = {J_EAAI},
  author       = {Peng Wang and Lyudmila Mihaylova and Philippe Bonnifait and Philippe Xu and Jianwen Jiang},
  doi          = {10.1016/j.engappai.2021.104445},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104445},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-refined box particle filtering for autonomous vehicle localisation with OpenStreetMap},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Structured sparsity learning for large-scale fuzzy cognitive
maps. <em>EAAI</em>, <em>105</em>, 104444. (<a
href="https://doi.org/10.1016/j.engappai.2021.104444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy cognitive map (FCM) as a kind of intelligent soft computing method, by combining the advantages of neural network and fuzzy logic, can be used to mine the causal relationships between concepts and make reasoning. However, how to effectively learn the large-scale FCMs is still an open problem. In this article, by means of structured sparsity learning, a robust learning method for large-scale FCMs based on iterative smoothing algorithm is proposed. Firstly, in terms of sparse signal reconstruction, the objective function of learning method is constructed by using elastic and total variation (TV) penalties, which can be conducive to capture the sparse structure information of FCM and improve the robustness of network reconstruction. Due to the non-smoothness of the TV penalty, Nesterov’s smoothing technique is used to solve the non-smooth problem, thus transforming the problem into a convex optimization problem. Subsequently, in order to quickly solve the convex optimization, the algorithm based on proximal gradient descent is applied. In the experiment part, synthetic FCM models with different densities, sizes and noises are used to evaluate the proposed method, and the experimental results demonstrate the proposed method can make full use of the observations to learn the structural information of FCM. Moreover, the real-world data from the gene regulatory networks (GRNs) are further used to evaluate the effect of network reconstruction, and a higher reconstruction accuracy can be verified.},
  archive      = {J_EAAI},
  author       = {Fengqian Ding and Chao Luo},
  doi          = {10.1016/j.engappai.2021.104444},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104444},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Structured sparsity learning for large-scale fuzzy cognitive maps},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive-critic-based hybrid intelligent optimal tracking
for a class of nonlinear discrete-time systems. <em>EAAI</em>,
<em>105</em>, 104443. (<a
href="https://doi.org/10.1016/j.engappai.2021.104443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid intelligent tracking control approach is developed to address optimal tracking problems for a class of nonlinear discrete-time systems. The generalized value iteration algorithm is utilized to attain the admissible tracking control with off-line training, while the on-line near-optimal control method is established to enhance the control performance. It is emphasized that the value iteration performance is improved by introducing the acceleration factor. By collecting the input–output data of the unknown system plant, the model neural network is constructed to provide the partial derivative of the system state with respect to the control law as the approximate control matrix. A novel computational strategy is introduced to obtain the steady control of the reference trajectory. The critic and action neural networks are utilized to approximate the cost function and the tracking control, respectively. Considering approximation errors of neural networks, the stability analysis of the specific systems is provided via the Lyapunov approach. Finally, two numerical examples with industrial application backgrounds are involved for verifying the effectiveness of the proposed approach.},
  archive      = {J_EAAI},
  author       = {Ding Wang and Mingming Zhao and Mingming Ha and Lingzhi Hu},
  doi          = {10.1016/j.engappai.2021.104443},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104443},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptive-critic-based hybrid intelligent optimal tracking for a class of nonlinear discrete-time systems},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analyzing imbalanced online consumer review data in product
design using geometric semantic genetic programming. <em>EAAI</em>,
<em>105</em>, 104442. (<a
href="https://doi.org/10.1016/j.engappai.2021.104442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To develop a successful product, understanding the relationship between customer satisfaction (CS) and design attributes of a new product is essential. Nowadays IoT technologies are used to collect online review data from social media. More representative CS models are developed using online review data. However, online review data is imbalanced, since popular products receive more online consumer reviews and unpopular products receive less. When imbalanced data is used, CS models learn the characteristics of majority data while rarely learning minority data. Misleading analysis for product development is made since the CS model is biased to popular products. This paper proposes an approach to generate nondominated CS models which learn equally to imbalanced data from popular and unpopular products. A multi-objective optimization problem is formulated to learn equally in imbalanced data. This problem is proposed to be solved by the geometric semantic genetic programming (GSGP); a Pareto set of nondominated CS models is generated by the GSGP. Product designers select the most preferred models in the Pareto set. The preferred nondominated CS model attempts to tradeoff unpopular and popular products, to determine optimal design attributes and maximize the CS. The case study shows that the proposed GSGP is able to generate CS models with more accurate CS predictions compared to the commonly used methods. The proposed GSGP also generates a Pareto set of nondominated CS models which equally learn consumer reviews for those dryers. Based on the Pareto set, the design team selects the most preferred CS model.},
  archive      = {J_EAAI},
  author       = {Kit Yan Chan and C.K. Kwong and Huimin Jiang},
  doi          = {10.1016/j.engappai.2021.104442},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104442},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analyzing imbalanced online consumer review data in product design using geometric semantic genetic programming},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel time-power based grey model for nonlinear time
series forecasting. <em>EAAI</em>, <em>105</em>, 104441. (<a
href="https://doi.org/10.1016/j.engappai.2021.104441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To deal with various nonlinear issues in real applications, a novel time-power based grey model is put forward. However, in the original form of this model, the time-power parameter α normally equals to an integer, and then the analytical expression of the time response function will be obtained. Otherwise, if the parameter α equals to a non-integer, one cannot obtain the concrete time response function for future estimations. This situation may significantly restrict the applications of this grey model. To address such drawbacks, an optimized version is designed in this work. In the proposed model, a simplified solution to the differential equation is derived by using the definite integral technique. Furthermore, for improving accuracy, the time-power parameter α is optimized by utilizing the Particle Swarm Optimization algorithm based on the model parameter packages. Subsequently, the efficacy and practicality of this simplified function have been verified by numerical simulations and experimental studies. Moreover, the method of probability density prediction is employed for verifying the reliability and stability of the proposed model for the first time when predicting the settlement of the soft-clay subgrade on an expressway. The demonstration cases illustrate that the quantitative improvements over forecasts of the proposed model are even more pronounced with a level accuracy of 2.29% and 1.19% MAPE values in the fitted and predicted periods, respectively, which can significantly increase the predicting accuracy by more than 10% with respect to the other benchmarks. Therefore, the new proposed model not only has greater application fields and prospects but also achieves higher and more reliable predicting accuracy with the optimal α under the support of the Particle Swarm Optimization algorithm, compared with the competing models.},
  archive      = {J_EAAI},
  author       = {Keyong Wan and Bin Li and Weijie Zhou and Haicheng Zhu and Song Ding},
  doi          = {10.1016/j.engappai.2021.104441},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104441},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel time-power based grey model for nonlinear time series forecasting},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting of individual electricity consumption using
optimized gradient boosting regression with modified particle swarm
optimization. <em>EAAI</em>, <em>105</em>, 104440. (<a
href="https://doi.org/10.1016/j.engappai.2021.104440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of forecasting consumers’ energy consumption is currently a trend in energy supply companies. An accurate prediction of energy consumption is a powerful tool to check for inconsistencies between what is recorded and the actual amount consumed. In practice, Brazilian energy companies verify inconsistencies in the manual reading of consumption, using a consumption range based on the predicted consumption. This consumption forecast is currently realized by the average of previous consumptions and, therefore, can be improved by the use of machine learning techniques. For this purpose, an Optimized Gradient Boosting Regressor (OGBR) was proposed, which has been optimized by a modified version of the Particle Swarm Optimization (PSO) for fast parameter optimization. The OGBR prediction results on a dataset of over 2 million consumers were compared with its unmodified version and with the Seasonal and Trend decomposition using Loess (STL). In addition, the forecast stability of the OGBR over 12 months was evaluated. Therefore, the energy consumption forecasting performance was improved by using the OGBR and this performance was better than its unmodified version, in all validation metrics, and better than STL, in most classes of consumption.},
  archive      = {J_EAAI},
  author       = {Luis F.M. Sepulveda and Petterson S. Diniz and João O.B. Diniz and Stelmo M.B. Netto and Carolina L.S. Cipriano and Alexandre C. Araújo and Victor H.B. Lemos and Alexandre C.P. Pessoa and Darlan B.P. Quintanilha and João D.S. Almeida and Aristófanes C. Silva and Anselmo C. Paiva and Geraldo Braz Jr. and Márcia I.A. Silva and Eliana M.G. Monteiro and Italo F.S. Silva and Eduardo C. Fernandes},
  doi          = {10.1016/j.engappai.2021.104440},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104440},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting of individual electricity consumption using optimized gradient boosting regression with modified particle swarm optimization},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple-objective optimization applied in extracting
multiple-choice tests. <em>EAAI</em>, <em>105</em>, 104439. (<a
href="https://doi.org/10.1016/j.engappai.2021.104439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Student evaluation is an essential part of education and is usually done through examinations. These examinations generally use tests consisting of several questions as crucial factors to determine the quality of the students. Test-making can be thought of as a multi-constraint optimization problem. However, the test-making process that is done by either manually or randomly picking questions from question banks still consumes much time and effort. Besides, the quality of the tests generated is usually not good enough. The tests may not entirely satisfy the given multiple constraints such as required test durations, number of questions, and question difficulties. In this paper, we propose parallel strategies, in which parallel migration is based on Pareto optimums, and applyan improved genetic algorithm called a genetic algorithm combined with simulated annealing, GASA, which improves diversity and accuracy of the individuals by encoding schemes and a new mutation operator of GA to handle the multiple objectives while generating multiple choice-tests from a large question bank. The proposed algorithms can use the ability to exploit historical information structure in the discovered tests, and use this to construct desired tests later. Experimental results show that the proposed approaches are efficient and effective in generating valuable tests that satisfy specified requirements. In addition, the results, when compared with those from traditional genetic algorithms, are improved in several criteria including execution time, search speed, accuracy, solution diversity, and algorithm stability.},
  archive      = {J_EAAI},
  author       = {Tram Nguyen and Toan Bui and Hamido Fujita and Tzung-Pei Hong and Ho Dac Loc and Vaclav Snasel and Bay Vo},
  doi          = {10.1016/j.engappai.2021.104439},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104439},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiple-objective optimization applied in extracting multiple-choice tests},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probability transformation of mass function: A weighted
network method based on the ordered visibility graph. <em>EAAI</em>,
<em>105</em>, 104438. (<a
href="https://doi.org/10.1016/j.engappai.2021.104438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transform of basic probability assignment to probability distribution is an important aspect of decision making process. To address this issue, a weighted network method based on the ordered visibility graph is proposed in this paper, named OVGWP. In this proposed method, the information volume of focal elements is calculated by belief entropy. The entropy value is used to determine the rank of each proposition. After generating the rank, a weighted network corresponding to the given basic probability assignment can be constructed. The global ratio for proportional belief transformation is determined by the degree of nodes and its weighted edges in the network. Compared with existing ordered visibility graph probability, we have considered not only the belief value itself, but also the cardinality of basic probability assignment. Hence the proposed OVGWP considers a much more comprehensive information for transformation. Experimental results reveal that OVGWP produces an effective and reasonable transformation performance compared with existing methods. If the basic probability assignment is given as m ( Θ ) = 1 , the proposed OVGWP has the same result with pignistic probability transformation. The proposed OVGWP satisfies the consistency of the upper and lower boundaries.},
  archive      = {J_EAAI},
  author       = {Luyuan Chen and Yong Deng and Kang Hao Cheong},
  doi          = {10.1016/j.engappai.2021.104438},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104438},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Probability transformation of mass function: A weighted network method based on the ordered visibility graph},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polar coordinate system to solve an uncertain linguistic
z-number and its application in multicriteria group decision-making.
<em>EAAI</em>, <em>105</em>, 104437. (<a
href="https://doi.org/10.1016/j.engappai.2021.104437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Z-numbers have been a research hotspot because of the significant advantages in revealing the uncertainty and randomness of information. However, the computation of existing research on the linguistic Z-numbers is relatively complicated. The principal purpose of this paper is to express the linguistic Z-numbers from a new perspective and simplify the computation. Firstly, the polar coordinate system is adopted to describe the linguistic Z-numbers and form a new concept of Z-polar coordinate (ZPC). Secondly, a novel score function is defined to rank different Z-numbers. Thirdly, the Z-polar coordinate vector synthesis power weighted (ZPCVSPW) operator is proposed to integrate multiple information. To determine the weight vector of criteria in the fusion process, a new approach of calculating objective weights is suggested based on the entropy weight method (EWM) with the consideration of the uniqueness of ZPC. Finally, an example concerning multicriteria group decision-making (MCGDM) is performed to illustrate the feasibility of the proposed method. Besides, the validity of the proposed method is demonstrated by three testing criteria. The robustness analysis, complexity analysis, and comparison with other widely used methods are carried out.},
  archive      = {J_EAAI},
  author       = {Qianlei Jia and Jiayue Hu and Ehab Safwat and Ahmed Kamel},
  doi          = {10.1016/j.engappai.2021.104437},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104437},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Polar coordinate system to solve an uncertain linguistic Z-number and its application in multicriteria group decision-making},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep long short term memory based minimum variance kernel
random vector functional link network for epileptic EEG signal
classification. <em>EAAI</em>, <em>105</em>, 104426. (<a
href="https://doi.org/10.1016/j.engappai.2021.104426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the efficiently extracted and reduced features using deep long short-term memory (DLSTM) of the epileptic EEG signal integrated with minimum variance kernel random vector functional link net (MVKRVFLN) classifier are used to identify the seizure and non-seizure productively. Our methodology uses Children Hospital Boston-Massachusetts Institute of Technology (CHB-MIT) multi-channel scalp EEG data, Bonn university single-channel intracranial EEG data, and two-channel Bern Barcelona intracranial EEG data recordings to assess the performance. The non-stationary, non-linear, complex, and chaotic type EEG signal is directly applied to DLSTM to obtain compressed significant features. The scatter plots of the DLSTM output features signify this compressed information are unique in nature. The excellent generalization ability, faster learning rate, simpler network-based MVKRVFLN classifier is formulated to well identify the seizure and non-seizure epochs precisely by applying the deep LSTM extracted discriminative features as input. The type of kernel function selection and choice of regularization coefficient are added information to improve the performance of the proposed approach. The suggested technique provides excellent classification accuracy, superior detection ability, faster speed, and insignificant false positive rate per hour, simpler structure, robustness to classify the seizure and non-seizure signals.},
  archive      = {J_EAAI},
  author       = {Sebamai Parija and Ranjeeta Bisoi and P.K. Dash and Mrutyunjaya Sahani},
  doi          = {10.1016/j.engappai.2021.104426},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104426},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep long short term memory based minimum variance kernel random vector functional link network for epileptic EEG signal classification},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Graph matching based reasoner: A symbolic approach to
question answering. <em>EAAI</em>, <em>105</em>, 104425. (<a
href="https://doi.org/10.1016/j.engappai.2021.104425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text understanding and reasoning are among the core areas of artificial intelligence. Even a total solution to automatic text understanding and reasoning is still beyond the current techniques, thus it is time to build the stepping stones to solve a more straightforward problem set like question-answering (QA) without ambiguous utterances in the contexts or questions. The reported state-of-the-art approaches to this kind of problem are nearly all connectionist models based on neural networks. Significant progress has even been made in this direction. It is still hard for the pure connectionist models to handle logical reasoning. They generally suffer from the longstanding drawback of poor explainability and sensitivity to data noise and distribution. In this paper, we propose a complementary symbolic approach, GMR (Graph Matching based Reasoner) to QA — it automatically generates reasoning rules in the form of graphs from the training set and uses the generated rules to infer answers to the questions in the test set via graph matching. By employing this symbolic approach, 20 tasks in bAbI are solved with an average accuracy of 99.38%, and it outperforms the state-of-the-art for a real-life QA dataset WikiTableQuestions. After analyzing the accuracy of the basic evaluation indicators, we studied the generalization ability of the model in the paper, including the anti-noise ability, the convergence of the model, the stability of the model, the complexity of the algorithm, and the uncertainty of the parameters. Through comprehensive analysis and comparison, our model is stronger than the neural network model regarding anti-noise interference. Compared with the neural network model, our model performs very well in multi-tasking, and the stability of the model is quite high. The diversity of tasks did not reduce the stability of the model. We have conducted a comprehensive analysis and comparison of the parameter uncertainties. Our model can optimally select parameter configurations and will not cause a sharp drop in performance due to the parameter uncertainties. Finally, we describe the complexity of the GMR method and the optimal configuration of its parameters.},
  archive      = {J_EAAI},
  author       = {Jiabao Han and Hongzhi Wang},
  doi          = {10.1016/j.engappai.2021.104425},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104425},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph matching based reasoner: A symbolic approach to question answering},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Winner determination for logistics service procurement
auctions under disruption risks and quantity discounts. <em>EAAI</em>,
<em>105</em>, 104424. (<a
href="https://doi.org/10.1016/j.engappai.2021.104424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disruption risks and quantity discounts have not been explicitly studied in traditional winner determination problems. This paper investigates an innovative winner determination problem with accidental disruptions and quantity discounts for a fourth party logistics provider in a logistics service procurement auction. An effective hybrid strategy that integrates a fortification policy with an outside option policy is developed to mitigate possible disruptions. Integrating the hybrid strategy with a piecewise-linear discount function, a stochastic nonlinear winner determination model is constructed. Utilizing a linearization technique, such a nonlinear winner determination model can be reformulated as a mixed integer linear program. To obtain nearly optimal solutions, a scenario-based approximation method is developed, including a reduced scenario technique and a dual decomposition Lagrangian relaxation technique. Numerical experiments are conducted to illustrate the effectiveness and applicability of the proposed model and method. When the discount parameter decreases or the disruption probability increases, the fortification policy becomes more important for the logistics system. An interesting result indicates that both the auctioneer and bidders may benefit from considering the discount policy. Managerial implications are drawn for fourth party logistics providers to run a reliable logistics system in a cost-effective way.},
  archive      = {J_EAAI},
  author       = {Mingqiang Yin and Xiaohu Qian and Min Huang and Qingyu Zhang},
  doi          = {10.1016/j.engappai.2021.104424},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104424},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Winner determination for logistics service procurement auctions under disruption risks and quantity discounts},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven method for the improving forecasts of local
weather dynamics. <em>EAAI</em>, <em>105</em>, 104423. (<a
href="https://doi.org/10.1016/j.engappai.2021.104423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes the modeling approach for lower atmosphere dynamics in a selected location. The purpose of this model is to provide short-term and long-term forecasts of the weather variables which are used as the input data for the model of the dispersion of radioactive air pollution. The information from this integrated system is important for the implementation of the population safety measures in the case of a nuclear accident with an atmospheric release. We developed a dynamical, probabilistic, and non-parametric model based on Gaussian processes (GPs). GP nonlinear autoregressive model with exogenous inputs and variational training principle was implemented for multi-output training. A Monte Carlo approach to multi-output simulation of the model for long-term forecasts is presented which allows arbitrary prior distributions over function values. The model encompasses all available measurements from the weather stations near the location of interest and combines them with the forecasts from the numerical weather prediction model. The contribution of the developed model is the harvesting of all available information and simultaneously providing interconnected forecasts. The key result of this investigation is the improvement of short-term and long-term weather variable forecasts over those of the numerical weather prediction model. Consequently, we significantly enhance the dispersion forecast of radioactive air pollution for the case study considered. The computationally demanding modeling is accelerated using general-purpose computing on graphics processing units. The proposed method represents a step forward in the assurance of safety in the case of a nuclear accident.},
  archive      = {J_EAAI},
  author       = {Tadej Krivec and Juš Kocijan and Matija Perne and Boštjan Grašic and Marija Zlata Božnar and Primož Mlakar},
  doi          = {10.1016/j.engappai.2021.104423},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104423},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven method for the improving forecasts of local weather dynamics},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to traverse over graphs with a monte carlo tree
search-based self-play framework. <em>EAAI</em>, <em>105</em>, 104422.
(<a href="https://doi.org/10.1016/j.engappai.2021.104422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combinatorial optimization (CO) problems on the graph are the core and classic problems in artificial intelligence (AI) and operations research (OR). For example, the Vehicle Routing Problem (VRP) and Traveling Salesman Problem (TSP) are fascinating NP-hard problems and have important significance for the existing transportation system. Traditional methods such as heuristics methods, exact algorithms, and solution solvers can already find approximate solutions on small-scale graphs. However, they are helpless for large-scale graphs and other problems with similar structures. Moreover, traditional methods often require artificially designed heuristic functions to aid decision-making. In recent years, more and more work has focused on applying deep learning and reinforcement learning (RL) to learn heuristics, which allows us to learn the internal structure of the graph end-to-end and find the optimal path under the guidance of heuristic rules. However, most of these still need manual assistance, and the RL method used has the problems of low sampling efficiency and small searchable space. This paper proposes a novel framework (called OmegaZero) based on Alphago Zero, which does not prescribe expert experience or label data but is trained through self-play. We divide the learning into two stages: in the first stage, we employ graph attention network (GAT) and GRU to learn node representations and memory history trajectories. In the second stage, we employ Monte Carlo tree search (MCTS) and deep RL to search for the solution space and train the model.},
  archive      = {J_EAAI},
  author       = {Qi Wang and Yongsheng Hao and Jie Cao},
  doi          = {10.1016/j.engappai.2021.104422},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104422},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning to traverse over graphs with a monte carlo tree search-based self-play framework},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). WhONet: Wheel odometry neural network for vehicular
localisation in GNSS-deprived environments. <em>EAAI</em>, <em>105</em>,
104421. (<a
href="https://doi.org/10.1016/j.engappai.2021.104421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a deep learning approach is proposed to accurately position wheeled vehicles in Global Navigation Satellite Systems (GNSS) deprived environments. In the absence of GNSS signals, information on the speed of the wheels of a vehicle (or other robots alike), recorded from the wheel encoder, can be used to provide continuous positioning information for the vehicle, through the integration of the vehicle’s linear velocity to displacement. However, the displacement estimation from the wheel speed measurements are characterised by uncertainties, which could be manifested as wheel slips or/and changes to the tyre size or pressure, from wet and muddy road drives or tyres wearing out. As such, we exploit recent advances in deep learning to propose the Wh eel O dometry neural Net work (WhONet) to learn the uncertainties in the wheel speed measurements needed for correction and accurate positioning. The performance of the proposed WhONet is first evaluated on several challenging driving scenarios, such as on roundabouts, sharp cornering, hard-brake and wet roads (drifts). WhONet’s performance is then further and extensively evaluated on longer-term GNSS outage scenarios of 30 s, 60 s, 120 s and 180 s duration, respectively over a total distance of 493 km. The experimental results obtained show that the proposed method is able to accurately position the vehicle with up to 93% reduction in the positioning error of its original counterpart (physics model) after any 180 s of travel.},
  archive      = {J_EAAI},
  author       = {Uche Onyekpe and Vasile Palade and Anuradha Herath and Stratis Kanarachos and Michael E. Fitzpatrick},
  doi          = {10.1016/j.engappai.2021.104421},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104421},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {WhONet: Wheel odometry neural network for vehicular localisation in GNSS-deprived environments},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-scattering-preserving adaptive self-organizing map.
<em>EAAI</em>, <em>105</em>, 104420. (<a
href="https://doi.org/10.1016/j.engappai.2021.104420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel improved adaptive version of the Self-Organizing Map (SOM). Our enhancement of SOM adapts to the input data scattering, in this way, preserving the principal input data structure. In order to capture and extract the data scattering from the input dataset, we propose carrying out a preliminary input data clustering. As a result of forming the clusters in the input data space, the inner-cluster variances are calculated. The inner-cluster variances are subsequently employed as the basis for the determination of the neighborhood widths of the SOM’s Best Matching Units (BMUs). The method, introduced in this paper, has been a subject to the empirical evaluation carried out using the three real-world datasets of different size, dimensionality, and data type, representing three various experimental fields. Our proposal has been assessed on the basis of a comparison with seven reference data visualization approaches. The introduced method appeared to be superior over the remaining investigated data visualization techniques, and consequently, its effectiveness, usefulness, and accuracy have been verified and confirmed.},
  archive      = {J_EAAI},
  author       = {Dominik Olszewski},
  doi          = {10.1016/j.engappai.2021.104420},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104420},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A data-scattering-preserving adaptive self-organizing map},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modified lightning search algorithm for optimization.
<em>EAAI</em>, <em>105</em>, 104419. (<a
href="https://doi.org/10.1016/j.engappai.2021.104419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript proposes a new metaheuristic optimization algorithm for solving the problems related to constraint optimization. The proposed algorithm is based on a nature-inspired algorithm like a lightning search algorithm and differential evolution algorithm. The proposed algorithm consists of two stages. In the first/exploitation/local stage, the fitness values are calculated by using a lightning search algorithm, the inclusion of weight factor in the lightning search algorithm, and differential evolution algorithm using the same population. In the second/global/exploration stage, the minimum value of fitness for each row population by the implementation of the above three algorithms is updated with the population. The first and second stage continues until certain criteria are achieved. The final minimum value is the optimized result. Validation of the proposed methodology is performed by using 60 benchmark functions. The proposed methodology is compared with seven other well-known algorithms namely the lightning search algorithm, differential evolution algorithm cuckoo search algorithm, particle swarm optimization algorithm, seagull optimization algorithm, chimp optimization algorithm, and mayfly algorithm by computing mean, standard deviation, best and worst value for 60 benchmark functions. The proposed methodology is also validated by implementing it in seven real-time constraint optimized problems. Furthermore, the efficiency of the proposed technique has been validated statistically for unimodal and multimodal test functions. The results show a better performance of the proposed optimized algorithm compared to other algorithms.},
  archive      = {J_EAAI},
  author       = {Damodar Panigrahy and Padarbinda Samal},
  doi          = {10.1016/j.engappai.2021.104419},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104419},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modified lightning search algorithm for optimization},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid particle swarm optimization with crisscross
learning strategy. <em>EAAI</em>, <em>105</em>, 104418. (<a
href="https://doi.org/10.1016/j.engappai.2021.104418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an efficient and simple optimization algorithm, particle swarm optimization (PSO) has been widely applied to solve various real optimization problems. However, avoiding premature convergence and balancing the global exploration and local exploitation capabilities of the PSO remains two crucial problems. To overcome these drawbacks of PSO, a hybrid particle swarm optimization with crisscross learning strategy (PSO-CL) algorithm is proposed in this paper. In PSO-CL, in order to well balance the global exploration and local exploitation capabilities of PSO, a search direction adjustment mechanism based on subpopulation division operation is proposed. Meantime, to avoid the premature convergence and enhance the global search ability, a crossover-based comprehensive learning strategy (CCL) is adopted. Additionally, a stochastic example learning strategy (SEL) is introduced, which can assist collective information to be spread among separate sub-swarms, improve the local exploitation ability of the algorithm. 15 classic benchmark functions, CEC2017 test suite and two real-world optimization problems are utilized to verify the promising performance of PSO-CL, experimental results and statistical analysis indicate that PSO-CL has competitive performance compared with state-of-the-art PSO variants.},
  archive      = {J_EAAI},
  author       = {Baoxian Liang and Yunlong Zhao and Yang Li},
  doi          = {10.1016/j.engappai.2021.104418},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104418},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid particle swarm optimization with crisscross learning strategy},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved marine predators algorithm for shape
optimization of developable ball surfaces. <em>EAAI</em>, <em>105</em>,
104417. (<a
href="https://doi.org/10.1016/j.engappai.2021.104417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The shape optimization of developable surfaces is a pivotal and knotty technique in CAD/CAM and used in many product manufacturing planning operations, e.g., for ships, aircraft wing, automobiles, garments, etc. In this paper, an improved marine predators algorithm (MPA) is used to optimize the shape of shape-adjustable generalized cubic developable Ball (SGCD-Ball, for short) surfaces. Firstly, to solve the problems of shape adjustment and optimization for developable surfaces, we present a class of novel shape-adjustable generalized cubic Ball basis functions, and then construct the SGCD-Ball surfaces with shape parameters by using the presented basis functions. The shapes of the surfaces can be adjusted and optimized expediently by using the shape parameters. Secondly, the shape optimization of developable surfaces is mathematically an optimization problem that can be effectively dealt with by swarm intelligence algorithm. In this regard, by incorporating a quasi-opposition strategy and a differential evolution algorithm to the MPA, an improved MPA called ODMPA is developed to increase the population diversity and enhance its capability of jumping out of the local minima. Furthermore, the superiority of the proposed ODMPA is verified by comparing with standard MPA , modified MPA and several well-known intelligent algorithms on 23 classical benchmark functions, the CEC’17 test suite and three engineering optimization problems, respectively. Finally, by minimizing the energy of the SGCD-Ball surfaces as the evaluation standard, the shape optimization models of the corresponding enveloping and spine curve developable surfaces are established. The ODMPA is utilized to solve the shape optimization models, and the SGCD-Ball surfaces with minimum energy are obtained. Some representative numerical examples demonstrate the superiority of the proposed ODMPA in effectively solving the shape optimization models in terms of precision and robustness.},
  archive      = {J_EAAI},
  author       = {Gang Hu and Xiaoni Zhu and Guo Wei and Ching-Ter Chang},
  doi          = {10.1016/j.engappai.2021.104417},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104417},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved marine predators algorithm for shape optimization of developable ball surfaces},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Universal transformer hawkes process with adaptive recursive
iteration. <em>EAAI</em>, <em>105</em>, 104416. (<a
href="https://doi.org/10.1016/j.engappai.2021.104416">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asynchronous events sequences are widely distributed in the natural world and human activities, such as earthquakes records, users’ activities in social media, and so on. How to distill the information from these seemingly disorganized data is a persistent topic that researchers focus on. One of the most useful models is the point process model, and on the basis, the researchers obtain many noticeable results. Moreover, in recent years, point process models on the foundation of neural networks, especially recurrent neural networks (RNN) are proposed and compare with the traditional models, their performance is greatly improved. Enlighten by transformer model, which can learn sequence data efficiently without recurrent and convolutional structure, transformer Hawkes process comes out, and achieves state-of-the-art performance. However, there is some research proving that the re-introduction of recursive calculations in transformer can further improve transformer’s performance. Thus, we come out with a new kind of transformer Hawkes process model, universal transformer Hawkes process (UTHP), which contains both recursive mechanism and self-attention mechanism, and to improve the local perception ability of the model, we also introduce convolutional neural network (CNN) in the position-wise-feed-forward part. We conduct experiments on several datasets to validate the effectiveness of UTHP and explore the changes after the introduction of the recursive mechanism. These experiments on multiple datasets demonstrate that the performance of our proposed new model has a certain improvement compared with the previous state-of-the-art models.},
  archive      = {J_EAAI},
  author       = {Lu-ning Zhang and Jian-wei Liu and Zhi-yan Song and Xin Zuo},
  doi          = {10.1016/j.engappai.2021.104416},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104416},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Universal transformer hawkes process with adaptive recursive iteration},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bearing fault diagnosis with intermediate domain based
layered maximum mean discrepancy: A new transfer learning approach.
<em>EAAI</em>, <em>105</em>, 104415. (<a
href="https://doi.org/10.1016/j.engappai.2021.104415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, deep learning models for condition monitoring of mechanical systems increasingly gained importance. Most of the previous works use data of the same domain (e.g., bearing type) or of a large amount of (labeled) samples. This approach is not valid for many real-world scenarios from industrial use-cases where only a small amount of data, often unlabeled, is available. In this paper, we propose, evaluate, and compare a novel technique based on an intermediate domain, which creates a new representation of the features in the data and abstracts the defects of rotating elements such as bearings. The results based on an intermediate domain related to characteristic frequencies show an improved accuracy of up to 32 % on small labeled datasets compared to the current state-of-the-art in the time-frequency domain. Furthermore, a Convolutional Neural Network (CNN) architecture is proposed for transfer learning. We also propose and evaluate a new approach for transfer learning, which we call Layered Maximum Mean Discrepancy (LMMD). This approach is based on the Maximum Mean Discrepancy (MMD) but extends it by considering the special characteristics of the proposed intermediate domain. The presented approach outperforms the traditional combination of Hilbert–Huang Transform (HHT) and S-Transform with MMD on all datasets for unsupervised as well as for semi-supervised learning. In most of our test cases, it also outperforms other state-of-the-art techniques. This approach is capable of using different types of bearings in the source and target domain under a wide variation of the rotation speed.},
  archive      = {J_EAAI},
  author       = {Sebastian Schwendemann and Zubair Amjad and Axel Sikora},
  doi          = {10.1016/j.engappai.2021.104415},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104415},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bearing fault diagnosis with intermediate domain based layered maximum mean discrepancy: A new transfer learning approach},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Locality cross-view regression for feature extraction.
<em>EAAI</em>, <em>105</em>, 104414. (<a
href="https://doi.org/10.1016/j.engappai.2021.104414">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression-based methods (RBMs) have become a widely-used technique for feature extraction. However, most RBMs are only suitable for single-view data and fail to explore the consistency and complementarity information from multiple views. In this paper, we firstly propose a unified framework called locality cross-view regression (ULCR) to realize multi-view feature extraction. ULCR utilizes a regression loss function to explore the relationship between different views, meanwhile, preserving the manifold structure of samples. Then, under the ULCR framework, we propose a standard LCR (SLCR) which utilizes F-norm as the metric. SLCR is convenient for solving, but sensitive to the outliers. Therefore, a robust locality cross-view regression (RLCR) is proposed which uses L2,1-norm instead of F-norm in SLCR. The convergence analysis of the algorithm and the relationship between SLCR and RLCR are discussed. Experiment results on image datasets illustrate that the proposed methods develop better performance than other related methods.},
  archive      = {J_EAAI},
  author       = {Jinxin Zhang and Hongjie Zhang and Wenwen Qiang and Naiyang Deng and Ling Jing},
  doi          = {10.1016/j.engappai.2021.104414},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104414},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Locality cross-view regression for feature extraction},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards cross-lingual voice cloning in higher education.
<em>EAAI</em>, <em>105</em>, 104413. (<a
href="https://doi.org/10.1016/j.engappai.2021.104413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid progress of modern AI tools for automatic speech recognition and machine translation is leading to a progressive cost reduction to produce publishable subtitles for educational videos in multiple languages. Similarly, text-to-speech technology is experiencing large improvements in terms of quality, flexibility and capabilities. In particular, state-of-the-art systems are now capable of seamlessly dealing with multiple languages and speakers in an integrated manner, thus enabling lecturer’s voice cloning in languages she/he might not even speak. This work is to report the experience gained on using such systems at the Universitat Politècnica de València (UPV), mainly as a guidance for other educational organizations willing to conduct similar studies. It builds on previous work on the UPV’s main repository of educational videos, MediaUPV, to produce multilingual subtitles at scale and low cost. Here, a detailed account is given on how this work has been extended to also allow for massive machine dubbing of MediaUPV. This includes collecting 59 h of clean speech data from UPV’s academic staff, and extending our production pipeline of subtitles with a state-of-the-art multilingual and multi-speaker text-to-speech system trained from the collected data. Our main result comes from an extensive, subjective evaluation of this system by lecturers contributing to data collection. In brief, it is shown that text-to-speech technology is not only mature enough for its application to MediaUPV, but also needed as soon as possible by students to improve its accessibility and bridge language barriers.},
  archive      = {J_EAAI},
  author       = {Alejandro Pérez and Gonçal Garcés Díaz-Munío and Adrià Giménez and Joan Albert Silvestre-Cerdà and Albert Sanchis and Jorge Civera and Manuel Jiménez and Carlos Turró and Alfons Juan},
  doi          = {10.1016/j.engappai.2021.104413},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104413},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards cross-lingual voice cloning in higher education},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid particle swarm optimization algorithm for scheduling
flexible assembly systems with blocking and deadlock constraints.
<em>EAAI</em>, <em>105</em>, 104411. (<a
href="https://doi.org/10.1016/j.engappai.2021.104411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the scheduling problem of flexible assembly systems (FASs) without intermediate buffers. The main characteristic of the problem is that as no intermediate buffer exists between consecutive machines, blocking and deadlock constraints must be considered. Petri nets are used to model the considered FASs, and a novel hybrid particle swarm optimization (HPSO) algorithm is proposed to minimize the makespan. The proposed algorithm is the combination of the discrete PSO, particle repairing algorithm, particle improvement strategy, and local search method. First, each candidate solution for the problem is encoded as a permutation with repetition of part numbers, and can be uniquely decoded into a sequence of transitions. To ensure the feasibility of solutions, a repairing algorithm is developed, in which a deadlock avoidance policy is used. Then, a particle improvement policy is proposed to improve the performance of particles. Meanwhile, a local search method is designed and incorporated into HPSO to improve its search ability. Experiments are conducted to verify the effectiveness of the particle improvement policy and local search method. Comparisons between HPSO and ten other algorithms are performed. The comparison results and analysis show that our proposed algorithm can find feasible solutions for all tested instances, and is superior to other scheduling algorithms in terms of finding better solutions and performance stability.},
  archive      = {J_EAAI},
  author       = {Xiaoling Li and Keyi Xing and Qingchang Lu},
  doi          = {10.1016/j.engappai.2021.104411},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104411},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid particle swarm optimization algorithm for scheduling flexible assembly systems with blocking and deadlock constraints},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of novel metaheuristic algorithms on color
aerial image multilevel thresholding. <em>EAAI</em>, <em>105</em>,
104410. (<a
href="https://doi.org/10.1016/j.engappai.2021.104410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Color image thresholding is a well-known approach for image segmentation. An objective function, based on image entropy, is defined by threshold numbers and locations in the color histogram. Multiple classes of images can be created with multilevel thresholding. The main problem with thresholding techniques is to decide the threshold color values for each image. For a human operator, it is very hard to determine the specific threshold values of the images to be segmented. From this perspective, multilevel color image thresholding can be considered as an optimization problem that an algorithm should determine the optimum threshold values to obtain a perfectly segmented image. In recent years, metaheuristic algorithms become popular in several fields including image thresholding by their advantage of flexible structure. The motivation of this study relies on the fact that using same algorithm to solve any particular problem do not guarantee the best results as stated in no-free lunch theorem in optimization. Therefore, six novel nature inspired algorithms such as equilibrium optimization (EO), political optimizer (PO), turbulent flow of water-based optimization (TFWO), henry gas solubility optimization (HGSO), marine predators algorithm (MPA), and slime mould algorithm (SMA) are chosen to be compared by determining the multilevel color image thresholding values. These algorithms, which are used for the first time to solve this problem, are also compared statistically with extensive experiments. Aerial test images obtained by drones are used in the experiments. Kapur’s entropy and between-class variance (Otsu’s method) objectives are maximized by metaheuristic algorithms. Experimental results are evaluated with structural similarity (SSIM), peak-signal noise ratio (PSNR), blind/referenceless image spatial quality evaluator (BRISQUE), perception-based image quality evaluator (PIQE), natural image quality evaluator (NIQE), and computing CPU time consumption of the algorithms. Another problem of thresholding is that the question of how to compare the results objectively. Many image quality metrics may give incompatible results. Correlation analysis of the average ranking results show that image quality metrics used in this study are compatible to each other. Extensive experiments show that MPA and TFWO outperformed SMA, EO, PO and HGSO in terms of PSNR, SSIM, BRISQUE, PIQE, NIQE, and CPU time consumption for multilevel color aerial image thresholding.},
  archive      = {J_EAAI},
  author       = {Rifat Kurban and Ali Durmus and Ercan Karakose},
  doi          = {10.1016/j.engappai.2021.104410},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104410},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comparison of novel metaheuristic algorithms on color aerial image multilevel thresholding},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TDCMF: Two-dimensional complex mass function with its
application in decision-making. <em>EAAI</em>, <em>105</em>, 104409. (<a
href="https://doi.org/10.1016/j.engappai.2021.104409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to efficiently handle uncertain information has always been a problem which puzzles some practitioners and researchers. The complex evidence theory has many applications in handling uncertain information. However, the complex evidence theory is incapable of considering the situation that when the system is becoming more and more complex. In this paper, therefore, a two-dimensional complex mass function (TDCMF) is proposed. The TDCMF are modeled as complex numbers and some basic concepts are newly defined. Moreover, the proposed TDCMF considers not only the support degree but also non-support degree and hesitation degree. Based on that, a combination rule of TDCMF is proposed. Then an algorithm for decision-making based on the proposed TDCMF and combination rule is proposed. Finally, two applications of the proposed algorithm are carried out to address the issue of target identification and medical diagnosis in a comparative way, which validates the rationality of the proposed algorithm.},
  archive      = {J_EAAI},
  author       = {Hui Guo and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2021.104409},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104409},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TDCMF: Two-dimensional complex mass function with its application in decision-making},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning and focusing strategies to improve ACO that solves
CSP. <em>EAAI</em>, <em>105</em>, 104408. (<a
href="https://doi.org/10.1016/j.engappai.2021.104408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristics are powerful techniques for solving hard real-world problems in many application domains. Their behavior and performance strongly depend on their ability to efficiently explore and exploit the search space. A well-known metaheuristic is Ant Colony Optimization which has been successfully applied to solve many engineering problems. In this paper, we focus on ACO that solves Constraint Satisfaction Problems. In this context ACO has already shown to be able to solve many difficult CSPs, however, some problems are still very hard for this kind of technique. We introduce two strategies that allow improving ACO intensification and diversification process: one for learning in a pre-processing step and a second strategy to focus the search to a feasible space. Our results suggest that both the learning phase as well as the strategy to focus the search allow improving the ACO performance especially to solve hard CSPs. Moreover, these strategies can be applied to ACO for other application domains.},
  archive      = {J_EAAI},
  author       = {Nicolás Rojas-Morales and María-Cristina Riff and Bertrand Neveu},
  doi          = {10.1016/j.engappai.2021.104408},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104408},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning and focusing strategies to improve ACO that solves CSP},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessment of the running resistance of a diesel passenger
train using evolutionary bilevel algorithms and operational data.
<em>EAAI</em>, <em>105</em>, 104405. (<a
href="https://doi.org/10.1016/j.engappai.2021.104405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary bilevel algorithms are used for approximating the running resistance on the basis of the long-term fuel consumption data of a diesel passenger train in different routes. The input data comprises the geometry of these routes, speed and acceleration limits and certain engine properties. A running resistance is found for which the consumptions predicted by the model are equal to the logged consumptions of the vehicle for each of the routes in the training set. The model has been validated with simulated data with known properties and also with a diesel-hydraulic railcar operating on a 94 km route in northern Spain. The error in the running resistance estimation using evolutionary algorithms with respect to the measurement with a coasting test was less than 4%.},
  archive      = {J_EAAI},
  author       = {Luciano Sánchez and Pablo Luque and Daniel Álvarez},
  doi          = {10.1016/j.engappai.2021.104405},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104405},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Assessment of the running resistance of a diesel passenger train using evolutionary bilevel algorithms and operational data},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating method of pythagorean fuzzy sets from the
negation of probability. <em>EAAI</em>, <em>105</em>, 104403. (<a
href="https://doi.org/10.1016/j.engappai.2021.104403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy sets have been widely concerned due it can better deal with more complex and uncertain problems. To expand the application of fuzzy sets, Yager proposed Pythagorean fuzzy sets (PFS) which has been used in many fields. However, in the most cases, the PFS can be generated by expert assessment, which can limit the application of PFS. Hence, how to reasonably generate Pythagorean fuzzy number from known information is a problem worthy of discussion. The paper proposed a method to generate the Pythagorean fuzzy number by considering the negation of probability, namely Pythagorean fuzzy sets based on negation (NPFS). The probability and the probability after negation can be understood as membership and non-membership in the Pythagorean fuzzy number. Besides, NPFS is also set the connection between probability and PFS. There are some numerical examples used to explain the proposed NPFS. In order to explore the effectiveness of NPFS, the paper can not only apply NPFS to artificial decision-making, but also to data-driven applications, which used to handle the multi-criterion decision making (MCDM) and classification problems. In MCDM, the paper applied the NPFS into TOPSIS and used the fault diagnosis to verify its effectiveness by comparing with the results of probability. In the application of classification, the paper proposed the classification method based on NPFS and used real world data to verify the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Xiaozhuan Gao and Yong Deng},
  doi          = {10.1016/j.engappai.2021.104403},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104403},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Generating method of pythagorean fuzzy sets from the negation of probability},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Short-term dependency of a class of nonlinear continuous
time dynamic systems. <em>EAAI</em>, <em>105</em>, 104402. (<a
href="https://doi.org/10.1016/j.engappai.2021.104402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic systems usually have long-term dependency. Recent work, however, shows that the long-term memory models like recurrent neural networks and short-term memory models like feed-forward neural networks have comparable performance in approximating the behavior of dynamic systems. While the pioneering researchers try to understand the short-term dependency in discrete time dynamic systems, this paper focuses on a class of continuous time dynamic systems characterized by ordinary differential equations. In this class of continuous time dynamic systems, only the variable can be observed, and its derivatives with respect to time cannot be measured directly. By analyzing the observability of the continuous time dynamic systems and the sampled systems, we show that the current output only depends on finite steps of history information when sampling fast. If the sampling is fast enough such that the Euler approximation can approximate the sampled system well, the current output only relies on the most recent n steps of history information. Here, n is the order of the ordinary differential equation. Later, we verified our results with the NARMAX method.},
  archive      = {J_EAAI},
  author       = {Jieming Sun and Lichun Li},
  doi          = {10.1016/j.engappai.2021.104402},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104402},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Short-term dependency of a class of nonlinear continuous time dynamic systems},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning from experience for rapid generation of local car
maneuvers. <em>EAAI</em>, <em>105</em>, 104399. (<a
href="https://doi.org/10.1016/j.engappai.2021.104399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Being able to rapidly respond to the changing scenes and traffic situations by generating feasible local paths is of pivotal importance for car autonomy. We propose to train a deep neural network (DNN) to plan feasible and nearly-optimal paths for kinematically constrained vehicles in a small constant time. Our DNN model is trained using a novel weakly supervised approach and a gradient-based policy search. On real and simulated scenes and a large set of local planning problems, we demonstrate that our approach outperforms the existing planners with respect to the number of successfully completed tasks. While the path generation time is about 40 ms, the generated paths are smooth and comparable to those obtained from conventional path planners.},
  archive      = {J_EAAI},
  author       = {Piotr Kicki and Tomasz Gawron and Krzysztof Ćwian and Mete Ozay and Piotr Skrzypczyński},
  doi          = {10.1016/j.engappai.2021.104399},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104399},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning from experience for rapid generation of local car maneuvers},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging effectiveness and efficiency in page stream deep
segmentation. <em>EAAI</em>, <em>105</em>, 104394. (<a
href="https://doi.org/10.1016/j.engappai.2021.104394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The separation of documents contained in a page stream is a critical activity in some segments. That is the case of the Brazilian judiciary system since it is overwhelmed with files resulting from batch scanning of lawsuits, finishing in PDFs containing several types of mixed documents. To make such a file usable, we must divide it into cohesive sets of pages that result in a single piece. The typical approach to this task involves sorting the page into a stream that reveals the transition between documents. That is, it is about identifying the page that highlights a new piece in the stream. For this task, classification methods combining text and image got the best results, obtaining accuracy and kappa scores respectively of 91.9% and 83.1% in the Tobacoo800 dataset. This outcome, although remarkable, requires excessive computational demand. In this work, by changing the entry of image models and employing a novel labeling system, we achieved the same result, without the overhead that the modal text imposes on the solution. In addition, we built a new public dataset called AI.Lab.Splitter specifically aimed at page stream segmentation task with more than 30k labeled samples. Finally, in addition to VGG, we used EfficientNet, whose number of parameters is 1/6 of the former. We could observe an advantage close to 2.5% in f1 score, compared to the same proposal using VGG in our dataset.},
  archive      = {J_EAAI},
  author       = {Fabricio Ataides Braz and Nilton Correia da Silva and Jonathan Alis Salgado Lima},
  doi          = {10.1016/j.engappai.2021.104394},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104394},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Leveraging effectiveness and efficiency in page stream deep segmentation},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rule-based space characterization for rumour detection in
health. <em>EAAI</em>, <em>105</em>, 104389. (<a
href="https://doi.org/10.1016/j.engappai.2021.104389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Last decades have witnessed a radical change in the way information spreads. Social networks provide a constantly updated pool of news to the end-users but the absence of systematic control and moderation of the posts easily leads to spread unverified news with an instrumental value and likely to be dangerous, which are referred to as rumours. To tackle this issue various systems for automatic rumour detection among conversations, i.e. an aggregated set of posts, have been recently presented in the literature. However, few efforts have been directed towards rumour detection at the level of single posts (micro-level), which is the challenging scenario that we tackle in this work. Moving at a finer scale is an urgent need since both rumour and non-rumour posts are included in the same conversation. Here the rumour detection issue is addressed presenting a novel feature selection approach, which characterizes the feature space aiming at minimizing samples in unreliable configurations. This approach is compared with other state-of-the-art methods using a pool of different learning algorithms on two health-related Twitter datasets, labelled at the micro-level. Our proposal yields promising results: it outperforms other feature selection approaches with a best accuracy of 96.8% and enhances the performance of our previous work up to 5%. These findings prove the potential of the feature selection method introduced, which gives access to samples distribution in the feature space, providing privileged information for the construction of the classifier decision boundaries. Nonetheless they also bring a step forward the micro-level rumour detection analysis.},
  archive      = {J_EAAI},
  author       = {Rosa Sicilia and Mario Merone and Roberto Valenti and Paolo Soda},
  doi          = {10.1016/j.engappai.2021.104389},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104389},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Rule-based space characterization for rumour detection in health},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wafer map defect recognition based on deep transfer
learning-based densely connected convolutional network and deep forest.
<em>EAAI</em>, <em>105</em>, 104387. (<a
href="https://doi.org/10.1016/j.engappai.2021.104387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complexity and dynamics of the semiconductor manufacturing processes, wafer maps will present various defect patterns caused by various process faults. Identification of those defect patterns on wafer maps can help operators in finding out root-causes of abnormal processes, and then ensures that the manufacturing process is restored to the normal state as soon as possible. This paper proposes a wafer map defect recognition (WMDR) model based on integration of deep transfer learning and deep forest. Firstly, we transfer the network weight parameters of ImageNet to the convolutional neural network (CNN) (i.e., densely connected convolutional network (DenseNet)) and redesign the classification layer. This reduces the training time and then improves feature learning performance of DenseNet. Moreover, the transfer learning-based feature learning is able to solve class imbalance of wafer defect patterns. Finally, deep forest is utilized to identify the wafer defect pattern based on the abstract features from the wafer maps extracted by DenseNet. The experimental results on an industrial case show that the method can effectively improve WMDR performance and outperforms those well-known CNNs and other typical classifiers.},
  archive      = {J_EAAI},
  author       = {Jianbo Yu and Zongli Shen and Shijin Wang},
  doi          = {10.1016/j.engappai.2021.104387},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {10},
  pages        = {104387},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Wafer map defect recognition based on deep transfer learning-based densely connected convolutional network and deep forest},
  volume       = {105},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation of connected driving in hazardous weather
conditions: General and extensible multiagent architecture and models.
<em>EAAI</em>, <em>104</em>, 104412. (<a
href="https://doi.org/10.1016/j.engappai.2021.104412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on historical records, driving in hazardous weather conditions is one of the most serious causes that lead to fatal accidents on roads in general and in United Arab Emirates (UAE) highways in particular. One solution for improving road safety is to equip the vehicles and infrastructure with connected and smart devices. Before deploying a concrete solution to the field, it must be validated by simulation, and more specifically agent-based simulation. Several key features are expected for the simulation framework, such as the reproduction of different and detailed behaviors for the components of the road infrastructure and for the drivers, simulate specific weather conditions and forecast their impacts on the global system behavior. Additionally, several technological features are related to recent advancements in agent software engineering and simulation. This paper proposes an agent-based model for the modeling and simulation of traffic in foggy weather conditions that covers the above features and technological requirements. The architecture is used and validated on two scenarios of traffic on UAE highways in foggy weather conditions. The first scenario does not include an intelligent transport system, and the second considers smart speed limit panels. From the experiments, the proposed model supports the expected key features, i.e., microscopic simulation of intelligent transport systems, including infrastructure and connected cars, and of different driving behaviors (human or autonomous car). Even if the included weather condition model is basic, a proof of concept is provided regarding the connection of an agent model and a weather condition model.},
  archive      = {J_EAAI},
  author       = {Fatma Outay and Stéphane Galland and Nicolas Gaud and Abdeljalil Abbas-Turki},
  doi          = {10.1016/j.engappai.2021.104412},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104412},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Simulation of connected driving in hazardous weather conditions: General and extensible multiagent architecture and models},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). More intelligent and robust estimation of battery
state-of-charge with an improved regularized extreme learning machine.
<em>EAAI</em>, <em>104</em>, 104407. (<a
href="https://doi.org/10.1016/j.engappai.2021.104407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-charge (SOC) is the key parameter for battery management, and the accurate estimation of SOC is pretty important for the safe and stable operation of lithium batteries. This paper investigates a regularized extreme learning machine trained with the spectral Fletcher–Reeves algorithm and tuned with the beetle antennae search algorithm (BAS-SFR-RELM) for intelligent and robust SOC estimation. In the experiment section, the urban dynamometer driving schedule (UDDS) profile and the Los Angeles 92 (LA92) profile are performed on a battery test platform for data collection. In the simulation section, the root mean squared error (RMSE) and the mean absolute error (MAE) are adopted to evaluate the performance of the model. Compared with the linear regression (LR), the back propagation (BP) network, the multi-layer perceptron (MLP), and the long short-term memory (LSTM) network, the BAS-SFR-RELM method can efficiently obtain the optimal regularization coefficient to effectively prevent overfitting with faster convergence speed. Increasing the number of hidden neurons in the BAS-SFR-RELM appropriately can improve the SOC estimation precision. Implementing the BAS-SFR-RELM with the noise-added data set gives high robustness for SOC estimation},
  archive      = {J_EAAI},
  author       = {Meng Jiao and Dongqing Wang and Yan Yang and Feng Liu},
  doi          = {10.1016/j.engappai.2021.104407},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104407},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {More intelligent and robust estimation of battery state-of-charge with an improved regularized extreme learning machine},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An insight into crash avoidance and overtaking advice
systems for autonomous vehicles: A review, challenges and solutions.
<em>EAAI</em>, <em>104</em>, 104406. (<a
href="https://doi.org/10.1016/j.engappai.2021.104406">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergence of communication technologies made the automotive industries across the globe to embrace Advanced Driver Assistance Systems (ADAS) by considerable investments to ensure accident-free travel, reduction of pollution, fuel conservation. ADAS achieves its goals by integrating complex subsystems such as obstacle avoidance, overtaking advice, lane changing assistance, planning shortest routes, parking assistance, automatic gear shifting, etc., using the emerging technologies. This article emphasizes the road safety aspect of the ADAS by exploring Crash Avoidance and Overtaking Advice (CAOA) subsystems. Existing studies have a noticeable lack of connectivity between various aspects of CAOA subsystems. This review deeply explores and connects CAOA subsystems like road geometries, road debris, obstacle avoidance algorithms powered by Artificial Intelligence (AI), overtaking advice systems, perception challenges of human drivers in various light and weather conditions, driver inattention and misjudgments, vehicle blind-spots, vehicle parameter analysis, performance of vision sensors, in-vehicle computers, driver–vehicle interactions, Vehicle to Infrastructure (V2I) technologies. This article emphasizes the three primary performance metrics of the ADAS, namely accuracy, response time and robustness. Finally, this article discusses a typical functional architecture and gaps identified in existing studies. This article is structured to assist like-minded researchers, who work on CAOA systems for road safety.},
  archive      = {J_EAAI},
  author       = {P. Shunmuga Perumal and M. Sujasree and Suresh Chavhan and Deepak Gupta and Venkat Mukthineni and Soorya Ram Shimgekar and Ashish Khanna and Giancarlo Fortino},
  doi          = {10.1016/j.engappai.2021.104406},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104406},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An insight into crash avoidance and overtaking advice systems for autonomous vehicles: A review, challenges and solutions},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group of components detection in engineering drawings based
on graph matching. <em>EAAI</em>, <em>104</em>, 104404. (<a
href="https://doi.org/10.1016/j.engappai.2021.104404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer-aided design (CAD) applications are paramount tools to inspect piping and instrumentation diagrams (P&amp;ID) that represent the structure and functionality of oil and gas facilities. These tools allow engineers to navigate along the P&amp;IDs and facilitate their inspection and maintenance tasks. Usually, these applications allow the user to search components for their identity or label. For instance, searching component I D − 2354 or the components with V a l v e label. Nevertheless, sometimes, engineers wish to search for a group of components that has a specific structure or similar to it. For example, they want to detect the appearances of structures that include a v a l v e c h e c k connected to two g e n e r a l v a l v e s and a b u t t e r f l y v a l v e . This paper proposes a method, based on the graph matching theory, that solves this problem. The computational complexity to detect the appearance of a component in a P&amp;ID is linear with respect to the number of components whereas the computational complexity to detect similar structures is exponential. For this reason, heuristic algorithms have to be used. The aim of this work is to add this functionality to a CAD application.},
  archive      = {J_EAAI},
  author       = {Elena Rica and Susana Álvarez and Francesc Serratosa},
  doi          = {10.1016/j.engappai.2021.104404},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104404},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Group of components detection in engineering drawings based on graph matching},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tacho-less sparse CNN to detect defects in rotor-bearing
systems at varying speed. <em>EAAI</em>, <em>104</em>, 104401. (<a
href="https://doi.org/10.1016/j.engappai.2021.104401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic identification of bearing and rotor defects, when operated at varying speed is challenging. To make this challenging task possible, a tacho-less deep learning model is developed which can effectively learn, even from small data set. For accurate learning from small data set, existing CNN is made sparse. Sparsity is incorporated in the CNN by adding newly developed sparsity cost in the existing cost function of CNN to enhance the learning capability of CNN. The method works in the following steps. First, vibration signals are processed with Fourier synchro squeezed transform (FSST) to obtain tachometer information. The extracted tachometer information is used to change the time domain signal to angular domain signal. Second, wavelet transform of angular domain signals is carried out to produce time–frequency images. Third, time–frequency images of angular domain signals are applied to the improved version of CNN. After learning, time–frequency images obtained from angular domain signals of defective bearings and rotor are applied to detect defects. The defect identification accuracy attained by the proposed method is 96.6 %. This accuracy is higher as compared to the accuracy achieved by the methods used in existing works. This has been made possible due to sparsity cost functions assimilated in the cost function of CNN that evade avoidable activation of neurons in the feature extraction layers of CNN, which makes the learning of modified CNN becomes deeper in comparison to existing CNN.},
  archive      = {J_EAAI},
  author       = {Anil Kumar and Govind Vashishtha and C.P. Gandhi and Hesheng Tang and Jiawei Xiang},
  doi          = {10.1016/j.engappai.2021.104401},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104401},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Tacho-less sparse CNN to detect defects in rotor-bearing systems at varying speed},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A location conversion method for roads through deep
learning-based semantic matching and simplified qualitative direction
knowledge representation. <em>EAAI</em>, <em>104</em>, 104400. (<a
href="https://doi.org/10.1016/j.engappai.2021.104400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Qualitative direction knowledge that appears in natural language descriptions of road-related locations could point to the interior of individual roads or associate multiple roads. Interpreting such descriptions to perform location conversion for roads will support intelligent road-related location services. Existing geocoding technologies could perform textual or semantic matching to transform road names to spatial locations, and research on qualitative direction reasoning could perform efficient location conversion based on semantic queries of qualitative direction knowledge between roads. However, research on geocoding lacks the consideration of matching the described internal direction knowledge of a road to a part of the road. Moreover, efficient location conversion based on semantic queries cannot scale to large road datasets due to the retrieval efficiency of a large amount of qualitative direction knowledge between roads. To accomplish this goal, this study proposes a location conversion method for roads, wherein a road ontology is designed to model the interior direction knowledge of the roads, a deep learning-based road semantic matching model is trained to match the internal direction knowledge descriptions and road segments, and a simplified qualitative direction knowledge representation between roads is performed to support rapid location conversion between roads based on efficient semantic queries. The proposed method was implemented on a road dataset of New York State. The results demonstrate that the proposed method can be effectively applied in road location conversion based on descriptions that contain qualitative direction knowledge inside individual roads or between multiple roads, which expands the scope of artificial intelligence applications.},
  archive      = {J_EAAI},
  author       = {Ruozhen Cheng and Jing Chen},
  doi          = {10.1016/j.engappai.2021.104400},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104400},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A location conversion method for roads through deep learning-based semantic matching and simplified qualitative direction knowledge representation},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fair classification via monte carlo policy gradient method.
<em>EAAI</em>, <em>104</em>, 104398. (<a
href="https://doi.org/10.1016/j.engappai.2021.104398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence is steadily increasing its impact on everyday life. Therefore, the societal issues of artificial intelligence have become an important concern in the AI research. The presence of data that reflects human biases towards historically discriminated groups defined by sensitive features such as race and gender, results in machine learning models which discriminate against these groups. In order to tackle the impact of bias in data, researchers developed a variety of specialized machine learning algorithms which are able to satisfy different fairness constraints imposed on the model. Group fairness constraints do not fit standard machine learning formulations easily due to their non-differentiable nature. In this paper we developed a technique for learning a fair classifier by Monte Carlo policy gradient method which naturally deals with such non-differentiable constraints. Our methodology focuses on direct optimization of both group fairness metric and predictive performance of the model. In addition, we propose two different variance reduction techniques of gradient estimation. We compare our models to seven other related and state-of-the-art models and demonstrate that they are able to achieve better trade-off between accuracy and unfairness. To the best of our knowledge, this is the first fair classification algorithm which solves the issue of non-differentiable constraints by reinforcement learning techniques.},
  archive      = {J_EAAI},
  author       = {Andrija Petrović and Mladen Nikolić and Miloš Jovanović and Miloš Bijanić and Boris Delibašić},
  doi          = {10.1016/j.engappai.2021.104398},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104398},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fair classification via monte carlo policy gradient method},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EEEA-net: An early exit evolutionary neural architecture
search. <em>EAAI</em>, <em>104</em>, 104397. (<a
href="https://doi.org/10.1016/j.engappai.2021.104397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goals of this research were to search for Convolutional Neural Network (CNN) architectures, suitable for an on-device processor with limited computing resources, performing at substantially lower Network Architecture Search (NAS) costs. A new algorithm entitled an Early Exit Population Initialisation (EE-PI) for Evolutionary Algorithm (EA) was developed to achieve both goals. The EE-PI reduces the total number of parameters in the search process by filtering the models with fewer parameters than the maximum threshold. It will look for a new model to replace those models with parameters more than the threshold. Thereby, reducing the number of parameters, memory usage for model storage and processing time while maintaining the same performance or accuracy. The search time was reduced to 0.52 GPU day. This is a huge and significant achievement compared to the NAS of 4 GPU days achieved using NSGA-Net, 3,150 GPU days by the AmoebaNet model, and the 2,000 GPU days by the NASNet model. As well, Early Exit Evolutionary Algorithm networks (EEEA-Nets) yield network architectures with minimal error and computational cost suitable for a given dataset as a class of network algorithms. Using EEEA-Net on CIFAR-10, CIFAR-100, and ImageNet datasets, our experiments showed that EEEA-Net achieved the lowest error rate among state-of-the-art NAS models, with 2.46% for CIFAR-10, 15.02% for CIFAR-100, and 23.8% for ImageNet dataset. Further, we implemented this image recognition architecture for other tasks, such as object detection, semantic segmentation, and keypoint detection tasks, and, in our experiments, EEEA-Net-C2 outperformed MobileNet-V3 on all of these various tasks. (The algorithm code is available at https://github.com/chakkritte/EEEA-Net ).},
  archive      = {J_EAAI},
  author       = {Chakkrit Termritthikun and Yeshi Jamtsho and Jirarat Ieamsaard and Paisarn Muneesawang and Ivan Lee},
  doi          = {10.1016/j.engappai.2021.104397},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104397},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EEEA-net: An early exit evolutionary neural architecture search},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A density-based evolutionary clustering algorithm for
intelligent development. <em>EAAI</em>, <em>104</em>, 104396. (<a
href="https://doi.org/10.1016/j.engappai.2021.104396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the clustering mechanism of human cognitive development, this paper proposes a density-based evolutionary clustering algorithm based on incremental data (DBEC). The DBEC algorithm is developed from a zero sample state without prior knowledge, and the control parameter can evolve as the number of samples increases, which simulates the human cognitive development process structurally. Furthermore, we propose conservative, robust, and radical DBEC algorithms based on different combinations of strategies. These three types of DBEC algorithms have different characteristics, and can find various clustering attributes of the samples to be clustered. Finally, we analyse the performance of three types of DBEC algorithms and compare their result with those of other popular clustering algorithms on the datasets in the experiment. The results show the effectiveness of DBEC algorithms.},
  archive      = {J_EAAI},
  author       = {Haibin Xie and Peng Li},
  doi          = {10.1016/j.engappai.2021.104396},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104396},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A density-based evolutionary clustering algorithm for intelligent development},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Picture fuzzy set and quality function deployment approach
based novel framework for multi-criteria group decision making method.
<em>EAAI</em>, <em>104</em>, 104395. (<a
href="https://doi.org/10.1016/j.engappai.2021.104395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality function deployment (QFD) translates customers’ requirements into product design requirements for improving quality and design of the product. Very often, customers’ requirements are uncertain because of imprecision and linguistic representation. Many researchers have integrated fuzzy set (FS) and intuitionistic fuzzy set (IFS) with QFD to model uncertainty in the preferences of customers’ requirements due to imprecision and vagueness. Since picture fuzzy set (PFS) which is an extension of IFS, has been proved more ideal than fuzzy and intuitionistic fuzzy set in modeling of fuzziness and uncertainty in real life problem of decision making, we have integrated QFD with PFS to propose a multi-criteria group decision making (MCGDM) method. Present study contributes a MCGDM method that uses prominent characteristic of QFD in the integration of heterogeneous preferences of decision makers by splitting them into groups of users and analysts. Positive, negative and no correlations among engineering criteria without normalization in QFD is used in proposed MCGDM method to obtain more precise overall relationship matrix and hence final ranking of alternatives. Feasibility and suitability of proposed MCGDM method is verified by using it on a real case study of ranking of Facebook, Instagram, WhatsApp and Twitter in which users are taken as decision makers.},
  archive      = {J_EAAI},
  author       = {Akanksha Singh and Sanjay Kumar},
  doi          = {10.1016/j.engappai.2021.104395},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104395},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Picture fuzzy set and quality function deployment approach based novel framework for multi-criteria group decision making method},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid adaptive learning neural network control for
steer-by-wire systems via sigmoid tracking differentiator and
disturbance observer. <em>EAAI</em>, <em>104</em>, 104393. (<a
href="https://doi.org/10.1016/j.engappai.2021.104393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Steer-by-Wire (SbW) systems are usually affected negatively by the friction torque and self-aligning torque. This paper proposes a hybrid learning neural network controller to achieve precise control for the SbW system. Firstly, a sigmoid tracking differentiator (STD) is introduced to obtain the velocity signal with the angle measurement only. Secondly, by combining the model-free technology, the neural network is applied to overcome the lumped uncertainty including the friction torque and self-aligning torque. Different from the related literature, a second-order identification model is designed to construct the learning law so that the neural network can be adjusted by the tracking error and modeling error simultaneously. Finally, a disturbance observer is proposed for the compensation of compound disturbance including the external disturbance and neural network approximated error. The advantages are that the proposed control scheme not only ensures good tracking performance using the least sensors but also can handle uncertainty and attenuate measurement noise. Lyapunov stability theory proves that the tracking error is uniformly ultimately bounded. Numerical simulations and experiments show the effectiveness and superiorities of the proposed control method.},
  archive      = {J_EAAI},
  author       = {Yunlong Wang and Yongfu Wang and Ming Tie},
  doi          = {10.1016/j.engappai.2021.104393},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104393},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid adaptive learning neural network control for steer-by-wire systems via sigmoid tracking differentiator and disturbance observer},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decision-making model of machine tool remanufacturing
alternatives based on dual interval rough number clouds. <em>EAAI</em>,
<em>104</em>, 104392. (<a
href="https://doi.org/10.1016/j.engappai.2021.104392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remanufacturing of machine tools has become one of the crucial topical subjects as it can effectively reduce the manufacturing cost compared with traditional new product development. The assessment and selection of different remanufacturing alternatives are vital for successfully implementing the remanufacturing of machine tools. Although numerous fuzzy theory-based methods have been developed to evaluate and select the reasonable remanufacturing alternatives in the machine tool remanufacturing process, they still have some drawbacks, such as requiring extra assumptions, ignoring the impact of internal relationships among distinct criteria, and lacking the mechanism of manipulating diverse uncertain information. To cover such limitations, this study develops an applicable decision-making method to assist managers in extracting the essential remanufacturing alternatives for product improvement. First, a new concept named dual interval rough number clouds (DIRNCs) is developed by combining the merit of interval rough numbers (IRNs) and interval cloud model in handling uncertain information. Then, an applicable decision-making support model of remanufacturing alternatives is constructed based on DIRNCs, two non-linear weighting methods, and a technique for order performance by similarity to ideal solution (TOPSIS). Finally, an assessment of remanufacturing alternatives of machine tools is presented to illustrate the model, whose effectivity is demonstrated by comparing extant models. Results display that the developed DIRNC-based model is more advantageous than triangular fuzzy-based, cloud model-based, fuzzy rough-based, and IRN-based methods.},
  archive      = {J_EAAI},
  author       = {Guangquan Huang and Liming Xiao and Genbao Zhang},
  doi          = {10.1016/j.engappai.2021.104392},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104392},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Decision-making model of machine tool remanufacturing alternatives based on dual interval rough number clouds},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic pixel-level crack segmentation in images using
fully convolutional neural network based on residual blocks and pixel
local weights. <em>EAAI</em>, <em>104</em>, 104391. (<a
href="https://doi.org/10.1016/j.engappai.2021.104391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cracks are significant indicators for the evaluation of the structural health and monitoring process. However, manual crack detection is a time-consuming and challenging task due to large areas, complex structure, and safety risks. Deep learning has emerged as a useful technique to automate the crack detection and identification process. For balanced data, existing deep learning models attempt to segment both crack pixels and non-crack pixels equally. However, due to the highly imbalanced ratio between crack pixels and non-crack pixels, the pixel-wise loss is dominantly guided by the non-crack region and has relatively little influence from the crack region. This leads to the low segmentation accuracy for crack pixels. To address the imbalance problem, this work proposes a local weighting factor with a sensitivity map to remove the network biasness and accurately predict the sensitive pixels. Furthermore, we implement a deep fully convolutional neural network for crack pixel segmentation based on residual blocks with a different number of filters in each convolutional operation that segments the crack pixels and non-crack pixels with unbiased probabilities. For performance evaluation, a new Multi Structure Crack Image (MSCI) dataset is built. By using the MSCI dataset, the proposed method achieved 98.19% crack pixel accuracy and 98.13% non-crack pixel accuracy along with 98.16% average accuracy. In addition, the training time for 10 epochs has dramatically decreased and the experimental results show that the proposed crack segmentation network (CSN) architecture along with local weighting factor and sensitivity map has better crack pixel segmentation accuracy than U-Net and SegNet architectures.},
  archive      = {J_EAAI},
  author       = {Raza Ali and Joon Huang Chuah and Mohamad Sofian Abu Talip and Norrima Mokhtar and Muhammad Ali Shoaib},
  doi          = {10.1016/j.engappai.2021.104391},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104391},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automatic pixel-level crack segmentation in images using fully convolutional neural network based on residual blocks and pixel local weights},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approaching the social dilemma of autonomous vehicles with a
general social welfare function. <em>EAAI</em>, <em>104</em>, 104390.
(<a href="https://doi.org/10.1016/j.engappai.2021.104390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the social dilemma related to the trolley problem in ethics regarding the driving behavior of an autonomous vehicle (AV) when there are passengers in the AV and pedestrians on the street. To investigate the optimal driving behaviors in different concepts of values, we introduce a general social welfare function (SWF) into our model that encompasses the three types of Bentham- ( ρ = 0 ), Nash- ( ρ → 1 ), and Rawls-type ( ρ → ∞ ) SWFs as a special case. Parameter ρ is key and represents the inequality aversion. We first demonstrate that the optimal solution continuously and monotonically moves from ρ = 0 to ρ → ∞ . This result implies that the optimal solutions involving the Bentham- and Rawls-type SWFs are extreme (maximum or minimum value) solutions, whereas solutions involving the Nash-type SWF can be intermediate. Although some empirical studies have stated that it is better for a policymaker or AV manufacturer to employ Benthamism, our results suggest that care should be applied when choosing a driving behavior. Second, if the total utility of the passengers (or pedestrians) at the optimum is relatively large, our results indicate that the AV will likely go straight and hit the pedestrians (or swerve and crash into a wall) as ρ increases (or decreases). Finally, we discuss the applicability of our results in controlling AVs worldwide. We confirm that setting ρ = 0 is preferred in the U.S., Canada, Australia, and some Western European countries, whereas setting ρ &gt; 0 is preferred in some African and Asian countries, such as China, India, and Japan.},
  archive      = {J_EAAI},
  author       = {Takeshi Ebina and Keita Kinjo},
  doi          = {10.1016/j.engappai.2021.104390},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104390},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Approaching the social dilemma of autonomous vehicles with a general social welfare function},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From clustering to clustering ensemble selection: A review.
<em>EAAI</em>, <em>104</em>, 104388. (<a
href="https://doi.org/10.1016/j.engappai.2021.104388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering, as an unsupervised learning, is aimed at discovering the natural groupings of a set of patterns, points, or objects. In clustering algorithms, a significant problem is the absence of a deterministic approach based on which users can decide which clustering method best matches a given set of input data. This is due to using certain criteria for optimization. Clustering ensemble as a knowledge reuse offers a solution to solve the challenges inherent in clustering. It seeks to explore results of high stability and robustness by composing computed solutions achieved by base clustering algorithms without getting access to the features. Combining base clusterings together degrades the quality of the final solution when low-quality ensemble members are used. Several researchers in this field have suggested the concept of clustering ensemble selection for the aim of selecting a subset of base clustering based on quality and diversity. While clustering ensemble makes a combination of all ensemble members, clustering ensemble selection chooses a subset of ensemble members and forms a smaller cluster ensemble that performs better than the clustering ensemble. This survey includes the historical development of data clustering that makes an overview on basic clustering techniques, discusses clustering ensemble algorithms including ensemble generation mechanisms and consensus function, and point out clustering ensemble selection techniques with considering quality and diversity.},
  archive      = {J_EAAI},
  author       = {Keyvan Golalipour and Ebrahim Akbari and Seyed Saeed Hamidi and Malrey Lee and Rasul Enayatifar},
  doi          = {10.1016/j.engappai.2021.104388},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104388},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {From clustering to clustering ensemble selection: A review},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IP-cores watermarking scheme at behavioral level using
genetic algorithms. <em>EAAI</em>, <em>104</em>, 104386. (<a
href="https://doi.org/10.1016/j.engappai.2021.104386">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an improved watermarking scheme for soft Intellectual Property (IP) -Cores using Genetic Algorithms (GAs). For this purpose, a watermark signature and an IP-Core behavioral description are translated into Finite State Machines (FSMs). Both FSMs are merged in a single one containing a watermarked IP-Core without disrupting its original functionality. Therefore, we tackle NP-completeness of the subgraph isomorphism problem found during FSMs merging process via a tailored GA. However, not deeply embedded states are a key problem that may ease watermark’s removal. To overcome this issue, a FSM reduction algorithm is also considered in the proposed watermarking scheme. Moreover, the proposed scheme also targets transitions regrouping which impact the amount of hardware resources usage and a mechanism for selecting the best watermarked FSM. A thorough empirical assessment shows a significant improvement in terms of reduction and watermark embedding strength.},
  archive      = {J_EAAI},
  author       = {Jorge Echavarria and Alicia Morales-Reyes and René Cumplido and Miguel A. Salido and Claudia Feregrino-Uribe},
  doi          = {10.1016/j.engappai.2021.104386},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104386},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IP-cores watermarking scheme at behavioral level using genetic algorithms},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new solving function optimization problems
methods—resonance algorithm. <em>EAAI</em>, <em>104</em>, 104385. (<a
href="https://doi.org/10.1016/j.engappai.2021.104385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The chorus shows its unique charm with its beautiful harmony, uniform rhythm, colorful layers and free and precise pitch. If the Harmony is compared to the body and the Rhythm is like a bone, the Intonation will be the flesh and blood of this “elf”. This paper abstracts the chorus effect into a multivariate function, constructs the mathematical relationship between Intonation, Tempo, Harmony, Rhythm, and Intensity, A novel mathematical algorithm—Resonance Algorithm (RA) is proposed, which finds the optimal solution of the multivariate function in the chorus effect through the cooperation and information sharing between individuals in the group. In order to verify the correctness of the proposed method, the performance of RA algorithm is tested. Firstly, the ability to search for complex function is compared with GA, ACO, PSO, etc. The results show that RA has better ability to search for optimal value, and the accuracy of the optimal value is higher. Secondly, RA and PSO are not only combined with SVM and Gaussian process respectively, but also classification and data fitting are performed. The experimental results show that RA has the characteristics of adaptability and stability, no need to set parameters, and easy to implement.},
  archive      = {J_EAAI},
  author       = {WenXin Yu and WeiHong Xiao},
  doi          = {10.1016/j.engappai.2021.104385},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104385},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new solving function optimization problems methods—Resonance algorithm},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study on the use of edge TPUs for eye fundus image
segmentation. <em>EAAI</em>, <em>104</em>, 104384. (<a
href="https://doi.org/10.1016/j.engappai.2021.104384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation can be implemented using Deep Learning methods with fast and efficient segmentation networks. Single-board computers (SBCs) are difficult to use to train deep networks due to their memory and processing limitations. Specific hardware such as Google’s Edge TPU makes them suitable for real time predictions using complex pre-trained networks. In this work, we study the performance of two SBCs, with and without hardware acceleration for fundus image segmentation, though the conclusions of this study can be applied to the segmentation by deep neural networks of other types of medical images. To test the benefits of hardware acceleration, we use networks and datasets from a previous published work and generalize them by testing with a dataset with ultrasound thyroid images. We measure prediction times in both SBCs and compare them with a cloud based TPU system. The results show the feasibility of Machine Learning accelerated SBCs for optic disc and cup segmentation obtaining times below 25 ms per image using Edge TPUs.},
  archive      = {J_EAAI},
  author       = {Javier Civit-Masot and Francisco Luna-Perejón and José María Rodríguez Corral and Manuel Domínguez-Morales and Arturo Morgado-Estévez and Antón Civit},
  doi          = {10.1016/j.engappai.2021.104384},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104384},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A study on the use of edge TPUs for eye fundus image segmentation},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiscale domain adaption models and their application in
fault transfer diagnosis of planetary gearboxes. <em>EAAI</em>,
<em>104</em>, 104383. (<a
href="https://doi.org/10.1016/j.engappai.2021.104383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, various deep domain adaption (DDA) models, such as deep domain confusion (DDC) and deep adaption network (DAN), are proposed. These models can adapt a trained model in the source domain to new classification tasks in the target domain. However, these classical DDA models suffer from some inherent drawbacks. For example, traditional DDA models can output only one transfer feature (TF) with high dimension and fixed scales, thus possibly losing important information while performing domain confusion operation. Multiscale domain adaption (MSDA) is proposed in this paper to remold and improve the classical DDA models to solve the aforementioned problems. MSDA is a universally applicable strategy that can be embedded into most existing classical DDA models. An MSDA block is designed and constructed on the basis of multiscale convolution networks to replace the last convolutional layer of the original DDA model. The MSDA block has four parallel pipelines consisting of multiscale convolutional and global average pooling operations. Therefore, MSDA can extract more domain-invariant features than the original feature extractor, meanwhile the four low-dimension TFs can simplify the calculation of domain confusion losses. The four TFs are concatenated into a feature vector, and then it is input into the top classifier for fault identification. MSDA can be effectively applied to five classical DDA models and enhance their abilities of domain adaption. The effectiveness and advantage of the proposed MSDA are verified through 18 fault transfer diagnosis tasks of planetary gearboxes.},
  archive      = {J_EAAI},
  author       = {Qunwang Yao and Yi Qin and Xin Wang and Quan Qian},
  doi          = {10.1016/j.engappai.2021.104383},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104383},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multiscale domain adaption models and their application in fault transfer diagnosis of planetary gearboxes},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partially observable monte carlo planning with state
variable constraints for mobile robot navigation. <em>EAAI</em>,
<em>104</em>, 104382. (<a
href="https://doi.org/10.1016/j.engappai.2021.104382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous mobile robots employed in industrial applications often operate in complex and uncertain environments. In this paper we propose an approach based on an extension of Partially Observable Monte Carlo Planning (POMCP) for robot velocity regulation in industrial-like environments characterized by uncertain motion difficulties. The velocity selected by POMCP is used by a standard engine controller which deals with path planning. This two-layer approach allows POMCP to exploit prior knowledge on the relationships between task similarities to improve performance in terms of time spent to traverse a path with obstacles. We also propose three measures to support human-understanding of the strategy used by POMCP to improve the performance. The overall architecture is tested on a Turtlebot3 in two environments, a rectangular path and a realistic production line in a research lab. Tests performed on a C++ simulator confirm the capability of the proposed approach to profitably use prior knowledge, achieving a performance improvement from 0.7% to 3.1% depending on the complexity of the path. Experiments on a Unity simulator show that the proposed two-layer approach outperforms also single-layer approaches based only on the engine controller (i.e., without the POMCP layer). In this case the performance improvement is up to 37% comparing to a state-of-the-art deep reinforcement learning engine controller, and up to 51% comparing to the standard ROS engine controller. Finally, experiments in a real-world testing arena confirm the possibility to run the approach on real robots.},
  archive      = {J_EAAI},
  author       = {Alberto Castellini and Enrico Marchesini and Alessandro Farinelli},
  doi          = {10.1016/j.engappai.2021.104382},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104382},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Partially observable monte carlo planning with state variable constraints for mobile robot navigation},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Common and specific deep feature representation for
multimode process monitoring using a novel variable-wise weighted
parallel network. <em>EAAI</em>, <em>104</em>, 104381. (<a
href="https://doi.org/10.1016/j.engappai.2021.104381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal data are common in industrial processes because of switched operating conditions, varying feedstocks and changed product designs and so on. To guarantee process safety and improving process performance, a variable-wise weighted parallel stacked auto-encoder model is proposed for nonlinear multimode process monitoring. Considering the similarity and difference between multiple operating modes with complex process nonlinearities, mode-common and mode-specific deep features are parallelly extracted with the proposed new model. Since each variable distinctly contributes to the mode-common features, variable-wise weights are designed with an optimal transport distance between modes when the mode-common features are learned. Moreover, different from designing a unified monitoring index for all modes, three asymmetric indices are designed to not only trigger an alarm for an anomaly, but also indicate whether the anomaly is caused by mode-common factors, mode-specific factors or others. Thus, the real-time monitoring results, together with some diagnosis information are simultaneously presented. A numerical example and a real industry application are used to validate the monitoring efficacy of the proposed model.},
  archive      = {J_EAAI},
  author       = {Kai Wang and Zhiying Guo and Yalin Wang and Xiaofeng Yuan and Chunhua Yang},
  doi          = {10.1016/j.engappai.2021.104381},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104381},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Common and specific deep feature representation for multimode process monitoring using a novel variable-wise weighted parallel network},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new evidential similarity measurement based on tanimoto
measure and its application in multi-sensor data fusion. <em>EAAI</em>,
<em>104</em>, 104380. (<a
href="https://doi.org/10.1016/j.engappai.2021.104380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer evidence theory is a powerful fusion approach for reasoning under uncertain circumstances. However, unreasonable results will generate when utilizing Dempster’s combination rule to fuse highly conflicting evidence. How to accurately measure the conflict degree between two pieces of evidence is still a problem to be solved. To date, the method of conflict measurement has been proposed by many authors. Unfortunately, the effectiveness of these approaches is limited. In this paper, a new method of evidential similarity measurement is devised in the light of Tanimoto measurement to describe the inconsistency between bodies of evidence. Then, a novel evidential conflict measurement approach is presented in accordance with the evidential similarity measurement to quantify the conflict degree between bodies of evidence. It is analyzed and proved that the novel approach of evidential conflict measurement satisfies the property of conflict measures. Some numerical examples are given to demonstrate the efficacy and superiority of the proposed approach. Moreover, the validity of the proposed approach is evaluated by the application of target recognition.},
  archive      = {J_EAAI},
  author       = {Zhan Deng and Jianyu Wang},
  doi          = {10.1016/j.engappai.2021.104380},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104380},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new evidential similarity measurement based on tanimoto measure and its application in multi-sensor data fusion},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised anomaly detection for underwater gliders using
generative adversarial networks. <em>EAAI</em>, <em>104</em>, 104379.
(<a href="https://doi.org/10.1016/j.engappai.2021.104379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An effective anomaly detection system is critical for marine autonomous systems operating in complex and dynamic marine environments to reduce operational costs and achieve concurrent large-scale fleet deployments. However, developing an automated fault detection system remains challenging for several reasons including limited data transmission via satellite services. Currently, most anomaly detection for marine autonomous systems, such as underwater gliders, rely on intensive analysis by pilots. This study proposes an unsupervised anomaly detection system using bidirectional generative adversarial networks guided by assistive hints for marine autonomous systems with time series data collected by multiple sensors. In this study, the anomaly detection system for a fleet of underwater gliders is trained on two healthy deployment datasets and tested on other nine deployment datasets collected by a selection of vehicles operating in a range of locations and environmental conditions. The system is successfully applied to detect anomalies in the nine test deployments, which include several different types of anomalies as well as healthy behaviour. Also, a sensitivity study of the data decimation settings suggests the proposed system is robust for Near Real-Time anomaly detection for underwater gliders.},
  archive      = {J_EAAI},
  author       = {Peng Wu and Catherine A. Harris and Georgios Salavasidis and Alvaro Lorenzo-Lopez and Izzat Kamarudzaman and Alexander B. Phillips and Giles Thomas and Enrico Anderlini},
  doi          = {10.1016/j.engappai.2021.104379},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104379},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised anomaly detection for underwater gliders using generative adversarial networks},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BiS4EV: A fast routing algorithm considering charging
stations and preferences for electric vehicles. <em>EAAI</em>,
<em>104</em>, 104378. (<a
href="https://doi.org/10.1016/j.engappai.2021.104378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electric Vehicles (EVs) have grown in recent years as they have become a promising alternative to traditional fossil fuel-driven vehicles. As a result, new routing algorithms that consider both the locations of charging stations and the charging preferences of users are necessary to maintain urban traffic efficiency. This paper proposes a Constrained Route Planning (CRP) approach, called BiS4EV, to provide efficient route planning for EVs in large urban road networks. CRP is an NP-hard problem. BiS4EV introduces a two-layered structure to solve the CRP problem for EVs. In the first layer, BiS4EV integrates the locations of charging stations and the battery consumption on each road arc into a road network graph and proposes a fast routing algorithm that considers the constraints of battery capacity and charging preferences to find the shortest feasible path for EVs. The second layer incorporates charging policies to the obtained path, which forms a complete route plan for EVs. Such a two-layered method breaks down the complexity of the problem and avoids directly solving the entire NP-hard problem. We have proved the correctness of the proposed approach in theory, and the presented experimental results verified the efficiency and the effectiveness of BiS4EV from the practical aspect.},
  archive      = {J_EAAI},
  author       = {Ying Zhang and Bin Wu and Yao-Yi Chiang and Xin Zhang and Yuanchang Chen and Muyang Li and Fanyu Li},
  doi          = {10.1016/j.engappai.2021.104378},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104378},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BiS4EV: A fast routing algorithm considering charging stations and preferences for electric vehicles},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A meta-analysis of industry 4.0 design principles applied in
the health sector. <em>EAAI</em>, <em>104</em>, 104377. (<a
href="https://doi.org/10.1016/j.engappai.2021.104377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The approach of health 4.0 is driven out from the well-known industry 4.0. The goal of industry 4.0 is to bring a revolution in the manufacturing sector by digitization. The future of health management will become timelier and more personalized as new technologies will empower individuals to conduct their health monitoring by using cyber–physical systems. The design principles of industry 4.0 connect the physical and virtual world in real-time. Virtualization in health happens after the emergence of Information and Communication Technologies (ICT). For this 5G, the next-generation mobile network provides ambient intelligence for orchestration of medical services so that government and private companies can reconsider health prospects. These technological developments in healthcare, big data and industry 4.0 are individually attracting the huge attention of academics and industries. However, a detailed study of big data and industry 4.0 together concerning healthcare is still not present in the existing literature. The main contribution of this article is to present a meta-analytic approach to interpret, integrate and critically investigate the findings of original articles. This study expounds a novel approach for achieving effectual and comparable results related to the explained research problems. The results summarize about the standards used in main research directions, and existing deficiencies present in this area. The findings of this systematic literature review (SLR) can be helpful as future guidelines to researchers and practitioners working in the area of health 4.0 and related topics.},
  archive      = {J_EAAI},
  author       = {Amrita Sisodia and Rajni Jindal},
  doi          = {10.1016/j.engappai.2021.104377},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104377},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A meta-analysis of industry 4.0 design principles applied in the health sector},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual generation of pavement crack images based on
improved deep convolutional generative adversarial network.
<em>EAAI</em>, <em>104</em>, 104376. (<a
href="https://doi.org/10.1016/j.engappai.2021.104376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the problems associated with a small sample size during intelligent road detection, a virtual image set generation method for asphalt pavement cracks is proposed based on improved deep convolutional generative adversarial networks (DCGANs). First, a small set of sample crack images is collected and used as the basic image set to perform filtering, gamma transformation, and other processes, whereby crack feature recognition is enhanced. Second, a variational autoencoder (VAE) is used to encode real crack images. The latent variable values obtained from the VAE are provided as input to the DCGAN model generator, and the model hyperparameters are optimized. Subsequently, the adaptive moment estimation (Adam) optimizer is used to reoptimize the model and thereby improve the model convergence speed and generalization ability. The proposed method has the advantages of both VAE and DCGAN. Finally, a pavement crack classification detection model based on faster region convolutional neural network (Faster R-CNN) is used to evaluate the reliability of the generated crack images. The results show that the augmented dataset of the proposed method with the detection model has an average precision of 90.32%, which is higher than that of the conventional method evaluated using the same test dataset. The proposed method generates virtual crack images that are moderately identical to real ones, thereby solving the problem of insufficient image datasets of cracks in specific road sections. The method also provides data assurance for the intelligentization of pavement crack detection and the reduction of pavement maintenance costs.},
  archive      = {J_EAAI},
  author       = {Lili Pei and Zhaoyun Sun and Liyang Xiao and Wei Li and Jing Sun and He Zhang},
  doi          = {10.1016/j.engappai.2021.104376},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104376},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Virtual generation of pavement crack images based on improved deep convolutional generative adversarial network},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A population-based iterated greedy algorithm to minimize
total flowtime for the distributed blocking flowshop scheduling problem.
<em>EAAI</em>, <em>104</em>, 104375. (<a
href="https://doi.org/10.1016/j.engappai.2021.104375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the distributed blocking flowshop scheduling problem (DBFSP) which is a meaningful generalization of the blocking flowshop scheduling problem in the distributed production environment. The objective of minimizing the total flowtime is relevant and important in the current dynamic manufacturing environment, but, as far as we know, it has not been investigated in the DBFSP previously. In this paper, a population-based iterated greedy (PBIG) algorithm is proposed to solve the DBFSP with the total flowtime criterion, which takes the advantage of both the population-based search approach and the iterated greedy algorithm. First, an effective constructive heuristic is proposed by integrating two existing constructive approaches to initialize the population with a high level of quality and diversity. Second, three different procedures to generate the offspring solutions are tested for the effective exploration capability, each of which rationally combines the destruction, reconstruction and selection operator. Third, the insertion neighborhood and swap neighborhood are investigated to enhance the local exploitation ability and a hybrid local search procedure that utilizes simultaneously both the two neighborhoods are proposed. The comprehensive experimental evaluation based on a total of 720 well-known instances shows that the proposed algorithms outperform the existing effective algorithms at a significant margin.},
  archive      = {J_EAAI},
  author       = {Shuai Chen and Quan-Ke Pan and Liang Gao and Hong-yan Sang},
  doi          = {10.1016/j.engappai.2021.104375},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104375},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A population-based iterated greedy algorithm to minimize total flowtime for the distributed blocking flowshop scheduling problem},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Photovoltaic cell model parameter optimization using
micro-charge field effect p systems. <em>EAAI</em>, <em>104</em>,
104374. (<a
href="https://doi.org/10.1016/j.engappai.2021.104374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building a highly accurate model for photovoltaic (PV) cells based on actual sampled data is essential for the simulation, optimization, evaluation, and control of photovoltaic power generation systems. But finding globally optimal model parameters, which give the best fit to experimental data, is a great challenge. In this paper, a new optimization algorithm, called the micro-charge field effect P systems optimization algorithm (MFE-POA) is proposed. Though the analysis of the interaction among ionic substances inside a living cell membrane and considering the algorithm’s dual needs of exploration and convergence accuracy, combined with the law of interaction between charges, we designed a novel micro-charge interaction rule based on distance, force characteristics, spatial location, and percentage of search completion, and embedded it into our existing P systems optimization algorithm (POA). Numerical studies and results analysis on some benchmark test functions demonstrate that MFE-POA can produce solutions of high quality and has great stability. The proposed method is applied to the model parameter estimation of the two types of PV cell models and multi-cell PV modules in different environmental conditions. The experimental results clearly argue the effectiveness of our proposed MFE-POA. Comparisons with other methods are presented and the results show that the proposed optimization algorithm is helpful and worth great promoting for parameter estimation in renewable energy modeling and prediction.},
  archive      = {J_EAAI},
  author       = {Shipin Yang and Nelson Max and Shengdong Xie and Lijuan Li and Tingting Zhao},
  doi          = {10.1016/j.engappai.2021.104374},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104374},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Photovoltaic cell model parameter optimization using micro-charge field effect p systems},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new efficient biased random key genetic algorithm for open
shop scheduling with routing by capacitated single vehicle and makespan
minimization. <em>EAAI</em>, <em>104</em>, 104373. (<a
href="https://doi.org/10.1016/j.engappai.2021.104373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the last years, researchers have been paying particular attention to scheduling problems integrating production environments and distribution systems to adopt more realistic assumptions. This paper aims to present a new biased random key genetic algorithm with an iterated greedy local search procedure (BRKGA-IG) for open shop scheduling with routing by capacitated vehicles. We propose approximation and exact algorithms to obtain high-quality solutions in acceptable computational times. This paper presents a new integer linear programming model. The proposed integer model has not been addressed in the revised literature. The objective function adopted is makespan minimization, and we use the relative deviation as performance criteria. BRKGA-IG has a new decoding scheme for OSSP-VRP solutions, an intensive exploitation mechanism with an iterated greedy local search procedure, and a restart mechanism to reduce premature population convergence. With these new mechanisms, the extensive computational experience carried out shows that the proposed metaheuristic BRKGA-IG is promising in solving large-sized instances for the new proposed problem, outperforming all other tested methods.},
  archive      = {J_EAAI},
  author       = {Levi R. Abreu and Roberto F. Tavares-Neto and Marcelo S. Nagano},
  doi          = {10.1016/j.engappai.2021.104373},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104373},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new efficient biased random key genetic algorithm for open shop scheduling with routing by capacitated single vehicle and makespan minimization},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective scheduling technique based on hybrid
hitchcock bird algorithm and fuzzy signature in cloud computing.
<em>EAAI</em>, <em>104</em>, 104372. (<a
href="https://doi.org/10.1016/j.engappai.2021.104372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the number of requests in the cloud increases, providers face more problems (e.g., task scheduling and resource management). The exhaustive search for determining the optimal solutions of scheduling problem is usually impractical and hence metaheuristic algorithms have been widely used to evolve solutions for task scheduling. In this paper, we firstly propose a hybrid meta-heuristic algorithm called Hybrid Fuzzy Hitchcock Bird (HFHB) and second, a multi-objective form of HFHB (MOHFHB) is introduced to solve multi-objective problems (e.g., task scheduling). The HFHB algorithm consists of three main enhancements: (a) The first random population of birds is improved, (b) The attack regulator parameter is set with a fuzzy Sugeno-signature, and (c) The dead birds are replaced with new birds. In multi-objective form (MOHFHB), two concepts (i.e., crowding distance and ranking non-dominated solution) are added to determine the optimal Pareto front. In the first part, HFHB and MOHFHB are evaluated as two global optimizers. In the second part, HFHB and MOHFHB are evaluated for a task scheduling problem against Moth Search Algorithm with DE (MSDE), Enhanced Multi-Verse Optimizer (EMVO), Fuzzy Modified Particle Swarm Optimization (FMPSO), and Simulated-annealing-based Bees Algorithm (SBA). The results indicate that HFHB improves makespan by 12.57%, 38.61%, and 35.75%, and resource utilization by 1.14%, 7.30%, and 5.25% compared to FMPSO, MSDE, and EMVO, respectively.},
  archive      = {J_EAAI},
  author       = {B. Mohammad Hasani Zade and N. Mansouri and M.M. Javidi},
  doi          = {10.1016/j.engappai.2021.104372},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104372},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective scheduling technique based on hybrid hitchcock bird algorithm and fuzzy signature in cloud computing},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asynchronous observer design for switched t–s systems with
unmeasurable premises and switching mismatches. <em>EAAI</em>,
<em>104</em>, 104371. (<a
href="https://doi.org/10.1016/j.engappai.2021.104371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the design of asynchronous switched observers for continuous-time nonlinear switched systems, where Takagi–Sugeno fuzzy models represents the nonlinear modes, with mismatching switching laws and bounded output disturbances (e.g. representing measurement bias, noise or fault). The proposed switched T–S observers allow state estimations when the systems’ premise variables are not necessarily measurable and when the observer’s active switched-mode does not necessarily match the one of the switched system. To derive the design conditions, a multiple Lyapunov function candidate is considered to cope with the asynchronous switching modes, together with a H ∞ criterion to minimize the transfer between the output disturbance and the state estimation errors. Moreover, Lipschitz constraints are considered to cope with the unmeasurable premise variables. The proposed conditions are declined into four theorems as Linear Matrix Inequalities. Despite their increasing computational cost, these theorems bring successive conservatism improvements, allowing the users to select the appropriate conditions regarding to the complexity of their applications. Finally, an academic example and a practical one (dealing with a tunnel diode circuit) are given to compare the conservatism and to illustrate the effectiveness of the proposed asynchronous switched T–S observer design methodologies},
  archive      = {J_EAAI},
  author       = {Issam Chekakta and Djamel E.C. Belkhiat and Kevin Guelton and Dalel Jabri and Noureddine Manamanni},
  doi          = {10.1016/j.engappai.2021.104371},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104371},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Asynchronous observer design for switched T–S systems with unmeasurable premises and switching mismatches},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-stage optimization of the installation of energy
storage systems in railway electrical infrastructures with
nature-inspired optimization algorithms. <em>EAAI</em>, <em>104</em>,
104370. (<a
href="https://doi.org/10.1016/j.engappai.2021.104370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Installing Energy Storage Systems (ESSs) to improve electrical infrastructures of Direct-current (DC) railway systems implies considerable investments that must be assessed carefully. Therefore, it is often necessary to combine detailed railway simulations and decision support mechanisms. Unfortunately, most examples in the literature deal with this topic applying only a single-stage optimization approach: the whole installation is undertaken in a single step, assuming the total budget is available. This paper presents a comprehensive methodology to assess the gradual deployment of the installations when the budget is split into different time periods. This approach is a common situation in real projects and has not been studied yet in the literature. Most often, this type of multi-stage problem is tackled by optimizing each stage independently. On the contrary, this paper proposes to take decisions considering the global impact of each stage optimization, rendering a more efficient solution. This paper proposes a multi-stage formulation of two nature-inspired optimization algorithms (Genetic and Fireworks) to address the installation of ESSs in a realistic railway line. Results demonstrate the excellent behavior of the proposed multi-stage optimization.},
  archive      = {J_EAAI},
  author       = {David Roch-Dupré and Tad Gonsalves and Asunción P. Cucala and Ramón R. Pecharromán and Álvaro J. López-López and Antonio Fernández-Cardador},
  doi          = {10.1016/j.engappai.2021.104370},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104370},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-stage optimization of the installation of energy storage systems in railway electrical infrastructures with nature-inspired optimization algorithms},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IDCR: Improved dempster combination rule for multisensor
fault diagnosis. <em>EAAI</em>, <em>104</em>, 104369. (<a
href="https://doi.org/10.1016/j.engappai.2021.104369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data gathered from multiple sensors can be effectively fused for accurate monitoring of many engineering applications. In the last few years, one of the most sought after applications for multisensor fusion has been fault diagnosis. Dempster–Shafer Theory of Evidence along with Dempster’s Combination Rule is a very popular method for multisensor fusion which can be successfully applied to fault diagnosis. But if the information obtained from the different sensors shows high conflict, the classical Dempster’s Combination Rule may produce counter-intuitive result. To overcome this shortcoming, this paper proposes an improved combination rule for multisensor data fusion. Numerical examples have been put forward to show the effectiveness of the proposed method. Comparative analysis has also been carried out with existing methods to show the superiority of the proposed method in multisensor fault diagnosis.},
  archive      = {J_EAAI},
  author       = {Nimisha Ghosh and Sayantan Saha and Rourab Paul},
  doi          = {10.1016/j.engappai.2021.104369},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104369},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {IDCR: Improved dempster combination rule for multisensor fault diagnosis},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient repairs of infeasible job shop problems by
evolutionary algorithms. <em>EAAI</em>, <em>104</em>, 104368. (<a
href="https://doi.org/10.1016/j.engappai.2021.104368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the task of repairing infeasibility in the context of infeasible job shop scheduling problems with a hard constraint on the maximum makespan allowed. For this purpose, we adopt a job-based view of repairs, that allows for dropping some of the jobs and so gives rise to the problem of computing the largest subset of jobs that can be scheduled under the makespan constraint. Recent work proposed a genetic algorithm for solving this problem, which integrates an efficient solution builder for defining the search space. In this paper, we build on this earlier work and make several contributions. We provide a formal analysis of both the search space and the solution builder. Then, we propose two important enhancements to the genetic algorithm: first, we develop a new solution builder aimed at reducing the number of feasibility tests, making the search process more efficient. In addition, we propose a more effective procedure for testing the feasibility of different subsets of jobs under the given makespan constraint based on the use of a light-weight genetic algorithm. Experimental results show that the proposed methods are effective at solving the problem, and that the enhancements bring significant improvements.},
  archive      = {J_EAAI},
  author       = {Raúl Mencía and Carlos Mencía and Ramiro Varela},
  doi          = {10.1016/j.engappai.2021.104368},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104368},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient repairs of infeasible job shop problems by evolutionary algorithms},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust two-dimensional capped l2,1-norm linear discriminant
analysis with regularization and its applications on image recognition.
<em>EAAI</em>, <em>104</em>, 104367. (<a
href="https://doi.org/10.1016/j.engappai.2021.104367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-dimensional linear discriminant analysis (2DLDA) is an effective matrix-based supervised dimensionality reduction method that expresses 2D data directly. However, 2DLDA magnifies the influence of outliers and noise since the construction of 2DLDA is based on squared Frobenius norm. To overcome its sensitivity, this paper investigates a two-dimensional capped l 2 , 1 -norm linear discriminant analysis, called 2DCLDA. The application of capped l 2 , 1 -norm makes 2DCLDA identify outliers and suppress the effect of noise effectively. To avoid singularity and give a stable performance, a regularization term is also considered in the between-class scatter. 2DCLDA is solved through a series of generalized eigenvalue problems, with each subproblem can be deemed as a weighted 2DLDA with regularization. It is proved that the proposed iteration algorithm monotonously decreases the objective of 2DCLDA. At last, 2DCLDA with its related approaches on several face image databases is compared, and the experimental results demonstrate the superiority of 2DCLDA, especially for noise data.},
  archive      = {J_EAAI},
  author       = {Chun-Na Li and Yi-Fan Qi and Yuan-Hai Shao and Yan-Ru Guo and Ya-Fen Ye},
  doi          = {10.1016/j.engappai.2021.104367},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104367},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust two-dimensional capped l2,1-norm linear discriminant analysis with regularization and its applications on image recognition},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Overcoming model bias for robust offline deep reinforcement
learning. <em>EAAI</em>, <em>104</em>, 104366. (<a
href="https://doi.org/10.1016/j.engappai.2021.104366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art reinforcement learning algorithms mostly rely on being allowed to directly interact with their environment to collect millions of observations. This makes it hard to transfer their success to industrial control problems, where simulations are often very costly or do not exist, and exploring in the real environment can potentially lead to catastrophic events. Recently developed, model-free, offline RL algorithms, can learn from a single dataset (containing limited exploration) by mitigating extrapolation error in value functions. However, the robustness of the training process is still comparatively low, a problem known from methods using value functions. To improve robustness and stability of the learning process, we use dynamics models to assess policy performance instead of value functions, resulting in MOOSE (MOdel-based Offline policy Search with Ensembles), an algorithm which ensures low model bias by keeping the policy within the support of the data. We compare MOOSE with state-of-the-art model-free, offline RL algorithms BRAC, BEAR and BCQ on the Industrial Benchmark and MuJoCo continuous control tasks in terms of robust performance, and find that MOOSE outperforms its model-free counterparts in almost all considered cases, often even by far.},
  archive      = {J_EAAI},
  author       = {Phillip Swazinna and Steffen Udluft and Thomas Runkler},
  doi          = {10.1016/j.engappai.2021.104366},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104366},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Overcoming model bias for robust offline deep reinforcement learning},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Industrial fault diagnosis based on active learning and
semi-supervised learning using small training set. <em>EAAI</em>,
<em>104</em>, 104365. (<a
href="https://doi.org/10.1016/j.engappai.2021.104365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industrial fault diagnosis has been investigated for many years, and many approaches have been proposed to identify industrial faults. However, the size of the actual training set is usually small, which severely degrades the performance of existing fault diagnostic models. To solve this problem, a new fault diagnosis method was proposed based on active and semi-supervised learning. First, uncertain unlabelled samples were selected by estimating the first two values in the class probability distribution of the samples. They were labelled by experts to update the performance of the models learned from a small training set. Second, heterogeneous classifiers were adopted to increase the diversity of the base classifiers, and noise samples were deleted using a sample pruning operation. The weights of the base classifier were designed for ensemble learning based on the test error rates. An evaluation using the Case Western Reserve University and Intelligent Maintenance Systems data showed that the performance of the proposed method was better than those of the other methods in the experiment. The experimental results showed that this study provided a promising and useful methodology for fault diagnosis under a small training set.},
  archive      = {J_EAAI},
  author       = {Chuanxia Jian and Kaijun Yang and Yinhui Ao},
  doi          = {10.1016/j.engappai.2021.104365},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104365},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industrial fault diagnosis based on active learning and semi-supervised learning using small training set},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph convolutional neural networks with geometric and
discrimination information. <em>EAAI</em>, <em>104</em>, 104364. (<a
href="https://doi.org/10.1016/j.engappai.2021.104364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, geometric deep learning methods have been proposed, which are called Graph Convolutional Neural Networks (GCNNs). GCNNs not only can extract effective features like the classical CNN, but also can effectively reflect the true geometric structure of original data. Although GCNNs consider the geometric structure of original data, they construct the same feature graph to perform graph convolution, and ignore the difference between the local structures of different samples. Therefore, a novel Graph Convolutional Neural Network with Geometric and Discrimination information (GDGCNN) is proposed, which integrates traditional machine learning ideas to further improve the performance of feature extraction. In order to exploit differences between the local structures of different samples and make full use of the geometric structure of original data, GDGCNN constructs different feature graphs for different training batches to fully exploit the local geometry of data. Moreover, the discriminant regularization is introduced into GDGCNN to effectively utilize the discriminant information contained in original data. Therefore, GDGCNN has good discriminative ability and robustness. The experimental results show that GDGCNN can perform feature extraction tasks very well, and it is superior to some existing methods for classification in terms of accuracy and F1-Score.},
  archive      = {J_EAAI},
  author       = {Ronghua Shang and Yang Meng and Weitong Zhang and Fanhua Shang and Licheng Jiao and Shuyuan Yang},
  doi          = {10.1016/j.engappai.2021.104364},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104364},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Graph convolutional neural networks with geometric and discrimination information},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive algorithms for normalized probabilistic
linguistic preference relations in view of the disjunctive probability
based consistency and consensus analysis. <em>EAAI</em>, <em>104</em>,
104363. (<a
href="https://doi.org/10.1016/j.engappai.2021.104363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates decision making with normalized probabilistic linguistic preference relations (NPLPRs). Consistency analysis is indispensable for deriving the reasonable ranking. After recalling previous research, we find that all previous concepts cannot fully define consistent NPLPRs. As a fundamental topic of decision making with preference relations, it is necessary to further study the consistency of NPLPRs. For this purpose, an interactive algorithm for deriving disjunctive probabilistic additive linguistic preference relations (DP-ALPRs) is provided, by which an additive consistency concept for NPLPRs is defined. When NPLPRs are unacceptably consistent, models for obtaining acceptably additively consistent NPLPRs are built. Considering the situation where only incomplete NPLPRs are obtained, a disjunctive probability and additive consistency based interactive algorithm for ascertaining missing judgments is provided. Meanwhile, we discuss group decision making (GDM) with NPLPRs and offer a distance measure based formula to determine the weights of the decision makers. In addition, the method defines a consensus index and builds models for improving the consensus level. Under the additive consistency and consensus discussions, an interactive algorithm for GDM with NPLPRs is proposed. Finally, the new method is applied to select green raw material suppliers to illustrate the application and compared with several previous ones.},
  archive      = {J_EAAI},
  author       = {Fanyong Meng and Witold Pedrycz and Jie Tang and Hamido Fujita},
  doi          = {10.1016/j.engappai.2021.104363},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104363},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interactive algorithms for normalized probabilistic linguistic preference relations in view of the disjunctive probability based consistency and consensus analysis},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spiking neural network-based multi-task autonomous learning
for mobile robots. <em>EAAI</em>, <em>104</em>, 104362. (<a
href="https://doi.org/10.1016/j.engappai.2021.104362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are the new generation of artificial neural networks that closely mimic the time encoding and information processing aspects of the human brain. In this work, a multi-task autonomous learning paradigm is proposed for the mobile robot application, which employs a SNN to construct the controlling system of the mobile robot. The Reward-modulated Spiking-time-dependent Plasticity learning rule is developed for the SNN-based controller, which aims to achieve the capability of autonomous learning under multiple tasks. Reward signals are generated based on the instantaneous frequencies of pre- and post-synaptic spikes, which adapts to the sensory stimuli and environmental feedback. Meanwhile, inspired by lateral inhibition connections, a task switch mechanism is designed to enable the controller to switch the operations between multiple tasks. Two tasks of obstacle avoidance and target tracking are used for performance evaluation and results demonstrate that the mobile robot with the proposed paradigm is able to autonomously learn, switch and complete the tasks.},
  archive      = {J_EAAI},
  author       = {Junxiu Liu and Hao Lu and Yuling Luo and Su Yang},
  doi          = {10.1016/j.engappai.2021.104362},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104362},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Spiking neural network-based multi-task autonomous learning for mobile robots},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disturbance-observer based prescribed-performance fuzzy
sliding mode control for PMSM in electric vehicles. <em>EAAI</em>,
<em>104</em>, 104361. (<a
href="https://doi.org/10.1016/j.engappai.2021.104361">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of accurate speed tracking control of electric vehicles powered by permanent magnet synchronous motor (PMSM) under external load torque disturbance. Firstly, the dynamic model of PMSM is given, and the controller is designed based on backstepping control. Secondly, a second-order sliding mode differentiator is used to approximate the derivative of virtual control law and solve the problem of explosion of complexity. Considering the load disturbance of PMSM in the actual operation due to road roughness, a novel disturbance observer is proposed to the estimate the load disturbance. In addition, in order to achieve prescribed tracking error performance, the prescribed-performance control is proposed to guarantee the tracking error within a given prescribed boundary. Finally, the finite-time stability of the system is proved, the simulation and real-time implementation results verify the effectiveness of the designed controller.},
  archive      = {J_EAAI},
  author       = {Yuchen Dai and Shuangfei Ni and Dezhi Xu and Liyan Zhang and Xing-Gang Yan},
  doi          = {10.1016/j.engappai.2021.104361},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104361},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Disturbance-observer based prescribed-performance fuzzy sliding mode control for PMSM in electric vehicles},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting fractional accumulation and background value
optimization in multivariate interval grey prediction model and its
application. <em>EAAI</em>, <em>104</em>, 104360. (<a
href="https://doi.org/10.1016/j.engappai.2021.104360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of small sample and poor information, the data often change rapidly and interact with multiple factors which make it a challenge to analyse and predict multivariate sequences efficiently. Due to the fact that real systems usually show fractional order characteristics, the aim of this paper is to consider the approach improving the forecast results of multivariate interval grey prediction model via exploiting fractional accumulation. Noting that fractional accumulation could disturb the exponential law, the connotation prediction method is introduced to balance the disturbance. Correspondingly, a fractional connotation prediction method is constructed. In addition, traditional background value coefficient is optimized by using the particle swarm optimization algorithm (PSO). Therefore, a multivariate interval grey fractional accumulative connotation prediction model with optimized background value coefficient is constructed, in which the interval grey number time series are transformed into kernel series and radius series. Finally, the developed model is applied to clean energy prediction in China to verify the feasibility and validity.},
  archive      = {J_EAAI},
  author       = {Huiling Huang and Zhifu Tao and Jinpei Liu and Jianhua Cheng and Huayou Chen},
  doi          = {10.1016/j.engappai.2021.104360},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104360},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploiting fractional accumulation and background value optimization in multivariate interval grey prediction model and its application},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy-efficient production scheduling through machine
on/off control during preventive maintenance. <em>EAAI</em>,
<em>104</em>, 104359. (<a
href="https://doi.org/10.1016/j.engappai.2021.104359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies an important extension of energy-efficient production scheduling research, where machine on/off control and machine maintenance are considered simultaneously. The inspiration of this extension is that a machine must be turned off if it needs to be maintained, and an already-turned-off machine can be maintained without needing to be restarted. We therefore formulate an energy-efficient production scheduling problem with machine maintenance through machine on/off control, aiming to optimise three objectives – the makespan, total number of machine restarts, and energy consumption – at the same time. Four rules are designed to set the machine on/off criteria, maintenance periods and predefined maintenance windows, based on solutions of the job shop scheduling problem (JSP) as a test case. Three heuristics are proposed to insert the maintenance activities into the solutions and move their maintenance-operation blocks to optimise the objectives. The effectiveness of the first rule and the moving of maintenance-operation blocks have been proven mathematically. Our proposed heuristics, unlike traditional heuristic algorithms, are expected to be applicable and effective even if we change the objectives and constraints, require minimal computational time (only a few seconds) to optimise a scheduling solution, and can solve different types of scheduling problems without needing any modification. Experiments undertaken indicate promising performance of the proposed heuristics based on 182 JSP benchmark instances.},
  archive      = {J_EAAI},
  author       = {Guiliang Gong and Raymond Chiong and Qianwang Deng and Wenwu Han and Like Zhang and Dan Huang},
  doi          = {10.1016/j.engappai.2021.104359},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104359},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Energy-efficient production scheduling through machine on/off control during preventive maintenance},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting exchange rates with the iMLP: New empirical
insight on one multi-layer perceptron for interval time series (ITS).
<em>EAAI</em>, <em>104</em>, 104358. (<a
href="https://doi.org/10.1016/j.engappai.2021.104358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The foreign exchange market (FX) is a market for converting the currency of one country into that of another country. Spot exchange rates movements are carefully observed every minute around the world. But governments, banks and multinational companies generally develop decision-making under other frequencies of time like days, weeks, months, quarters, or semesters. Interval time series (ITS) assign an interval of values at every period of time. For example, daily or monthly lows and highs values are key examples of ITS. Several forecasting methods have been developed for ITS. Neural networks have attracted research focused on FX forecasting. The Multi-Layer Perceptron (MLP) with one hidden layer is one of the best networks for forecasting crisp time series. For ITS, the iMLP (interval MLP) was proposed as an extension of the MLP. The number and type of inputs and the number of neurons in the hidden layer (15 is the usual number) are key parameters to rank different architectures of the network. We analyze these hyperparameters in the forecasting performance of the iMLP through the EUR/USD on a low–high daily basis, on different behaviors such as uptrend, downtrend, or sideways; on different accuracy measures, including coverage and efficiency rates, and incorporating other rates such as GBP/USD or AUD/USD. The election of 15 neurons is discarded. Moreover, we compare these iMLP networks with the interval random walk and results are quite promising. Finally, we conclude that in any context of FX, several iMLP networks should be considered which opens new research avenues.},
  archive      = {J_EAAI},
  author       = {Carlos Maté and Lucía Jimeńez},
  doi          = {10.1016/j.engappai.2021.104358},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104358},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting exchange rates with the iMLP: New empirical insight on one multi-layer perceptron for interval time series (ITS)},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective genetic algorithm optimization of a
directionally sensitive radiation detection system using a surrogate
transport model. <em>EAAI</em>, <em>104</em>, 104357. (<a
href="https://doi.org/10.1016/j.engappai.2021.104357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Direction-sensitive and imaging radiation detection systems often rely on complicated mask geometries to reconstruct source positions and images. Optimizing the design of these masks is difficult, often non-intuitive, and computationally intensive due to the radiation transport involved. Advances in computational resources, efficient, stochastic optimization techniques, and improved variance reduction in radiation transport through hybrid deterministic-Monte Carlo methods have enabled researchers to consider methods to find formal optimal solutions for these systems. However, many systems span a complex and large design space making full radiation transport simulations to inform the optimization routine computationally intractable. This work applies a multi-objective genetic algorithm to a generalizable surrogate model, benchmarked through full Monte Carlo radiation transport simulations, to determine the optimal design for the rotating scatter mask directionally-sensitive detection system. Performing the equivalent optimization of 10,000 design evaluations with Monte Carlo radiation transport simulations would take 460 CPU-years. In contrast, the 10,000 surrogate design evaluations produced Pareto frontiers comparable to the Monte Carlo results, while reducing the computational cost by 99.998% to 4.1 CPU-days. The chosen optimal designs maintain high directional accuracy with respect to the original design, while improving the response basis similarity by 14% and increasing the efficiency by a factor of 40 at the cost of increasing the mask’s mass by a factor of 3.},
  archive      = {J_EAAI},
  author       = {Darren E. Holland and Robert J. Olesen and James E. Bevins},
  doi          = {10.1016/j.engappai.2021.104357},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104357},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-objective genetic algorithm optimization of a directionally sensitive radiation detection system using a surrogate transport model},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Customer sentiment analysis with more sensibility.
<em>EAAI</em>, <em>104</em>, 104356. (<a
href="https://doi.org/10.1016/j.engappai.2021.104356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Customers’ evaluations on products can be derived by analyzing online reviews using machine learning. Positive or negative responses can be sensed by words they write in reviews, and topics they compliment or complain about can be grasped by clustering reviews. Combination of those results is regarded as the customers’ sentiment analysis. When reviews are given as free-form text without scores, general-purpose dictionaries are used to recognize sentiment words. However, customers do not only use standard words to express their emotions, but they also use non-grammatical language such as internet jargon. Unfortunately, existing methods cannot capture those sentiment words. Moreover, combination of sentiment words with customer topics simply represents frequencies and does not indicate detailed evaluation patterns. In this study, we propose a customer sentiment analysis method consisting of sentiment propagation and customer review analysis. It works more sensibly by expanding sentiment words from dictionary to those varying words as mentioned above. To implement this, semi-supervised learning is employed to a word graph that is constructed by a word embedding algorithm. Using this more sensible word graph, customer review analysis is conducted. Reviews are grouped into major complaint topics. Meanwhile, an index for customer dissatisfaction is designed by composition of ‘controversy’ and ‘complaint’. The former stands for ‘coverage of dissatisfaction’ while the latter indicates ‘degree of dissatisfaction’. The proposed method was applied to 3,11,550 reviews across five automobiles from ten internet communities. Case study illustrates which parts of automobiles lead to customer dissatisfaction, and therefore where investment and examination are required.},
  archive      = {J_EAAI},
  author       = {Sunghong Park and Junhee Cho and Kanghee Park and Hyunjung Shin},
  doi          = {10.1016/j.engappai.2021.104356},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104356},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Customer sentiment analysis with more sensibility},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OIS-RF: A novel overlap and imbalance sensitive random
forest. <em>EAAI</em>, <em>104</em>, 104355. (<a
href="https://doi.org/10.1016/j.engappai.2021.104355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classifier learning with imbalanced data is one of the main challenges in the data mining community. An ensemble of classifiers is a popular solution to this problem, and it has acquired significant attention owing to its better performance as compared to individual classifiers. In this paper, we propose an imbalanced classification ensemble method, which is hereafter referred to as overlap and imbalanced sensitive random forest (OIS-RF). We consider the existence of overlap in imbalanced data and create a new coefficient called Hard To Learn (HTL) which aims to measure the degree of importance for each training instance. In this regard, OIS-RF focuses more on learning the instances with high importance in each sub-dataset. Furthermore, to encourage the diversity of the ensemble, a weighted bootstrap method is proposed to generate sub-datasets containing diverse local information. The proposed method is evaluated on imbalanced datasets and is supported by statistical analyses. The results show that our method outperforms 9 state-of-the-art ensemble algorithms.},
  archive      = {J_EAAI},
  author       = {Bo-Wen Yuan and Zhong-Liang Zhang and Xing-Gang Luo and Yang Yu and Xiao-Hua Zou and Xiao-Dong Zou},
  doi          = {10.1016/j.engappai.2021.104355},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104355},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {OIS-RF: A novel overlap and imbalance sensitive random forest},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VASP: An autoencoder-based approach for multivariate anomaly
detection and robust time series prediction with application in
motorsport. <em>EAAI</em>, <em>104</em>, 104354. (<a
href="https://doi.org/10.1016/j.engappai.2021.104354">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim is to provide a framework for robust time series prediction in the presence of anomalies. The framework is developed based on a data set from motorsport but is not limited to this specific area. In motorsport, the usage of sensors during races is generally restricted. Estimating the outputs of these missing sensors therefore provides an advantage over the competition. Deep learning approaches such as long short-term memory (LSTM) neural networks have proven to be useful for that task, however, their accuracy decreases significantly if anomalies occur in the input signals. To overcome this problem, we propose the variational autoencoder based selective prediction (VASP) framework which combines the tasks of anomaly detection and time series prediction. VASP consists of a variational autoencoder (VAE), an anomaly detector and LSTM predictors. Depending on the anomaly detector, a subset of the inputs may be replaced by the VAE, allowing a more robust prediction. To the best of our knowledge the approach of using a VAE to only selectively replace anomalous input data before prediction has not yet been published. Our contributions are clear implementation guidelines and a comparison to other VAE-based methods and a LSTM approach as baseline. We simulate anomalies with three approaches and show that VASP outperforms other methods by having no trade-off between accuracy and robustness. VASP is as accurate as the baseline for regular data, but for anomalous inputs the error is reduced by 13% to 33% on average and up to 70% in special cases.},
  archive      = {J_EAAI},
  author       = {Julian von Schleinitz and Michael Graf and Wolfgang Trutschnig and Andreas Schröder},
  doi          = {10.1016/j.engappai.2021.104354},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104354},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {VASP: An autoencoder-based approach for multivariate anomaly detection and robust time series prediction with application in motorsport},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pixel-level automatic annotation for forest fire image.
<em>EAAI</em>, <em>104</em>, 104353. (<a
href="https://doi.org/10.1016/j.engappai.2021.104353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an automatic annotation method for forest fire images in the level of pixel, where supervise information is introduced by interactive convex hulls. Instead of usual rectangle-/ regular -shaped regions, we propose a convex hull algorithm for visually selecting polygonal ( irregular ) fire and no-fire regions. Guided by the goals of forest fire monitoring systems: high fire detection rate (true-positive) and then low false alarm rate (false-positive), we construct a k-nearest neighbor (kNN) based KD-tree to speed annotation. Compared to state-of-the-art, the proposed method not only widens the view of fire detection from conventional two-class to multi-class classification problem to meet complex forest image background, but also relaxes the limit of i.i.d (independent and identical distribution) hypothesis on machine learning methods. Furthermore, it is simple to use, which just relies on pixel information and avoids considering additional auxiliary features from multiple color spaces. Experimental evaluations are carrying on forest fire images, MIVIA dead-directional videos, and more challenging omni-directional videos. The comparison demonstrates that the proposed pixel-level annotation method is able to achieve higher fire detection rate and lower false alarm rate at the same time.},
  archive      = {J_EAAI},
  author       = {Xubing Yang and Run Chen and Fuquan Zhang and Li Zhang and Xijian Fan and Qiaolin Ye and Liyong Fu},
  doi          = {10.1016/j.engappai.2021.104353},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104353},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pixel-level automatic annotation for forest fire image},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved assessment model for candidate design schemes with
an interval rough integrated cloud model under uncertain group
environment. <em>EAAI</em>, <em>104</em>, 104352. (<a
href="https://doi.org/10.1016/j.engappai.2021.104352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design scheme decision is a vital activity at the early stage of product development, which is usually conducted by expert assessment. Since various uncertainties inherently exist in experts’ linguistic assessments, such as vagueness, randomness, and diversity, single uncertainty manipulation methods may not be sufficient to select suitable design alternatives. However, existing methods usually only employ single models to handle experts’ assessment uncertainties. Besides, the relative weights of experts and assessment criteria are essential information in decision system which can reasonably capture the relationship of different factors. However, most current references only consider the criteria’s weight, which also influences the rationality of assessment results. Hence, this study proposes a new decision model to address the above-mentioned limitations. First, a novel linguistic manipulation model, namely interval rough integrated clouds (IRICs), is developed to handle various uncertainties by combining the interval rough number theory and cloud model theory. Second, two hybrid-weighting methods are proposed to respectively identify the overall weights of experts and assessment criteria by considering both subjective and objective aspects. Finally, a real-world case of alternative assessment is conducted to demonstrate its feasibility and reliability. Some existing known methods evaluate the proposed method’s performance, and the results illustrate that the proposed method is outperforming many existing assessment methods.},
  archive      = {J_EAAI},
  author       = {Liming Xiao and Guangquan Huang and Genbao Zhang},
  doi          = {10.1016/j.engappai.2021.104352},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104352},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improved assessment model for candidate design schemes with an interval rough integrated cloud model under uncertain group environment},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting the fiber orientation in glass fiber reinforced
polymers using the moment of inertia and convolutional neural networks.
<em>EAAI</em>, <em>104</em>, 104351. (<a
href="https://doi.org/10.1016/j.engappai.2021.104351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mechanical properties of glass fiber reinforced polymers (GFRP) are significantly governed by the orientation of the fibers in the composite. Micro X-ray computed tomography (CT) imaging offers a way of determining the fiber’s orientation in a non-destructive fashion. Various approaches have been presented to compute the direction of the fibers based on fiber tracking or weighted volume algorithms. In this work we present two novel approaches, one employing convolutional neural networks (CNNs) and the other directional analysis by inertia tensor evaluation (ITE). We establish a workflow based on molecular dynamics simulations to efficiently create synthetic training data for the CNN. The two methods are applied to two experimental CT scans of the GFRP polyamide 66 of two different components, featuring different CT resolutions, fiber lengths and volume fractions. The CNN model trained by synthetic data predicts fiber orientations consistently and with similar accuracy as best-in-class commercially available products. We observe an increase in computational speeds of at least a factor of 4 on CPUs or about a factor of 50 on GPUs, respectively. A striking feature of this approach is that the ground truth of our training data is perfectly known and no time-consuming manual labeling of fibers for training is needed. The proposed ITE method is very robust and particularly suited to lower resolution CT scans, as the evaluation of gradients is not necessary. Both methods extend the toolbox of weighted volume approaches and are well-suited to predict orientations of densely-packed fibers that are often encountered in industrial practice. In addition, predictions by the trained CNN model can be run on standard office hardware which makes them particularly interesting for industrial environments.},
  archive      = {J_EAAI},
  author       = {Patrick Bleiziffer and Jürgen Hofmann and Robert Zboray and Thorsten Wiege and Roger Herger},
  doi          = {10.1016/j.engappai.2021.104351},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104351},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting the fiber orientation in glass fiber reinforced polymers using the moment of inertia and convolutional neural networks},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A real shapley value for evidential games with fuzzy
characteristic function. <em>EAAI</em>, <em>104</em>, 104350. (<a
href="https://doi.org/10.1016/j.engappai.2021.104350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Game theory is a famous issue of expert decision making. The real Shapley value for cooperative games with fuzzy characteristic function has high performance in deal with cooperative games, which is an effective tool in deal with issues of game theory. The real Shapley value for cooperative games with fuzzy characteristic function is based on the level sets, which is the extent of fuzzy sets. However, the real Shapley value for cooperative games with fuzzy characteristic function cannot solve the evidential games problems. What is the real Shapley value for evidential games with fuzzy characteristic function is still an open problem. This paper proposes the real Shapley value for evidential games with characteristic function, which consists of level sets, the real evidential Shapley value, basic probability assignment function. The real Shapley value for evidential games with fuzzy characteristic function can solve the expert decision making issues under evidential environment, with the aid of basic probability assignment function. Meanwhile, the theorem of the proposed model has been discussed. Numerical examples has been applied to illustrate the effectiveness of the proposed model. The experimental results show that proposed model can obtain the real evidential Shapley value of a given evidential games and address the issues of expert decision making.},
  archive      = {J_EAAI},
  author       = {Yige Xue and Yong Deng},
  doi          = {10.1016/j.engappai.2021.104350},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104350},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A real shapley value for evidential games with fuzzy characteristic function},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bi-level distribution mixture framework for unsupervised
driving performance evaluation from naturalistic truck driving data.
<em>EAAI</em>, <em>104</em>, 104349. (<a
href="https://doi.org/10.1016/j.engappai.2021.104349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Driving performance evaluations can contribute to fleet management and lead to safer and more economical driving conditions for manned or driverless fleet vehicles. One approach to driving performance evaluation involves quantitative mapping or categorical labeling of skill levels and categorizing of driving patterns from extraordinarily mild to the most aggressive. This paper presents a big data system for driving performance evaluations of drivers and trips using a probabilistic framework. The proposed framework combines a feature mixture model for scoring driving performance through defined objective comparison criteria and a latent style mixture model for classifying drivers by the main driving styles they exhibit. To demonstrate the effectiveness of the proposed models, we perform both quantitative and qualitative experiments. The results show that the former produces an interpretable and normal scorecard model, while the latter helps build an improved clustering model that represents enhanced driver behavior.},
  archive      = {J_EAAI},
  author       = {Lin Lu and Shengwu Xiong and Yaxiong Chen},
  doi          = {10.1016/j.engappai.2021.104349},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104349},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A bi-level distribution mixture framework for unsupervised driving performance evaluation from naturalistic truck driving data},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving current interest with item and review sequential
patterns for sequential recommendation. <em>EAAI</em>, <em>104</em>,
104348. (<a
href="https://doi.org/10.1016/j.engappai.2021.104348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequential recommendation (SR) aims to recommend items based on user information and behavior sequences. Almost all the existing works for SR construct short-term preference and long-term preference only based on the user–item interactions or the reviews rather than considering the two types of information simultaneously. In fact, interaction items and reviews commonly reflect the user’s semantic information, and play significant roles in modeling the user preference. In this paper, we propose a novel model named Parallel Item sequential pattern and Review Sequential Pattern (PIRSP) for the sequential recommendation. Specifically, first, PIRSP learns two levels of sequential patterns from item and review information, respectively: (1) item sequential pattern, which uses a gated recurrent unit with an item-attention mechanism to model history behavior sequences; (2) review sequential pattern, which takes a convolution neural network with a target-attention mechanism for modeling associated reviews of interaction items. Then, we introduce a fusion gating mechanism for selectively combining the two sequential patterns to learn the short-term preference. Second, we employ a convolution neural network with aspect information to learn the long-term preference. Finally, we utilize a linear fusion on the long-term preference and short-term preference for modeling user preference and making final recommendation. The experimental results indicate that our model outperforms other state-of-the-art methods on the Amazon dataset. Our analysis of PIRSP’s recommendation process shows the positive effect of the two types of information and fusion gating mechanism on the performance of sequential recommendation.},
  archive      = {J_EAAI},
  author       = {Jinjin Zhang and Xiaodong Mu and Peng Zhao and Kai Kang and Chenhui Ma},
  doi          = {10.1016/j.engappai.2021.104348},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104348},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Improving current interest with item and review sequential patterns for sequential recommendation},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards benchmark datasets for machine learning based
website phishing detection: An experimental study. <em>EAAI</em>,
<em>104</em>, 104347. (<a
href="https://doi.org/10.1016/j.engappai.2021.104347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing popularity of the Internet led to a substantial growth of e-commerce. However, such activities have main security challenges primary caused by cyberfraud and identity theft. Therefore, checking the legitimacy of visited web pages is a crucial task to secure costumers’ identities and prevent phishing attacks. The use of machine learning is widely recognized as a promising solution. The literature is rich with studies that use machine learning techniques for website phishing detection. However, their findings are dataset dependent and are far away from generalization. Two main reasons for this unfortunate state are the impracticable replication and absence of appropriate benchmark datasets for fair evaluation of systems. Moreover, phishing tactics are continuously evolving and proposed systems are not following those rapid changes. In this paper, we present a general scheme for building reproducible and extensible datasets for website phishing detection. The aim is to (1) enable comparison of systems adopting different features, (2) overtake the short-lived nature of phishing websites, and (3) keep track of the evolution of phishing tactics. For experimenting the proposed scheme, we start by adopting a refined categorization of website phishing features and we systematically select a total of 87 commonly recognized ones, we categorize them, and we made them subjects for relevance and runtime analysis. We use the collected set of features to build a dataset in light of the proposed scheme. Thereafter, we use a conceptual replication approach to check the genericity of former findings for the built dataset. Specifically, we evaluate the performance of classifiers on individual and combined categories of features, we investigate different combinations of models, and we explore the effects of filter and wrapper methods on the selection of discriminative features. The results show that Random Forest is the most predictive classifier. Features gathered from external services are the most discriminative where features extracted from web page contents are less distinguishing. Besides external service based features, some web page content features are found not suitable for runtime detection. The use of hybrid features provided the best accuracy score of 96.61%. By investigating different feature selection methods, filter-based ranking with incremental removal of less important features improved the performance up to 96.83% better than wrapper methods.},
  archive      = {J_EAAI},
  author       = {Abdelhakim Hannousse and Salima Yahiouche},
  doi          = {10.1016/j.engappai.2021.104347},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104347},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Towards benchmark datasets for machine learning based website phishing detection: An experimental study},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human flow recognition using deep networks and vision
methods. <em>EAAI</em>, <em>104</em>, 104346. (<a
href="https://doi.org/10.1016/j.engappai.2021.104346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper focuses on developing the system for people flow recognition based on many video camera images. The project arose based on the real need — its application in the city malls to find the most visited places and support customers’ campaigns. The potential application in other domains is possible (public buildings, airports). In contrast to the existing solutions, our approach involves on-edge image analysis to decrease the risk of data loss and the system cost. In the project, we design the whole processing pipeline composed of the component modules responsible for detecting, tracking, and reidentifying (shuffling) people. Our experimental platform enabled us to compare multiple method variants for each module. Based on extensive experimental research, the final solution uses the pretrained SSD method in the detection module. The centroid algorithm applied to displacement vectors combined with the Siamese network is the basis for the object tracking module. The best model to solve the reidentification task is the Resnet50. For the Market 1501 dataset, it achieved Rank-1 efficiency of 84.6%. The system gives a visualization of the main paths of people’s movements in the form of a heat map and assigns the direction where people most often look. In the experimental study, we assessed the system’s effectiveness and time efficiency, and the current results give a perspective for its commercialization in the nearest future.},
  archive      = {J_EAAI},
  author       = {Mateusz Zimoch and Urszula Markowska-Kaczmar},
  doi          = {10.1016/j.engappai.2021.104346},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104346},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Human flow recognition using deep networks and vision methods},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diagnosing with a hybrid fuzzy–bayesian inference approach.
<em>EAAI</em>, <em>104</em>, 104345. (<a
href="https://doi.org/10.1016/j.engappai.2021.104345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A diagnosis based on Bayesian theory requires knowledge of the a priori and conditional probabilities of the states of the system being diagnosed. The a priori probabilities are frequently provided nowadays by the manufacturers of these systems. In turn, the probabilities of conditional observations are, as a rule, not available. The question arises as to whether and under what conditions it is possible to substitute conditional probabilities with some aggregate obtainable on the grounds of fuzzy logic. This article responds to this question by proposing a hybrid approach with novelty characteristics in both theoretical and practical terms. In the initial phase of the deliberations, it was concluded that the fundamental difference between Bayesian and fuzzy approaches is that the fuzzy approach considers the uncertainty and lack of precision of observations but overlooks the frequency of observations, and the opposite is true of the Bayesian approach. It therefore seems reasonable to seek the hybridization of both methods so that the Bayesian approach carrying the information regarding the subjective probabilities of faults can be applied in practice. To this end, it has been shown that the probability of a conditional observation can be estimated by calculating the degree of truth of the premise for that observation in the state-specific fuzzy rule. The reminder is devoted to presenting numerical and simulation examples illustrating and verifying the proposed approach.},
  archive      = {J_EAAI},
  author       = {Jan Maciej Kościelny and Michał Bartyś and Anna Sztyber},
  doi          = {10.1016/j.engappai.2021.104345},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104345},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diagnosing with a hybrid fuzzy–Bayesian inference approach},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PEAVC: An improved minimum vertex cover solver for massive
sparse graphs. <em>EAAI</em>, <em>104</em>, 104344. (<a
href="https://doi.org/10.1016/j.engappai.2021.104344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several important applications related to complex network analysis require finding small vertex covers in massive sparse graphs. To fulfill this task, this paper proposes a general algorithm framework named PEAF , which includes preprocessing stage, solving stage, and inverse-processing stage. Based on PEAF , a minimum vertex cover (MinVC) solver PEAVC is developed, which uses PreP to reduce the graph, BGVC to obtain a vertex cover of bipartite-graph components, FastVC2 to solve the connected components left, and Inv_PreP to get a vertex cover of the original problem. Computational experiments on 90 massive REAL-WORLD benchmark graphs indicate that PreP can reduce the vertex number by 83.25% on average, which is superior to other graph reduction methods. PEAVC performs remarkably well by discovering 5 best-known results (new upper bounds) never reported in the literature, match the best known results for 63 other instances and obtain exact MinVCs for 55 instances. Experiments also show that PEAVC has an extremely high performance.},
  archive      = {J_EAAI},
  author       = {Jiaqi Gu and Ping Guo},
  doi          = {10.1016/j.engappai.2021.104344},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104344},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PEAVC: An improved minimum vertex cover solver for massive sparse graphs},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Deep learning with nonlocal and local structure preserving
stacked autoencoder for soft sensor in industrial processes.
<em>EAAI</em>, <em>104</em>, 104341. (<a
href="https://doi.org/10.1016/j.engappai.2021.104341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based soft sensor has been widely used for quality prediction in modern industry. Traditional deep learning like stacked autoencoder (SAE) only captures the feature representations by minimizing the global reconstruction errors, which causes a loss of the intrinsic geometric structure embedded in the raw data. To address this problem, a nonlocal and local structure preserving stacked autoencoder (NLSP-SAE) is proposed for soft sensor. Different from the original SAE, NLSP-SAE aims to extract the meaningful structure-relevant features by establishing a new objective function with a regularizer of the nonlocal and local data structure information. For local structure preserving, NLSP-SAE enforces two adjacent data points to be near each other in the reconstructed space. While for nonlocal structure preserving, NLSP-SAE constrains two nonadjacent data points to be far apart from each other. The application on an industrial hydrocracking process demonstrates that NLSP-SAE can improve the prediction accuracy for quality variables.},
  archive      = {J_EAAI},
  author       = {Chenliang Liu and Yalin Wang and Kai Wang and Xiaofeng Yuan},
  doi          = {10.1016/j.engappai.2021.104341},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104341},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep learning with nonlocal and local structure preserving stacked autoencoder for soft sensor in industrial processes},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CEBRA: A CasE-based reasoning application to recommend
banking products. <em>EAAI</em>, <em>104</em>, 104327. (<a
href="https://doi.org/10.1016/j.engappai.2021.104327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Following data ethics and respecting the clients’ privacy, the banking environment can use the client data that is available to them to offer personalized services to its clients. Intelligent recommender systems can support this attempt through specialized technological architectures. This article proposes the inclusion of CEBRA (CasE-Based Reasoning Application), a case-based reasoning system oriented to commercial banking, in a Fog Computing architecture coordinated by virtual agents. Throughout this article, the model of this architecture is presented and its life cycle is described, and improvements are proposed through the incorporation of several techniques in the retrieve and reuse phases, including the extraction of interests expressed by users on their social network profiles and collaborative filtering systems. A comprehensive case study has been carried out and a dataset of 60,000 cases has been generated to evaluate CEBRA. As a result, the Recommender System is presented, by including, the recommendation algorithm and a REST interface for its use. The recommendations are based on the user’s profile, previous ratings and/or additional knowledge such as the user’s contextual information. The proposal takes advantage of contextual information to support the promotion of banking and financial products, improving user satisfaction.},
  archive      = {J_EAAI},
  author       = {Elena Hernández-Nieves and Guillermo Hernández and Ana B. Gil-González and Sara Rodríguez-González and Juan M. Corchado},
  doi          = {10.1016/j.engappai.2021.104327},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104327},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CEBRA: A CasE-based reasoning application to recommend banking products},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid metaheuristic multi-layer reinforcement learning
approach for two-level energy management strategy framework of
multi-microgrid systems. <em>EAAI</em>, <em>104</em>, 104326. (<a
href="https://doi.org/10.1016/j.engappai.2021.104326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study builds a two-level energy management strategy framework for decentralized autonomy of microgrids and optimal coordinated operation of a multi-microgrid system. To reduce the operational cost of a combined cooling, heating and power multi-microgrid system with uncertain information and to improve the accuracy of load demand prediction, a hybrid metaheuristic multi-layer reinforcement learning algorithm is proposed for the framework of a multi-microgrid system. The proposed method is composed of a weighted delayed deep deterministic policy gradient algorithm, power adjustment network, and a genetic algorithm. At the first level, the microgrid operators utilize weighted delayed deep deterministic policy gradient algorithm with power adjustment network to optimize their operational strategies; at the second level, the distribution system operator employs a genetic algorithm to adjust its operational decision-making for minimizing the operational cost of the multi-microgrid system, reducing the peak-to-average ratios and power fluctuations at the points of common coupling. The data privacy of the parties in the multi-microgrid system is protected as each entity in the system does not have direct access to other entities’ information during the decision-making process. Numerical simulation results show that the proposed weighted delayed deep deterministic policy gradient algorithm with power adjustment network can rapidly obtain high-quality deterministic approximate optimal solution for economic dispatch of the microgrid. The framework proposed in this study achieves decentralized autonomy of microgrids, reduces the operational cost of the multi-microgrid system with incomplete or uncertain information, and indirectly improves the accuracy of load demands prediction at the points of common coupling.},
  archive      = {J_EAAI},
  author       = {Linfei Yin and Shengyuan Li},
  doi          = {10.1016/j.engappai.2021.104326},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104326},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid metaheuristic multi-layer reinforcement learning approach for two-level energy management strategy framework of multi-microgrid systems},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Presentation a trust walker for rating prediction in
recommender system with biased random walk: Effects of h-index
centrality, similarity in items and friends. <em>EAAI</em>,
<em>104</em>, 104325. (<a
href="https://doi.org/10.1016/j.engappai.2021.104325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the use of trust-based recommendation systems to predict the scores of items not rated by users has attracted many researchers’ interest. Accordingly, they create a trusted network of users, move in the trust graph, and search for the desired rank among the users by creating a Trust Walker and Random walk algorithm. Meanwhile, we face some challenges such as calculating the level of trust between users, the movement of Trust Walker using Random walk (random route selection), not discovering the desired rank, and as a result, the algorithm failure. In the present study, in order to solve the mentioned challenges, a trust-based recommender system is presented that predicts the ranks of items that the target user has not rated. In the first stage, a trusted network is developed based on the three criteria. In the next step, we define a Trust Walker to calculate the level of trust between users, and we apply the Biased Random Walk (BRW) algorithm to move it; the proposed method recommends it to the target user in the case of finding the desired rank of the item, and if that item does not exist in the defined trust network, it uses association rules to recognize items that are dependent on the item being searched and recommends them to the target user. The evaluation of this research has been performed on three datasets, and the obtained results indicate higher efficiency and more accuracy of the proposed method.},
  archive      = {J_EAAI},
  author       = {Saman Forouzandeh and Mehrdad Rostami and Kamal Berahmand},
  doi          = {10.1016/j.engappai.2021.104325},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104325},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Presentation a trust walker for rating prediction in recommender system with biased random walk: Effects of H-index centrality, similarity in items and friends},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved artificial tree algorithm with two populations
(IATTP). <em>EAAI</em>, <em>104</em>, 104324. (<a
href="https://doi.org/10.1016/j.engappai.2021.104324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many new bio-inspired algorithms are recently being proposed, artificial tree (AT) algorithm, inspired by the growth of trees and the update behavior of branches, is one of them. There are also some improved AT algorithms being proposed to improve their calculation accuracy. However, the main challenges of AT algorithms lie in the insufficiencies in the design of update operators as well as the position interaction between branches and the capture of key information and the performance of AT algorithms needs to be enhanced. This work proposes an improved AT algorithm with two populations (IATTP). In IATTP, the update strategies of branches are redesigned, and a variety of efficient update operators are designed and applied. The branch population is changed from one to two, and the competition mechanism between populations is proposed. Through the migration of branches between populations, the scale of population with better efficiency is expanded and the size of population with lower efficiency is reduced, thus a reasonable interaction between populations and branches is realized. With above strategies, the efficiency and accuracy of IATTP are significantly improved. The results of IATTP are proved to be advantageous when the performance of IATTP is compared with AT algorithm, improved artificial tree (IAT) algorithm and feedback artificial tree (FAT) algorithm through typical test problems. Meanwhile, the results of IATTP in current state are also preferable when IATTP is compared with other improved algorithms in high dimensional problems. The experimental results prove that IATTP is competitive in solving optimization problems.},
  archive      = {J_EAAI},
  author       = {Yaping Xiao and Hanbin Chi and Qiqi Li},
  doi          = {10.1016/j.engappai.2021.104324},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104324},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved artificial tree algorithm with two populations (IATTP)},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised support vector regression based on data
similarity and its application to rock-mechanics parameters estimation.
<em>EAAI</em>, <em>104</em>, 104317. (<a
href="https://doi.org/10.1016/j.engappai.2021.104317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rock-mechanics parameters such as Young’s modulus and Poisson’s ratio are critical to geomechanical analysis and resource exploration. Because these parameters come from laboratory measurement, they present some characteristics such as insufficient samples and contamination of outliers. In this paper, a novel semi-supervised support vector machine soft sensor is devised considering the characteristics of the parameters. First, it takes into account data similarity and selects labeled data set that are most similar to the continuous unlabeled data set at each iteration to improve estimation performance. Meanwhile, an outlier deletion algorithm is developed for a better similarity comparison. After that, a semi-supervised approach is presented for the estimation of rock-mechanics parameters, it can leverage continuous unlabeled data to train the model dynamically. Finally, the verification of our method is carried out on data set from UCI (University of California, Irvine) and several drilling sites. The results demonstrate that our method outperforms eight well-known methods in estimation accuracy.},
  archive      = {J_EAAI},
  author       = {Xi Chen and Weihua Cao and Chao Gan and Yasuhiro Ohyama and Jinhua She and Min Wu},
  doi          = {10.1016/j.engappai.2021.104317},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104317},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Semi-supervised support vector regression based on data similarity and its application to rock-mechanics parameters estimation},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep replacement: Reinforcement learning based constellation
management and autonomous replacement. <em>EAAI</em>, <em>104</em>,
104316. (<a
href="https://doi.org/10.1016/j.engappai.2021.104316">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Deep Reinforcement Learning (DRL) algorithm, Proximal Policy Optimization (PPO2), is deployed on a custom spacecraft (S/C) build and loss model to determine if an Artificial Intelligence (AI) can learn to monitor satellite constellation health and determine an optimal replacement strategy. A custom environment is created to simulate how S/C are built, launched, generate revenue, and finally decay. The reinforcement learning agent successfully learned an optimal policy for two models: a Simplified Model where the financial cost of actions is ignored; and an Advanced Model where the financial cost of actions is a major element. In both models the AI monitors the constellations and takes multiple strategic and tactical actions to replace satellites to maintain constellation performance. The Simplified Model showed that the PPO2 algorithm was able to converge on an optimal solution after ∼ 200,000 simulations. The Advanced Model was much more difficult for the AI to learn, and thus, the performance drops during the early episodes, but eventually converges to an optimal policy at ∼ 25,000,000 simulations. With the Advanced Model, the AI is taking actions that are successfully providing strategies for constellation management and satellite replacements which include these actions’ financial implications. Thus, the methods in this paper provide initial research developments towards a real-world tool and an AI application that can aid various Aerospace businesses in managing Low Earth Orbit (LEO) constellations. This type of AI application may become imperative for deploying and maintaining small satellite mega-constellations.},
  archive      = {J_EAAI},
  author       = {Joseph Kopacz and Jason Roney and Roman Herschitz},
  doi          = {10.1016/j.engappai.2021.104316},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104316},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep replacement: Reinforcement learning based constellation management and autonomous replacement},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EMORL: Effective multi-objective reinforcement learning
method for hyperparameter optimization. <em>EAAI</em>, <em>104</em>,
104315. (<a
href="https://doi.org/10.1016/j.engappai.2021.104315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter optimization is critical for the performance of machine learning algorithms. Significant efforts have been dedicated to improve the final accuracy of algorithm by hyperparameter tuning. However, some indicators (such as latency, cpu utilization) are also very important in the actual environment. In this paper, we propose a novel method EMORL ( E ffective M ulti- O bjective R einforcement L earning) based on multi-objective reinforcement learning for hyperparameter optimization to solve the above limitations. Specifically, we extend hyperparameter optimization problem to the reinforcement learning framework and employ an agent to select hyperparameters sequentially, and design a scalarization function that combines accuracy and latency as a multi-objective reward to guide the policy update. To improve the efficiency of hyperparameter optimization, previously successful configuration is reused for reshaping the advantage function. In the experiment, we apply the proposed method to tune the hyperparameters of the eXtreme Gradient Boosting on 101 tasks and convolutional neural networks on 2 tasks. The experimental results demonstrate that the proposed method is better than other methods in most tasks, especially in terms of latency. In addition, we verify the various components of the proposed method through ablation experiments.},
  archive      = {J_EAAI},
  author       = {SenPeng Chen and Jia Wu and XiYuan Liu},
  doi          = {10.1016/j.engappai.2021.104315},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104315},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {EMORL: Effective multi-objective reinforcement learning method for hyperparameter optimization},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QANA: Quantum-based avian navigation optimizer algorithm.
<em>EAAI</em>, <em>104</em>, 104314. (<a
href="https://doi.org/10.1016/j.engappai.2021.104314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution is an effective and practical approach that is widely applied for solving global optimization problems. Nevertheless, its effectiveness and scalability are decreased when the problems’ dimension is increased. Hence, this paper is devoted to proposing a novel DE algorithm named quantum-based avian navigation optimizer algorithm (QANA) inspired by the extraordinary precision navigation of migratory birds during long-distance aerial paths. In the QANA, the population is distributed by partitioning into multi flocks to explore the search space effectively using proposed self-adaptive quantum orientation and quantum-based navigation consisted of two mutation strategies, DE/quantum/I and DE/quantum/II. Except for the first iteration, each flock is assigned using an introduced success-based population distribution (SPD) policy to one of the quantum mutation strategies. Meanwhile, the information flow is shared through the population using a new communication topology named V-echelon. Furthermore, we introduce two long-term and short-term memories to provide meaningful knowledge for partial landscape analysis and a qubit-crossover operator to generate the next search agents. The effectiveness and scalability of the proposed QANA were extensively evaluated using benchmark functions CEC 2018 and CEC 2013 as LSGO problems. The results were statistically analyzed by the Wilcoxon signed-rank sum test, ANOVA, and mean absolute error tests. Finally, the applicability of the QANA to solve real-world problems was evaluated by four engineering problems. The experimental results and statistical analysis prove that the QANA is superior to the competitor DE and swarm intelligence algorithms in test functions CEC 2018 and CEC 2013, with overall effectiveness of 80.46% and 73.33%, respectively.},
  archive      = {J_EAAI},
  author       = {Hoda Zamani and Mohammad H. Nadimi-Shahraki and Amir H. Gandomi},
  doi          = {10.1016/j.engappai.2021.104314},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104314},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {QANA: Quantum-based avian navigation optimizer algorithm},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel complex evidential distance with its application in
pattern recognition. <em>EAAI</em>, <em>104</em>, 104312. (<a
href="https://doi.org/10.1016/j.engappai.2021.104312">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex evidence theory is an effective information fusion method, which can be used to fuse complex basic belief assignments (CBBAs) and obtain a reasonable result. In complex evidence theory, it is still an open issue for conflict management. In order to address this problem, this paper focuses on putting forward a new distance to measure conflict between CBBAs. The newly defined complex evidential distance takes into account not only the singletons, but also the subsets as well as their power sets. Therefore, it has a better performance to measure the conflict between the CBBAs. In addition, the proposed distance satisfies distance properties of nonnegativity, nondegeneracy, symmetry and the triangle inequality. In particular, when the CBBAs degenerate to classical BBAs, the proposed distance can also measure conflict well. Furthermore, a number of numerical examples are given to illustrate the above mentioned properties. Based on the newly devised distance measure, a basic pattern recognition algorithm is proposed. Subsequently, it is extended to a weighted scheme of pattern recognition algorithm. Finally, those two algorithms are applied to solve medical diagnosis to demonstrate their effectiveness.},
  archive      = {J_EAAI},
  author       = {Zhanhao Zhang and Fuyuan Xiao},
  doi          = {10.1016/j.engappai.2021.104312},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104312},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel complex evidential distance with its application in pattern recognition},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient robot localization and SLAM algorithms using
opposition based high dimensional optimization algorithm. <em>EAAI</em>,
<em>104</em>, 104308. (<a
href="https://doi.org/10.1016/j.engappai.2021.104308">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle filter (PF) is introduced to tackle the limitations of the Kalman filter which adopts Gaussian in the state and noise of the system. PFs have the problem of sample impoverishment and one approach to solve this problem is to optimize the proposal distribution shown by particles. This paper introduces a novel evolutionary PF based on Opposition based High Dimensional optimization Algorithm (OHDA) to reposition the particles of PF in high probable regions for estimation. OHDA will preserve the diversity of particles while emphasizing the more informative ones by information sharing and angular movement operators. Opposite particles are introduced in this paper to speed up the convergence of PF. Virtual forward movement by angular movement of OHDA is employed to better guide the search process. The optimized PF can improve the performance of the estimation algorithms in problems such as localization and SLAM. In robot localization problem, particles show the location of the robot in a known environment. For SLAM (Simultaneous Localization And Mapping), particles contain the location of the robot as well as estimated map of the environment. The application of the resulting evolutionary particle filter is tested in both localization and SLAM. Comparing the results of the proposed evolutionary particle filter with other algorithms confirms the efficiency of applying OHDA to PF in terms of improving estimation accuracy in the well-known Victoria park dataset and some other generated test environments. Comparing optimization algorithms on FASTSLAM and UFASTSLAM are PSO, FA, MVO, and MGWO.},
  archive      = {J_EAAI},
  author       = {Manizheh GhaemiDizaji and Chitra Dadkhah and Henry Leung},
  doi          = {10.1016/j.engappai.2021.104308},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104308},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient robot localization and SLAM algorithms using opposition based high dimensional optimization algorithm},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TriTSA: Triple tree-seed algorithm for dimensional
continuous optimization and constrained engineering problems.
<em>EAAI</em>, <em>104</em>, 104303. (<a
href="https://doi.org/10.1016/j.engappai.2021.104303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree-Seed Algorithm (TSA) is a meta-heuristic optimization algorithm with good performance in solving continuous optimization problems. However, there is an imbalance between its exploration and exploitation when solving complex problems, mainly lack exploration. To overcome this problem, this paper proposes two tree migration mechanisms: triple-learning-based migration mechanism and sine-random-distribution migration mechanism. The target tree position is migrated by learning from the first three trees in the current iteration. The sine function is added to the tree migration formula to enhance the randomness of tree distribution. In order to verify these migration mechanisms, Triple Tree-Seed Algorithm (TriTSA) has been proposed and compared with TSA on 30 well-known test functions from IEEE CEC 2014. In addition, STSA, SCA, PSO, ABC, Jaya, and TLBO are adopted in some comparative experiments on different dimensions. The experiments show that the tree migration mechanism can improve the optimization capability of the original algorithm effectively. On all 30 benchmark test functions, TriTSA outperforms TSA on 10, 30, 50, and 100 dimensions by 70%, 90%, 90%, and 97% respectively. Finally, the proposed TriTSA is compared with TSA, ABC, PSO, and SCA on solving two classical engineering design problems. It is proved that the proposed algorithm is more applicable in solving practical problems.},
  archive      = {J_EAAI},
  author       = {Jianhua Jiang and Yutong Liu and Ziying Zhao},
  doi          = {10.1016/j.engappai.2021.104303},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104303},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {TriTSA: Triple tree-seed algorithm for dimensional continuous optimization and constrained engineering problems},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new active contour model driven by pre-fitting bias field
estimation and clustering technique for image segmentation.
<em>EAAI</em>, <em>104</em>, 104299. (<a
href="https://doi.org/10.1016/j.engappai.2021.104299">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to uneven illumination or limitations of imaging devices, intensity inhomogeneities are more or less present in images obtained by different imaging modes. This ubiquitous intensity inhomogeneity makes image segmentation more difficult. This paper proposes a new bias field model (KPBFE) based on pre-fitting bias field estimation to deal with intensity inhomogeneity in the image segmentation. A new function for computing bias field b is proposed with K-means++ clustering algorithm. The computation method of clustering center points takes into account the average value of the grayscale within the contour of the bias field estimation and outside the contour. Meanwhile, we use a variational level set function with arctan function and a new adaptive function τ to limit the magnitude of the data driver term. Since the computation of bias field estimation is completed before the iteration and there is no convolution operation in the process, the computing speed of the proposed model is greatly increased. Experiments results show that our model can effectively segment the images with intensity inhomogeneity. Compared with some classical models, our method also has faster computation speed, higher segmentation accuracy and better initial robustness.},
  archive      = {J_EAAI},
  author       = {Guirong Weng and Bin Dong},
  doi          = {10.1016/j.engappai.2021.104299},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104299},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new active contour model driven by pre-fitting bias field estimation and clustering technique for image segmentation},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attitude-based entropy function and applications in
decision-making. <em>EAAI</em>, <em>104</em>, 104290. (<a
href="https://doi.org/10.1016/j.engappai.2021.104290">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The popular entropy functions are rigorously analysed in the context of uncertainty in the real world decision making. Based on the findings, a new entropy function is introduced specifically for the human decision making. The proposed function considers an agent’s degree of sensitivity towards uncertainty, i.e., the tendency to exaggerate or downplay the inherent uncertainty. The proposed entropy function is equipped to deal with both the subjective and probabilistic uncertainties alike, which are often interlinked in a decision-making context. The properties of the proposed entropy function are rigorously studied. A real case-study in portfolio diversification highlights the usefulness of the entropy function. It was found that the attitude plays a profound role, when there are a large number of uncertain systems (portfolios) to compare and choose from, or when the portfolios are more diversified.},
  archive      = {J_EAAI},
  author       = {Manish Aggarwal},
  doi          = {10.1016/j.engappai.2021.104290},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104290},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attitude-based entropy function and applications in decision-making},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural control of an induction motor with regenerative
braking as electric vehicle architecture. <em>EAAI</em>, <em>104</em>,
104275. (<a
href="https://doi.org/10.1016/j.engappai.2021.104275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the synthesis of an induction motor neural controller and a regenerative braking controller for an electric vehicle architecture, based on two energy system, a Main Energy System (MES) and an Auxiliary Energy System (AES). Such controllers are based on system identification, trajectory tracking and state estimation. System identification uses a Recurrent High Order Neural Network (RHONN), trained with an Extended Kalman Filter (EKF). RHONN obtains an accurate motor model which is robust in presence of external disturbances and parameter variations. To force the motor to track a desired torque trajectory and to reject undesired disturbances, an inverse optimal controller based on the identified neural model is proposed. Therefore, the proposed scheme does not need a-priori knowledge of motor parameters. For state estimation a super-twisting observer is implemented to estimate the rotor magnetic fluxes. The regenerative braking controller addresses the issue when the battery is not capable to accept the generated energy due to braking; Therefore, an AES based on a super capacitor and a buck–boost converter is a solution to recover the braking energy and give power to the motor during acceleration. The regenerative braking controller is based on a PI control to regulate voltage and current of the super capacitor. Simulation and experimental results illustrate the performance of the proposed controllers which are implemented using a rapid control prototyping platform integrated by a dSPACE board. Experimental tests are carried out for a topology with and without AES to illustrate the improvement of the proposed EV architecture.},
  archive      = {J_EAAI},
  author       = {Eduardo Quintero-Manríquez and Edgar N. Sanchez and M. Elena Antonio-Toledo and Flavio Muñoz},
  doi          = {10.1016/j.engappai.2021.104275},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104275},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Neural control of an induction motor with regenerative braking as electric vehicle architecture},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prioritization of key quality characteristics with the
three-dimensional HoQ model-based interval-valued spherical fuzzy-ORESTE
method. <em>EAAI</em>, <em>104</em>, 104271. (<a
href="https://doi.org/10.1016/j.engappai.2021.104271">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ranking key quality characteristics (KQCs) which are widely utilized to evaluate the product quality level and selecting the most important one are necessary for improving the quality of mechanical and electrical product. Many classical ranking methods have been proposed to rank KQCs, e.g., the classical quality function deployment (QFD) method, the classical ORESTE method. However, some drawbacks in constructing ranking framework, rating KQCs/influence factors (IFs) and ranking KQCs are existed in these methods. To solve this problem, we develop a three-dimensional house of quality (HoQ) model-based interval-valued spherical fuzzy-ORESTE (IVSF-ORESTE) method to rank KQCs. First, the three-dimensional HoQ models which add meta-action units (MAUs) dimension are constructed to provide a ranking framework, and interval-valued spherical fuzzy sets (IVSFSs) are utilized to rate KQCs/IFs. Secondly, some new distance and weight distance measures based on the Dice and the Jaccard similarity are proposed to extend the traditional distance measure between IVSFSs. Furthermore, the IVSF-QFD method is used to calculate the importance degrees of IFs and the KQCs are ranked with the IVSF-ORESTE method. Finally, a real case vis-à-vis a NC rotary table is illustrated to explain the implementation process of the proposed method, and discussion results indicate that the proposed ranking method is rational and valid.},
  archive      = {J_EAAI},
  author       = {Chuanxi Jin and Yan Ran and Zhichao Wang and Genbao Zhang},
  doi          = {10.1016/j.engappai.2021.104271},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104271},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prioritization of key quality characteristics with the three-dimensional HoQ model-based interval-valued spherical fuzzy-ORESTE method},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Caspar: Towards decision making helpers agents for IoT,
based on natural language and first order logic reasoning.
<em>EAAI</em>, <em>104</em>, 104269. (<a
href="https://doi.org/10.1016/j.engappai.2021.104269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the last decade, the market of Internet of Things has become quite disruptive, together with commercial clouds providing connection between every sort of devices and the global network, supported by vocal assistants. On the other hands, such commercial products are limited to work on limited domains, although easily scalable, without aspiring to higher level of reasoning in the field of Decisions Making. In this work, we show a way towards the design of an architecture for building cognitive agents leveraging Natural Language Processing. Such agents will be not based on clouds and do not require any semantic training, plus they will be able of deduction on facts and rules in First Order Logic inferred directly from Natural Language. After the description of the architecture and its underlying components, a case-study is provided to show the effectiveness in cases of direct commands and routines, subordinated also by a Meta-Reasoning in a conceptual space, parsing the utterances with promising real-time performances.},
  archive      = {J_EAAI},
  author       = {Carmelo Fabio Longo and Francesco Longo and Corrado Santoro},
  doi          = {10.1016/j.engappai.2021.104269},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {9},
  pages        = {104269},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Caspar: Towards decision making helpers agents for IoT, based on natural language and first order logic reasoning},
  volume       = {104},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SATPAS: SINR-based adaptive transmission power assignment
with scheduling in wireless sensor network. <em>EAAI</em>, <em>103</em>,
104313. (<a
href="https://doi.org/10.1016/j.engappai.2021.104313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a centralized metaheuristic algorithm is proposed for assigning minimum transmission power to each sensor node for every transmission link along with a scheduling slot while satisfying the Signal to Interference plus Noise Ratio constraint in the Wireless Sensor Network. Simultaneous communication in all communication links is not possible while maintaining SINR constraints. Thus, the algorithm also tries to maximize the number of concurrent transmission links in each scheduling slot. We formulate the optimization problem with two objective functions as (i) Communication link wise adaptive and minimum transmission power assignment together with scheduling slot number and (ii) Minimization of the required number of scheduling slots. Probabilistic interference model, which is more realistic, is used for calculating the receiver interference, unlike the graph-based interference model mostly described in the literature. Genetic Algorithm with Edge-set and Edge-window-decoder chromosome representation schemes are used for optimization. Extensive simulations are carried out to demonstrate the efficiency of proposed algorithms using different benchmark data sets and special network topologies like spiral, cluster, and mesh. Our proposed algorithm outperforms the existing MST-based algorithm in terms of minimum transmission power requirement, number of scheduling slots required, and rate of convergence.},
  archive      = {J_EAAI},
  author       = {Susil Kumar Mohanty and Siba K. Udgata},
  doi          = {10.1016/j.engappai.2021.104313},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104313},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SATPAS: SINR-based adaptive transmission power assignment with scheduling in wireless sensor network},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Type-2 neutrosophic number based multi-attributive border
approximation area comparison (MABAC) approach for offshore wind farm
site selection in USA. <em>EAAI</em>, <em>103</em>, 104311. (<a
href="https://doi.org/10.1016/j.engappai.2021.104311">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The technical, logistical, and ecological challenges associated with offshore wind development necessitate an extensive site selection analysis. Technical parameters such as wind resource, logistical concerns such as distance to shore, and ecological considerations such as fisheries all must be evaluated and weighted, in many cases with incomplete or uncertain data. Making such a critical decision with severe potential economic and ecologic consequences requires a strong decision-making approach to ultimately guide the site selection process. This paper proposes a type-2 neutrosophic number (T2NN) fuzzy based multi-criteria decision-making (MCDM) model for offshore wind farm (OWF) site selection. This approach combines the advantages of neutrosophic numbers sets, which can utilize uncertain and incomplete information, with a multi-attributive border approximation area comparison that provides formulation flexibility and easy calculation. Further, this study develops and integrates a techno-economic model for OWFs in the decision-making. A case study is performed to evaluate and rank five proposed OWF sites off the coast of New Jersey. To validate the proposed model, a comparison against three alternative T2NN fuzzy based models is performed. It is demonstrated that the implemented model yields the same ranking order as the alternative approaches. Sensitivity analysis reveals that changing criteria weightings does not affect the ranking order.},
  archive      = {J_EAAI},
  author       = {Muhammet Deveci and Nuh Erdogan and Umit Cali and Joseph Stekli and Shuya Zhong},
  doi          = {10.1016/j.engappai.2021.104311},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104311},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Type-2 neutrosophic number based multi-attributive border approximation area comparison (MABAC) approach for offshore wind farm site selection in USA},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A flexible risk assessment approach integrating subjective
and objective weights under uncertainty. <em>EAAI</em>, <em>103</em>,
104310. (<a
href="https://doi.org/10.1016/j.engappai.2021.104310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk assessment plays a critical role in the product design, manufacture and production process for different engineering fields. Traditionally, risk assessment-related issues are addressed using the failure mode and effects analysis approach to perform reliability analysis. However, information provided by experts in the risk assessment process often includes complete information, incomplete information and hesitant information at the same time. The traditional failure mode and effects analysis approach cannot handle incomplete information and hesitant information in the risk assessment process. Moreover, the traditional failure mode and effects analysis approach does not take into account the subjective and objective weights of the risk factors. In order to effectively overcome the limitations of the traditional failure mode and effects analysis method, this paper proposes a novel flexible risk assessment approach integrating subjective and objective weights under uncertainty. For handling the incomplete information, the proposed method uses currently known information to fill in the missing information. On the other hand, the proposed method uses hesitant fuzzy linguistic term set instead of single linguistic term set to handle hesitant information in the risk assessment process. Moreover, the proposed uses the concept of statistical variance to calculate the objective weights of the risk factors. An illustrative example of the screen printing stage of photovoltaic cell manufacturing is adopted to demonstrate the rationality and practicability of the proposed method. This paper also compares the risk priority results of the proposed method with those of the traditional FMEA method, the hesitant fuzzy linguistic term set method, and the Rao and Patel (2010) method. The simulation results indicate that the proposed can provide more correctly rank the identified causes of failure. The proposed not only simultaneously considers the subjective and objective weights for the risk factors, but also can handle hesitant information and missing information of the assessment attribute values.},
  archive      = {J_EAAI},
  author       = {Ta-Chun Wen and Hsiang-Yu Chung and Kuei-Hu Chang and Zong-Sian Li},
  doi          = {10.1016/j.engappai.2021.104310},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104310},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A flexible risk assessment approach integrating subjective and objective weights under uncertainty},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An enhanced archimedes optimization algorithm based on local
escaping operator and orthogonal learning for PEM fuel cell parameter
identification. <em>EAAI</em>, <em>103</em>, 104309. (<a
href="https://doi.org/10.1016/j.engappai.2021.104309">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-heuristic optimization algorithms aim to tackle real world problems through maximizing some specific criteria such as performance, profit, and quality or minimizing others such as cost, time, and error. Accordingly, this paper introduces an improved version of a well-known optimization algorithm namely Archimedes optimization algorithm (AOA). The enhanced version combines two efficient strategies namely Local escaping operator (LEO) and Orthogonal learning (OL) to introduce the (I-AOA) optimization algorithm. Moreover, the performance of the proposed I-AOA has been evaluated on the CEC’2020 test suite, and three engineering design problems. Furthermore, I-AOA is applied to determine the optimal parameters of polymer electrolyte membrane (PEM) fuel cell (FC). Two commercial types of PEM fuel cells: 250W PEMFC and BCS 500W are considered to prove the superiority of the proposed optimizer. During the optimization procedure, the seven unknown parameters ( ξ 1 , ξ 2 , ξ 3 , ξ 4 , λ , R C , and b ) of PEM fuel cell are assigned to be the decision variables. Whereas the cost function that required to be in a minimum state is represented by the RMSE between the estimated cell voltage and the measured data. The obtained results by the I-AOA are compared to other well-known optimizers such as Whale Optimization Algorithm (WOA), Moth-Flame Optimization Algorithm (MFO), Sine Cosine Algorithm (SCA), Particle Swarm Optimization Algorithm (PSO), Harris hawks optimization (HHO), Tunicate Swarm Algorithm (TSA) and original AOA. The comparison confirmed the superiority of the suggested algorithm in identifying the optimum PEM fuel cell parameters considering various operating conditions compared to the other optimization algorithms.},
  archive      = {J_EAAI},
  author       = {Essam H. Houssein and Bahaa El-din Helmy and Hegazy Rezk and Ahmed M. Nassef},
  doi          = {10.1016/j.engappai.2021.104309},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104309},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An enhanced archimedes optimization algorithm based on local escaping operator and orthogonal learning for PEM fuel cell parameter identification},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An imperialist competitive algorithm with feedback for
energy-efficient flexible job shop scheduling with transportation and
sequence-dependent setup times. <em>EAAI</em>, <em>103</em>, 104307. (<a
href="https://doi.org/10.1016/j.engappai.2021.104307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Flexible job shop scheduling problems have been extensively investigated in the past decade; however, transportation, sequence-dependent setup times (SDST) and energy efficiency are seldom incorporated together in flexible job shop. In this paper, energy-efficient flexible job shop scheduling problem (EFJSP) with transportation and SDST is considered and an imperialist competitive algorithm with feedback (FICA) is developed to minimize makespan, total tardiness and total energy consumption simultaneously. Assimilation and adaptive revolution are newly implemented by feedback and a new imperialist competition is presented by solution transferring among empires and the reinforced search. Extensive experiments are conducted and the computational results demonstrate that FICA provides promising results for EFJSP with transportation and SDST.},
  archive      = {J_EAAI},
  author       = {Ming Li and Deming Lei},
  doi          = {10.1016/j.engappai.2021.104307},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104307},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An imperialist competitive algorithm with feedback for energy-efficient flexible job shop scheduling with transportation and sequence-dependent setup times},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Five-step discrete-time noise-tolerant zeroing neural
network model for time-varying matrix inversion with application to
manipulator motion generation. <em>EAAI</em>, <em>103</em>, 104306. (<a
href="https://doi.org/10.1016/j.engappai.2021.104306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel Taylor-type difference rule with O ( τ 4 ) pattern error is provided for the first-order derivative approximation. Then, a high accuracy noise-tolerant five-step discrete-time zeroing neural network (ZNN) (termed as FDNTZNN model) is proposed to solve the time-varying matrix inversion problem in real-time. In addition, to obtain the derivative value of time-varying variables in real-world applications, the backward-difference rule is exploited to develop the FD-NTZNN model when the derivative information is unknown (FD-NTZNN-U). Theoretical analysis demonstrates that the proposed FD-NTZNN models have the properties of 0 − stability, consistency and convergence. For comparative analysis, the classical Euler-type discrete-time ZNN model (EDZNN), five-step Taylor-type discrete-time ZNN model (FDZNN) and Euler-type discrete-time noise-tolerant ZNN (NTZNN) model (ED-NTZNN) are reconsidered. Ultimately, two illustrative numerical simulations and an application example to motion generation of manipulator are simulated to substantiate the feasibility and effectiveness of the proposed FD-NTZNN model and FD-NTZNN-U model for online time-varying matrix inversion in the presence of different types of noise.},
  archive      = {J_EAAI},
  author       = {Keping Liu and Yongbai Liu and Yun Zhang and Lin Wei and Zhongbo Sun and Long Jin},
  doi          = {10.1016/j.engappai.2021.104306},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104306},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Five-step discrete-time noise-tolerant zeroing neural network model for time-varying matrix inversion with application to manipulator motion generation},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multimodal deep fusion graph framework to detect social
distancing violations and FCGs in pandemic surveillance. <em>EAAI</em>,
<em>103</em>, 104305. (<a
href="https://doi.org/10.1016/j.engappai.2021.104305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In pandemic surveillance, ensuring social distance has emerged as a challenging issue due to the lack of proper therapeutic agents, and this envisages the need for automated social distance monitoring to avoid the formation of social gatherings and free-standing conversation groups (FCGs). The robustness sought in detecting these groups cannot be achieved when there are illumination variation and occlusion among subjects by solely relying on video data from distributed cameras. In this paper, we propose a deep learning framework for integrating data from multiple sensor modalities taking into account the spatial properties necessary to manage illumination variation and occlusion of video data. From the fused data, social distance compliance violations are notified by the presence of social groups as graphs detected using a pre-trained deep framework and connected components in graph theory. A cost function is devised for social group graph clustering to identify FCGs by using the socio-psychological theory of Friends-formation. Experiment analysis on four benchmark datasets shows that the proposed approach excels at detecting social distance violations and FCGs, and succeeds in analyzing the potential risk of pandemic spread in an area by the calculation of violation scores and rate of violation.},
  archive      = {J_EAAI},
  author       = {Elizabeth B. Varghese and Sabu M. Thampi},
  doi          = {10.1016/j.engappai.2021.104305},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104305},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multimodal deep fusion graph framework to detect social distancing violations and FCGs in pandemic surveillance},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Entropy based designing and analysis of a compact single
layer double negative metamaterial with oblique incidents.
<em>EAAI</em>, <em>103</em>, 104304. (<a
href="https://doi.org/10.1016/j.engappai.2021.104304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The underlying study investigates a novel fuzzy cross entropy based methodology for enhancing the designing and analysis of a compact single layer double negative metamaterial with varying oblique incidents. Materials having a refractive index greater than unity may slow down the propagation of waves in comparison to the vacuum. A material with zero refractive index can boost the speed and wavelength of the wave to infinity. Nevertheless, metamaterials with a negative index of refraction have the necessary capability for controlling the wave velocity, although, mimicking zero index property in materials is quite difficult in real practices. Based on experimental observations and data visualizations, the lower bound of each measured indiscriminative index of refraction is extracted at various oblique incidents and then rehabilitated into the form of normalized and idealized fuzzy index sets (FISs). Thereafter, the proposed fuzzy cross entropy measure is deployed for identifying the most negative indiscriminative refractive index along with the desired wave velocity, intended to obtain the best incident angle and desired transition frequency. The experimental results suggest that the structure is behaving as a double negative metamaterial for all the azimuth angles with transition frequency fluctuating near to 7 GHz with different negative levels. The lowest transition frequency for the designed structure is observed at 0°azimuthal and increases thereafter with augmenting incident angle up to 90°. Although, the observed transition frequency decreases thereafter with further augmentation of incident angle (from 90°to 180°) and exhibits approximate symmetry in terms of transition frequency with the center of symmetry at 90°. Subsequently, the minimum (maximum) fuzzy cross entropy value between normalized and idealized fuzzy index sets is deployed to obtain the highest (lowest) wave velocity, which is observed at 135°(157.5°) azimuthal angle. The underlying fuzzy cross entropy-based methodology is capable of handling double negative metamaterial with oblique incidents and can effectively be applied for achieving the desired wave velocity as well as indiscriminative refractive index, depending upon the application requirements.},
  archive      = {J_EAAI},
  author       = {Harbinder Singh and C.P. Gandhi and Amit Gupta and Surbhi Bakshi},
  doi          = {10.1016/j.engappai.2021.104304},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104304},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Entropy based designing and analysis of a compact single layer double negative metamaterial with oblique incidents},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CAFE: Knowledge graph completion using neighborhood-aware
features. <em>EAAI</em>, <em>103</em>, 104302. (<a
href="https://doi.org/10.1016/j.engappai.2021.104302">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graphs (KGs) currently contain a vast amount of structured information in the form of entities and relations. Because KGs are often constructed automatically by means of information extraction processes, they may miss information that was either not present in the original source or not successfully extracted. As a result, KGs might lack useful and valuable information. Current approaches that aim to complete missing information in KGs have two main drawbacks. First, some have a dependence on embedded representations, which impose a very expensive preprocessing step and need to be recomputed again as the KG grows. Second, others are based on long random paths that may not cover all relevant information, whereas exhaustively analyzing all possible paths between entities is very time-consuming. In this paper, we present an approach to complete KGs based on evaluating candidate triples using a set of neighborhood-based features. Our approach exploits the highly connected nature of KGs by analyzing the entities and relations surrounding any given pair of entities, while avoiding full recomputations as new entities are added. Our results indicate that our proposal is able to identify correct triples with a higher effectiveness than other state-of-the-art approaches, achieving higher average F1 scores in all tested datasets. Therefore, we conclude that the information present in the vicinities of the two entities within a candidate triple can be leveraged to determine whether that triple is missing from the KG or not.},
  archive      = {J_EAAI},
  author       = {Agustín Borrego and Daniel Ayala and Inma Hernández and Carlos R. Rivero and David Ruiz},
  doi          = {10.1016/j.engappai.2021.104302},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104302},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {CAFE: Knowledge graph completion using neighborhood-aware features},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-term forecasting of multivariate time series in
industrial furnaces with dynamic gaussian bayesian networks.
<em>EAAI</em>, <em>103</em>, 104301. (<a
href="https://doi.org/10.1016/j.engappai.2021.104301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many of the data sets extracted from real-world industrial environments are time series that describe dynamic processes with characteristics that change over time. In this paper, we focus on the fouling process in an industrial furnace, which corresponds to a non-stationary multivariate time series with a seasonal component, non-homogeneous cycles and sporadic human interventions. We aim to forecast the evolution of the temperature inside the furnace over a long span of time of two and a half months. To accomplish this, we model the time series with dynamic Gaussian Bayesian networks (DGBNs) and compare their performance with convolutional recurrent neural networks. Our results show that DGBNs are capable of properly treating seasonal data and can capture the tendency of a time series without being distorted by the effect of interventions or by the varying length of the cycles.},
  archive      = {J_EAAI},
  author       = {David Quesada and Gabriel Valverde and Pedro Larrañaga and Concha Bielza},
  doi          = {10.1016/j.engappai.2021.104301},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104301},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-term forecasting of multivariate time series in industrial furnaces with dynamic gaussian bayesian networks},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault source location of wind turbine based on heterogeneous
nodes complex network. <em>EAAI</em>, <em>103</em>, 104300. (<a
href="https://doi.org/10.1016/j.engappai.2021.104300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous studies regarding wind turbine health management based on wind turbine supervisory control and data acquisition (SCADA) signals focused on detecting incipient failure. In this case, most current SCADA alarm systems adopt a single or multi-signal threshold trigger alarm. When a wind turbine is operating in a large wind farm, it is catastrophic for maintenance personnel lied in the reason that the current SCADA system may trigger many alarms in the short term. Therefore, the fault source must be identified and the candidate fault sources sorted. This study aims to obtain the fault location of wind turbines based on a complex network, which does not require a large number of historical monitoring signals. A directed graph of the wind turbine and fault location theoretical framework is established; an improvement is achieved based on the heterogeneity of nodes abstracted by components of a wind turbine and variables of SCADA. The proposed fault location method based on heterogeneous nodes complex networks (HNCN) is improved based on degree-based mean-field theory and is verified by spreading simulated data and four SCADA alarm cases at a wind farm located in Liaoning, China.},
  archive      = {J_EAAI},
  author       = {Kai Zhang and Baoping Tang and Lei Deng and Xiaoxia Yu and Jing Wei},
  doi          = {10.1016/j.engappai.2021.104300},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104300},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fault source location of wind turbine based on heterogeneous nodes complex network},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pushing artificial intelligence to the edge: Emerging
trends, issues and challenges. <em>EAAI</em>, <em>103</em>, 104298. (<a
href="https://doi.org/10.1016/j.engappai.2021.104298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Giancarlo Fortino ( Managing Guest Editor ) and MengChu Zhou and Mohammad Mehedi Hassan and Mukaddim Pathan and Stamatis Karnouskos},
  doi          = {10.1016/j.engappai.2021.104298},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104298},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pushing artificial intelligence to the edge: Emerging trends, issues and challenges},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel grey multivariate model for forecasting landslide
displacement. <em>EAAI</em>, <em>103</em>, 104297. (<a
href="https://doi.org/10.1016/j.engappai.2021.104297">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting landslide displacement is an important issue in engineering geology. In this field, it is difficult to accurately forecast the displacement of the step point of a step-type landslide. In this study, a novel grey multivariate model is proposed for forecasting landslide displacement. The proposed model transforms the original sequence by using the Hausdorff derivative operator, determines the model parameters by using the particle swarm optimization algorithm, and uses the trapezoidal integral formula to calculate the predicted value. Two numerical examples show that the average absolute relative error and mean squared error of the proposed model are smaller than those of the recursive discrete multivariate grey model and the multivariable grey model with structure compatibility. The proposed model is used to forecast the displacement of the Bazimen landslide in the Three Gorges Reservoir area of China. The previous month’s displacement, precipitation, and change in the reservoir water level are used as input variables. The results show that the performance of the proposed model is superior to that of the extreme learning machine model. This paper provides an effective method for forecasting displacement of the step point of a step-type landslide.},
  archive      = {J_EAAI},
  author       = {S.H. Li and L. Zhu and Y. Wu and X.Q. Lei},
  doi          = {10.1016/j.engappai.2021.104297},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104297},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel grey multivariate model for forecasting landslide displacement},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptable automation with modular deep reinforcement
learning and policy transfer. <em>EAAI</em>, <em>103</em>, 104296. (<a
href="https://doi.org/10.1016/j.engappai.2021.104296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Future industrial automation systems are anticipated to be shaped by intelligent technologies that allow for the adaptability of machines to the variations and uncertainties in processes and work environments. This paper is motivated by the need for devising new intelligent methods that enable efficient and scalable training of collaborative robots on a variety of tasks that foster their adaptability to new tasks and environments. Recent advances in deep Reinforcement Learning (RL) provide new possibilities to realize this vision. The state-of-the-art in deep RL offers proven algorithms that enable autonomous learning and mastery of a variety of robotic manipulation tasks with minimal human intervention. However, current deep RL algorithms predominantly specialize in a narrow range of tasks, are sample inefficient, and lack sufficient stability, which hinders their adoption in real-life, industrial settings. This paper develops and tests a Hyper-Actor Soft Actor–Critic (HASAC) deep RL framework based on the notions of task modularization and transfer learning to tackle this limitation. The goal of the proposed HASAC is to enhance an agent’s adaptability to new tasks by transferring the learned policies of former tasks to the new task through a ”hyper-actor”. The HASAC framework is tested on the virtual robotic manipulation benchmark, Meta-World. Numerical experiments indicate superior performance by HASAC over state-of-the-art deep RL algorithms in terms of reward value, success rate, and task completion time.},
  archive      = {J_EAAI},
  author       = {Zohreh Raziei and Mohsen Moghaddam},
  doi          = {10.1016/j.engappai.2021.104296},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104296},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptable automation with modular deep reinforcement learning and policy transfer},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A physics-informed deep learning approach for bearing fault
detection. <em>EAAI</em>, <em>103</em>, 104295. (<a
href="https://doi.org/10.1016/j.engappai.2021.104295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, advances in computer technology and the emergence of big data have enabled deep learning to achieve impressive successes in bearing condition monitoring and fault detection. While existing deep learning approaches are able to efficiently detect and classify bearing faults, most of these approaches depend exclusively on data and do not incorporate physical knowledge into the learning and prediction processes—or more importantly, embed the physical knowledge of bearing faults into the model training process, which makes the model physically meaningful. To address this challenge, we propose a physics-informed deep learning approach that consists of a simple threshold model and a deep convolutional neural network (CNN) model for bearing fault detection. In the proposed physics-informed deep learning approach, the threshold model first assesses the health classes of bearings based on known physics of bearing faults. Then, the CNN model automatically extracts high-level characteristic features from the input data and makes full use of these features to predict the health class of a bearing. We designed a loss function for training and validating the CNN model that selectively amplifies the effect of the physical knowledge assimilated by the threshold model when embedding this knowledge into the CNN model. The proposed physics-informed deep learning approach was validated using (1) data from 18 bearings on an agricultural machine operating in the field, and (2) data from bearings on a laboratory test stand in the Case Western Reserve University (CWRU) Bearing Data Center.},
  archive      = {J_EAAI},
  author       = {Sheng Shen and Hao Lu and Mohammadkazem Sadoughi and Chao Hu and Venkat Nemani and Adam Thelen and Keith Webster and Matthew Darr and Jeff Sidon and Shawn Kenny},
  doi          = {10.1016/j.engappai.2021.104295},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104295},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics-informed deep learning approach for bearing fault detection},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Maximum 3D tsallis entropy based multilevel thresholding of
brain MR image using attacking manta ray foraging optimization.
<em>EAAI</em>, <em>103</em>, 104293. (<a
href="https://doi.org/10.1016/j.engappai.2021.104293">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nevertheless, the accuracy of a multilevel image thresholding technique using 1D or 2D Tsallis entropy is limited. To overcome this, we propose a maximum 3D Tsallis entropy-based multilevel thresholding method. The idea of 3D Tsallis entropy is introduced. Opposed to the 1D/2D Tsallis entropy, the 3D Tsallis entropy-based approach is more robust, it performs well even in the case of the low signal-to-noise-ratio and contrast. Manta Ray Foraging Optimization (MRFO) algorithm is a newly introduced algorithm to solve the optimization problem by imitating the foraging technique of Manta Ray fish in the ocean using a mathematical model. Due to insufficient energy levels of search agents in MRFO, they fail to avoid local minima and fall on it. To make the algorithm more effective for the segmentation application, we introduce a new algorithm coined as attacking Manta Ray foraging optimization (AMRFO). A set of classical benchmark functions together with composite functions (CEC 2014) is used to validate the proposed AMRFO algorithm. Statistical analysis is implicitly carried out using Wilcoxon’s signed-rank test and Friedman’s mean rank test. Interestingly, the results show that the proposed AMRFO is superior to the state-of-the-art optimization algorithms. Moreover, the proposed method is also compared with 1D/2D Tsallis entropy-based approaches. To experiment, 100 test images from the AANLIB MR Image dataset are considered. Our method outperforms 1D/2D Tsallis entropy-based approaches. The proposed scheme would be useful for the segmentation of multi-spectral color images.},
  archive      = {J_EAAI},
  author       = {Bibekananda Jena and Manoj Kumar Naik and Rutuparna Panda and Ajith Abraham},
  doi          = {10.1016/j.engappai.2021.104293},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104293},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Maximum 3D tsallis entropy based multilevel thresholding of brain MR image using attacking manta ray foraging optimization},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A retrospective study on handwritten mathematical symbols
and expressions: Classification and recognition. <em>EAAI</em>,
<em>103</em>, 104292. (<a
href="https://doi.org/10.1016/j.engappai.2021.104292">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Context: Many scientific and technical literature documents contain MSs and MEs that are more challenging to be recognized by computers than plain text. The recognition of HMSE becomes not only an ambitious task but a motivating research area covering concepts of computer vision, pattern recognition, feature extraction, and artificial intelligence. Objective: The objective is to perform an extensive state of the art on the techniques and methods used for recognizing and classifying HMSE. The authors endeavor to bring out all significant findings in sub-processes, representation models, algorithms, tools, datasets, and comparative analysis of the accuracy of the recognition models. Method: The current research implements the standard SLR method based on a comprehensive set of 120 articles published in 21 leading journals and 39 premier conferences and workshops. Results: Existing literature about recognition techniques and models is classified broadly into three categories; AI technique (65%) is majorly implemented in the selected studies. The prominent sub-process ‘segmentation’ (52%) is mostly used. The box and tree are the prevailing representation models. The popular datasets are recognized as CROHME 2014 and CROHME 2016, used by 60% of the selected studies. Masaki Nakagawa, C. Viard Guardin, Richard Zanibbi, and Harold Mouchere are the most noticed authors in ME recognition. Conclusion: The reviewers call for increased awareness of the potential benefits of existing and emerging recognition techniques and identify the need to develop a more accurate and semantic-based recognition model. Recommendations are given for future research.},
  archive      = {J_EAAI},
  author       = {Sakshi and Vinay Kukreja},
  doi          = {10.1016/j.engappai.2021.104292},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104292},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A retrospective study on handwritten mathematical symbols and expressions: Classification and recognition},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NHACR: A novel heuristic approach for 2D rectangle packing
area minimization problem with central rectangle. <em>EAAI</em>,
<em>103</em>, 104291. (<a
href="https://doi.org/10.1016/j.engappai.2021.104291">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a special 2D rectangle packing problem, the 2D rectangle packing area minimization problem with central rectangle (CR-RPAMP) has one or more central rectangles among the candidate items. The central rectangles should be packed near the center of the final layout. At the same time, the length–width ratio of the final layout must be within a reasonable region. The CR-RPAMP has been applied in many areas such as the layout design of semi-submersible platform, farmland irrigation, urban planning. In this study, to improve the performance of heuristic approach for solving the CR-RPAMP, three novel strategies including strategy of filling inner space, strategy of generating inner space and strategy of simplifying packing process, are proposed and combined to form a novel heuristic approach NHACR (Novel Heuristic Approach for CR-RPAMP). The analyses of computational complexity of the proposed NHACR indicate that it has low computational complexity. Based on two famous sets of benchmark instances, the proposed NHACR shows better performance compared with several existing algorithms considering the success rate, the filling rate of final layout and the computing time. Finally, the NHACR is utilized to solve a specific application problem in oil and gas industry and its advantage is further confirmed.},
  archive      = {J_EAAI},
  author       = {Lei Wu and Xinming Li and Chao Liu and Wensheng Xiao},
  doi          = {10.1016/j.engappai.2021.104291},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104291},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {NHACR: A novel heuristic approach for 2D rectangle packing area minimization problem with central rectangle},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discriminative semi-supervised non-negative matrix
factorization for data clustering. <em>EAAI</em>, <em>103</em>, 104289.
(<a href="https://doi.org/10.1016/j.engappai.2021.104289">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently semi-supervised non-negative matrix factorization (NMF) has received a lot of attentions in computer vision, information retrieval and pattern recognition, because that partial label information can produce considerable improvement in learning accuracy of the algorithms. However, the existing semi-supervised NMF algorithms cannot make full use of label information, that is, they cannot guarantee that the labeled data of different clusters will not be classified into a same group in the new representation space. In this paper, we propose a novel discriminative semi-supervised NMF (DSSNMF) algorithm, which utilizes the label information of a fraction of the data as a discriminative constraint. We explore the proposed DSSNMF method with two different cost function formulations and provide the corresponding update rules for the optimization problems. Empirical experiments demonstrate the effectiveness of our novel algorithm through a set of evaluations based on real-world applications.},
  archive      = {J_EAAI},
  author       = {Zhiwei Xing and Meng Wen and Jigen Peng and Jinqian Feng},
  doi          = {10.1016/j.engappai.2021.104289},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104289},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Discriminative semi-supervised non-negative matrix factorization for data clustering},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Industry 4.0: Latent dirichlet allocation and clustering
based theme identification of bibliography. <em>EAAI</em>, <em>103</em>,
104280. (<a
href="https://doi.org/10.1016/j.engappai.2021.104280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Industry 4.0 with its fusion of technologies has brought an unprecedented growth in all sectors. In this paper, we first present the several pillars of Industry 4.0 which have contributed to the advancement of this field. Then, we perform a bibliometric profile of the Industry 4.0 publications in Web of Science by analyzing the publications and citation structure, most referenced publications, most productive and influential authors, organizations and countries. Further, an extensive analysis of the key words is presented along with the citation bursts of top keywords. Various visualizations tools have been to used show relationships between different bibliometric profiles. The individual growth of different research areas over the year is also presented. The results show promising growth of Industry 4.0 as a research area, various collaborative groups have been identified which are working extensively in the growth of the domain, spearheaded by China, however, considerable contribution of developing countries is also there. An abstract analysis is done using K-means clustering and Latent Dirichlet Allocation (LDA) to identify key research themes.},
  archive      = {J_EAAI},
  author       = {Manvendra Janmaijaya and Amit K. Shukla Ph.D. and Pranab K. Muhuri and Ajith Abraham},
  doi          = {10.1016/j.engappai.2021.104280},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104280},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Industry 4.0: Latent dirichlet allocation and clustering based theme identification of bibliography},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simulation–optimization framework for enhancing robustness
in bulk berth scheduling. <em>EAAI</em>, <em>103</em>, 104276. (<a
href="https://doi.org/10.1016/j.engappai.2021.104276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The service time of the vessels is one of the main indicators of ports’ competitiveness. This, together with the increasing volume of bulk transportation, make the efficient management of scarce resources such as berths a crucial option for enhancing the productivity of the overall terminal. In real scenarios, the information available to port operators may vary once the planning has been elaborated. Unforeseen events, errors, or modifications in the available information can lead to inefficient terminal management and the initial scheduling might become unfeasible. This implies that the use of deterministic approaches may not be enough to maximize productivity. Therefore, in this work, proactive simulation–optimization approaches that utilize the information collected during the simulation for guiding the optimization search to provide robust solutions are proposed. Moreover, a multi-objective approach based on the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) for jointly tackling the problem objective as well as the deviations because of stochastic changes is developed. Finally, we also investigate the contribution of time management strategies such as buffers to absorb stochastic modifications and hence increase solutions’ robustness. The computational results indicate, on the one hand, the benefit of integrating both types of objectives (i.e., deterministic and stochastic) to guide the simulation–optimization process, and on the other hand, the benefit of using the multi-objective approaches like NSGA-II. Finally, the incorporation of buffers leads to better performance in terms of reducing penalty costs due to disruptions, shortening the planning risks related to only considering deterministic planning.},
  archive      = {J_EAAI},
  author       = {Alan Dávila de León and Eduardo Lalla-Ruiz and Belén Melián-Batista and J. Marcos Moreno-Vega},
  doi          = {10.1016/j.engappai.2021.104276},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104276},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A simulation–optimization framework for enhancing robustness in bulk berth scheduling},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Giving commands to a self-driving car: How to deal with
uncertain situations? <em>EAAI</em>, <em>103</em>, 104257. (<a
href="https://doi.org/10.1016/j.engappai.2021.104257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current technology for autonomous cars primarily focuses on getting the passenger from point A to B. Nevertheless, it has been shown that passengers are afraid of taking a ride in self-driving cars. One way to alleviate this problem is by allowing the passenger to give natural language commands to the car. However, the car can misunderstand the issued command or the visual surroundings which could lead to uncertain situations. It is desirable that the self-driving car detects these situations and interacts with the passenger to solve them. This paper proposes a model that detects the uncertain situations when a command is given and finds the visual objects causing it. Optionally, a question generated by the system describing the uncertain objects is included. We argue that if the car could explain the objects in a human-like way, passengers could gain more confidence in the car’s abilities. Thus, we investigate how to (1) detect uncertain situations and their underlying causes, and (2) how to generate clarifying questions for the passenger. When evaluating on the Talk2Car dataset, we show that the proposed model, Uncertainty Resolving System (URS), improves 12.6% in terms of I o U . 5 compared to not using URS. Furthermore, we designed a referring expression generator (REG) Attribute-Referring Expression Generator (A-REG) tailored to a self-driving car setting which yields a relative improvement of 6% METEOR and 8% ROUGE-l compared with state-of-the-art REG models, and is three times faster.},
  archive      = {J_EAAI},
  author       = {Thierry Deruyttere and Victor Milewski and Marie-Francine Moens},
  doi          = {10.1016/j.engappai.2021.104257},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {8},
  pages        = {104257},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Giving commands to a self-driving car: How to deal with uncertain situations?},
  volume       = {103},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RISE controller tuning and system identification through
machine learning for human lower limb rehabilitation via neuromuscular
electrical stimulation. <em>EAAI</em>, <em>102</em>, 104294. (<a
href="https://doi.org/10.1016/j.engappai.2021.104294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromuscular electrical stimulation (NMES) has been effectively applied in many rehabilitation treatments of individuals with spinal cord injury (SCI). In this context, we introduce a novel, robust, and intelligent control-based methodology to closed-loop NMES systems. Our approach utilizes a robust control law to guarantee system stability and machine learning tools to optimize both the controller parameters and system identification. Regarding the latter, we introduce the use of past rehabilitation data to build more realistic data-driven identified models. Furthermore, we apply the proposed methodology for the rehabilitation of lower limbs using a control technique named the robust integral of the sign of the error (RISE), an offline improved genetic algorithm optimizer, and neural network models. Although in the literature, the RISE controller presented good results on healthy subjects, without any fine-tuning method, a trial and error approach would quickly lead to muscle fatigue for individuals with SCI. In this paper, for the first time, the RISE controller is evaluated with two paraplegic subjects in one stimulation session and with seven healthy individuals in at least two and at most five sessions. The results showed that the proposed approach provided a better control performance than empirical tuning, which can avoid premature fatigue on NMES-based clinical procedures.},
  archive      = {J_EAAI},
  author       = {Héber H. Arcolezi and Willian R.B.M. Nunes and Rafael A. de Araujo and Selene Cerna and Marcelo A.A. Sanches and Marcelo C.M. Teixeira and Aparecido A. de Carvalho},
  doi          = {10.1016/j.engappai.2021.104294},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104294},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {RISE controller tuning and system identification through machine learning for human lower limb rehabilitation via neuromuscular electrical stimulation},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning-based application autoscaling in the
cloud: A survey. <em>EAAI</em>, <em>102</em>, 104288. (<a
href="https://doi.org/10.1016/j.engappai.2021.104288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reinforcement Learning (RL) has demonstrated a great potential for automatically solving decision-making problems in complex, uncertain environments. RL proposes a computational approach that allows learning through interaction in an environment with stochastic behavior, where agents take actions to maximize some cumulative short-term and long-term rewards. Some of the most impressive results have been shown in Game Theory where agents exhibited superhuman performance in games like Go or Starcraft 2, which led to its gradual adoption in many other domains, including Cloud Computing. Therefore, RL appears as a promising approach for Autoscaling in Cloud since it is possible to learn transparent (with no human intervention), dynamic (no static plans), and adaptable (constantly updated) resource management policies to execute applications. These are three important distinctive aspects to consider in comparison with other widely used autoscaling policies that are defined in an ad-hoc way or statically computed as in solutions based on meta-heuristics. Autoscaling exploits the Cloud elasticity to optimize the execution of applications according to given optimization criteria, which demands deciding when and how to scale up/down computational resources and how to assign them to the upcoming processing workload. Such actions have to be taken considering that the Cloud is a dynamic and uncertain environment. Motivated by this, many works apply RL to the autoscaling problem in the Cloud. In this work, we exhaustively survey those proposals from major venues, and uniformly compare them based on a set of proposed taxonomies. We also discuss open problems and prospective research in the area.},
  archive      = {J_EAAI},
  author       = {Yisel Garí and David A. Monge and Elina Pacini and Cristian Mateos and Carlos García Garino},
  doi          = {10.1016/j.engappai.2021.104288},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104288},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reinforcement learning-based application autoscaling in the cloud: A survey},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Thick gradual sets and their computations: Application for
determining the uncertain zone explored by an underwater robot.
<em>EAAI</em>, <em>102</em>, 104287. (<a
href="https://doi.org/10.1016/j.engappai.2021.104287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new concept of thick gradual sets (TGSs), which is based on the notions of thick sets (TSs) and gradual sets (GSs). A TS is an uncertain set, which is represented by a pair of crisp sets (CSs). These CSs represent the upper and lower bounds of the TS. Therefore, a TS can be considered as an interval of CSs. A GS is a CS, which is parameterized by a degree of pertinence and aims to increase the specificity of CSs. Furthermore, a TGS is an interval of GSs, i.e., a pair of lower and upper GSs. In situations when the constraint of monotonicity (consistency) is guaranteed, a GS becomes a type-1 fuzzy set (T1FS) and a TGS can be regarded as a thick fuzzy set (TFS). Moreover, a TFS, which is composed of lower and upper T1FS bounds, can be interpreted as a type-2 fuzzy set (T2FS). According to the TGS representation, this new approach offers an original concept for interpreting, manipulating, and computing some uncertain quantities that cannot be represented by GSs, T1FSs, and/or T2FSs. The potential applications of the TGS concept has been validated using application examples in the frameworks of solving fuzzy systems of equations and uncertain fuzzy regression and through a real-world application where the trajectory of an underwater robot is uncertain and cannot be precisely known because of disturbances induced by the environment. The proposed approach makes it possible to compute the uncertain zone explored by the underwater robot.},
  archive      = {J_EAAI},
  author       = {Reda Boukezzoula and Luc Jaulin and Benoit Desrochers and Laurent Foulloy},
  doi          = {10.1016/j.engappai.2021.104287},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104287},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Thick gradual sets and their computations: Application for determining the uncertain zone explored by an underwater robot},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative multi-agent model for collision avoidance
applied to air traffic management. <em>EAAI</em>, <em>102</em>, 104286.
(<a href="https://doi.org/10.1016/j.engappai.2021.104286">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the future, Air Traffic Control (ATC) will have to cope with a radical change in air traffic. Apart from the probable increase in traffic that will push the system to its limits, the insertion of new aerial vehicles such as drones into the airspace – with different flight performances, and utterly different objective – will increase its complexity. Current research aims at increasing the level of automation and/or partial delegation of the control to on-board systems. In this work, we investigate the collision avoidance management problem using a decentralized distributed approach. We propose an autonomous and generic multi-agent system to address this complex problem, where mobile entities are agents, that use a finite set of discrete speed vector modifications to follow their trajectories while avoiding separation losses. We validate our system using a state-of-the-art benchmark. The results underline the adequacy of our local and cooperative approach to efficiently solve the studied problem, competing with centralized methods. Additionally, the conducted sensitivity analysis underlines the robustness of our approach regarding some used parameters.},
  archive      = {J_EAAI},
  author       = {Augustin Degas and Elsy Kaddoum and Marie-Pierre Gleizes and Françoise Adreit and Arcady Rantrua},
  doi          = {10.1016/j.engappai.2021.104286},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104286},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cooperative multi-agent model for collision avoidance applied to air traffic management},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploratory analysis and performance prediction of big data
transfer in high-performance networks. <em>EAAI</em>, <em>102</em>,
104285. (<a
href="https://doi.org/10.1016/j.engappai.2021.104285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Big data transfer in large-scale scientific and business applications is increasingly carried out over connections with guaranteed bandwidth provisioned in High-performance Networks (HPNs) via advance bandwidth reservation. Provisioning agents need to carefully schedule data transfer requests, compute network paths, and allocate appropriate bandwidths. Such reserved bandwidths, if not fully utilized, could be simply wasted due to the exclusive access during the approved time window, and cause extra overhead and complexity for resource management. This calls for accurate performance prediction to reserve bandwidths that match actual needs and avoid over-provisioning. We employ machine learning algorithms to predict big data transfer performance based on extensive performance measurements collected in the past several years from data transfer tests using different protocols and toolkits between various end sites on several real-life physical or emulated testbeds. We first analyze the performance patterns in response to a comprehensive list of parameters in end-host systems, network connections, and data transfer applications, which motivate the use of machine learning and also help us identify the effects of latent factors. We then propose threshold- and clustering-based methods to eliminate negative effects of latent factors in data preprocessing and build a robust performance predictor based on customized domain-oriented loss functions. The performance of the proposed methods is verified by extensive experiments using SVR and RFR as well as theoretical analysis of the general performance bound.},
  archive      = {J_EAAI},
  author       = {Daqing Yun and Wuji Liu and Chase Q. Wu and Nageswara S.V. Rao and Rajkumar Kettimuthu},
  doi          = {10.1016/j.engappai.2021.104285},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104285},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploratory analysis and performance prediction of big data transfer in high-performance networks},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Q-learning and hyper-heuristic based algorithm
recommendation for changing environments. <em>EAAI</em>, <em>102</em>,
104284. (<a
href="https://doi.org/10.1016/j.engappai.2021.104284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A considerable amount of research has been devoted to solving static optimization problems via bio-inspired metaheuristic algorithms. However, most of the algorithms assume that all problem-related data remain unchanged during the optimization process, which is not a realistic assumption. Recently, dynamic optimization problems (DOPs) grabbed remarkable attention from the research community. However, the literature still lacks clear guidelines on selecting the most appropriate bio-inspired algorithm under changing environments. Due to the availability of many design choices, the selection of a suitable bio-inspired metaheuristic algorithm becomes an immediate challenge. This study proposes an algorithm recommendation architecture using Q-learning and hyper-heuristic approaches to help decision-makers select the most suitable bio-inspired algorithm for a given problem. To this end, Artificial Bee Colony (ABC), Manta Ray Foraging Optimization (MRFO), Salp Swarm Algorithm (SSA), and Whale Optimization Algorithm (WOA) are employed as low-level optimizers so that the Q-learning and hyper-heuristic automatically select the optimizer in each cycle of the optimization process. The proposed algorithms are implemented in dynamic multidimensional knapsack problems, a natural extension of the well-known 0–1 knapsack problem. The performances of the recommender and standalone bio-inspired algorithms are evaluated through a comprehensive experimental analysis including appropriate statistical tests. Thus, the significant differences among the algorithms are revealed. The obtained results point out the efficiencies of the Q-learning-based algorithm recommender and MRFO in solving the dynamic multidimensional knapsack problem.},
  archive      = {J_EAAI},
  author       = {İlker Gölcük and Fehmi Burcin Ozsoydan},
  doi          = {10.1016/j.engappai.2021.104284},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104284},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Q-learning and hyper-heuristic based algorithm recommendation for changing environments},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel design of experiment algorithm using improved
evolutionary multi-objective optimization strategy. <em>EAAI</em>,
<em>102</em>, 104283. (<a
href="https://doi.org/10.1016/j.engappai.2021.104283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper aims to propose an intelligent design of experiment (DOE) algorithm using an improved evolutionary multi-objective optimization approach. Adaptive evolutionary strategies are embedded in the algorithm to support the design of simulation test schemes with multiple factors whose levels are same or different. Comparative results with several existing DOE algorithms show better sampling capacity and fine sampling efficiency of the proposed algorithm. Application effects of a complex flight simulator indicate the algorithm a wide technological prospect of serving well certain complex systems.},
  archive      = {J_EAAI},
  author       = {Yuhong Li and Ni Li and Guanghong Gong and Jin Yan},
  doi          = {10.1016/j.engappai.2021.104283},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104283},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel design of experiment algorithm using improved evolutionary multi-objective optimization strategy},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memetic teaching–learning-based optimization algorithms for
large graph coloring problems. <em>EAAI</em>, <em>102</em>, 104282. (<a
href="https://doi.org/10.1016/j.engappai.2021.104282">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Graph Coloring Problem (GCP) can be simply defined as partitioning the vertices of a graph into independent sets while minimizing the number of colors used. So far, many approaches have been implemented to solve the GCP. However, researchers are still trying to solve this important NP-Hard problem much faster and with better results for large graphs. The Teaching-Learning-Based Optimization (TLBO) metaheuristic is a recent approach that has attracted the attention of many researchers due to its algorithm-specific parameterless concept and high performance. In this study, we propose a new memetic TLBO algorithm (TLBO-Color) combined with a robust tabu search algorithm to solve the GCP. A scalable parallel version of TLBO-Color is also developed for painting 43 benchmark DIMACS graphs with thousands of vertices and millions of edges. The optimization times of the TLBO-Color algorithm are very practical and the best results (for 33 of the graphs) or solutions with a few more colors are reported. On average, there are only 1.77% more colors compared to the best solutions. The obtained results confirm that the proposed algorithm is competitive with the state-of-the-art algorithms in the literature.},
  archive      = {J_EAAI},
  author       = {Tansel Dokeroglu and Ender Sevinc},
  doi          = {10.1016/j.engappai.2021.104282},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104282},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Memetic Teaching–Learning-based optimization algorithms for large graph coloring problems},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cluster-based fine-to-coarse superpixel segmentation.
<em>EAAI</em>, <em>102</em>, 104281. (<a
href="https://doi.org/10.1016/j.engappai.2021.104281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an image preprocessing technology, superpixel segmentation has become an important tool in the field of computer vision. How to obtain a more accurate, faster, and easier-to-apply superpixel segmentation algorithm is a problem faced by researchers. In this paper, a cluster-based fine-to-coarse superpixel segmentation (FCSS) algorithm is proposed. By introducing color thresholds and depth thresholds with practical physical meanings as algorithm parameters, high-quality segmentation with fewer superpixels is achieved. It not only reduces the complexity of the upper application, but also provides an easy to understand interface. Superpixel segmentation methods often cannot achieve high-quality segmentation through a set of parameters. Experimental results show that FCSS can achieve finer segmentation by setting different parameters, and the segmentation results are superior to other algorithms. When the number of superpixels is 100, the segmentation performance of FCSS is better than that of existing state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Xiangjun Li and Yong Zhou and Xinping Zhang and Su Xu and Peng Yu},
  doi          = {10.1016/j.engappai.2021.104281},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104281},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cluster-based fine-to-coarse superpixel segmentation},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel deep autoencoder and hyperparametric adaptive
learning for imbalance intelligent fault diagnosis of rotating
machinery. <em>EAAI</em>, <em>102</em>, 104279. (<a
href="https://doi.org/10.1016/j.engappai.2021.104279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_EAAI},
  author       = {Wanxiang Li and Zhiwu Shang and Maosheng Gao and Shiqi Qian and Baoren Zhang and Jie Zhang},
  doi          = {10.1016/j.engappai.2021.104279},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104279},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel deep autoencoder and hyperparametric adaptive learning for imbalance intelligent fault diagnosis of rotating machinery},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust ultra-wideband range error mitigation with deep
learning at the edge. <em>EAAI</em>, <em>102</em>, 104278. (<a
href="https://doi.org/10.1016/j.engappai.2021.104278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ultra-wideband (UWB) is the state-of-the-art and most popular technology for wireless localization. Nevertheless, precise ranging and localization in non-line-of-sight (NLoS) conditions is still an open research topic. Indeed, multipath effects, reflections, refractions, and complexity of the indoor radio environment can easily introduce a positive bias in the ranging measurement, resulting in highly inaccurate and unsatisfactory position estimation. This article proposes an efficient representation learning methodology that exploits the latest advancement in deep learning and graph optimization techniques to achieve effective ranging error mitigation at the edge. Channel Impulse Response (CIR) signals are directly exploited to extract high semantic features to estimate corrections in either NLoS or LoS conditions. Extensive experimentation with different settings and configurations has proved the effectiveness of our methodology and demonstrated the feasibility of a robust and low computational power UWB range error mitigation.},
  archive      = {J_EAAI},
  author       = {Simone Angarano and Vittorio Mazzia and Francesco Salvetti and Giovanni Fantin and Marcello Chiaberge},
  doi          = {10.1016/j.engappai.2021.104278},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104278},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Robust ultra-wideband range error mitigation with deep learning at the edge},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel dual attention-based BLSTM with hybrid features in
speech emotion recognition. <em>EAAI</em>, <em>102</em>, 104277. (<a
href="https://doi.org/10.1016/j.engappai.2021.104277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Though the emotional state does not alter the content of language, it is a major determinant in human communication, because it provides much more positive feedback. The purpose of the speech emotion recognition is to automatically identify emotional or physiological state of a human being from their voice. In this paper, we propose a novel dual-level architecture, called dual attention-based bidirectional long short-term memory networks (dual attention-BLSTM) to recognize speech emotion. We also confirm that the recognition performance is better with different features as input than with only identical features in the dual-layer structure. Experiments on the IEMOCAP databases show the advantage of our proposed approach. The average recognition accuracy of our method is 70.29% in unweighted accuracy (UA) and the corresponding performance improvements are 2.89 compared to the best baseline methods. The results show that the architecture of our designed can better learn to distinguish features of the emotional information.},
  archive      = {J_EAAI},
  author       = {Qiupu Chen and Guimin Huang},
  doi          = {10.1016/j.engappai.2021.104277},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104277},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel dual attention-based BLSTM with hybrid features in speech emotion recognition},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-term prediction of time series using fuzzy cognitive
maps. <em>EAAI</em>, <em>102</em>, 104274. (<a
href="https://doi.org/10.1016/j.engappai.2021.104274">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a powerful recognized knowledge modeling tool, fuzzy cognitive maps (FCMs) have been investigated for time series modeling and forecasting problems. This methodology performs well in one-step-ahead or short-term prediction but poorly in terms of long-term prediction because of the potentially complex interaction between different ensuing steps. In this article, a sound conceptual method is proposed for long-term time series prediction with FCMs, which melds FCMs, time series segmentation and fuzzy clustering. A time series is divided into suitable and internally homogeneous segments. Dynamic time warping is introduced to evaluate the distance between segments. Subsequently, modified fuzzy c-means based on dynamic time warping is utilized to fuzzify these segments such that the segments are transformed into fuzzy time series and semantic vectors. The convex optimization based method is utilized with intent to rapidly and robustly learn FCMs. Consequently, the weight of FCMs can be obtained on the basis of the fuzzy time series. Eventually, the forecasting time segment will be capable of inference according to the formed FCMs and the semantic vectors. In addition, the semantic vectors can intuitively reflect the main characteristics and change tendencies of the time series. To demonstrate the long-term prediction ability of our method, we test it on both synthetic and real-life datasets in comparison with other representative and up-to-date forecasting methods; the superior performance of our method exhibits its excellent capability in forecasting future values.},
  archive      = {J_EAAI},
  author       = {Guoliang Feng and Liyong Zhang and Jianhua Yang and Wei Lu},
  doi          = {10.1016/j.engappai.2021.104274},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104274},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Long-term prediction of time series using fuzzy cognitive maps},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SpaceLDA: Topic distributions aggregation from a
heterogeneous corpus for space systems. <em>EAAI</em>, <em>102</em>,
104273. (<a
href="https://doi.org/10.1016/j.engappai.2021.104273">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of highly complex systems such as spacecraft entails large amounts of documentation. Tracking relevant information, including hundreds of requirements, throughout several design stages is a challenge. In this study, we propose a novel strategy based on Topic Modelling to facilitate the management of spacecraft design requirements. We introduce spaceLDA, a novel domain-specific semi-supervised Latent Dirichlet Allocation (LDA) model enriched with lexical priors and an optimised Weighted Sum (WS). We collect and curate the first large collection of unstructured data related to space systems, combining several sources: Wikipedia pages, books, and feasibility reports provided by the European Space Agency (ESA). We train the spaceLDA model on three subsets of our heterogeneous training corpus. To combine the resulting per-document topic distributions, we enrich our model with an aggregation method based on an optimised WS. We evaluate our model through a case study, a categorisation of spacecraft design requirements. We finally compare our model’s performance with an unsupervised LDA model and with a literature aggregation method. The results demonstrate that the spaceLDA model successfully identifies the topics of requirements and that our proposed approach surpasses the use of a classic LDA model and the state of the art aggregation method.},
  archive      = {J_EAAI},
  author       = {Audrey Berquand and Yashar Moshfeghi and Annalisa Riccardi},
  doi          = {10.1016/j.engappai.2021.104273},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104273},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SpaceLDA: Topic distributions aggregation from a heterogeneous corpus for space systems},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ishita approach to construct an interval-valued triangular
fuzzy regression model using a novel least-absolute based discrepancy.
<em>EAAI</em>, <em>102</em>, 104272. (<a
href="https://doi.org/10.1016/j.engappai.2021.104272">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Regression models in the presence of fuzziness imposed researchers to construct regression models in three cases based on the fuzziness of the model’s components — independent, dependent variables and the parameters. The purpose of this study is to construct full interval-valued triangular fuzzy regression model (IVTFRM) (when the regression components are represented as interval-valued triangular fuzzy numbers (IVTFNs). This paper proposes an approach (named as Ishita approach) using a mathematical linear optimization problem to find IVTFRM’s parameters of the minimum discrepancy between the given patterns and predicted values of the dependent variable. For the same and behind the fact that the more uncertainty of an IVTFN is reduced, the more accuracy is gotten; the paper proposed a novel least absolute discrepancy between two IVTFNs which take into the consideration the distance between the maximum points of the piecewise uncertainty function of the two IVTFNs. Moreover, compared to the existing approach, the proposed model is general to fit any type of datasets whereas the existing model can only fit positive interval-valued triangular fuzzy data. The proposed approach is demonstrated with a real-life application. The model of proposed Ishita approach for the real-life application shows its superiority over the model of the only one existing approach.},
  archive      = {J_EAAI},
  author       = {Abdullah Al-Qudaimi},
  doi          = {10.1016/j.engappai.2021.104272},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104272},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Ishita approach to construct an interval-valued triangular fuzzy regression model using a novel least-absolute based discrepancy},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Random wheel: An algorithm for early classification of
student performance with confidence. <em>EAAI</em>, <em>102</em>,
104270. (<a
href="https://doi.org/10.1016/j.engappai.2021.104270">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The educational data mining researchers have achieved significant efficiency in predicting student performance during the tenure of the course. However, an early prediction before course commencement is still a research challenge. Such advanced forecast can help the teachers in providing timely assistance to uplift the academic performance of a student, reduce the number of failures and performance degradations. Importantly, an additional measure of prediction confidence can be useful in this regard to decide the magnitude of the assistance required. The primary objective of this study is to predict the failure, degradation and improvement before course commencement. A real dataset containing nearly 0.6 million records is used here for this purpose. We have initially applied multiple state-of-the-art classifiers on this dataset to predict the performance in binary terms. Unfortunately, these classifiers could not perform well, and they are unable to provide the desired prediction confidence as well. We have therefore proposed a novel scalable algorithm, named random wheel, for classification. It not only works efficiently on this dataset but also works well with other benchmarked datasets. The proposed classifier provides an additional measure to indicate the prediction confidence. It, in turn, increases the acceptability of the prediction.},
  archive      = {J_EAAI},
  author       = {Anupam Khan and Soumya K. Ghosh and Durgadas Ghosh and Shubham Chattopadhyay},
  doi          = {10.1016/j.engappai.2021.104270},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104270},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Random wheel: An algorithm for early classification of student performance with confidence},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hierarchical knowledge guided backtracking search
algorithm with self-learning strategy. <em>EAAI</em>, <em>102</em>,
104268. (<a
href="https://doi.org/10.1016/j.engappai.2021.104268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the performance of the backtracking search optimization algorithm (BSA), a multi-population cooperative evolution strategy guided BSA with hierarchical knowledge (HKBSA) is proposed in this paper. According to the domain knowledge of the candidates in objective space, the population is divided into the dominant population, the ordinary population and the inferior population. The information between the sub-populations has interacted with the evolution processes of the three sub-populations. The individuals in the dominant population are maintained as the optimal solutions and are utilized to guide the evolution of the other two sub-populations. A multi-strategy mutation mechanism is applied to solve non-separable problems. The distribution vector of inferior individuals is constructed by sampling, and a mechanism of the individual generation with feedback is proposed by combining self-learning strategy and elite learning strategy. The convergence of HKBSA is analyzed with the Markov model. Compared with the state-of-the-art BSA variants, HKBSA outperforms other algorithms in terms of the speed of convergence, solution accuracy and stability.},
  archive      = {J_EAAI},
  author       = {Fuqing Zhao and Jinlong Zhao and Ling Wang and Jie Cao and Jianxin Tang},
  doi          = {10.1016/j.engappai.2021.104268},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104268},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hierarchical knowledge guided backtracking search algorithm with self-learning strategy},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building and benchmarking an arabic speech commands dataset
for small-footprint keyword spotting. <em>EAAI</em>, <em>102</em>,
104267. (<a
href="https://doi.org/10.1016/j.engappai.2021.104267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The introduction of the Google Speech Commands dataset accelerated research and resulted in a variety of new deep learning approaches that address keyword spotting tasks. The main contribution of this work is the building of an Arabic Speech Commands dataset, a counterpart to Google’s dataset. Our dataset consists of 12000 instances, collected from 30 contributors, and grouped into 40 keywords. We also report different experiments to benchmark this dataset using classical machine learning and deep learning approaches, the best of which is a Convolutional Neural Network with Mel-Frequency Cepstral Coefficients that achieved an accuracy of ∼ 98%. Additionally, we point out some key ideas to be considered in such tasks.},
  archive      = {J_EAAI},
  author       = {Abdulkader Ghandoura and Farouk Hjabo and Oumayma Al Dakkak},
  doi          = {10.1016/j.engappai.2021.104267},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104267},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Building and benchmarking an arabic speech commands dataset for small-footprint keyword spotting},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online parallel framework for real-time visual tracking.
<em>EAAI</em>, <em>102</em>, 104266. (<a
href="https://doi.org/10.1016/j.engappai.2021.104266">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discriminative correlation filter (DCF) based tracking algorithms have recently achieved excellent performance in challenging factors such as rotations and distractors. However, in case with fast motions and full occlusion, these trackers are not always effective and easily drift. In contrast, Siamese matching networks are insensitive to fast motions, but suffer from distractors. In this work, we propose an efficient real-time parallel framework for robust visual tracking. By incorporating DCF and Siamese network into the tracking framework to complement each other and better distinguish target objects from background clutters. Additionally, to improve tracking results and prevent target drift, we introduce an effective tracker switch method to select suitable tracker in each frame by considering the confidence estimation as well as motion smoothness, and examines the impact among all trackers over time. To validate the effectiveness of our method, we perform comprehensive experiments on three popular benchmark datasets, namely OTB2013, OTB2015, VOT2016, and TC128. The experimental results demonstrate that the proposed algorithm exhibits favorably results and real-time tracking speed against state-of-art trackers.},
  archive      = {J_EAAI},
  author       = {Xiaojing Li and Lei Huang and Guanqun Wei and Zhiqiang Wei},
  doi          = {10.1016/j.engappai.2021.104266},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104266},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online parallel framework for real-time visual tracking},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collective multi agent deployment for wireless sensor
network maintenance. <em>EAAI</em>, <em>102</em>, 104265. (<a
href="https://doi.org/10.1016/j.engappai.2021.104265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the problem of wireless sensor network (WSN) maintenance using a team of physical autonomous mobile agents. The agents are deployed in the area of the WSN in such a way that would minimize the time it takes them to reach a failed sensor and repair it. The team must constantly optimize its collective deployment to account for occupied agents. The objective is to define the optimal deployment and task allocation strategy, that minimize the solution cost. The solution cost is a linear combination of the weighted sensors’ downtime, the agents’ traveling distance, and penalties incurred due to unrepaired sensors within a certain time limit. Our proposed solution algorithms are inspired by research in the field of computational geometry and the design of our algorithms is based on state of the art approximation algorithms for the classical problem of facility location. We empirically compare and analyze the performance of several proposed algorithms. The sensitivity of the algorithms’ performance to the following parameters is analyzed: agents to sensors ratio, sensors’ sparsity, frequency and distribution of failures, repair duration, repair capacity, and communication limitations. Our results demonstrate that: (i) cooperation enhances the team’s performance by orders of magnitude, (ii) k -Median based deployment algorithm provides up to 30% improvement in downtime, (iii) k -Center based deployment incurs 10% fewest penalties, and (iv) k -Centroid based deployment is most efficient in terms of minimizing the overall costs, with up to 21% lower cost than the next best algorithm.},
  archive      = {J_EAAI},
  author       = {Harel Yedidsion and Danny Hermelin and Michael Segal},
  doi          = {10.1016/j.engappai.2021.104265},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104265},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Collective multi agent deployment for wireless sensor network maintenance},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Constraint based local search for flowshops with
sequence-dependent setup times. <em>EAAI</em>, <em>102</em>, 104264. (<a
href="https://doi.org/10.1016/j.engappai.2021.104264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Permutation flowshop scheduling problem with sequence-dependent setup times (PFSP-SDST) and makespan minimisation is NP-hard. It has important practical applications, for example, in the cider industry and the print industry. There exist several metaheuristic algorithms to solve this problem. However, within practical time limits, those algorithms still either find low quality solutions or struggle with large problems. In this paper, we have proposed a simple but effective local search algorithm, called constraint based local search (CBLS) algorithm, which transforms the SDST constraints into an auxiliary objective function and uses the auxiliary objective function to guide the search towards the optimal value of the actual objective function. Our motivation comes from the constraint optimisation models in artificial intelligence (AI), where constraint-based informed decisions are of particular interest instead of random-based decisions. Our experimental results on well-known 480 instances of PFSP-SDST show that the proposed CBLS algorithm outperforms existing state-of-the-art PFSP-SDST algorithms. Moreover, our algorithm obtains new upper bounds for 204 out of 360 medium- and large-sized problem instances.},
  archive      = {J_EAAI},
  author       = {Vahid Riahi and M.A. Hakim Newton and Abdul Sattar},
  doi          = {10.1016/j.engappai.2021.104264},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104264},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Constraint based local search for flowshops with sequence-dependent setup times},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel hybrid gravitational search particle swarm
optimization algorithm. <em>EAAI</em>, <em>102</em>, 104263. (<a
href="https://doi.org/10.1016/j.engappai.2021.104263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle Swarm Optimization (PSO) algorithm is a member of the swarm computational family and widely used for solving nonlinear optimization problems. But, it tends to suffer from premature stagnation, trapped in the local minimum and loses exploration capability as the iteration progresses. On the contrary, Gravitational Search Algorithm (GSA) is proficient for searching global optimum, however, its drawback is its slow searching speed in the final phase. To overcome these problems in this paper a novel Hybrid Gravitational Search Particle Swarm Optimization Algorithm (HGSPSO) is presented. The key concept behind the proposed method is to merge the local search ability of GSA with the capability for social thinking (gbest) of PSO. To examine the effectiveness of these methods in solving the abovementioned issues of slow convergence rate and trapping in local minima five standard and some modern CEC benchmark functions are used to ensure the efficacy of the presented method. Additionally, a DNA sequence problem is also solved to confirm the proficiency of the proposed method. Different parameters such as Hairpin, Continuity, H-measure, and Similarity are employed as objective functions. A hierarchal approach was used to solve this multi-objective problem where a single objective function is first obtained through a weighted sum method and the results were then empirically validated. The proposed algorithm has demonstrated an extraordinary performance per solution stability and convergence.},
  archive      = {J_EAAI},
  author       = {Talha Ali Khan and Sai Ho Ling},
  doi          = {10.1016/j.engappai.2021.104263},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104263},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel hybrid gravitational search particle swarm optimization algorithm},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Transformer based network for open information extraction.
<em>EAAI</em>, <em>102</em>, 104262. (<a
href="https://doi.org/10.1016/j.engappai.2021.104262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on Open Information Extraction (Open IE) has made great progress in recent years; it is the task that detects a group of structured, machine-readable statements usually represented in triple form or n-ary relation statements. Open IE is among the core areas of the territory of Natural Language Processing (NLP), and these extractions decompose grammatically complex sentences in a corpus into the relationships they represent, which can be leveraged for various downstream tasks. Even though a lot of work has been done in this direction, there are still many issues with the existing strategies. Most of the previous Open IE systems employ a group of artificially constructed patterns to detect and extract relational tuples from a sentence in a corpus, and these patterns are either automatically learned from annotated training examples or hand-crafted. Such an approach faces some issues, the first is that it requires a lot of manpower. Secondly, they used many NLP tools, therefore, error accumulation in the procedure can negatively impact the results. In this paper, we propose an Open IE approach based on the Transformer architecture. To verify our approach, we make a study using a large and public benchmark dataset, and the experimental results showed that our model achieves a better performance than many existing baselines.},
  archive      = {J_EAAI},
  author       = {Jiabao Han and Hongzhi Wang},
  doi          = {10.1016/j.engappai.2021.104262},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104262},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformer based network for open information extraction},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Predicting chinese total retail sales of consumer goods by
employing an extended discrete grey polynomial model. <em>EAAI</em>,
<em>102</em>, 104261. (<a
href="https://doi.org/10.1016/j.engappai.2021.104261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The total retail sales of consumer goods is not only an important indicator to measure the consumption level of the Chinese people, but also an important indicator of the national economy. Therefore, it is of great significance to analyze the development trend of Chinese total retail sales of consumer goods for the healthy development of Chinese economy. To explore the future development trend of Chinese total retail sales of consumer goods, this paper develops an extensive discrete grey model by the introduction of weighted fractional accumulation and discretization error, which is abbreviated as WFDPGM(1,1,t α ) model. To further enhance the prediction performance of the proposed model, the whale optimization algorithm (WOA) is employed to determine the emerging coefficients. Three real cases are used to verify the effectiveness of the proposed model by comparing with other competing models. Lastly, based on Chinese retail sales of consumer goods from 2005 to 2019, the numerical results show that the proposed model outperforms other benchmarks, and the future development of Chinese retail sales of consumer goods will maintain an increasing trend, reaching 533033 . 15 × 1 0 9 yuan in 2025. And some managerial insights are obtained from numerical examples.},
  archive      = {J_EAAI},
  author       = {Chong Liu and Wanli Xie and Wen-Ze Wu and Hegui Zhu},
  doi          = {10.1016/j.engappai.2021.104261},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104261},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Predicting chinese total retail sales of consumer goods by employing an extended discrete grey polynomial model},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comprehensive survey on 2D multi-person pose estimation
methods. <em>EAAI</em>, <em>102</em>, 104260. (<a
href="https://doi.org/10.1016/j.engappai.2021.104260">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human pose estimation is a fundamental yet challenging computer vision task and studied by many researchers around the world in recent years. As a basic task in computer vision, multi-person pose estimation is the core component for many practical applications. This paper extensively reviews recent works on multi-person pose estimation. Specifically, we illustrate and analyze popular methods in detail and compare their pros and cons to fill in the gaps existing in other surveys. In addition, the commonly used datasets, evaluation metrics, and open-source systems are also introduced respectively. Finally, we summarize the development of multi-person pose estimation frameworks and discuss the research trends.},
  archive      = {J_EAAI},
  author       = {Chen Wang and Feng Zhang and Shuzhi Sam Ge},
  doi          = {10.1016/j.engappai.2021.104260},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104260},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A comprehensive survey on 2D multi-person pose estimation methods},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction model of burn-through point with fuzzy time
series for iron ore sintering process. <em>EAAI</em>, <em>102</em>,
104259. (<a
href="https://doi.org/10.1016/j.engappai.2021.104259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Burn-through point (BTP) is an essential parameter in the iron ore sintering process. Operators usually judge whether the current production is stable by monitoring the BTP. It comes with significant application prospects to predict the BTP accurately. A prediction model of the BTP with fuzzy time series is designed in this paper. First, the fuzzy time series prediction method with the Fuzzy C-Means clustering is presented as the core modeling method. A prediction model of the response is constructed to obtain a timely response to the current BTP. The prediction model of the difference is established to estimate the present unmeasurable disturbance on the BTP. Then, a hybrid prediction model is built, which realizes the composition of these two models by an adjustment factor. Finally, a series of experiments is carried out using the raw time series data from an iron and steel plant. The experimental result shows that the designed model has better prediction performance for the BTP than existing models, which is an advantage resulting from the hybrid structure and the fuzzy time series prediction model with the Fuzzy C-Means clustering. This prediction model of the BTP implies the foundation for the stable control of the iron ore sintering process.},
  archive      = {J_EAAI},
  author       = {Sheng Du and Min Wu and Luefeng Chen and Witold Pedrycz},
  doi          = {10.1016/j.engappai.2021.104259},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104259},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Prediction model of burn-through point with fuzzy time series for iron ore sintering process},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel neural network based on dynamic time warping and
kalman filter for real-time monitoring of supersonic inlet flow
patterns. <em>EAAI</em>, <em>102</em>, 104258. (<a
href="https://doi.org/10.1016/j.engappai.2021.104258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A supersonic inlet is one of the key components in a supersonic air-breathing propulsion system and is the basis for protection control. The overall system performance can be greatly influenced by its flow patterns, so it plays a crucial part and is necessary to develop methods for monitoring its flow patterns to ensure stable and safe operation. This issue can be viewed as a time series classification (TSC) task. Traditionally, several manually-engineered features are extracted as the indicators to evaluate the operation status, but this process can be heavily dependent on the professional experience. In this paper, a novel neural network called DTW-SLFN-KF is proposed, which integrates Dynamic Time Warping (DTW) and Kalman Filter (KF) into a single-hidden-layer neural network (SLFN) architecture to directly determine flow patterns from the dynamic sensor signals. The proposed network first adopts a DTW layer as the feature extractor to automatically extract robust features, and exploits the flexible alignment ability of DTW to keep the temporal continuity and deal with the temporal distortions. Then, these features are fed into an SLFN for classification. After that, to make full use of the extracted features and improve the classification performance of SLFN when the network structure is fixed, KF is applied as a linear post-processing technique to get the predicted output of SLFN closer to the true output. Experimental results demonstrate that the proposed DTW-SLFN-KF network has better comprehensive performance for monitoring the flow patterns of supersonic inlet in terms of monitoring accuracy and real-time performance when compared with other competitive methods.},
  archive      = {J_EAAI},
  author       = {Huan Wu and Yong-Ping Zhao and Hui-Jun Tan},
  doi          = {10.1016/j.engappai.2021.104258},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104258},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel neural network based on dynamic time warping and kalman filter for real-time monitoring of supersonic inlet flow patterns},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Color texture image retrieval based on copula multivariate
modeling in the shearlet domain. <em>EAAI</em>, <em>102</em>, 104256.
(<a href="https://doi.org/10.1016/j.engappai.2021.104256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing number of images on the Internet, image retrieval framework is needed for image-based search. Shearlet transform is a sparse, multiscale, and multidimensional representation used to extract anisotropic features in image processing applications such as image fusion and image denoising. In this paper, we proposed a color texture image retrieval framework based on Shearlet domain modeling using Copula multivariate model. In the proposed framework, Gaussian Copula is used to model the dependencies between different sub-bands of the Non-Subsample Shearlet Transform (NSST) and non-Gaussian models are used for marginal modeling of the coefficients. Six different schemes are proposed for modeling NSST coefficients based on the four types of neighboring defined; moreover, Kullback–Leibler Divergence(KLD) close form is calculated in different situations for the two Gaussian Copula and non-Gaussian functions in order to investigate the similarities in the proposed retrieval framework. The Jeffery divergence (JD) criterion, which is a symmetrical version of KLD, is used for investigating similarities in the proposed framework. We have implemented our experiments on four texture image retrieval benchmark datasets, the results of which show the superiority of the proposed framework over the existing state-of-the-art methods. In addition, the retrieval time of the proposed framework is also analyzed in the two steps of feature extraction and similarity matching, which also shows that the proposed framework enjoys an appropriate retrieval time.},
  archive      = {J_EAAI},
  author       = {Sadegh Etemad and Maryam Amirmazlaghani},
  doi          = {10.1016/j.engappai.2021.104256},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104256},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Color texture image retrieval based on copula multivariate modeling in the shearlet domain},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). MLANet: Multi-layer anchor-free network for generic lesion
detection. <em>EAAI</em>, <em>102</em>, 104255. (<a
href="https://doi.org/10.1016/j.engappai.2021.104255">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In medical image processing, detecting lesions from computed tomography (CT) scans becomes an important research problem with increasing attention. However, this problem is nontrivial because lesions from different organs and parts reflect different characteristics as well as different sizes. Most conventional methods only use a single-scale architecture to detect lesion areas. To get rid of the drawbacks above in medical imaging, a multi-scale framework called MLANet is proposed. To deal with the scale imbalance problem, we design a new backbone—a mixed hourglass network, in which each hourglass module share different input sizes and orders to extract features from different scales. And then the information is sent to the proposed Strengthen Weighted Feature Pyramid Network (SWFPN), a multi-layer weighted feature fusion module, to combine more semantic and spatial information, especially for the case where the number of layers is small. Finally, a Center-to-Corner (C2C) transformation is proposed to deal with the inaccurate size prediction of lesions. It is a non-linear transformation function, aiming to make the predictions more stable and accurate. MLANet is an end-to-end network and is easy to train. In our experiment, it achieves 65.2% AP50, as well as 88.3% in the sensitivity of FPs@4.0 on the DeepLesion dataset, which exceeds many state-of-the-art detectors.},
  archive      = {J_EAAI},
  author       = {Zhe Liu and Xi Xie and Yuqing Song and Yang Zhang and Xuesheng Liu and Jiawen Zhang and Victor S. Sheng},
  doi          = {10.1016/j.engappai.2021.104255},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104255},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {MLANet: Multi-layer anchor-free network for generic lesion detection},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-kernel support vector data description with boundary
information. <em>EAAI</em>, <em>102</em>, 104254. (<a
href="https://doi.org/10.1016/j.engappai.2021.104254">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The One-Class Classification (OCC) exists in many real-world applications, such as novelty detection, outlier detection, facial verification, and anomaly detection. SVDD is an efficient method to solve the OCC problem. How to describe a hypersphere with minimized volume that encloses almost all the target class samples is the key point of the SVDD. However, the existing SVDD-based methods generally neglect the boundary information of samples in the construction of the classifier. To fully utilize the boundary information to guide the training process, this paper introduces Multi-Kernel Learning (MKL) into the traditional Support Vector Data Description (SVDD) based on the boundary information, proposes a novel method called MKL-SVDD. The proposed MKL-SVDD first determines the boundary samples based on the geometrical and statistical information, and assigns the special weight for the boundary samples to improve the effect of the boundary samples in the optimization process. Meanwhile, to enhance the feature expression capabilities, the proposed MKL-SVDD utilizes the location information of samples as the supervised signal to design the kernel weights for multiple kernels to obtain the optimal kernel combination. Extensive experiments on 11 UCI datasets and 7 KEEL datasets demonstrate the superiority of the MKL-SVDD over the other state-of-the-art methods. The Bayesian analysis of the experiment results theoretically prove that the MKL-SVDD is superior to other methods on UCI and KEEL datasets with 100% and over 96% probability respectively.},
  archive      = {J_EAAI},
  author       = {Wei Guo and Zhe Wang and Sisi Hong and Dongdong Li and Hai Yang and Wen Du},
  doi          = {10.1016/j.engappai.2021.104254},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104254},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-kernel support vector data description with boundary information},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Including steady-state information in nonlinear models: An
application to the development of soft-sensors. <em>EAAI</em>,
<em>102</em>, 104253. (<a
href="https://doi.org/10.1016/j.engappai.2021.104253">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the dynamical data of a system only convey dynamic information over a limited operating range, the identification of models with good performance over a wider operating range is very unlikely. To overcome such a shortcoming, this paper describes a methodology to train models from dynamical data and steady-state information, which is assumed available. The novelty is that the procedure can be applied to models with rather complex structures such as multilayer perceptron neural networks in a bi-objective fashion without the need to compute fixed points neither analytically nor numerically. As a consequence, the required computing time is greatly reduced. The capabilities of the proposed method are explored in numerical examples and the development of soft-sensors for downhole pressure estimation for a real deep-water offshore oil well. The results indicate that the procedure yields suitable soft-sensors with good dynamical and static performance and, in the case of models that are nonlinear in the parameters, the gain in computation time is about three orders of magnitude considering existing approaches.},
  archive      = {J_EAAI},
  author       = {Leandro Freitas and Bruno H.G. Barbosa and Luis A. Aguirre},
  doi          = {10.1016/j.engappai.2021.104253},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104253},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Including steady-state information in nonlinear models: An application to the development of soft-sensors},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The explosion operation of fireworks algorithm boosts the
coral reef optimization for multimodal medical image registration.
<em>EAAI</em>, <em>102</em>, 104252. (<a
href="https://doi.org/10.1016/j.engappai.2021.104252">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image registration is becoming increasingly important in diagnosis and treatment planning, as it enables to align and integrate different images having a shared content, which obtained under different conditions, into a single representation. The most challenging issues of registration is finding a optimal transformation which settled by optimization methods. With this work, we present a Fireworks Algorithm (FWA) boosts the Coral Reefs Optimization Algorithm (CRO) for medical image registration (FWBCR). Firstly, the Coral Reefs Optimization is easily trapping in local optimum, we enhance the exploration ability of the CRO by integrated with a explosion operator of the FWA. At the Broadcast Spawning stage of CRO, a large fraction of corals are applying the crossover operator which has a good exploitation ability and a small fraction of corals with good solutions are applying the explosion operator which has a good exploration ability. Therefore, the algorithm we proposed is well solved the trades off between exploitation and exploration. Secondly, the explosion amplitude affects the search ability. A larger explosion amplitude benefit for the exploration in the early stages of the algorithm. Contrary, a smaller explosion amplitude benefit for the exploitation in the late stages of the algorithm. To deal with these problems, we design an adaptive explosion amplitude which depends on the fitness of the best solution and the worst solution. Thirdly, the phenomenon of the explosion operator is to generate lots of sparks. It is hard to select a small number of sparks with less computation effort while to guarantee the diversity of the swarm for next generation from a large number of sparks. To overcome this difficulty, we exploring the use of the clustering algorithm on the sparks then get some cluster centers as the new solutions. In this way, the diversity of the swarm can be ensured and the computation effort can be greatly reduced through reducing the number of evaluations. Finally, inspired by the Differential Evolution Algorithm, we construct a differential migration vector(DMV) with the most promising right direction and adaptive length, and to generate elite solutions by adding the DMV to the position of the spark centers. The FWBCR has been tested in numerous experiments on benchmark datasets include six kind of different modality images, from up to eighteen different patients, which can make up 54 multimodal registration scenarios. For registration precision, FWBCR obtained best in 19 scenarios, BBO-EL obtained best in 22 scenarios, while CRO-SL obtained best in 13 scenarios, which demonstrated that FWBCR outperformed the CRO variants like CRO-SL in most cases and as good as the state-of-the-art in the registration field. In addition, compared with BBO-EL, FWBCR achieve fast convergence rate and increase computing performance by 30%.},
  archive      = {J_EAAI},
  author       = {Yilin Chen and Fazhi He and Xiantao Zeng and Haoran Li and Yaqian Liang},
  doi          = {10.1016/j.engappai.2021.104252},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104252},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The explosion operation of fireworks algorithm boosts the coral reef optimization for multimodal medical image registration},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep regression adaptation networks with model-based
transfer learning for dynamic load identification in the frequency
domain. <em>EAAI</em>, <em>102</em>, 104244. (<a
href="https://doi.org/10.1016/j.engappai.2021.104244">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Frequency-domain dynamic load identification methods based on neural network (NN) models construct models independently at each frequency, but are inaccurate and inefficient to train. To address these problems, a deep regression adaptation network (DRAN) with model-transfer learning is proposed for identifying dynamic loads in the frequency domain. The aim is to take advantage of the similarity of uncorrelated multi-source dynamic loads and multi-vibration response at adjacent frequencies. First, a DRAN model for load identification is established using the historical data for a specific frequency. Second, the trained DRAN parameters are transferred to the DRAN for the target frequency as the initial parameter values. Next, the transferred DRAN is fine-tuned with the historical data of the target frequency to obtain the load identification model of the target frequency. Finally, the trained DRAN parameters of the current target frequency are transferred to the next target frequency. This process is iterated until a DRAN model for all frequencies is established. Because a frequency response function is a continuous function varying with frequency, the relationships between the dynamic loads and response at adjacent frequencies are similar. DRAN can adapt the historical data of different frequencies to one neural network for training, and then extract the common feature information of different frequencies to improve the accuracy of the model. Moreover, instead of setting the initial weights randomly and training them independently for each DRAN model, model-transfer learning is used to obtain better initial weights from the trained weights of DRAN models of adjacent frequencies. The proposed method was evaluated on the experimental data of a cylindrical shell structure under acoustic vibration joint excitation. The results show that the proposed method can obtain better initial weights, higher accuracy, better noise robustness, and shorter training time than a neural network.},
  archive      = {J_EAAI},
  author       = {Cheng Wang and Delei Chen and Jianwei Chen and Xiongming Lai and Ting He},
  doi          = {10.1016/j.engappai.2021.104244},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104244},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep regression adaptation networks with model-based transfer learning for dynamic load identification in the frequency domain},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretable machine learning approaches to prediction of
chronic homelessness. <em>EAAI</em>, <em>102</em>, 104243. (<a
href="https://doi.org/10.1016/j.engappai.2021.104243">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a machine learning approach to predict chronic homelessness from de-identified client shelter records drawn from a commonly used Canadian homelessness management information system. Using a 30-day time step, a time series dataset for 6521 individuals was generated, consisting of static features for client attributes and dynamic features describing shelter service usage over time. Five candidate models were trained to predict whether a client will be in a state of chronic homelessness 6 months in the future. The training method was fine-tuned to achieve a high F1-score, with a desired balance between recall and precision, in favour of recall. Mean, recall and precision across 10-fold cross validation were above 0.9 and 0.6 respectively for three out of the five candidate models. An interpretability method was applied to explain individual predictions and gain insight into the overall factors contributing to chronic homelessness among the population studied. This study demonstrates that it is possible to achieve state-of-the-art performance and improved stakeholder trust of what are usually “black box” machine learning models using an interpretability algorithm.},
  archive      = {J_EAAI},
  author       = {Blake VanBerlo and Matthew A.S. Ross and Jonathan Rivard and Ryan Booker},
  doi          = {10.1016/j.engappai.2021.104243},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104243},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable machine learning approaches to prediction of chronic homelessness},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Computer vision detection of foreign objects in coal
processing using attention CNN. <em>EAAI</em>, <em>102</em>, 104242. (<a
href="https://doi.org/10.1016/j.engappai.2021.104242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foreign objects in coal seriously affect the efficiency and safety of clean coal production. Currently, the removal of foreign objects in coal preparation plant mainly depends on manual picking, which has disadvantages of high labor intensity and low efficiency. Therefore, there is an urgent need for rapid detection and removal of foreign objects. However, due to the inference of the background and surround objects, it is a challenge for the accurate detection of foreign objects. In this study, a convolutional neural network (CNN) with attention modules was designed to accurately segment foreign objects from a complex background in real-time. The proposed network consists of an encoder and a decoder, and the attention mechanism was introduced into the decoder to capture rich semantic information. The visualization results proved that the attention modules could focus on the features of the salient region and inhibit the irrelevant background, which significantly improved the accuracy of the detection The results showed that the proposed model correctly recognized 97% of the foreign objects in the 1871 sets of test images. The mean intersection over union (MIOU) of the optimal model was 91.24%, and the inference speed was greater than 15 fps/s, which satisfied the real-time requirement.},
  archive      = {J_EAAI},
  author       = {Kanghui Zhang and Weidong Wang and Ziqi Lv and Yuhan Fan and Yang Song},
  doi          = {10.1016/j.engappai.2021.104242},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104242},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Computer vision detection of foreign objects in coal processing using attention CNN},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Competitive optimality: A novel application in evaluating
practical AI systems. <em>EAAI</em>, <em>102</em>, 104241. (<a
href="https://doi.org/10.1016/j.engappai.2021.104241">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Captcha test aims to discriminate human from machine in real-time based on the knowledge of test instances and the response patterns. In this paper, Captcha is used to propose an analytic framework entailing the general evaluation of practical AI systems under time and sample-size constraints. This is referred as the Competitive Optimality (CO) framework and it denotes probabilistic approach for estimating AI systems or tasks A, B using the fault or system errors in response given as A e , B e , respectively. This is used to analytically formulate the measures given as: system B dominates system A in attaining small on average error: P r A e &gt; B e ≥ P r A e &lt; B e ; Success: P r h u m a n e r r o r &lt; λ − P r h u m a n e r r o r &gt; λ ; human-executability of AI test V : V α , β if ∝ portion of the population attains β competitive errors on the test and, Hardness of AI problem P A o v e r B = Pr ( A e &gt; B e ) − Pr ( B e &gt; A e ) . The CO framework is used to formalize Turing gap and Region of Competitive Inequity for human and machine as observable at the respective interfaces. It is also shown to give minimum on average performance which justifies its usefulness for practical AI systems involving various constraints. Moreover, CO is shown as general framework for supervised evaluation and to characterize the competitive intelligence in performing AI tasks.},
  archive      = {J_EAAI},
  author       = {J.R. Bhatnagar},
  doi          = {10.1016/j.engappai.2021.104241},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104241},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Competitive optimality: A novel application in evaluating practical AI systems},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust and adaptive fuzzy logic based differential
evolution algorithm using population diversity tuning for
multi-objective optimization. <em>EAAI</em>, <em>102</em>, 104240. (<a
href="https://doi.org/10.1016/j.engappai.2021.104240">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents an improved Multi-objective Differential Evolution based algorithm to solve multi-objective optimization problems. In the proposed algorithm named as Fuzzy Adaptive Multi-objective Differential Evolution with Diversity Control (FAMDE-DC), fuzzy system is used to control population diversity at decision variable space by self-adapting the crossover rate control parameter at various stages of evolution. Techniques such as non-dominated sorting, controlled elitism and dynamic crowding distance is used for selecting potential individuals. This control parameter adaptation and improved selection procedure results in controlling population diversity in decision space and identifying potential candidates in objective space, attaining true Pareto-optimal front with better convergence and diversity metrics. These properties make it robust and to be applied to varied problem domains without manual fine-tuning of parameters. The performance of FAMDE-DC algorithm is analysed using a set of benchmark test functions DTLZ and CEC2009 problems. Further the results are compared with other popular evolutionary based multi-objective algorithms. FAMDE-DC had a better Inverted Generational Distance (IGD) measure towards true Pareto-optimal front. The outcome of FAMDE-DC is also validated through nonparametric statistical tests Friedman and Wilcoxon signed rank test.},
  archive      = {J_EAAI},
  author       = {Brindha S. and Miruna Joe Amali S.},
  doi          = {10.1016/j.engappai.2021.104240},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104240},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A robust and adaptive fuzzy logic based differential evolution algorithm using population diversity tuning for multi-objective optimization},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PTANet: Triple attention network for point cloud semantic
segmentation. <em>EAAI</em>, <em>102</em>, 104239. (<a
href="https://doi.org/10.1016/j.engappai.2021.104239">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For 3D point cloud semantic segmentation, mining more informative features to enrich contextual representation is regarded as the key to achieve better segmentation performance. Unfortunately, the existing point cloud segmentation network lacks a comprehensive consideration of utilizing contextual information from both global and local perspectives, thus failing to fully explore the contextual representation, which prevents fine-grained objects from being accurately recognized. Therefore, this paper proposes a neural network dubbed PTANet that effectively enriches the contextual representation to improve segmentation accuracy. PTANet possesses two uncomplicated and effective parts: Triple Attention Block and Density Scale Learning Strategy. Triple Attention Block consists of three sub modules: 1. Position attention module updates feature maps by modeling the interdependency between the spatial positions of each point. 2. Channel attention module recalibrates the original feature in the light of the correlation weight between the channels of feature maps to enrich the contextual representation globally. 3. Local Region attention module calculates the interdependence weight between local neighbors to further complement the local feature information. In addition, to alleviate the adverse effect of non-uniform distribution of point cloud on the inference results, Density Scale Learning Strategy applies the kernel density estimation under the adaptive bandwidth to fit the density scale of each point. In particular, the density scale weighted to the feature maps can also supplement the density information for local features. The experimental performance verifies the effectiveness of PTANet. It obtained 86.1% mIoU on ShapeNet, 62.4% mIoU on ScannetV2, and 87.9% OA on S3DIS.},
  archive      = {J_EAAI},
  author       = {Haozhe Cheng and Jian Lu and Maoxin Luo and Wei Liu and Kaibing Zhang},
  doi          = {10.1016/j.engappai.2021.104239},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104239},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PTANet: Triple attention network for point cloud semantic segmentation},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strategies of attack–defense game for wireless sensor
networks considering the effect of confidence level in fuzzy
environment. <em>EAAI</em>, <em>102</em>, 104238. (<a
href="https://doi.org/10.1016/j.engappai.2021.104238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a common case that Wireless Sensor Networks are attacked by malware in the real world. According to the game theory, the action of attack–defense between Wireless Sensor Network(WSN) and malware can be regarded as a game. While substantial efforts have been made to address this issue, most of these efforts have predominantly focused on the analysis of attack–defense game in the known environment. Given that the process of gaming in real world often contains a lot of fuzzy information, we extend the focus in this line by considering the fuzzy exterior environment. Specifically, we assume the WSN attack–defense Stackelberg game is in the fuzzy environment by using fuzzy variable. Then Stackelberg game theory is utilized to calculate the equilibrium solutions of the introduced m a x i m a x chance-constrained model and m i n i m a x chance-constrained model. Based on the simulation data, this study demonstrates the confidence levels and decision perspectives affect the optimal strategy of WSN and the reliability of WSN. Finally, the novel analytical method is compared with the non-fuzzy WSN attack–defense game method. The analysis shows that the novel approach is optimal in terms of predicting the behavior of malware in resisting the attack of malware.},
  archive      = {J_EAAI},
  author       = {Yingfu Wu and Bingyi Kang and Hao Wu},
  doi          = {10.1016/j.engappai.2021.104238},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104238},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Strategies of attack–defense game for wireless sensor networks considering the effect of confidence level in fuzzy environment},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature-based evidential reasoning for probabilistic risk
analysis and prediction. <em>EAAI</em>, <em>102</em>, 104237. (<a
href="https://doi.org/10.1016/j.engappai.2021.104237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Risk analysis plays an important role in quality control in engineering projects for the consideration of time, cost, safety, and the environment. This study proposes a feature-based evidential reasoning approach for probabilistic risk analysis and prediction, incorporating the learning process of belief degrees and estimation of the judgment quality. Firstly, classifiers are trained to estimate the probabilistic risk from sub-groups of factors. Secondly, the judgment from each classifier is evaluated according to the classifier’s performance which is characterized by the importance weight and reliability. Finally, the judgments from classifiers are fused via evidential reasoning to give the overall probabilistic risk classification result. The proposed approach displays superior performance on the dataset from Wuhan Metro with a 16% increase in precision, a 6% increase in recall, and an 8% increase in F1-score, compared to the direct model without information fusion. The fused model achieves a classification accuracy of 0.86 on the testing samples, which is better than the direct model. Besides, the model shows good error tolerance for wrongly classified results from classifiers without information fusion. The model has an acceptable performance even when the dataset is challenging to conduct classification tasks due to high overlapping areas in the attribute space.},
  archive      = {J_EAAI},
  author       = {Ying Wang and Limao Zhang},
  doi          = {10.1016/j.engappai.2021.104237},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104237},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Feature-based evidential reasoning for probabilistic risk analysis and prediction},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A framework for smart control using machine-learning
modeling for processes with closed-loop control in industry 4.0.
<em>EAAI</em>, <em>102</em>, 104236. (<a
href="https://doi.org/10.1016/j.engappai.2021.104236">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection for processes with closed-loop control has become a widespread need in Industry 4.0 shop floors. A major challenge in monitoring such processes arises from the unknown dependencies among monitored observations, as these dependencies may change dynamically and with high frequency. Motivated by these considerations, a novel framework is proposed for self-adaptive smart control using adaptive machine-learning models. On the one hand, data driven machine-learning algorithms can deal with patterns and dependencies within the data that were not necessarily known in advance. On the other hand, the recurrent self-adaptive mechanism triggers the need to switch to a new type of machine-learning model to capture and reflect new dependencies among monitored observations resulting from changes in the process. The proposed framework and the associated case study described in this paper could serve as a firm basis for implementing self-adaptive smart process control in Industry 4.0 shop-floor processes with closed-loop control.},
  archive      = {J_EAAI},
  author       = {Gonen Singer and Yuval Cohen},
  doi          = {10.1016/j.engappai.2021.104236},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104236},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A framework for smart control using machine-learning modeling for processes with closed-loop control in industry 4.0},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Peak shaving in district heating exploiting reinforcement
learning and agent-based modelling. <em>EAAI</em>, <em>102</em>, 104235.
(<a href="https://doi.org/10.1016/j.engappai.2021.104235">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {District Heating (DH) technology is considered to be a sustainable and quasi-renewable way of producing and distributing hot water along the city to heat buildings. However, the main obstacle to wider adoption of DH technology is represented by the thermal request peak in the morning hours of winter days, especially in Mediterranean countries. In this paper, this peak-shaving problem is tackled by combining three different approaches. A thermodynamic model is used to monitor the buildings’ thermal response to energy profile modifications. An agent-based model is adopted in order to represent the end-users and their adaptability to variations of temperatures in buildings. Finally, a Reinforcement Learning algorithm is used to optimally mediate between two needs: on the one hand, a set of anticipations and delays is applied to the energy profiles in order to reduce the thermal request peak. On the other hand, the algorithm learns by trial and error the individual agents’ sensitivity to thermal comfort, avoiding drastic modifications for the most sensitive users. The experiments carried out in the DH network in Torino (north-west of Italy) demonstrate that the proposed approach, compared with a literature solution chosen as a baseline, allows to achieve better results in terms of overall performances and speed of convergence.},
  archive      = {J_EAAI},
  author       = {Francesco M. Solinas and Lorenzo Bottaccioli and Elisa Guelpa and Vittorio Verda and Edoardo Patti},
  doi          = {10.1016/j.engappai.2021.104235},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104235},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Peak shaving in district heating exploiting reinforcement learning and agent-based modelling},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep reinforcement learning for QoS provisioning at the MAC
layer: A survey. <em>EAAI</em>, <em>102</em>, 104234. (<a
href="https://doi.org/10.1016/j.engappai.2021.104234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality of Service (QoS) provisioning is based on various network management techniques including resource management and medium access control (MAC). Various techniques have been introduced to automate networking decisions, particularly at the MAC layer. Deep reinforcement learning (DRL), as a solution to sequential decision making problems, is a combination of the power of deep learning (DL), to represent and comprehend the world, with reinforcement learning (RL), to understand the environment and act rationally. In this paper, we present a survey on the applications of DRL in QoS provisioning at the MAC layer. First, we present the basic concepts of QoS and DRL. Second, we classify the main challenges in the context of QoS provisioning at the MAC layer, including medium access and data rate control, and resource sharing and scheduling. Third, we review various DRL algorithms employed to support QoS at the MAC layer, by analyzing, comparing, and identifying their pros and cons. Furthermore, we outline a number of important open research problems and suggest some avenues for future research.},
  archive      = {J_EAAI},
  author       = {Mahmoud Abbasi and Amin Shahraki and Md. Jalil Piran and Amir Taherkordi},
  doi          = {10.1016/j.engappai.2021.104234},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104234},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep reinforcement learning for QoS provisioning at the MAC layer: A survey},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical delay-memory echo state network: A model
designed for multi-step chaotic time series prediction. <em>EAAI</em>,
<em>102</em>, 104229. (<a
href="https://doi.org/10.1016/j.engappai.2021.104229">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting for long-term dynamics of complex systems from observations is a challenging topic in the field of time series modeling and analysis, and is continually under research. Noteworthily, multi-step prediction requires accurate learning of dynamics and correlations between historical data for predicting future behavior. In this paper, we proposed a modified recurrent neural network named hierarchical delay-memory echo state network (HDESN) for solving the task of multi-step chaotic time series prediction. The HDESN uses multiple reservoirs with delay-memory capabilities, which can simultaneously discover and explore the information of short-term and long-term memory hidden in the historical sequence, and extract the valuable evolution patterns through deep topology and hierarchical processing. Moreover, to ensure high-quality prediction results and reduce the computational burden as much as possible, we further design a phase-space representation strategy which can calculate a compact topology and delay-memory coefficient according to the chaotic characteristics of the data. Compared with other improved ESN-based models, the proposed HDESN does not have a larger memory capacity to capture potential evolution law hidden in the complex system layer by layer, but can also adaptively determine a suitable network architecture to reflect the mapping relations in chaotic phase space. The experimental results on two benchmark chaotic systems and a real-world meteorological dataset demonstrate that the proposed HDESN model obtains satisfactory performance in multi-step chaotic time series prediction.},
  archive      = {J_EAAI},
  author       = {Xiaodong Na and Weijie Ren and Xinghan Xu},
  doi          = {10.1016/j.engappai.2021.104229},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {6},
  pages        = {104229},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hierarchical delay-memory echo state network: A model designed for multi-step chaotic time series prediction},
  volume       = {102},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretable tropical cyclone intensity estimation using
dvorak-inspired machine learning techniques. <em>EAAI</em>,
<em>101</em>, 104233. (<a
href="https://doi.org/10.1016/j.engappai.2021.104233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intensity of a tropical cyclone is correlated strongly to the damage it causes when it makes landfall. Most of the time, tropical cyclones are located over the open ocean, where direct intensity measurements are difficult to obtain. An alternative approach is to estimate the tropical cyclone intensity indirectly from satellite images. In this case, there are two key points to consider: spatial and temporal relationships. For spatial relationships, the basic assumption is that cyclones with similar intensities have similar patterns. Thus, researchers can estimate intensity using pattern extraction and investigating similarities. For temporal relationships, the intensity of the cyclone is assumed to change smoothly, as a tropical cyclone is a continuous weather phenomenon. Thus, satellite images belonging to the same tropical cyclone should have a temporal (chronological) relationship with one another, meaning that the estimated intensity value of subsequent images should not change too drastically. In this research, we take advantage of these two key points and use random walk with a restart model to discover hidden correlations between target and historical cyclone images to estimate their intensity. We then use machine learning models to determine the temporal relationships among cyclone images, smoothing the prediction of the tropical cyclone event as a whole. Finally, our results show 15.77-knot root-mean-square error (RMSE) for the intensity estimation of tropical cyclones in the West Pacific Basin area.},
  archive      = {J_EAAI},
  author       = {Yu-Ju Lee and David Hall and Quan Liu and Wen-Wei Liao and Ming-Chun Huang},
  doi          = {10.1016/j.engappai.2021.104233},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104233},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Interpretable tropical cyclone intensity estimation using dvorak-inspired machine learning techniques},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A physics-informed machine learning approach for solving
heat transfer equation in advanced manufacturing and engineering
applications. <em>EAAI</em>, <em>101</em>, 104232. (<a
href="https://doi.org/10.1016/j.engappai.2021.104232">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A physics-informed neural network is developed to solve conductive heat transfer partial differential equation (PDE), along with convective heat transfer PDEs as boundary conditions (BCs), in manufacturing and engineering applications where parts are heated in ovens. Since convective coefficients are typically unknown, current analysis approaches based on trial-and-error finite element (FE) simulations are slow. The loss function is defined based on errors to satisfy PDE, BCs and initial condition. An adaptive normalizing scheme is developed to reduce loss terms simultaneously. In addition, theory of heat transfer is used for feature engineering. The predictions for 1D and 2D cases are validated by comparing with FE results. While comparing with theory-agnostic ML methods, it is shown that only by using physics-informed activation functions, the heat transfer beyond the training zone can be accurately predicted. Trained models were successfully used for real-time evaluation of thermal responses of parts subjected to a wide range of convective BCs.},
  archive      = {J_EAAI},
  author       = {Navid Zobeiry and Keith D. Humfeld},
  doi          = {10.1016/j.engappai.2021.104232},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104232},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A physics-informed machine learning approach for solving heat transfer equation in advanced manufacturing and engineering applications},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cellular estimation of distribution algorithm designed to
solve the energy resource management problem under uncertainty.
<em>EAAI</em>, <em>101</em>, 104231. (<a
href="https://doi.org/10.1016/j.engappai.2021.104231">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Energy Resource Management (ERM) can be modeled as a Mixed-Integer Non-Linear Problem whose aim is to maximize profits generally using smart grid capabilities more than importing energy from external markets. Due to this, many resources and customers are involved in optimization, making ERM a complex problem. Moreover, when the inherent uncertainty of weather conditions, load forecast, electric vehicles planned trips, or market prices is considered, deterministic approaches might fail in obtaining optimal solutions to the problem. In this context, evolutionary algorithms are a useful tool to find effective near-optimal solutions. In fact, to design and test evolutionary algorithms to solve the ERM problem under uncertainty, the research community has developed a simulation framework. In this paper, we propose the Cellular Univariate Marginal Distribution Algorithm with Normal-Cauchy distribution (CUMDANCauchy) to address the ERM problem in uncertain environments. CUMDANCauchy uses a univariate estimation of the product of Normal and Cauchy distributions over each feature, and produces new individuals not only by the sampling of the learned distributions but also using neighborhoods of individuals from a ring cellular structure. The experiments performed over two case studies show that: CUMDANCauchy is as competitive as the previous dominant class of algorithms in terms of the global fitness achieved; its convergence behavior is among the best in comparison with the other tested algorithms; its running time is similar to the algorithm with the best global fitness achieved in the first case study, and it is the fastest algorithm in the second one.},
  archive      = {J_EAAI},
  author       = {Yoan Martínez-López and Ansel Y. Rodríguez-González and Julio Madera and Miguel Bethencourt Mayedo and Fernando Lezama},
  doi          = {10.1016/j.engappai.2021.104231},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104231},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Cellular estimation of distribution algorithm designed to solve the energy resource management problem under uncertainty},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Suspicious news detection through semantic and sentiment
measures. <em>EAAI</em>, <em>101</em>, 104230. (<a
href="https://doi.org/10.1016/j.engappai.2021.104230">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation has always existed in society. Nowadays, the technological development and the appearance of social networks, pseudo-newspapers and blogs, have aggravated this problem by facilitating the rapid spread of malicious news. This fact makes it easier to use disinformation as an attack vector for huge communities. This has led to the development of procedures that detect the appearance of this type of news and mitigate its influence. This article presents the Knowledge Recovering Architecture based on Keywords Extraction from Narratives for Suspicious News Detection (KRAKEN-SND) system. Its main goal is to support human experts to detect suspicious news articles that should be verified. In order to achieve this objective, it gathers narratives from multiple reliable information sources. Then, it extracts the semantic and sentiment relevant features from these narratives. This information is structured by date using a conceptual graph to generate trustworthy knowledge. The system includes a novel similarity measure that combines three specific components. This measure uses the stored knowledge to detect the peculiarity of a reported narrative that may contain suspicious information. Several experiments using relevant topics as Brexit and the COVID-19 pandemic among others have been carried out to validate the proposal, obtaining promising results.},
  archive      = {J_EAAI},
  author       = {Alejandro G. Martín and Alberto Fernández-Isabel and César González-Fernández and Carmen Lancho and Marina Cuesta and Isaac Martín de Diego},
  doi          = {10.1016/j.engappai.2021.104230},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104230},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Suspicious news detection through semantic and sentiment measures},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automation of load balancing for gantt planning using
reinforcement learning. <em>EAAI</em>, <em>101</em>, 104226. (<a
href="https://doi.org/10.1016/j.engappai.2021.104226">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Typically, in the shipbuilding industry, several vessels are built concurrently, and a production plan is established through a hierarchical planning process. This process largely comprises strategic planning (long-term) and master planning (mid-term) aspects. The portion that requires the most manual work of the planner is the load balancing in the master planning stage. The load balancing of master planning is an area where optimization studies using mixed integer programming, genetic algorithms, tabu search algorithms, and others have been actively conducted in the field of operational research. However, its practical application has not been successful due to the complexity and the curse of dimensionality, which is dependent on the manual work of the planner. Therefore, a new method that can facilitate the efficient action of optimal decisions is required, replacing conventional production planning methods based on the manual work of the planner. With the advent of the 4th industrial revolution in recent years, machine learning technology based on deep neural networks has been rapidly developing and applied to a wide range of engineering problems. This study introduces a methodology that can quickly improve the load balancing problem in shipyard master planning by using a deep neural network-based reinforcement learning algorithm among various machine learning techniques. Furthermore, we aim to verify the feasibility of the developed methodology using the ship block production data of an actual shipyard.},
  archive      = {J_EAAI},
  author       = {Jong Hun Woo and Byeongseop Kim and SuHeon Ju and Young In Cho},
  doi          = {10.1016/j.engappai.2021.104226},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104226},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automation of load balancing for gantt planning using reinforcement learning},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ZE-numbers: A new extended z-numbers and its application on
multiple attribute group decision making. <em>EAAI</em>, <em>101</em>,
104225. (<a
href="https://doi.org/10.1016/j.engappai.2021.104225">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the core mechanism of intelligent systems, decision-making has received widespread attention in recent years. As decision-making environments become more complex, large amounts of data are fuzzy and partially reliable. Zadeh proposed the concept of the Z-numbers, this more anthropomorphic fuzzy set representation framework describes the simultaneous existence of probability measures and probability measures of random variables, and it is regarded as a very powerful tool for modeling uncertain information. However, the representation of Z-numbers still has limitations. Therefore, we propose a new extended Z-numbers, Z E = ( ( A , B ) , E ) , E is the credibility. As the objective reliability of ( A , B ) , it restricts the original Z-numbers. At the same time, the conversion function between them is also defined. Based on this, we proposed a multi-attribute group decision-making (MAGDM) method considering the attitudes of decision-makers. Application examples show the rationality and effectiveness of the proposed methodology, and the superiority of this method is further illustrated through comparison and discussion with other methods.},
  archive      = {J_EAAI},
  author       = {Ye Tian and Xiangjun Mi and Yunpeng Ji and Bingyi Kang},
  doi          = {10.1016/j.engappai.2021.104225},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104225},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ZE-numbers: A new extended Z-numbers and its application on multiple attribute group decision making},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A generalized TODIM-ELECTRE II based integrated
decision-making framework for technology selection of energy
conservation and emission reduction with unknown weight information.
<em>EAAI</em>, <em>101</em>, 104224. (<a
href="https://doi.org/10.1016/j.engappai.2021.104224">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy conservation and emission reduction (ECER) has become an indispensable trend of green life. How to choose a suitable technology for ECER under complex decision-making scenarios has become a key issue faced by traditional industrial enterprises. In this paper, a new integrated decision-making framework is established for technology-selection problems. Firstly, to describe complex linguistic information more accurately and reduce information loss, this framework employs the double hierarchy hesitant fuzzy linguistic term sets (DHHFLTSs) to describe the performance of alternatives. To avoid data redundancy and simplify the computation, we improve the operations of double hierarchy hesitant fuzzy linguistic elements (DHHFLEs) and propose a new comparison method for DHHFLEs. Secondly, based on the proposed normalized projection-based difference measurement, a novel method is proposed to derive the weights of experts regarding each criterion, the group decision-making method based on the best-worst method is also utilized to derive the criteria’s weights via consistent pairwise comparisons. Further, an integrated generalized TODIM (an acronym in Portuguese of interactive and multiple attribute decision making)-ELECTRE II (Elimination and Choice Translating Reality II) method is established to rank alternatives, which has the advantages of dealing with the non-compensatory problem of criteria and considering risk-aversion behavior of experts simultaneously. Subsequently, a case study of emission-reduction technology investment is provided to manifest the practicality and reliability of the given framework. Finally, the preponderance and effectiveness of the proposed method are illuminated through a comparative analysis with several existing representative methods.},
  archive      = {J_EAAI},
  author       = {Zhengmin Liu and Di Wang and Xinya Wang and Xiaolan Zhao and Peide Liu},
  doi          = {10.1016/j.engappai.2021.104224},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104224},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A generalized TODIM-ELECTRE II based integrated decision-making framework for technology selection of energy conservation and emission reduction with unknown weight information},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting crude oil price with a new hybrid approach and
multi-source data. <em>EAAI</em>, <em>101</em>, 104217. (<a
href="https://doi.org/10.1016/j.engappai.2021.104217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Faced with the growing research toward crude oil price fluctuations influential factors following the accelerated development of Internet technology, accessible data such as Google search volume index (GSVI) are increasingly quantified and incorporated into forecasting approaches. In this study, we apply multi-scale data that including both traditional economic data and GSVI data reflecting macro and micro mechanisms affecting crude oil price respectively, so as to reduce the forecasting deviation and improve the forecasting accuracy at source. In addition, a new hybrid approach: K-means＋KPCA＋KELM based on “divide and conquer” strategy is proposed for deeply exploring the information of above multi-data so that improve monthly crude oil price forecasting accuracy. Empirical results can be analyzed from data and method levels. At the data level, GSVI data perform better than economic data in level forecasting accuracy but with opposite performance in directional forecasting accuracy because of “Herd Behavior”, while hybrid data combined their advantages and obtain best forecasting performance in both level and directional accuracy. At the method level, the approaches with “divide and conquer” strategy gain a better forecasting performance, which demonstrates that “divide and conquer” strategy can effectively improve the forecasting performance.},
  archive      = {J_EAAI},
  author       = {Yifan Yang and Ju’e Guo and Shaolong Sun and Yixin Li},
  doi          = {10.1016/j.engappai.2021.104217},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104217},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting crude oil price with a new hybrid approach and multi-source data},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised feature selection techniques in network intrusion
detection: A critical review. <em>EAAI</em>, <em>101</em>, 104216. (<a
href="https://doi.org/10.1016/j.engappai.2021.104216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Learning (ML) techniques are becoming an invaluable support for network intrusion detection, especially in revealing anomalous flows, which often hide cyber-threats. Typically, ML algorithms are exploited to classify/recognize data traffic on the basis of statistical features such as inter-arrival times, packets length distribution, mean number of flows, etc. Dealing with the vast diversity and number of features that typically characterize data traffic is a hard problem. This results in the following issues: (i) the presence of so many features leads to lengthy training processes (particularly when features are highly correlated), while prediction accuracy does not proportionally improve; (ii) some of the features may introduce bias during the classification process, particularly those that have scarce relation with the data traffic to be classified. To this end, by reducing the feature space and retaining only the most significant features, Feature Selection (FS) becomes a crucial pre-processing step in network management and, specifically, for the purposes of network intrusion detection. In this review paper, we complement other surveys in multiple ways: (i) evaluating more recent datasets (updated w.r.t. obsolete KDD 99) by means of a designed-from-scratch Python-based procedure; (ii) providing a synopsis of most credited FS approaches in the field of intrusion detection, including Multi-Objective Evolutionary techniques; (iii) assessing various experimental analyses such as feature correlation, time complexity, and performance. Our comparisons offer useful guidelines to network/security managers who are considering the incorporation of ML concepts into network intrusion detection, where trade-offs between performance and resource consumption are crucial.},
  archive      = {J_EAAI},
  author       = {M. Di Mauro and G. Galatro and G. Fortino and A. Liotta},
  doi          = {10.1016/j.engappai.2021.104216},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104216},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Supervised feature selection techniques in network intrusion detection: A critical review},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using modified term frequency to improve term weighting for
text classification. <em>EAAI</em>, <em>101</em>, 104215. (<a
href="https://doi.org/10.1016/j.engappai.2021.104215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text classification (TC) is an essential task of natural language processing (NLP). In order to improve the performance of TC, term weighting is often used to obtain effective text representation by assigning appropriate weights to each term. A term weighting scheme is generally composed of term frequency factor, collection frequency factor and normalization factor. The normalization factor is commonly used as an optional factor to offset the influence of document length. Through the investigation of the existing term weighting schemes, we found that most of them focus on finding a more effective collection frequency factor, but rarely pay attention to finding a new term frequency factor. In this paper, we first proposed a new term frequency factor called modified term frequency (MTF). Different from the normalization factor, MTF directly modifies the raw term frequency based on the length information of all training documents. Then we proposed a new term weighting scheme by combining MTF with an existing collection frequency factor called modified distinguishing feature selector (MDFS). We denoted our scheme by MTF-MDFS (MDFS-based MTF). Extensive experimental results on 19 benchmark text datasets and 6 real-world text datasets show that our proposed MTF and MTF-MDFS are all much better than their state-of-the-art competitors in terms of the classification accuracy and the weighted average of F 1 of widely used base classifiers, such as MNB, SVM and LR.},
  archive      = {J_EAAI},
  author       = {Long Chen and Liangxiao Jiang and Chaoqun Li},
  doi          = {10.1016/j.engappai.2021.104215},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104215},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Using modified term frequency to improve term weighting for text classification},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying the module structure of swarms using a new
framework of network-based time series clustering. <em>EAAI</em>,
<em>101</em>, 104214. (<a
href="https://doi.org/10.1016/j.engappai.2021.104214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm is a collective motion phenomenon whose dynamic mechanism and cooperation structure could be identified based on observations. Unmanned Aerial Vehicles (UAV) is a special artificial swarm with unique rules and structures. Therefore, corresponding identification methods need to be developed. One critical identification problem is distinguishing the swarm’s cooperation structure, which is usually clustered and grouped to achieve stability of behaviors and low communication cost. This paper proposes a framework of Overlay Network Integrated Time series clustering (ONIT) to identify the UAV swarm structures based on trajectories. The framework consists of Snapshot, Net Growth and Net Split. It can fuse with most distance functions in time series clustering, achieving high accuracy, update ability, and fault tolerance with various datasets. We create point-based and sliding window-based snapshots, allowing the framework compatible with more methods. In particular, the Dynamic Time Wrapping (DTW) correspondence in point-based snapshots shows the high scalability of the framework, and the Euclidean Distance (ED) correspondence shows that the framework can still significantly improve the accuracy while maintaining the simplicity of calculation. The test results show that the fused ONIT-clustering algorithms, especially the point-based ones, outperform original time series clustering methods separately in simulation datasets of UAV swarms and UCR repository by 28% and 27%. In summary, the proposed framework is a flexible and scalable time series clustering method that can solve various time series clustering problems especially the trajectory clustering of the UAV swarm and has great potential for general time series analysis.},
  archive      = {J_EAAI},
  author       = {Kongjing Gu and Ziyang Mao and Xiaojun Duan and Guanlin Wu and Liang Yan},
  doi          = {10.1016/j.engappai.2021.104214},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104214},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Identifying the module structure of swarms using a new framework of network-based time series clustering},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamic framework of multi-attribute decision making under
pythagorean fuzzy environment by using dempster–shafer theory.
<em>EAAI</em>, <em>101</em>, 104213. (<a
href="https://doi.org/10.1016/j.engappai.2021.104213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel framework for dynamic multi-attribute decision making (MADM) in Pythagorean fuzzy environments based on Dempster–Shafer theory (DST). The credibility of decision information decreases with time, so it is significant to capture the dynamic credibility of decision information in the temporal dimension. The proposed credibility decay model discounts decision information based on the credibility decay factor to obtain the basic probability assignment (BPA) vector corresponding to individual periods. Weight determination is an important aspect of dynamic MADM. We propose weighting the attributes in-period and in each period via subjective approach (evidential best–worst method) and objective approach (entropy weight method), respectively. We determine the period weight from the dual dimensions of information and consistency. The dynamic MADM is completed by combining the decision information of all attributes in each period, fusing the decision information of different periods, and calculating the ranking index of each alternative. The proposed dynamic decision framework is validated by a case study.},
  archive      = {J_EAAI},
  author       = {Liguo Fei and Yuqiang Feng},
  doi          = {10.1016/j.engappai.2021.104213},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104213},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamic framework of multi-attribute decision making under pythagorean fuzzy environment by using Dempster–Shafer theory},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A spherical fuzzy methodology integrating maximizing
deviation and TOPSIS methods. <em>EAAI</em>, <em>101</em>, 104212. (<a
href="https://doi.org/10.1016/j.engappai.2021.104212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the uncertainty and vagueness, ambiguity and subjectivity of the information in an intricate decision-making environment, the assessment data specified by experts are mostly fuzzy and uncertain. As an extension of Pythagorean fuzzy sets (PyFSs) and picture fuzzy sets (PFSs), spherical fuzzy sets (SFSs) are used frequently for presenting fuzzy and indeterminate information. In multi-criteria decision-making (MCDM) problems, the weights of criteria are not known generally. The maximizing deviation technique is a useful tool to handle such problems that we have partially or incomplete information about the criteria’ weights. This research expands the classical maximizing deviation technique to the spherical fuzzy maximizing deviation technique using single-valued (SV) and interval-valued (IV) spherical fuzzy sets to determine criteria weights. To rank the alternatives and specify the preeminent preference, we proposed the Interval Valued Spherical Fuzzy TOPSIS method based on the similarity measure instead of distance measure. For this purpose, we proposed an IVSF cosine similarity measure. To present its effectiveness and practicability, we apply the proposed methodology to an advertisement strategy selection problem, where IVSF sets are used to represent the evaluations about alternatives and criteria. A sensitivity analysis with different similarity measurements is performed to show the reliability of the proposed methodology.},
  archive      = {J_EAAI},
  author       = {Elmira Farrokhizadeh and Seyed Amin Seyfi-Shishavan and Fatma Kutlu Gündoğdu and Yaser Donyatalab and Cengiz Kahraman and Seyyed Hadi Seifi},
  doi          = {10.1016/j.engappai.2021.104212},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104212},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A spherical fuzzy methodology integrating maximizing deviation and TOPSIS methods},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent advances in motion and behavior planning techniques
for software architecture of autonomous vehicles: A state-of-the-art
survey. <em>EAAI</em>, <em>101</em>, 104211. (<a
href="https://doi.org/10.1016/j.engappai.2021.104211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous vehicles (AVs) have now drawn significant attentions in academic and industrial research because of various advantages such as safety improvement, lower energy and fuel consumption, exploitation of road network, reduced traffic congestion and greater mobility. In critical decision making process during motion of an AV, intelligent motion planning takes an important and challenging role for obstacle avoidance, searching for the safest path to follow, generation of suitable behavior and comfortable trajectory generation by optimization while keeping road boundaries and traffic rules as important concerns. An AV should also be able to decide the safest behavior (such as overtaking in case of highway driving) at each moment during driving. The behavior planning techniques anticipate the behaviors of all traffic participants; then it reasonably decides the best and safest behavior for AV. For this highly challenging task, many different motion and behavior planning techniques for AVs have been developed over past few decades. The purpose of this paper is to present an exhaustive and critical review of these existing approaches on motion and behavior planning for AVs in terms of their feasibility, capability in handling dynamic constraints and obstacles, and optimality of motion for comfort. A critical evaluation of the existing behavior planning techniques highlighting their advantages, ability in handling of static and dynamic obstacles, vehicle constraints and limitations in operational environments has also been presented.},
  archive      = {J_EAAI},
  author       = {Omveer Sharma and N.C. Sahoo and N.B. Puhan},
  doi          = {10.1016/j.engappai.2021.104211},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104211},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Recent advances in motion and behavior planning techniques for software architecture of autonomous vehicles: A state-of-the-art survey},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An image segmentation method based on a modified
local-information weighted intuitionistic fuzzy c-means clustering and
gold-panning algorithm. <em>EAAI</em>, <em>101</em>, 104209. (<a
href="https://doi.org/10.1016/j.engappai.2021.104209">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image segmentation method based on clustering analysis has the advantages of small sample space constraints and strong universality. As an unsupervised clustering algorithm, the fuzzy C-means clustering algorithm is widely used in practical engineering. However, it is still some shortcomings: the fuzzy C-means clustering algorithm is difficult to interpret the noise effectively, which makes it more sensitive to the noise, and the selection of key parameters has to be made by trial and error experiments, reducing the adaptability of the algorithm. Besides, its iteration process is heavily influenced by the initial clustering centers and easy to fall into local optimum. Therefore, an intuitionistic Fuzzy C-means clustering method, based on local-information weight, is proposed in this paper. By introducing the local-information weight, the proposed algorithm adjusts the local-information influence weight adaptively in fuzzy partition, which enhances its robustness to noisy images. Furthermore, a novel swarm intelligence algorithm, called the Gold-Panning Algorithm, is proposed to optimize the initial clustering centers and key parameters in the clustering algorithm. By utilizing the Gold-Panning Algorithm, the adaptability of the proposed clustering algorithm is further improved. In this paper, the proposed methods are explained in detail and compared with the existing methods to demonstrate its superior performance.},
  archive      = {J_EAAI},
  author       = {Dong Wei and Zhongbin Wang and Lei Si and Chao Tan and Xuliang Lu},
  doi          = {10.1016/j.engappai.2021.104209},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104209},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An image segmentation method based on a modified local-information weighted intuitionistic fuzzy C-means clustering and gold-panning algorithm},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving a new robust reverse job shop scheduling problem by
meta-heuristic algorithms. <em>EAAI</em>, <em>101</em>, 104207. (<a
href="https://doi.org/10.1016/j.engappai.2021.104207">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing concerns of companies to economic savings, optimal utilization of resources, and increased environmental protection regulations prompt the manufacturers to be more focused on the recycling of the products that are at the end of their useful life. This study considers a job shop scheduling problem with reverse flows under uncertainty. Since the main parameter of the model (i.e., the processing time of operations) is tainted with a great degree of uncertainty in real-world applications, a robust programming approach is utilized. This paper proposes a computationally efficient model. Due to the complexity and difficulty of solving the presented model, an exact solution method for small-sized instances and simulated annealing (SA) and discrete harmony search (DHS) algorithms for medium- and large-sized instances are proposed. The model performance is evaluated by comparing the computational results with the literature. Furthermore, the performance of the proposed meta-heuristic algorithms is evaluated by comparing the resulted solutions with the exact method for small-sized instances and with three other meta-heuristics algorithms, such as discrete particle swarm optimization (DPSO) and invasive weed optimization (DIWO), and iterated greedy (IG) algorithms, for medium- and large-sized instances. The satisfying results show that the presented model and proposed algorithms ensure good quality solutions within a reasonable time for all test problems and the SA algorithm outperforms the DIWO, DPSO, DHS, and IG algorithms in most cases.},
  archive      = {J_EAAI},
  author       = {K. Dehghan-Sanej and M. Eghbali-Zarch and R. Tavakkoli-Moghaddam and S.M. Sajadi and S.J. Sadjadi},
  doi          = {10.1016/j.engappai.2021.104207},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104207},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving a new robust reverse job shop scheduling problem by meta-heuristic algorithms},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inferring the value of a variable using measure based
information of a related variable. <em>EAAI</em>, <em>101</em>, 104201.
(<a href="https://doi.org/10.1016/j.engappai.2021.104201">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We first describe the problem, determining the best value for a variable W whose value depends on the value of a related variable V. Here we assume our knowledge of V is uncertain and is modeled using a fuzzy measure. We discuss the properties of a fuzzy measure and its use modeling uncertainty. We describe the concept of the dual of a fuzzy measure and the related idea of a Pan-Dual. We describe a procedure for obtaining the best estimate of W using the Pan-Dual of V and provide an illustrative example.},
  archive      = {J_EAAI},
  author       = {Ronald R. Yager},
  doi          = {10.1016/j.engappai.2021.104201},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104201},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Inferring the value of a variable using measure based information of a related variable},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-criteria decision making method based on DNMA and
CRITIC with linguistic d numbers for blockchain platform evaluation.
<em>EAAI</em>, <em>101</em>, 104200. (<a
href="https://doi.org/10.1016/j.engappai.2021.104200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since more and more blockchain platforms have been utilized in diverse business applications, the blockchain platform evaluation becomes significant for clients. There are challenges regarding the blockchain platform evaluation in terms of information uncertainty, multiple types of criteria, and the correlations between criteria. This study dedicates to proposing a method to solve these problems by integrating linguistic D numbers (LDNs), double normalization-based multiple aggregation (DNMA) method, and Criteria Importance Through Inter-criteria Correlation (CRITIC) method. Firstly, a conversion rule of LDNs is introduced to enhance the comparative rule of LDNs. Then, an integrated multiple criteria decision making framework is proposed by incorporating DNMA with LDNs. This method not only can effectively capture the incomplete or uncertain decision-making information with respect to cost, benefit, and target criteria, but also can reduce the loss of decision information caused by single normalized technology. The CRITIC method is integrated in the LDN-based DNMA method to reflect the correlations between criteria in the blockchain platform evaluation process. To investigate the efficiency of the proposed method, a numerical example of blockchain platform evaluation is given. The sensitivity analysis demonstrates the robustness and stability of the developed method. The comparative analysis shows that our method can identify the potentially important criteria in the decision-making process effectively.},
  archive      = {J_EAAI},
  author       = {Han Lai and Huchang Liao},
  doi          = {10.1016/j.engappai.2021.104200},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104200},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-criteria decision making method based on DNMA and CRITIC with linguistic d numbers for blockchain platform evaluation},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A re-optimized deep auto-encoder for gas turbine
unsupervised anomaly detection. <em>EAAI</em>, <em>101</em>, 104199. (<a
href="https://doi.org/10.1016/j.engappai.2021.104199">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of hidden features or reconstruction errors extracted by deep auto-encoder (DAE) is becoming popular to discriminate anomalies from normal. Nevertheless, the fact that the existing methods only involving one of these two aspects loss the useful information from the other one motivates this investigation of method to combine reconstruction errors with hidden features. More importantly, anomalies are not removed in the training set when optimizing the traditional DAE, which weakens the discrimination of the reconstruction error. Aiming at these two problem, a new deep learning method, the so-called Re-optimized Deep Auto-Encoder (R-DAE), is developed to improve the detective performance for gas turbine unsupervised anomaly detection. First, the developed R-DAE takes the hidden features and the induced reconstruction errors as the final features. Second, to make the reconstruction error more discriminative, a sample selection mechanism is designed to attempt to remove anomalies from original unannotated training set, which makes the R-DAE almost unaffected by abnormal samples during training. Third, to effectively process time series, isolation forest is used to detect the obtained final features. Experiments on the real-life operation data of a gas turbine sample fleet validate the excellent detective performance of the proposed method.},
  archive      = {J_EAAI},
  author       = {Song Fu and Shisheng Zhong and Lin Lin and Minghang Zhao},
  doi          = {10.1016/j.engappai.2021.104199},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104199},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A re-optimized deep auto-encoder for gas turbine unsupervised anomaly detection},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State–space modeling for control based on physics-informed
neural networks. <em>EAAI</em>, <em>101</em>, 104195. (<a
href="https://doi.org/10.1016/j.engappai.2021.104195">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic system models, based on partial differential equations (PDEs), are often unsuitable for direct use in control or state estimation purposes, due to the high computational cost arising from the necessity to apply sophisticated numerical methods for a solution, such as semi-discretization, also known as spatial discretization. Hence, there is often an inevitable trade-off between accuracy and computational efficiency during the model reduction step to ensure real-time applicability. In this contribution, we propose a state–space model formulation, using so-called physics-informed neural networks . This modeling approach enables a highly efficient inclusion of complex physical system descriptions within the design of control or state estimation setups. The resulting state–space model does not require any numerical solution techniques during the state propagation, as each time step is based on the evaluation of a reasonably sized neural net that approximates the solution of the PDE. Thus, this approach is suitable for real-time applications of various complex dynamic systems that can be described by one or a set of PDEs. Besides the modeling approach itself, the contribution also provides an illustrative example of the state–space modeling method in the context of model predictive control, as well as state estimation with an extended Kalman filter. These methods will be applied to a system based on a numerical solution of the Burgers equation.},
  archive      = {J_EAAI},
  author       = {Florian Arnold and Rudibert King},
  doi          = {10.1016/j.engappai.2021.104195},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104195},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {State–space modeling for control based on physics-informed neural networks},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel recommendation scheme with multifactorial weighted
matrix decomposition strategies via forgetting rule. <em>EAAI</em>,
<em>101</em>, 104191. (<a
href="https://doi.org/10.1016/j.engappai.2021.104191">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation systems play more and more important roles in many fields, such as movie recommendation, book recommendation, music recommendation. Sparse data and large-scale data result in low recommendation efficiency and a cold start problem. Recently, matrix decomposition plays an active role in recommendation with its high recommendation efficiency and fast recommendation speed. But in most matrix completion mechanisms, time influence and users features are not fully utilized. In this paper, a continuous function is constructed to grasp the time-varying rule of users’ interests, and the scores of different scoring time are processed by this function. Thus, the processed scores contain not only the user interests but also their memory rule. Moreover, user interests may change slowly over time, so we keep the original rating matrix in the recommendation process. Finally, a new matrix decomposition optimization model is constructed by considering the score matrix that combines time information and the original score matrix. Compared with the recent matrix decomposition recommendation algorithms, the effectiveness of our proposed algorithm is verified based on the recommended evaluation metrics and several datasets.},
  archive      = {J_EAAI},
  author       = {Jianrui Chen and Yanqing Lu and Fanhua Shang and Tingting Zhu},
  doi          = {10.1016/j.engappai.2021.104191},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104191},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel recommendation scheme with multifactorial weighted matrix decomposition strategies via forgetting rule},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian retinex underwater image enhancement.
<em>EAAI</em>, <em>101</em>, 104171. (<a
href="https://doi.org/10.1016/j.engappai.2021.104171">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper develops a Bayesian retinex algorithm for enhancing single underwater image with multiorder gradient priors of reflectance and illumination. First, a simple yet effective color correction approach is adopted to remove color casts and recover naturalness. Then a maximum a posteriori formulation for underwater image enhancement is established on the color-corrected image by imposing multiorder gradient priors on reflectance and illumination. The l 1 norm is appropriately used to model piecewise and piecewise linear approximations on the reflectance, and the l 2 norm is used to enforce spatial smoothness and spatial linear smoothness on the illumination. Meanwhile, a complex underwater image enhancement issue is turned into two simple denoising subproblems where their convergence analyses are mathematically provided, and their solutions can be derived by an efficient optimization algorithm. Besides, the proposed model is fast implemented on pixelwise operations while not requiring additional prior knowledge about underwater imaging conditions. Final experiments demonstrate the effectiveness of the proposed method in color correction, naturalness preservation, structures and details promotion, artifacts or noise suppression. Compared with several traditional and leading enhancement approaches, the proposed method yields better results on qualitative and quantitative assessments. The superiority of the proposed method can be extended to several challenging applications.},
  archive      = {J_EAAI},
  author       = {Peixian Zhuang and Chongyi Li and Jiamin Wu},
  doi          = {10.1016/j.engappai.2021.104171},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104171},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Bayesian retinex underwater image enhancement},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New global optimization algorithms based on multi-loop
distributed control systems with serial structure and ring structure for
solving global optimization problems. <em>EAAI</em>, <em>101</em>,
104115. (<a
href="https://doi.org/10.1016/j.engappai.2020.104115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, new optimization algorithms using multi-loop distributed control systems with serial structure and ring structure are proposed for solving global optimization problems, where the control plant of the subsystem is replaced by the objective function of a given optimization problem. When the control plant of each sub-loop control system is known, some simplified methods of the control plant are first proposed. These approaches change a complex control plant into a simple function without changing global optimization solution to find the global optimization solution more easily by using multi-loop distributed control systems that has two kinds of serial structure and ring structure. When the control plant of each sub-loop control system is unknown, the objective function is identified by a neural network. In addition, a proposed special neural network as a local search rule is divided to m neural network subsystems by different sizes of the effective change interval of the transformation function. In other words, the smaller the index number of a subsystem is, the stronger the local search ability of the subsystem is, otherwise, the stronger the global search ability of the subsystem is. And the current best optimization solution between all neural network subsystems is used to guide each neural network subsystem. Simultaneously, a new filled function is proposed as a global search rule. It can jump out of a local minimum point and move to another local minimum point with smaller objective function value. Finally, 17 experimental examples show the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Baiquan Lu and Zhongwei Zheng and Zhijun Zhang and Ying Yu and Tingzhang Liu},
  doi          = {10.1016/j.engappai.2020.104115},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {5},
  pages        = {104115},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {New global optimization algorithms based on multi-loop distributed control systems with serial structure and ring structure for solving global optimization problems},
  volume       = {101},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Review of swarm intelligence-based feature selection
methods. <em>EAAI</em>, <em>100</em>, 104210. (<a
href="https://doi.org/10.1016/j.engappai.2021.104210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past decades, the rapid growth of computer and database technologies has led to the rapid growth of large-scale datasets. On the other hand, data mining applications with high dimensional datasets that require high speed and accuracy are rapidly increasing. An important issue with these applications is the curse of dimensionality, where the number of features is much higher than the number of patterns. One of the dimensionality reduction approaches is feature selection that can increase the accuracy of the data mining task and reduce its computational complexity. The feature selection method aims at selecting a subset of features with the lowest inner similarity and highest relevancy to the target class. It reduces the dimensionality of the data by eliminating irrelevant, redundant, or noisy data. In this paper, a comparative analysis of different feature selection methods is presented, and a general categorization of these methods is performed. Moreover, in this paper, state-of-the-art swarm intelligence is studied, and the recent feature selection methods based on these algorithms are reviewed. Furthermore, the strengths and weaknesses of the different studied swarm intelligence-based feature selection methods are evaluated.},
  archive      = {J_EAAI},
  author       = {Mehrdad Rostami and Kamal Berahmand and Elahe Nasiri and Saman Forouzandeh},
  doi          = {10.1016/j.engappai.2021.104210},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104210},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Review of swarm intelligence-based feature selection methods},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local–global attentive adaptation for object detection.
<em>EAAI</em>, <em>100</em>, 104208. (<a
href="https://doi.org/10.1016/j.engappai.2021.104208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial adaptive methods have been proven to be useful for domain transfer in many fields such as image recognition and semantic segmentation, etc However, for object detection, since each image could have different combinations of objects, brutally aligning all the images without considering their transferability may cause the notorious phenomena named ‘negative transfer’. On the other hand, strong matching the local-level features makes sense, as it not only reduces the discrepancy between different domain distributions, but preserves the category-level semantic information. However, it is hard to markedly achieve domain invariance using a simple adversarial adaptive method. In this work, we propose an effective method termed Local–Global Attentive Adaptation for object Detection (LGAAD). Our method can alleviate the negative transfer caused by improper global alignments through leveraging an adaptively and dynamically weighted transferability to highlight the more transferable images. Furthermore, the proposed method also achieves the strong matching between two domains at local-level features to alleviate the cross-domain discrepancy by using the attention mechanism after multiple local discriminators. Additionally, we also consider the domain impacts of instance-wise features and backgrounds in images with large domain divergence, a non-negligible factor for improving the domain adaptive detection model performance. Extensive experiments of various domain shift scenarios show that our method exceeds the state-of-the-art results on several public datasets. Furthermore, qualitative visualization and ablation analyzes can demonstrate the validity of our approach for attending the interested regions and instances on domain adaptation.},
  archive      = {J_EAAI},
  author       = {Dan Zhang and Jingjing Li and Xingpeng Li and Zhekai Du and Lin Xiong and Mao Ye},
  doi          = {10.1016/j.engappai.2021.104208},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104208},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Local–Global attentive adaptation for object detection},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A temporal LASSO regression model for the emergency
forecasting of the suspended sediment concentrations in coastal oceans:
Accuracy and interpretability. <em>EAAI</em>, <em>100</em>, 104206. (<a
href="https://doi.org/10.1016/j.engappai.2021.104206">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In situ observations of suspended sediment concentration (SSC) and hydrodynamics were conducted in the subaqueous Yellow River Delta, China. With the dataset, a new least absolute shrinkage and selection operator (LASSO) regression model with temporal autocorrelation incorporated (temporal LASSO) is proposed for SSC prediction and mechanism investigation in coastal oceans. The model is concise and practical, effectively shrinking the interrelated variables into representative ones, while also achieving one-hour ahead forecasting with both higher accuracy and better interpretability than other data-driven methods. The model interpretability is further validated with direct data analysis from a physical perspective. Specifically, Empirical Mode Decomposition is employed to decouple the measured SSC into intrinsic mode functions (IMFs) and a residual. The periods of each subseries estimated from both zero-crossing and spectrum analysis show that IMF 1 physically corresponds to the sediment resuspension by M4 tidal currents, IM F 2 is the M2 tidal advection, IMF 3 -IMF 5 are the resuspension by wind waves, IM F 6 is the spring–neap tidal pumping of sediments. The contributions estimated with the ratio of variance are 12 %, 14 %, 63 %, and 10 %, respectively, over the observation period. The residual is the seasonal variations which can be taken as the background SSC thus not included for variance contribution. Waves make the dominant contribution which verifies the rationality of the LASSO shrinkage and confirms the model interpretability. The temporal LASSO model is shown to be a potential tool for emergency forecasting and mechanism explanation of SSC to benefit ocean environmental engineering management.},
  archive      = {J_EAAI},
  author       = {Shaotong Zhang and Jinran Wu and Yonggang Jia and You-Gan Wang and Yaqi Zhang and Qibin Duan},
  doi          = {10.1016/j.engappai.2021.104206},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104206},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A temporal LASSO regression model for the emergency forecasting of the suspended sediment concentrations in coastal oceans: Accuracy and interpretability},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An effective combination of loss gradients for multi-task
learning applied on instance segmentation and depth estimation.
<em>EAAI</em>, <em>100</em>, 104205. (<a
href="https://doi.org/10.1016/j.engappai.2021.104205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advanced driver assistance systems are responsible for assisting decision making and can play an important role in safety and traffic efficiency. Such systems require robust perception methods to handle complex urban scenes, and one way to achieve this is through instance segmentation. However, due to the difficulty in separating overlapping objects into different instances, this task becomes very challenging. For this, several authors proposed CNN-based methods and used depth information to enhance the instance segmentation performance. A promising way to explore this information is by adopting a multi-task learning approach, in which multiple tasks are learned simultaneously by sharing the same architecture. Usually, this combination is made by the weighted sum of loss functions, in which the weight of each task is defined manually. Nonetheless, when tasks have different natures with variation in the order of magnitude, performing this combination during training so that all tasks converge towards their optimal solution is not trivial. Aiming to get the best possible solution, we modeled the multi-task learning as a multiobjective optimization problem and, as the main contribution of this paper, we proposed a greedy approach to find the weighting coefficients for each task, performing a trade-off between tasks that allow the optimization of multiple loss functions. Experimental results showed that it is possible to enhance instance segmentation when depth information is properly explored. Moreover, not only did depth information help instance segmentation, but also did the instance segmentation help the depth estimations, achieving better performance compared to single-task models.},
  archive      = {J_EAAI},
  author       = {Angelica Tiemi Mizuno Nakamura and Valdir Grassi Jr. and Denis Fernando Wolf},
  doi          = {10.1016/j.engappai.2021.104205},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104205},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An effective combination of loss gradients for multi-task learning applied on instance segmentation and depth estimation},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A better way of extracting dominant colors using salient
objects with semantic segmentation. <em>EAAI</em>, <em>100</em>, 104204.
(<a href="https://doi.org/10.1016/j.engappai.2021.104204">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most prominent parts of professional design consists of combining the right colors. This combination can affect emotions, psychology, and user experience since each color in the combination has a unique effect on each other. It is a very challenging to determine the combination of colors since there are no universally accepted rules for it. Yet finding the right color combination is crucial when it comes to designing a new product or decorating the interiors of a room. The main motivation of this study is to extract the dominant colors of a salient object from an image even if the objects overlap each other. In this way, it is possible to find frequent and popular color combinations of a specific object. So, first of all, a modified Inception-ResNet architecture was designed semantically segmentate objects in the image. Then, SALGAN was applied to find the salient object in the image since the aim here is to find the dominant colors of the salient object in a given image. After that, the outputs consisted of the SALGAN applied image and segmented image were combined to obtain the corresponding segment for the purpose of finding the salient object on the image. Finally, since we aimed to quantize the pixels of the corresponding segment in the image, we applied k-means clustering which partitions samples into K clusters. The algorithm works iteratively to assign each data point to one of the K groups based on their features. Data points were clustered according to feature similarity. As a result the clustering, the most relevant dominant colors were extracted. Our comprehensive experimental survey has demonstrated the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Ayse Bilge Gunduz and Berk Taskin and Ali Gokhan Yavuz and Mine Elif Karsligil},
  doi          = {10.1016/j.engappai.2021.104204},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104204},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A better way of extracting dominant colors using salient objects with semantic segmentation},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dynamical hybrid method to design decision making process
based on GRA approach for multiple attributes problem. <em>EAAI</em>,
<em>100</em>, 104203. (<a
href="https://doi.org/10.1016/j.engappai.2021.104203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article intends to study the dynamic hybrid multi-attribute decision making (DHMADM) process, where the choice information is given in two-scale intuitionistic fuzzy numbers (IFNs) as well as interval-valued intuitionistic fuzzy numbers (IVIFNs) by the decision-makers (DMs) at distinct periods. We have contributed some new dynamic weighted aggregation operators (AOs), namely dynamic intuitionistic fuzzy Dombi weighted average (DIFDWA), weighted geometric (DIFDWG) operators, and uncertain dynamic intuitionistic fuzzy Dombi weighted average (UDIFDWA), weighted geometric (UDIFDWG) operators for interval uncertainty. Next, we have obtained the aggregated data by using these dynamic Dombi operators. Then, we apply two grey relational analysis (IF-GRA and IVIF-GRA) approach on the aggregated matrix to obtain the overall grey relational degree for each option from positive and negative ideal (PIA and NIA) alternative. Then, we evaluate each choice’s relative relational degree from the positive to get the final rank. Finally, we demonstrate the proposed model with a numerical example to compare the proposed model for applicability and validity.},
  archive      = {J_EAAI},
  author       = {Chiranjibe Jana and Madhumangal Pal},
  doi          = {10.1016/j.engappai.2021.104203},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104203},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dynamical hybrid method to design decision making process based on GRA approach for multiple attributes problem},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Colorectal histology tumor detection using ensemble deep
neural network. <em>EAAI</em>, <em>100</em>, 104202. (<a
href="https://doi.org/10.1016/j.engappai.2021.104202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With a mortality rate of approximately 33.33%, Colorectal cancer serves as the second most prevalent malignant tumor type in the world. AI-guided clinical care/tool can help in reducing health disparities, specifically in resource-constrained regions. In this paper, using multi-class tissue features, we proposed an Ensemble Deep Neural Network to Tumor in Colorectal Histology images. On two different publicly available datasets: NCT-CRC-HE-100K (107,180 images) and Colorectal Histology (5000 images), we achieved accuracies of 96.16% and 92.83%, respectively. When datasets are combined, it provided a benchmark accuracy of 99.13%. We efficiently used resourced data, thereby achieving results that outperformed the state-of-the-art works.},
  archive      = {J_EAAI},
  author       = {Sourodip Ghosh and Ahana Bandyopadhyay and Shreya Sahay and Richik Ghosh and Ishita Kundu and K.C. Santosh},
  doi          = {10.1016/j.engappai.2021.104202},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104202},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Colorectal histology tumor detection using ensemble deep neural network},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft rumor control in social networks: Modeling and
analysis. <em>EAAI</em>, <em>100</em>, 104198. (<a
href="https://doi.org/10.1016/j.engappai.2021.104198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, social networks become ubiquitous platforms for sharing and diffusing information around the world. However, spreading rumors as unverified and opaque information in social networks causes harmful damages to societies. An approach for combating rumors in social networks is to use soft control mechanisms i.e. enhancing the people’s knowledge and awareness against the rumor to persuade them avoiding rumor dissemination. In this paper, we propose a soft rumor control model in which people refer to their trusted friends or ask the reputable authorities about the rumor to avoid rumor spreading. The model includes a method for selecting consultants who are both expert in rumor context and responsive to queries about rumors by the user. The battlespace between rumor and anti-rumor spreaders is then modeled as an evolutionary game to analyze the controls’ effectiveness. To evaluate the proposed model, we use Pheme dataset of tweets and conduct simulation analysis. It is shown that trusted consultants suggested by the model with high precision are the same users who send anti-rumor messages in real world. Furthermore, we analyze and compare soft rumor control methods on societies with different assumed cyber literacy and habits. Moreover, it is interestingly shown that using soft rumor control mechanisms in some situations outperforms traditional hard controls (e.g. censorship). Note that as we have used tangible factors in formulating the proposed model, it can help social network developers to build feasible soft rumor control facilities in their own products.},
  archive      = {J_EAAI},
  author       = {Mojgan Askarizadeh and Behrouz Tork Ladani},
  doi          = {10.1016/j.engappai.2021.104198},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104198},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Soft rumor control in social networks: Modeling and analysis},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain knowledge based explainable feature construction
method and its application in ironmaking process. <em>EAAI</em>,
<em>100</em>, 104197. (<a
href="https://doi.org/10.1016/j.engappai.2021.104197">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data driven industrial modeling has been comprehensively studied for its high modeling accuracy. However, the unexplainable characteristic of data-driven modeling hinders workers from understanding the model and controlling process, and further holds back its application in industrial process. In order to solve this problem, we propose a genetic algorithm based method to construct interpretable features for industrial modeling in this paper. This model adopts the framework similar to genetic algorithm, but redefines the populations as features to adapt to the task of feature construction. The populations are evaluated by fitness function with punishment term to ensure the constructed features are concise. By using different genetic mutation and crossover operators, the proposed framework has the ability to combine domain knowledge to handle the characteristics of data, such as nonlinear, dynamic and time lag. The proposed method is experimented on the silicon content prediction task in ironmaking process, which is a classical process industry, achieving high accuracy.},
  archive      = {J_EAAI},
  author       = {Yanrui Li and Chunjie Yang},
  doi          = {10.1016/j.engappai.2021.104197},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104197},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Domain knowledge based explainable feature construction method and its application in ironmaking process},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two efficient nature inspired meta-heuristics solving
blocking hybrid flow shop manufacturing problem. <em>EAAI</em>,
<em>100</em>, 104196. (<a
href="https://doi.org/10.1016/j.engappai.2021.104196">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hybrid flow shop scheduling problem is one of the most relevant optimization problem in manufacturing industry. In this paper, we investigate the blocking hybrid flow shop scheduling problem under the constraint of sequence dependent setup time. The objective is to minimize the total tardiness and earliness with uniform parallel machines under the constraint of sequence dependent setup time. To solve this kind of problems, significant developments of new meta-heuristic algorithms make it possible to implement new metaheuristics inspired by the behavior of living beings or natural phenomena. In this context, we suggest six algorithms based on the migratory bird optimization and the water wave optimization algorithms. We give three new versions for each meta-heuristic in order to solve this optimization problem. The main improvement of the suggested algorithms concerns the exploration phase of the neighborhood system. The enhancement approaches are based on the iterated greedy algorithm, the greedy randomized adaptive search procedure, the path relinking technique and the local search procedures. These modifications in the two nature inspired meta-heuristics make it possible to develop a new neighborhood generation structure constituting hybrid optimization algorithms. A comparative study between the different proposed methods is carried out on a variety of problems ranging from small to relatively large size instances. The simulations show good performances recorded by the water wave optimization algorithm in term of quality and convergence speed towards the best solution.},
  archive      = {J_EAAI},
  author       = {Said Aqil and Karam Allali},
  doi          = {10.1016/j.engappai.2021.104196},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104196},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Two efficient nature inspired meta-heuristics solving blocking hybrid flow shop manufacturing problem},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reduced order model based on machine learning for
numerical analysis: An application to geomechanics. <em>EAAI</em>,
<em>100</em>, 104194. (<a
href="https://doi.org/10.1016/j.engappai.2021.104194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical methods are very important in geotechnical and geological engineering. This study presents a reduced-order numerical model to approximate the displacement and stress field in geotechnical and geological engineering contexts by combining numerical methods, proper orthogonal decomposition (POD), and multi-output support vector machine (MSVM). Snapshots were generated using Latin hypercube sampling. POD was used to compute POD-based vectors and their coefficients. Training samples were constructed from the numerical model and POD coefficients input. The MSVM algorithm was adopted to present the relationship based on these training samples. A reduced-order model was developed by predicting the POD coefficients using MSVM, and the displacement and stress field was then predicted based on the POD vectors and predicted POD coefficients. The proposed method was verified and demonstrated for a circular tunnel. The results show the displacement and stress fields are in excellent agreement with the analytical solution and with the numerical solution, and the predicted deformations are consistent with rock mechanics theory. The proposed method predicts the deformation and mechanical behavior of geomaterials well and may be used to replace numerical models for back analysis, for optimal design, and for uncertainty analysis in geotechnical and geological engineering, all of which involve repeated computation.},
  archive      = {J_EAAI},
  author       = {Hongbo Zhao},
  doi          = {10.1016/j.engappai.2021.104194},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104194},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reduced order model based on machine learning for numerical analysis: An application to geomechanics},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient fractional-order modified harris hawks optimizer
for proton exchange membrane fuel cell modeling. <em>EAAI</em>,
<em>100</em>, 104193. (<a
href="https://doi.org/10.1016/j.engappai.2021.104193">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An effective harmony between the exploration and exploitation phases in meta-heuristics is an essential design consideration to provide reliable performance on a wide range of optimization problems. This paper proposes a novel approach to enhance the exploratory behavior of the Harris hawks optimizer (HHO) based on the fractional calculus (FOC) memory concept. In the proposed variant of the HHO, a hawk moves with a fractional-order velocity, and the rabbit escaping energy is adaptively tuned based on FOC parameters to avoid premature convergence. As a result, the fractional-order modified Harris hawks optimizer (FMHHO) is proposed. The sensitivity of the algorithm performance vis-a-vis the FOC parameters is addressed, and the best variant is recommended based on twenty-three benchmarks. For validating the quality of the proposed variant, twenty-eight benchmarks of CEC2017 are tested. For evaluating the proposed variant against the other present-day techniques, several statistical measures and non-parametric tests are performed. Moreover, to demonstrate the applicability of the proposed technique, the proton exchange membrane fuel cell (PEMFC) model parameters estimation process is handled based on several measured datasets. In this series of experiments, the FMHHO variant is compared with the standard HHO and the other techniques based on intensive statistical metrics, mean convergence curves, and dataset fitting. The overall outcome shows that the FOC memory property improves the performance of the classical HHO and leads to accurate and robust solutions fitting the measured data.},
  archive      = {J_EAAI},
  author       = {Dalia Yousri and Seyedali Mirjalili and J.A. Tenreiro Machado and Sudhakar Babu Thanikanti and Osama elbaksawi and Ahmed Fathy},
  doi          = {10.1016/j.engappai.2021.104193},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104193},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Efficient fractional-order modified harris hawks optimizer for proton exchange membrane fuel cell modeling},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HK–SEIR model of public opinion evolution based on
communication factors. <em>EAAI</em>, <em>100</em>, 104192. (<a
href="https://doi.org/10.1016/j.engappai.2021.104192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microblog, with its good interaction and convenient dissemination, has become the main platform for public opinion dissemination. How to discover the law of public opinion dissemination, and to identify the public opinion accurately have become the hot researches. In this paper, we define the user influence, topic popularity, topic interest to analysis the process of opinions fusion among the users under the interest and confidence threshold. We propose a new public opinion evolution HK–SEIR model which combines the opinion fusion HK and the epidemic transmission SEIR models. Firstly, the topic interest degree is added to the opinion fusion HK model, and the interaction behavior between the users under the interest and confidence threshold is analyzed. Then, we calculate the probability of topic propagation caused by the interaction of opinions between users under group pressure, and the probability that users change from the infected state to the removed state under topic popularity. Finally, we analyze the changes of the susceptible, exposed, infected and removed states in the process of public opinion communication. The experiment proves that the HK–SEIR model is closer to the work-rest rules of public opinion communication than SEIR, SIR model. The density peak time is closer to the peak of real public opinion communication. We find that the user interest is the main factor influencing the public opinion dissemination after the interaction of user opinions fusion reaches a certain degree. The negative public opinion of the higher proportion can easily reach the peak of public opinion propagation.},
  archive      = {J_EAAI},
  author       = {Qing Li and YaJun Du and ZhaoYan Li and JinRong Hu and RuiLin Hu and BingYan Lv and Peng Jia},
  doi          = {10.1016/j.engappai.2021.104192},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104192},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {HK–SEIR model of public opinion evolution based on communication factors},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Underwater target detection based on faster r-CNN and
adversarial occlusion network. <em>EAAI</em>, <em>100</em>, 104190. (<a
href="https://doi.org/10.1016/j.engappai.2021.104190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Underwater target detection is an important part of ocean exploration, which has important applications in military and civil fields. Since the underwater environment is complex and changeable and the sample images that can be obtained are limited, this paper proposes a method to add the adversarial occlusion network (AON) to the standard Faster R-CNN detection algorithm which called Faster R-CNN-AON network. The AON network has a competitive relationship with the Faster R-CNN detection network, which learns how to block a given target and make it difficult for the detecting network to classify the blocked target correctly. Faster R-CNN detection network and the AON network compete and learn together, and ultimately enable the detection network to obtain better robustness for underwater seafood. The joint training of Faster R-CNN and the adversarial network can effectively prevent the detection network from overfitting the generated fixed features. The experimental results in this paper show that compared with the standard Faster R-CNN network, the increase of mAP on VOC07 data set is 2.6%, and the increase of mAP on the underwater data set is 4.2%.},
  archive      = {J_EAAI},
  author       = {Lingcai Zeng and Bing Sun and Daqi Zhu},
  doi          = {10.1016/j.engappai.2021.104190},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104190},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Underwater target detection based on faster R-CNN and adversarial occlusion network},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of the sensitivity of the end-of-turn detection
task to errors generated by the automatic speech recognition process.
<em>EAAI</em>, <em>100</em>, 104189. (<a
href="https://doi.org/10.1016/j.engappai.2021.104189">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An End-Of-Turn Detection Module (EOTD-M) is an essential component of automatic Spoken Dialogue Systems. The capability of correctly detecting whether a user’s utterance has ended or not improves the accuracy in interpreting the meaning of the message and decreases the latency in the answer. Usually, in dialogue systems, an EOTD-M is coupled with an Automatic Speech Recognition Module (ASR-M) to transmit complete utterances to the Natural Language Understanding unit. Mistakes in the ASR-M transcription can have a strong effect on the performance of the EOTD-M. The actual extent of this effect depends on the particular combination of ASR-M transcription errors and the sentence featurization techniques implemented as part of the EOTD-M. In this paper we investigate this important relationship for an EOTD-M based on semantic information and particular characteristics of the speakers (speech profiles). We introduce an Automatic Speech Recognition Simulator (ASR-SIM) that models different types of semantic mistakes in the ASR-M transcription as well as different speech profiles. We use the simulator to evaluate the sensitivity to ASR-M mistakes of a Long Short-Term Memory network classifier trained in EOTD with different featurization techniques. Our experiments reveal the different ways in which the performance of the model is influenced by the ASR-M errors. We corroborate that not only is the ASR-SIM useful to estimate the performance of an EOTD-M in customized noisy scenarios, but it can also be used to generate training datasets with the expected error rates of real working conditions, which leads to better performance.},
  archive      = {J_EAAI},
  author       = {César Montenegro and Roberto Santana and Jose A. Lozano},
  doi          = {10.1016/j.engappai.2021.104189},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104189},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analysis of the sensitivity of the end-of-turn detection task to errors generated by the automatic speech recognition process},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An integrated sustainable medical supply chain network
during COVID-19. <em>EAAI</em>, <em>100</em>, 104188. (<a
href="https://doi.org/10.1016/j.engappai.2021.104188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, in the pharmaceutical industry, a growing concern with sustainability has become a strict consideration during the COVID-19 pandemic. There is a lack of good mathematical models in the field. In this research, a production–distribution–inventory–allocation–location problem in the sustainable medical supply chain network is designed to fill this gap. Also, the distribution of medicines related to COVID-19 patients and the periods of production and delivery of medicine according to the perishability of some medicines are considered. In the model, a multi-objective, multi-level, multi-product, and multi-period problem for a sustainable medical supply chain network is designed. Three hybrid meta-heuristic algorithms, namely, ant colony optimization, fish swarm algorithm, and firefly algorithm are suggested, hybridized with variable neighborhood search to solve the sustainable medical supply chain network model. Response surface method is used to tune the parameters since meta-heuristic algorithms are sensitive to input parameters. Six assessment metrics were used to assess the quality of the obtained Pareto frontier by the meta-heuristic algorithms on the considered problems. A real case study is used and empirical results indicate the superiority of the hybrid fish swarm algorithm with variable neighborhood search.},
  archive      = {J_EAAI},
  author       = {Fariba Goodarzian and Ata Allah Taleizadeh and Peiman Ghasemi and Ajith Abraham},
  doi          = {10.1016/j.engappai.2021.104188},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104188},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An integrated sustainable medical supply chain network during COVID-19},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bi-level encoding scheme for the clustered shortest-path
tree problem in multifactorial optimization. <em>EAAI</em>,
<em>100</em>, 104187. (<a
href="https://doi.org/10.1016/j.engappai.2021.104187">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Clustered Shortest-Path Tree Problem (CluSPT) plays an important role in various types of optimization problems in real-life. Recently, some Multifactorial Evolutionary Algorithms (MFEAs) have been introduced to deal with the CluSPT, but these researches still have some shortcomings, such as evolution operators only perform on complete graphs and huge resource consumption for finding the solution on large search spaces. To overcome these limitations, this paper describes an MFEA-based approach to solve the CluSPT. The proposed algorithm utilizes Dijkstra’s algorithm to construct the spanning trees in clusters while using evolutionary operators for building the spanning tree connecting clusters. This approach takes advantage of both exact and approximate algorithms, so it enables the algorithm to function efficiently on complete and sparse graphs alike. Furthermore, evolutionary operators such as individual encoding and decoding methods are also designed with great consideration regarding performance and memory usage. We have included proof of the repairing method’s efficacy in ensuring all solutions are valid. We have conducted tests on various types of Euclidean instances to assess the effectiveness of the proposed algorithm and methods. Experiment results point out the effectiveness of the proposed algorithm existing heuristic algorithms in most of the test cases. The impact of the proposed MFEA was analyzed, and a possible influential factor that may be useful for further study was also pointed out.},
  archive      = {J_EAAI},
  author       = {Huynh Thi Thanh Binh and Ta Bao Thang and Nguyen Duc Thai and Pham Dinh Thanh},
  doi          = {10.1016/j.engappai.2021.104187},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104187},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A bi-level encoding scheme for the clustered shortest-path tree problem in multifactorial optimization},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Potential-based multiobjective reinforcement learning
approaches to low-impact agents for AI safety. <em>EAAI</em>,
<em>100</em>, 104186. (<a
href="https://doi.org/10.1016/j.engappai.2021.104186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The concept of impact-minimisation has previously been proposed as an approach to addressing the safety concerns that can arise from utility-maximising agents. An impact-minimising agent takes into account the potential impact of its actions on the state of the environment when selecting actions, so as to avoid unacceptable side-effects. This paper proposes and empirically evaluates an implementation of impact-minimisation within the framework of multiobjective reinforcement learning. The key contributions are a novel potential-based approach to specifying a measure of impact, and an examination of a variety of non-linear action-selection operators so as to achieve an acceptable trade-off between achieving the agent’s primary task and minimising environmental impact. These experiments also highlight a previously unreported issue with noisy estimates for multiobjective agents using non-linear action-selection, which has broader implications for the application of multiobjective reinforcement learning.},
  archive      = {J_EAAI},
  author       = {Peter Vamplew and Cameron Foale and Richard Dazeley and Adam Bignold},
  doi          = {10.1016/j.engappai.2021.104186},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104186},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Potential-based multiobjective reinforcement learning approaches to low-impact agents for AI safety},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Arrangement optimization of a novel three dimensional
multiphase flow imaging device employing modified harmony search
algorithm. <em>EAAI</em>, <em>100</em>, 104185. (<a
href="https://doi.org/10.1016/j.engappai.2021.104185">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas–liquid two-phase flow is a typical flow. Its bubble characteristic measurement is of great importance on studying the flow mechanism and guiding the practical fluid mechanical engineering. In this paper, a novel three dimensional (3D) multiphase flow imaging device was designed and optimized to measure the transparent object that has an opaque object in the center of the 3D observed area. Its mathematical model was built and the constraints were defined based on the geometrical relationship and design requirements. Based on the original harmony search (HS) algorithm, a modified harmony search algorithm (MHS-MC) for improving both the performance on the global optima of the multi-modal problems and the convergence performance of the constrained optimization problems was integrated and applied to optimize the arrangement of the single-camera-multi-mirror device. As a case study, the 3D multiphase flow imaging method was applied in the 3D reconstruction of the cavitation bubble cluster inside a water hydraulic valve. The statistics of the Pareto data show the good performance of the MHS-MC algorithm. And the cavitation experimental results testify the effectiveness of the proposed MHS-MC algorithm. The cavitation bubble cluster can be reconstructed with quite high precision.},
  archive      = {J_EAAI},
  author       = {Haihang Wang and He Xu and Xiao-Zhi Gao and Zitong Zhao and Jinwei Huang},
  doi          = {10.1016/j.engappai.2021.104185},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104185},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Arrangement optimization of a novel three dimensional multiphase flow imaging device employing modified harmony search algorithm},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A boundary approach for set inversion. <em>EAAI</em>,
<em>100</em>, 104184. (<a
href="https://doi.org/10.1016/j.engappai.2021.104184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, we present a new interval-based set inversion algorithm which takes into account the continuity of the problem. In the case where the set Y to be inverted has some volume, we show that inverting the boundary ∂ Y of Y is sufficient to reconstruct the preimage X = f − 1 ( Y ) . The inversion of ∂ Y separates the domain of f into two regions : one inside X and one outside. To detect which part is inside or outside, we show that we can retro-propagate the information coming from Y at negligible cost. The efficiency of the approach is illustrated on a localization problem.},
  archive      = {J_EAAI},
  author       = {Luc Jaulin},
  doi          = {10.1016/j.engappai.2021.104184},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104184},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A boundary approach for set inversion},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving multi-objective model of assembly line balancing
considering preventive maintenance scenarios using heuristic and grey
wolf optimizer algorithm. <em>EAAI</em>, <em>100</em>, 104183. (<a
href="https://doi.org/10.1016/j.engappai.2021.104183">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current assembly line balancing studies ignore the preventive maintenance (PM) of machines in some workstations, implying that the already-known PM information has been completely missed. Moreover, PM may bring about a production stoppage for a considerable time. Hence, this paper considers PM scenarios into the assembly line balancing problem to improve the production efficiency and smoothness simultaneously. For this multi-objective problem, a heuristic rule relying on the tacit knowledge is dug up via gene expression programming to obtain an acceptable solution quickly. Then, an enhanced grey wolf optimizer algorithm with two improvements is proposed to achieve Pareto front solutions. Specifically, a variable step-size decoding mechanism accelerates the speed of the algorithm; the specially-designed neighbor operators prevent the algorithm from trapping in local optima. Experiment results demonstrate that the discovered heuristic rule outperforms other existing rules; the joint of improvements endows the proposed meta-heuristic with significant superiority over three variants and other six well-known algorithms. Besides, a real-world case study is conducted to validate the discovered rule and the proposed meta-heuristic.},
  archive      = {J_EAAI},
  author       = {Kai Meng and Qiuhua Tang and Zikai Zhang and Chunlong Yu},
  doi          = {10.1016/j.engappai.2021.104183},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104183},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Solving multi-objective model of assembly line balancing considering preventive maintenance scenarios using heuristic and grey wolf optimizer algorithm},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Keras2c: A library for converting keras neural networks to
real-time compatible c. <em>EAAI</em>, <em>100</em>, 104182. (<a
href="https://doi.org/10.1016/j.engappai.2021.104182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the growth of machine learning models and neural networks in measurement and control systems comes the need to deploy these models in a way that is compatible with existing systems. Existing options for deploying neural networks either introduce very high latency, require expensive and time consuming work to integrate into existing code bases, or only support a very limited subset of model types. We have therefore developed a new method called Keras2c, which is a simple library for converting Keras/TensorFlow neural network models into real-time compatible C code. It supports a wide range of Keras layers and model types including multidimensional convolutions, recurrent layers, multi-input/output models, and shared layers. Keras2c re-implements the core components of Keras/TensorFlow required for predictive forward passes through neural networks in pure C, relying only on standard library functions considered safe for real-time use. The core functionality consists of ∼ 1500 lines of code, making it lightweight and easy to integrate into existing codebases. Keras2c has been successfully tested in experiments and is currently in use on the plasma control system at the DIII-D National Fusion Facility at General Atomics in San Diego.},
  archive      = {J_EAAI},
  author       = {Rory Conlin and Keith Erickson and Joseph Abbate and Egemen Kolemen},
  doi          = {10.1016/j.engappai.2021.104182},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104182},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Keras2c: A library for converting keras neural networks to real-time compatible c},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online learning of neural networks using random projections
and sliding window: A case study of a real industrial process.
<em>EAAI</em>, <em>100</em>, 104181. (<a
href="https://doi.org/10.1016/j.engappai.2021.104181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online Learning of non-stationary data streams is a challenging task. This work presents an online training method for a Single hidden Layer Feedforward neural Network (SLFN) that learns sample-by-sample, using an adjustable sliding window to adapt the network when data has changed. The method presents a fast training procedure, estimating hidden and output layer parameters independently. Tests with four synthetic datasets showed a good accuracy and quick recovery after drift occurrences. The proposed method is also applied to a real dataset from an industrial process in order to address the anomaly detection task, with the network acting as a classifier. Results show that the method is able to detect drifts prior to anomalies in the pre-fault periods, in the real situation that appeared in the industrial dataset.},
  archive      = {J_EAAI},
  author       = {Wagner J. Alvarenga and Felipe V. Campos and Vítor M. Hanriot and Eduardo B. Gonçalves and Alexsander C.A.A. Costa and Lourenço R.G. Araujo and Eduardo Magalhães and Antonio P. Braga},
  doi          = {10.1016/j.engappai.2021.104181},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104181},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Online learning of neural networks using random projections and sliding window: A case study of a real industrial process},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-driven order reduction in hammerstein–wiener models of
plasma dynamics. <em>EAAI</em>, <em>100</em>, 104180. (<a
href="https://doi.org/10.1016/j.engappai.2021.104180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of identifying and therefore modelling a complex system makes use of various techniques and strategies whose computational efforts change drastically. It is not straightforward to analyse the complexity of a system as a whole because of myriads of factors, such as the way of arranging its constituent items and how they interact mutually. Intuitively, the bigger the set of sub-parts is, the more numerous the degrees of freedom are. Additionally there is not a specific and global criterion for optimally determining an always-working method that makes the identification procedure easier, especially in those contexts where the number of unknown variables can make the difference. In this sense, plasma physics is not an exception, being a field where complex phenomena, such as plasma instabilities, easily arise. From a systemic, high-level perspective, the possibility of employing a model that can describe these behaviours is particularly appealing, since it can be exploited for control applications that have not to neglect the underlying physical nature. So far, most of the work published in literature has focused on more physically-grounded models, which could describe how plasma physics works in detail, but very little has been done as mentioned before, with the aim of providing a computational, yet system-oriented, insight of these physical systems. Starting from real flux measurements recorded thanks to suitable sensors installed inside Tokamak machines, the paper attempts to provide a solution based on already known tools available in literature to solve the aforementioned problem, by combining both machine learning-based strategies for dimensionality reduction and control theory. More in detail, the whole architecture presented in this work is founded on the use of auto-encoders, which are intrinsically capable of compressing input features thanks to their structure, and Hammerstein–Wiener models, which are structurally endowed with both linear and non-linear sub-modellers for better capturing the whole dynamics to identify. By merging these functional blocks, it is possible to address both the issue of establishing the most relevant sub-set of variables for identification and the identification problem itself, resulting in a fully customisable approach to data-driven modelling.},
  archive      = {J_EAAI},
  author       = {Angelo Giuseppe Spinosa and Arturo Buscarino and Luigi Fortuna and Matteo Iafrati and Giuseppe Mazzitelli},
  doi          = {10.1016/j.engappai.2021.104180},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104180},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Data-driven order reduction in Hammerstein–Wiener models of plasma dynamics},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Marine dual fuel engines monitoring in the wild through
weakly supervised data analytics. <em>EAAI</em>, <em>100</em>, 104179.
(<a href="https://doi.org/10.1016/j.engappai.2021.104179">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background: Maritime transportation accounts for around 80% of the world freight movements, remarkably contributing to the global environmental footprint. Dual fuel engines, running on both gaseous and liquid fuels, represent a viable way toward the reduction of emissions at the cost of additional complexity in monitoring activities. Motivation: Data-driven methods represent the frontier in research and in maritime industrial applications, and they usually require a large amount of labelled data, i.e., sensor measurements plus the associated engine status usually annotated by human operators, which are costly and seldomly available in the wild. Unlabelled samples, instead, are commonly, cheaply, and readily available. Hypothesis: The enabling technology for data-driven methods is the availability of a network of sensors and an automation system able to capture and store the associated stream of data. Methods: In this paper, we design and propose multiple alternatives toward the weakly supervised marine dual fuel engines data-driven monitoring. To this aim, we will rely on a Digital Twin of the dual fuel engine or on novelty detection algorithms and we will compare them against state-of-the-art fully supervised approaches. Results: Results on data generated from a real-data validated simulator of a marine dual fuel engine demonstrate that the proposed weakly supervised monitoring approaches lead to a negligible loss in accuracy compared to costly and often unfeasible fully supervised ones supporting the validity of the proposal for its application in the wild. Conclusion: The main outcome is a guideline for selecting the best data-driven dual fuel engine monitoring method according to the available data.},
  archive      = {J_EAAI},
  author       = {Andrea Coraddu and Luca Oneto and Davide Ilardi and Sokratis Stoumpos and Gerasimos Theotokatos},
  doi          = {10.1016/j.engappai.2021.104179},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104179},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Marine dual fuel engines monitoring in the wild through weakly supervised data analytics},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emotion space modelling for social robots. <em>EAAI</em>,
<em>100</em>, 104178. (<a
href="https://doi.org/10.1016/j.engappai.2021.104178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the interaction between artificial systems and their users is an important issue in artificial intelligence. In current trends in social robotics, this is accomplished by making such systems not just intelligent but also emotionally sensitive. Therefore, artificial emotional intelligence (AEI) is focused on simulating and extending natural emotion (especially human emotion) to provide robots with the capability to recognise and express emotions in human–robot interaction (HRI). In this treatise, we present an overview of the advances made in AEI by highlighting the progress recorded in the areas of emotion classification, emotional robots, and emotion space modelling in HRI. This review is aimed at providing readers with a succinct, yet adequate compendium of the progresses made in the emerging AEI sub-discipline. It is hoped this effort will stimulate further interest aimed at the pursuit of more advanced algorithms and models for available technologies and possible applications to other domains.},
  archive      = {J_EAAI},
  author       = {Fei Yan and Abdullah M. Iliyasu and Kaoru Hirota},
  doi          = {10.1016/j.engappai.2021.104178},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104178},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Emotion space modelling for social robots},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new dynamic radius SVDD for fault detection of aircraft
engine. <em>EAAI</em>, <em>100</em>, 104177. (<a
href="https://doi.org/10.1016/j.engappai.2021.104177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When using traditional support vector data description (SVDD) to deal with classification problems, low accuracy is often achieved, especially in the case of noise interference. The traditional SVDD adopts a fixed hypersphere radius to set classification boundary, which means that it tends to force all normal samples and outliers to be separated by a fixed radius, which is unreasonable to a certain extent. In order to reduce the impact of this defect, a dynamic radius support vector data description (DR-SVDD) is firstly proposed in this paper, which introduces the idea of angle in the kernel space and flexibly selects the relevant decision radius for each testing sample. Then, the feasibility and effectiveness of the proposed algorithm are verified on several benchmark data sets. Finally, DR-SVDD based fault detection is carried out for a certain turboshaft engine, and the expected results are obtained, which fully demonstrates its effectiveness and robustness.},
  archive      = {J_EAAI},
  author       = {Yong-Ping Zhao and Yun-Long Xie and Zhi-Feng Ye},
  doi          = {10.1016/j.engappai.2021.104177},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104177},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new dynamic radius SVDD for fault detection of aircraft engine},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modified kalman particle swarm optimization: Application for
trim problem of very flexible aircraft. <em>EAAI</em>, <em>100</em>,
104176. (<a
href="https://doi.org/10.1016/j.engappai.2021.104176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Particle swarm optimization (PSO) is one of the most popular stochastic swarm-based metaheuristic algorithms. Kalman filter principle is introduced to predict the global optimum more accurately to enhance convergence. However, the evolution of particles in current Kalman PSO merely depends on the adjustment based on observation. In this paper, a modified Kalman particle swarm optimization (MKPSO) algorithm is proposed. The population is extended with the estimated optimum based on Kalman filtering, in which the prediction model is formulated as the weighted central optimum. Benchmark functions in the CEC14 test suite are adopted to verify the effectiveness of MKPSO. Numerical results show that MKPSO is more effective in mining capability for high-dimensional problems. Besides, the superiority of MKPSO lies in solving hybrid optimization problems. At last, MKPSO is applied to maximize the attainable moments subset of very flexible aircraft (VFA) on account for redundancy of control surfaces. Simulation results reveal that there is a trade-off between flight and control performance for VFA.},
  archive      = {J_EAAI},
  author       = {Hao Lei and Boyi Chen and Yanbin Liu and Yuping Lv},
  doi          = {10.1016/j.engappai.2021.104176},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104176},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Modified kalman particle swarm optimization: Application for trim problem of very flexible aircraft},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reliable KNN filling approach for incomplete
interval-valued data. <em>EAAI</em>, <em>100</em>, 104175. (<a
href="https://doi.org/10.1016/j.engappai.2021.104175">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued data (IVD) is a kind of data where each feature is an interval, and embeds the uncertainty and variability information. However, the missing values (lower or upper bound, or both of them are missed) may occur in the process of data acquisition and transmission, which may lead to obstacles for data processing. To obtain good results, it is important for IVD to process (often ignore or fill) the missing values. A dataset including missing values is named as incomplete interval-valued (IIV) set here. Some ignoring and filling methods for numeric or symbolic data have been proposed, but they cannot be applied for IIV datasets directly. In this work, a reliable k-nearest neighbor approach (RKNN) for incomplete interval-valued data (IIVD) is proposed. A combining rule to determine whether a datum including missing values should be ignored or filled is designed. Those samples with the missing value for each feature will be ignored directly. It is different from existing ignoring methods that need to set the percentage of missing entries. For the rest of missing samples, they will be filled according to their K complete nearest neighbors, which can ensure the filled value more reliable. In so doing, RKNN can exclude a small number of missing samples that may increase uncertainty, and avoid the repetition of the filled values (like median or a fixed constant). The experiment results on 12 synthetic datasets and 4 real-world datasets demonstrate that the proposed method can process the incomplete interval-valued data effectively, and obtain a good classification performance simultaneously.},
  archive      = {J_EAAI},
  author       = {Xiaobo Qi and Husheng Guo and Wenjian Wang},
  doi          = {10.1016/j.engappai.2021.104175},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104175},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A reliable KNN filling approach for incomplete interval-valued data},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Meta-action reliability-based mechanical product
optimization design under uncertainty environment. <em>EAAI</em>,
<em>100</em>, 104174. (<a
href="https://doi.org/10.1016/j.engappai.2021.104174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliability allocation is an important procedure in the early stage of product design. However, there is not a good design scheme for the reliability allocation of mechanical products. Firstly, the reliability allocation of mechanical products is still at the system level or component level, which makes it impossible to obtain more detailed reliability input parameters. Secondly, to simplify the allocation process, the interactions among allocation objects are usually ignored, which makes the result of reliability allocation not optimistic. Thirdly, the uncertainty of reliability-based mechanical product optimization has not been dealt with effectively. Therefore, this paper proposes a multi-criteria decision-making (MCDM) for mechanical product optimization design based on meta-action reliability, which integrates decision-making trial and evaluation laboratory (DEMATEL), uncertain linguistic ordered weighted averaging (ULOWA) operator, and preference ranking organization method for enrichment evaluations (PROMETHEE) II method. Also, the interval number is used to deal with the uncertainty flexibly in the decision-making process. Finally, the application and feasibility of the proposed method are illustrated with the automatic pallet changer (APC) of a CNC machine tool as an example. This method provides guidance for the reliability optimization design of mechanical products.},
  archive      = {J_EAAI},
  author       = {Yifan Chen and Yan Ran and Zhichao Wang and Xinlong Li and Xin Yang and Genbao Zhang},
  doi          = {10.1016/j.engappai.2021.104174},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104174},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Meta-action reliability-based mechanical product optimization design under uncertainty environment},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel grey prediction evolution algorithm for multimodal
multiobjective optimization. <em>EAAI</em>, <em>100</em>, 104173. (<a
href="https://doi.org/10.1016/j.engappai.2021.104173">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications, solving multimodal multiobjective optimization problems (MMOPs), which have multiple Pareto optimal sets (PSs) in the decision space mapping to the same Pareto front (PF) in the objective space, has great significance for decision makers. The issue of how to maintain diversity in both decision space and objective space remains a key problem for existing multimodal multiobjective evolutionary algorithms. To address this issue, a novel grey prediction evolution algorithm for multimodal multiobjective optimization, termed MMGPE, is proposed in this paper. This is the first time that the grey prediction evolution algorithm (GPE), which is a recently proposed competitive optimization algorithm with strong exploration capability, is improved for MMOPs. These improvements are conducted in the following four aspects: (1) an initialization operator based on particle swarm optimization, (2) an adaptive parameter setting strategy depending on the domain of decision variables of MMOPs, (3) an accelerating convergence mechanism inspired by the niche principle, and (4) an environmental selection operator based on a nondominated sorting mechanism and a special crowding distance approach. The performance of MMGPE is compared with two state-of-the-art multiobjective evolutionary algorithms and four multimodal multiobjective evolutionary algorithms on 11 multimodal multiobjective test functions. MMGPE is also applied to solve a practical problem. The results show the MMGPE’s effectiveness and superiority in achieving the goal of finding multiple PSs while obtaining a well-distributed PF.},
  archive      = {J_EAAI},
  author       = {Ting Zhou and Zhongbo Hu and Quan Zhou and Shixiong Yuan},
  doi          = {10.1016/j.engappai.2021.104173},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104173},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel grey prediction evolution algorithm for multimodal multiobjective optimization},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Counting trees with point-wise supervised segmentation
network. <em>EAAI</em>, <em>100</em>, 104172. (<a
href="https://doi.org/10.1016/j.engappai.2021.104172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree counting plays an important role in wide applications of environmental protection, agricultural planning and crop yield estimation. However, traditional tree counting methods require expensive feature engineering, which causes additional mistake and cannot be optimized overall. Recently, deep learning based approaches have been adopted for this task which demonstrate state-of-the-art performance. In this paper, a point-wise supervised segmentation network is proposed based on a deep segmentation network with only weak supervision, which can complete localization and generate mask of each tree simultaneously. In the first step, a tree feature extractor module is adopted to extract features of input images with a novel encoder–decoder network. In the second step, an effective strategy is designed to deal with different conditions with mask predictions. Finally, the basic localization and rectification guidance are introduced to train the whole network. In addition, two different datasets are created and an existing challenging plant dataset is selected to evaluate the proposed method. Experimental results on those datasets show that the proposed method outperforms the state-of-the-art methods in most challenging conditions. This method has great potential to reduce human labor due to effective automatic generated masks.},
  archive      = {J_EAAI},
  author       = {Pinmo Tong and Pengcheng Han and Suicheng Li and Ni Li and Shuhui Bu and Qing Li and Ke Li},
  doi          = {10.1016/j.engappai.2021.104172},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104172},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Counting trees with point-wise supervised segmentation network},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coral reefs optimization algorithms for agent-based model
calibration. <em>EAAI</em>, <em>100</em>, 104170. (<a
href="https://doi.org/10.1016/j.engappai.2021.104170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Calibrating agent-based models involves estimating multiple parameter values. This can be performed automatically using automatic calibration but its success depends on the optimization method’s ability for exploring the parameter search space. This paper proposes to carry out this process using coral reefs optimization algorithms, a new branch of competitive bio-inspired metaheuristics that, beyond its novel metaphor, has shown its good behavior in other optimization problems. The performance of these metaheuristics for model calibration is evaluated by conducting an exhaustive experimentation against well-established and recent evolutionary algorithms, including their hybridization with local search procedures. The study analyzes the calibration accuracy of the metaheuristics using an integer coding scheme over a benchmark of 12 problem instances of an agent-based model with an increasing number of decision variables. The outstanding performance of the memetic coral reefs optimization is reported after performing statistical tests to the results.},
  archive      = {J_EAAI},
  author       = {Ignacio Moya and Enrique Bermejo and Manuel Chica and Óscar Cordón},
  doi          = {10.1016/j.engappai.2021.104170},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104170},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Coral reefs optimization algorithms for agent-based model calibration},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dual linguistic scale-based digitization and exploitation
method for scrap steel remanufacturing process selection. <em>EAAI</em>,
<em>100</em>, 104169. (<a
href="https://doi.org/10.1016/j.engappai.2021.104169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Language is a preferred way for evaluators to express their opinions. As an important part of qualitative decision making, computing with words mainly focuses on transferring linguistic information to numerical values for operations. A significant challenge is how to model the meaning of linguistic information given by evaluators. This study aims to explore the principle of an evaluator to judge alternatives over different kinds of criteria and establish linguistic scale functions to simulate the personalized semantics of linguistic terms. In addition a dual linguistic scale in the form of linguistic terms and numerical meanings is developed to represent decision information. We then develop a method called the dual linguistic scale-based digitization and exploitation method to deduce the ranking of alternatives for multiple criteria decision-making problems, which considers the personalized cognition of evaluators and the personalized requirements of decision-makers for the trade-offs between criteria A case study concerning the scrap steel remanufacturing is conducted to demonstrate the validity of the proposed method. The results demonstrate that linguistic computational models have an influence on the ranking results of alternatives.},
  archive      = {J_EAAI},
  author       = {Xingli Wu and Huchang Liao},
  doi          = {10.1016/j.engappai.2021.104169},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104169},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A dual linguistic scale-based digitization and exploitation method for scrap steel remanufacturing process selection},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast just-in-time-learning recursive multi-output LSSVR for
quality prediction and control of multivariable dynamic systems.
<em>EAAI</em>, <em>100</em>, 104168. (<a
href="https://doi.org/10.1016/j.engappai.2021.104168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at quality prediction and control of blast furnace (BF) ironmaking process characterized by complicated nonlinear time-varying dynamics, this paper proposes a just-in-time-learning (JITL) recursive multi-output least squares support vector regression (JITL-R-M-LSSVR) algorithm with fast nonlinear local learning capability for multivariable dynamic systems. The proposed fast JITL-R-M-LSSVR effectively combines the online local learning of JITL with the multi-output LSSVR (M-LSSVR) based on multi-task transfer learning, and focuses on how to ensure the rapid verification of the local model during online learning of M-LSSVR, and how to perform model pruning while recursively updating the model parameters to improve the calculation efficiency. To this end, the proposed algorithm uses a derived multi-output incremental learning algorithm to recursively update model parameters online in a gentle way, which has better modeling stability and smoothness than the traditional way that discards old models. At the same time, when the model is pruned, a novel multi-output reverse decremental learning algorithm is proposed to adaptively delete the modeling data, so as to effectively control the sample size and reduces the calculation cost. In particular, the model verification of the proposed algorithm only needs to construct the M-LSSVR modeling matrix and the matrix inverse operation once, and the matrix after deleting each modeling sample can be easily obtained by reverse decremental learning of the original modeling matrix, which can achieve fast and efficient model verification. Finally, the effectiveness and practicability of the proposed method are verified by applying it to prediction modeling and predictive control of the molten iron quality in BF ironmaking process.},
  archive      = {J_EAAI},
  author       = {Ping Zhou and Weiqi Chen and Chengming Yi and Zhaohui Jiang and Tao Yang and Tianyou Chai},
  doi          = {10.1016/j.engappai.2021.104168},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104168},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fast just-in-time-learning recursive multi-output LSSVR for quality prediction and control of multivariable dynamic systems},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Q-rung orthopair fuzzy weighted induced logarithmic distance
measures and their application in multiple attribute decision making.
<em>EAAI</em>, <em>100</em>, 104167. (<a
href="https://doi.org/10.1016/j.engappai.2021.104167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a more flexible and practical approach than the Pythagorean fuzzy set and intuitionistic fuzzy set, the q-rung orthopair fuzzy set (q-ROFS) has been widely used to express vagueness and uncertainty. In this paper, a method based on a weighted induced logarithmic distance is presented to help address multiple attribute decision making (MADM) with q-ROFS information. A new induced weighted logarithmic distance measure is first proposed to remedy the shortcomings of existing methods. Some outstanding properties have also been examined in detail. Considering the superiority of q-ROFS in modeling uncertainties, the improved induced weighted logarithmic distance measure is then extended to q-ROFS, thereby obtaining two new q-ROFS distance measures. Moreover, based on the developed q-ROFS distance measures, a new method for handling MADM problems under q-ROFS environment is presented, wherein information concerning the attribute weights is completely unknown. Finally, a numerical example concerning smart phone selection is presented to demonstrate the validity and superiority of the proposed method.},
  archive      = {J_EAAI},
  author       = {Shouzhen Zeng and Yingjie Hu and Xiaoying Xie},
  doi          = {10.1016/j.engappai.2021.104167},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104167},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Q-rung orthopair fuzzy weighted induced logarithmic distance measures and their application in multiple attribute decision making},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reachable set bounding of output-feedback control for
discrete-time large-scale IT-2 fuzzy descriptor systems using
distributed event-based broadcasts. <em>EAAI</em>, <em>100</em>, 104166.
(<a href="https://doi.org/10.1016/j.engappai.2021.104166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the distributed event-based broadcasting of output-feedback control for discrete-time large-scale fuzzy descriptor systems subject to reachable set bounding. First, each nonlinear subsystem is represented by the interval type-2 fuzzy model, where fuzzy representation is assumed to be appearing not only in both the state and input matrices but also in the derivative matrix. By using a descriptor redundancy approach, the fuzzy representation in the derivative matrix is reformulated into the linear one. Then, we introduce an output-feedback fuzzy controller with distributed event-based broadcasting, where all subsystems communicate with each other via a distributed network, and each subsystem broadcasts its decision-making of transmission based on a prescribed event. Two event-based mechanisms (EBMs) are respectively proposed to examine when the system output and fuzzy premise variable should be transmitted to the controller. Moreover, by further employing a descriptor redundancy representation, combined with reachable set analysis method, it will be shown that the proposed fuzzy controller guarantees that the estimation error is bounded within the ellipsoidal boundary while communication data are transmitted to the controller as little as possible, and sufficient condition for designing the desired controller is derived in terms of linear matrix inequalities (LMIs). Finally, a simulation study is given to show the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Xingyi Wang and Zhixiong Zhong and Hak-Keung Lam and Zuoyong Li},
  doi          = {10.1016/j.engappai.2021.104166},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104166},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reachable set bounding of output-feedback control for discrete-time large-scale IT-2 fuzzy descriptor systems using distributed event-based broadcasts},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning scalable multi-agent coordination by spatial
differentiation for traffic signal control. <em>EAAI</em>, <em>100</em>,
104165. (<a
href="https://doi.org/10.1016/j.engappai.2021.104165">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent control of the traffic signal is critical to the optimization of transportation systems. To achieve global optimal traffic efficiency in large-scale road networks, recent works have focused on coordination among intersections, which have shown promising results. However, existing studies paid more attention to observations sharing among intersections (both explicit and implicit) and did not care about the consequences after decisions. In this paper, we design a multi-agent coordination framework based on Deep Reinforcement Learning method for traffic signal control, defined as γ - Reward that includes both original γ - Reward and γ - Attention-Reward . Specifically, we propose the Spatial Differentiation method for coordination which uses the temporal–spatial information in the replay buffer to amend the reward of each action. A concise theoretical analysis that proves the proposed model can converge to Nash equilibrium is given. By extending the idea of Markov Chain to the dimension of space–time, this truly decentralized coordination mechanism replaces the graph attention method and realizes the decoupling of the road network, which is more scalable and more in line with practice. The simulation results show that the proposed model remains a state-of-the-art performance even not use a centralized setting. Code is available in https://github.com/Skylark0924/Gamma_Reward .},
  archive      = {J_EAAI},
  author       = {Junjia Liu and Huimin Zhang and Zhuang Fu and Yao Wang},
  doi          = {10.1016/j.engappai.2021.104165},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104165},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning scalable multi-agent coordination by spatial differentiation for traffic signal control},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PSO-based sink placement and load-balanced anycast routing
in multi-sink WSNs considering compressive sensing theory.
<em>EAAI</em>, <em>100</em>, 104164. (<a
href="https://doi.org/10.1016/j.engappai.2021.104164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the sink placement and anycast routing to increase the lifetime of multi-sink wireless sensor networks. Two algorithms are proposed, namely “Multi-sink Placement and Anycast Routing (MPAR)” and “Extended Multi-sink Placement and Anycast Routing (EMPAR)”, to jointly address the problems of clustering, multi-sink placement, and load-balanced anycast routing. MPAR and EMPAR rely on a two-level architecture in which sensors are clustered at the lower level. Each sensor transmits its data to the corresponding Cluster Head (CH) via a load-balanced data aggregation routing tree. At the upper level, both schemes use a modified particle swarm optimization algorithm to determine the best location of sinks. For each sink, a high-level anycast routing tree is developed using the ant colony optimization algorithm. Each anycast tree uses the hybrid Compressive Sensing (CS) method to forward the aggregated data from CHs to sinks. Extensive simulations are conducted to illustrate the efficiency of the proposed algorithms in terms of energy consumption, energy consumption variance, and network lifetime. The results show that EMPAR has a better performance than MPAR due to its CH selection strategy. As an advantage, EMPAR considers both remaining energy and distance criteria along with a rest factor to select the best CH for each cluster. For an average number of clusters, EMPAR reduces the energy consumption by 5.98% and 12.20%, respectively, compared to the MPAR algorithm and the energy-aware CS-based data aggregation algorithm. It also increases the network lifetime in comparison with the aforementioned algorithms by 12.26% and 30.38%, respectively.},
  archive      = {J_EAAI},
  author       = {Anis Jari and Avid Avokh},
  doi          = {10.1016/j.engappai.2021.104164},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104164},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {PSO-based sink placement and load-balanced anycast routing in multi-sink WSNs considering compressive sensing theory},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). General type-2 fuzzy multi-switching synchronization of
fractional-order chaotic systems. <em>EAAI</em>, <em>100</em>, 104163.
(<a href="https://doi.org/10.1016/j.engappai.2021.104163">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the problem of multi-switching synchronization of the chaotic systems (CSs) with fractional-order dynamics is considered. Unlike to the most studies, the dynamics of slave chaotic systems are unknown and also the master systems are not fixed but are switched between several synchronization modes. A general type-2 (GT2) fuzzy neural network (FNN) is proposed to approximate the unknown nonlinearities. The stability and robustness is investigated by the Lyapunov theorem and the fractional-order adaptation laws are obtained to optimize the rules of GT2FNNs. The robustness of the proposed scheme against approximation errors and variation of synchronization modes is guaranteed by the proposed compensators. The good performance of schemed method is demonstrated by several simulations and comparison with recent presented control techniques.},
  archive      = {J_EAAI},
  author       = {Mohammad Hosein Sabzalian and Ardashir Mohammadzadeh and Weidong Zhang and Kittisak Jermsittiparsert},
  doi          = {10.1016/j.engappai.2021.104163},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104163},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {General type-2 fuzzy multi-switching synchronization of fractional-order chaotic systems},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved manta ray foraging optimizer for cost-effective
emission dispatch problems. <em>EAAI</em>, <em>100</em>, 104155. (<a
href="https://doi.org/10.1016/j.engappai.2021.104155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Manta ray foraging optimization (MRFO) has been developed and applied for solving few engineering optimization problems. In this paper, an elegant approach based on MRFO integrated with Gradient-Based Optimizer (GBO), named MRFO–GBO, is proposed to efficiently solve the economic emission dispatch (EED) problems. The proposed MRFO–GBO aims to reduce the probability of original MRFO to get trapped into local optima as well as accelerate the solution process. The goal of solving optimal Economic Emission Dispatch (EED) is to economically provide all required electrical loads as well as minimizing the emission with satisfying the operating equality and inequality constraints. Single and multi-objective EED problems are solved using the proposed MRFO–GBO and classical MRFO. In multi-objective EED, fuzzy set theory is adapted to determine the best compromise solution among Pareto optimal solutions. The proposed algorithm is firstly validated through well-known CEC’17 test functions, and then applied for solving several scenarios of EED problems for three electrical systems with 3-generators, 5-generators, and 6-generators. The validation is achieved through different load levels of the tested systems to prove the robustness of the proposed algorithm. The results obtained by the proposed MRFO–GBO are compared with those obtained by recently published optimization techniques as well as the original MRFO and GBO. The results illustrate the ability of the proposed MRFO–GBO in effectively solving the single and multi-objective EED problems in terms of precision, robustness, and convergence characteristics.},
  archive      = {J_EAAI},
  author       = {Mohamed H. Hassan and Essam H. Houssein and Mohamed A. Mahdy and Salah Kamel},
  doi          = {10.1016/j.engappai.2021.104155},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104155},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {An improved manta ray foraging optimizer for cost-effective emission dispatch problems},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new interval type-2 fuzzy logic system under dynamic
environment: Application to financial investment. <em>EAAI</em>,
<em>100</em>, 104154. (<a
href="https://doi.org/10.1016/j.engappai.2021.104154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new interval type-2 fuzzy logic system (IT2 FLS) for financial investment with time-varying parameters adaptive to real-time data streams by using an on-line learning method based on a state-space framework. Particularly, our state-space approach regards the parameters of IT2 FLSs as state variables to sequentially learn by Bayesian filtering algorithms under dynamic environments, where time-series data are continuously observed with occasional structural changes. Moreover, our proposal is effective for financial investment, which often involves various practical complex constraints, because general state-space model makes it possible to flexibly deal with non-linearities. In our empirical experiment with time-series data of global financial assets, our approach is applied to on-line parameter learning of type-1 and type-2 FLSs for portfolio decision making. As a result, it is shown that the IT2 FLS holds its advantage against the type-1 FLS, even though both of the type-1 and type-2 models have the adaptive time-varying parameters, which is an unexplored topic for empirical studies of this area.},
  archive      = {J_EAAI},
  author       = {Akihiko Takahashi and Soichiro Takahashi},
  doi          = {10.1016/j.engappai.2021.104154},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104154},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new interval type-2 fuzzy logic system under dynamic environment: Application to financial investment},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised concrete feature selection based on mutual
information for diagnosing faults and cyber-attacks in power systems.
<em>EAAI</em>, <em>100</em>, 104150. (<a
href="https://doi.org/10.1016/j.engappai.2020.104150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Removing the redundant features from massive data collected from power systems is of paramount importance in improving the efficiency of data-driven diagnostic systems. This work proposes a novel concrete feature selection based on mutual information, called CFMI, for selecting proper features to enhance diagnosing faults and cyber-attacks in power systems. The proposed technique is then compared with various state-of-the-art techniques and a comprehensive study has been performed on the selected features. All techniques are evaluated with respect to simulated scenarios on IEEE 39-bus system and a Three-Bus Two-Line experimental setup. The attained results, on one hand, verify the superiority of the proposed CFMI technique over other techniques. On the other hand, the selected features from both setups denote that current and voltage features are more informative than other features for diagnostic systems. Furthermore, the results of the comprehensive study shows that those features collected from generation buses are of higher priority for diagnostic systems.},
  archive      = {J_EAAI},
  author       = {Hossein Hassani and Ehsan Hallaji and Roozbeh Razavi-Far and Mehrdad Saif},
  doi          = {10.1016/j.engappai.2020.104150},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104150},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised concrete feature selection based on mutual information for diagnosing faults and cyber-attacks in power systems},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forecasting the sales and stock of electric vehicles using a
novel self-adaptive optimized grey model. <em>EAAI</em>, <em>100</em>,
104148. (<a
href="https://doi.org/10.1016/j.engappai.2020.104148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To alleviate the threatening pressure of energy shortage and environmental issues, the adoption of electric vehicles (EVs) is regarded as an effective measure. Therefore, accurate predictions of EVs sales and stock are crucial to deploying charging infrastructures, improving industrial policies, and providing credible references of the renewable sources demand in the transportation system. To this end, a new self-adaptive optimized grey model is proposed with the following improvements: first, a dynamic weighted sequence is generated to extract more value from the available observations by sufficiently highlighting the new data without information lapses. Second, the weighted coefficient and modified initial condition can adjust to various samples and thus augment the applicability of the proposed model. Third, Simpson’s formula is utilized to reconstruct the background value and then integrated with the modified initial condition to smooth the data saltations and further enhance the forecasting precision. To validate the rationality and efficacy of the novel model, four cases regarding the sales and stock of EVs are simulated by the proposed model compared with six benchmarks. As demonstrated in the empirical results, the novel model performs with the highest forecasting precision in most cases, which reveals that the optimization techniques exerted on the initial condition and background value can strikingly enhance the adaptability and prediction accuracy of the grey model. Thus, the novel model can be regarded as a promising tool for EVs prediction.},
  archive      = {J_EAAI},
  author       = {Song Ding and Ruojin Li},
  doi          = {10.1016/j.engappai.2020.104148},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104148},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Forecasting the sales and stock of electric vehicles using a novel self-adaptive optimized grey model},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalability achievements for enumerative biclustering with
online partitioning: Case studies involving mixed-attribute datasets.
<em>EAAI</em>, <em>100</em>, 104147. (<a
href="https://doi.org/10.1016/j.engappai.2020.104147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biclustering is a powerful data analysis technique and its concept is appealing in many domains, such as natural sciences and market basket analysis. To exemplify the wide range of biclustering applications, we can also mention recommender systems, educational data mining, emerging topic detection and counterfeit product detection. In this paper, we further extend RIn-Close_CVC, a biclustering algorithm capable of performing, in numerical datasets, an efficient, complete, correct and non-redundant enumeration of maximal biclusters with constant values on columns. By avoiding a priori partitioning and itemization of the dataset, RIn-Close_CVC implements an online partitioning, which is demonstrated here to guide to more informative biclustering results. The improved algorithm, called RIn-Close_CVC3, is characterized by: a drastic reduction in memory usage; a consistent gain in runtime; additional ability to handle datasets with missing values; and new skills to operate with attributes characterized by distinct distributions or even mixed data types. Moreover, RIn-Close_CVC3 keeps those four attractive properties of RIn-Close_CVC, as formally proved here. The experimental results include synthetic and real-world datasets used to perform scalability and sensitivity analyses, besides a comparative inquiry involving a priori and online partitioning. As a practical case study, a parsimonious set of relevant and interpretable mixed-attribute-type rules is obtained in the context of supervised descriptive pattern mining.},
  archive      = {J_EAAI},
  author       = {Rosana Veroneze and Fernando J. Von Zuben},
  doi          = {10.1016/j.engappai.2020.104147},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {4},
  pages        = {104147},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Scalability achievements for enumerative biclustering with online partitioning: Case studies involving mixed-attribute datasets},
  volume       = {100},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The barzilai–borwein method for distributed optimization
over unbalanced directed networks. <em>EAAI</em>, <em>99</em>, 104151.
(<a href="https://doi.org/10.1016/j.engappai.2020.104151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies optimization problems over multi-agent systems, in which all agents cooperatively minimize a global objective function expressed as a sum of local cost functions. Each agent in the systems uses only local computation and communication in the overall process without leaking their private information. Based on the Barzilai–Borwein (BB) method and multi-consensus inner loops, a distributed algorithm with the availability of larger step-sizes and accelerated convergence, named as ADBB, is proposed. Moreover, owing to the employment of only row-stochastic weight matrices, ADBB can resolve the optimization problems over unbalanced directed networks without requiring the knowledge of neighbors’ out-degree for each agent. Via establishing contraction relationships between the consensus error, the optimality gap, and the gradient tracking error, ADBB is theoretically proved to converge linearly to the global optimal solution. A real-world data set is used in simulations to validate the correctness of the theoretical analysis.},
  archive      = {J_EAAI},
  author       = {Jinhui Hu and Xin Chen and Lifeng Zheng and Ling Zhang and Huaqing Li},
  doi          = {10.1016/j.engappai.2020.104151},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104151},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {The Barzilai–Borwein method for distributed optimization over unbalanced directed networks},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint pairwise graph embedded sparse deep belief network for
fault diagnosis. <em>EAAI</em>, <em>99</em>, 104149. (<a
href="https://doi.org/10.1016/j.engappai.2020.104149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An enhanced intelligent diagnosis method is proposed based on a joint pairwise graph embedded sparse deep belief network with partial least square fine-tuning (J-PDBN). In this novel framework, the joint pairwise graph embedded sparse deep belief network (DBN) is considered as an unsupervised learning method to realize fast parameters initialization and to extract data features. It combines the advantages of both the pairwise graph and sparse representation, which can preserve the manifold structure of the original data and generate discriminant features. The partial least square (PLS) is used to optimize the parameters to eliminate the gradient diffusion in the supervised learning process. The J-PDBN-based fault diagnosis is implemented by both the unsupervised learning method and PLS fine-tuning, which contributes to better classification capabilities. Finally, gearbox and bearing fault diagnosis experiments are conducted. The results show that the total recognition rates of the proposed method are 93.65% in the gearbox case and 95.96% in the bearing case, which are higher than those of other methods. Specifically, the testing accuracy is approximately 10% higher than those of the DBN network for both cases. This validates the effectiveness and superiority of the proposed method.},
  archive      = {J_EAAI},
  author       = {Jie Yang and Weimin Bao and Yanming Liu and Xiaoping Li and Junjie Wang and Yue Niu and Jin Li},
  doi          = {10.1016/j.engappai.2020.104149},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104149},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Joint pairwise graph embedded sparse deep belief network for fault diagnosis},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view low-rank preserving embedding: A novel method for
multi-view representation. <em>EAAI</em>, <em>99</em>, 104140. (<a
href="https://doi.org/10.1016/j.engappai.2020.104140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, we have witnessed a surge of interest in multi-view representation learning. When facing multiple views that are highly related but sightly different from each other, most existing multi-view methods might fail to fully explore multi-view information. Additionally, pairwise correlations among multiple views often vary drastically, which makes multi-view representation challenging. Therefore, how to learn appropriate representation from multi-view information is still an open but challenging problem. To handle this issue, this paper proposes a novel multi-view learning method, named Multi-view Low-rank Preserving Embedding (MvLPE). It integrates all views into a common latent space, termed as centroid view, by minimizing the disagreement between centroid view and each view, which encourages different views to mutually learn from each other. Unlike existing methods with explicit weight definition, the proposed method could automatically allocate an ideal weight for each view according to its contribution. Besides, MvLPE could maintain its low-rank reconstruction structure for each view while integrating all views into centroid view. Since there is no closed-form solution for MvLPE, an effective algorithm based on iterative alternating strategy is provided to obtain the solution. The experiments on six benchmark datasets validate the effectiveness of the proposed method, which achieves superior performance over its counterparts.},
  archive      = {J_EAAI},
  author       = {Xiangzhu Meng and Lin Feng and Huibing Wang},
  doi          = {10.1016/j.engappai.2020.104140},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104140},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-view low-rank preserving embedding: A novel method for multi-view representation},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Process monitoring of batch process based on overcomplete
broad learning network. <em>EAAI</em>, <em>99</em>, 104139. (<a
href="https://doi.org/10.1016/j.engappai.2020.104139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Process monitoring is a common strategy for monitoring the industrial production operation state. It can detect abnormal conditions in industrial processes and provide certain guidance for production. Many classical data-driven process monitoring approaches neglect the non-Gaussian and nonlinearity of the data. For solving the above problems, this paper designs an overcomplete broad learning system (OBLS) with incremental learning ability. The method combines multiple fault data into one data matrix. Then the overcomplete approach is employed to capture the non-Gaussian information from the original data to obtain a mixed matrix. Next, the weights of the OBLS network are trained according to the extracted feature matrix containing non-Gaussian information and its corresponding fault label. Meanwhile, the nonlinearity of the data is addressed by the OBLS network. Finally, the incremental learning capabilities of the OBLS network enable it to be updated quickly when new fault samples are added to the training set without entire retraining process. The experimental results in numerical examples, penicillin fermentation simulation platform and real-world industrial process demonstrate the superiority and feasibility of the OBLS model.},
  archive      = {J_EAAI},
  author       = {Chang Peng and Lu RuiWei},
  doi          = {10.1016/j.engappai.2020.104139},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104139},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Process monitoring of batch process based on overcomplete broad learning network},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Load balancing and neural dynamic model to optimize
replicator dynamics controllers for vibration reduction of highway
bridge structures. <em>EAAI</em>, <em>99</em>, 104138. (<a
href="https://doi.org/10.1016/j.engappai.2020.104138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Earthquakes cause irreparable damages to the built environment, which has led bridge engineers to develop structural control systems to mitigate damage and improve vibration reduction in real-time. Among control systems, base isolation is one of the most commonly used passive control strategies for seismic protection of civil structures. Yet, it lacks real-time adaptability, has lower energy dissipation, and poor performance during near-fault earthquakes. To overcome these limitations, a hybrid control system comprised of semi-active magneto-rheological (MR) dampers and passive base isolation bearings is installed at the deck and piers for vibration reduction of highway bridge structures. This paper, inspired by evolutionary game theory and artificial intelligence, proposes data-driven replicator dynamic control algorithms to distribute the command voltage to the current driver of the semi-active MR dampers. It incorporates a load balancing strategy to reallocate additional resources. To achieve a high-performance design of the game-theory-inspired controllers, a patented neural dynamic model is used to optimize the control parameters. The evaluation of the proposed methodology uses a benchmark control problem based on the 91/5 highway bridge in Southern California subjected to near-field earthquake accelerograms. The performance of five different proposed controllers is compared with conventional Lyapunov and fuzzy logic control algorithms using 21 performance criteria. Results show the load balancing capability of the proposed control algorithms to mitigate the vibrations experienced by the bridge structure and further increase the durability of semi-active devices. The novelty of the methodology impacts how game-theory controllers make control decisions among multiple devices in engineering problems.},
  archive      = {J_EAAI},
  author       = {Sajad Javadinasab Hormozabad and Mariantonieta Gutierrez Soto},
  doi          = {10.1016/j.engappai.2020.104138},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104138},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Load balancing and neural dynamic model to optimize replicator dynamics controllers for vibration reduction of highway bridge structures},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep machine learning algorithm for construction of the
kolmogorov–arnold representation. <em>EAAI</em>, <em>99</em>, 104137.
(<a href="https://doi.org/10.1016/j.engappai.2020.104137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Kolmogorov–Arnold representation is a proven adequate replacement of a continuous multivariate function by a hierarchical structure of multiple functions of one variable. The proven existence of such representation inspired many researchers to search for a practical way of its construction, since such model answers the needs of machine learning. This article shows that the Kolmogorov–Arnold representation is not only a composition of functions but also a particular case of a tree of the discrete Urysohn operators. The article introduces new, quick and computationally stable algorithm for constructing of such Urysohn trees. Besides continuous multivariate functions, the suggested algorithm covers the cases with quantised inputs and combination of quantised and continuous inputs. The article also contains multiple results of testing of the suggested algorithm on publicly available datasets, used also by other researchers for benchmarking.},
  archive      = {J_EAAI},
  author       = {A. Polar and M. Poluektov},
  doi          = {10.1016/j.engappai.2020.104137},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104137},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep machine learning algorithm for construction of the Kolmogorov–Arnold representation},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel probabilistic intuitionistic fuzzy set based model
for high order fuzzy time series forecasting. <em>EAAI</em>,
<em>99</em>, 104136. (<a
href="https://doi.org/10.1016/j.engappai.2020.104136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present research proposes a novel probabilistic intuitionistic fuzzy time series forecasting (PIFTSF) model using support vector machine (SVM) to address both uncertainty and non-determinism associated with real world time series data. In this model, the probability of membership values of crisp observation is determined to handle the statistical uncertainty. At the same time, the intuitionistic fuzzy element of crisp observation is determined to handle the non-statistical uncertainty along with non-determinism. Then, both the membership values are aggregated to obtain the probabilistic intuitionistic fuzzy element which handles both statistical and non-statistical uncertainty along with non-determinism due to hesitancy. Additionally, a novel trend-based discretization (TBD) method is proposed to determine the universe of discourse and number of intervals (NOIs) of fuzzy time series (FTS). For the first time, the fuzzy logical relationships (FLRs) are established for the probabilistic intuitionistic fuzzy set by considering the ratio trend variation (RTV) of crisp observation along with the mean of aggregated membership values which is modelled using SVM. The efficiency of the proposed PIFTSF model is demonstrated with sixteen diversified time series datasets and seven existing FTS models. A sensitivity analysis is carried out with respect to different design strategies to ensure the robustness of the proposed model. Extensive statistical analyses on obtained results confirm the superiority of the proposed model over other existing models. Further, Wilcoxon signed rank test, and Friedman and Nemenyi hypothesis test ensures the accuracy, robustness and reliability of the proposed model against its counterparts.},
  archive      = {J_EAAI},
  author       = {Radha Mohan Pattanayak and H.S. Behera and Sibarama Panigrahi},
  doi          = {10.1016/j.engappai.2020.104136},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104136},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel probabilistic intuitionistic fuzzy set based model for high order fuzzy time series forecasting},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptation of the idea of concept drift to some behavioral
biometrics: Preliminary studies. <em>EAAI</em>, <em>99</em>, 104135. (<a
href="https://doi.org/10.1016/j.engappai.2020.104135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we present a novel strategy that utilizes concept drift to improve some biometric procedures. The proposed method can be applied whenever behavioral signals change and those changes need to be detected. From a security point of view, this is important because detection of and appropriate response to change should result in some alteration in the operation of the biometric system. As one example, this allows for the detection of legitimate and illegitimate users. Experiments performed on real biometric signals have demonstrated that the proposed techniques could be introduced into existing professional biometric systems based on behavioral features.},
  archive      = {J_EAAI},
  author       = {Piotr Porwik and Rafal Doroz},
  doi          = {10.1016/j.engappai.2020.104135},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104135},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adaptation of the idea of concept drift to some behavioral biometrics: Preliminary studies},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Construct a robust least squares support vector machine
based on lp-norm and l∞-norm. <em>EAAI</em>, <em>99</em>, 104134. (<a
href="https://doi.org/10.1016/j.engappai.2020.104134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite some L p -norm LSSVMs own feature selection and prediction ability, they still suffer from two common issues. (i) They always ignore edge points because the L 2 -norm metric is used to measure the classification error of the training samples. The edge points are important in some practical application or on the datasets that are non-independent and identically distributed (non-i.i.d). (ii) They spend higher computational time and storage space for the large scale datasets. In order to solve the above two shortcomings while retaining the feature selection ability, we adopt L ∞ -norm to measure the classification error of training samples and still use L p -norm (0 &lt;p&lt; 1) to measure the maximum margin between two parallel support planes, then obtain a novel LSSVM classifier, denoted as L p -L ∞ -LSSVM . Our L p -L ∞ -LSSVM owns three advantages: (1) L ∞ -norm on empirical risk ensures the effective recognition of edge points, thereby improving the robustness and generalization ability of the classifier. (2) L p -norm on structural risk possess feature selection ability, whether for the linear or non-linear separable case and is suitable for the small samples size (SSS) problem. (3) Inspired by the sequential minimal optimization (SMO) algorithm, we designed an iterative heuristic algorithm by breaking the large quadratic programming problem (QPP) into a series of smallest possible QPPs, which can avoid high time-consuming. This algorithm not only ensures the convergence of optimum solution but also consumes lower computational time and storage space for large scale datasets. Finally, extensive numerical experiments once again verify the above opinions and show the outstanding classification performance and feature selection ability simultaneously.},
  archive      = {J_EAAI},
  author       = {Ting Ke and Lidong Zhang and Xuechun Ge and Hui Lv and Min Li},
  doi          = {10.1016/j.engappai.2020.104134},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104134},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Construct a robust least squares support vector machine based on lp-norm and l∞-norm},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Current status of hybrid structures in wind forecasting.
<em>EAAI</em>, <em>99</em>, 104133. (<a
href="https://doi.org/10.1016/j.engappai.2020.104133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power is one of the most important clean energy and alternative to fossil fuels. More attention has been paid to this renewable resource in today’s world due to increasing public awareness, concerns about greenhouse gas emissions and environmental issues, and reducing the oil and gas reservoirs. Accurate and precise wind speed and wind power forecasts are the most critical and influential factors in making desired and efficient managerial and operational decisions in the wind energy area. Wind power and speed forecasting play an essential role in the planning, controlling, and monitoring of intelligent wind power systems. Therefore, several different models have been developed in the subject literature in order to predict this energy source more accurately. However, there is no general consensus on the model that must be selected and used in a specific situation of time horizon, sample size, complexity, uncertainty, etc. Hybrid models are the most frequently used and the most popular forecasting models in the energy literature. In this paper, combined approaches used in the wind energy forecasting field are first categorized into four main categories: 1) Data preprocessing based approaches, 2) Parameter optimization-based approaches, 3) Post processing based approaches, and 4) component combination-based approaches. Results indicate that the component combination-based category is the most diverse and extensive hybrid approach in the literature. Thus, in the next section of the paper, more attention is paid to these approaches and then classified into two major classes of series and parallel hybrid models. The literature review demonstrates that parallel hybrid models are more popular approaches in comparison with series hybrid models and more used for wind forecasting. Other specific and detailed conclusions and remarks are introduced in related sections.},
  archive      = {J_EAAI},
  author       = {Mehrnaz Ahmadi and Mehdi Khashei},
  doi          = {10.1016/j.engappai.2020.104133},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104133},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Current status of hybrid structures in wind forecasting},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective electricity load forecasting using enhanced
double-reservoir echo state network. <em>EAAI</em>, <em>99</em>, 104132.
(<a href="https://doi.org/10.1016/j.engappai.2020.104132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate electricity load prediction is essential to ensure the efficient, reliable, and secure operation of the power system. In this study, a hybrid forecasting method called improved backtracking search optimization algorithm (IBSA)–double-reservoir echo state network (DRESN) (IBSA–DRESN) is proposed on the basis of IBSA and DRESN. Mutual information is utilized to eliminate low-significance input features and retain key input features. The DRESN structure aims to increase the diversity of the network. Roulette strategy, adaptive mutation operator, and niche operator is introduced to improve the standard BSA algorithm. The IBSA is applied to optimize several critical parameters in the DRESN neural network. The proposed IBSA–DRESN method is evaluated using two electricity load datasets, namely, North-America and PJM. Compared with eight popular benchmark models, prediction results show that IBSA–DRESN is more accurate for one-step ahead electricity load forecasting. In one-day ahead forecasting, IBSA–DRESN obtains better prediction performance in most cases.},
  archive      = {J_EAAI},
  author       = {Lu Peng and Sheng-Xiang Lv and Lin Wang and Zi-Yun Wang},
  doi          = {10.1016/j.engappai.2020.104132},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104132},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Effective electricity load forecasting using enhanced double-reservoir echo state network},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ACOTSP-MF: A memory-friendly and highly scalable ACOTSP
approach. <em>EAAI</em>, <em>99</em>, 104131. (<a
href="https://doi.org/10.1016/j.engappai.2020.104131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ant Colony Optimization (ACO) is a population-based meta-heuristic inspired by the social behavior of ants. It is successfully applied in solving many NP-hard problems, such as the Traveling Salesman Problem (TSP). Large-sized instances pose two memory problems to the ACOTSP algorithm: the memory size and the memory bandwidth. This work has focused on developing ACOTSP-MF, a new ACOTSP algorithm proposed to adequately manage the memory issues that arise while solving large TSP instances. ACOTSP-MF uses the nearest neighbor list, introducing a novel class of cities, the backup cities , while grouping cities into three classes: the nearest neighbor cities, the backup cities, and the rest of the cities (the majority). ACOTSP-MF also modifies how the base ACOTSP carries out the tour construction and pheromone update phases depending on the group to which a city belongs. This way, ACOTSP-MF reduces both the memory requirements of its data structures (from O ( n ∗ n ) to O ( n ) ), and the memory bandwidth needs (thanks to better exploitation of the memory data locality). In this paper, we have carried out an in-depth analysis of ACOTSP-MF performance for medium and large TSP instances, covering vectorization and scalability issues and showing its main bottlenecks. For medium-size instances, the paper reports speedup factors of 20-500X for the rl11849 instance compared to the base ACOTSP version. ACOTSP-MF is intended and especially adequate for large-size instances. In this context, the paper reports excellent execution time for the Tour Construction phase, with less than 500 ms per iteration for the earring-200k instance. Finally, a study about the solution quality of ACOTSP-MF has been included, showing that ACOTSP-MF paired with local search offers high solution quality (within 2% of the best-known solution).},
  archive      = {J_EAAI},
  author       = {Pablo A. Martínez and José M. García},
  doi          = {10.1016/j.engappai.2020.104131},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104131},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {ACOTSP-MF: A memory-friendly and highly scalable ACOTSP approach},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pattern-based bootstrapping framework for biomedical
relation extraction. <em>EAAI</em>, <em>99</em>, 104130. (<a
href="https://doi.org/10.1016/j.engappai.2020.104130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The progress made in the realm of ‘-omics’ technologies has led to a tremendous increase in the quantum of biomedical research published. Information extraction from this huge unstructured mass of data needs automation through text mining methods. Biomedical relation extraction is one such vital automation processes for extracting biomedical relations hidden in scientific literature. In the recent past, several supervised machine learning methods have been used to identify biomedical relations. However, given the variations in textual expression, huge corpus size and small task-specific training data, semi-supervised techniques appear to perform better. To this end, we propose a system that uses the semi-supervised bootstrapping algorithm to extract biomedical relations from text. The unlabelled corpus used contains sentences with biomedical entities represented as patterns with the dependency tree feature. Bootstrapping starts with a seed set and iteratively learns new patterns from the unlabelled corpus. We have designed a three-level masking technique to generate new patterns, and incorporated three types of scoring to help select appropriate patterns. The pattern-based bootstrapping method performs well with a minimum seed set. The system is able to extract 37,450 patterns from the unlabelled corpus that represents different biomedical relations. These patterns, in turn, are able to identify 460,886 relation pairs with 1327 single, and 1012 coupled, trigger words that convey the semantics of the biomedical relation. More than 64% of the identified relations have evidence in the CTD database.},
  archive      = {J_EAAI},
  author       = {S.S. Deepika and T.V. Geetha},
  doi          = {10.1016/j.engappai.2020.104130},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104130},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Pattern-based bootstrapping framework for biomedical relation extraction},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysing centralities for organisational role inference in
online social networks. <em>EAAI</em>, <em>99</em>, 104129. (<a
href="https://doi.org/10.1016/j.engappai.2020.104129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intensive use of Online Social Networks (OSN) nowadays has made users expose more information without realising it. Malicious users or marketing agencies are now able to infer information that is not published on OSNs by using data from targets friends to use for their benefit. In this paper, the authors present a generalisable method capable of deducing the roles of employees of an organisation using their Twitter relationships and the features of the graph from their organisation. The authors also conduct an extensive analysis of the node centralities to study their roles in the inference of the different classes proposed. Derived from the experiments and the ablation study conducted to the centralities, the authors conclude that the latent features of the graph along with the directed relationships perform better than previously proposed methods when classifying the role of the employees of an organisation. Additionally, to evaluate the method, the authors also contribute with a new dataset consisting of three directed graphs (one for each organisation) representing the relationships between the employees obtained from Twitter.},
  archive      = {J_EAAI},
  author       = {Rubén Sánchez-Corcuera and Aritz Bilbao-Jayo and Unai Zulaika and Aitor Almeida},
  doi          = {10.1016/j.engappai.2020.104129},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104129},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Analysing centralities for organisational role inference in online social networks},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Capturing waste collection planning expert knowledge in a
fitness function through preference learning. <em>EAAI</em>,
<em>99</em>, 104113. (<a
href="https://doi.org/10.1016/j.engappai.2020.104113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper copes with the COGERSA waste collection process. Up to now, experts have been manually designed the process using a trial and error mechanism. This process is not globally optimized, since it has been progressively and locally built as council demands appear. Planning optimization algorithms usually solve it, but they need a fitness function to evaluate a route planning quality. The drawback is that even experts are not able to propose one in a straightforward way due to the complexity of the process. Hence, the goal of this paper is to build a fitness function though a preference framework, taking advantage of the available expert knowledge and expertise. Several key performance indicators together with preference judgments are carefully established according to the experts for learning a promising fitness function. Particularly, the additivity property of them makes the task be much more affordable, since it allows to work with routes rather than with route plannings. Besides, a feature selection analysis is performed over such indicators, since the experts suspect of a potential existing (but unknown) redundancy among them. The experiment results confirm this hypothesis, since the best C − index (98% against around 94%) is reached when 6 or 8 out of 21 indicators are taken. Particularly, truck load seems to be a highly promising key performance indicator, together to the travelled distance along non-main roads. A comparison with other existing approaches shows that the proposed method clearly outperforms them, since the C − index goes from 72% or 90% to 98%.},
  archive      = {J_EAAI},
  author       = {Laura Fdez-Díaz and Míriam Fdez-Díaz and José Ramón Quevedo and Elena Montañés},
  doi          = {10.1016/j.engappai.2020.104113},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104113},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Capturing waste collection planning expert knowledge in a fitness function through preference learning},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel probabilistic linguistic decision-making method with
consistency improvement algorithm and DEA cross-efficiency.
<em>EAAI</em>, <em>99</em>, 104108. (<a
href="https://doi.org/10.1016/j.engappai.2020.104108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Probabilistic linguistic term set (PLTS) is highly useful for decision-makers (DMs) to describe qualitative and uncertain information in the decision-making process. This paper proposes a novel probabilistic linguistic decision-making method with consistency improvement algorithm and data envelopment analysis (DEA) cross-efficiency. Firstly, we put forward the concept of order consistency of probabilistic linguistic preference relation (PLPR). The order consistency is helpful for DMs to make quick and efficient decision in certain situations. Then, based on the defined multiplicative consistency of PLPR, we develop a consistency improvement algorithm to transform the unacceptable multiplicative consistent PLPRs into the acceptable ones. Furthermore, a DEA model is established to derive the priority weight vector of alternatives from the acceptable multiplicative consistent PLPR. Meanwhile, for the alternatives that have equal priority weights, we use a DEA cross-efficiency model to further differentiate and obtain the final ranking of alternatives. Finally, a numerical example of emergency logistics distribution selection is given to illustrate the effectiveness and applicability of the proposed method.},
  archive      = {J_EAAI},
  author       = {Jinpei Liu and Yun Zheng and Ligang Zhou and Feifei Jin and Huayou Chen},
  doi          = {10.1016/j.engappai.2020.104108},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {3},
  pages        = {104108},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel probabilistic linguistic decision-making method with consistency improvement algorithm and DEA cross-efficiency},
  volume       = {99},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diurnal emotions, valence and the coronavirus lockdown
analysis in public spaces. <em>EAAI</em>, <em>98</em>, 104122. (<a
href="https://doi.org/10.1016/j.engappai.2020.104122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A large-scale analysis of diurnal and seasonal mood cycles in global social networks has been performed successfully over the past ten years using Twitter, Facebook and blogs. This study describes the application of remote biometric technologies to such investigations on a large scale for the first time. The performance of this research was under real conditions producing results that conform to natural human diurnal and seasonal rhythm patterns. The derived results of this, 208 million data research on diurnal emotions, valence and facial temperature correlate with the results of an analogical Twitter research performed worldwide (UK, Australia, US, Canada, Latin America, North America, Europe, Oceania, and Asia). It is established that diurnal valence and sadness were correlated with one another both prior to and during the period of the coronavirus crisis, and that there are statistically significant relationships between the values of diurnal happiness, sadness, valence and facial temperature and the numbers of their data. Results from the simulation and formal comparisons appear in this article. Additionally the analyses on the COVID-19 screening, diagnosing, monitoring and analyzing by applying biometric and AI technologies are described in Housing COVID-19 Video Neuroanalytics.},
  archive      = {J_EAAI},
  author       = {Arturas Kaklauskas and Ajith Abraham and Virgis Milevicius},
  doi          = {10.1016/j.engappai.2020.104122},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104122},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Diurnal emotions, valence and the coronavirus lockdown analysis in public spaces},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid of clustering and meta-heuristic algorithms to
solve a p-mobile hub location–allocation problem with the depreciation
cost of hub facilities. <em>EAAI</em>, <em>98</em>, 104121. (<a
href="https://doi.org/10.1016/j.engappai.2020.104121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hubs act as intermediate points for the transfer of materials in the transportation system. In this study, a novel p -mobile hub location–allocation problem is developed. Hub facilities can be transferred to other hubs for the next period. Implementation of mobile hubs can reduce the costs of opening and closing the hubs, particularly in an environment with rapidly changing demands. On the other hand, the movement of facilities reduces lifespan and adds relevant costs. The depreciation cost and lifespan of hub facilities must be considered and the number of movements of the hub’s facilities must be assumed to be limited. Three objective functions are considered to minimize costs, noise pollutions, and the harassment caused by the establishment of a hub for people, a new objective that locates hubs in less populated areas. A multi-objective mixed-integer non-linear programming (MINLP) model is developed. To solve the proposed model, four meta-heuristic algorithms, namely multi-objective particle swarm optimization (MOPSO), a non-dominated sorting genetic algorithm (NSGA-II), a hybrid of k -medoids as a famous clustering algorithm and NSGA-II (KNSGA-II), and a hybrid of K -medoids and MOPSO (KMOPSO) are implemented. The results indicate that KNSGA-II is superior to other algorithms. Also, a case study in Iran is implemented and the related results are analyzed.},
  archive      = {J_EAAI},
  author       = {Mahdi Mokhtarzadeh and Reza Tavakkoli-Moghaddam and Chefi Triki and Yaser Rahimi},
  doi          = {10.1016/j.engappai.2020.104121},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104121},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid of clustering and meta-heuristic algorithms to solve a p-mobile hub location–allocation problem with the depreciation cost of hub facilities},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-based learning of self-media data for marketing
intention detection. <em>EAAI</em>, <em>98</em>, 104118. (<a
href="https://doi.org/10.1016/j.engappai.2020.104118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of natural language processing, accuracy of intention detection is the basis for subsequent research on human-machine speech interaction. However, the problem of ambiguity in word vectors reduces the accuracy of intent detection. Meantime, there is a disconnection between local features and global features as well, resulting in text feature extraction that cannot fully reflect semantic information. These issues are all barriers of intention detection. Therefore, this paper proposes an attention-based convolutional neural network for self-media data learning (called A-CNN) for marketing intention. We cascade the traditional CNN with the self-attention model in the Attention networks to form a new network structure called A-CNN, and put forward a fast feature extraction method based on skip-gram-based learning called FSLText, to represent the high-dimension word vectors in the A-CNN. On the premise of maintaining the advantages of the CNN, A-CNN can not only solve the problem of local and global features disconnection caused by the CNN pooling layer, but also avoid the increase of algorithm complexity. The Self-Attention mechanism in the Attention model can effectively optimize the weight of local features of the information in global features, and retain local features that are more useful for intention detection. A fast feature extraction method which is based on Skip-gram can retain the semantic and word order information of the text. The method is beneficial to the marketing intention detection. According to the experiment, our A-CNN, compared with traditional machine learning methods, can improve 12.32% accuracy. Contrast to the dual-channel CNN, the accuracy rate is improved by 9.68%, and compared with the ATT-CNN, it is improved by 9.97%. On the F1 score, the A-CNN can improve the F1 score by about 9.37% in comparison with the traditional machine learning methods, the accuracy rate is increased by 9.68% compared with the dual-channel CNN, and 9.68% in contrast with ATT-CNN. It illustrates that our A-CNN can effectively address semantic and feature selection for marketing intention detection.},
  archive      = {J_EAAI},
  author       = {Zhihao Hou and Kun Ma and Yufeng Wang and Jia Yu and Ke Ji and Zhenxiang Chen and Ajith Abraham},
  doi          = {10.1016/j.engappai.2020.104118},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104118},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Attention-based learning of self-media data for marketing intention detection},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning dynamic regression with automatic distractor
repression for real-time UAV tracking. <em>EAAI</em>, <em>98</em>,
104116. (<a
href="https://doi.org/10.1016/j.engappai.2020.104116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With high efficiency and efficacy, the trackers based on the discriminative correlation filter have experienced rapid development in the field of unmanned aerial vehicle (UAV) over the past decade. In literature, these trackers aim at solving a regression problem in which the circulated samples are mapped into a Gaussian label for online filter training. However, the fixed target label for regression makes trackers lose adaptivity in uncertain tracking scenarios. One of the typical failure cases is that the distractors, e.g. , background clutter, camouflage, and similar object, are prone to confuse these trackers. In this work, an efficient approach to instantly monitor the local maximums of the response map for discovering distractors automatically is proposed. In addition, the regression target is accordingly learned, i.e. , the location possessing local maximum indicates latent distractor and thus should be repressed by reducing its target response value in filter training. Qualitative and quantitative experiments performed on three challenging well-known benchmarks demonstrate that the presented method not only outperforms the state-of-the-art handcrafted feature-based trackers but also exhibits comparable performance compared to deep learning-based approaches. Specifically, the presented tracker has phenomenal practicability in real-time UAV applications with an average speed of ∼ 50 frames per second on an affordable CPU.},
  archive      = {J_EAAI},
  author       = {Changhong Fu and Fangqiang Ding and Yiming Li and Jin Jin and Chen Feng},
  doi          = {10.1016/j.engappai.2020.104116},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104116},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Learning dynamic regression with automatic distractor repression for real-time UAV tracking},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-agent hierarchical policy gradient for air combat
tactics emergence via self-play. <em>EAAI</em>, <em>98</em>, 104112. (<a
href="https://doi.org/10.1016/j.engappai.2020.104112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Air-to-air confrontation has attracted wide attention from artificial intelligence scholars. However, in the complex air combat process, operational strategy selection depends heavily on aviation expert knowledge, which is usually expensive and difficult to obtain. Moreover, it is challenging to select optimal action sequences efficiently and accurately with existing methods, due to the high complexity of action selection when involving hybrid actions, e.g., discrete/continuous actions. In view of this, we propose a novel Multi-Agent Hierarchical Policy Gradient algorithm (MAHPG), which is capable of learning various strategies and transcending expert cognition by adversarial self-play learning. Besides, a hierarchical decision network is adopted to deal with the complicated and hybrid actions. It has a hierarchical decision-making ability similar to humankind, and thus, reduces the action ambiguity efficiently. Extensive experimental results demonstrate that the MAHPG outperforms the state-of-the-art air combat methods in terms of both defense and offense ability. Notably, it is discovered that the MAHPG has the ability of Air Combat Tactics Interplay Adaptation, and new operational strategies emerged that surpass the level of experts.},
  archive      = {J_EAAI},
  author       = {Zhixiao Sun and Haiyin Piao and Zhen Yang and Yiyang Zhao and Guang Zhan and Deyun Zhou and Guanglei Meng and Hechang Chen and Xing Chen and Bohao Qu and Yuanjie Lu},
  doi          = {10.1016/j.engappai.2020.104112},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104112},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Multi-agent hierarchical policy gradient for air combat tactics emergence via self-play},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel artificial autonomous system for supporting
investment decisions using a big five model approach. <em>EAAI</em>,
<em>98</em>, 104107. (<a
href="https://doi.org/10.1016/j.engappai.2020.104107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the design of an artificial autonomous system (called AAS) for the stock market domain that considers an approximation from the Big Five model, which proposes that the personality of an individual belongs to one of five different personality profiles: openness, conscientiousness, extraversion, agreeableness, and neuroticism. Several studies have explored investment and financial issues while considering the Big Five model, usually by analyzing data obtained from surveys applied to real people. However, to the best of our knowledge, there are no proposals that suggest the design of an AAS for supporting investment decisions that use the Big Five model as the central approach. The main objective of this proposal is to design an AAS for making investment decisions, where the decisions are adjusted to market conditions through the use of a policy function that adapts over time. This policy function adjusts the consumption level and investment portfolio composition required by the investment profile, considering both the market conditions and the Big Five model profile associated with the AAS. The effectiveness of the investment process is measured by observing the variations in the accumulated wealth and utility. The utility is measured through an abstract representation of the well-being or satisfaction of the investor (i.e., the AAS). AAS—Extraversion obtained the highest accumulated wealth, while AAS—Agreeableness obtained the highest level of utility, showing that the accumulated wealth is only one factor influencing the investor’s well-being.},
  archive      = {J_EAAI},
  author       = {Daniel Cabrera-Paniagua and Rolando Rubilar-Torrealba},
  doi          = {10.1016/j.engappai.2020.104107},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104107},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A novel artificial autonomous system for supporting investment decisions using a big five model approach},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A grunwald–letnikov based manta ray foraging optimizer for
global optimization and image segmentation. <em>EAAI</em>, <em>98</em>,
104105. (<a
href="https://doi.org/10.1016/j.engappai.2020.104105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a modified version of Manta ray foraging optimizer (MRFO) algorithm to deal with global optimization and multilevel image segmentation problems. MRFO is a meta-heuristic technique that simulates the behaviors of manta rays to find the food. MRFO established its ability to find a suitable solution for a variant of optimization problems. However, by analyzing its behaviors during the optimization process, it is observed that its exploitation ability is less than exploration ability, which makes MRFO more sensitive to attractive to a local point. Therefore, we enhanced MRFO by using the fractional-order (FO) calculus during the exploitation phase. We used the heredity and non-locality properties of the Grunwald–Letnikov fractional differ-integral operator to simulate the after effect of the previous locations of manta rays on their future movement directions. The proposed Fractional-order MRFO (FO-MRFO) quality is confirmed using a set of two experimental series. Firstly, it is applied to find the solution for CEC2017 benchmark functions with different dimensions of 10, 30, and 50. Through performing the non-parametric statistical analysis, the FO-MRFO shows its superiority in comparison with the basic MRFO. For the second series of experiments, the developed algorithm is implemented as a multilevel threshold image segmentation technique. In this experiment, a variant of natural images is used to assess FO-MFRO. According to different performance measures, the FO-MRFO outperforms the compared algorithms in the global optimization and image segmentation.},
  archive      = {J_EAAI},
  author       = {Mohamed Abd Elaziz and Dalia Yousri and Mohammed A.A. Al-qaness and Amr M. AbdelAty and Ahmed G. Radwan and Ahmed A. Ewees},
  doi          = {10.1016/j.engappai.2020.104105},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104105},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A Grunwald–Letnikov based manta ray foraging optimizer for global optimization and image segmentation},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shortening the gap between pre- and post-layout analog IC
performance by reducing the LDE-induced variations with multi-objective
simulated quantum annealing. <em>EAAI</em>, <em>98</em>, 104102. (<a
href="https://doi.org/10.1016/j.engappai.2020.104102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The design of analog and mixed-signal integrated circuits (ICs) is intricate due to the continuous nature of the signals handled. Still, it is also strongly affected by the physical implementation of analog devices on the circuits’ layout. The circuit layout corresponds to the physical implementation of an analog IC used in fabrication that describes its devices geometrically. As circuits’ integration and device sizes shrink, the physics of the interactions between devices, as they are placed in the layout, was proved to easily drive analog and mixed-signal ICs from promising pre-layout performances to completely post-layout malfunction. As these layout-dependent effects (LDEs) can only be evaluated once the layout is completed, the true post-layout performance is only evaluated in a late stage of the traditional design flow, causing expensive redesign iterations lacking the information that identifies precisely where, in the layout, there are problems needed to be solved. For technologies above the 40-nanometers, the leading causes of LDEs are mobility and threshold voltage variations. This paper proposes an automatic device placement methodology that explicitly accounts for, and minimizes, these LDEs. An absolute representation of the floorplan is adopted, and, multiple optimization techniques, including the novel, constrained archive-based multi-objective implementation of the simulated quantum annealing inspired algorithm, enhanced with specific LDE-impact mitigation operators are applied to solve the problem. In each of these optimization processes, established LDE formulations for accurate circuit simulation models are used to evaluate each candidate placement solution, and, guide the optimization process. In the case of multi-objective implementations, ultimately offering a realistic perspective of the LDE-aware design tradeoffs between performance deterioration and used chip area. Experimental results conducted over state-of-the-art analog structures on a challenging 65-nanometers technology node show that the proposed methodology shortens the gap between pre- and post-layout performance by reducing the LDE-induced variations, aiming for first-time-right layout design.},
  archive      = {J_EAAI},
  author       = {Ricardo Martins and Nuno Lourenço and Ricardo Póvoa and Nuno Horta},
  doi          = {10.1016/j.engappai.2020.104102},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104102},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Shortening the gap between pre- and post-layout analog IC performance by reducing the LDE-induced variations with multi-objective simulated quantum annealing},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fusion particle and fingerprint recognition for indoor
positioning system on mobile. <em>EAAI</em>, <em>98</em>, 104082. (<a
href="https://doi.org/10.1016/j.engappai.2020.104082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High accuracy localization is easily obtained in an exterior context with GPS, but the development of indoor positioning systems remains a challenge. The GPS signals, by nature, cannot penetrate walls thus preventing this technology to provide any service indoor. This paper proposes a practical implementation of an accurate Indoor Positioning System based on Bluetooth Low Energy technology to ensure a low power, efficient and easy to setup infrastructure. It is available on any current Smartphone and requires no extra devices for the user. We use a fusion of the inertial sensors available on the device to output a precise and drift-free estimation of the user displacement, leverage this information with iBeacon radio signals used as anchors to readjust the path if needed and process all these inputs in a Particle Filter. We augmented the Fingerprinting-based likelihood calculation of the particles position’s with a unique simulation of the particle’s theoretical RSSI and also reduced the number of particles to better fit within the bounds of the computational capabilities of mobile devices. The experiment was conducted in a 400 m 2 open space and yielded positive results as a first attempt in accurate indoor localization and proved to be viable in an indoor context.},
  archive      = {J_EAAI},
  author       = {C. Lamoureux and R. Chelouah},
  doi          = {10.1016/j.engappai.2020.104082},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104082},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Fusion particle and fingerprint recognition for indoor positioning system on mobile},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrate domain knowledge in training multi-task cascade
deep learning model for benign–malignant thyroid nodule classification
on ultrasound images. <em>EAAI</em>, <em>98</em>, 104064. (<a
href="https://doi.org/10.1016/j.engappai.2020.104064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic and accurate diagnosis of thyroid nodules in ultrasound images is of great significance to reduce the workload and radiologists’ misdiagnosis rate. Although deep learning has shown strong image classification performance, the inherent limitations of medical images small dataset and time-consuming access to lesion annotations, leaving this work still facing challenges. In our study, a multi-task cascade deep learning model (MCDLM) was proposed, which integrates radiologists’ various domain knowledge (DK) and uses multimodal ultrasound images for automatic diagnosis of thyroid nodules. Specifically, we transfer the knowledge learned by U-net from the source domain to the target domain under the guidance of radiologist’ marks to obtain more accurate nodules’ segmentation results. We then quantify the nodules’ ultrasound features (UF) as conditions to assist the dual-path semi-supervised conditional generative adversarial network (DScGAN) in generating higher quality images obtaining more powerful discriminators. After that, we concatenate DScGAN learning’s image representation to train a supervised support vector machine (S3VM) for thyroid nodule classification. The experiment results on ultrasound images of 1030 patients suggest that the MCDLM model can achieve almost the same classification performance as the fully supervised learning (an accuracy of 90.01% and an AUC of 91.07%) using only about 35% of the full labeled dataset, which saves a lot of time and effort compared to traditional methods.},
  archive      = {J_EAAI},
  author       = {Wenkai Yang and Yunyun Dong and Qianqian Du and Yan Qiang and Kun Wu and Juanjuan Zhao and Xiaotang Yang and Muhammad Bilal Zia},
  doi          = {10.1016/j.engappai.2020.104064},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104064},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Integrate domain knowledge in training multi-task cascade deep learning model for benign–malignant thyroid nodule classification on ultrasound images},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BeCAPTCHA: Behavioral bot detection using touchscreen and
mobile sensors benchmarked on HuMIdb. <em>EAAI</em>, <em>98</em>,
104058. (<a
href="https://doi.org/10.1016/j.engappai.2020.104058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we study the suitability of a new generation of CAPTCHA methods based on smartphone interactions. The heterogeneous flow of data generated during the interaction with the smartphones can be used to model human behavior when interacting with the technology and improve bot detection algorithms. For this, we propose BeCAPTCHA, a CAPTCHA method based on the analysis of the touchscreen information obtained during a single drag and drop task in combination with the accelerometer data. The goal of BeCAPTCHA is to determine whether the drag and drop task was realized by a human or a bot. We evaluate the method by generating fake samples synthesized with Generative Adversarial Neural Networks and handcrafted methods. Our results suggest the potential of mobile sensors to characterize the human behavior and develop a new generation of CAPTCHAs. The experiments are evaluated with HuMIdb 1 (Human Mobile Interaction database), a novel multimodal mobile database that comprises 14 mobile sensors acquired from 600 users. HuMIdb is freely available to the research community.},
  archive      = {J_EAAI},
  author       = {Alejandro Acien and Aythami Morales and Julian Fierrez and Ruben Vera-Rodriguez and Oscar Delgado-Mohatar},
  doi          = {10.1016/j.engappai.2020.104058},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {2},
  pages        = {104058},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {BeCAPTCHA: Behavioral bot detection using touchscreen and mobile sensors benchmarked on HuMIdb},
  volume       = {98},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transformers-based information extraction with limited data
for domain-specific business documents. <em>EAAI</em>, <em>97</em>,
104100. (<a
href="https://doi.org/10.1016/j.engappai.2020.104100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information extraction plays an important role for data transformation in business cases. However, building extraction systems in actual cases face two challenges: (i) the availability of labeled data is usually limited and (ii) highly detailed classification is required. This paper introduces a model for addressing the two challenges. Different from prior studies that usually require a large number of training samples, our extraction model is trained with a small number of data for extracting a large number of information types. To do that, the model takes into account the contextual aspect of pre-trained language models trained on a huge amount of data on general domains for word representation. To adapt to our downstream task, the model employs transfer learning by stacking Convolutional Neural Networks to learn hidden representation for classification. To confirm the efficiency of our method, we apply the model to two actual cases of document processing for bidding and sale documents of two Japanese companies. Experimental results on real testing sets show that, with a small number of training data, our model achieves high accuracy accepted by our clients.},
  archive      = {J_EAAI},
  author       = {Minh-Tien Nguyen and Dung Tien Le and Linh Le},
  doi          = {10.1016/j.engappai.2020.104100},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104100},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Transformers-based information extraction with limited data for domain-specific business documents},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised damage clustering in complex aeronautical
composite structures monitored by lamb waves: An inductive approach.
<em>EAAI</em>, <em>97</em>, 104099. (<a
href="https://doi.org/10.1016/j.engappai.2020.104099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural Health Monitoring (SHM), i.e. the action of monitoring structures in real-time and in an automated manner, is a major challenge in several industrial fields such as aeronautic. SHM is by nature a very high dimensional data-driven problem that possesses several specificities when addressed as a machine learning problem. First of all data in damaged cases are rare and very costly as the generation of damaged data is not always possible and simulations are not reliable especially when dealing with complex structures. SHM is thus by nature an unsupervised problem. Furthermore, any incoming sample should be instantaneously clustered and handcrafted damage indexes are commonly used as a first dimension reduction step due to large datasets to be processed. As a consequence, unsupervised dimensionality reduction (DR) techniques that project very high dimensional data into a two or three-dimensional space (such as t-SNE or UMAP) are very appealing in such a context. However, these methods suffer from one major drawback which is that they are unable to cluster any unknown incoming sample. To solve this we propose to add inductive abilities to these well know methods by associating their projection bases with Deep Neural Networks (DNNs). The resulting DNNs are then able to cluster any incoming unknown samples. Based on those tools, a SHM methodology allowing for unsupervised damage clustering with dimensionality reduction is presented here. To demonstrate the effectiveness of the method, results of damage classification on large experimental data sets coming from complex aeronautical composite structures monitored through Lamb waves are shown. Furthermore, several DR techniques have been benchmarked and recommendations are derived. It is demonstrated that the use of raw Lamb wave signals instead of the associated damage indexes is more effective. This non-intuitive result helps to reduce the gap between laboratory research and the actual start-up of SHM activities in industrial applications.},
  archive      = {J_EAAI},
  author       = {Amirhossein Rahbari and Marc Rébillat and Nazih Mechbal and Stephane Canu},
  doi          = {10.1016/j.engappai.2020.104099},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104099},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Unsupervised damage clustering in complex aeronautical composite structures monitored by lamb waves: An inductive approach},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic clustering analysis for driving styles
identification. <em>EAAI</em>, <em>97</em>, 104096. (<a
href="https://doi.org/10.1016/j.engappai.2020.104096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For intelligent driving systems, the ability to recognize different driving styles of surrounding vehicles is crucial in determining the safest, yet more efficient driving decisions especially in the context of the mixed driving environment. Knowing for instance if the vehicle in the adjacent lane is aggressive or cautious can greatly assist in the decision making of ego vehicle in terms of whether and when it is appropriate to make particular manoeuvres (e.g. lane change). In addition, vehicles behave differently under different surrounding environments, making the driving styles identification highly challenging. To this end, in this paper we propose a dynamic clustering based driving styles identification and profiling approach where clusters vary in response to the changing surrounding environment. To better capture dynamic driving patterns and understand the driving style switch behaviours and more complicated driving patterns, a position-dependent dynamic clustering structure is developed where a driver is assigned to a cluster sequence rather than a single cluster. To the best of our knowledge, this is the first research paper of its kind on the dynamic clustering of driving styles. The usefulness of the proposed method is demonstrated on a real-world vehicle trajectory dataset where results show that driving style switches and more complex driving behaviours can be better captured. The potential applications in intelligent driving systems are also discussed.},
  archive      = {J_EAAI},
  author       = {Maria Valentina Niño de Zepeda and Fanlin Meng and Jinya Su and Xiao-Jun Zeng and Qian Wang},
  doi          = {10.1016/j.engappai.2020.104096},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104096},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Dynamic clustering analysis for driving styles identification},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep multi-level feature pyramids: Application for
non-canonical firearm detection in video surveillance. <em>EAAI</em>,
<em>97</em>, 104094. (<a
href="https://doi.org/10.1016/j.engappai.2020.104094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The epidemic of gun violence worldwide necessitates the need for an active-based video surveillance network to combat this crime. In this context, autonomously detecting handguns is crucial in capturing firearm-related crimes. However, current object detectors using deep learning are unable to capture handguns at different scales in an unconstrained environment. Hence, this paper puts forward an enhanced deep multi-level feature pyramid network that addresses the difficulty in inferring handguns from a non-canonical perspective. We first construct a dataset containing handguns in an unconstrained environment for representation learning. The dataset is constructed from a set of 250 recorded videos and with over 2500 distinct labeled frames. Crucially, these labeled frames account for the absence of a proper video surveillance-based handgun dataset. We then train the dataset on a multi-level multi-scale object detector, i.e., M2Det. We further improve the performance of M2Det by: (1) Enhancing the base features by concatenating shallow, medium and deep features from the backbone according to its relative receptive field; (2) Implementing generalized intersection-over-union as its localization loss; and (3) Integrating Focal Loss as its classification loss to improve detection of small-scale handguns. Experiments on a challenging video surveillance test dataset demonstrate that the proposed model achieves 87.42% accuracy. In addition, we implement adaptive surveillance image partitioning to redetect handguns at specific regions. This method potentially solves the challenge of sporadically poor real-world handgun classifications. This model is capable of pioneering non-canonical handgun detection for active-based video surveillance systems. The dataset and trained models are available at : https://github.com/MarcusLimJunYi/Monash-Guns-Dataset .},
  archive      = {J_EAAI},
  author       = {JunYi Lim and Md Istiaque Al Jobayer and Vishnu Monn Baskaran and Joanne MunYee Lim and John See and KokSheik Wong},
  doi          = {10.1016/j.engappai.2020.104094},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104094},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep multi-level feature pyramids: Application for non-canonical firearm detection in video surveillance},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-dimensional association information analysis
approach to automated detection and localization of myocardial
infarction. <em>EAAI</em>, <em>97</em>, 104092. (<a
href="https://doi.org/10.1016/j.engappai.2020.104092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing an accurate and automatic algorithm for detection and localization of myocardial infarction (MI) remains a great challenge for multi-lead electrocardiograph (ECG) signals. The core is a novel technique of multi-dimensional association information analysis for a multi-lead ECG tensor. Tensorization based on Discrete Wavelet Transform is investigated to construct an effective ECG tensor containing multi-dimensional association information from 12-lead ECG signals. The multi-lead feature extraction algorithm based on Parallel Factor Analysis is developed to automatically extract the low-dimensional and highly recognizable lead characteristic features of the tensor. After that a bagged decision tree is constructed to categorize 12 types of heartbeats, healthy controls and 11 kinds of MI, from the lead features. Using the PTB database, we compare with the existing MI diagnosis methods. For MI detection, significant improvement of the accuracy, sensitivity and specificity are achieved; as high as 99.88%, 99.98% and 99.39% respectively. Furthermore, an experiment with 36-dimensional features obtained from the ECG tensor is conducted for the localization of 11 kinds of MI, and our proposed method achieved an accuracy of 99.40%, sensitivity of 99.86%, and specificity of 99.89%. The proposed algorithm can effectually accomplish the localization of 11 categories of MI by using the lead features extracted from the multi-dimensional association ECG tensor, which has not been achieved in literature. The accurate and comprehensive tool development will greatly help cardiologists diagnose 12-lead ECG signals of MI.},
  archive      = {J_EAAI},
  author       = {Jieshuo Zhang and Ming Liu and Peng Xiong and Haiman Du and Hong Zhang and Feng Lin and Zengguang Hou and Xiuling Liu},
  doi          = {10.1016/j.engappai.2020.104092},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104092},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multi-dimensional association information analysis approach to automated detection and localization of myocardial infarction},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GRAVITAS: A model checking based planning and goal reasoning
framework for autonomous systems. <em>EAAI</em>, <em>97</em>, 104091.
(<a href="https://doi.org/10.1016/j.engappai.2020.104091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work follow the verification as planning paradigm and propose to use model-checking techniques to solve planning and goal reasoning problems for autonomous systems with high-degree of assurance. It presents a novel modelling framework — Goal Task Network (GTN) that encompass both goal reasoning and planning under a unified formal description that enables the use of assurance tools. The paper provides a systematic method that highlights how an industrial model checker (PAT) can be used to solve goal reasoning and planning problems modelled by GTNs. Further, this paper also introduces the design of an automated system framework for Goal Reasoning And Verification for Independent Trusted Autonomous Systems (GRAVITAS). The proposed framework is demonstrated in an experiment that simulates a survey mission performed by the REMUS-100 autonomous underwater vehicle.},
  archive      = {J_EAAI},
  author       = {Hadrien Bride and Jin Song Dong and Ryan Green and Zhé Hóu and Brendan Mahony and Martin Oxenham},
  doi          = {10.1016/j.engappai.2020.104091},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104091},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {GRAVITAS: A model checking based planning and goal reasoning framework for autonomous systems},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causal artificial neural network and its applications in
engineering design. <em>EAAI</em>, <em>97</em>, 104089. (<a
href="https://doi.org/10.1016/j.engappai.2020.104089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce the computational cost in engineering design, expensive high-fidelity simulation models are approximated by mathematical models, named as metamodels. Typical metamodeling methods assume that expensive simulation models are black-box functions. In this paper, in order to improve the accuracy of metamodels and reduce the cost of building metamodels, knowledge about engineering design problems is employed to help develop a novel metamodel, named as causal artificial neural network (causal-ANN). Cause–effect relations intrinsic to the design problem are employed to decompose an ANN into sub-networks and values of intermediate variables are utilized to train these sub-networks. By involving knowledge of the design problem, the accuracy of causal-ANN is higher than the traditional metamodeling methods that assume black-box functions. Additionally, one can identify attractive subspaces from the causal-ANN by leveraging the structure of the causal-ANN and the theory of Bayesian Networks. The impacts of fidelity of causal graphs and design variable correlations are also discussed in the paper. The engineering case studies demonstrate that the causal-ANN can be accurately constructed with a small number of expensive simulations, and attractive design subspaces can be identified directly from the causal-ANN.},
  archive      = {J_EAAI},
  author       = {Di Wu and G. Gary Wang},
  doi          = {10.1016/j.engappai.2020.104089},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104089},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Causal artificial neural network and its applications in engineering design},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing functionals using differential evolution.
<em>EAAI</em>, <em>97</em>, 104086. (<a
href="https://doi.org/10.1016/j.engappai.2020.104086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaheuristic algorithms are typically used for optimizing a function f : A → R , where A is a subset of R N . Nevertheless, many real-life problems require A to be a set of functions which makes f a functional. In this paper, we present a methodology to address the optimization of functionals by using the evolutionary algorithm known as Differential Evolution. Unlike traditional techniques where continuity and differentiability assumptions are required to solve some associated differential equations—like calculus of variations, Pontryagin’s principle or dynamic programming, the optimization is carried out directly on the functional without the need of any of the assumptions mentioned before. Lagrangians involving derivatives are considered, these derivatives are computed implementing Automatic Differentiation with dual numbers. To the best of our knowledge, this is the first time that a metaheuristic optimization approach has been applied to directly optimize a broad variety of functionals. The effectiveness of our methodology is validated by solving two problems. The first problem is related to the implementation of quarantine and isolation in SARS epidemics and the second validation problem deals with the well-known brachistochrone curve problem. The results of both validation problems are in outstanding agreement with those obtained with the application of traditional techniques, specifically with the Forward–Backward-Sweep method in the first problem, and with the calculus of variations for the latter problem. We also found that interpolation may be employed to solve the large scale global optimization problems arisen in the optimization of functionals.},
  archive      = {J_EAAI},
  author       = {K.B. Cantún-Avila and D. González-Sánchez and S. Díaz-Infante and F. Peñuñuri},
  doi          = {10.1016/j.engappai.2020.104086},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104086},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimizing functionals using differential evolution},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial robustness and attacks for multi-view deep
models. <em>EAAI</em>, <em>97</em>, 104085. (<a
href="https://doi.org/10.1016/j.engappai.2020.104085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent work has highlighted the vulnerability of many deep machine learning models to adversarial examples. It attracts increasing attention to adversarial attacks, which can be used to evaluate the security and robustness of models before they are deployed. However, to our best knowledge, there is no specific research on the adversarial robustness and attacks for multi-view deep models. Based on the fact that adversarial examples generalize well among different models, this paper takes the adversarial attack on the multi-view convolutional neural network as an example to investigate the adversarial robustness of multi-view deep models, and further proposes effective multi-view adversarial attacks. This paper proposes two strategies, two-stage attack (TSA) and end-to-end attack (ETEA), to attack against well-trained multi-view models. With the mild assumption that the single-view model on which the target multi-view model is based is known, we first propose the TSA strategy. The main idea of TSA is to attack the multi-view model with adversarial examples generated by attacking the associated single-view model, by which state-of-the-art single-view attack methods are directly extended to the multi-view scenario. Then we further propose the ETEA strategy where the multi-view model is provided publicly. The ETEA is applied to accomplish direct attacks on the target multi-view model, where we develop three effective multi-view attack methods. Extensive experimental results show that multi-view models are more robust than single-view models and demonstrate the effectiveness of the proposed multi-view adversarial attacks.},
  archive      = {J_EAAI},
  author       = {Xuli Sun and Shiliang Sun},
  doi          = {10.1016/j.engappai.2020.104085},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104085},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Adversarial robustness and attacks for multi-view deep models},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Engineering collective intelligence at the edge with
aggregate processes. <em>EAAI</em>, <em>97</em>, 104081. (<a
href="https://doi.org/10.1016/j.engappai.2020.104081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge computing promotes the execution of complex computational processes without the cloud, i.e., on top of the heterogeneous, articulated, and possibly mobile systems composed of IoT and edge devices. Such a pervasive smart fabric augments our environment with computing and networking capabilities. This leads to a complex and dynamic ecosystem of devices that should not only exhibit individual intelligence but also collective intelligence —the ability to take group decisions or process knowledge among autonomous units of a distributed environment. Self-adaptation and self-organisation mechanisms are also typically required to ensure continuous and inherent toleration of changes of various kinds, to distribution of devices, energy available, computational load, as well as faults. To achieve this behaviour in a massively distributed setting like edge computing demands, we seek for identifying proper abstractions, and engineering tools therefore, to smoothly capture collective behaviour, adaptivity, and dynamic injection and execution of concurrent distributed activities. Accordingly, we elaborate on a notion of “aggregate process” as a concurrent collective computation whose execution and interactions are sustained by a dynamic team of devices, whose spatial region can opportunistically vary over time. We ground this notion by extending the aggregate computing model and toolchain with new constructs to instantiate aggregate processes and regulate key aspects of their lifecycle. By virtue of an open-source implementation in the ScaFi framework, we show basic programming examples as well as case studies of edge computing, evaluated by simulation in realistic settings.},
  archive      = {J_EAAI},
  author       = {Roberto Casadei and Mirko Viroli and Giorgio Audrito and Danilo Pianini and Ferruccio Damiani},
  doi          = {10.1016/j.engappai.2020.104081},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104081},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Engineering collective intelligence at the edge with aggregate processes},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid feature selection method based on information
theory and binary butterfly optimization algorithm. <em>EAAI</em>,
<em>97</em>, 104079. (<a
href="https://doi.org/10.1016/j.engappai.2020.104079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is the problem of finding the optimal subset of features for predicting class labels by removing irrelevant or redundant features. S-shaped Binary Butterfly Optimization Algorithm (S-bBOA) is a nature-inspired algorithm for solving the feature selection problems. The evidence shows that S-bBOA has a better performance in exploration, exploitation, convergence, and avoidance of getting stuck in local optimal compared to other optimization algorithms. However, S-bBOA does not consider redundancy and relevancy of features. This paper proposes Information Gain binary Butterfly Optimization Algorithm (IG-bBOA), to overcome the S-bBOA constraints firstly. IG-bBOA maximizes both the classification accuracy and the mean of the mutual information between features and class labels. In addition, IG-bBOA also tries to minimize the number of selected features and is used within a three-phase proposed method called Ensemble Information Theory based binary Butterfly Optimization Algorithm (EIT-bBOA). In the first phase, 80% of irrelevant and redundant features are removed using Minimal Redundancy-Maximal New Classification Information (MR-MNCI) feature selection. In the second phase, the best feature subset is selected using IG-bBOA. Finally, a similarity based ranking method is used to select the final features subset. The experimental results are conducted using six standard datasets from UCI repository. The findings confirm the efficiency of the proposed method in improving the classification accuracy and selecting the best optimal features subset with minimum number of feature in most cases.},
  archive      = {J_EAAI},
  author       = {Zohre Sadeghian and Ebrahim Akbari and Hossein Nematzadeh},
  doi          = {10.1016/j.engappai.2020.104079},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104079},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A hybrid feature selection method based on information theory and binary butterfly optimization algorithm},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A fast x-shaped foreground segmentation network with
CompactASPP. <em>EAAI</em>, <em>97</em>, 104077. (<a
href="https://doi.org/10.1016/j.engappai.2020.104077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Foreground segmentation models are designed to extract moving objects of varying sizes from the background, which can benefit from representations of various scales. As an effective module for capturing multi-scale contexts, Atrous Spatial Pyramid Pooling (ASPP) convolves a final feature representation via multiple parallel atrous convolutions with different dilation rates. However, as the dilation rate increases, ASPP gradually loses its large-scale modeling ability because the sampling of atrous kernel becomes progressively sparse within the receptive field. To solve this problem, we design a CompactASPP module to convolve feature maps compactly . Without significantly increasing the module size, the CompactASPP can encode multi-scale features from all neurons within the receptive field rather than from neurons in several sparsely distributed positions. Furthermore, we leverage CompactASPP modules to enhance our previous X-Net. The proposed Fast X-Net substantially improves the segmentation speed by over 63.6% and attains new state-of-the-art performances on CDnet2014, SBI2015 and UCSD benchmarks.},
  archive      = {J_EAAI},
  author       = {Jin Zhang and Shuaihui Wang and Junyang Qiu and Xinran Pan and Junhua Zou and Yexin Duan and Zhisong Pan and Yang Li},
  doi          = {10.1016/j.engappai.2020.104077},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104077},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A fast X-shaped foreground segmentation network with CompactASPP},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploration of convolutional neural network models for
source code classification. <em>EAAI</em>, <em>97</em>, 104075. (<a
href="https://doi.org/10.1016/j.engappai.2020.104075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of Artificial Intelligence is becoming common in many engineering fields. Among them, one of the newest and rapidly evolving is software generation, where AI can be used to automatically optimise the implementation of an algorithm for a given computing platform. In particular, Deep Learning technologies can be used to the decide how to allocate pieces of code to hardware platforms with multiple cores and accelerators, that are common in high performance and edge computing applications. In this work, we explore the use of Convolutional Neural Networks (CNN)s to analyse the application source code and decide the best compute unit to minimise the execution time. We demonstrate that CNN models can be successfully applied to source code classification, providing higher accuracy with consistently reduced learning time with respect to state-of-the-art methods. Moreover, we show the robustness of the method with respect to source code pre-processing, compiler options and hyper-parameters selection.},
  archive      = {J_EAAI},
  author       = {Francesco Barchi and Emanuele Parisi and Gianvito Urgese and Elisa Ficarra and Andrea Acquaviva},
  doi          = {10.1016/j.engappai.2020.104075},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104075},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Exploration of convolutional neural network models for source code classification},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A forest-based algorithm for selecting informative variables
using variable depth distribution. <em>EAAI</em>, <em>97</em>, 104073.
(<a href="https://doi.org/10.1016/j.engappai.2020.104073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predictive maintenance of systems and their components in technical systems is a promising approach to optimize system usage and reduce system downtime. Various sensor data are logged during system operation for different purposes, but sometimes not directly related to the degradation of a specific component. Variable selection algorithms are necessary to reduce model complexity and improve interpretability of diagnostic and prognostic algorithms. This paper presents a forest-based variable selection algorithm that analyzes the distribution of a variable in the decision tree structure, called Variable Depth Distribution , to measure its importance. The proposed variable selection algorithm is developed for datasets with correlated variables that pose problems for existing forest-based variable selection methods. The proposed variable selection method is evaluated and analyzed using three case studies: survival analysis of lead–acid batteries in heavy-duty vehicles, engine misfire detection, and a simulated prognostics dataset. The results show the usefulness of the proposed algorithm, with respect to existing forest-based methods, and its ability to identify important variables in different applications. As an example, the battery prognostics case study shows that similar predictive performance is achieved when only 17% percent of the variables are used compared to all measured signals.},
  archive      = {J_EAAI},
  author       = {Sergii Voronov and Daniel Jung and Erik Frisk},
  doi          = {10.1016/j.engappai.2020.104073},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104073},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A forest-based algorithm for selecting informative variables using variable depth distribution},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of differential evolution to multi-objective
tuning of vibration spectrum analyzers based on microelectromechanical
systems. <em>EAAI</em>, <em>97</em>, 104071. (<a
href="https://doi.org/10.1016/j.engappai.2020.104071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The vibration spectrum is a feature used in several monitoring systems designed to diagnose many mechanical systems. The most usual way to obtain this feature is to input the time domain vibration data into a processor programmed with algorithms, such as the Fast Fourier Transform. Alternatively, this feature can be obtained more directly by using twin-microaccelerometers data and a simple electronic circuit. When compared to the spectrum calculation using the Fast Fourier Transform, the second strategy presents advantages related to the possibility to design microsensors with reduced size and low power consumption. However, the manufacturing process results into different physical parameters between the twin-accelerometers, and these differences raise the spectrum distortion. To overcome this drawback, in this work the tuning of the spectrum analyzer microdevice based on twin-microaccelerometers is proposed by adjusting the accelerometers actuation voltages amplitudes. To perform the tuning, three different variations of the Generalized Differential Evolution algorithm—an extension of Differential Evolution to solve multi-objective problems—with four boundary-handling strategies are used and their results are compared. The objective functions and constraints are based on the Fourier series composition of the spectrum analyzer system closed-loop gain—which depends on the actuation voltages. The advantages and disadvantages of applying this strategy are discussed in detail, as well as the results obtained for the Pareto-set approximation. The results obtained in MATLAB® simulations—specially the distortion-sensitivity compromise—are demonstrated, discussed, and validated.},
  archive      = {J_EAAI},
  author       = {Yara Quilles Marinho and Fabiano Fruett and Mateus Giesbrecht},
  doi          = {10.1016/j.engappai.2020.104071},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104071},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Application of differential evolution to multi-objective tuning of vibration spectrum analyzers based on microelectromechanical systems},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal design of a general type-2 fuzzy classifier for the
pulse level and its hardware implementation. <em>EAAI</em>, <em>97</em>,
104069. (<a
href="https://doi.org/10.1016/j.engappai.2020.104069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {. Nowadays, soft computing has been of great help in solving real-world problems and satisfying the needs in our everyday life. We require more than ever the development and implementation of models and techniques that assist in medical issues due to the recent pandemic. The aim of this work is the development and hardware implementation of a general type-2 fuzzy classifier for the pulse levels and the optimization of the general type-2 membership functions parameters using the Ant Lion Optimizer to compare results of type 1 and interval type-2 fuzzy classifiers with the patients of the Framingham database. This study additionally explains the implementation process of the general type-2 fuzzy classifier on the Jetson Nano hardware Development Board and the comparison of execution time with interval type-2, and type-1 fuzzy classifiers. This work offers a novel perspective in that the general type-2 fuzzy classifier can be implemented for embedded applications with excellent performance regarding hardware resources consumption.},
  archive      = {J_EAAI},
  author       = {Oscar Carvajal and Patricia Melin and Ivette Miramontes and German Prado-Arechiga},
  doi          = {10.1016/j.engappai.2020.104069},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104069},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimal design of a general type-2 fuzzy classifier for the pulse level and its hardware implementation},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep hybrid model for recommendation by jointly leveraging
ratings, reviews and metadata information. <em>EAAI</em>, <em>97</em>,
104066. (<a
href="https://doi.org/10.1016/j.engappai.2020.104066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although matrix factorization (MF) based collaborative filtering (CF) and deep learning approaches have achieved great success, there is still much room for improvement in recommender systems. Most of the existing approaches mainly adopt product ratings, reviews or content features in order to predict unknown rating for a user–item pair. In the discourse matter, some recent works attempted to obtain better latent representations of users and items by integrating different multi-source data, however, the heterogeneity of data is still a problem deserving study. Such models usually face two issues: (1) They extract the representations in a static and independent manner, thus ignoring the correlations between latent features learned from different information sources. (2) There is no unified framework that can mutually learn latent features from different sources such as ratings, reviews and meta-data of users, items and reviews. In the proposed model, called A Deep Hybrid Model for Recommendation (DHMR), we propose a joint deep model for learning higher-order non-linear latent feature interactions from reviews and metadata information. Further, we incorporate user–item interactions (from user–item ratings matrix) adopting MF model into the neural network. Thus, the proposed model consists of two parallel neural networks and an MF based model that are integrated by the attention and MLP layers at the top, learning lower-order (linear and non-linear) feature interactions of users and items separately and higher-order non-linear feature interactions jointly. Extensive experiments on real-world datasets demonstrate that DHMR significantly outperforms state-of-the-art recommendation models.},
  archive      = {J_EAAI},
  author       = {Zahid Younas Khan and Zhendong Niu and Ally S. Nyamawe and Ijaz ul Haq},
  doi          = {10.1016/j.engappai.2020.104066},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104066},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A deep hybrid model for recommendation by jointly leveraging ratings, reviews and metadata information},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularizing extreme learning machine by dual locally linear
embedding manifold learning for training multi-label neural network
classifiers. <em>EAAI</em>, <em>97</em>, 104062. (<a
href="https://doi.org/10.1016/j.engappai.2020.104062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning has been received much attention due to its applicability in machine learning problems. In current years, quite few approaches based on either extreme learning machine (ELM) or radial basis function (RBF) neural network have been proposed with the aim of increasing the efficiency of the multi-label classification. Most existing multi-label learning algorithms focus on information about the feature space. In this paper, our major intention is to regularize the objective function of multi-label learning methods via Locally Linear Embedding (LLE). To achieve this goal, two neural network architectures namely Multi-Label RBF (ML-RBF) and Multi-Label Multi Layer ELM (ML-ELM) are utilized. Then, a regularized multi-label learning method via feature manifold learning (RMLFM) and a regularized multi-label learning method via dual-manifold learning (RMLDM) are established for training two network structures. RMLDM simultaneously exploits the geometry structure of both feature and data space. Furthermore, eight different configurations of applying training algorithms (i.e., RMLFM and RMLDM) to model architectures (i.e., ML-RBF and ML-ELM) are considered for conducting comparisons. The validity and effectiveness of these eight classifiers are indicated by a number of experimental studies on several multi-label datasets. Furthermore, the experiments indicate that the efficiency of the classification can be improved considerably against some cutting-the-edge multi-label techniques for the neural classifiers in which the dual-manifold learning is used as the training method.},
  archive      = {J_EAAI},
  author       = {Mohammad Rezaei-Ravari and Mahdi Eftekhari and Farid Saberi-Movahed},
  doi          = {10.1016/j.engappai.2020.104062},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104062},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Regularizing extreme learning machine by dual locally linear embedding manifold learning for training multi-label neural network classifiers},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A bidirectional graph neural network for traveling salesman
problems on arbitrary symmetric graphs. <em>EAAI</em>, <em>97</em>,
104061. (<a
href="https://doi.org/10.1016/j.engappai.2020.104061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has recently been shown to provide great achievement to the traveling salesman problem (TSP) on the Euclidean graphs. These methods usually fully represent the graph by a set of coordinates, and then captures graph information from the coordinates to generate the solution. The TSP on arbitrary symmetric graphs models more realistic applications where the working graphs maybe sparse, or the distance between points on the graphs may not satisfy the triangle inequality. When prior learning-based methods being applied to the TSP on arbitrary symmetric graphs, they are not capable to capture graph features that are beneficial to produce near-optimal solutions. Moreover, they suffer from serious exploration problems. This paper proposes a bidirectional graph neural network (BGNN) for the arbitrary symmetric TSP. The network learns to produce the next city to visit sequentially by imitation learning. The bidirectional message passing layer is designed as the most important component of BGNN. It is able to encode graphs based on edges and partial solutions. By this way, the proposed approach is much possible to construct near-optimal solutions for the TSP on arbitrary symmetric graphs, and it is able to be combined with informed search to further improve performance.},
  archive      = {J_EAAI},
  author       = {Yujiao Hu and Zhen Zhang and Yuan Yao and Xingpeng Huyan and Xingshe Zhou and Wee Sun Lee},
  doi          = {10.1016/j.engappai.2020.104061},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104061},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A bidirectional graph neural network for traveling salesman problems on arbitrary symmetric graphs},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid evolutionary algorithms and lagrangian relaxation for
multi-period star hub median problem considering financial and service
quality issues. <em>EAAI</em>, <em>97</em>, 104056. (<a
href="https://doi.org/10.1016/j.engappai.2020.104056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hub facilities are centralized locations that consolidate and distribute the commodities in transportation networks. In many real world applications, transport service providers may prefer to lease hub facilities for a time horizon rather than being owned or constructed. In this paper, a modeling framework is proposed for the multi-period hub location problem that arises in the design of the star–star network with two types of hubs and links. It includes a designated static central hub, some movable hub facilities and a set of nodes with pairwise demands. A periodic growth in the amount of budget is considered at each period to expand the transportation network and an interest rate is also applied to the unused budget available during each period. Since the overall quality of services in the hub and spoke systems rely on the length of the paths, upper bound constraints are considered for the paths between nodes. Numerical experiments are carried out to show the applicability of the proposed model. Due to the computational complexity of the model, an improved genetic algorithm (GA) and a hybrid particle swarm optimization (HPSO) are utilized to find near optimal solutions. Both algorithms employ caching strategy to improve the computation times. Moreover, the HPSO benefits from genetic operators and local search methods to update the particles. In order to assess the effectiveness of the proposed methods, the results are compared with a pure GA and a proper lower bound achieved by a Lagrangian relaxation method.},
  archive      = {J_EAAI},
  author       = {Hamid Tikani and Reza Ramezanian and Mostafa Setak and Tom Van Woensel},
  doi          = {10.1016/j.engappai.2020.104056},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104056},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Hybrid evolutionary algorithms and lagrangian relaxation for multi-period star hub median problem considering financial and service quality issues},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A powerful lichtenberg optimization algorithm: A damage
identification case study. <em>EAAI</em>, <em>97</em>, 104055. (<a
href="https://doi.org/10.1016/j.engappai.2020.104055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization is an essential tool to minimize or maximize functions, obtaining optimal results on costs, mass, energy, gains, among others. Actual problems may be multimodal, nonlinear, and discontinuous and may not be minimized by classical analytical methods that depend on the gradient. In this context, there are metaheuristic algorithms inspired by natural phenomena to optimize real engineering problems. No algorithm is the worst or the best, but more efficient for a given problem. Thus, a new nature-inspired algorithm called Lichtenberg Optimization Algorithm (LA) is applied in this study to solve a complex inverse damage identification problem in mechanical structures built by composite material. To verify the performance of the new algorithm, both LA and Finite Element Method (FEM) were used to identify delamination damage and the results were compared to other algorithms such as Genetic Algorithm (GA) and SunFlower Optimization (SFO). LA was shown to be a powerful damage identification tool since it was able to detect damage even in particular situations like noisy response and low damage severity.},
  archive      = {J_EAAI},
  author       = {João Luiz Junho Pereira and Matheus Brendon Francisco and Sebastião Simões da Cunha Jr. and Guilherme Ferreira Gomes},
  doi          = {10.1016/j.engappai.2020.104055},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104055},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A powerful lichtenberg optimization algorithm: A damage identification case study},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep softmax collaborative representation for robust
degraded face recognition. <em>EAAI</em>, <em>97</em>, 104052. (<a
href="https://doi.org/10.1016/j.engappai.2020.104052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (DCNN) have attracted much attention in the field of face recognition because they have achieved high performance than other approaches in the so-called in-the-wild datasets. However, in many real-world applications of face recognition, the performance of CNN-based algorithms is significantly decreased when images contain various kinds of degradations caused by random noise, motion blur, compression artifacts, uncontrolled illumination, and occlusion. Moreover, this is because the main weakness of existing DCNN models is the overfitting problem. To boost the recognition performance of state-of-the-art deep learning networks, we propose a deep softmax collaborative representation-based network, which can be used as a divide-and-conquer algorithm to help multiple DCCNs work together more effectively to solve multiple sub-problems of face reconstruction and classification. We demonstrated several experiments with challenging face recognition datasets. Our extensive experiments demonstrate that our proposed method is more robust and efficient in dealing with the challenging real-world problems in face recognition compared to related state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Duc My Vo and Duc Manh Nguyen and Sang-Woong Lee},
  doi          = {10.1016/j.engappai.2020.104052},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104052},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Deep softmax collaborative representation for robust degraded face recognition},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Concurrent multi-process graph-based design component
synthesis: Framework and algorithm. <em>EAAI</em>, <em>97</em>, 104051.
(<a href="https://doi.org/10.1016/j.engappai.2020.104051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facing today’s increasingly complex and high-demanded design missions, the abundant and multifarious design components distributed in different disciplines and locations should be fully considered and elaborately synthesized. However, this involves a large amount of data processing workload which heavily restrains the application and development of the traditional graph-based synthesis methods. Therefore, a concurrent multi-process graph-based design component synthesis method is proposed to break the bottleneck. With this method, the heavy workload can be dynamically and efficiently decentralized and shared in a group of processes working simultaneously and concurrently. As an application, a software prototype is presented, and the design component synthesis of a biochemical heating system is completed with it.},
  archive      = {J_EAAI},
  author       = {Bin Chen and Jie Hu and Jin Qi and Weixing Chen},
  doi          = {10.1016/j.engappai.2020.104051},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104051},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Concurrent multi-process graph-based design component synthesis: Framework and algorithm},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Digital watermarking with improved SMS applied for QR code.
<em>EAAI</em>, <em>97</em>, 104049. (<a
href="https://doi.org/10.1016/j.engappai.2020.104049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of information technology, infringements have become increasingly serious. Digital watermarking is an effective method to protect information. The current watermarking technology still has room for further improvement in imperceptibility and robustness. This paper proposes an improved watermarking technology using meta-heuristic algorithm. Further, Quick Response code (QR code) is used as a carrier to transmit information. The improved Discrete Wavelet Transform-Singular Value Decomposition (DWT-SVD) is used to hide the watermark into the QR code. Therefore, digital watermarking is realized on the QR code. In the common watermark embedding methods, the digital watermark is related to the embedding strength. How to find a suitable embedding factor and reduce distortion is of great significance to these watermarking algorithms. This paper mainly proposes two novel algorithms based on States of Matter Search (SMS) algorithm to find suitable embedding factors. The first algorithm uses an adaptive parameter to control the movement of particles called the adaptive step States of Matter Search (sSMS). The second algorithm incorporates co-evolutionary matrix to enhance the search capability named Co-evolution States of Matter Search (CSMS). DWT-SVD is updated through two algorithms to acquire optimal embedding strength factors on the QR code watermarking. By adjusting the embedding strength factors, the intensity of the watermark embedded in different frequency domains would be modified. The experimental results have higher PSNR and the QR code can still be decoded by a general decoder. It shows that the proposed approaches are practicable and effective.},
  archive      = {J_EAAI},
  author       = {Jeng-Shyang Pan and Xiao-Xue Sun and Shu-Chuan Chu and Ajith Abraham and Bin Yan},
  doi          = {10.1016/j.engappai.2020.104049},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104049},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Digital watermarking with improved SMS applied for QR code},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Microblog sentiment analysis via embedding social contexts
into an attentive LSTM. <em>EAAI</em>, <em>97</em>, 104048. (<a
href="https://doi.org/10.1016/j.engappai.2020.104048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of microblogging services like Twitter and Sina Weibo, users are able to post various contents on breaking news, public events, or products conveniently and swiftly. These massive contents carry users’ mass sentiment and opinions on various topics, which are a kind of useful and timely source. Traditional microblog sentiment analysis methods often assume that microblogs are independent and identically distributed, they ignore the fact that the microblogs are networked data. Although some methods take the relations between microblogs into consideration, they only use shallow network features which are not sufficient, such as neighbors. Besides, these methods are content-based methods because they cannot use social context information in the prediction stage. To solve this problem, in this paper we use a deep learning method to fully capture the features of microblog relations including both the implicit and explicit ones and use these features to promote microblog sentiment analysis results. Specifically, we first construct a graph which models the relations between microblogs inspired by sentiment consistency and emotional contagion theories. Then we embed the microblog graph and get a continuous vector representation for social contexts of each microblog. After that, we propose a novel neural network to integrate social context knowledge with text information. To handle the problem that different words have different contributions to the classification result, we introduce the attention mechanism into our model. We conduct experiments on three publicly released datasets. The experimental results show that our proposed model can outperform state-of-the-art methods consistently and significantly.},
  archive      = {J_EAAI},
  author       = {Jing Yang and Xiaomei Zou and Wei Zhang and Hongyu Han},
  doi          = {10.1016/j.engappai.2020.104048},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104048},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Microblog sentiment analysis via embedding social contexts into an attentive LSTM},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Step-wise multi-grained augmented gradient boosting decision
trees for credit scoring. <em>EAAI</em>, <em>97</em>, 104036. (<a
href="https://doi.org/10.1016/j.engappai.2020.104036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Credit scoring is an important financial tool for banks to determine whether to issue the loan to potential borrowers. Ensemble algorithms, which mainly can be divided into bagging ensembles and boosting ensembles, have shown great promise for credit scoring. However, some problems need to be further addressed: (1) Bagging-type algorithms enrich the feature diversity while keep the training target unchanged. However, these methods acting as feature augmentation process that highly rely on the training targets may increase the statistical similarity of the prediction results. (2) Though boosting-type ensemble algorithms avoid the problem of high prediction similarity, boosting algorithms always work on the original credit features leading to the lack of feature diversity. (3) A more intelligent credit risk management system should well balance the accuracy and its interpretability. Based on the above considerations, in this study, a step-wise multi-grained augmented gradient boosting decision trees (mg-GBDT) is proposed for credit scoring. In the proposed method, a multi-grained scanning is introduced for feature augmentation, which enriches the input feature of GBDT; the GBDT-based step-wisely optimization mechanism ensures low-deviation of credit scoring; besides, the proposed method inherits the good interpretability of tree-based structure, which provides intuitive reference results for policy-makers. Experiments on 6 credit datasets show that the proposed method outperforms classic GBDT. Moreover, numerical results indicate that mg-GBDT provides an alternative to neural network-based feature enhancement. Finally, the global interpretation results and the visualized decision path demonstrate that mg-GBDT can be a good choice for accurate credit scoring interpretation.},
  archive      = {J_EAAI},
  author       = {Wanan Liu and Hong Fan and Min Xia},
  doi          = {10.1016/j.engappai.2020.104036},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104036},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Step-wise multi-grained augmented gradient boosting decision trees for credit scoring},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multiclass classification using one-versus-all approach
with the differential partition sampling ensemble. <em>EAAI</em>,
<em>97</em>, 104034. (<a
href="https://doi.org/10.1016/j.engappai.2020.104034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The One-versus-all(OVA) approach is one of the mainstream decomposition methods by which multiple binary classifiers are used to solve multiclass classification tasks. However, it exists the problems of serious class imbalance. This paper proposes a differential partition sampling ensemble method(DPSE) in the OVA framework. The number of majority samples and that of the minority samples in each binary training dataset are used as the upper and lower limits of the sampling interval respectively. Within this range, the construction process of the arithmetic sequence is simulated to generate the set containing multiple different sampling numbers with equal intervals. All samples are divided into safe examples, borderline examples, rare examples, and outliers according to the neighborhood information, then Random undersampling for safe samples(s-Random undersampling) and SMOTE for borderline examples and rare examples (br-SMOTE) are proposed based on the distribution characteristics of the classes. In each iteration, according to the number of differential sampling, the two methods are used to undersample or oversample the majority and minority in each binary training dataset to balance the number of positive and negative samples, which preserves the characteristic of the class structure as much as possible. Balanced training sets are used to train the binary classification model with multiple sub classifiers. The thorough experiments performed on 27 KEEL public multiclass datasets show that DPSE outperforms the typical methods in the OVA scheme, the One-versus-One scheme or direct way in classification performance.},
  archive      = {J_EAAI},
  author       = {Xin Gao and Yang He and Mi Zhang and Xinping Diao and Xiao Jing and Bing Ren and Weijia Ji},
  doi          = {10.1016/j.engappai.2020.104034},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104034},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A multiclass classification using one-versus-all approach with the differential partition sampling ensemble},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reverse nearest neighbors bhattacharyya bound linear
discriminant analysis for multimodal classification. <em>EAAI</em>,
<em>97</em>, 104033. (<a
href="https://doi.org/10.1016/j.engappai.2020.104033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, an effective improvement of linear discriminant analysis (LDA) called L2-norm linear discriminant analysis via the Bhattacharyya error bound estimation (L2BLDA) was proposed in its adaptability and nonsingularity. However, L2BLDA assumes all samples from the same class are independently identically distributed (i.i.d.). In real world, this assumption sometimes fails. To solve this problem, in this paper, reverse nearest neighbor (RNN) technique is imbedded into L2BLDA and a novel linear discriminant analysis named RNNL2BLDA is proposed. Rather than using classes to construct within-class and between-class scatters, RNNL2BLDA divides each class into subclasses by using RNN technique, and then defines the scatter matrices on these classes that may contain several subclasses. This makes RNNL2BLDA get rid of the i.i.d.assumption in L2BLDA and applicable to multimodal data, which have mixture of Gaussian distributions. In addition, by setting a threshold in RNN, RNNL2BLDA achieves robustness. RNNL2BLDA can be solved through a simple standard generalized eigenvalue problem. Experimental results on an artificial data set, some benchmark data sets as well as two human face databases demonstrate the effectiveness of the proposed method.},
  archive      = {J_EAAI},
  author       = {Yan-Ru Guo and Yan-Qin Bai and Chun-Na Li and Yuan-Hai Shao and Ya-Fen Ye and Cheng-zi Jiang},
  doi          = {10.1016/j.engappai.2020.104033},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104033},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Reverse nearest neighbors bhattacharyya bound linear discriminant analysis for multimodal classification},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SLAM; definition and evolution. <em>EAAI</em>, <em>97</em>,
104032. (<a
href="https://doi.org/10.1016/j.engappai.2020.104032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Simultaneous Localization and Mapping (SLAM) is a key problem in the field of Artificial Intelligence and mobile robotics that addresses the problem of localization and mapping when a prior map of the workspace is not accessible. The determination of the SLAM problem has gained significant research momentum up to recent times. In this paper, firstly the problem of SLAM, its general model, framework, the difficulties, and leading approaches are described. Secondly, the progress of SLAM solving algorithms is surveyed throughout history. Pre-development, early SLAM solving algorithms, recent and present methods are presented and the progression of the state-of-art is reviewed based on the impact of leading approaches. We have selected some of the most important approaches of all time (1986–2019) to understand the research development, current trends, and intellectual structure of SLAM. Furthermore, from the trend of recent studies and the existence of difficult problems, a brief but sufficient review in the visual SLAM with the most outstanding approaches is presented. This paper provides one single sufficient review that allows researchers to understand the trend of SLAM, where it has come from, where it is going to and what needs to be more investigated in the SLAM-related field area. The future, in other words, the potential most important approaches inspiring the future researches in the SLAM problem can be seen. This paper will be an efficient overview and a valuable survey for introducing the SLAM solving approaches in mobile robotics as well as the general application of SLAM.},
  archive      = {J_EAAI},
  author       = {Hamid Taheri and Zhao Chun Xia},
  doi          = {10.1016/j.engappai.2020.104032},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104032},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {SLAM; definition and evolution},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new belief divergence measure for dempster–shafer theory
based on belief and plausibility function and its application in
multi-source data fusion. <em>EAAI</em>, <em>97</em>, 104030. (<a
href="https://doi.org/10.1016/j.engappai.2020.104030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dempster–Shafer theory (DST) has extensive and important applications in information fusion. However, when the evidences are highly conflicting with each other, the Dempster’s combination rule often leads to a series of counter-intuitive results. In this paper, we propose a new belief divergence measure for DST, which can reflect the correlation of different kinds of subsets by taking into account the belief measure and plausibility measure of mass function. Furthermore, the proposed divergence measure has the properties of boundedness, non-degeneracy and symmetry. In addition, a new multi-source data fusion method is proposed based on the proposed divergence measure. This method utilizes not only the credibility weights but also the information volume weights to determine the comprehensive weights of evidences, which can fully reflect the relationship between evidences. Application cases and simulation results show that the proposed method is reasonable and effective.},
  archive      = {J_EAAI},
  author       = {Hongfei Wang and Xinyang Deng and Wen Jiang and Jie Geng},
  doi          = {10.1016/j.engappai.2020.104030},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104030},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {A new belief divergence measure for Dempster–Shafer theory based on belief and plausibility function and its application in multi-source data fusion},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conformance testing of ontologies through ontology
requirements. <em>EAAI</em>, <em>97</em>, 104026. (<a
href="https://doi.org/10.1016/j.engappai.2020.104026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, several standard ontologies have been developed to maximise semantic interoperability in different domains; such standard ontologies ensure quality and integrity when describing a domain. Therefore, mechanisms to guarantee that developers build ontologies that conform to such standards are needed. However, while in fields such as Software Engineering or industry, conformance testing plays an essential role during product development, in the Ontology Engineering field there is a lack of techniques for this type of testing. This work introduces an ontology conformance testing method to analyse conformance between an ontology and a standard based on the standard requirements. Grounded on this method, the work also presents a minimum common knowledge identification method for analysing how a group of standards covers a particular domain and for identifying whether there are conflicts between them. This work has been validated by analysing the conformance between an ontology network and a set of standards on the Internet of Things domain, and by analysing the minimum common knowledge between such standards. This analysis shows that the conformance between ontologies and standards is mostly related to definition of classes. Furthermore, the analysis shows that although the analysed standards are related to the same domain, they are created to describe different areas of concern and, thus, there is a minimum overlap between them. Finally, it was concluded that the quality of the conformance analysis depends on the quality of the requirements specification: the more precise the requirements, the more precise the analysis between ontologies and standards.},
  archive      = {J_EAAI},
  author       = {Alba Fernández-Izquierdo and Raúl García-Castro},
  doi          = {10.1016/j.engappai.2020.104026},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104026},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Conformance testing of ontologies through ontology requirements},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Complex ISAR target recognition using deep adaptive
learning. <em>EAAI</em>, <em>97</em>, 104025. (<a
href="https://doi.org/10.1016/j.engappai.2020.104025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target recognition in real-world environment is a most important and challenging computer vision task. In this paper, a real-world complex ISAR target recognition method is proposed on a computationally limited platform using deep adaptive learning (DAL). Particularly, adaptive multimodal mechanism (AMM) is presented to efficiently handle the complex multimodal recognition problem, which substantially improves CNNs’ sampling and transformation capability and significantly increases output feature maps’ resolutions. Moreover, feature learning, attribute prediction, relation mining, image matching, image understanding, image summarization, and label expansion are considered in a unified framework. Extensive qualitative and quantitative experiments are performed, and the results show the proposed method outperforms the several state-of-the-art methods.},
  archive      = {J_EAAI},
  author       = {Bin Xue and Wanjun Yi and Feng Jing and Shuai Wu},
  doi          = {10.1016/j.engappai.2020.104025},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104025},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Complex ISAR target recognition using deep adaptive learning},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AONet: Active offset network for crowd flow prediction.
<em>EAAI</em>, <em>97</em>, 104022. (<a
href="https://doi.org/10.1016/j.engappai.2020.104022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting crowd flow is of great importance to public safety and traffic management. The crowd flow is difficult to predict accurately and timely due to the uncertainty of the future positions. In this paper, we propose a novel Active Offset Network (AONet), in which ActiveGRU (Active Gate Recurrent Unit) is designed to predict the variation of pedestrians’ positions in the crowd flow. Its inner location-variant recurrent structure is implemented by utilizing convolution operation on low dimensional spatio-temporal sequences to obtain fractional offset locations. Afterwards, the sampling locations are determined by bilinear interpolation on fractional offset locations. Moreover, a probabilistic sparse strategy is introduced to reduce the links between sampling locations during supervised training. Finally, the experiments over popular benchmarks demonstrate that our method can actively characterize the future positions of pedestrians. Meanwhile, the performance of the proposed AONet is superior over state-of-art baselines with regard to both accuracy and computational savings.},
  archive      = {J_EAAI},
  author       = {Dafeng Wang and Qian Ma and Naiyao Wang and Xuanzhe Fan and Mingyu Lu and Hongbo Liu},
  doi          = {10.1016/j.engappai.2020.104022},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104022},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {AONet: Active offset network for crowd flow prediction},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Iterated two-phase local search for the colored traveling
salesmen problem. <em>EAAI</em>, <em>97</em>, 104018. (<a
href="https://doi.org/10.1016/j.engappai.2020.104018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The colored traveling salesmen problem (CTSP) is a generalization of the popular traveling salesman problem with multiple salesmen. In CTSP, the cities are divided into m exclusive city sets ( m is the number of salesmen) and one shared city set. The goal of CTSP is to determine a shortest Hamiltonian circuit (also called route or tour) for each of the m salesmen satisfying that (1) each route includes all cities of an exclusive city set and some (or all) cities of the shared city set, and (2) each city of the shared city set is included in one unique route. CTSP is a relevant model for a number of practical applications and is known to be computationally challenging. We present the first iterated two-phase local search algorithm for this important problem which combines a local optima exploration phase and a local optima escaping phase. We show computational results on 65 common benchmark instances to demonstrate its effectiveness and especially report 22 improved upper bounds. We make the source code of the algorithm publicly available to facilitate its use in future research and real applications.},
  archive      = {J_EAAI},
  author       = {Pengfei He and Jin-Kao Hao},
  doi          = {10.1016/j.engappai.2020.104018},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104018},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Iterated two-phase local search for the colored traveling salesmen problem},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective constructive heuristics and discrete bee colony
optimization for distributed flowshop with setup times. <em>EAAI</em>,
<em>97</em>, 104016. (<a
href="https://doi.org/10.1016/j.engappai.2020.104016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed permutation flowshop scheduling problem (DPFSP) has been a hot issue in recent years. Due to the practical relevance of sequence-dependent setup time (SDST), we consider the DPFSP with SDST to minimize makespan. For the purpose, we propose three constructive heuristics and an effective discrete artificial bee colony (DABC) algorithm. All the heuristics are based on a greedy assignment rule and a local search of job blocks in each factory. In the local search, three different setup times are respectively considered for inserting a job block. In the DABC, to balance the local exploitation and the global exploration, we propose six composite neighborhood operators according to the problem characteristics. The first three are based on insertion and swap operators, and the second three have a close relationship with the critical factory. A problem-oriented local search method is developed to improve the best individual in the population. A comprehensive computational campaign against the closely related and state-of-the-art algorithms in the literature shows that both the proposed heuristics and DABC are very effective for solving the problem under consideration.},
  archive      = {J_EAAI},
  author       = {Jiang-Ping Huang and Quan-Ke Pan and Zhong-Hua Miao and Liang Gao},
  doi          = {10.1016/j.engappai.2020.104016},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104016},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Effective constructive heuristics and discrete bee colony optimization for distributed flowshop with setup times},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of support vector machine through the use of
metaheuristic algorithms in forecasting TBM advance rate. <em>EAAI</em>,
<em>97</em>, 104015. (<a
href="https://doi.org/10.1016/j.engappai.2020.104015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advance rate (AR) of a tunnel boring machine (TBM) in hard rock condition is a key parameter for the successful accomplishment of a tunneling project, and the proper and reliable prediction of this parameter can lead to minimizing the risks associated to high capital costs and scheduling for such projects. This research aims at optimizing the hyper-parameters of the support vector machine (SVM) technique through the use of three optimization algorithms, namely, gray wolf optimization (GWO), whale optimization algorithm (WOA) and moth flame optimization (MFO), in forecasting TBM AR. In fact, the role of these optimization techniques is to optimize the hyperparameters ‘C’ and ‘gamma’ of the SVM model to get higher performance prediction. To develop the hybrid SVM-based models, 1,286 sample sets of data collected from a water transfer tunnel in Malaysia comprising seven input variables, i.e., rock mass rating, uniaxial compressive strength, Brazilian tensile strength, rock quality designation, weathering zone, thrust force and revolution per minute, and one output variable, i.e., TBM AR, were considered and used. Several GWO-SVM, WOA-SVM and MFO-SVM models were constructed to predict TBM AR considering their effective parameters. The accuracy levels of the proposed models were assessed using four statistical indices, i.e., the coefficient of determination (R 2 ), root mean squared error (RMSE), mean absolute error (MAE), and variance accounted for (VAF). Modeling results revealed that the MFO algorithm can capture better hyper-parameters of the SVM model in predicting TBM AR among all three hybrid models. R 2 of (0.9623 and 0.9724), RMSE of (0.1269 and 0.1155), and VAF of (96.24 and 97.34%), respectively, for training and test stages of the MFO-SVM model confirmed that this hybrid SVM model is a powerful and applicable technique addressing problems related to TBM performance with a high level of accuracy.},
  archive      = {J_EAAI},
  author       = {Jian Zhou and Yingui Qiu and Shuangli Zhu and Danial Jahed Armaghani and Chuanqi Li and Hoang Nguyen and Saffet Yagiz},
  doi          = {10.1016/j.engappai.2020.104015},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104015},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Optimization of support vector machine through the use of metaheuristic algorithms in forecasting TBM advance rate},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automation of hemocompatibility analysis using image
segmentation and supervised classification. <em>EAAI</em>, <em>97</em>,
104009. (<a
href="https://doi.org/10.1016/j.engappai.2020.104009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hemocompatibility of blood-contacting medical devices remains one of the major challenges in biomedical engineering and makes research in the field of new and improved materials inevitable. However, current in-vitro test and analysis methods are still lacking standardization and comparability, which impedes advances in material design. For example, the optical platelet analysis of material in-vitro hemocompatibility tests is carried out manually or semi-manually by each research group individually. As a step towards standardization, this paper proposes an automation approach for the optical platelet count and analysis. To this end, fluorescence images are segmented using Zach’s convexification of the multiphase-phase piecewise constant Mumford–Shah model. The non-background components then need to be classified as platelet or no platelet. For this purpose, a supervised random forest is applied to feature vectors derived from the components using features like area, perimeter and circularity. With an overall high accuracy ( &gt; 93 %) and low error rates ( ≤ 5 %), the random forest achieves reliable results. This is supported by high areas under the receiver–operator characteristic curve ( ≥ 0.94) and the prediction–recall curve ( ≥ 0.77), respectively. We developed a novel method for a fast, user-independent and reproducible analysis of material hemocompatibility tests. The automatized analysis method overcomes the current obstacles in the way of standardized in-vitro material testing and is therefore a unique and powerful tool for advances in biomaterial research.},
  archive      = {J_EAAI},
  author       = {Johanna C. Clauser and Judith Maas and Jutta Arens and Thomas Schmitz-Rode and Ulrich Steinseifer and Benjamin Berkels},
  doi          = {10.1016/j.engappai.2020.104009},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104009},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Automation of hemocompatibility analysis using image segmentation and supervised classification},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete crow-inspired algorithms for traveling salesman
problem. <em>EAAI</em>, <em>97</em>, 104006. (<a
href="https://doi.org/10.1016/j.engappai.2020.104006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crow search algorithm is one of bio-inspired optimization algorithms which is essentially derived for solving continuous based optimization problems. Although many main-frame discrete optimizers are available, they still have some performance challenges. This paper proposes three discrete crow inspired algorithms for enhancing the performance of the original crow search algorithm when it is applied for solving discrete traveling salesman problems. The proposed algorithms are derived based on modular arithmetic, basic operators and dissimilar solutions techniques. Each technique guarantees switching from continuous spaces into discrete spaces without losing information. Such algorithms are called Modular Arithmetic, Basic Operators, and Dissimilar Solutions algorithms. For evaluating their performance, the proposed algorithms are compared with the most state-of-the-art discrete optimizers for solving 111 instances of traveling salesman problems. Simulation results illustrate that, the performance of the proposed algorithms is much better than the performance of most state-of-the-art discrete optimizers in terms of the average optimal solutions accuracy, the average errors from the optimal solutions and the average of computational time.},
  archive      = {J_EAAI},
  author       = {Ghaleb H. Al-Gaphari and Rowaida Al-Amry and Afrah S. Al-Nuzaili},
  doi          = {10.1016/j.engappai.2020.104006},
  journal      = {Engineering Applications of Artificial Intelligence},
  month        = {1},
  pages        = {104006},
  shortjournal = {Eng. Appl. Artif. Intell.},
  title        = {Discrete crow-inspired algorithms for traveling salesman problem},
  volume       = {97},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
