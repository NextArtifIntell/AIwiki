<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>MLA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="mla---106">MLA - 106</h2>
<ul>
<li><details>
<summary>
(2021). Integrating semantic edges and segmentation information for
building extraction from aerial images using UNet. <em>MLA</em>,
<em>6</em>, 100194. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Understanding urban dynamics, such as estimating population, urban development, and several other uses, necessitates up-to-date large-scale building maps. Since aerial imagery provides enough textural and structural details, it has been utilized as a critical data source for building detection. However, accurate mapping of building objects from aerial imagery is a challenging task. This problem is attributed due to presence of vegetation and shadows in images that present similar spectral values and transparency as a building class. To deal with the issues mentioned above, we offer a new deep-learning structure named MultiRes-UNet network, which is an improved version of the original UNet network. In the proposed network, we utilized the MultiRes block to assimilate the features learned from the data at various scales and comprise some more spatial details . Also, we suggest the incorporation of several convolutional operations along with the skip connections to mitigate the differences between the encode–decoder features. Furthermore, we integrated semantic edge information with semantic polygons to solve the issue of irregular semantic polygons and enhance the boundary of semantic polygons. We tested our network on aerial images for roof segmentation dataset, and the experimental results exhibited that the proposed network can improve the quantitative results of Intersection Over Union to 0.78\% after adding semantic edges. We also used state-of-the-art comparative models such as UNet, DeeplabV3, ResNet , and FractalNet networks to show the competency of the introduced network, and the results prove the success of the introduced network for building object extraction from aerial imagery.},
  archive      = {J_MLA},
  author       = {Abolfazl Abdollahi and Biswajeet Pradhan},
  doi          = {10.1016/j.mlwa.2021.100194},
  journal      = {Machine Learning with Applications},
  pages        = {100194},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Integrating semantic edges and segmentation information for building extraction from aerial images using UNet},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explainable AI in drought forecasting. <em>MLA</em>,
<em>6</em>, 100192. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Droughts are one of the disastrous natural hazards which has severe impacts on agricultural production, economy, and society. One of the critical steps for effective drought management is developing a robust forecasting model and understanding how the variables affect the model outcomes. The present study forecasts SPI-12 at a lead time of 3 months, using the Long Short-Term Memory (LSTM) model, and further interprets the spatial and temporal relationship between variables and forecasting results using SHapley Additive exPlanations (SHAP). The developed model is tested in four different regions in New South Wales (NSW), Australia. SPI-12 was computed using monthly rainfall data collected from Scientific Information for Land Owners (SILO) for 1901–2018. The model was trained from 1901–2000 and tested from 2001–2018, and the performance was measured using Coefficient of Determination (R 2 ), Nash–Sutcliffe Efficiency (NSE) and Root-Mean-Square-Error (RMSE). To understand the underlying impact of variables on the model outcomes, SHAPley values were calculated for the entire testing period and also at three different temporal ranges, which are during the Millennium Drought (2001–2010), post drought period (2011–2018) and at a seasonal scale (summer months). The comparison of the results shows a significant variation in the impact of variables on forecasting, both temporally and spatially. It also shows the need to study the model outcomes for specific regions and for a shorter duration than the entire testing period. This is a first of its study towards interpreting the forecasting model in drought studies, which could help understand the behaviour of drought variables.},
  archive      = {J_MLA},
  author       = {Abhirup Dikshit and Biswajeet Pradhan},
  doi          = {10.1016/j.mlwa.2021.100192},
  journal      = {Machine Learning with Applications},
  pages        = {100192},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Explainable AI in drought forecasting},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Structural health monitoring of exterior beam–column
subassemblies through detailed numerical modelling and using various
machine learning techniques. <em>MLA</em>, <em>6</em>, 100190. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100190">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Structural health monitoring of beam–column joints is paramount, as they are critical load-carrying components of reinforced concrete buildings. Evaluating the ultimate joint shear capacity and failure modes of beam–columns, especially in seismic events, is a crucial task, especially in view of life safety concerns. Traditional methods used to determine the joint shear capacity of beam–column joints are often inaccurate and cumbersome owing to improper accounting of governing parameters that influence beam–column joints’ behaviour. In this study, the performance of machine learning-based structural health monitoring techniques are evaluated in predicting the joint shear capacity and the mode of failure for the exterior beam–column joint taking into account their complex structural behaviour through both numerical modelling and various machine learning techniques. The data used to train and test the model was collected from laboratory experiments and other test data available in the literature. The results indicated the superiority of the proposed particle swarm optimized artificial neural network (PSO-ANN) and XGboost over previously used approaches. Hence, the proposed techniques can be efficiently used for monitoring of structural performance by making informed decision regarding condition assessment of RC buildings.},
  archive      = {J_MLA},
  author       = {Giuseppe Santarsiero and Mayank Mishra and Manav Kumar Singh and Angelo Masi},
  doi          = {10.1016/j.mlwa.2021.100190},
  journal      = {Machine Learning with Applications},
  pages        = {100190},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Structural health monitoring of exterior beam–column subassemblies through detailed numerical modelling and using various machine learning techniques},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Machine learning tensile strength and impact toughness of
wheat straw reinforced composites. <em>MLA</em>, <em>6</em>, 100188. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100188">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wheat straw reinforced composite is considered as a “green composite” as it utilizes biodegradable and recyclable food waste materials as reinforcing materials. Mechanical properties, such as tensile strength and impact toughness, are greatly dependent on the composite content and processing parameters. While compression molding is one of popular methods to fabricate the wheat straw/polypropylene composite, experimental trials to achieve targeted mechanical properties can be time-consuming and expensive. In this work, we develop the Gaussian process regression model to present the relationship among the fiber content, processing parameters of the compression molding, and mechanical performance of wheat straw reinforced polypropylene composites. The model achieves a correlation coefficient of 99.13\% (95.68\%), a root mean square error of 0.0857 (0.4369), and a mean absolute error of 0.0693 (0.3265) for tensile strength (impact toughness). The models are simple and fast to implement, produce predictions with high accuracy, and thus might be considered as efficient tools for mechanical property estimations. Should data become available, the model may be extended to include other descriptors, such as the wheat straw length, size distribution, and chemical treatment parameters.},
  archive      = {J_MLA},
  author       = {Yun Zhang and Xiaojie Xu},
  doi          = {10.1016/j.mlwa.2021.100188},
  journal      = {Machine Learning with Applications},
  pages        = {100188},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning tensile strength and impact toughness of wheat straw reinforced composites},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of machine learning algorithms for prediction of
sinter machine productivity. <em>MLA</em>, <em>6</em>, 100186. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100186">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sinter machine productivity is key techno-economic parameter of an integrated steel plant. It depends upon the composition of different constituents like iron ore fines, flux and coke breeze which are agglomerated to produce sinter for blast furnaces. It is difficult to assess the interdependence of these constituents and their effect on sinter productivity through physical experimentation. In this paper, machine learning and data analytics approach have been applied to predict the sinter machine productivity. Industrial data of sinter machine productivity from an integrated steel plant have been collected. Linear regression and artificial neural network (ANN) models were developed to predict sinter machine productivity with the composition of constituent materials of the agglomerate as model inputs. The ANN model, developed in the present work, agrees well with measured sinter machine productivity. Sensitivity analysis identified that, percentage of MgO in flux and CaO in sinter have a highly detrimental effect whereas total Fe content in iron ore fines and percentage of SiO 2 in sinter have the most favorable impact on sinter machine productivity.},
  archive      = {J_MLA},
  author       = {Arpit Mallick and Subhra Dhara and Sushant Rath},
  doi          = {10.1016/j.mlwa.2021.100186},
  journal      = {Machine Learning with Applications},
  pages        = {100186},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Application of machine learning algorithms for prediction of sinter machine productivity},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AutoEncoder-based feature ranking for alzheimer disease
classification using PET image. <em>MLA</em>, <em>6</em>, 100184. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100184">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method of ranking the effectiveness of brain region of interest (ROI) in order to separate Normal Control (NC) from Alzheimer’s disease (AD) brains Positron Emission Tomography (PET) images based on AutoEncoder (AE) networks. Firstly, PET brains are mapped into ROIs using an anatomical atlas. Then, multiple AE models are trained and fine-tuned with softmax. After that, the connection weights learned from AEs are used to rank ROIs according to the total contribution of ROIs to the networks. We proposed a 2-phase feature ranking method which is able to significantly improve the ranking results. Lastly, the top-ranked ROIs are then input into a support vector machine (SVM) classifier. In experiments on ADNI dataset, the proposed method significantly improves the accuracy of the classifier when compared to other popular feature ranking methods such as: Fisher score, T-score, Conditional Mutual Information Maximization (CMIM), and Lasso. Our result shows that simple single-hidden-layer AE models can be used effectively to perform the feature ranking task. The proposed method could be easily applied to any image dataset where a feature selection is needed.},
  archive      = {J_MLA},
  author       = {Pham Minh Tuan and Trong-Le Phan and Mouloud Adel and Eric Guedj and Nguyen Linh Trung},
  doi          = {10.1016/j.mlwa.2021.100184},
  journal      = {Machine Learning with Applications},
  pages        = {100184},
  shortjournal = {Mach. Learn. Appl.},
  title        = {AutoEncoder-based feature ranking for alzheimer disease classification using PET image},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Technical indicators for energy market trading.
<em>MLA</em>, <em>6</em>, 100182. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100182">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technical indicators have been widely applied to the financial trading market, often combined with machine learning algorithms, to predict future stock market prices. The characteristics of energy market data are comparable to financial trading data; hence this research derives eight price prediction technical indicators for hourly electricity prices from the Irish Integrated Single Electricity Market. The proposed indicators consider the three key types of price indicators: trend, oscillator, and momentum. Building the technical indicators from raw electricity price data helps to capture market behaviours and find information to predict future profitable prices. The electricity price data for the proposed indicators were collected from February 2019 until March 2020. Three machine learning regression algorithms were trained with the technical indicators: Extreme Gradient Boosting, Gradient Boosting, and Random Forest . The results demonstrate that the price prediction models perform much better when trained using the proposed technical indicators when compared with baseline raw price data models.},
  archive      = {J_MLA},
  author       = {Catherine McHugh and Sonya Coleman and Dermot Kerr},
  doi          = {10.1016/j.mlwa.2021.100182},
  journal      = {Machine Learning with Applications},
  pages        = {100182},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Technical indicators for energy market trading},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble prediction of mean bubble size in a continuous
casting mold using data driven modeling techniques. <em>MLA</em>,
<em>6</em>, 100180. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100180">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gas injection into a slab continuous casting mold is a common practice as it enables long casting sequences by reducing SEN clogging. However, too much gas injection can generate lots of bubbles, and bubbles formed inside the mold are also responsible for the occurrence of various quality defects such as deterioration of steel cleanliness, reoxidation of liquid steel, and occurrence of sliver and blister defects, etc. Mean bubble size is a key parameter and controlling it can resolve/reduce these quality issues. Operating parameters such as gas flow rate and liquid flow rate are the major factors affecting the mean bubble size. Two-phase water modeling​ experiments were performed to generate bubbles in the mold, and the mean bubble diameter was captured using various gas and liquid flow rates. Clear images of bubbles were recorded using a high-speed high-resolution camera along with the application of shadowgraphy. Bubble images were processed using an image processing software, ImageJ to obtain bubble characteristics, and Sauter mean diameter was calculated for each operating condition. Advance machine learning techniques such as Multilinear Regression (MLR), Decision Tree (DT), Support Vector Machine (SVM), and Artificial Neural Network (ANN) were used on the experimental data to predict the combined effect of these operating parameters on the mean bubble diameter. All four ML techniques were compared considering the values of cross-validated adjusted R 2 , and a performance metric is presented to compare the suitability of ML techniques in this case.},
  archive      = {J_MLA},
  author       = {Amiy Srivastava and Ruibin Wang and Soumitra Kumar Dinda and Kinnor Chattopadhyay},
  doi          = {10.1016/j.mlwa.2021.100180},
  journal      = {Machine Learning with Applications},
  pages        = {100180},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Ensemble prediction of mean bubble size in a continuous casting mold using data driven modeling techniques},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning of truck traffic classification groups from
weigh-in-motion data. <em>MLA</em>, <em>6</em>, 100178. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100178">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pavement Mechanistic-Empirical (ME) design requires high-dimensional traffic feature inputs by categories, including Vehicle Class Distributions (VCD), Monthly Distribution Factors (MDF), Hourly Distribution Factors (HDF), and Normalized Axles Load Spectra (NALS). In simplifying the Pavement ME design practice, Truck Traffic Classification (TTC) groups are commonly used for characterizing traffic inputs. Thus, properly defining TTC groups is critical for state-specific pavement ME design practice. In this study, the truck traffic data from existing Weight-in-Motion (WIM) stations were mined to develop specific TTC groups to assist with pavement ME design practice in Georgia. An effective data analytics procedure was developed by leveraging unsupervised machine learning techniques to reduce the high-dimensional traffic features by stratified Principal Component Analysis (PCA), followed by K-means clustering to establish appropriate TTC groups. For a case study, the performance of two typical designs was evaluated using the AASHTOWare pavement mechanistic-empirical (ME) design software with respect to two scenarios of traffic inputs: (1) the derived cluster-based groups, and (2) the national default TTC groups. The results indicated that direct application of the national default TTC groups resulted in over-design of pavement structure in Georgia. Therefore, it is highly recommended that customized TTC groups should be developed using state-specific WIM data.},
  archive      = {J_MLA},
  author       = {Narges Tahaei and Jidong J. Yang and Mi Geum Chorzepa and S. Sonny Kim and Stephan A. Durham},
  doi          = {10.1016/j.mlwa.2021.100178},
  journal      = {Machine Learning with Applications},
  pages        = {100178},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning of truck traffic classification groups from weigh-in-motion data},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate modeling of fluid dynamics with a multigrid
inspired neural network architecture. <em>MLA</em>, <em>6</em>, 100176.
(<a href="https://doi.org/10.1016/j.mlwa.2021.100176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Algebraic or geometric multigrid methods are commonly used in numerical solvers as they are a multi-resolution method able to handle problems with multiple scales. In this work, we propose a modification to the commonly-used U-Net neural network architecture that is inspired by the principles of multigrid methods, referred to here as U-Net-MG. We then demonstrate that this proposed U-Net-MG architecture can successfully reduce the test prediction errors relative to the conventional U-Net architecture when modeling a set of fluid dynamic problems. In total, we demonstrate an improvement in the prediction of velocity and pressure fields for the canonical fluid dynamics cases of flow past a stationary cylinder, flow past 2 cylinders in out-of-phase motion, and flow past an oscillating airfoil in both the propulsion and energy harvesting modes. In general, while both the U-Net and U-Net-MG models can model the systems well with test RMSEs of less than 1\%, the use of the U-Net-MG architecture can further reduce RMSEs by between 20\% and 70\%.},
  archive      = {J_MLA},
  author       = {Quang Tuyen Le and Chinchun Ooi},
  doi          = {10.1016/j.mlwa.2021.100176},
  journal      = {Machine Learning with Applications},
  pages        = {100176},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Surrogate modeling of fluid dynamics with a multigrid inspired neural network architecture},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Two phase learning technique in modular neural network for
pattern classification of handwritten hindi alphabets. <em>MLA</em>,
<em>6</em>, 100174. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100174">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modular neural network overcomes the problem of monolithic structures of artificial neural networks . Generally modular neural network is an integration of smaller sub complete neural network models . Each model works independently on a sub portion of larger size pattern vectors . There are two ways of modularizing the neural network i.e. modularizing learning and modularizing structure. In this present work the modular neural network with modular learning for pattern classification of hand written Hindi alphabets is considered. In the presented approach 24 individual sub neural networks have been considered for first phase computing. In the second phase the collective outputs of first phase is presented as input to global neural network. Thus, the output of second phase presents the desired classification of the given large training set. Neural networks of first phase are trained locally for decomposed input patterns with gradient descent learning. Updated weights of the first phase are mapped to the global neural network. The global neural network is further trained for the collective output patterns of the first phase computing. Two phases of modular neural network i.e. decomposition and replication have been applied to perform the classification task . Simulation results are indicating that the complete neural network is approximated well when updated weights of first phase are combined with new weights of second phase and it generalized well when only updated weights of sub neural network of first phase are mapped to the connection strength of global neural network.},
  archive      = {J_MLA},
  author       = {Manu Pratap Singh and Gunjan Singh},
  doi          = {10.1016/j.mlwa.2021.100174},
  journal      = {Machine Learning with Applications},
  pages        = {100174},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Two phase learning technique in modular neural network for pattern classification of handwritten hindi alphabets},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explainable outlier detection: What, for whom and why?
<em>MLA</em>, <em>6</em>, 100172. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier algorithms are becoming increasingly complex. Thereby, they become much less interpretable to the data scientists applying the algorithms in real-life settings and to end-users using their predictions. We argue that outliers are context-dependent and, therefore, can only be detected via domain knowledge, algorithm insight, and interaction with end-users. As outlier detection is equivalent to unsupervised semantic binary classification , at the core of interpreting an outlier algorithm we find the semantics of the classes, i.e., the algorithm’s conceptual outlier definition. We investigate current interpretable and explainable outlier algorithms: what they are, for whom they are, and what their value proposition is. We then discuss how interpretation and explanation and user involvement have the potential to provide the missing link to bring modern complex outlier algorithms from computer science labs into real-life applications and the challenges they induce.},
  archive      = {J_MLA},
  author       = {Jonas Herskind Sejr and Anna Schneider-Kamp},
  doi          = {10.1016/j.mlwa.2021.100172},
  journal      = {Machine Learning with Applications},
  pages        = {100172},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Explainable outlier detection: What, for whom and why?},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Assessing feature selection method performance with class
imbalance data. <em>MLA</em>, <em>6</em>, 100170. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100170">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying the most informative features is a crucial step in feature selection. This paper focuses primarily on wrapper feature selection methods designed to detect important features with F1-score as the target metric. As an initial step, most wrapper methods order features according to importance. However, in most cases, the importance is defined according to the classification method used and varies with the characteristics of the data set. Using synthetically simulated data, we examine four existing feature ordering techniques to find the most desirable and the most effective ordering mechanism to identify informative features. Using the results, an improved method is suggested to extract the most informative feature subset from the data set. The method uses the sum of absolute values of the first k k principal component loadings to order the features where k k is a user-defined application-specific value. It also applies a sequential feature selection method to extract the best subset of features. We further compare the performance of the proposed feature selection method with results from the existing Recursive Feature Elimination (RFE) by simulating data for several practical scenarios with a different number of informative features and different imbalance rates. We also validate the method using a real-world application on several classification methods. The results based on the accuracy measures indicate that the proposed approach performs better than the existing feature selection methods.},
  archive      = {J_MLA},
  author       = {Surani Matharaarachchi and Mike Domaratzki and Saman Muthukumarana},
  doi          = {10.1016/j.mlwa.2021.100170},
  journal      = {Machine Learning with Applications},
  pages        = {100170},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Assessing feature selection method performance with class imbalance data},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GM FASST: General method for labeling augmented sub-sampled
images from a small data set for transfer learning. <em>MLA</em>,
<em>6</em>, 100168. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100168">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, the use of transfer learning was explored to achieve the overall goal of classifying a small number (approx. 215 images) of Nonlinear Multiphoton Multimodal Microscopy Images of unstained oral cancer biopsies into three categories—healthy, inflammatory, and cancerous. This is achieved by first training a neural network model to detect basic histological components of human tissues, such as the stroma and mucosa, from a much larger (5000 images) Kaggle data set containing images of stained human colorectal cancer biopsies. Experiments were conducted to optimize the model’s architecture and hyperparameters, i.e., hidden layers, optimizers, and API callback functions used prior to retraining the model on a new and much smaller data set consisting of 215 Nonlinear Multiphoton Multimodal Microscopy Images. In addition to having different class labels, these images were acquired using an entirely different imaging and detection set up, and thus have different features than the Kaggle data set. In order to expand the limited size of the Nonlinear Multiphoton Multimodal Microscopy Images data set; tiling methods were used to sub-sample and augment the images though standard transforms such as rotation, scaling and mirroring. This research shows transfer learning and data set re-sampling can improve classification accuracy by 10\% over training on the smaller data set alone.},
  archive      = {J_MLA},
  author       = {Gabrielle A. Murashova and Dirk Colbry},
  doi          = {10.1016/j.mlwa.2021.100168},
  journal      = {Machine Learning with Applications},
  pages        = {100168},
  shortjournal = {Mach. Learn. Appl.},
  title        = {GM FASST: General method for labeling augmented sub-sampled images from a small data set for transfer learning},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applied artificial intelligence for predicting construction
projects delay. <em>MLA</em>, <em>6</em>, 100166. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents evidence of a developed ensemble of ensembles predictive model for delay prediction – a global phenomenon that has continued to strangle the construction sector despite considerable mitigation efforts. At first, a review of the existing body of knowledge on influencing factors of construction project delay was used to survey experts to approach its quantitative data collection. Secondly, data cleaning, feature selection, and engineering, hyperparameter optimization, and algorithm evaluation were carried out using the quantitative data to train ensemble machine learning algorithms (EMLA) – bagging, boosting, and naïve bayes, which in turn was used to develop hyperparameter optimized predictive models: Decision Tree , Random Forest , Bagging, Extremely Randomized Trees, Adaptive Boosting (CART), Gradient Boosting Machine, Extreme Gradient Boosting, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes. Finally, a multilayer high performant ensemble of ensembles (stacking) predictive model was developed to maximize the overall performance of the EMLA combined. Results from the evaluation metrics : accuracy score, confusion matrix , precision, recall, f1 score, and Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) indeed proved that ensemble algorithms are capable of improving the predictive force relative to the use of a single algorithm in predicting construction projects delay.},
  archive      = {J_MLA},
  author       = {Christian Nnaemeka Egwim and Hafiz Alaka and Luqman Olalekan Toriola-Coker and Habeeb Balogun and Funlade Sunmola},
  doi          = {10.1016/j.mlwa.2021.100166},
  journal      = {Machine Learning with Applications},
  pages        = {100166},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Applied artificial intelligence for predicting construction projects delay},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous driving architectures: Insights of machine
learning and deep learning algorithms. <em>MLA</em>, <em>6</em>, 100164.
(<a href="https://doi.org/10.1016/j.mlwa.2021.100164">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research in Autonomous Driving is taking momentum due to the inherent advantages of autonomous driving systems. The main advantage being the disassociation of the driver from the vehicle reducing the human intervention. However, the Autonomous Driving System involves many subsystems which need to be integrated as a whole system. Some of the tasks include Motion Planning, Vehicle Localization, Pedestrian Detection, Traffic Sign Detection, Road-marking Detection, Automated Parking, Vehicle Cybersecurity, and System Fault Diagnosis . This paper aims to the overview of various Machine Learning and Deep Learning Algorithms used in Autonomous Driving Architectures for different tasks like Motion Planning, Vehicle Localization, Pedestrian Detection, Traffic Sign Detection, Road-marking Detection, Automated Parking, Vehicle Cybersecurity and Fault Diagnosis. This paper surveys the technical aspects of Machine Learning and Deep Learning Algorithms used for Autonomous Driving Systems. Comparison of these algorithms is done based on the metrics like mean Intersect in over Union (mIoU), Average Precision (AP)missed detection rate, miss rate False Positives Per Image (FPPI), and average number for false frame detection. This study contributes to picture a review of the Machine Learning and Deep Learning Algorithms used for Autonomous Driving Systems and is organized based on the different tasks of the system.},
  archive      = {J_MLA},
  author       = {Mrinal R. Bachute ( Ph.D [Electronics], Industry Liaison Officer and Associate Professor ) and Javed M. Subhedar ( M.S.[Automotive Electronics] )},
  doi          = {10.1016/j.mlwa.2021.100164},
  journal      = {Machine Learning with Applications},
  pages        = {100164},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Autonomous driving architectures: Insights of machine learning and deep learning algorithms},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Super-resolution reconstruction based on two-stage residual
neural network. <em>MLA</em>, <em>6</em>, 100162. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the constant update of deep learning technology, the super-resolution reconstruction technology based on deep learning has also attained a significant breakthrough. This paper primarily discusses the integration of deep learning and super-resolution reconstruction techniques. Regarding the application of deep learning in super-resolution reconstruction, the improvement is focused on the two dimensions of algorithm efficiency and reconstruction effect. On the basis of the currently available neural network algorithms, this paper puts forward the two-stage residual super-resolution reconstruction network structure. Thereinto, the improvement is mainly embodied in the modification of the image feature extraction network modules and the increase of the residual block into two stages. It is experimentally evidenced by algorithm simulation that the two-stage residual network in this paper shows a certain extent of improvement for the super-resolution reconstruction effect compared with the related methods.},
  archive      = {J_MLA},
  author       = {Lin Dong and Kohei Inoue},
  doi          = {10.1016/j.mlwa.2021.100162},
  journal      = {Machine Learning with Applications},
  pages        = {100162},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Super-resolution reconstruction based on two-stage residual neural network},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Basic bounds on cluster error using distortion-rate.
<em>MLA</em>, <em>6</em>, 100160. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a popular type of unsupervised learning technique that performs natural groupings on samples to generate probably approximately correct groups. These clusters or groups are expected to have high intra-similarity and high inter-distinctiveness. Practical clustering problems may combine varying levels of intra-similarity or quality and distinctiveness or diversity. We propose an information analytic approach to measure the quality and diversity given in terms of the cluster error. Unlike previous models that show information measures derived from probability of samples in cluster, the proposed framework employs distortion-rate approach by first formulating the probability of distortion for multiple-types of samples in the cluster. In this framework, cluster formation is shown as naturally greedy action which leads to showing the average minimum distortion of cluster. We also obtain probabilistic bounds on the cluster error and present case study on use of distortion-rate approach for clustering. For limiting case of binary typical cluster, the bound is shown to resemble Fano inequality. For the first time, analytic performance limits along with notion of bias and variance are formalized for clustering.},
  archive      = {J_MLA},
  author       = {JR. Bhatnagar},
  doi          = {10.1016/j.mlwa.2021.100160},
  journal      = {Machine Learning with Applications},
  pages        = {100160},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Basic bounds on cluster error using distortion-rate},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning predictions for lost time injuries in power
transmission and distribution projects. <em>MLA</em>, <em>6</em>,
100158. (<a href="https://doi.org/10.1016/j.mlwa.2021.100158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although advanced machine learning algorithms are predominantly used for predicting outcomes in many fields, their utilisation in predicting incident outcome in construction safety is still relatively new. This study harnesses Big Data with Deep Learning to develop a robust safety management system by analysing unstructured incident datasets consisting of 168,574 data points from power transmission and distribution projects delivered across the UK from 2004 to 2016. This study compared Deep Learning performance with popular machine learning algorithms (support vector machine, random forests , multivariate adaptive regression splines, generalised linear model, and their ensembles) concerning lost time injury and risk assessment in power utility projects. Deep Learning gave the best prediction for safety outcomes with high skills (AUC = 0.95, R 2 R2 = 0.88, and multi-class ROC = 0.93), thus outperforming the other algorithms. The results from this study also highlight the significance of quantitative analysis of empirical data in safety science and contribute to an enhanced understanding of injury patterns using predictive analytics in conjunction with safety experts’ perspectives. Additionally, the results will enhance the skills of safety managers in the power utility domain to advance safety intervention efforts.},
  archive      = {J_MLA},
  author       = {Ahmed O. Oyedele and Anuoluwapo O. Ajayi and Lukumon O. Oyedele},
  doi          = {10.1016/j.mlwa.2021.100158},
  journal      = {Machine Learning with Applications},
  pages        = {100158},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning predictions for lost time injuries in power transmission and distribution projects},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Genetic algorithm based feature selection and naïve bayes
for anomaly detection in fog computing environment. <em>MLA</em>,
<em>6</em>, 100156. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The sharp rise in network attacks has been a major source of concern in cyber security, particularly that now internet usage and connectivity are in high demand. As a complement to cloud computing , fog computing can offer low-latency services among users of mobile and the cloud. Because of the closeness of the end users to the fog nodes and having inadequate computing resources, fog devices may get into security issues. Conventional network threats may demolish the fog computing system. The use of Intrusion Detection Systems (IDS) in conventional networks has been extensively researched, applying them directly in to the fog computing platform might become unsuitable. Nodes of the fog generate enormous quantities of data most of the time, so implementing an Intrusion detection system model over large datasets in the fog computing setting is critical. To combat some of these network attacks, an intrusion detection system (IDS), a strategic intrusion prevention innovation that can be applied in the fog computing platform utilizing machine learning techniques for network anomaly detection and network event classification threat, has proven efficient and effective. This paper presented a Genetic Algorithm Wrapper-Based feature selection and Nave Bayes for Anomaly Detection Model (GANBADM) in a Fog Environment which removes extraneous attributes to reduce time complexity while also developing an enhanced model that can predict results with greater accuracy using the Security Laboratory Knowledge Discovery Dataset (NSL-KDD). Based on the analysis, the developed system has a higher overall performance of 99.73\% accuracy, with a false positive rate as low as 0.6\%. This results show that the proposed GANBADM approach performs better than similar approaches in the literature.},
  archive      = {J_MLA},
  author       = {John Oche Onah and Shafi’i Muhammad Abdulhamid and Mohammed Abdullahi and Ibrahim Hayatu Hassan and Abdullah Al-Ghusham},
  doi          = {10.1016/j.mlwa.2021.100156},
  journal      = {Machine Learning with Applications},
  pages        = {100156},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Genetic algorithm based feature selection and naïve bayes for anomaly detection in fog computing environment},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An investigation of XGBoost-based algorithm for breast
cancer classification. <em>MLA</em>, <em>6</em>, 100154. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the leading cancers affecting women around the world. The Computer-Aided Diagnosis (CAD) system is a powerful tool to assist pathologists during the process of diagnosing cancer, which effectively identifies the presence of cancerous cells. A standard CAD system includes processes of pre-processing, feature extraction, feature selection and classification. In this paper, we propose an enhanced breast cancer classification technique called Deep Learning and eXtreme Gradient Boosting (DLXGB) on histopathology breast cancer images using the BreaKHis dataset. This method first applies data augmentation and stain normalization for pre-processing, then pre-trained DenseNet201 will automatically learn features within an image and combine with a powerful gradient boosting classifier. The proposed classification technique is designed to classify breast cancer histology images into binary benign and malignant, and additionally one of eight non-overlapping/overlapping categories: i.e., Adenosis (A), Fibroadenoma (F), Phyllodes Tumour (PT), And Tubular Adenoma (TA) Ductal Carcinoma (DC), Lobular Carcinoma (LC), Mucinous Carcinoma (MC), And Papillary Carcinoma (PC). With DLXGB, we have obtained an accuracy of 97\% for both binary and multi-classification improving the exiting work done by researchers using the BreaKHis dataset. The results indicated that this method could produce a powerful prediction for breast cancer image classification.},
  archive      = {J_MLA},
  author       = {Xin Yu Liew and Nazia Hameed and Jeremie Clos},
  doi          = {10.1016/j.mlwa.2021.100154},
  journal      = {Machine Learning with Applications},
  pages        = {100154},
  shortjournal = {Mach. Learn. Appl.},
  title        = {An investigation of XGBoost-based algorithm for breast cancer classification},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sense and learn: Self-supervision for omnipresent sensors.
<em>MLA</em>, <em>6</em>, 100152. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning general-purpose representations from multisensor data produced by the omnipresent sensing systems (or IoT in general) has numerous applications in diverse use cases. Existing purely supervised end-to-end deep learning techniques depend on the availability of a massive amount of well-curated data, acquiring which is notoriously difficult but required to achieve a sufficient level of generalization on a task of interest. In this work, we leverage the self-supervised learning paradigm towards realizing the vision of continual learning from unlabeled inputs. We present a generalized framework named Sense and Learn for representation or feature learning from raw sensory data. It consists of several auxiliary tasks that can learn high-level and broadly useful features entirely from unannotated data without any human involvement in the tedious labeling process. We demonstrate the efficacy of our approach on several publicly available datasets from different domains and in various settings, including linear separability , semi-supervised or few shot learning , and transfer learning . Our methodology achieves results that are competitive with the supervised approaches and close the gap through fine-tuning a network while learning the downstream tasks in most cases. In particular, we show that the self-supervised network can be utilized as initialization to significantly boost the performance in a low-data regime with as few as 5 labeled instances per class, which is of high practical importance to real-world problems. Likewise, the learned representations with self-supervision are found to be highly transferable between related datasets, even when few labeled instances are available from the target domains.},
  archive      = {J_MLA},
  author       = {Aaqib Saeed and Victor Ungureanu and Beat Gfeller},
  doi          = {10.1016/j.mlwa.2021.100152},
  journal      = {Machine Learning with Applications},
  pages        = {100152},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Sense and learn: Self-supervision for omnipresent sensors},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for the discovery of new pre-miRNAs: Helping
the fight against COVID-19. <em>MLA</em>, <em>6</em>, 100150. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Severe Acute Respiratory Syndrome-Coronavirus 2 (SARS-CoV-2) has been recently found responsible for the pandemic outbreak of a novel coronavirus disease (COVID-19). In this work, a novel approach based on deep learning is proposed for identifying precursors of small active RNA molecules named microRNA (miRNA) in the genome of the novel coronavirus. Viral miRNA-like molecules have shown to modulate the host transcriptome during the infection progression, thus their identification is crucial for helping the diagnosis or medical treatment of the disease. The existence of the mature miRNAs derived from computationally predicted miRNA precursors (pre-miRNAs) in the novel coronavirus was validated with small RNA-seq data from SARS-CoV-2-infected human cells. The results demonstrate that computational models can provide accurate and useful predictions of pre-miRNAs in the SARS-CoV-2 genome, underscoring the relevance of machine learning in the response to a global sanitary emergency. Moreover, the interpretability of our model shed light on the molecular mechanisms underlying the viral infection, thus contributing to the fight against the COVID-19 pandemic and the fast development of new treatments. Our study shows how recent advances in machine learning can be used, effectively, in response to public health emergencies . The approach developed in this work could be of great help in future similar emergencies to accelerate the understanding of the singularities of any viral agent and for the development of novel therapies. Data and source code available at : https://sourceforge.net/projects/sourcesinc/files/aicovid/ .},
  archive      = {J_MLA},
  author       = {L.A. Bugnon and J. Raad and G.A. Merino and C. Yones and F. Ariel and D.H. Milone and G. Stegmayer},
  doi          = {10.1016/j.mlwa.2021.100150},
  journal      = {Machine Learning with Applications},
  pages        = {100150},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Deep learning for the discovery of new pre-miRNAs: Helping the fight against COVID-19},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ECR-DBSCAN: An improved DBSCAN based on computational
geometry. <em>MLA</em>, <em>6</em>, 100148. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new density based clustering algorithm E C R − D B S C A N ECR−DBSCAN based on D B S C A N DBSCAN , has been presented in this paper. Computational geometry is applied to develop the modified D B S C A N DBSCAN algorithm. It is well known that the quality of density based clustering depends on its input parameters. However, it is not easy to determine proper values of input parameters for D B S C A N DBSCAN . This paper presents three significant modifications or extensions to D B S C A N DBSCAN related with (i) selection of hyper parameter e p s i l o n epsilon ( e p s eps ) using the radii of empty or voronoi circles (ii) selection of parameter minPoints ( m p mp ) for the same epsilon and (iii) redistribution of noise points to suitable clusters using the concept of centroid hinged clustering. E C R − D B S C A N ECR−DBSCAN is implemented with PYTHON accompanied by extensive experiment on benchmark data sets. Our experimental results establish the novelty and validity of the proposed clustering method over standard techniques.},
  archive      = {J_MLA},
  author       = {Kinsuk Giri and Tuhin Kr. Biswas and Pritisha Sarkar},
  doi          = {10.1016/j.mlwa.2021.100148},
  journal      = {Machine Learning with Applications},
  pages        = {100148},
  shortjournal = {Mach. Learn. Appl.},
  title        = {ECR-DBSCAN: An improved DBSCAN based on computational geometry},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partial dependence through stratification. <em>MLA</em>,
<em>6</em>, 100146. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial dependence curves (FPD) are commonly used to explain feature importance once a supervised learning model has been fitted to data. However, it is common for the same partial dependence algorithm to give meaningfully different curves for different supervised models, even when the algorithm is applied to the same data. As a result, it is difficult to distinguish between model artifacts and true relationships in the data. In this paper, we contribute metods for computing partial dependence curves, for both numerical ( StratPD ) and categorical explanatory variables ( CatStratPD ), that work directly from training data rather than the predictions of a fitted model. Our methods provide a direct estimate of partial dependence, and rely on approximating the partial derivative of an unknown regression function . We investigate settings where contemporary partial dependence methods – including FPD, Accumulated Local Effects (ALE), and SHapley Additive exPlanations (SHAP) methods – give biased results. We demonstrate that our approach works correctly on synthetic data and plausibly on real data sets . This work motivates a new line of inquiry into nonparametric partial dependence that provides robust information about the variables considered in a supervised learning task.},
  archive      = {J_MLA},
  author       = {Terence Parr and James D. Wilson},
  doi          = {10.1016/j.mlwa.2021.100146},
  journal      = {Machine Learning with Applications},
  pages        = {100146},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Partial dependence through stratification},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A machine learning framework to predict the risk of opioid
use disorder. <em>MLA</em>, <em>6</em>, 100144. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opioid overdose epidemic is a national public health crisis in the US. Little is known about how large-scale data analytics can be leveraged to help physicians predict whether a prescription opioid user will develop opioid use disorder. To that end, we proposed a machine learning framework for identifying potential risk factors of opioid use disorder from a large-scale healthcare claims data. These risk factors identified by the proposed framework can be used to predict which patient will be at higher risk of opioid use disorder following an opioid prescription. We utilized clinical diagnosis and prescription histories from Massachusetts commercially insured individuals who were prescribed opioids. We performed several feature selection techniques on a class imbalanced analytic sample to identify patient-level demographic and clinical features that were influential predictors of opioid use disorder. We, then compared the predictive power of four well-known machine learning algorithms : Logistic Regression , Random Forest , Decision Tree , and Gradient Boosting to predict the patients’ risk of opioid use disorder. The study results showed that the Random Forest model achieved superior predictive performance in terms of AUC and recall. Alongside the higher predictive accuracy , the random forest model identified clinical features, some of which were fairly consistent with prior clinical findings. In addition, our proposed framework is capable of extracting some other clinical features, which are predictive of opioid use disorder and indicative as the proxies of patients’ health status. We anticipate that the findings of our study will potentially help reduce in-appropriate and over prescription of opioids.},
  archive      = {J_MLA},
  author       = {Md Mahmudul Hasan and Gary J. Young and Mehul Rakeshkumar Patel and Alicia Sasser Modestino and Leon D. Sanchez and Md. Noor-E-Alam},
  doi          = {10.1016/j.mlwa.2021.100144},
  journal      = {Machine Learning with Applications},
  pages        = {100144},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A machine learning framework to predict the risk of opioid use disorder},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A class-specific metaheuristic technique for explainable
relevant feature selection. <em>MLA</em>, <em>6</em>, 100142. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A significant amount of previous research into feature selection has been aimed at developing methods that can derive variables that are relevant to an entire dataset. Although these approaches have revealed substantial improvements in classification accuracy , they have failed to address the problem of explainability of outputs. This paper seeks to address this problem of identifying explainable features using a class-specific feature selection method based on genetic algorithms and the one-vs-all strategy. Our proposed method finds relevant features for each class in the dataset and uses these features to enable more accurate classification, and also interpretation of the outputs. The results of our experiments demonstrate that the proposed method provides descriptive insights into prediction outputs, and also outperforms popular global feature selection techniques in the classifications of high dimensional and noisy datasets. Since there are no known challenging benchmark datasets for evaluating class-specific feature selection algorithms, this paper also recommends an approach for combining disparate datasets for this purpose.},
  archive      = {J_MLA},
  author       = {Chinedu Pascal Ezenkwu and Uduak Idio Akpan and Bliss Utibe-Abasi Stephen},
  doi          = {10.1016/j.mlwa.2021.100142},
  journal      = {Machine Learning with Applications},
  pages        = {100142},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A class-specific metaheuristic technique for explainable relevant feature selection},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Network analysis of corn cash price comovements.
<em>MLA</em>, <em>6</em>, 100140. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Commodity price comovements are an important issue in economics given their significant implications for food and resource sectors that directly influence social well-being. This study approaches this issue by focusing on daily cash prices of 182 corn markets from the seven largest harvest states in the United States for 2006–2011 by using correlation based hierarchical analysis and synchronization analysis, through which we can determine interactions and interdependence among these prices, heterogeneities in price synchronization, and their changing patterns over time. As the first study of the issue concentrating on prices of hundreds of spatially dispersed markets for a commodity of indubitable economic significance, empirical findings show that the degree of comovements is generally higher after November 2006 but no persistent increase is observed. Different groups of markets are identified, each of which has its members exhibit similar price dynamics. Certain markets show potential of serving as price leaders. Results here benefit food and resource policy analysis and design for economic welfare. The empirical framework has potential of being adapted to network analysis of prices of different commodities.},
  archive      = {J_MLA},
  author       = {Xiaojie Xu and Yun Zhang},
  doi          = {10.1016/j.mlwa.2021.100140},
  journal      = {Machine Learning with Applications},
  pages        = {100140},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Network analysis of corn cash price comovements},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). COVID-19 detection in x-ray images using convolutional
neural networks. <em>MLA</em>, <em>6</em>, 100138. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 global pandemic affects health care and lifestyle worldwide, and its early detection is critical to control cases’ spreading and mortality. The actual leader diagnosis test is the Reverse transcription Polymerase chain reaction (RT-PCR), result times and cost of these tests are high, so other fast and accessible diagnostic tools are needed. Inspired by recent research that correlates the presence of COVID-19 to findings in Chest X-ray images, this papers’ approach uses existing deep learning models (VGG19 and U-Net) to process these images and classify them as positive or negative for COVID-19. The proposed system involves a preprocessing stage with lung segmentation, removing the surroundings which does not offer relevant information for the task and may produce biased results; after this initial stage comes the classification model trained under the transfer learning scheme; and finally, results analysis and interpretation via heat maps visualization. The best models achieved a detection accuracy of COVID-19 around 97\%.},
  archive      = {J_MLA},
  author       = {Daniel Arias-Garzón and Jesús Alejandro Alzate-Grisales and Simon Orozco-Arias and Harold Brayan Arteaga-Arteaga and Mario Alejandro Bravo-Ortiz and Alejandro Mora-Rubio and Jose Manuel Saborit-Torres and Joaquim Ángel Montell Serrano and Maria de la Iglesia Vayá and Oscar Cardona-Morales and Reinel Tabares-Soto},
  doi          = {10.1016/j.mlwa.2021.100138},
  journal      = {Machine Learning with Applications},
  pages        = {100138},
  shortjournal = {Mach. Learn. Appl.},
  title        = {COVID-19 detection in X-ray images using convolutional neural networks},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating COVID-19 rt in real-time: An indonesia health
policy perspective. <em>MLA</em>, <em>6</em>, 100136. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {COVID-19 (SARS COV2 n-corona virus) is the newfangled virus of the coronavirus family. COVID-19 can cause serious illness with symptoms of fever, cold, cough, and respiratory blockage. COVID-19 is a contagious virus, which originated in Wuhan, China. After one month, WHO declared it as a Pandemic due to its rapid spreading. Presently, Indonesia is also facing a hard time controlling the spread. Hence, it is essential to understand the spread rate in Indonesia and to analyze the strategies to minimize the virus spread. The proposed study can be used to assess variations in virus spread both nationally, and sub-nationally. This allows public health officials and policy-makers to track the progress of the outbreak in near real-time using an epidemiologically valid measure.},
  archive      = {J_MLA},
  author       = {Sankaraiah Sreeramula and Deny Rahardjo},
  doi          = {10.1016/j.mlwa.2021.100136},
  journal      = {Machine Learning with Applications},
  pages        = {100136},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Estimating COVID-19 rt in real-time: An indonesia health policy perspective},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning in computer vision: A critical review of
emerging techniques and application scenarios. <em>MLA</em>, <em>6</em>,
100134. (<a href="https://doi.org/10.1016/j.mlwa.2021.100134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been overwhelmingly successful in computer vision (CV), natural language processing , and video/speech recognition. In this paper, our focus is on CV. We provide a critical review of recent achievements in terms of techniques and applications. We identify eight emerging techniques, investigate their origins and updates, and finally emphasize their applications in four key scenarios, including recognition, visual tracking, semantic segmentation , and image restoration. We recognize three development stages in the past decade and emphasize research trends for future works. The summarizations, knowledge accumulations, and creations could benefit researchers in the academia and participators in the CV industries.},
  archive      = {J_MLA},
  author       = {Junyi Chai and Hao Zeng and Anming Li and Eric W.T. Ngai},
  doi          = {10.1016/j.mlwa.2021.100134},
  journal      = {Machine Learning with Applications},
  pages        = {100134},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Deep learning in computer vision: A critical review of emerging techniques and application scenarios},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A web crowdsourcing framework for transfer learning and
personalized speech emotion recognition. <em>MLA</em>, <em>6</em>,
100132. (<a href="https://doi.org/10.1016/j.mlwa.2021.100132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech Emotion Recognition (SER) is an important part of Affective Computing and emotionally aware Human–Computer Interaction. Emotional expression may vary depending on the language, culture, and the speaker’s personality and vocal attributes. Speaker-adaptive systems can address this issue. In real-world applications, it is not feasible to obtain big datasets for deep learning model training from a specific speaker. This paper proposes a transfer learning approach for personalized SER based on convolutional neural networks . A CNN is trained in a multi-user dataset for generalization and then is fine-tuned for a small speaker-specific dataset. A VGGish model, pre-trained a large-scale dataset for audio event recognition is also evaluated for the task. This comparison highlights the significance of network capacity, dataset length, and domain-relativity for transfer learning. To enhance the applicability of this approach in real-world conditions, a web crowdsourcing application is implemented. An online platform is provided where contributors can follow a standard procedure to record and submit annotated utterances of emotional speech. The recordings are validated and added to the publicly available AESDD dataset of emotional speech. The platform can be used for the creation of personalized emotional speech datasets for speaker-adaptive SER, following the transfer learning strategies that have been evaluated.},
  archive      = {J_MLA},
  author       = {Nikolaos Vryzas and Lazaros Vrysis and Rigas Kotsakis and Charalampos Dimoulas},
  doi          = {10.1016/j.mlwa.2021.100132},
  journal      = {Machine Learning with Applications},
  pages        = {100132},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A web crowdsourcing framework for transfer learning and personalized speech emotion recognition},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Network representation learning systematic review: Ancestors
and current development state. <em>MLA</em>, <em>6</em>, 100130. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world information networks are increasingly occurring across various disciplines including online social networks and citation networks. These network data are generally characterized by sparseness, nonlinearity and heterogeneity bringing different challenges to the network analytics task to capture inherent properties from network data. Artificial intelligence and machine learning have been recently leveraged as powerful systems to learn insights from network data and deal with presented challenges. As part of machine learning techniques, graph embedding approaches are originally conceived for graphs constructed from feature represented datasets, like image dataset, in which links between nodes are explicitly defined. These traditional approaches cannot cope with network data challenges. As a new learning paradigm, network representation learning has been proposed to map a real-world information network into a low-dimensional space while preserving inherent properties of the network. In this paper, we present a systematic comprehensive survey of network representation learning, known also as network embedding, from birth to the current development state. Through the undertaken survey, we provide a comprehensive view of reasons behind the emergence of network embedding and, types of settings and models used in the network embedding pipeline. Thus, we introduce a brief history of representation learning and word representation learning ancestor of network embedding. We provide also formal definitions of basic concepts required to understand network representation learning followed by a description of network embedding pipeline. Most commonly used downstream tasks to evaluate embeddings, their evaluation metrics and popular datasets are highlighted. Finally, we present the open-source libraries for network embedding.},
  archive      = {J_MLA},
  author       = {Amina Amara and Mohamed Ali Hadj Taieb and Mohamed Ben Aouicha},
  doi          = {10.1016/j.mlwa.2021.100130},
  journal      = {Machine Learning with Applications},
  pages        = {100130},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Network representation learning systematic review: Ancestors and current development state},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ambient temperature and solar irradiance forecasting
prediction horizon sensitivity analysis. <em>MLA</em>, <em>6</em>,
100128. (<a href="https://doi.org/10.1016/j.mlwa.2021.100128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Selecting the correct weather forecasting technique is a crucial task when planning an efficient solar energy generation system. Estimating accurate solar photovoltaic systems power output depends on the correct modeling of solar irradiance and ambient temperature, evidencing the need for a framework to select the correct technique to forecast these parameters. This paper presents a review of the forecasting methods to predict solar irradiance and ambient temperature, considering the sensitivity to the forecasting horizon. The methodology includes estimating an interval for ambient temperature and solar irradiance by using the Mean Absolute Error as the percentage of variation in these parameters. To provide context, the study considers best-case and worst-case scenarios for four cities, estimating the power output for a sample array and analyzing the differences between the cases. The power output estimation of the PV array varied between 36\% and 50\% (on average) for the short-term prediction, and 54\% to 95\% for the long-term. The changes in the location produced an average variation of 43\% in terms of power production, and up to 187\% in economic value (USD) for the short term, and 44.5\% and 187\% for the long term. The results suggest a marked sensitivity to the variation in the forecasting horizon and significance with regards to location selection (considering the changes in solar irradiation and the cost of electricity).},
  archive      = {J_MLA},
  author       = {Jose Ramirez-Vergara and Lisa B. Bosman and Walter D. Leon-Salas and Ebisa Wollega},
  doi          = {10.1016/j.mlwa.2021.100128},
  journal      = {Machine Learning with Applications},
  pages        = {100128},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Ambient temperature and solar irradiance forecasting prediction horizon sensitivity analysis},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linear regression on a set of selected templates from a pool
of randomly generated templates. <em>MLA</em>, <em>6</em>, 100126. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study linear regression for two datasets. For the MNIST dataset we do so using max convolutions, whose parameters are generated directly from training images for the digit recognition problem, hence we call them max convolution templates. From a large pool of randomly generated convolutional templates, we select by iterative process the ones which improve defined linear regression minimization problem the most. With these templates, we use linear and logistic regression and achieve high accuracy, comparable with deep neural networks . We explain why, in a production environment, using this approach has advantages over the use of deep neural networks. On a second dataset ‘Adult Data Set’ of income predictions, we show a similar convolution type approach for generating a pool of random templates and show that the same template selection process and linear regression can be used as for the MNIST dataset.},
  archive      = {J_MLA},
  author       = {Peter Taraba},
  doi          = {10.1016/j.mlwa.2021.100126},
  journal      = {Machine Learning with Applications},
  pages        = {100126},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Linear regression on a set of selected templates from a pool of randomly generated templates},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study of the generalizability of self-supervised
representations. <em>MLA</em>, <em>6</em>, 100124. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in self-supervised learning (SSL) made it possible to learn generalizable visual representations from unlabeled data . The performance of Deep Learning models fine-tuned on pretrained SSL representations is on par with models fine-tuned on the state-of-the-art supervised learning (SL) representations. Irrespective of the progress made in SSL, its generalizability has not been studied extensively. In this article, we perform a deeper analysis of the generalizability of pretrained SSL and SL representations by conducting a domain-based study for transfer learning classification tasks . The representations are learned from the ImageNet source data, which are then fine-tuned using two types of target datasets: similar to the source dataset , and significantly different from the source dataset. We study generalizability of the SSL and SL-based models via their prediction accuracy as well as prediction confidence. In addition to this, we analyze the attribution of the final convolutional layer of these models to understand how they reason about the semantic identity of the data. We show that the SSL representations are more generalizable as compared to the SL representations. We explain the generalizability of the SSL representations by investigating its invariance property , which is shown to be better than that observed in the SL representations.},
  archive      = {J_MLA},
  author       = {Atharva Tendle and Mohammad Rashedul Hasan},
  doi          = {10.1016/j.mlwa.2021.100124},
  journal      = {Machine Learning with Applications},
  pages        = {100124},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A study of the generalizability of self-supervised representations},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data mining for faster, interpretable solutions to inverse
problems: A case study using additive manufacturing. <em>MLA</em>,
<em>6</em>, 100122. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving inverse problems , where we find the input values that result in desired values of outputs, can be challenging. The solution process is often computationally expensive and it can be difficult to interpret the solution in high-dimensional input spaces. In this paper, we use a problem from additive manufacturing to address these two issues with the intent of making it easier to solve inverse problems and exploit their results. First, focusing on Gaussian process surrogates that are used to solve inverse problems, we describe how a simple modification to the idea of tapering can substantially speed up the surrogate without losing accuracy in prediction. Unlike block tapering, which approximates the covariance matrix by diagonal blocks, our approach divides the data itself into blocks. Both approaches reduce the computational cost by replacing the Cholesky decomposition of the full matrix by the decomposition of multiple smaller matrices, but our approach gives accurate predictions despite the approximation as we identify hyperparameters optimal for each block. Second, we demonstrate that Kohonen self-organizing maps can be used to visualize and interpret the solution to the inverse problem in the high-dimensional input space. For our data set, as not all input dimensions are equally important, we show that using weighted distances results in a better organized map that not only makes the relationships among the inputs obvious, but also indicates the location of the solution in the input space so an additive manufacturing engineer can control the inputs appropriately for a desired output.},
  archive      = {J_MLA},
  author       = {Chandrika Kamath and Juliette Franzman and Ravi Ponmalai},
  doi          = {10.1016/j.mlwa.2021.100122},
  journal      = {Machine Learning with Applications},
  pages        = {100122},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Data mining for faster, interpretable solutions to inverse problems: A case study using additive manufacturing},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficacy of novel summation-based synergetic artificial
neural network in ADHD diagnosis. <em>MLA</em>, <em>6</em>, 100120. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention Deficit Hyperactivity Disorder (ADHD) is a critical condition that affects millions of children and often continues into adulthood. In this paper, we propose a dual 3D CNN data integration platform, that we call SSANN, a Summation-based Synergetic Artificial Neural Network , for ADHD diagnosis. The diagnosis problem in our research is simplified into a binary classification problem to detect an ADHD affected or a typical developing child given magnetic resonance imaging scans. Our proposed model has two 3D CNN branches with varying structures: (1) The first branch extracts features from the functional MRI (fMRI) data from the subjects, (2) the second branch extracts features from the structural MRI (sMRI) data of the corresponding subjects. Later, output matrices of both branches are combined with a proposed summation induced process which then is fed into a fully connected neural network and finally produce the binary classification prediction. Our proposed model achieved accuracy of 72.89\% on the ADHD-200 dataset, which performs superior than the state-of-the-art approaches on the same evaluation dataset. Our proposed SSANN model can extract useful features from the fMRI and sMRI data, which can also be employed to understand the brain anatomy and its functions in the subjects better, as well as can be used in other machine learning algorithms to design and develop diagnostic tools that certainly has potential to escort ADHD research move forward. Our proposed model offers a robust multi-modal data integration platform that can also be adapted in other medical imaging domains.},
  archive      = {J_MLA},
  author       = {Jian Peng and Madhuri Debnath and Ashis Kumer Biswas},
  doi          = {10.1016/j.mlwa.2021.100120},
  journal      = {Machine Learning with Applications},
  pages        = {100120},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Efficacy of novel summation-based synergetic artificial neural network in ADHD diagnosis},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A federated approach for fine-grained classification of
fashion apparel. <em>MLA</em>, <em>6</em>, 100118. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As online retail services proliferate and are pervasive in modern lives, applications for classifying fashion apparel features from image data are becoming more indispensable. Online retailers, from leading companies to start-ups, can leverage such applications in order to increase profit margin and enhance the consumer experience. Many notable schemes have been proposed to classify fashion items, however, the majority of such schemes have focused upon classifying basic-level categories, such as T-shirts, pants, skirts, shoes, bags, and so forth. In contrast to most prior efforts, this paper aims to enable an in-depth classification of fashion item attributes within the same category. Beginning with a single dress, we seek to classify the type of dress hem, the hem length, and the sleeve length. The proposed scheme is comprised of three major stages: (a) localization of a target item from an input image using semantic segmentation , (b) detection of human key points (e.g., point of shoulder) using a pre-trained CNN and a bounding box, and (c) three-phase classification of the attributes using a combination of algorithmic approaches and deep neural networks . The experimental results demonstrate that the proposed scheme is highly effective, with all categories having average precision of above 93.02\%, and outperforms existing Convolutional Neural Networks (CNNs)-based schemes.},
  archive      = {J_MLA},
  author       = {Tejaswini Mallavarapu and Luke Cranfill and Eun Hye Kim and Reza M. Parizi and John Morris and Junggab Son},
  doi          = {10.1016/j.mlwa.2021.100118},
  journal      = {Machine Learning with Applications},
  pages        = {100118},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A federated approach for fine-grained classification of fashion apparel},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimation of gross calorific value based on coal analysis
using an explainable artificial intelligence. <em>MLA</em>, <em>6</em>,
100116. (<a href="https://doi.org/10.1016/j.mlwa.2021.100116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Developing fuel resources is strategically crucial for Armenia. Far more than any other fossil fuel resource, coal roughly generates half the nation’s electricity. Although coal could play a critical role, no vast data is available about Armenia coal properties. Using robust modeling of energy indexes such as coal gross calorific value (GCV) by considering trivial existing datasets could be an essential clue for ensuring sustainable development. For the first time, this investigation is going to model GCV for Armenia coal samples. For this purpose, SHAP (SHapley Additive exPlanations) as a novel explainable artificial intelligence will be introduced. SHAP enables understanding the magnitude of relationships between each individual input record and its representative output and ranks input variables based on their effectiveness. SHAP was coupled by extreme gradient boosting (xgboost) as the most recently generated powerful predictive machine learning tool (SHAP-Xgboost). SHAP-Xgboost could accurately (R 2 = 0 2=0 .99) model GCV based on proximate and ultimate variables of Armenia coal samples. These significant outcomes open a new window for developing high interpretability models to assess coal properties and pinpoint the influential parameters.},
  archive      = {J_MLA},
  author       = {Saeed Chehreh Chelgani},
  doi          = {10.1016/j.mlwa.2021.100116},
  journal      = {Machine Learning with Applications},
  pages        = {100116},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Estimation of gross calorific value based on coal analysis using an explainable artificial intelligence},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Restaurant recommender system based on sentiment analysis.
<em>MLA</em>, <em>6</em>, 100114. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, exploiting sentiment analysis has become popular in designing recommender systems in various fields, including the restaurant and food area. However, most of the sentiment analysis-based restaurant recommender systems only use static information such as food quality, price, and service quality. The analysis of users’ opinions and the extraction of their food preferences lead to the provision of personalized recommendations, which is a research gap in literature; In this paper, a context-aware recommender system is proposed that extracts the food preferences of individuals from their comments and suggests restaurants in accordance with these preferences. For this purpose, the semantic approach is used to cluster the name of foods extracted from users’ comments and analyze their sentiments about them. Finally, nearby open restaurants are recommended based on their similarity to user preferences. For evaluation, the TripAdvisor website has been used and comments from 100 different users have been collected during the first 9 months of 2018. The precision, recall and f-measure of the system are measured in three scenarios of top1, top3, and top5. The results indicate that the proposed system can provide recommendations with a precision of 92.8\%, giving users a high degree of precision. Besides, the system outperforms the previous research in these criteria.},
  archive      = {J_MLA},
  author       = {Elham Asani and Hamed Vahdat-Nejad and Javad Sadri},
  doi          = {10.1016/j.mlwa.2021.100114},
  journal      = {Machine Learning with Applications},
  pages        = {100114},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Restaurant recommender system based on sentiment analysis},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyper-sinh: An accurate and reliable function from shallow
to deep learning in TensorFlow and keras. <em>MLA</em>, <em>6</em>,
100112. (<a href="https://doi.org/10.1016/j.mlwa.2021.100112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the ‘hyper-sinh’, a variation of the m-arcsinh activation function suit-able for Deep Learning (DL)-based algorithms for supervised learning, including Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN), such as the Long Short-Term Memory (LSTM). hyper-sinh, developed in the open-source Python libraries TensorFlow and Keras, is thus described and validated as an accurate and reliable activation function for shallow and deep neural networks . Improvements in accuracy and reliability in image and text classification tasks on six (N=6) medium-to-large open-source benchmark datasets are discussed. Experimental results demonstrate that the overall competitive classification performance of the novel hyper-sinh function on shallow and deep neural networks yielded the highest performance. Furthermore, this activation is evaluated against other gold standard activation functions, demonstrating its overall competitive accuracy and reliability for both image and text classification tasks.},
  archive      = {J_MLA},
  author       = {Luca Parisi and Renfei Ma and Narrendar RaviChandran and Matteo Lanzillotta},
  doi          = {10.1016/j.mlwa.2021.100112},
  journal      = {Machine Learning with Applications},
  pages        = {100112},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Hyper-sinh: An accurate and reliable function from shallow to deep learning in TensorFlow and keras},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Enhancing care strategies for preterm pregnancies by using
a prediction machine to aid clinical care decisions. <em>MLA</em>,
<em>6</em>, 100110. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Preterm births are one of the main causes of death in children under the age of 5; they carry financial implications to the economy and cause exceptional psychological distress to mothers and their families. Prior work has been done in the application of classification methods towards predicting whether a pregnant patient is likely to deliver preterm, but the majority of these solutions have been done separately without full consideration of how their proposed solution can be integrated into a clinical system setup. In this work, we propose a multi order cybernetic framework to design a recommender system that can be used to form a closed loop clinical interaction poised towards steering a system from its current state into a more desirable outcome. Using fused estimates from both electrohysterogram (electrophysiology) and tocogram (mechanical) signals from uterine wall contractions, a classification machine was designed to classify between Preterm/Term states, and also predict an associated delivery imminency for the pregnant patient. The classification machine was implemented using a multilayer perceptron neural network (MLP) and a support vector machine (SVM), where it was seen that the SVM outperformed the MLP in the majority of the classification tasks . Further work in this area would involve the application of regression techniques towards the classification tasks, which is expected to also provide greater model interpretability and continuous state estimation.},
  archive      = {J_MLA},
  author       = {Ejay Nsugbe and Olusayo Obajemu and Oluwarotimi William Samuel and Ibrahim Sanusi},
  doi          = {10.1016/j.mlwa.2021.100110},
  journal      = {Machine Learning with Applications},
  pages        = {100110},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Enhancing care strategies for preterm pregnancies by using a prediction machine to aid clinical care decisions},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An hybrid particle swarm optimization with crow search
algorithm for feature selection. <em>MLA</em>, <em>6</em>, 100108. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advancements in science, engineering, and technology have facilitated huge generation of datasets. These huge datasets contain noisy, redundant, and irrelevant features which negatively affects the performance of classification techniques in machine learning and data mining process . Feature selection is a pre-processing stage for reducing the dimensionality of datasets by selecting the most important attributes while increasing the accuracy of classification at the same time. In this paper, we present a novel hybrid binary version of enhanced chaotic crow search and particle swarm optimization algorithm (ECCSPSOA) to solve feature selection problems. In the proposed ECCSPSOA, in order to navigate the feature space, we hybridized the enhanced version of the CSA algorithm which has a better search strategy and particle swarm optimization (PSO) which is capable of converging into the best global solution in the search field. We further embed opposition-based learning technique in the local search of the hybrid algorithm. The ECCSPSOA was compared using 15 datasets from the UCI repository with four well-known optimization algorithms , such as particle swarm optimization (PSO), binary particle swarm optimization (BPSO), crow search algorithm (CSA), and chaotic crow search algorithm (CCSA). In the experiments with k-Nearest Neighbour (KNN) as a classifier, six different performance metrics were used. To tackle the over-fitting problem, each dataset is divided into training and testing data using K-fold cross-validation. The computational findings demonstrate that the proposed algorithm obtains an average accuracy rate of 89.67\% over 15 datasets, indicating that our technique exceeds state-of-the-art findings in 12 of the 15 datasets studied. Furthermore, the suggested approach outperforms state-of-the-art methods in terms of fitness value and standard deviation, obtaining the lowest value in 13 and 8 of the datasets studied respectively.},
  archive      = {J_MLA},
  author       = {Abdulhameed Adamu and Mohammed Abdullahi and Sahalu Balarabe Junaidu and Ibrahim Hayatu Hassan},
  doi          = {10.1016/j.mlwa.2021.100108},
  journal      = {Machine Learning with Applications},
  pages        = {100108},
  shortjournal = {Mach. Learn. Appl.},
  title        = {An hybrid particle swarm optimization with crow search algorithm for feature selection},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic classification of takeaway food outlet cuisine
type using machine (deep) learning. <em>MLA</em>, <em>6</em>, 100106.
(<a href="https://doi.org/10.1016/j.mlwa.2021.100106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have not disaggregated neighbourhood exposure to takeaway (‘fast-’) food outlets by cuisine type sold, which would otherwise permit examination of differential impacts on diet, obesity and related disease. This is partly due to the substantial resource challenge of manual classification of unclassified takeaway outlets at scale. We describe the development of a new model to automatically classify takeaway food outlets, by 10 major cuisine types, based on business name alone. We used machine (deep) learning, and specifically a Long Short Term Memory variant of a Recurrent Neural Network, to develop a predictive model trained on labelled outlets (n = 14,145), from an online takeaway food ordering platform. We validated the accuracy of predictions on unseen labelled outlets (n = 4,000) from the same source. Although accuracy of prediction varied by cuisine type, overall the model (or ‘classifier’) made a correct prediction approximately three out of four times. We demonstrated the potential of the classifier to public health researchers and for surveillance to support decision-making, through using it to characterise nearly 55,000 takeaway food outlets in England by cuisine type, for the first time. Although imperfect, we successfully developed a model to classify takeaway food outlets, by 10 major cuisine types, from business name alone, using innovative data science methods. We have made the model available for use elsewhere by others, including in other contexts and to characterise other types of food outlets, and for further development.},
  archive      = {J_MLA},
  author       = {Tom R.P. Bishop and Stephanie von Hinke and Bruce Hollingsworth and Amelia A. Lake and Heather Brown and Thomas Burgoine},
  doi          = {10.1016/j.mlwa.2021.100106},
  journal      = {Machine Learning with Applications},
  pages        = {100106},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Automatic classification of takeaway food outlet cuisine type using machine (deep) learning},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep learning based hazardous materials (HAZMAT) sign
detection robot with restricted computational resources. <em>MLA</em>,
<em>6</em>, 100104. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most challenging and non-trivial tasks in robot-based rescue operations is the Hazardous Materials (HAZMAT) sign detection in dangerous operation fields, in order to prevent further unexpected disasters. Each HAZMAT sign has a specific meaning that the rescue robot should detect and interpret to take a safe action, accordingly. Accurate HAZMAT detection and real-time processing are the two most important factors in such robotics applications . Furthermore, the rescue robot should cope with some secondary challenges such as image distortion and restricted CPU and computational resources, embedded in the robot. In this research, we propose a CNN-Based pipeline called DeepHAZMAT for HAZMAT sign detection and segmentation in four steps: (1) Input data volume optimisation before feeding into the CNN network, (2) Application of a YOLO-based structure to collect the required visual information from the hazardous areas, (3) HAZMAT sign segmentation and separation from the background using adaptive GrabCut technique, and (4) Post-processing optimisation using morphological operators and convex hull algorithms. In spite of the utilisation of a very limited CPU and memory resources, the experimental results show the proposed method has successfully maintained a better performance in terms of detection-speed and detection-accuracy, compared to classical and modern state-of-the-art methods.},
  archive      = {J_MLA},
  author       = {Amir Sharifi and Ahmadreza Zibaei and Mahdi Rezaei},
  doi          = {10.1016/j.mlwa.2021.100104},
  journal      = {Machine Learning with Applications},
  pages        = {100104},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A deep learning based hazardous materials (HAZMAT) sign detection robot with restricted computational resources},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploratory data analysis for airline disruption management.
<em>MLA</em>, <em>6</em>, 100102. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reliable platforms for data collation during airline schedule operations have significantly increased the quality and quantity of available information for effectively managing airline schedule disruptions. To that effect, this paper applies macroscopic and microscopic techniques by way of basic statistics and machine learning , respectively, to analyze historical scheduling and operations data from a major airline in the United States. Macroscopic results reveal that majority of irregular operations in airline schedule that occurred over a one-year period stemmed from disruptions due to flight delays, while microscopic results validate different modeling assumptions about key drivers for airline disruption management like turnaround as a Gaussian process .},
  archive      = {J_MLA},
  author       = {Kolawole Ogunsina and Ilias Bilionis and Daniel DeLaurentis},
  doi          = {10.1016/j.mlwa.2021.100102},
  journal      = {Machine Learning with Applications},
  pages        = {100102},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Exploratory data analysis for airline disruption management},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cloud deployment of game theoretic categorical clustering
using apache spark: An application to car recommendation. <em>MLA</em>,
<em>6</em>, 100100. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personal vehicles are invariably being preferred over public transport nowadays. Contact-less feature inspection and analysis based on personal preferences will be in high demand among customers in the post-pandemic world. A comprehensive online car recommendation system will be the customers’ spontaneous choice to understand and select the features of vehicles. However, the clustering of such categorical features is a challenging task as it is difficult to compare two textual attributes. In this paper, we have designed a cloud-based system that will automatically address this issue. Motivated by the cooperative game theory and fuzzy technique, and integrating the concept of Shapley theorem, a categorical data clustering algorithm has been developed. At the same time, to overcome the major limitation of having a high time complexity of the order O O ( n 2 ) (n2) associated with the Shapley computation, the proposed algorithm has been distributed using Apache Spark’s Map Reduce architecture in Google Cloud Platform. The model has been thoroughly validated based on its performance on several synthetic as well as real data sets. Finally, a car recommendation system has been proposed and tested on three car sell data sets. The proposed approach outperforms the corresponding existing categorical clustering approaches in terms of various clustering validity indices. To the best of the authors’ knowledge, this is the first attempt to apply Map Reduce based Shapley computation over the categorical clustering, which can find its application beyond the proposed car recommendation system as well.},
  archive      = {J_MLA},
  author       = {Srimanta Kundu and Ujjwal Maulik ( Fellow IEEE )},
  doi          = {10.1016/j.mlwa.2021.100100},
  journal      = {Machine Learning with Applications},
  pages        = {100100},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Cloud deployment of game theoretic categorical clustering using apache spark: An application to car recommendation},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning and statistical approach in modeling and
optimization of surface roughness in wire electrical discharge
machining. <em>MLA</em>, <em>6</em>, 100099. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current work implements machine learning techniques such as artificial neural network (ANN), support vector machine (SVM), and genetic algorithm (GA) to model and optimize the surface roughness during wire electrical discharge machining (WEDM) of Inconel 718. For this, surface roughness values were obtained from real-time WEDM experiments conducted under the different levels of control factors such as pulse on time, pulse off time, peak current, servo voltage, and wire feed rate. The optimum ANN model architecture was identified as 5-10-10-1 and SVM parameters were tuned with the help of the grid search technique. The ANN and SVM models’ predictions were compared with response surface methodology (RSM) predictions and performance was evaluated based on correlation coefficient ( R-value ) between experimental and model predictions. The SVM predictions were accurate among all the models studied, as determined from the R-value of 0.99998 with experimental results and the least mean absolute percentage error (MAPE) of 0.0347\%. Further, the GA approach was implemented using the developed RSM equation as the fitness function and led to 61.31\% improvement in the surface roughness. The proposed SVM and GA approach would help quick and high accurate prediction and optimization of surface roughness during WEDM of Inconel 718.},
  archive      = {J_MLA},
  author       = {Uma Maheshwera Reddy Paturi and Suryapavan Cheruku and Venkat Phani Kumar Pasunuri and Sriteja Salike and N.S. Reddy and Srija Cheruku},
  doi          = {10.1016/j.mlwa.2021.100099},
  journal      = {Machine Learning with Applications},
  pages        = {100099},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning and statistical approach in modeling and optimization of surface roughness in wire electrical discharge machining},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantile convolutional neural networks for value at risk
forecasting. <em>MLA</em>, <em>6</em>, 100096. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a new method for forecasting Value at Risk. Convolutional neural networks can do time series forecasting, since they can learn local patterns in time. A simple modification enables them to forecast not the mean, but arbitrary quantiles of the distribution, and thus allows them to be applied to V a R VaR -forecasting. The proposed model can learn from the price history of different assets, and it seems to produce fairly accurate forecasts.},
  archive      = {J_MLA},
  author       = {Gábor Petneházi},
  doi          = {10.1016/j.mlwa.2021.100096},
  journal      = {Machine Learning with Applications},
  pages        = {100096},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Quantile convolutional neural networks for value at risk forecasting},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison among interpretative proposals for random
forests. <em>MLA</em>, <em>6</em>, 100094. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The growing success of Machine Learning (ML) is making significant improvements to predictive models, facilitating their integration in various application fields. Despite its growing success, there are some limitations and disadvantages: the most significant is the lack of interpretability that does not allow users to understand how particular decisions are made. Our study focus on one of the best performing and most used models in the Machine Learning framework, the Random Forest model. It is known as an efficient model of ensemble learning , as it ensures high predictive precision, flexibility, and immediacy; it is recognized as an intuitive and understandable approach to the construction process, but it is also considered a Black Box model due to the large number of deep decision trees produced within it. The aim of this research is twofold. We present a survey about interpretative proposal for Random Forest and then we perform a machine learning experiment providing a comparison between two methodologies, inTrees, and NodeHarvest, that represent the main approaches in the rule extraction framework. The proposed experiment compares methods performance on six real datasets covering different data characteristics: n. of observations, balanced/unbalanced response, the presence of categorical and numerical predictors. This study contributes to picture a review of the methods and tools proposed for ensemble tree interpretation, and identify, in the class of rule extraction approaches, the best proposal.},
  archive      = {J_MLA},
  author       = {Massimo Aria and Corrado Cuccurullo and Agostino Gnasso},
  doi          = {10.1016/j.mlwa.2021.100094},
  journal      = {Machine Learning with Applications},
  pages        = {100094},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A comparison among interpretative proposals for random forests},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid radial basis function DEA and its applications to
regression, segmentation and cluster analysis problems. <em>MLA</em>,
<em>6</em>, 100092. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper uses a radial basis function (RBF) transformation of data envelopment analysis (DEA) data to perform RBF-DEA. It is shown that the RBF-DEA frontier identifies cases that have average efficiency scores in traditional DEA. The formal identification of average efficiency cases allows decision-makers to use these cases and related information for regression, segmentation and cluster analysis. Additionally, negative inputs and outputs can be used in RBF-DEA and unique ranking of fully efficient cases in traditional DEA can be achieved by further evaluating these fully efficient cases against the average RBF-DEA regression frontier. When compared to traditional cluster analysis, RBF-DEA cluster analysis offers unique advantages in that number of clusters do not need to be mentioned and cluster labels are identified by the RBF-DEA technique. Furthermore, unlike the traditional techniques, RBF-DEA cluster memberships are not sensitive to any initial random starting points.},
  archive      = {J_MLA},
  author       = {Parag C. Pendharkar},
  doi          = {10.1016/j.mlwa.2021.100092},
  journal      = {Machine Learning with Applications},
  pages        = {100092},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Hybrid radial basis function DEA and its applications to regression, segmentation and cluster analysis problems},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image orientation detection by ensembles of stochastic CNNs.
<em>MLA</em>, <em>6</em>, 100090. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we deal with the problem of accurately and automatically detecting the orientation of general images, for instance, of holiday snapshots. Detecting image orientation is an easy task for a human being but can be a long and tedious activity during processing and management of digital photos. Several attempts have been made in the design of systems for automated displaying images in their correct orientation, however, this is still an open problem. In this work we exploit the power of deep learning proposing a transfer learning approach that adjusts pre-trained convolutional neural networks to this classification task . We create ensembles of different Convolutional Neural Network models designed by randomly changing the activation functions in all the activation layers of a given network. Along with several known activation functions we also include the novel Soft Learnable activation function in the “random set”. Our resulting ensembles have been extensively evaluated on more than 45,000 images taken from four different public datasets, showing a remarkable performance improvement with respect to other state-of-the-art approaches. All the source code used for this work is freely available at https://github.com/LorisNanni/ .},
  archive      = {J_MLA},
  author       = {Alessandra Lumini and Loris Nanni and Luca Scattolaro and Gianluca Maguolo},
  doi          = {10.1016/j.mlwa.2021.100090},
  journal      = {Machine Learning with Applications},
  pages        = {100090},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Image orientation detection by ensembles of stochastic CNNs},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantile–quantile embedding for distribution transformation
and manifold embedding with ability to choose the embedding
distribution. <em>MLA</em>, <em>6</em>, 100088. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new embedding method, named Quantile–Quantile Embedding (QQE), for distribution transformation and manifold embedding with the ability to choose the embedding distribution. QQE, which uses the concept of quantile–quantile plot from visual statistical tests, can transform the distribution of data to any theoretical desired distribution or empirical reference sample. Moreover, QQE gives the user a choice of embedding distribution in embedding the manifold of data into the low dimensional embedding space. It can also be used for modifying the embedding distribution of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric learning, for better representation or visualization of data. We propose QQE in both unsupervised and supervised forms. QQE can also transform a distribution to either an exact reference distribution or its shape. We show that QQE allows for better discrimination of classes in some cases. Our experiments on different synthetic and image datasets show the effectiveness of the proposed embedding method.},
  archive      = {J_MLA},
  author       = {Benyamin Ghojogh and Fakhri Karray and Mark Crowley},
  doi          = {10.1016/j.mlwa.2021.100088},
  journal      = {Machine Learning with Applications},
  pages        = {100088},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Quantile–Quantile embedding for distribution transformation and manifold embedding with ability to choose the embedding distribution},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised-learning link prediction in single layer and
multiplex networks. <em>MLA</em>, <em>6</em>, 100086. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The emergence of complex real-world networks has put forth a plethora of information about different domains. Link-prediction is one of the emerging research problems that utilizes the information from the networks to find future relationships between the nodes. The structure of real-world networks varies from having homogeneous relationships to having multiple associations. The homogeneous relationships are modeled by single-layer networks, while the multiplex networks represent the multiple associations. This study proposes a solution for finding future links in single-layer and multiplex networks by using supervised machine learning techniques. This study considers a set of topological features of the network for training the machine learning classifiers. The training and testing data set construction framework devised in this work helps in evaluating the proposed method on different networks. This study also contributes towards identifying four community-based features for the proposed mechanism.},
  archive      = {J_MLA},
  author       = {Deepanshu Malhotra and Rinkaj Goyal},
  doi          = {10.1016/j.mlwa.2021.100086},
  journal      = {Machine Learning with Applications},
  pages        = {100086},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Supervised-learning link prediction in single layer and multiplex networks},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary clustering and community detection algorithms
for social media health surveillance. <em>MLA</em>, <em>6</em>, 100084.
(<a href="https://doi.org/10.1016/j.mlwa.2021.100084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prominent rise of social networks within the past decade have become a gold mine for data mining operations seeking to model the real world through these virtual worlds. One of the most important applications that has been proposed is utilizing information generated from social networks as a supplemental health surveillance system to monitor disease epidemics. At the time this research was conducted in 2020, the COVID-19 virus had evolved into a global pandemic, forcing many countries to implement preventative measures to halt its expanse. Health surveillance has been a powerful tool in placing further preventative measures, however it is not a perfect system, and slowly collected, misidentified information can prove detrimental to these efforts. This research proposes a new potential surveillance avenue through unsupervised machine learning using dynamic, evolutionary variants of clustering algorithms DBSCAN and the Louvain method to allow for community detection in temporal networks. This technique is paired with geographical data collected directly from the social media Twitter, to create an effective and accurate health surveillance system that grows as time passes. The experimental results show that the proposed system is promising and has the potential to be an advancement on current machine learning health surveillance techniques.},
  archive      = {J_MLA},
  author       = {Heba Elgazzar and Kyle Spurlock and Tanner Bogart},
  doi          = {10.1016/j.mlwa.2021.100084},
  journal      = {Machine Learning with Applications},
  pages        = {100084},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Evolutionary clustering and community detection algorithms for social media health surveillance},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparative analysis of credit card fraud detection in
simulated annealing trained artificial neural network and hierarchical
temporal memory. <em>MLA</em>, <em>6</em>, 100080. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of misclassification has always been a major concern in detecting online credit card fraud in e-commerce systems. This concern greatly poses a significant challenge to financial institutions and online merchants with regards to financial loss. This paper specifically compares an Artificial Neural Network trained by the Simulated Annealing technique (SA-ANN) with a proposed emerging online learning technology in anomaly detection known as the Hierarchical Temporal Memory based on the Cortical Learning Algorithms (HTM-CLA). Comparisons are also made with a deep recurrent neural technique based on the Long Short-Term Memory ANN (LSTM-ANN). The performances of these systems are investigated on the basis of correctly classifying credit card fraud (CCF) using an average classification performance ratio metric. The results of simulations on two CCF benchmark datasets (the Australian and German CCF data) showed promising competitive performance of the proposed HTM-CLA with the SA-ANN. The HTM-CLA also clearly outperformed the LSTM-ANN in the considered benchmark datasets by a factor of 2:1.},
  archive      = {J_MLA},
  author       = {E.N. Osegi and E.F. Jumbo},
  doi          = {10.1016/j.mlwa.2021.100080},
  journal      = {Machine Learning with Applications},
  pages        = {100080},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Comparative analysis of credit card fraud detection in simulated annealing trained artificial neural network and hierarchical temporal memory},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Model-based segmentation using neural network-based boundary
detectors: Application to prostate and heart segmentation in MR images.
<em>MLA</em>, <em>6</em>, 100078. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model-based segmentation (MBS) is a variant of active surfaces and active shape models that has successfully been used to segment anatomical structures such as the heart or the brain. We propose to integrate neural networks (NNs) into MBS for boundary detection. We formulate boundary detection as a regression task and use a NN to predict the distances between a surface mesh and the corresponding boundary points. The proposed approach has been applied to two tasks — prostate segmentation in MR images and the segmentation of the left and right ventricle in MR images. For the first task, data from the Prostate MR Image Segmentation 2012 (PROMISE12) challenge has been used. For the second task, a diverse database with cardiac MR images from six clinical sites has been used. We compare the results to the popular U-net approaches using the nnU-net implementation that is among the top performing segmentation algorithms in various challenges. In cross-validation experiments, the mean Dice scores are very similar and no statistically significant difference is observed. On the PROMISE12 test set, nnU-net Dice scores are significantly better. This is achieved by using an ensemble of 2D and 3D U-nets to generate the final segmentation, a concept that may also be adapted to NN-based boundary detection in the future. While the U-net provides a voxel labeling, our approach provides a 3D surface mesh with pre-defined mesh topology , establishes correspondences with respect to the reference mesh, avoids isolated falsely segmented regions and ensures proper connectivity of different regions.},
  archive      = {J_MLA},
  author       = {Tom Brosch and Jochen Peters and Alexandra Groth and Frank Michael Weber and Jürgen Weese},
  doi          = {10.1016/j.mlwa.2021.100078},
  journal      = {Machine Learning with Applications},
  pages        = {100078},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Model-based segmentation using neural network-based boundary detectors: Application to prostate and heart segmentation in MR images},
  volume       = {6},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Three-objective optimization of boiler combustion process
based on multi-objective teaching–learning based optimization algorithm
and ameliorated extreme learning machine. <em>MLA</em>, <em>5</em>,
100082. (<a href="https://doi.org/10.1016/j.mlwa.2021.100082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The combustion optimization problem of Circulation Fluidized Bed Boiler (CFBB) can be regarded as a constrained dynamic multi-objective optimization problem, so it has become a hot research to solve the problem for saving energy and reducing polluting gas. However, it is difficult to optimize the combustion process based on traditional optimization method due to a variety of complex characteristics of boiler, such as non-linearity, strong coupling , large lag. In order to address the boiler combustion optimization problem, a kind of multi-objective modified teaching–learning-based optimization (namely MMTLBO) is proposed. For the MMTLBO, a constrained mechanism is firstly introduced into MMTLBO. Finally, the MMTLBO and ameliorated extreme learning machine (AELM) are utilized to optimize the CFBB’s combustion process for increasing the thermal efficiency and reducing the NOx/SO 2 emissions concentration. The AELM is used to establish the comprehensive model of the thermal efficiency and NOx/SO 2 emissions. The model accuracy and standard deviation can arrive 10 −2 and 10 −4 , separately. So the model shows high generalization ability and good stability. Based on the model, the MMTLBO is applied to optimize the boiler’s combustion process parameters. Experiment results show that the MMTLBO can find several groups reasonable combustion parameters which increase the thermal efficiency and reduce the NOx/SO 2 emissions concentration. Therefore, the AELM and MMTLBO are the effective artificial intelligence algorithms.},
  archive      = {J_MLA},
  author       = {Yunpeng Ma and Heqi Wang and Xinxin Zhang and Likun Hou and Jiancai Song},
  doi          = {10.1016/j.mlwa.2021.100082},
  journal      = {Machine Learning with Applications},
  pages        = {100082},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Three-objective optimization of boiler combustion process based on multi-objective teaching–learning based optimization algorithm and ameliorated extreme learning machine},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighing live sheep using computer vision techniques and
regression machine learning. <em>MLA</em>, <em>5</em>, 100076. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research arose from the need to aggregate computer vision technology and machine learning in sheep weight control and facilitate the weighing process of animals in farms. The experiment was conducted to collect the images of the animals and their weights, and later, the annotations of the images were made, generating a mask image dataset. We selected the attribute extraction algorithms that extracted shape, size, and angles with k-curvature. With these extracted data, we used the stratified five-fold cross-validation. Also, we used eight machine learning techniques aimed at regression, and the result obtained when compared to the metric Adjusted R 2 R2 was the technique called Random Forest Regressor to obtain Adjusted R 2 R2 0.687 ( ± ± 0.09) and MAE of 3.099 ( ± ± 1.52) kilograms. By performing the ANOVA test to check if it is statistically relevant using the Adjusted R 2 R2 measure, we got a p p -value of 0.00000807 (8.07e−06). The contribution of the work is sheep weight prediction in a non-invasive way using images. Therefore, the results achieved make it possible to measure the animal’s weight with an MAE of 3.099 kg.},
  archive      = {J_MLA},
  author       = {Diego André Sant’Ana and Marcio Carneiro Brito Pache and José Martins and Wellington Pereira Soares and Sebastião Lucas Neves de Melo and Vanir Garcia and Vanessa Aparecida de Moares Weber and Natália da Silva Heimbach and Rodrigo Gonçalves Mateus and Hemerson Pistori},
  doi          = {10.1016/j.mlwa.2021.100076},
  journal      = {Machine Learning with Applications},
  pages        = {100076},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Weighing live sheep using computer vision techniques and regression machine learning},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning algorithms for fraud prediction in property
insurance: Empirical evidence using real-world microdata. <em>MLA</em>,
<em>5</em>, 100074. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper evaluated fraud prediction in property insurance claims using various machine learning models based on real-world data from a major Brazilian insurance company. The models were tested recursively and average predictive results were compared controlling for false positives and false negatives . The results showed that ensemble-based methods (random forest and gradient boosting) and deep neural networks yielded the best results, exhibiting superior average performance in comparison to the other classifiers, including the commonly used logistic regression . In addition, we compiled a general profile of confirmed fraudsters from the dataset and estimated the impact of each feature in the global classification performance and for prominent cases of false positive and false negative predictions using eXplainable Artificial Intelligence methods. The findings of this study can aid risk analysts and professionals in assessing the strengths and weaknesses of each model and to build empirically effective decision rules to evaluate future insurance policies.},
  archive      = {J_MLA},
  author       = {Matheus Kempa Severino and Yaohao Peng},
  doi          = {10.1016/j.mlwa.2021.100074},
  journal      = {Machine Learning with Applications},
  pages        = {100074},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning algorithms for fraud prediction in property insurance: Empirical evidence using real-world microdata},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trends in human activity recognition with focus on machine
learning and power requirements. <em>MLA</em>, <em>5</em>, 100072. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The advancement and availability of technology can be employed to improve our daily lives. One example is Human Activity Recognition (HAR). HAR research has been mainly explored using imagery but is currently evolving to the use of sensors and has the ability to have a positive impact, including individual health monitoring and removing the barrier of healthcare. To reach a marketable HAR device, state-of-the-art classifications and power consumption methods such as convolutional neural network (CNN), data compression and other emerging techniques are reviewed here. The review of the current literature creates a foundation in HAR and addresses the lack of available HAR datasets, recommendation of classification and power reduction techniques, current drawbacks and their respective solutions, as well as future trends in HAR. The lack of publicly available datasets makes it difficult for new users to explore the field of HAR. This paper dedicates a section to publicly available datasets for users to access. Finally, a framework is suggested for HAR applications, which envelopes the current literature and emerging trends in HAR.},
  archive      = {J_MLA},
  author       = {Binh Nguyen and Yves Coelho and Teodiano Bastos and Sridhar Krishnan},
  doi          = {10.1016/j.mlwa.2021.100072},
  journal      = {Machine Learning with Applications},
  pages        = {100072},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Trends in human activity recognition with focus on machine learning and power requirements},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A machine learning model pipeline for detecting wet pavement
condition from live scenes of traffic cameras. <em>MLA</em>, <em>5</em>,
100070. (<a href="https://doi.org/10.1016/j.mlwa.2021.100070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Highway safety is largely influenced by weather conditions that have become increasingly volatile due to the climate change. It well known that wet pavement significantly reduces surface friction, leading to inflated collision risk. Thus, timely knowledge of the road surface condition is critical for safe driving. In this paper, a novel machine learning model pipeline is proposed to detect the wetness of pavement based on live images of highway scenes captured by publicly accessible traffic cameras. To simplify the learning task, we finetuned the state-of-the-art instance segmentation baseline models to extract background instance targets, including pavement, sky, and vegetation, which are common in highway scenes. Then, the color mixture attributes in HSV (hue, saturation and value) of each segmented instance were extracted and used as visual cues for inferring pavement condition. Finally, gradient boosting ensemble classifiers are constructed and trained using the HSV features to predict the wetness of pavement. For the segmentation task , we leveraged Detectron2 baseline models (Mask R-CNN) and evaluated three backbone networks : R50-FPN, R101-FPN, and X101-FPN. For the classification task , two most popular gradient boosting algorithms (XGBoost and CatBoost) were evaluated together with a classic logistic model. Based on experiments with our custom dataset, the best performance (F 1 score: 0.927, AUC: 0.975) was achieved by the R101-FPN backbone coupled with the CatBoost classifier.},
  archive      = {J_MLA},
  author       = {Clint Morris and Jidong J. Yang},
  doi          = {10.1016/j.mlwa.2021.100070},
  journal      = {Machine Learning with Applications},
  pages        = {100070},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A machine learning model pipeline for detecting wet pavement condition from live scenes of traffic cameras},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel algorithm for extracting frequent gradual patterns.
<em>MLA</em>, <em>5</em>, 100068. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction of frequent gradual pattern is an important problem in computer science and largely studied by the scientist’s community of research in data mining. A frequent gradual pattern translates a recurrent co-variation between the attributes of a database. Many applications issues from many domains, such as economy, health, education, market, bio-informatics, astronomy or web mining , are based on the extraction of frequent gradual patterns. Algorithms to extract frequent gradual patterns in the large databases are greedy in CPU time and memory space. This raises the problem of improving the performances of these algorithms. This paper presents a technique for improving the performance of frequent gradual pattern extraction algorithms. The exploitation of this technique leads to a new, more efficient algorithm called SGrite. The experiments carried out confirm the interest of the proposed technique.},
  archive      = {J_MLA},
  author       = {Tayou Djamegni Clémentin and Tabueu Fotso Laurent Cabrel and Kenmogne Edith Belise},
  doi          = {10.1016/j.mlwa.2021.100068},
  journal      = {Machine Learning with Applications},
  pages        = {100068},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A novel algorithm for extracting frequent gradual patterns},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Application of noninvasive magnetomyography in labour
imminency prediction for term and preterm pregnancies and ethnicity
specific labour prediction. <em>MLA</em>, <em>5</em>, 100066. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the application of magnetomyography (MMG) signals from uterine contractions in pregnant patients towards the prediction of labour imminency within or above 48 h. The study utilised the MMG signals collected from a host of pregnant patients retrieved from a Physionet database, which also contained information regarding patients’ ethnicity and pregnancy. Utilising​ the information available in addition to the dataset, the study investigated the prospect of designing an ethnic specific labour imminency classifier to allow for an enhanced prediction, with an emphasis on Black and Caucasian ethnicities due to the nature of the data. Using an extended feature vector and a support vector machine (SVM) classifier, it was seen that the labour imminency was enhanced across the various classifier metrics considered in the ethnic specific classifier when compared with the generalised classifier. The results from the classification exercise, which considered the fusion of MMG signal information with the information on patients’ records, showed greater variability and a slightly lower classifier performance, thus suggesting that the MMG signals present a more reliable way of classifier training. Subsequent work in this area would now involve the application of optimisation algorithms to select an optimal number of electrodes that can be used for data acquisition, and thereby contributing towards the lowering of the cost associated with the implementation of the method using the MMG instrumentation.},
  archive      = {J_MLA},
  author       = {Ejay Nsugbe and Olusayo Obajemu and Oluwarotimi William Samuel and Ibrahim Sanusi},
  doi          = {10.1016/j.mlwa.2021.100066},
  journal      = {Machine Learning with Applications},
  pages        = {100066},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Application of noninvasive magnetomyography in labour imminency prediction for term and preterm pregnancies and ethnicity specific labour prediction},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Short-time multi-energy load forecasting method based on
CNN-Seq2Seq model with attention mechanism. <em>MLA</em>, <em>5</em>,
100064. (<a href="https://doi.org/10.1016/j.mlwa.2021.100064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrated Energy Systems have become a vital energy utilization to alleviate the multiple stress of energy, environment, and economy worldwide. Integrated Energy Microgrid (IEM) is a small-scale integrated energy system located in a distribution network close to the demand side. The accurate forecasting of multi-load is an essential prerequisite for ensuring the reliable and economic operation of an IEM. Comprehensively considering temperature, humidity, wind speed, and the coupling relationship of multi-energy, this paper proposes a CNN-Seq2Seq model with an attention mechanism based on a multi-task learning method for a short-time multi-energy load forecasting. In detail, CNN is used to extract useful features of the input data. Then, the short-time multi-energy load is forecasted by using Seq2Seq according to the extracted features. Meanwhile, the attention mechanism and multi-task learning method are introduced to improve the accuracy of load forecasting. The simulation results with the actual data of an IEM validate the effectiveness of the proposed short-time multi-energy load forecasting method.},
  archive      = {J_MLA},
  author       = {Ge Zhang and Xiaoqing Bai ( Ph.D. ) and Yuxuan Wang},
  doi          = {10.1016/j.mlwa.2021.100064},
  journal      = {Machine Learning with Applications},
  pages        = {100064},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Short-time multi-energy load forecasting method based on CNN-Seq2Seq model with attention mechanism},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hacking the venture industry: An early-stage startups
investment framework for data-driven investors. <em>MLA</em>,
<em>5</em>, 100062. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Investing in early-stage companies is incredibly hard, especially when no data are available to support the decision process. Venture capitalists often rely on gut feeling or heuristics to reach a decision, which is biased and potentially harmful. This work proposes a new data-driven framework to help investors be more effective in selecting companies with a higher probability of success. We built upon existing interdisciplinary research and augmented it with further analysis on more than 600,000 companies over a 20-year timeframe. The resulting framework is therefore a smart checklist of 21 relevant features that may help investors to select the companies more likely to succeed.},
  archive      = {J_MLA},
  author       = {Francesco Corea and Giorgio Bertinetti and Enrico Maria Cervellati},
  doi          = {10.1016/j.mlwa.2021.100062},
  journal      = {Machine Learning with Applications},
  pages        = {100062},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Hacking the venture industry: An early-stage startups investment framework for data-driven investors},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection and deep neural networks for stock price
direction forecasting using technical analysis indicators. <em>MLA</em>,
<em>5</em>, 100060. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the factor zoo, which has theoretical and empirical implications for finance, from a machine learning perspective. More specifically, we discuss feature selection in the context of deep neural network models to predict the stock price direction. We investigated a set of 124 technical analysis indicators used as explanatory variables in the recent literature and specialized trading websites. We applied three feature selection methods to shrink the feature set aiming to eliminate redundant information from similar indicators. Using daily data from stocks of seven global market indexes between 2008 and 2019, we tested neural networks with different settings of hidden layers and dropout rates. We compared various classification metrics, taking into account profitability and transaction costs levels to analyze economic gains. The results show that the variables were not uniformly chosen by the feature selection algorithms and that the out-of-sample accuracy rate of the prediction converged to two values — besides the 50\% accuracy value that would suggest market efficiency, a “strange attractor” of 65\% accuracy also was achieved consistently. We also found that the profitability of the strategies did not manage to significantly outperform the Buy-and-Hold strategy, even showing fairly large negative values for some hyperparameter combinations.},
  archive      = {J_MLA},
  author       = {Yaohao Peng and Pedro Henrique Melo Albuquerque and Herbert Kimura and Cayan Atreio Portela Bárcena Saavedra},
  doi          = {10.1016/j.mlwa.2021.100060},
  journal      = {Machine Learning with Applications},
  pages        = {100060},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Feature selection and deep neural networks for stock price direction forecasting using technical analysis indicators},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural network for system of ordinary differential
equations: Vectorized algorithm and simulation. <em>MLA</em>,
<em>5</em>, 100058. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is aimed at applying deep artificial neural networks for solving system of ordinary differential equations. We developed a vectorized algorithm and implemented using python code. We conducted different experiments for selecting better neural architecture. For the learning of the neural network , we utilized the adaptive moment minimization method. Finally, we compare the method with one of the traditional numerical methods-Runge–Kutta order four. We have shown that, the artificial neural network could provide better accuracy for smaller numbers of grid points.},
  archive      = {J_MLA},
  author       = {Tamirat Temesgen Dufera},
  doi          = {10.1016/j.mlwa.2021.100058},
  journal      = {Machine Learning with Applications},
  pages        = {100058},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Deep neural network for system of ordinary differential equations: Vectorized algorithm and simulation},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How have high-impact scientific studies designing their
experiments on mixed data clustering? A systematic map to guide better
choices. <em>MLA</em>, <em>5</em>, 100056. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many scientific works on grouping mixed data have chosen different experimental scenarios to structure their findings, which involve deciding from the programming language to the use of real-world and/or simulated datasets and performance measures, for example. Due to these characteristics directly influence the conclusion of the studies and the way new scientific works are proposed, it would be useful to have a wide map with the main choices that have been done by the authors of high-impact scientific documents so that the community can reflect on the thematic direction, identify best practices, and propose new paths for future research. To the best of our knowledge, such a map does not exist, neither a methodological procedure to build it. Therefore, this paper proposes a systematic methodology to reach such maps and provides a wide and in-depth map of the main choices the authors of high-impact scientific documents on mixed data clustering and surrounding studies have done in their experiments. As a result, 160 documents were systematically selected and classified into one of the six class of data clustering approaches, besides individually tabulated. From the tables for each class, we found, for instance, that real-world datasets are used more frequently than simulated ones, the documents used more external indices, followed by internal and relative ones, it is not common for the authors to inform the programming language they have used, except in the partitional class. We also provided the address of the algorithms’ code when they are made available by the authors.},
  archive      = {J_MLA},
  author       = {Nádia Junqueira Martarelli and Marcelo Seido Nagano},
  doi          = {10.1016/j.mlwa.2021.100056},
  journal      = {Machine Learning with Applications},
  pages        = {100056},
  shortjournal = {Mach. Learn. Appl.},
  title        = {How have high-impact scientific studies designing their experiments on mixed data clustering? a systematic map to guide better choices},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using hospital admission, discharge &amp; transfer (ADT)
data for predicting readmissions. <em>MLA</em>, <em>5</em>, 100055. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Readmission of patients within a specific period after their discharge from a hospital is a cause of concern for the healthcare industry due to the cost involved. Most of the work done for predicting such readmissions using machine learning (ML) have been based on EHR, claims or authorization data from specific sources, which are mostly snapshot data at one static point in time and hence delayed. ADT being dynamic as the data is available instantaneous on occurrence of a medical event/visit adds value. Our goal is to utilize machine learning on unlabeled ADT data to identify patients who are at a high risk of being readmitted. We approached the problem in three parts. First, we labeled patient events using logical rules and finalized one of many readmission definitions that was more encapsulating of varied scenarios. Second, feature engineering was done which encapsulates the longitudinal timeline of each patient in a representative way considering all the contextual information. Third, we developed an automated machine learning pipeline which takes modeling inputs from the user, runs various models to generate readmission prediction, does a cross validation and returns the best model. We tried multiple combinations of models and cross-validation strategies and decided on a random forest model with specific hyper-parameter values and to be the most effective method to classify high risk patients. It had a test AUC-ROC of 72\% which is better than quite a few industry standards. The model currently implemented in the client environment identifies the high-risk patients in real-time to care nurses who in turn take proper interventions to reduce their chances of readmission.},
  archive      = {J_MLA},
  author       = {Pronojit Saha and Reelina Sircar and Arnab Bose},
  doi          = {10.1016/j.mlwa.2021.100055},
  journal      = {Machine Learning with Applications},
  pages        = {100055},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Using hospital admission, discharge &amp; transfer (ADT) data for predicting readmissions},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble based filter feature selection with harmonize
particle swarm optimization and support vector machine for optimal
cancer classification. <em>MLA</em>, <em>5</em>, 100054. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explosive increase of dataset features may intensify the complexity of medical data analysis in deciding necessary treatment for the patient. In most cases, the accuracy of diagnosis system is vitally impacted by the data dimensionality and classifier parameters. Since these two processes are dependent, conducting them independently could deteriorate the accuracy performance. Filter algorithm is used to eliminate irrelevant features based on ranking. However, independent filter still incapable to consider features dependency and resulting in imbalance selection of significant features which consequently degrade the classification performance. In order to mitigate this problem, ensemble of multi filters algorithm such as Information Gain (IG), Gain Ratio (GR), Chi-squared (CS) and Relief-F (RF) are utilized as it can considers the intercorrelation between features. The proper kernel parameters settings may also influence the classification performance. Hence, a harmonize classification technique using Particle Swarm Optimization (PSO) and Support Vector Machine (SVM) is employed to optimize the searching of optimal significant features and kernel parameters synchronously without degrading the accuracy. Therefore, an ensemble filter feature selection with harmonize classification of PSO and SVM (Ensemble-PSO-SVM) are proposed in this research. The effectiveness of the proposed method is examined on standard Breast Cancer and Lymphography datasets. Experimental results showed that the proposed method successfully signify the classifier accuracy performance with optimal significant features compared to other existing methods such as PSO-SVM and classical SVM. Hence, the proposed method can be used as an alternative method for determining the optimal solution in handling high dimensional data .},
  archive      = {J_MLA},
  author       = {Tengku Mazlin Tengku Ab Hamid and Roselina Sallehuddin and Zuriahati Mohd Yunos and Aida Ali},
  doi          = {10.1016/j.mlwa.2021.100054},
  journal      = {Machine Learning with Applications},
  pages        = {100054},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Ensemble based filter feature selection with harmonize particle swarm optimization and support vector machine for optimal cancer classification},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convection indicator for pre-tactical air traffic flow
management using neural networks. <em>MLA</em>, <em>5</em>, 100053. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convective weather is a large source of disruption for air traffic management operations. Being able to predict thunderstorms the day before operations can help traffic managers plan around weather and improve air traffic flow management operations. In this paper, machine learning is applied on data from satellite storm observations and ensemble numerical weather prediction products to detect convective weather 36 h in advance. The learning task is formulated as a binary classification problem and a neural network is trained to predict the occurrence of storms. The neural network results are used to develop a probabilistic based convection indicator capable of outperforming existing convection indicators found in the literature. Lastly, applications of the neural network based indicator in an air traffic management setting are presented.},
  archive      = {J_MLA},
  author       = {Aniel Jardines and Manuel Soler and Alejandro Cervantes and Javier García-Heras and Juan Simarro},
  doi          = {10.1016/j.mlwa.2021.100053},
  journal      = {Machine Learning with Applications},
  pages        = {100053},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Convection indicator for pre-tactical air traffic flow management using neural networks},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning-based malicious user detection for reliable
cooperative radio spectrum sensing in cognitive radio-internet of
things. <em>MLA</em>, <em>5</em>, 100052. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Cognitive Radio based Internet of Things (CR-IoT) is a promising technology that provides IoT endpoints, i.e., CR-IoT users the capability to share the radio spectrum otherwise allocated to licensed Primary Users (PUs). Cooperative Spectrum Sensing (CSS) improves spectrum sensing accuracy in a CR-IoT network. However, its performance may be degraded by potential attacks of the malicious CR-IoT users that send their incorrect sensing information to the corresponding Fusion Center (FC). This study presents a promising Machine Learning (ML)-based malicious user detection scheme for a CR-IoT network that uses a Support Vector Machine (SVM) algorithm to identify and classify malicious CR-IoT users. The classification allows the FC to make a more robust global decision based on the sensing results (i.e., energy vectors) which are reported only by the normal CR-IoT users. The effectiveness of the proposed SVM algorithm based ML in a CR-IoT network with the malicious CR-IoT users is verified via simulations.},
  archive      = {J_MLA},
  author       = {Md Shamim Hossain and Md Sipon Miah},
  doi          = {10.1016/j.mlwa.2021.100052},
  journal      = {Machine Learning with Applications},
  pages        = {100052},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Machine learning-based malicious user detection for reliable cooperative radio spectrum sensing in cognitive radio-internet of things},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Public policymaking for international agricultural trade
using association rules and ensemble machine learning. <em>MLA</em>,
<em>5</em>, 100046. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {International economics has a long history of improving our understanding of factors causing trade, and the consequences of free flow of goods and services across countries. The recent shocks to the free-trade regime, especially trade disputes among major economies, as well as black swan events (such as trade wars and pandemics), raise the need for improved predictions to inform policy decisions. Artificial Intelligence (AI) methods are allowing economists to solve such prediction problems in new ways. In this manuscript, we present novel methods that predict and associate food and agricultural commodities traded internationally. Association Rules (AR) analysis has been deployed successfully for economic scenarios at the consumer or store level (such as for market basket analysis). In our work however; we present analysis of imports/exports associations and their effects on country–commodity trade flows. Moreover, Ensemble Machine Learning (EML) methods are developed to provide improved agricultural trade predictions, outlier events’ implications, and quantitative pointers to policy makers.},
  archive      = {J_MLA},
  author       = {Feras A. Batarseh and Munisamy Gopinath and Anderson Monken and Zhengrong Gu},
  doi          = {10.1016/j.mlwa.2021.100046},
  journal      = {Machine Learning with Applications},
  pages        = {100046},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Public policymaking for international agricultural trade using association rules and ensemble machine learning},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain tumor detection in MR image using superpixels,
principal component analysis and template based k-means clustering
algorithm. <em>MLA</em>, <em>5</em>, 100044. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present era, human brain tumor is the extremist dangerous and devil to the human being that leads to certain death. Furthermore, the brain tumor arises more complexity of patients life with time. As a result, early detection of tumors is most crucial to save and prolong the patient’s lifetime. Therefore, enhanced brain tumor detection is required in medical fields. Automatic human brain tumor detection in magnetic resonance imaging (MRI) is playing a vital role in several symptomatic and cures applications. However, the existing schemes (e.g., random forest , Fuzzy C-means, artificial neural network (ANN) and wavelet transform) can detect brain tumors with insufficient accuracy and longer execution time (in minutes). In this paper, we propose an enhanced brain tumor detection scheme based on the template-based K-means (TK) algorithm with superpixels and principal component analysis (PCA) which efficiently detects the human brain tumors in lower execution time. At first, we extract essential features using both superpixels and PCA which helps accurately to detect brain tumors. Then, image enhancement is done using a filter that helps to improve accuracy. Finally, the image segmentation is performed through TK-means clustering algorithm to detect the brain tumor. The experimental results show that the proposed detection scheme achieves a better accuracy and a reduced execution time (in seconds) than other existing schemes for the detection of brain tumor in MR image.},
  archive      = {J_MLA},
  author       = {Md Khairul Islam and Md Shahin Ali and Md Sipon Miah and Md Mahbubur Rahman and Md Shahariar Alam and Mohammad Amzad Hossain},
  doi          = {10.1016/j.mlwa.2021.100044},
  journal      = {Machine Learning with Applications},
  pages        = {100044},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Brain tumor detection in MR image using superpixels, principal component analysis and template based K-means clustering algorithm},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretable predictive maintenance for hard drives.
<em>MLA</em>, <em>5</em>, 100042. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing machine learning approaches for data-driven predictive maintenance are usually black boxes that claim high predictive power yet cannot be understood by humans. This limits the ability of humans to use these models to derive insights and understanding of the underlying failure mechanisms, and also limits the degree of confidence that can be placed in such a system to perform well on future data. We consider the task of predicting hard drive failure in a data center using recent algorithms for interpretable machine learning. We demonstrate that these methods provide meaningful insights about short- and long-term drive health, while also maintaining high predictive performance . We also show that these analyses still deliver useful insights even when limited historical data is available, enabling their use in situations where data collection has only recently begun.},
  archive      = {J_MLA},
  author       = {Maxime Amram and Jack Dunn and Jeremy J. Toledano and Ying Daisy Zhuo},
  doi          = {10.1016/j.mlwa.2021.100042},
  journal      = {Machine Learning with Applications},
  pages        = {100042},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Interpretable predictive maintenance for hard drives},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting pulmonary coccidioidomycosis with deep
convolutional neural networks. <em>MLA</em>, <em>5</em>, 100040. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Coccidioidomycosis is the most common systemic mycosis in dogs in the southwestern United States. With warming climates, affected areas and number of cases are expected to increase in the coming years, escalating also the chances of transmission to humans. As a result, developing methods for automating the detection of the disease is important, as this will help doctors and veterinarians more easily identify and diagnose positive cases. We apply machine learning models to provide accurate and interpretable predictions of Coccidioidomycosis. We assemble a set of radiographic images and use it to train and test state-of-the-art convolutional neural networks to detect Coccidioidomycosis. These methods are relatively inexpensive to train and very fast at inference time. We demonstrate the successful application of this approach to detect the disease with an Area Under the Curve (AUC) above 0.99 using 10-fold cross-validation. We also use the classification model to identify regions of interest and localize the disease in the radiographic images, as illustrated through visual heatmaps. This proof-of-concept study establishes the feasibility of very accurate and rapid automated detection of Valley Fever in radiographic images.},
  archive      = {J_MLA},
  author       = {Jordan Ott and David Bruyette and Cody Arbuckle and Dylan Balsz and Silke Hecht and Lisa Shubitz and Pierre Baldi},
  doi          = {10.1016/j.mlwa.2021.100040},
  journal      = {Machine Learning with Applications},
  pages        = {100040},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Detecting pulmonary coccidioidomycosis with deep convolutional neural networks},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FogNet: A multiscale 3D CNN with double-branch dense block
and attention mechanism for fog prediction. <em>MLA</em>, <em>5</em>,
100038. (<a href="https://doi.org/10.1016/j.mlwa.2021.100038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reduction of visibility adversely affects land, marine, and air transportation. Thus, the ability to skillfully predict fog would provide utility. We predict fog visibility categories below 1600 m, 3200 m and 6400 m by post-processing numerical weather prediction model output and satellite-based sea surface temperature (SST) using a 3D-Convolutional Neural Network (3D-CNN). The target is an airport located on a barrier island adjacent to a major US port; measured visibility from this airport serves as a proxy for fog that develops over the port. The features chosen to calibrate and test the model originate from the North American Mesoscale Forecast System, with values of each feature organized on a 32 × 32 horizontal grid; the SSTs were obtained from the NASA Multiscale Ultra Resolution dataset. The input to the model is organized as a high dimensional cube containing 288 to 384 layers of 2D horizontal fields of meteorological variables (predictor maps). In this 3D-CNN (hereafter, FogNet), two parallel branches of feature extraction have been designed, one for spatially auto-correlated features (spatial-wise dense block and attention module), and the other for correlation between input variables (variable-wise dense block and attention mechanism .) To extract features representing processes occurring at different scales, a 3D multiscale dilated convolution is used. Data from 2009 to 2017 (2018 to 2020) are used to calibrate (test) the model. FogNet performance results for 6, 12 − 12− and 24 − h 24−h lead times are compared to results from the High-Resolution Ensemble Forecast (HREF) system. FogNet outperformed HREF using 8 standard evaluation metrics .},
  archive      = {J_MLA},
  author       = {Hamid Kamangir and Waylon Collins and Philippe Tissot and Scott A. King and Hue Thi Hong Dinh and Niall Durham and James Rizzo},
  doi          = {10.1016/j.mlwa.2021.100038},
  journal      = {Machine Learning with Applications},
  pages        = {100038},
  shortjournal = {Mach. Learn. Appl.},
  title        = {FogNet: A multiscale 3D CNN with double-branch dense block and attention mechanism for fog prediction},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online handwritten gurmukhi word recognition using
fine-tuned deep convolutional neural network on offline features.
<em>MLA</em>, <em>5</em>, 100037. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recognition of online handwriting is a vital application of pattern recognition, which involves the extraction of spatial and temporal information of handwritten patterns, and understanding the handwritten text while writing on the digital surface. Although, online handwriting recognition is a mature but exciting and fast developing field of pattern recognition, the same is not true for many of the Indic scripts. Gurmukhi is one of such popular scripts of India, and online handwriting recognition issues for larger units as words or sentences largely remained unexplored for this script till date. The existing study and first ever attempt for online handwritten Gurmukhi word recognition has relied upon the widely used hidden Markov model. This existing study evaluated against and performed very well in their chosen metrics. But, the available online handwritten Gurmukhi word recognition system could not obtain more than 90\% recognition accuracy in data dependent environment too. The present study provided benchmark results for online handwritten Gurmukhi word recognition using deep learning architecture convolutional neural network , and obtained above 97\% recognition accuracy in data dependent mode of handwriting. The previous Gurmukhi word recognition system followed the stroke based class labeling approach, whereas the present study has followed the word based class labeling approach. Present Online handwritten Gurmukhi word recognition results are quite satisfactory. Moreover, the proposed architecture can be used to improve the benchmark results of online handwriting recognition of several major Indian scripts. Experimental results demonstrated that the deep learning system achieved great results in Gurmukhi script and outperforms existing results in the literature.},
  archive      = {J_MLA},
  author       = {Sukhdeep Singh and Anuj Sharma and Vinod Kumar Chauhan},
  doi          = {10.1016/j.mlwa.2021.100037},
  journal      = {Machine Learning with Applications},
  pages        = {100037},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Online handwritten gurmukhi word recognition using fine-tuned deep convolutional neural network on offline features},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An enhanced technique of skin cancer classification using
deep convolutional neural network with transfer learning models.
<em>MLA</em>, <em>5</em>, 100036. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is one of the top three perilous types of cancer caused by damaged DNA that can cause death. This damaged DNA begins cells to grow uncontrollably and nowadays it is getting increased speedily. There exist some researches for the computerized analysis of malignancy in skin lesion images. However, analysis of these images is very challenging having some troublesome factors like light reflections from the skin surface, variations in color illumination, different shapes, and sizes of the lesions. As a result, evidential automatic recognition of skin cancer is valuable to build up the accuracy and proficiency of pathologists in the early stages. In this paper, we propose a deep convolutional neural network (DCNN) model based on deep learning approach for the accurate classification between benign and malignant skin lesions. In preprocessing we firstly, apply filter or kernel to remove noise and artifacts; secondly, normalize the input images and extract features that help for accurate classification; and finally, data augmentation increases the number of images that improves the accuracy of classification rate. To evaluate the performance of our proposed, DCNN model is compared with some transfer learning models such as AlexNet, ResNet , VGG-16, DenseNet, MobileNet, etc. The model is evaluated on the HAM10000 dataset and ultimately we obtained the highest 93.16\% of training and 91.93\% of testing accuracy respectively. The final outcomes of our proposed DCNN model define it as more reliable and robust when compared with existing transfer learning models.},
  archive      = {J_MLA},
  author       = {Md Shahin Ali and Md Sipon Miah and Jahurul Haque and Md Mahbubur Rahman and Md Khairul Islam},
  doi          = {10.1016/j.mlwa.2021.100036},
  journal      = {Machine Learning with Applications},
  pages        = {100036},
  shortjournal = {Mach. Learn. Appl.},
  title        = {An enhanced technique of skin cancer classification using deep convolutional neural network with transfer learning models},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Individual time series and composite forecasting of the
chinese stock index. <em>MLA</em>, <em>5</em>, 100035. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We explore the short-run forecasting problem at horizons of 1, 5, 10, 15, and 20 days for three forecasting periods within one year for the Chinese stock index from April 16, 2010, the launch date of the index futures, to May 19, 2014 with daily closing prices. We study forecast performance of 51 individual time series models that are different variations of autoregressive models, (Bayesian) vector autoregressive models, and (Bayesian) vector error correction models, and 41 composite models based on different trimming strategies of these individual models. The composite models, including the previous best forecast, equal-weighted average, inverse mean squared error, bias adjusted mean, shrinkage, and odds matrix approaches , utilize the idea of model boosting to diversify against possible mis-specifications, breaks, and structural changes in individual models, and aim at more robust performance. Across all forecasting horizons and forecasting periods investigated, we arrive at a shrinkage composite model with the shrinkage parameter of 0.25 that is optimal based on the mean squared error. This result is robust against the choice of futures series used in individual models and the pre-processing of structural breaks in data. We also discuss empirical findings at a more granular level , including comparisons of individual models and those of composite forecasts. Our results should fulfill different forecasting users’ information needs for decision making and policy analysis. The empirical framework also has potential of being adapted to similar time series forecasting problems in different fields.},
  archive      = {J_MLA},
  author       = {Xiaojie Xu and Yun Zhang},
  doi          = {10.1016/j.mlwa.2021.100035},
  journal      = {Machine Learning with Applications},
  pages        = {100035},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Individual time series and composite forecasting of the chinese stock index},
  volume       = {5},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the way: Hailing a taxi with a smartphone? A hybrid
SEM-neural network approach. <em>MLA</em>, <em>4</em>, 100034. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Undoubtedly, mobile taxi booking (MTB) services have resulted in a significant disruption to the lives of the general public. However, with a lot of firms offering the service in Malaysia, this will bring about confusion to users, especially in deciding which MTB service is the best for their usage. As such, this research looks into determining the antecedents that affect the adoption of MTB services. This was achieved through the utilization of an extended Mobile Technology Acceptance Model (MTAM). A total of 330 usable responses were analyzed using Partial Least Squares-Structural Equation Modeling​ (PLS-SEM) and Artificial Neural Network (ANN) that yielded novel insights which will significantly benefit numerous stakeholders. Furthermore, this research extends the literature on MTB services from the perspective of a developing country and verifies the robustness of using an extended MTAM.},
  archive      = {J_MLA},
  author       = {Amos Junke Lau and Garry Wei-Han Tan and Xiu-Ming Loh and Lai-Ying Leong and Voon-Hsien Lee and Keng-Boon Ooi},
  doi          = {10.1016/j.mlwa.2021.100034},
  journal      = {Machine Learning with Applications},
  pages        = {100034},
  shortjournal = {Mach. Learn. Appl.},
  title        = {On the way: Hailing a taxi with a smartphone? a hybrid SEM-neural network approach},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text categorization with WEKA: A survey. <em>MLA</em>,
<em>4</em>, 100033. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work shows the use of WEKA , a tool that implements the most common machine learning algorithms , to perform a Text Mining analysis on a set of documents. Applying these methods requires initial steps where the text is converted into a structured format. Both the processing phase and the analysis of the transformed dataset, using classification and clustering algorithms, can be carried out entirely with this tool, in a rigorous and simple way. The work describes the construction of two classification models starting from two different sets of documents. These models are not meant to be good or realistic, but just illustrate how WEKA can be used for a Text Mining analysis.},
  archive      = {J_MLA},
  author       = {Donatella Merlini and Martina Rossini},
  doi          = {10.1016/j.mlwa.2021.100033},
  journal      = {Machine Learning with Applications},
  pages        = {100033},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Text categorization with WEKA: A survey},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A benchmark study of machine learning models for online fake
news detection. <em>MLA</em>, <em>4</em>, 100032. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The proliferation of fake news and its propagation on social media has become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been suggested to detect fake news. However, most of those focused on a specific type of news (such as political) which leads us to the question of dataset-bias of the models used. In this research, we conducted a benchmark study to assess the performance of different applicable machine learning approaches on three different datasets where we accumulated the largest and most diversified one. We explored a number of advanced pre-trained language models for fake news detection along with the traditional and deep learning ones and compared their performances from different aspects for the first time to the best of our knowledge. We find that BERT and similar pre-trained models perform the best for fake news detection, especially with very small dataset. Hence, these models are significantly better option for languages with limited electronic contents, i.e., training data. We also carried out several analysis based on the models’ performance, article’s topic, article’s length, and discussed different lessons learned from them. We believe that this benchmark study will help the research community to explore further and news sites/blogs to select the most appropriate fake news detection method.},
  archive      = {J_MLA},
  author       = {Junaed Younus Khan and Md. Tawkat Islam Khondaker and Sadia Afroz and Gias Uddin and Anindya Iqbal},
  doi          = {10.1016/j.mlwa.2021.100032},
  journal      = {Machine Learning with Applications},
  pages        = {100032},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A benchmark study of machine learning models for online fake news detection},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Review of classification algorithms with changing
inter-class distances. <em>MLA</em>, <em>4</em>, 100031. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms are often faced with several data related problems. Real-world datasets come in various types and dimensions, each of which constitute some form of data related problems; moreover, they often contain irrelevant or noisy features. As a result of these, different data related problems require different techniques for the classification process. In this paper, some data related problems of interest are replicated in different synthetic datasets in order to investigate and evaluate the performance of a range of learning algorithms. Specifically, the data problems studied in this research are: datasets with varying inter class distances (classes are separated by different amounts); datasets with classes having different input relevance; datasets with classes defined by multiple features and by multiple underlying pattern; datasets with increasing number of noisy features; and datasets with varying amplitudes of noisy features. Also, datasets with combination of some of the problems were also synthesized. These datasets were then used to measure and validate the performance of a number of selected classification algorithms . The results of the experimental investigations show that the GNG had the best performance on datasets with varying inter class distances while DL performed best on the other datasets of different data problems.},
  archive      = {J_MLA},
  author       = {Uduak Idio Akpan and Andrew Starkey},
  doi          = {10.1016/j.mlwa.2021.100031},
  journal      = {Machine Learning with Applications},
  pages        = {100031},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Review of classification algorithms with changing inter-class distances},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforcement learning for control of valves. <em>MLA</em>,
<em>4</em>, 100030. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is a study of reinforcement learning (RL) as an optimal-control strategy for control of nonlinear valves. It is evaluated against the PID (proportional–integral–derivative) strategy, using a unified framework. RL is an autonomous learning mechanism that learns by interacting with its environment. It is gaining increasing attention in the world of control systems as a means of building optimal-controllers for challenging dynamic and nonlinear processes. Published RL research often uses open-source tools (Python and OpenAI Gym environments). We use MATLAB’s recently launched (R2019a) Reinforcement Learning Toolbox \texttrademark to develop the valve controller; trained using the DDPG (Deep Deterministic Policy-Gradient) algorithm and Simulink® to simulate the nonlinear valve and create the experimental test-bench for evaluation. Simulink allows industrial engineers to quickly adapt and experiment with other systems of their choice. Results indicate that the RL controller is extremely good at tracking the signal with speed and produces a lower error with respect to the reference signal. The PID, however, is better at disturbance rejection and hence provides a longer life for the valves. Successful machine learning involves tuning many hyperparameters requiring significant investment of time and efforts. We introduce “Graded Learning” as a simplified, application oriented adaptation of the more formal and algorithmic “Curriculum for Reinforcement Learning”. It is shown via experiments that it helps converge the learning task of complex non-linear real world systems. Finally, experiential learnings gained from this research are corroborated against published research.},
  archive      = {J_MLA},
  author       = {Rajesh Siraskar},
  doi          = {10.1016/j.mlwa.2021.100030},
  journal      = {Machine Learning with Applications},
  pages        = {100030},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Reinforcement learning for control of valves},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inferring incompressible two-phase flow fields from the
interface motion using physics-informed neural networks. <em>MLA</em>,
<em>4</em>, 100029. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, physics-informed neural networks are applied to incompressible two-phase flow problems. We investigate the forward problem, where the governing equations are solved from initial and boundary conditions, as well as the inverse problem , where continuous velocity and pressure fields are inferred from scattered-time data on the interface position. We employ a volume of fluid approach, i.e. the auxiliary variable here is the volume fraction of the fluids within each phase. For the forward problem, we solve the two-phase Couette and Poiseuille flow. For the inverse problem, three classical test cases for two-phase modeling are investigated: (i) drop in a shear flow, (ii) oscillating drop and (iii) rising bubble. Data of the interface position over time is generated by numerical simulation. An effective way to distribute spatial training points to fit the interface, i.e. the volume fraction field, and the residual points is proposed. Furthermore, we show that appropriate weighting of losses associated with the residual of the partial differential equations is crucial for successful training. The benefit of using adaptive activation functions is evaluated for both the forward and inverse problem.},
  archive      = {J_MLA},
  author       = {Aaron B. Buhendwa and Stefan Adami and Nikolaus A. Adams},
  doi          = {10.1016/j.mlwa.2021.100029},
  journal      = {Machine Learning with Applications},
  pages        = {100029},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Inferring incompressible two-phase flow fields from the interface motion using physics-informed neural networks},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Audio classification of violin bowing techniques: An aid for
beginners. <em>MLA</em>, <em>4</em>, 100028. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Playing violin requires both left and right hands that move into one another to produce one distinctive sound. While some violin players improve their hearing and recognize these techniques, it can be difficult for some people. Although there are names and categories for each violin technique, distinctions sometimes become ambiguous. This paper presents an audio classification model utilizing Convolutional Neural Network (CNN) that determines the sound produced by violin and classifies the used technique. The dataset used was gathered from real violin players who were tasked to record themselves playing one specific technique. The recorded tracks were then carefully trimmed to remove the noise. The pre-processed recordings served as an input to a benchmark CNN model. To fully optimize the CNN model, we modified the architecture of the model and tweaked the hyper-parameters. A comparative analysis between the two models was discussed in the latter part of this paper. The result of the analysis showed that our proposed model with an average of 94.8\% accuracy outperformed the benchmark model with an average of 87.6\% accuracy. Using stratified cross-validation of five folds, we were able to measure the accuracy, training time, and predicting time of the models. A paired t-test with a p p -value of 0.01 that shows a significance between the performance of the two models.},
  archive      = {J_MLA},
  author       = {Hernan S. Alar and Ramil O. Mamaril and Lex P. Villegas and Jhon Roe D. Cabarrubias},
  doi          = {10.1016/j.mlwa.2021.100028},
  journal      = {Machine Learning with Applications},
  pages        = {100028},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Audio classification of violin bowing techniques: An aid for beginners},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time series classification of radio signal strength for
qualitative estimate of UAV motion. <em>MLA</em>, <em>4</em>, 100027.
(<a href="https://doi.org/10.1016/j.mlwa.2021.100027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many common navigation solutions fall short when an aircraft’s GPS signal is either jammed or spoofed. This is typically due to the iterative nature of the estimation process, which requires an acceptably accurate initial estimate, or due to the accumulated error of inertial sensors, which are unable to directly observe the position of an aircraft. A mechanism is presented in this paper which operates on qualitative information, allowing an aircraft to remain within a vicinity despite an absence of precision localization. A long-short-term-memory neural network was used for time series classification of radio signal strength data on a light weight fixed wing UAV . Simulation results show that the two class classifier is able to determine the motion of an aircraft with respect to a radio beacon with 97.73\% accuracy. The classes used for classification represent motion as either towards, or away from a beacon. A simple high level controller was designed to use the classification output and converge on a beacon. Results from this paper indicate that this unique application of qualitative navigation by the application of time series classification offers a viable alternative to aircraft navigation in GPS denied environments.},
  archive      = {J_MLA},
  author       = {Samuel Teague and Javaan Chahl},
  doi          = {10.1016/j.mlwa.2021.100027},
  journal      = {Machine Learning with Applications},
  pages        = {100027},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Time series classification of radio signal strength for qualitative estimate of UAV motion},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SSentiA: A self-supervised sentiment analyzer for
classification from unlabeled data. <em>MLA</em>, <em>4</em>, 100026.
(<a href="https://doi.org/10.1016/j.mlwa.2021.100026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, supervised machine learning (ML) methods have realized remarkable performance gains for sentiment classification utilizing labeled data. However, labeled data are usually expensive to obtain, thus, not always achievable. When annotated data are unavailable, the unsupervised tools are exercised, which still lag behind the performance of supervised ML methods by a large margin. Therefore, in this work, we focus on improving the performance of sentiment classification from unlabeled data . We present a self-supervised hybrid methodology SSentiA (Self-supervised Sentiment Analyzer) that couples an ML classifier with a lexicon-based method for sentiment classification from unlabeled data. We first introduce LRSentiA (Lexical Rule-based Sentiment Analyzer), a lexicon-based method to predict the semantic orientation of a review along with the confidence score of prediction. Utilizing the confidence scores of LRSentiA, we generate highly accurate pseudo-labels for SSentiA that incorporates a supervised ML algorithm to improve the performance of sentiment classification for less polarized and complex reviews. We compare the performances of LRSentiA and SSSentA with the existing unsupervised, lexicon-based and self-supervised methods in multiple datasets. The LRSentiA performs similarly to the existing lexicon-based methods in both binary and 3-class sentiment analysis . By combining LRSentiA with an ML classifier, the hybrid approach SSentiA attains 10\%–30\% improvements in macro F1 score for both binary and 3-class sentiment analysis. The results suggest that in domains where annotated data are unavailable, SSentiA can significantly improve the performance of sentiment classification. Moreover, we demonstrate that using 30\%–60\% annotated training data, SSentiA delivers similar performances of the fully labeled training dataset.},
  archive      = {J_MLA},
  author       = {Salim Sazzed and Sampath Jayarathna},
  doi          = {10.1016/j.mlwa.2021.100026},
  journal      = {Machine Learning with Applications},
  pages        = {100026},
  shortjournal = {Mach. Learn. Appl.},
  title        = {SSentiA: A self-supervised sentiment analyzer for classification from unlabeled data},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A geometric-based data reduction approach for large low
dimensional datasets: Delaunay triangulation in SVM algorithms.
<em>MLA</em>, <em>4</em>, 100025. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training a support vector machine (SVM) on large datasets is a slow daunting process. Further, SVM becomes slow in the testing phase, due to its large number of support vectors (SVs). This paper proposes an effective geometric algorithm based on construction of Delaunay triangulation (DT) algorithm using Quickhull algorithm with a novel strategy to exactly identify and extract the boundary data points laid between the two classes of a dataset, and later uses these most informative data points as a reduced dataset to solve various SVM algorithms and proposes new DT-SVM algorithms Two synthetic datasets with the size of 1K incrementally up to 500K datasets are generated to extensively verify the effectiveness of the proposed DT-SVM algorithms over various data sizes and for further assessment, the most efficient version of proposed DT-SVM is applied on well-known benchmark datasets from UCI Machine Learning Repository. Two variant of sequential minimization optimization (SMO) decomposition methods , in addition to Least Square form of SVM are implemented to present the scalability of new DT-SVM algorithms in linear/nonlinear separable/non-separable large low dimensional datasets. Moreover, the most efficient version of the proposed algorithm is compared to RCH-SK as a known geometric approach in the SVM literature. The results demonstrate that while the proposed approach improves the scalability of DT-SVM in large low dimensional datasets, it leads SVM algorithms to maintain the accuracy in an acceptable range with considerably lower time in both training and testing phases with using a noticeably fewer number of SVs.},
  archive      = {J_MLA},
  author       = {Omid Naghash Almasi and Modjtaba Rouhani},
  doi          = {10.1016/j.mlwa.2021.100025},
  journal      = {Machine Learning with Applications},
  pages        = {100025},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A geometric-based data reduction approach for large low dimensional datasets: Delaunay triangulation in SVM algorithms},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An effective adaptive customization framework for small
manufacturing plants using extreme gradient boosting-XGBoost and random
forest ensemble learning algorithms in an industry 4.0 environment.
<em>MLA</em>, <em>4</em>, 100024. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prevailing competitive manufacturing industry calls for continuous customer satisfaction for business sustainability. With the emergence of the Industry 4.0 paradigm, product customization, which gives customers the means to personalized products to meet their needs, has become a strategy to increase companies’ value. High-tech manufacturing firms are already diving deep into Industry 4.0 standards adopting innovative strategies to outstand themselves in the market, while small manufacturing plants are slow in embracing the digital transformation. The high cost involved in acquiring indispensable resources and the lack of expertise are some of the obstacles low-tech businesses face in endorsing this new paradigm. Inspired by the customization challenges of a small manufacturing plant, our main research contribution is to develop an effective adaptive customization platform that encodes the customization data history of a small manufacturing plant, from a static database, into a dynamic machine learning model to produce personalized products for their customers accurately. Our research improves customers’ experience by reducing the customization system’s complexity consisting of inputting several parameters to obtain personalized products to a single entry. The back-end of the platform uses powerful machine learning (ML) algorithms like extreme gradient boosting (XGBoost) and Random Forest (RF) ensemble learning to match a single customer input to the desired customized product category. Our research experiments convey insights, such as the best scenarios to use XGBoost over RF algorithms for regression problems with non-linear data. The excellent experimental results achieved on both machine learning models show the merits of this customization platform.},
  archive      = {J_MLA},
  author       = {Sonia Kahiomba Kiangala and Zenghui Wang},
  doi          = {10.1016/j.mlwa.2021.100024},
  journal      = {Machine Learning with Applications},
  pages        = {100024},
  shortjournal = {Mach. Learn. Appl.},
  title        = {An effective adaptive customization framework for small manufacturing plants using extreme gradient boosting-XGBoost and random forest ensemble learning algorithms in an industry 4.0 environment},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent trends in crowd analysis: A review. <em>MLA</em>,
<em>4</em>, 100023. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When overpopulated cities face frequent crowded events like strikes, demonstrations, parades or other sorts of people gatherings, they are confronted to multiple security issues. To mitigate these issues, security forces are often involved to monitor the gatherings and to ensure the security of their participants. However, when access to technology is limited, the security forces can quickly become overwhelmed. Fortunately, more and more important smart cities are adopting the concept of intelligent surveillance systems. In these situations, intelligent surveillance systems require the most advanced techniques of crowd analysis to monitor crowd events properly. In this review, we explore various studies related to crowd analysis. Crowd analysis is commonly broken down into two major branches: crowd statistics and crowd behavior analysis. When crowd statistics determines the Level Of Service (LoS) of a crowded scene, crowd behavior analysis describes the motion patterns and the activities that are observed in a scene. One of the hottest topics of crowd analysis is anomaly detection . Although a unanimous definition of anomaly has not yet been met, each of crowd analysis subtopics can be subjected to abnormality. The purpose of our review is to find subareas, in crowd analysis, that are still unexplored or that seem to be rarely addressed through the prism of Deep Learning .},
  archive      = {J_MLA},
  author       = {Mounir Bendali-Braham and Jonathan Weber and Germain Forestier and Lhassane Idoumghar and Pierre-Alain Muller},
  doi          = {10.1016/j.mlwa.2021.100023},
  journal      = {Machine Learning with Applications},
  pages        = {100023},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Recent trends in crowd analysis: A review},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction of obstructive sleep apnea using fast fourier
transform of overnight breath recordings. <em>MLA</em>, <em>4</em>,
100022. (<a href="https://doi.org/10.1016/j.mlwa.2021.100022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The objective of this study is to address the problem of predicting the risk of obstructive sleep apnea (OSA) from overnight breath recordings collected by a subject using a smartphone or an iPhone. The dataset used in this study was collected at a health care facility and consists of breathing amplitudes of 42 subjects using the smart phone App ZeeAppnea. A total of four data mining multi-level classifiers are used on the Fast Fourier Transform (FFT) of each time series, and prediction accuracies are computed. The Random Forest (RF) and the Support Vector Machine (SVM) classifiers yielded the best results, with overall multi-level prediction accuracies of 93\% and 90\%, respectively; the overall multi-level prediction accuracy of manual interpretations of recordings was 55\%. The binary overall accuracies for the severe OSA class were 98\% (RF), 95\% (SVM) and 69\% (manual interpretations). Our results show that either RF or SVM can be used on the recordings obtained from ZeeAppnea instead of the time-consuming manual interpretation of charts of breathing amplitudes by medical personnel, as this would improve prediction accuracy and automate the process of this screening application.},
  archive      = {J_MLA},
  author       = {Nicole L. Molin and Clifford Molin and Rohan J. Dalpatadu and Ashok K. Singh},
  doi          = {10.1016/j.mlwa.2021.100022},
  journal      = {Machine Learning with Applications},
  pages        = {100022},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Prediction of obstructive sleep apnea using fast fourier transform of overnight breath recordings},
  volume       = {4},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tunnel geomechanical parameters prediction using gaussian
process regression. <em>MLA</em>, <em>3</em>, 100020. (<a
href="https://doi.org/10.1016/j.mlwa.2021.100020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this study is to apply a modern intelligent method of Gaussian process regression (GPR) to predict the geological parameter of Rock Quality Designation (RQD) along the tunnel route. This method can also be used for any geological parameter prediction of tunnel future levels. The GPR method has been studied based on data obtained from 51 tunnels all over the world. Fifty data sets were utilized for intelligent modeling, while one of the data sets that belonged to Hamru tunnel in Iran, was used to evaluate the prediction approach. The comparisons’ results indicate that the GPR model’s prediction results are generally in good agreement with the actual results. The proposed GPR, on the whole, performs better than the support vector machine (SVM), artificial neural network (ANN) and linear regression (LR) in predictive analysis of the RQD parameter.},
  archive      = {J_MLA},
  author       = {Arsalan Mahmoodzadeh and Mokhtar Mohammadi and Hawkar Hashim Ibrahim and Tarik Ahmed Rashid and Adil Hussain Mohammed Aldalwie and Hunar Farid Hama Ali and Ako Daraei},
  doi          = {10.1016/j.mlwa.2021.100020},
  journal      = {Machine Learning with Applications},
  pages        = {100020},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Tunnel geomechanical parameters prediction using gaussian process regression},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influence propagation based community detection in complex
networks. <em>MLA</em>, <em>3</em>, 100019. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interaction between nodes in a complex network showing the property of homophily tends to produce community structure in the network. The detection of these communities is of immense financial and informational value . For this purpose, we propose a semi-supervised community detection algorithm , inspired by genetic genealogy and based on Label Propagation Algorithm , that detects communities in the network by taking into account the propagation of influence from different community centers identified in the network. Analysis of our proposed algorithm showed improved performance in detecting communities in real social networks.},
  archive      = {J_MLA},
  author       = {Parth Verma and Rinkaj Goyal},
  doi          = {10.1016/j.mlwa.2020.100019},
  journal      = {Machine Learning with Applications},
  pages        = {100019},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Influence propagation based community detection in complex networks},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OpinionMine: A bayesian-based framework for opinion mining
using twitter data. <em>MLA</em>, <em>3</em>, 100018. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies opinion mining from social media with probabilistic logic reasoning. As it is known, Twitter is one of the most active social networks, with millions of tweets sent daily, where multiple users express their opinion about traveling, economic issues, political decisions etc. As such, it offers a valuable source of information for opinion mining. In this paper we present OpinionMine, a Bayesian-based framework for opinion mining, exploiting Twitter Data. Initially, our framework imports Tweets massively by using Twitter’s API. Next, the imported Tweets are further processed automatically for constructing a set of untrained rules and random variables. Then, a Bayesian Network is derived by using the set of untrained rules, the random variables and an evidence set. After that, the trained model can be used for the evaluation of new Tweets. Finally, the constructed model can be retrained incrementally, thus becoming more robust. As application domain for the development of our methodology we have selected tourism because it is one of the most popular topics in social media. Our framework can predict users’ intention to visit a place. Among the advantages of our framework is that it follows an incremental learning strategy. That is, the derived model can be retrained incrementally with new training sets thus becoming more robust. Further, our framework can be easily adapted to opinion mining from social media on other topics, whereas the rules of the derived model are constructed in an efficient way and automatically.},
  archive      = {J_MLA},
  author       = {Stefanos Zervoudakis and Emmanouil Marakakis and Haridimos Kondylakis and Stefanos Goumas},
  doi          = {10.1016/j.mlwa.2020.100018},
  journal      = {Machine Learning with Applications},
  pages        = {100018},
  shortjournal = {Mach. Learn. Appl.},
  title        = {OpinionMine: A bayesian-based framework for opinion mining using twitter data},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scaleable input gradient regularization for adversarial
robustness. <em>MLA</em>, <em>3</em>, 100017. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work we revisit gradient regularization for adversarial robustness with some new ingredients. First, we derive new per-image theoretical robustness bounds based on local gradient information. These bounds strongly motivate input gradient regularization. Second, we implement a scaleable version of input gradient regularization which avoids double backpropagation : adversarially robust ImageNet models are trained in 33 h on four consumer grade GPUs. Finally, we show experimentally and through theoretical certification that input gradient regularization is competitive with adversarial training . Moreover we demonstrate that gradient regularization does not lead to gradient obfuscation or gradient masking.},
  archive      = {J_MLA},
  author       = {Chris Finlay and Adam M. Oberman},
  doi          = {10.1016/j.mlwa.2020.100017},
  journal      = {Machine Learning with Applications},
  pages        = {100017},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Scaleable input gradient regularization for adversarial robustness},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid and effective learning approach for click fraud
detection. <em>MLA</em>, <em>3</em>, 100016. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click Fraud is a fraudulent act of clicking on pay-per-click advertisements to increase the site’s revenue or to drain revenue from the advertiser. This illegal act has been putting commercial industries in a dilemma for quite some time. These industries think twice before advertising their products on websites and mobile-apps, as many parties try to exploit them. To safely promote their products, there must be an efficient system to detect click fraud. To address this problem, we propose a model called CFXGB (Cascaded Forest and XGBoost). The proposed model, classified under supervised machine learning , is a combination of two learning models used for feature transformation and classification. We showcase its superior performance compared to other related models, and make a comparison with multiple click fraud datasets with varying sizes.},
  archive      = {J_MLA},
  author       = {Thejas G.S. and Surya Dheeshjith and S.S. Iyengar and N.R. Sunitha and Prajwal Badrinath},
  doi          = {10.1016/j.mlwa.2020.100016},
  journal      = {Machine Learning with Applications},
  pages        = {100016},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A hybrid and effective learning approach for click fraud detection},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving discourse representations with node hierarchy
attention. <em>MLA</em>, <em>3</em>, 100015. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long text representation for natural language processing tasks has capture researchers’ attention recently. Beyond the sentence, finding a good representation for the text turns to the bag of the words that losses sequence order. Indeed, the text does not pattern in a haphazard way; rather, in a coherent document there exist systematic connections between sentences. Rhetorical structure theory models this connection in a tree structure format. This tree models text span and their relation. The importance of each text span is distinguished by their hierarchy type in the tree named nucleus and satellite. In this paper, we try to enrich text representation by taking into account the contribution of each phrase in the text based on its hierarchy type. We employ a deep recursive neural network as the attention mechanism to improve text representation. Our hypothesis is evaluated in a sentiment analysis framework. In addition, basic recursive neural network and predefined weighting attention consider as benchmarks. Results show that reweighting span vectors via a deeper layer of recursive neural network outperforms predefined scalar and no attention methods.},
  archive      = {J_MLA},
  author       = {Erfaneh Gharavi and Hadi Veisi and Rupesh Silwal and Matthew S. Gerber},
  doi          = {10.1016/j.mlwa.2020.100015},
  journal      = {Machine Learning with Applications},
  pages        = {100015},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Improving discourse representations with node hierarchy attention},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). White-box machine learning approaches to identify governing
equations for overall dynamics of manufacturing systems: A case study on
distillation column. <em>MLA</em>, <em>3</em>, 100014. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamical equations form the basis of design for manufacturing processes and control systems; however, identifying governing equations using a mechanistic approach is tedious. Recently, Machine learning (ML) has shown promise to identify the governing dynamical equations for physical systems faster. This possibility of rapid identification of governing equations provides an exciting opportunity for advancing dynamical systems modeling. However, applicability of the ML approach in identifying governing mechanisms for the dynamics of complex systems relevant to manufacturing has not been tested. We test and compare the efficacy of two white-box ML approaches (SINDy and SymReg) for predicting dynamics and structure of dynamical equations for overall dynamics in a distillation column. Results demonstrate that a combination of ML approaches should be used to identify a full range of equations. In terms of physical law, few terms were interpretable as related to Fick’s law of diffusion and Henry’s law in SINDy, whereas SymReg identified energy balance as driving dynamics.},
  archive      = {J_MLA},
  author       = {Renganathan Subramanian and Raghav Rajesh Moar and Shweta Singh},
  doi          = {10.1016/j.mlwa.2020.100014},
  journal      = {Machine Learning with Applications},
  pages        = {100014},
  shortjournal = {Mach. Learn. Appl.},
  title        = {White-box machine learning approaches to identify governing equations for overall dynamics of manufacturing systems: A case study on distillation column},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep gated recurrent neural network for petroleum
production forecasting. <em>MLA</em>, <em>3</em>, 100013. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting of oil production plays a vital role in petroleum engineering and contributes to supporting engineers in the management of petroleum reservoirs. However, reliable production forecasting is difficult to achieve, particularly in view of the increase in digital oil big data. Although a significant amount of work has been reported in the literature in relation to the use of machine learning in the oil and gas domain, traditional forecasting approaches have limited potential in terms of representing the complex features of time series data . More specifically, in a high-dimensional nonlinear multivariate time series dataset, a shallow machine is incapable of inferring the dependencies between past and future values. In this context, a novel forecasting model for petroleum production is proposed in this work. The model is a deep-gated recurrent neural network consisting of multiple hidden layers, where each layer has a number of nodes. The proposed model has a low-complexity architecture and the capacity to track long-interval time-series datasets. To evaluate the robustness of our model, the proposed technique was benchmarked with various standard approaches. The extensive empirical results demonstrate that the proposed model outperforms existing approaches.},
  archive      = {J_MLA},
  author       = {Raghad Al-Shabandar and Ali Jaddoa and Panos Liatsis and Abir Jaafar Hussain},
  doi          = {10.1016/j.mlwa.2020.100013},
  journal      = {Machine Learning with Applications},
  pages        = {100013},
  shortjournal = {Mach. Learn. Appl.},
  title        = {A deep gated recurrent neural network for petroleum production forecasting},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data mining of hospital suicidal and self-harm presentation
records using a tailored evolutionary algorithm. <em>MLA</em>,
<em>3</em>, 100012. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The assessment of outcomes for the Gold Coast Mental Health and Specialist Services Suicide Prevention Strategy implementation required data on suicidal and self-harm presentations to be captured from the Emergency Department Information System (EDIS) database. Suicidal and self-harm presentations are not uniformly coded in the EDIS and require human assessment to differentiate these presentations from other cases (e.g., accidental injuries). A novel evolutionary algorithm was used to learn weighting variables from a psychiatrist-rated training dataset in order to generate an appropriate cut-off score for identifying suicidal and self-harm presentations from EDIS. The resulting Searching EDIS for Records of Suicidal Presentations (SERoSP) program was then run on a psychiatrist-rated validation dataset using the weights generated by the algorithm. SERoSP is optimised to be able to detect suicidal and self-harm presentations with a high degree of accuracy (a sensitivity of 0.95 and a specificity of 0.92). The SERoSP program is a reliable and cost-effective tool for the identification of suicidal and self-harm presentations from EDIS data, and is currently being successfully used in the suicide prevention strategy evaluation.},
  archive      = {J_MLA},
  author       = {Nicolas J.C. Stapelberg and Marcus Randall and Jerneja Sveticic and Pete Fugelli and Hasmeera Dave and Kathryn Turner},
  doi          = {10.1016/j.mlwa.2020.100012},
  journal      = {Machine Learning with Applications},
  pages        = {100012},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Data mining of hospital suicidal and self-harm presentation records using a tailored evolutionary algorithm},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart healthcare disease diagnosis and patient management:
Innovation, improvement and skill development. <em>MLA</em>, <em>3</em>,
100011. (<a href="https://doi.org/10.1016/j.mlwa.2020.100011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data mining (DM) is an instrument of pattern detection and retrieval of knowledge from a large quantity of data. Many robust early detection services and other health-related technologies have developed from clinical and diagnostic evidence in both the DM and healthcare sectors . Artificial Intelligence (AI) is commonly used in the research and health care sectors. Classification or predictive analytics is a key part of AI in machine learning (ML). Present analyses of new predictive models founded on ML methods demonstrate promise in the area of scientific research. Healthcare professionals need accurate predictions of the outcomes of various illnesses that patients suffer from. In addition, timing is another significant aspect that affects clinical choices for precise predictions. In this regard, the authors have reviewed numerous publications in this area in terms of method, algorithms, and performance. This review paper summarized the documentation examined in accordance with approaches, styles, activities, and processes. The analyses and assessment techniques of the selected papers are discussed and an appraisal of the findings is presented to conclude the article. Present statistical models of healthcare remedies have been scientifically reviewed in this article. The uncertainty between statistical methods and ML has now been clarified. The study of related research reveals that the prediction of existing forecasting models differs even if the same dataset is used. Predictive models are also essential, and new approaches need to be improved.},
  archive      = {J_MLA},
  author       = {Arkadip Ray and Avijit Kumar Chaudhuri},
  doi          = {10.1016/j.mlwa.2020.100011},
  journal      = {Machine Learning with Applications},
  pages        = {100011},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Smart healthcare disease diagnosis and patient management: Innovation, improvement and skill development},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Predictions of adsorption energies of methane-related
species on cu-based alloys through machine learning. <em>MLA</em>,
<em>3</em>, 100010. (<a
href="https://doi.org/10.1016/j.mlwa.2020.100010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies show that the adsorption energy can be used as a descriptor of the catalytic activity in methane direct conversion. We develop Gaussian process regression models to predict DFT-calculated adsorption energies of CH 4 related species – CH 3 , CH 2 , CH, C, and H – on Cu-based alloys from elements’ readily available physical properties. As compared to conventional first-principle-based methods, the models are simple and fast to implement. They produce predictions with root mean squared errors of below 0.15 eV. The models also present numerical and statistical relationships between fundamental physiochemical parameters of doped elements and adsorption energies. Hence, they might be considered as efficient alternatives to the DFT approach for adsorption energy calculations, which allow for further assessments of certain solid catalysts’ catalytic performance.},
  archive      = {J_MLA},
  author       = {Yun Zhang and Xiaojie Xu},
  doi          = {10.1016/j.mlwa.2020.100010},
  journal      = {Machine Learning with Applications},
  pages        = {100010},
  shortjournal = {Mach. Learn. Appl.},
  title        = {Predictions of adsorption energies of methane-related species on cu-based alloys through machine learning},
  volume       = {3},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
