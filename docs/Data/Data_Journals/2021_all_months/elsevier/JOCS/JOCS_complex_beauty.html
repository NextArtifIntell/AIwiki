<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>JOCS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="jocs---156">JOCS - 156</h2>
<ul>
<li><details>
<summary>
(2021). Physics engine based simulation of shear behavior of
granular soils using hard and soft contact models. <em>JOCS</em>,
<em>56</em>, 101504. (<a
href="https://doi.org/10.1016/j.jocs.2021.101504">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physics engines have been widely used to simulate physical and mechanical processes in modern video games to create an immersive and realistic gaming experience. This study explores the feasibility of using an open-source physics engine, Chrono, as a discrete element method (DEM) platform to simulate shear behavior of granular soils. This study develops a series of pre-processing, servo-controlling, and post-processing functions to improve the Chrono platform, so that Chrono can generate soil specimens with designed packing densities, perform laboratory test simulations such as direct shear tests, and output stress-strain, fabric, and force chains. Traditional DEM codes use soft contact models (e.g., Hertzian contact model) to determine inter-particle contact forces, while most physics engines use a hard contact model (e.g., non-smooth contact dynamics) to determine inter-particle contact forces. The hard contact model enables physics engines to use large time steps in iterations without affecting the numerical stability and simulation accuracy, which remarkably accelerate simulation speeds compared with traditional DEM codes. Based on systematical comparisons between simulation results of two contact models and experimental results, this study demonstrates that the hard contact model can yield the shear behavior of granular soils observed in soft contact model simulations and laboratory tests.},
  archive      = {J_JOCS},
  author       = {Hantao He and Junxing Zheng and Ying Chen and Yingjie Ning},
  doi          = {10.1016/j.jocs.2021.101504},
  journal      = {Journal of Computational Science},
  pages        = {101504},
  shortjournal = {J. Comput. Sci.},
  title        = {Physics engine based simulation of shear behavior of granular soils using hard and soft contact models},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A conservative and stable explicit finite difference scheme
for the diffusion equation. <em>JOCS</em>, <em>56</em>, 101491. (<a
href="https://doi.org/10.1016/j.jocs.2021.101491">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present a conservative and stable explicit finite difference scheme for the heat equation. We use Saul’yev-type finite difference scheme and propose a conservative weighted correction step to make the scheme conservative. We can practically use about 100 times larger time step than the fully Euler-type explicit scheme. Computational results demonstrate that the proposed scheme has stable and good conservative properties.},
  archive      = {J_JOCS},
  author       = {Junxiang Yang and Chaeyoung Lee and Soobin Kwak and Yongho Choi and Junseok Kim},
  doi          = {10.1016/j.jocs.2021.101491},
  journal      = {Journal of Computational Science},
  pages        = {101491},
  shortjournal = {J. Comput. Sci.},
  title        = {A conservative and stable explicit finite difference scheme for the diffusion equation},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An algorithm for numerical solution of some nonlinear
multi-dimensional parabolic partial differential equations.
<em>JOCS</em>, <em>56</em>, 101487. (<a
href="https://doi.org/10.1016/j.jocs.2021.101487">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this research paper, a numerical method, named the three-step Ultraspherical wavelet collocation method, is presented for solving some nonlinear multi-dimensional parabolic partial differential equations . The method is third-order accurate in time. In this method, the three-step Taylor method is used to get the time derivative, while the Ultraspherical wavelet collocation method is used to get the space derivatives. Ultraspherical wavelets have good properties which make useful to carry out this aim. The presented method is developed for Burgers’ equation, Fisher–Kolmogorov–Petrovsky–Piscounov (Fisher–KPP) equation, and quasilinear parabolic equation . Three illustrative numerical problems are solved to demonstrate the efficiency, simplicity, and reliability of the presented method.},
  archive      = {J_JOCS},
  author       = {Neslihan Ozdemir and Aydin Secer and Mustafa Bayram},
  doi          = {10.1016/j.jocs.2021.101487},
  journal      = {Journal of Computational Science},
  pages        = {101487},
  shortjournal = {J. Comput. Sci.},
  title        = {An algorithm for numerical solution of some nonlinear multi-dimensional parabolic partial differential equations},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep neural network based framework for restoring the
damaged persian pottery via digital inpainting. <em>JOCS</em>,
<em>56</em>, 101486. (<a
href="https://doi.org/10.1016/j.jocs.2021.101486">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conservation of the historical artworks involves carefully planning interventions to prolong the material, historical, and design integrity of humanity&#39;s-built heritage. Among which, restoration of the destroyed parts of the artworks via inpainting is one of the most critical stages in the restorative conservation. Indeed, one of the significant assets of any art-historical work is its aesthetic aspects. However, usually due to the visual complexity and the diversity of the motifs, the number of patterns that a restorer artist can have in mind when repairing them, are limited. Also, the inpainting process of such artworks might be very slow and prone to errors; a slight error can cause severe mistakes for the aesthetic aspects of the artifact. Therefore, the need to develop an intelligent system to provide an image of the refurbished artifact before to the restoration operation, is undeniable. Motivated by the idea that the computer-vision-based image inpainting process could be an efficient solution for this purpose, in this paper, for the first time, we propose a framework that employs a deep artificial neural network-based approach to inpaint the images of Persian pottery for restoring their damaged parts. The framework can repair irregular structures that usually exist in Persian pottery and inpaints relatively large missing parts. Besides, the restored parts were seamlessly integrated with the rest of the image without the need for any further postprocessing. To evaluate the proposed framework, we have collected 677 images from different Kubachi ware (known as Persian pottery) to study the inpainting results. The provided dataset is available free for the research community. Quantitative and qualitative evaluations of the results show that the proposed framework performs well, where the inpainted parts are visually and semantically plausible, and the details of the predicted colors in the damaged areas are very satisfying.},
  archive      = {J_JOCS},
  author       = {Nacer Farajzadeh and Mahdi Hashemzadeh},
  doi          = {10.1016/j.jocs.2021.101486},
  journal      = {Journal of Computational Science},
  pages        = {101486},
  shortjournal = {J. Comput. Sci.},
  title        = {A deep neural network based framework for restoring the damaged persian pottery via digital inpainting},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Burr detection and classification using RUSTICO and image
processing. <em>JOCS</em>, <em>56</em>, 101485. (<a
href="https://doi.org/10.1016/j.jocs.2021.101485">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machined workpieces must satisfy quality standards such as avoid the presence of burrs in edge finishing to reduce production costs and time. In this work we consider three types of burr that are determined by the distribution of the edge shape on a microscopic scale: knife-type (without imperfections), saw-type (presence of small splinters that could be accepted) and burr-breakage (substantial deformation that produces unusable workpieces). The proposed method includes RUSTICO to classify automatically the edge of each piece according to its burr type. Experimental results validate its effectiveness, yielding a 91.2\% F1-Score and identifying completely the burr-breakage type.},
  archive      = {J_JOCS},
  author       = {Virginia Riego and Lidia Sánchez-González and Laura Fernández-Robles and Alexis Gutiérrez-Fernández and Nicola Strisciuglio},
  doi          = {10.1016/j.jocs.2021.101485},
  journal      = {Journal of Computational Science},
  pages        = {101485},
  shortjournal = {J. Comput. Sci.},
  title        = {Burr detection and classification using RUSTICO and image processing},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NURBS functional network approach for automatic image
segmentation of macroscopic medical images in melanoma detection.
<em>JOCS</em>, <em>56</em>, 101481. (<a
href="https://doi.org/10.1016/j.jocs.2021.101481">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing techniques are becoming standard technology in many medical specialities, such as dermatology, where they are a key tool for the early detection and diagnosis of melanoma and other skin cancers and tumors. A previous paper by the authors presented at SOCO 2020 conference introduced a new method for image segmentation of skin images through functional networks. The method performs well but it relies on a semi-automatic approach involving a combination of manual and automatic operations. This paper aims at making image segmentation of macroscopic skin images a fully automatic process . To this purpose, the present work extends our previous paper with five new relevant contributions: (1) a filtering strategy for removal of noise, hair and other artifacts; (2) two morphological operators for image enhancement; (3) a clustering-based binary classifier to separate the skin tumor from the image background; (4) a smoothing and discretization process to obtain the border points; and (5) a curve reconstruction method from the border points with NURBS using a new type of functional network particularly tailored for this task. This new method is applied to two different benchmarks, comprised respectively of four and two macroscopic medical images of skin tumors. The visual and numerical results show that the method performs very well, yielding segmented images which are suitable for clinical practice. This method is a significant step towards the future development of a fully automatic approach for the whole medical image analysis pipeline of skin images, including diagnosis and classification.},
  archive      = {J_JOCS},
  author       = {Akemi Gálvez and Andrés Iglesias and Iztok Fister and Iztok Fister Jr. and César Otero and José A. Díaz},
  doi          = {10.1016/j.jocs.2021.101481},
  journal      = {Journal of Computational Science},
  pages        = {101481},
  shortjournal = {J. Comput. Sci.},
  title        = {NURBS functional network approach for automatic image segmentation of macroscopic medical images in melanoma detection},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty quantification of real gas models in CO2
supersonic flow. <em>JOCS</em>, <em>56</em>, 101479. (<a
href="https://doi.org/10.1016/j.jocs.2021.101479">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Carbon dioxide ( CO 2 CO2 ) is an undesirable component present in natural gas composition. The supersonic separator is a new and potential technology for natural gas treatment, which expands the gas through supersonic velocities until a shock wave formation. The modeling capacity to predict the shock wave position inside the device is analyzed considering parametric uncertainties. Results from four real gas models were compared in computational fluid dynamic modeling. Uncertainties that affect coefficients in the real gas models were propagated through the carbon dioxide flow solver using the Latin Hypercube Sampling approach. It was observed that the shock wave introduces non-linearity in the local standard deviation. Soave–Redlich–Kwong and Aungier–Redlich–Kwong are slightly affected by input parametric uncertainties. On the other hand, the Peng–Robinson model results are strongly affected.},
  archive      = {J_JOCS},
  author       = {Wenna Raissa dos Santos Cruz and Fabio Pereira dos Santos and Ricardo de Andrade Medronho},
  doi          = {10.1016/j.jocs.2021.101479},
  journal      = {Journal of Computational Science},
  pages        = {101479},
  shortjournal = {J. Comput. Sci.},
  title        = {Uncertainty quantification of real gas models in CO2 supersonic flow},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A low-storage method consistent with second-order statistics
for time-resolved databases of turbulent channel flow up to reτ=5300.
<em>JOCS</em>, <em>56</em>, 101476. (<a
href="https://doi.org/10.1016/j.jocs.2021.101476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wall-bounded flows play an important role in numerous common applications, and have been intensively studied for over a century. However, the dynamics and structure of the logarithmic and outer regions remain controversial to this date, and understanding their dynamics is essential for the development of effective prediction and control strategies, and for the construction of a complete theory of wall-bounded flows. Recently, the use of time-resolved direct numerical simulations of turbulent flows at high Reynolds numbers has proved useful to study the physics of wall-bounded turbulence, but a proper analysis of the logarithmic and outer layers requires simulations at high Reynolds numbers in large domains, making the storage of complete time series challenging. In this paper a novel low-storage method for time-resolved databases is presented. This approach reduces the storage cost of time-resolved databases by storing filtered flow fields that target the large and intermediate scales, while retaining all the information needed to fully reconstruct the flow at the level of filtered flow fields and complete second-order statistics. This is done by storing also the filtered turbulent stresses, allowing to recover the exact effect of the small scales on the large and intermediate scales. A significant speed-up of the computations is achieved, first, by relaxing the numerical resolution, which is shown to affect only the dynamics close to the wall, but not the large scales stored in the database, and, second, by exploiting the computing power and efficiency of GPU co-processors using a new high-resolution hybrid CUDA-MPI code. This speed-up allows running for physically meaningful times to capture the dynamics of the large scales. The resulting temporally resolved large-scale database of a turbulent channel flow up to R e τ = 5300 Reτ=5300 , in large boxes for long times, is briefly introduced, showing significant indicators of large-scale dynamics with characteristic times of the order of up to eight eddy turnover times.},
  archive      = {J_JOCS},
  author       = {Alberto Vela-Martín and Miguel P. Encinar and Adrián García-Gutiérrez and Javier Jiménez},
  doi          = {10.1016/j.jocs.2021.101476},
  journal      = {Journal of Computational Science},
  pages        = {101476},
  shortjournal = {J. Comput. Sci.},
  title        = {A low-storage method consistent with second-order statistics for time-resolved databases of turbulent channel flow up to reτ=5300},
  volume       = {56},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved sine–cosine algorithm with dynamic selection
pressure. <em>JOCS</em>, <em>55</em>, 101477. (<a
href="https://doi.org/10.1016/j.jocs.2021.101477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sine cosine algorithm (SCA) is a newly developed optimization tool that has received increasing attention in the field of computational intelligence. Nevertheless, SCA has a combination of strong exploration and weak exploitation abilities, which undermines the performance of the algorithm. A dynamic selection strategy (DSS) has been proposed in this paper to overcome this limitation. The central idea is that the selection pressure of the parent is dynamically regulated during the course of evolution, and the parent with higher fitness have higher selection probability. Accordingly, the weak exploitation ability of SCA can be enhanced. This approach can be readily applied to other SCA variants as well. Results from systematic experiments conducted on CEC2014 competition benchmark suite show that the proposed DSS method can significantly improve the performance of the SCAs. In addition, the proposed DSS-SCA algorithm has been successfully applied to six engineering design problems, which shows that the algorithm has the potential to solve other practical problems.},
  archive      = {J_JOCS},
  author       = {Wenjuan He and Bing Wang and Ning Li and Xiaojie Gao and Wei Li and Qiaoyong Jiang},
  doi          = {10.1016/j.jocs.2021.101477},
  journal      = {Journal of Computational Science},
  pages        = {101477},
  shortjournal = {J. Comput. Sci.},
  title        = {An improved sine–cosine algorithm with dynamic selection pressure},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computational techniques for h2 optimal frequency-limited
model order reduction of large-scale sparse linear systems.
<em>JOCS</em>, <em>55</em>, 101473. (<a
href="https://doi.org/10.1016/j.jocs.2021.101473">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of frequency limited H 2 H2 optimal model order reduction for large-scale sparse linear systems. A set of first-order H 2 H2 optimality conditions are derived for the frequency limited model order reduction problem. These conditions involve the solution of two frequency limited Sylvester equations that are known to be computationally complex. We discuss a framework for solving these matrix equations efficiently. The idea is also extended to the frequency limited H 2 H2 optimal model order reduction of index-1 descriptor systems. Numerical experiments are carried out using Python programming language and the results are presented to demonstrate the approximation accuracy and computational efficiency of the proposed technique.},
  archive      = {J_JOCS},
  author       = {Xin Du and Kife I. Bin Iqbal and M. Monir Uddin and A. Mostakim Fony and Md. Tanzim Hossain and Mian Ilyas Ahmad and Mohammad Sahadet Hossain},
  doi          = {10.1016/j.jocs.2021.101473},
  journal      = {Journal of Computational Science},
  pages        = {101473},
  shortjournal = {J. Comput. Sci.},
  title        = {Computational techniques for h2 optimal frequency-limited model order reduction of large-scale sparse linear systems},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient momentum conservation constrained PDE-LDDMM with
gauss–newton–krylov optimization, semi-lagrangian runge–kutta solvers,
and the band-limited parameterization. <em>JOCS</em>, <em>55</em>,
101470. (<a href="https://doi.org/10.1016/j.jocs.2021.101470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes three efficient variants of Jacobi EPDiff PDE-LDDMM, where efficiency is achieved through Semi-Lagrangian Runge–Kutta integration and the band-limited parameterization. During Gauss–Newton–Krylov optimization, the method computes the gradient and the Hessian-vector product on the final time sample, and transports these magnitudes towards the initial time using the adjoint Jacobi equations and their incremental counterparts. Then, the optimization is performed on the initial time sample. The proposed methods have effectively achieved a considerable reduction of the computational complexity at a competitive accuracy. These variants constitute a contribution to the efficient computation of diffeomorphisms belonging to geodesics, suitable for statistical shape analysis or the construction of transversal and longitudinal models of shape variability using Principal Geodesic Analysis and Geodesic Regression in spaces of diffeomorphisms.},
  archive      = {J_JOCS},
  author       = {Monica Hernandez},
  doi          = {10.1016/j.jocs.2021.101470},
  journal      = {Journal of Computational Science},
  pages        = {101470},
  shortjournal = {J. Comput. Sci.},
  title        = {Efficient momentum conservation constrained PDE-LDDMM with Gauss–Newton–Krylov optimization, semi-lagrangian Runge–Kutta solvers, and the band-limited parameterization},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparison of combined data assimilation and machine
learning methods for offline and online model error correction.
<em>JOCS</em>, <em>55</em>, 101468. (<a
href="https://doi.org/10.1016/j.jocs.2021.101468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that it is possible to combine machine learning methods with data assimilation to reconstruct a dynamical system using only sparse and noisy observations of that system. The same approach can be used to correct the error of a knowledge-based model. The resulting surrogate model is hybrid, with a statistical part supplementing a physical part. In practice, the correction can be added as an integrated term ( i.e. in the model resolvent) or directly inside the tendencies of the physical model. The resolvent correction is easy to implement. The tendency correction is more technical, in particular it requires the adjoint of the physical model, but also more flexible. We use the two-scale Lorenz model to compare the two methods. The accuracy in long-range forecast experiments is somewhat similar between the surrogate models using the resolvent correction and the tendency correction. By contrast, the surrogate models using the tendency correction significantly outperform the surrogate models using the resolvent correction in data assimilation experiments. Finally, we show that the tendency correction opens the possibility to make online model error correction, i.e. improving the model progressively as new observations become available. The resulting algorithm can be seen as a new formulation of weak-constraint 4D-Var. We compare online and offline learning using the same framework with the two-scale Lorenz system, and show that with online learning, it is possible to extract all the information from sparse and noisy observations.},
  archive      = {J_JOCS},
  author       = {Alban Farchi and Marc Bocquet and Patrick Laloyaux and Massimo Bonavita and Quentin Malartic},
  doi          = {10.1016/j.jocs.2021.101468},
  journal      = {Journal of Computational Science},
  pages        = {101468},
  shortjournal = {J. Comput. Sci.},
  title        = {A comparison of combined data assimilation and machine learning methods for offline and online model error correction},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation of mixture components separation in a rarefied
argon-neon jet on the basis of direct solution of the boltzmann kinetic
equation. <em>JOCS</em>, <em>55</em>, 101467. (<a
href="https://doi.org/10.1016/j.jocs.2021.101467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An approach to numerical simulation of the flows of rarefied gas mixtures on the basis of direct solution of the Boltzmann kinetic equation is proposed. Software for simulating the rarefied gas flows based on the proposed approach was developed. Numerical simulation of a two-dimensional argon-neon gas mixture outflow from an instantly opened slit into vacuum was performed. Graphs of time evolution of output flow rates of the mixture components, and flow fields in steady-state regime were computed. Unsteady areas of strong gas mixture components separation were discovered.},
  archive      = {J_JOCS},
  author       = {S.S. Sitnikov and F.G. Tcheremissine},
  doi          = {10.1016/j.jocs.2021.101467},
  journal      = {Journal of Computational Science},
  pages        = {101467},
  shortjournal = {J. Comput. Sci.},
  title        = {Simulation of mixture components separation in a rarefied argon-neon jet on the basis of direct solution of the boltzmann kinetic equation},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FLOPs-efficient filter pruning via transfer scale for neural
network acceleration. <em>JOCS</em>, <em>55</em>, 101459. (<a
href="https://doi.org/10.1016/j.jocs.2021.101459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model pruning is a useful technique to reduce the computational cost of convolutional neural networks. In this paper, we first propose a simple but effective filter level pruning criterion, which assesses the importance of a filter by exploring the transfer scale (TS) of its feature maps in the next layer. The principle is that for a trained CNN model, an important filter should have strong connections with the next layer, otherwise the transfer scale of its feature map will be low and hence removing it will have little influence on the network. Besides, we observe that filters from the computationally-intensive layers are more sensitive to pruning, which makes it difficult to further compress the floating-point operations (FLOPs) of the model without reducing accuracy. To solve this problem, we propose a FLOPs-efficient group Lasso approach for TS to guide the network to use fewer filters in the computationally-intensive layers, which leads to better FLOPs compression performance after pruning. We refer to the proposed method as FETS. Compared with the state-of-the-art methods, our FETS achieves similar or better accuracy, but with significantly larger FLOPs compression ratio. In particular, with VGG-16, ResNet-56 and DenseNet-40 on CIFAR-10, we achieve similar or better accuracies than other methods, with only 48\%, 64\% and 58\% of the FLOPs. With ResNet-50 on ImageNet, we also achieve a relative FLOPs reduction of 30\%.},
  archive      = {J_JOCS},
  author       = {Zhixin Guo and Yifan Xiao and Wenzhi Liao and Peter Veelaert and Wilfried Philips},
  doi          = {10.1016/j.jocs.2021.101459},
  journal      = {Journal of Computational Science},
  pages        = {101459},
  shortjournal = {J. Comput. Sci.},
  title        = {FLOPs-efficient filter pruning via transfer scale for neural network acceleration},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Layer-wise relevance propagation for backbone identification
in discrete fracture networks. <em>JOCS</em>, <em>55</em>, 101458. (<a
href="https://doi.org/10.1016/j.jocs.2021.101458">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the framework of flow simulations in Discrete Fracture Networks, we consider the problem of identifying possible backbones, namely preferential channels in the network. Backbones can indeed be fruitfully used to analyze clogging or leakage, relevant for example in waste storage problems, or to reduce the computational cost of simulations. With a suitably trained Neural Network at hand, we use the Layer-wise Relevance Propagation as a feature selection method to detect the expected relevance of each fracture in a Discrete Fracture Network and thus identifying the backbone.},
  archive      = {J_JOCS},
  author       = {Stefano Berrone and Francesco Della Santa and Antonio Mastropietro and Sandra Pieraccini and Francesco Vaccarino},
  doi          = {10.1016/j.jocs.2021.101458},
  journal      = {Journal of Computational Science},
  pages        = {101458},
  shortjournal = {J. Comput. Sci.},
  title        = {Layer-wise relevance propagation for backbone identification in discrete fracture networks},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Verification of the neural network training process for
spectrum-based chemical substructure prediction using metamorphic
testing. <em>JOCS</em>, <em>55</em>, 101456. (<a
href="https://doi.org/10.1016/j.jocs.2021.101456">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fourier-transform infrared spectroscopy (FTIR) is one of the commonly used techniques in chemical analysis. The chemical bonds that are present in samples absorb infrared light at various wavelengths based on the properties of chemical bonds between sets of atoms bonded together. By extracting these absorbance patterns, we aim to predict the presence or absence of various substructures within a compound based on its FTIR spectrum. Hypothetically, a powerful machine learning method with enough examples of a substructure should be able to identify the structure of an unknown compound by analyzing its FTIR spectrum. To this extent we developed a novel system that trains neural networks to predict the presence of various substructures within a compound. We then propose to apply metamorphic testing to verify the network training process. Experimental results exhibit that metamorphic testing helps to develop a more effective training process for classifier neural networks.},
  archive      = {J_JOCS},
  author       = {Joshua D. Ellis and Razib Iqbal and Keiichi Yoshimatsu},
  doi          = {10.1016/j.jocs.2021.101456},
  journal      = {Journal of Computational Science},
  pages        = {101456},
  shortjournal = {J. Comput. Sci.},
  title        = {Verification of the neural network training process for spectrum-based chemical substructure prediction using metamorphic testing},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simple run-time infrastructure (SRTI): An accessible
distributed computing platform for interdisciplinary simulation.
<em>JOCS</em>, <em>55</em>, 101455. (<a
href="https://doi.org/10.1016/j.jocs.2021.101455">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed computing is a necessity for conducting cross-disciplinary research where field-specific computational models (simulators) are available, but have not been designed to work together. An example of this is natural hazards research. Simulators abound in the disparate fields that fall under this area, e.g. social science, engineering, economics, and health, but little progress has been made to integrate the simulators to study overarching and cross-disciplinary disaster scenarios. The reason for slow penetration of this technology is the high barrier to entry, which requires extensive knowledge of computer science and programming. Building upon an existing platform named Simple Run Time Infrastructure (SRTI v1), a new, fundamentally different version (SRTI v2) is developed to address the issues mentioned above. Designed to provide a low barrier to use, SRTI v2 is developed for users with limited programming experience and designed to simplify and streamline a user’s effort to compose a distributed simulation and handle time management. To achieve this primary objective, pre-compiled components are provided including the RTI Management Server, RTI Wrapper, and a GUI. By exploiting these pre-compiled components, users can compose a scalable distributed simulation with heterogeneous computational models. To demonstrate the concepts behind SRTI, a cross-language simulation, modified and extended from a time-dependent resilience analysis of an electric power system in the literature, is presented to show the scalability and usability of SRTI. Features of the different versions of SRTI are discussed and useful features to develop in the future are outlined.},
  archive      = {J_JOCS},
  author       = {Szu-Yun Lin and Andrew W. Hlynka and Lichao Xu and Hao Lu and Omar A. Sediek and Sherif El-Tawil and Vineet R. Kamat and Jason McCormick and Carol C. Menassa and Seymour M.J. Spence and Atul Prakash and Benigno Aguirre},
  doi          = {10.1016/j.jocs.2021.101455},
  journal      = {Journal of Computational Science},
  pages        = {101455},
  shortjournal = {J. Comput. Sci.},
  title        = {Simple run-time infrastructure (SRTI): An accessible distributed computing platform for interdisciplinary simulation},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Transformation operators based grey wolf optimizer for
travelling salesman problem. <em>JOCS</em>, <em>55</em>, 101454. (<a
href="https://doi.org/10.1016/j.jocs.2021.101454">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of swarm intelligence , the Grey Wolf Optimizer (GWO) is a popular algorithm based on leadership hierarchy. Primarily, GWO was proposed to solve continuous optimization problem . However, in recent years, GWO has been extensively explored to deal with a wide variety of real world problem regardless the nature of problem. GWO has received a lot of attention from researchers because of its advantages over other swarm intelligence approaches and its simplicity. The classical GWO is redesigned in this paper by incorporating the swap, shift and symmetry transformation operators to solve permutation-coded travelling salesman problem (TSP), and it is named as transformation operator based grey wolf optimizer (TO-GWO). In TO-GWO, each wolf represents a possible solution of TSP and using swap, shift and symmetry operators wolves interact with leader wolves in order to obtain optimal solution for TSP. In order to improve the proposed algorithm’s local search capability when solving discrete problems, 2-opt algorithm have also been adapted. The TO-GWO is implemented in MATLAB environment. In this study, the TO-GWO is tested over 50 TSP instances. Also, the results of proposed algorithm are compared with 12 state-of-the-art algorithms for TSP instances with various numbers of cities in order to evaluate its performance. For the majority of the TSP instances used in the experiment, the TO-GWO significantly outperforms other algorithms in terms of quality of solutions and efficiency.},
  archive      = {J_JOCS},
  author       = {Karuna Panwar and Kusum Deep},
  doi          = {10.1016/j.jocs.2021.101454},
  journal      = {Journal of Computational Science},
  pages        = {101454},
  shortjournal = {J. Comput. Sci.},
  title        = {Transformation operators based grey wolf optimizer for travelling salesman problem},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Axial vibration analysis of nanorods with variable density
based on nonlocal elastic theory and high-order finite difference
method. <em>JOCS</em>, <em>55</em>, 101452. (<a
href="https://doi.org/10.1016/j.jocs.2021.101452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel high-order finite difference method (p-FDM) for predicting the axial vibration behaviour of elastic nanorods with variable density based on nonlocal elastic theory. For p-FDM, it first solves the nodal weighting coefficients for approximating the first-order derivatives of displacements at the discrete nodes by using moving least-squares approximation. Next, p-FDM recursively determines the nodal weighting coefficients for approximating the higher-order derivatives by using the obtained weighting coefficients for the first-order derivative. After verifying with exact solutions, results show that the proposed p-FDM yields accurate vibration solutions for a nanorod with either fixed–fixed ends or fixed–free ends. Only a small number of regularly or irregularly distributed grid nodes are required by a high order p-FDM to obtain a converged solution. p-FDM realises an exponential rate of convergence for frequency solution when setting p = n − 2 p=n−2 where p p is order of p-FDM and n n is the number of grid nodes. New axial vibration solutions of nanorods with exponential density distribution are found by using p-FDM. It is shown that the axial frequencies are always larger for a nanorod with an exponential density distribution and no small-scale effect.},
  archive      = {J_JOCS},
  author       = {Y.P. Zhang},
  doi          = {10.1016/j.jocs.2021.101452},
  journal      = {Journal of Computational Science},
  pages        = {101452},
  shortjournal = {J. Comput. Sci.},
  title        = {Axial vibration analysis of nanorods with variable density based on nonlocal elastic theory and high-order finite difference method},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). YUKI algorithm and POD-RBF for elastostatic and dynamic
crack identification. <em>JOCS</em>, <em>55</em>, 101451. (<a
href="https://doi.org/10.1016/j.jocs.2021.101451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new metaheuristic algorithm with a search space reduction capability guided by simple formalism. The search population focuses partially on the inside the local search area while the rest explore globally, looking for better search areas. We call the new algorithm by YUKI Algoritm (YA) and employ it in a crack identification problem. With the aid of a set of measurements taken on the defected structure, we aim at identifying the crack parameters such as length and orientation. To this end, we use the so-called model reduction technique through Proper orthogonal Decomposition (POD) endorsed with Radial Basic Function (RBF), which helps in predicting (numerically) the measurement at new points (out of the set of sensors) via interpolation. This method is widely used in this context and was proven very effective computational-wise. In our study of the performance of YA, we deal with two cases; Firstly, in the case of the Elastostatic study. And secondly, in the case of dynamic analysis. We compare the performance of the suggested algorithm with the performance of well-known optimization methods, such as Teaching Learning Based Optimization (TLBO), Cuckoo Search (CS), and the Gray Wolf Optimizer (GWO). The results show that YA provides accurate and faster results compared to the mentioned algorithms.},
  archive      = {J_JOCS},
  author       = {Brahim Benaissa and Nourredine Aït Hocine and Samir Khatir and Mohamed Kamel Riahi and Seyedali Mirjalili},
  doi          = {10.1016/j.jocs.2021.101451},
  journal      = {Journal of Computational Science},
  pages        = {101451},
  shortjournal = {J. Comput. Sci.},
  title        = {YUKI algorithm and POD-RBF for elastostatic and dynamic crack identification},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Track finding algorithm using the track road method for the
PANDA forward tracker. <em>JOCS</em>, <em>55</em>, 101448. (<a
href="https://doi.org/10.1016/j.jocs.2021.101448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we present an algorithm for 3D track finding in the Forward Tracker of the PANDA experiment. This tracker is based on straw tube detectors and is designed to measure the deflection of particles in the magnetic field of the PANDA dipole magnet in order to determine their momenta. The algorithm uses the track road method for selecting track candidates. The applied track model in the projection onto the bending plane in the region before, inside and after the dipole magnet gap consists of line, circle and line, respectively. In the non-bending plane, a track projection is represented by a straight line. The algorithm was tested using simulated tracks of muons and obtained results for the track finding efficiency and for the momentum resolution are presented.},
  archive      = {J_JOCS},
  author       = {J. Płażek and J. Smyrski and P. Salabura and W. Przygoda and K. Korcyl},
  doi          = {10.1016/j.jocs.2021.101448},
  journal      = {Journal of Computational Science},
  pages        = {101448},
  shortjournal = {J. Comput. Sci.},
  title        = {Track finding algorithm using the track road method for the PANDA forward tracker},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Projecting LBM performance on exascale class architectures:
A tentative outlook. <em>JOCS</em>, <em>55</em>, 101447. (<a
href="https://doi.org/10.1016/j.jocs.2021.101447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the next years, the first Exascale class supercomputers will go online . In this paper, we portray a prospective Exascale scenario for a Lattice Boltzmann (LB) code, based on the performance obtained exploiting an up-to-date Petascale HPC facility. Although extrapolation is always a perilous exercise, in this work we aim to lay down a few guidelines to help the LBM community to carefully plan larger and more complex simulations using the forthcoming Exascale supercomputer machines.},
  archive      = {J_JOCS},
  author       = {Giorgio Amati and Sauro Succi and Pierluigi Fanelli and Vesselin K. Krastev and Giacomo Falcucci},
  doi          = {10.1016/j.jocs.2021.101447},
  journal      = {Journal of Computational Science},
  pages        = {101447},
  shortjournal = {J. Comput. Sci.},
  title        = {Projecting LBM performance on exascale class architectures: A tentative outlook},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An automated platform for assembling light-powered hydrogel
microrobots and their subsequent chemical binding. <em>JOCS</em>,
<em>55</em>, 101446. (<a
href="https://doi.org/10.1016/j.jocs.2021.101446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents light powered hydrogel microrobots (100 μm), that are directed to specific locations in their environment by an automated platform. The microrobots are actuated by focused laser light and crawl in aqueous environments by periodic volumetric changes of a section of their bodies. The platform consists of a stage, manipulated by stepper drivers and controlled by a Raspberry PI 4. This positions the laser light in the desired locations to move microrobots towards a goal location. The microrobots are localized via a microscope camera and repetitive usage of an algorithm based on Hough Gradient Method . The optimal position for the laser is chosen before every step so that the disk reaches the goal as fast as possible. Multiple disks are moved to form a formation of predefined geometry. An algorithm for finding the optimum sequence of disk movements to suitable positions is introduced. Subsequently, the disks are bound together chemically, using local UV illumination as the binding trigger. The bound formation can perform useful tasks, such as pushing and depositing a cargo at a target location.},
  archive      = {J_JOCS},
  author       = {Jan Vrba and Charlie Maslen and Jana Maxova and Jan Duras and Ivan Rehor and Jan Mares},
  doi          = {10.1016/j.jocs.2021.101446},
  journal      = {Journal of Computational Science},
  pages        = {101446},
  shortjournal = {J. Comput. Sci.},
  title        = {An automated platform for assembling light-powered hydrogel microrobots and their subsequent chemical binding},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). K and starting means for k-means algorithm. <em>JOCS</em>,
<em>55</em>, 101445. (<a
href="https://doi.org/10.1016/j.jocs.2021.101445">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The k-means method aims to divide a set of N objects into k clusters, where each cluster is represented by the mean value of its objects. This algorithm is simple and converges to local minima quickly. It has linear time complexity, but it requires the number of clusters in advance which requires some knowledge in advance, in addition to selecting the initial centers which affect the quality of the final result and the number of iterations. The quality of the final result and the number of iterations depend on both k and initial centers. Many papers tried to detect a suitable value for k (the number of clusters) or introduced a better method for selecting the initial centers only. This research introduces a method able to detect a near-optimal value for k and near-optimal initial centers. The proposed method adds a preprocessing step to get the number of clusters and the initial centers before applying the k-means method. The idea is to get initial clusters using a density-based method that does not require the number of clusters in advance and computes the mean values for objects in each cluster and uses this knowledge in k-means. This leads to improving the quality of the final result as presented in the experimental results. The proposed method will use the DBSCAN “Density-based spatial clustering of application with noise” method as a preprocessing step. So, the paper concentrates on the DBSCAN and k-means. The proposed method will converge to global minima which improve the quality of the final result. The proposed method requires the two input parameters for the DBSCAN method and its time complexity is o( n log n ) which is the same as that of DBSCAN.},
  archive      = {J_JOCS},
  author       = {Ahmed Fahim},
  doi          = {10.1016/j.jocs.2021.101445},
  journal      = {Journal of Computational Science},
  pages        = {101445},
  shortjournal = {J. Comput. Sci.},
  title        = {K and starting means for k-means algorithm},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards versatile conversations with data-driven dialog
management and its integration in commercial platforms. <em>JOCS</em>,
<em>55</em>, 101443. (<a
href="https://doi.org/10.1016/j.jocs.2021.101443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational interfaces have recently become a ubiquitous element in both the personal sphere by easing access to services, and industrial environments by the automation of services, improved customer support and its corresponding cost savings. However, designing the dialog model used by these interfaces to decide system responses is still a hard-to-accomplish task for complex conversational interactions. This paper describes a data-driven dialog management technique, which provides flexibility to develop, deploy and maintain this module. Various configurations for classification algorithms are assessed with two dialog corpora of different application domains, size, dimensionalities and set of possible system responses. The results of the evaluation show satisfactory accuracy and coherence rates in both tasks. As a proof of concept, our proposal has also been integrated with DialogFlow, a platform provided by Google to design conversational user interfaces. Our proposal has been assessed with a real use case, proving that it can be deployed in conjunction with commercial platforms, obtaining satisfactory results for the objective and subjective assessments completed.},
  archive      = {J_JOCS},
  author       = {Pablo Cañas and David Griol and Zoraida Callejas},
  doi          = {10.1016/j.jocs.2021.101443},
  journal      = {Journal of Computational Science},
  pages        = {101443},
  shortjournal = {J. Comput. Sci.},
  title        = {Towards versatile conversations with data-driven dialog management and its integration in commercial platforms},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Higher order and continuity l2 projections with piece-wise
constant test functions. <em>JOCS</em>, <em>55</em>, 101442. (<a
href="https://doi.org/10.1016/j.jocs.2021.101442">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on the isogeometric L 2 L2 projection problem employing higher-order C 1 C1 continuity basis functions that preserve the partition of unity. We show that the rows of the system of linear equations can be combined, and the test functions can be sum up to 1 using the partition of unity property at the quadrature points . Thus, the test functions in higher continuity IGA can be set to piece-wise constants. This formulation is equivalent to testing with piece-wise constant basis functions, with supports span over some parts of the domain. The resulting method is a Petrov–Galerkin formulation with piece-wise constant test functions. This observation has the following consequences. The numerical integration cost can be reduced because we do not need to evaluate the test functions since they are equal to 1. This observation is valid for any basis functions preserving the partition of unity property. It is independent of the problem dimension and geometry of the computational domain. The resulting method is equivalent to a linear combination of the collocations at points and with weights resulting from applied quadrature over the spans defined by supports of the piece-wise constant test functions. We show the algorithm for finding optimal supports of the piece-wise constant test functions using the inf–sup condition argument. We also discuss how the piece-wise constants’ replacement of the test functions can be utilized in modern integration methods, with weighted quadrature, sum factorization, and row by row assembly. We test our method on the isogeometric L 2 L2 projection, the explicit dynamics simulations in two and three dimensions, the heat transfer problem, and the three-dimensional elastic wave propagation simulations.},
  archive      = {J_JOCS},
  author       = {Maciej Paszyński and Marcin Łoś},
  doi          = {10.1016/j.jocs.2021.101442},
  journal      = {Journal of Computational Science},
  pages        = {101442},
  shortjournal = {J. Comput. Sci.},
  title        = {Higher order and continuity l2 projections with piece-wise constant test functions},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling information propagation in high-order networks
based on explicit–implicit relationship. <em>JOCS</em>, <em>55</em>,
101438. (<a href="https://doi.org/10.1016/j.jocs.2021.101438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A high-order network model with explicit relationship, implicit relationship and hyper nodes is constructed based on the characteristics of social networks. Based on this model, the information propagation processes in a complete trust network and a non-complete trust network are analyzed. In particular, when studying the information propagation in non-complete trust networks, a multi-information propagation training credibility SIR (MPTC-SIR) model is designed. Each node carries credibility value through propagating train with MPTC-SIR model and then quantifies it as the trust probability of nodes to the information. Finally, the simulations about true and fake information propagation were implemented respectively on three different networks. The experimental results show that the designed network model is closer to reality. The information propagation scope is much wider in the high-order complete trust network, and the information demise is relatively slow. The fake information spreads faster in the high-order non-complete trust network. In general, the trend of “bad news has wings” was reflected. The propagation of true information is slow but it is lasted a long time than that of fake information. The propagation of fake information is just the opposite. The theory matches the physical world, and the research has very important practical significance.},
  archive      = {J_JOCS},
  author       = {Fuzhong Nian and Yayong Shi and Jun Cao},
  doi          = {10.1016/j.jocs.2021.101438},
  journal      = {Journal of Computational Science},
  pages        = {101438},
  shortjournal = {J. Comput. Sci.},
  title        = {Modeling information propagation in high-order networks based on explicit–implicit relationship},
  volume       = {55},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Refinement of weights using attribute support for multiple
attribute decision making. <em>JOCS</em>, <em>54</em>, 101440. (<a
href="https://doi.org/10.1016/j.jocs.2021.101440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of approaches have been proposed to determine the weights for multiple attribute decision making . However, the resultant weights are usually assumed to be fixed, making it lack of tolerance to accommodate variation if the patterns of the subsequent data are subject to change. This article proposes a method to facilitate the adjustment of attribute weights, which accommodates a number of relevant characteristics. A model is first constructed that is able to express the requirements of a particular application. The concept of attribute support and consensus are then proposed for subsequent weight modification. A full algorithm is finally presented for the attribute weight adjustment. The effectiveness of the proposed method is validated by way of a case study in the tax credit domain with a sensitivity analysis of the method further evaluated.},
  archive      = {J_JOCS},
  author       = {Hengshan Zhang and Yimin Zhou and Tianhua Chen and Richard Hill and Zhongmin Wang and Yanping Chen},
  doi          = {10.1016/j.jocs.2021.101440},
  journal      = {Journal of Computational Science},
  pages        = {101440},
  shortjournal = {J. Comput. Sci.},
  title        = {Refinement of weights using attribute support for multiple attribute decision making},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards accommodating deadline driven jobs on high
performance computing platforms in grid computing environment.
<em>JOCS</em>, <em>54</em>, 101439. (<a
href="https://doi.org/10.1016/j.jocs.2021.101439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grid computing is a connected computing infrastructure that furnishes reliable, stable, ubiquitous, and economic access to high-end computational power. The dynamic nature of the grid brings several challenges to scheduling algorithms that operate in queuing-based scheduling approach. This approach typically performs scheduling based on a certain fixed priority which leads to increase the delay for the running applications. Thus, the overall performance will be deteriorated sharply. The main aim of this study is to minimize the delay in the scheduler for the dynamic jobs. Therefore, this paper tackles dynamic scheduling issues by proposing Swift Gap (SG) mechanism. SG comprises of two stages by applying two mechanisms: A Backfilling Mechanism and Metaheuristic Local Search Optimization Mechanism. In the first stage, the job is placed in the earliest gap available in the local resources’ schedules, while the second stage optimizes the performance by checking all available gaps among resources’ schedules to find a better gap to place the job in. To further improve the performance, the Completion Time Scheme (CTS) is developed. CTS reduces the delay by placing the job in the gap that guarantees the best start time for the job, and the fastest resource available. The integration between SG and CTS (SG-CTS) is achieved by applying best start time rule in the first stage only, whereas the second stage includes both rules.SG-CTS is evaluated through simulation by using real workloads that reflect a real grid system environment. The findings demonstrate that SG-CTS improves the slowdown by 27\%, bounded slowdown by 25\%, tardiness by 21\%, waiting time by 16\% and response time by 7\% compared to Conservative backfilling mechanism followed by Gap Search (CONS-GS). Finally, SG-CTS is evaluated against Deadline-Based Backfilling (DBF) algorithm. The evaluation revealed that SG-CTS performs better than DBF for slowdown and waiting time in HPC2N workload.},
  archive      = {J_JOCS},
  author       = {Omar Dakkak and Yousef Fazea and Shahrudin Awang Nor and Suki Arif},
  doi          = {10.1016/j.jocs.2021.101439},
  journal      = {Journal of Computational Science},
  pages        = {101439},
  shortjournal = {J. Comput. Sci.},
  title        = {Towards accommodating deadline driven jobs on high performance computing platforms in grid computing environment},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The role of the cellular automata cell size and time step
length in the microstructure evolution model—the static
recrystallization case study. <em>JOCS</em>, <em>54</em>, 101437. (<a
href="https://doi.org/10.1016/j.jocs.2021.101437">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper&#39;s main interest is the identification and elimination of major factors that can introduce disturbances in the predictions of the cellular automata (CA) static recrystallization (SRX) model. First, the most important CA SRX model components and major assumptions are shortly presented. Next, the determination of appropriate CA cell size, which is related to the CA space resolution, and CA time step length, is discussed. The new grain nucleation algorithm is also developed and is presented next. This research proved that such an algorithm is insensitive to the CA space size, increasing the model reliability in numerical simulation of SRX. Then, the minimum CA time step length, which does not affect the results and, at the same time, provides acceptable calculation time, is established. Obtained results indicate threshold values for both CA cell size and CA time step length that have to be reached to obtain reliable model predictions. The research outcome highlighted that the CA cell size of 0.375 μm is sufficient to discretize the area of 300 × 300 μm, and provide reliable results in an acceptable computational time. Finally, to accelerate the process of time step length identification, a new adaptation algorithm is also introduced. It is presented that such an algorithm provides reliable results in the shortest possible time.},
  archive      = {J_JOCS},
  author       = {Mateusz Sitko and Lukasz Madej},
  doi          = {10.1016/j.jocs.2021.101437},
  journal      = {Journal of Computational Science},
  pages        = {101437},
  shortjournal = {J. Comput. Sci.},
  title        = {The role of the cellular automata cell size and time step length in the microstructure evolution model—The static recrystallization case study},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive complete synchronization of two complex networks
with uncertain parameters, structures, and disturbances. <em>JOCS</em>,
<em>54</em>, 101436. (<a
href="https://doi.org/10.1016/j.jocs.2021.101436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present herein a study of adaptive complete synchronization of two complex networks with uncertain dynamic parameters, coupled structures, and disturbances. To investigate how system-related disturbance and system-independent disturbance affect network node dynamic behavior, we introduce two disturbance factors into the node dynamic equation of drive-response network model. Based on Lyapunov stability theory and robust adaptive principle, appropriate adaptive controllers are designed to synchronize the drive network and response network with disturbances. For nodes in the drive network with unknown dynamic parameters, a method is proposed to dynamically estimate unknown parameters and makes two networks still synchronized. The results of simulation demonstrate that node dynamic behavior can be locally changed by system-independent disturbance, while its chaotic state can be dramatically changed by system-related disturbance. In addition, the feasibility and effectiveness of designed controllers and parameter estimation method are verified. The comparison of simulation results shows that structural uncertainty exerts the local influence on network synchronization, but parametric uncertainty brings about the global influence.},
  archive      = {J_JOCS},
  author       = {Gang Wang and Shiwei Lu and Wenbin Liu and Runnian Ma},
  doi          = {10.1016/j.jocs.2021.101436},
  journal      = {Journal of Computational Science},
  pages        = {101436},
  shortjournal = {J. Comput. Sci.},
  title        = {Adaptive complete synchronization of two complex networks with uncertain parameters, structures, and disturbances},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effect of stenosis growth on blood flow at the bifurcation
of the carotid artery. <em>JOCS</em>, <em>54</em>, 101435. (<a
href="https://doi.org/10.1016/j.jocs.2021.101435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The effects of stenosis growth on the flow properties of blood in the bifurcation region of the carotid artery are considered. Details of the blood flow are simulated using the lattice Boltzmann method and the development of the stenosis is simulated in regions where there is a low velocity and low wall shear stress. The model is applied to investigate the near-wall haemodynamics, at different stages of stenosis development, over a cardiac cycle. Variations in time-averaged flow parameters are also considered.},
  archive      = {J_JOCS},
  author       = {A.C. Stamou and J. Radulovic and J.M. Buick},
  doi          = {10.1016/j.jocs.2021.101435},
  journal      = {Journal of Computational Science},
  pages        = {101435},
  shortjournal = {J. Comput. Sci.},
  title        = {Effect of stenosis growth on blood flow at the bifurcation of the carotid artery},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Four-factor model of quanto CDS with jumps-at-default and
stochastic recovery. <em>JOCS</em>, <em>54</em>, 101434. (<a
href="https://doi.org/10.1016/j.jocs.2021.101434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We modify the model of Itkin, Shcherbakov and Veygman (ISV), proposed for pricing Quanto CDS and risky bonds, in several ways. First, the recovery rate could significantly vary right before or at default, therefore, here we treat it as stochastic. Second, we assume the domestic interest rate to be deterministic, because, as shown by ISV, its volatility does not contribute much to the Quanto CDS spread. Finally, to solve the corresponding systems of 4D PDEs we use a flavor of the RBF method which is a combination of localized RBF and finite-difference methods. Results of our numerical experiments demonstrate that the influence of volatility of the recovery rate is significant if the correlation between the recovery rate and the log-intensity of the default is non-zero. Also, the impact of the recovery mean-reversion rate on the Quanto CDS spread could be comparable with the impact due to jump-at-default in the FX rate.},
  archive      = {J_JOCS},
  author       = {Andrey Itkin and Fazlollah Soleymani},
  doi          = {10.1016/j.jocs.2021.101434},
  journal      = {Journal of Computational Science},
  pages        = {101434},
  shortjournal = {J. Comput. Sci.},
  title        = {Four-factor model of quanto CDS with jumps-at-default and stochastic recovery},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On using variable molecular masses in multicomponent lattice
boltzmann simulations. <em>JOCS</em>, <em>54</em>, 101432. (<a
href="https://doi.org/10.1016/j.jocs.2021.101432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The option of varying the molecular mass in multicomponent lattice Boltzmann simulations is being explored. First, results are presented for droplet formation at an aperture in a second immiscible liquid medium in which the difference in density between the two media is achieved by introducing asymmetry in the EOS, via adding particularly intra-component interaction forces in a pseudo-potential LB model. The second application for models with variable molecular masses is a single-phase heterogeneous laminar-flow tubular chemical reactor, where the molecular masses of reactants and products differ. In this application, tuning the molecular mass requires modification of the standard equilibrium distribution function as well as the use of an extended velocity set, in our case D2Q13. The method is validated against analytical solutions for canonical 1-D diffusion-reaction cases. In both the droplet formation study and the chemical reactors, the results of the exploratory 2-D simulations look qualitatively correct.},
  archive      = {J_JOCS},
  author       = {Harry E.A. Van den Akker and Renske Donkers and Githin T. Zachariah and Orest Shardt},
  doi          = {10.1016/j.jocs.2021.101432},
  journal      = {Journal of Computational Science},
  pages        = {101432},
  shortjournal = {J. Comput. Sci.},
  title        = {On using variable molecular masses in multicomponent lattice boltzmann simulations},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of deep learning models in nonlinear detail map
prediction in pansharpening. <em>JOCS</em>, <em>54</em>, 101431. (<a
href="https://doi.org/10.1016/j.jocs.2021.101431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper provides a deep learning-based approximation of the MultiSpectral Band Intensity component by considering the joint multiplication of adjacent spectral channels. This calculation is conducted as part of a component substitution approach for the fusion of PANchromatic and MultiSpectral images in remote sensing. After calculating the band-dependent intensity elements, a deep learning model is trained to learn the nonlinear relationship between the PAN image and its nonlinear intensity elements. Low Resolution MultiSpectral bands are then fed into a trained network to achieve a high resolution MultiSpectral band estimation. Experiments performed on three datasets indicate that the established deep learning estimation methodology offers better performance compared to current approaches based on a number of objective metrics.},
  archive      = {J_JOCS},
  author       = {Arian Azarang and Nasser Kehtarnavaz},
  doi          = {10.1016/j.jocs.2021.101431},
  journal      = {Journal of Computational Science},
  pages        = {101431},
  shortjournal = {J. Comput. Sci.},
  title        = {Application of deep learning models in nonlinear detail map prediction in pansharpening},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An approach based on multiplex networks for modeling
cascading trust failures in social networks. <em>JOCS</em>, <em>54</em>,
101430. (<a href="https://doi.org/10.1016/j.jocs.2021.101430">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Removing nodes or links from a real-world social network may lead to a collapse in the entire network itself. This is due to the propagation effect of the initial removal. In the literature, this phenomenon is called cascading failure. In the context of trust modeling, cascading failure occurs when a node’s trust toward another, changes to distrust resulting in the removal of the trust link between them. This change in the trust network may affect the other nodes’ trust toward the target node. As the number of failures in a network increases, the users become more reluctant to share their interests and opinions with other members. Hence, it is important to model, detect and mitigate the cascading trust failures. Currently, simple computational trust models are used for modeling cascading trust failures in the existing works. The effect of relevant contexts in modeling cascading trust failures is still a missing concept in the proposed models. Failure in a specific trust context may impact the relevant contexts as well and may have less or no impact on the irrelevant contexts. Therefore, the need for a more comprehensive trust modeling approach for cascading trust failures is evident. In this paper, the proposed computational trust is formulated by considering the context dependencies in addition to the impact of trust contexts on one another. Also, by mapping the trust contexts to a multiplex network&#39;s layers and using the advantages of complex network analysis concepts, a new method for computing the similarity between the trust contexts is introduced. The introduced trust model uses the trust information of all layers ( i.e. , contexts) to compute the new trust values after a trust failure. In addition, the trust model uses the newly provided information to adjust the calculated trust values by leveraging real-world data. Besides, a model for trust cascading failure as well as an attack prevention method are introduced. By performing a wide range of experiments, including sensitivity analysis, accuracy analysis, and comparative studies, the effectiveness of the proposed approach is evaluated. Real-world networks&#39; data such as Facebook and Twitter&#39;s ego nets and synthetic data are used for the performed evaluations. It is shown that higher values for the context’s importance parameters make the trust links more vulnerable and easier to fail. The three well-known trust attack scenarios including HT, LT, and RT are performed and it is demonstrated that the layers with high similarity values tend to have more similar cascading failure patterns. It is shown that the accuracy of the introduced model for trust cascading failures is higher compared to the existing works. By adding the attack prevention component, the model&#39;s accuracy gets close to 1 in best cases, which is a notable improvement.},
  archive      = {J_JOCS},
  author       = {Mahrad Hanaforoosh and Mehrdad Ashtiani and Mohammad Abdollahi Azgomi},
  doi          = {10.1016/j.jocs.2021.101430},
  journal      = {Journal of Computational Science},
  pages        = {101430},
  shortjournal = {J. Comput. Sci.},
  title        = {An approach based on multiplex networks for modeling cascading trust failures in social networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic shape detection of ice crystals. <em>JOCS</em>,
<em>54</em>, 101429. (<a
href="https://doi.org/10.1016/j.jocs.2021.101429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clouds have a crucial impact on the energy balance of the Earth-Atmosphere system. They can cool the system by partly reflecting or scattering of the incoming solar radiation (albedo effect); moreover, thermal radiation as emitted from the Earth&#39;s surface can be absorbed and partly re-emitted by clouds leading to a warming of the atmosphere (greenhouse effect). The effectiveness of both effects crucially depends on the size and the shape of a cloud&#39;s particulate constituents, i.e. liquid water droplets or solid ice crystals. For studying cloud microphysics, in situ measurements on board of aircraft are commonly used. An important class of measurement techniques comprises optical array probes (OAPs) as developed since the 1970s [13] . While water droplets can be assumed as spherical, the shape and size of ice particles are highly variable. The currently used analysis methods to determine the particles’ size from OAP detection do rarely consider shape details or fine structures of ice particles, which may lead to artificial biases in the results. In this paper, we present two new computational analysis methods, combined in an hybrid approach, for an automatic classification of ice particles and water droplets. The first method computes the principal components of a cloud particle and uses them to determine an ellipse, which can then be used to filter for spherical particles. The second method uses convolutional neural networks (CNNs) for the classification of columns and rosettes, respectively. Although we currently only classify these two particle types with CNNs, the presented method can be easily adapted for the classification of other particle types. The particularity of our method is that we use a virtual data set to pre-train the networks, which are then further trained with a smaller amount of manually classified real cloud particles in a fine tuning step. We evaluated our models on a small data set of real cloud particles and in a final field test on OAP image data that was not previously classified. The precision of this field test was better than 81\% and ranged up to 98\%, demonstrating that the new methods are suitable for providing profound shape classifications of cloud particle images obtained by OAP measurements. All methods we describe in this paper have been implemented in Python and C and are fully open source. Code and documentation are available on Github ( https://github.com/lcsgrlch/oap ).},
  archive      = {J_JOCS},
  author       = {Lucas Grulich and Ralf Weigel and Andreas Hildebrandt and Michael Wand and Peter Spichtinger},
  doi          = {10.1016/j.jocs.2021.101429},
  journal      = {Journal of Computational Science},
  pages        = {101429},
  shortjournal = {J. Comput. Sci.},
  title        = {Automatic shape detection of ice crystals},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ab-initio study on physical properties of intermetallic LiPb
compound. <em>JOCS</em>, <em>54</em>, 101428. (<a
href="https://doi.org/10.1016/j.jocs.2021.101428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our work, some theoretical calculations of LiPb compound in B2 structure have been analyzed using Vienna ab initio simulation package (VASP). The ground state properties are revealed by fitting the calculated total energy-atomic volume to the Murnaghan equation. The studied compound is stable both thermodynamically and dynamically due to the formation of energy and its positive vibration frequencies. This compound shows ductile and soft property from calculated second-order elastic constants. By evaluating the electronic properties, the absence of band gap highlighted the metallic property of the compound. Finally the effects of pressure and temperature on thermodynamic properties were explained in detail.},
  archive      = {J_JOCS},
  author       = {Ilknur Kars Durukan and Yasemin Oztekin Ciftci},
  doi          = {10.1016/j.jocs.2021.101428},
  journal      = {Journal of Computational Science},
  pages        = {101428},
  shortjournal = {J. Comput. Sci.},
  title        = {Ab-initio study on physical properties of intermetallic LiPb compound},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Surrogate-assisted optimization for augmentation of finite
element techniques. <em>JOCS</em>, <em>54</em>, 101427. (<a
href="https://doi.org/10.1016/j.jocs.2021.101427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of finite element techniques for the analysis and optimization of complex thermo-mechanical structures typically involves highly nonlinear models for material characterization, tribological contact, large deformation, damage, etc. These nonlinearities usually call for a higher order spatio-temporal discretization, including a large number of elements and time-steps in order to provide good convergence and sufficiently accurate simulation results. Unfortunately, this inevitably leads to many expensive simulations in terms of cost and time if an optimization or adaption of design parameters has to be done. In this work, a surrogate-assisted optimization algorithm is utilized to find the setting of design parameters, which would lead to maximum damage in a simple tensile testing scenario involving a notched specimen with as few FEM simulations as possible.},
  archive      = {J_JOCS},
  author       = {Samineh Bagheri and Ulf Reinicke and Denis Anders and Wolfgang Konen},
  doi          = {10.1016/j.jocs.2021.101427},
  journal      = {Journal of Computational Science},
  pages        = {101427},
  shortjournal = {J. Comput. Sci.},
  title        = {Surrogate-assisted optimization for augmentation of finite element techniques},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete-time data-driven disturbance-observer control based
on fuzzy rules emulating networks. <em>JOCS</em>, <em>54</em>, 101426.
(<a href="https://doi.org/10.1016/j.jocs.2021.101426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamical models of real-world systems are uncertain at the best extent, and the controller is usually based on an approximate model. Additional unavoidable effects, such as un-modelled disturbances, discretisation and quantisation, as well as measurement and input noise, make the control of uncertain processes a challenging problem. This paper proposes a discrete-time controller for a class of highly uncertain dynamical systems, whose design is given in two stages: (i) a data-driven model is obtained by means of a fuzzy neural network and a nominal controller for the disturbance-free case is considered; and (ii) a disturbance-observer is formulated to compensate unknown effects. The boundedness of the tracking error signals is analysed and the performance of the proposed scheme is validated throughout experimental results.},
  archive      = {J_JOCS},
  author       = {Chidentree Treesatayapun and Aldo Jonathan Muñoz-Vázquez},
  doi          = {10.1016/j.jocs.2021.101426},
  journal      = {Journal of Computational Science},
  pages        = {101426},
  shortjournal = {J. Comput. Sci.},
  title        = {Discrete-time data-driven disturbance-observer control based on fuzzy rules emulating networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TinyMD: Mapping molecular dynamics simulations to
heterogeneous hardware using partial evaluation. <em>JOCS</em>,
<em>54</em>, 101425. (<a
href="https://doi.org/10.1016/j.jocs.2021.101425">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the suitability of the AnyDSL partial evaluation framework to implement tinyMD: an efficient, scalable, and portable simulation of pairwise interactions among particles. We compare tinyMD with the miniMD proxy application that scales very well on parallel supercomputers . We discuss the differences between both implementations and contrast miniMD’s performance for single-node CPU and GPU targets, as well as its scalability on SuperMUC-NG and Piz Daint supercomputers . Additionally, we demonstrate tinyMD’s flexibility by coupling it with the waLBerla multi-physics framework. This allow us to execute tinyMD simulations using the load-balancing mechanism implemented in waLBerla.},
  archive      = {J_JOCS},
  author       = {Rafael Ravedutti L. Machado and Jonas Schmitt and Sebastian Eibl and Jan Eitzinger and Roland Leißa and Sebastian Hack and Arsène Pérard-Gayot and Richard Membarth and Harald Köstler},
  doi          = {10.1016/j.jocs.2021.101425},
  journal      = {Journal of Computational Science},
  pages        = {101425},
  shortjournal = {J. Comput. Sci.},
  title        = {TinyMD: Mapping molecular dynamics simulations to heterogeneous hardware using partial evaluation},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability analysis of a three species food chain model with
linear functional response via imprecise and parametric approach.
<em>JOCS</em>, <em>54</em>, 101423. (<a
href="https://doi.org/10.1016/j.jocs.2021.101423">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, proper modeling of a biological system in an uncertain situation is a challenging task for researchers. Facing this challenge, in this article, a new concept of interval representation named as linear parametric representation is introduced by which a biological system in an uncertain situation can be formulated mathematically in a precise way. The aim of this work is to formulate a three species imprecise food chain model with one prey and two competing predators in an interval environment. Here, all the biological parameters except the conversion efficiency of the species are considered interval-valued. And interactions among the species are taken as Holling Type I functional response. Using the linear parametric representation of interval, a system in the interval form has been converted in the parametric form . Positivity and boundedness of the solutions of the proposed imprecise system are verified. Then, conditions of local stability, global stability and transcritical bifurcation of equilibrium points of the proposed system are established. Thereafter, all the theoretical results of this work are validated by a numerical example with interval-valued parametric data and results are presented pictorially. Finally, some biological implications of the obtained results are discussed and a fruitful conclusion has been made.},
  archive      = {J_JOCS},
  author       = {Uttam Ghosh and Bapin Mondal and Md Sadikur Rahman and Susmita Sarkar},
  doi          = {10.1016/j.jocs.2021.101423},
  journal      = {Journal of Computational Science},
  pages        = {101423},
  shortjournal = {J. Comput. Sci.},
  title        = {Stability analysis of a three species food chain model with linear functional response via imprecise and parametric approach},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Search by triplet: An efficient local track reconstruction
algorithm for parallel architectures. <em>JOCS</em>, <em>54</em>,
101422. (<a href="https://doi.org/10.1016/j.jocs.2021.101422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Millions of particles are collided every second at the LHCb detector placed inside the Large Hadron Collider at CERN. The particles produced as a result of these collisions pass through various detecting devices which will produce a combined raw data rate of up to 40 Tbps by 2021. These data will be fed through a data acquisition system which reconstructs individual particles and filters the collision events in real time. This process will occur in a heterogeneous farm employing exclusively off-the-shelf CPU and GPU hardware, in a two stage process known as High Level Trigger. The reconstruction of charged particle trajectories in physics detectors, also referred to as track reconstruction or tracking, determines the position, charge and momentum of particles as they pass through detectors. The Vertex Locator subdetector (VELO) is the closest such detector to the beamline, placed outside of the region where the LHCb magnet produces a sizable magnetic field. It is used to reconstruct straight particle trajectories which serve as seeds for reconstruction of other subdetectors and to locate collision vertices. The VELO subdetector will detect up to 10 9 109 particles every second, which need to be reconstructed in real time in the High Level Trigger. We present Search by triplet, an efficient track reconstruction algorithm. Our algorithm is designed to run efficiently across parallel architectures. We extend on previous work and explain the algorithm evolution since its inception. We show the scaling of our algorithm under various situations, and analyse its amortized time in terms of complexity for each of its constituent parts and profile its performance. Our algorithm is the current state-of-the-art in VELO track reconstruction on SIMT architectures, and we qualify its improvements over previous results.},
  archive      = {J_JOCS},
  author       = {Daniel Hugo Cámpora Pérez and Niko Neufeld and Agustín Riscos Núñez},
  doi          = {10.1016/j.jocs.2021.101422},
  journal      = {Journal of Computational Science},
  pages        = {101422},
  shortjournal = {J. Comput. Sci.},
  title        = {Search by triplet: An efficient local track reconstruction algorithm for parallel architectures},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effects of combined chemotherapeutic drugs on the growth and
survival of cancerous tumours– an in-silico study. <em>JOCS</em>,
<em>54</em>, 101421. (<a
href="https://doi.org/10.1016/j.jocs.2021.101421">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficacy of chemotherapeutic treatment continues to vary drastically from patient to patient because of the complex development and progression of cancer. The standard treatment procedures involve identification of the types and stages of cancer, followed by a plethora of therapies, however, with little or no room for personalizing the treatment. The objective of the current study is to develop a biologically consistent mathematical model of an avascular tumor, considering the mass transfer, pharmacological and pharmacodynamic characteristics of chemotherapy drugs and nutrients. The model simulation results are used to study progression of the tumor growth, while monitoring efficacy of the chemotherapeutic drugs, namely, cisplatin and paclitaxel. The simulations are performed using CompuCell3D, a Glazier-Graner-Hogeweg (GGH) model-based software integrated with partial differential solver, FiPy. Specifically, the developed model in this study considers the individual and combinatorial administration of the drugs. The model simulation results, with GGH as the underlying principle, allow studying the dynamics of the tumor at an individual cell-scale, while monitoring the cell-cycle phase, nutrient and drug uptakes, and cell repair. The simulation results reveal that paclitaxel is more potent than cisplatin when both drugs are administered combinatorically.},
  archive      = {J_JOCS},
  author       = {Prerna Kaura and Tanya Mishra and Nishith Verma and Indranil Saha Dalal and Vivek Sheraton},
  doi          = {10.1016/j.jocs.2021.101421},
  journal      = {Journal of Computational Science},
  pages        = {101421},
  shortjournal = {J. Comput. Sci.},
  title        = {Effects of combined chemotherapeutic drugs on the growth and survival of cancerous tumours– an in-silico study},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cylinder-lamina system fluid–structure interaction problem
solved with an original OpenFOAM code. <em>JOCS</em>, <em>54</em>,
101420. (<a href="https://doi.org/10.1016/j.jocs.2021.101420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In numerical simulations, the partitioned approach allows treating a multi-physics phenomenon as two different computational fields, which are solved separately with their respective mesh discretisation and algorithms. This is of particular interest to fluid–structure interaction (FSI) problems for their complex resolution. In this respect, through the partitioned approach, ModsFsiFoam (MODalSuperpositionFsiFoam) solver has been developed. It allows the application of two different methods for fluid and solid solutions. In particular, it is based on a theoretical approach, the modal superposition principle, for the structural solution; this method provides a certain result for the linear structural field. The FVM (Finite VolumeMethod), by far the most widely used method for fluid-dynamics and gas-dynamics problems, has been used instead to solve the Navier–Stokes equations for an incompressible laminar flow of Newtonian fluid . The interfacial conditions have been used to pass information between the domains through a coupling algorithm. Implemented in OpenFOAM, a development environment consisting of libraries and applications for Linux distributions , written in the C++ source code, ModsFsiFoam solver has been already applied with satisfactory results to a typical fluid–structure interaction case found in literature, i.e. a system composed by an inverted flag treated as a flexible lamina, clamped to a wind tunnel wall, in which airflow is introduced in the axial direction. In this work, ModsFsiFoam solver outputs are compared with a system, the results of which are known for both fluid-dynamics and structural fields. The configuration consists of a laminar incompressible channel flow around a solid structure with an elastic part.},
  archive      = {J_JOCS},
  author       = {C. Stefanini and F. Giorgetti and A. Mercuri and A. Facci and P. Fanelli},
  doi          = {10.1016/j.jocs.2021.101420},
  journal      = {Journal of Computational Science},
  pages        = {101420},
  shortjournal = {J. Comput. Sci.},
  title        = {Cylinder-lamina system fluid–structure interaction problem solved with an original OpenFOAM code},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applying a probabilistic infection model for studying
contagion processes in contact networks. <em>JOCS</em>, <em>54</em>,
101419. (<a href="https://doi.org/10.1016/j.jocs.2021.101419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modeling the spread of infectious diseases is central to the field of computational epidemiology. Two prominent approaches to modeling the contagion process include (i) simulating the spread in contact networks through Monte-Carlo processes and (ii) tracking the disease dynamics using meta-population models. In both cases, the individuals are explicitly (contact networks) or implicitly (meta-population) assumed to belong to exactly one disease state (e.g., susceptible, infected, etc.). In reality, the disease states of individuals are rarely so cleanly compartmentalized. A particular agent can exist in multiple disease states (such as infected and exposed) concurrently with varying probability. To model this stochasticity, we present a new method, that we term as the Probabilistic Infection Model (PIM). Unlike traditional models that assign exactly one state to each agent at each time step, the PIM computes the probability of each agent being in each of the infectious states. Our proposed PIM provides a more layered understanding of the dynamics of the outbreak at individual levels, by allowing the users to (i) estimate the value of R 0 at individual vertices and (ii) instead of an all or none value, provides the probability of each infected state of an agent. Additionally, using our probabilistic approach the overall trajectories of the outbreaks can be computed in one simulation, as opposed to the numerous (order of hundreds) repeated simulations required for the Monte Carlo process. We demonstrate the efficacy of PIM by comparing the results of the PIM simulations with those obtained by simulating stochastic SEIR models, as well as the time required for the simulations. We present results at the system and at the individual levels for three diseases; measles and two strains of influenza. We demonstrate how the PIM can be used to study the effect of varying the transimissibility of COVID-19 on its outbreak. This paper is an extended version of a manuscript published in the proceedings of the 2020 International Conference on Computational Science (ICCS) [30] . These extensions are primarily within Sections 4 (Relationship between graph structure and probability of infection) and 5 (Effect of varying COVID-19 transmissibility on outbreak dynamics).},
  archive      = {J_JOCS},
  author       = {William Qian and Sanjukta Bhowmick and Marty O’Neill and Suhasini Ramisetty-Mikler and Armin R. Mikler},
  doi          = {10.1016/j.jocs.2021.101419},
  journal      = {Journal of Computational Science},
  pages        = {101419},
  shortjournal = {J. Comput. Sci.},
  title        = {Applying a probabilistic infection model for studying contagion processes in contact networks},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving fractional optimal control problems with inequality
constraints by a new kind of chebyshev wavelets method. <em>JOCS</em>,
<em>54</em>, 101412. (<a
href="https://doi.org/10.1016/j.jocs.2021.101412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new orthonormal wavelets based on the sixth-kind Chebyshev polynomials is constructed to obtain the solution of fractional optimal control problems (FOCPs) with inequality constraints . The convergence analysis and error estimate of the sixth-kind Chebyshev wavelets function expansion are investigated. By using the relationship between the second-kind and sixth-kind Chebyshev polynomials, the exact formula of Riemann-Liouville fractional integral operator of Chebyshev wavelet is derived. For solving FOCPs, positive slack functions are added to inequality conditions, and then the problem is simplified to the problem of solving algebraic equations by fractional integral operational matrix and collocation method. The applicability and validity of the proposed method are verified by several examples and the results are compared with those reported in literature.},
  archive      = {J_JOCS},
  author       = {Xiaoyong Xu and Linchen Xiong and Fengying Zhou},
  doi          = {10.1016/j.jocs.2021.101412},
  journal      = {Journal of Computational Science},
  pages        = {101412},
  shortjournal = {J. Comput. Sci.},
  title        = {Solving fractional optimal control problems with inequality constraints by a new kind of chebyshev wavelets method},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). In-silico analysis of airflow dynamics and particle
transport within a human nasal cavity. <em>JOCS</em>, <em>54</em>,
101411. (<a href="https://doi.org/10.1016/j.jocs.2021.101411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a numerical investigation of the airflow dynamics and particle transport through an averaged human nasal cavity. The effect of particle size and breathing rate on the deposition patterns are explored. The simulations reveal that smaller particles penetrate deeper into the airway, whereas larger particles agglomerate near the anterior portion of the nasal cavity. Increasing the flow rate augmented the penetration of the particles. The complex interplay of the finite particle size and the flow inertia decided the spatial deposition of the particles. The findings from this study demonstrate the efficacy of state-of-art simulation frameworks for targeting respiratory disorders.},
  archive      = {J_JOCS},
  author       = {Manash Pratim Borthakur and Sauro Succi and Fabio Sterpone and Franck Pérot and Anxhelo Diko and Simone Melchionna},
  doi          = {10.1016/j.jocs.2021.101411},
  journal      = {Journal of Computational Science},
  pages        = {101411},
  shortjournal = {J. Comput. Sci.},
  title        = {In-silico analysis of airflow dynamics and particle transport within a human nasal cavity},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation of the improvement in the performance of a
silver-based surface plasmon resonance biosensor using experimental
results of cold plasma treatment of glass substrate. <em>JOCS</em>,
<em>54</em>, 101410. (<a
href="https://doi.org/10.1016/j.jocs.2021.101410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, the effect of observed pinholes in the Field emission scanning electron microscopy (FESEM) images on the performance of a silver-based surface plasmon resonance (SPR) biosensor is designed and analytically investigated by a ﬁnite element method using COMSOL multiphysics. The simulation results show that the sensitivity and ﬁgure of merit (FOM) enhancement of biosensor is attributed to the cold atmospheric-pressure plasma (CAP) treatment of glass substrate before deposition; leading to the omission of pinholes. This work is proposing a new way for SPR biosensors development using surface quality control of the deposited thin films with CAP treatment.},
  archive      = {J_JOCS},
  author       = {Maryam Hosseinpour and Akbar Zendehnam and Seyedeh Mehri Hamidi Sangdehi and Hamidreza Ghomi Marzdashti},
  doi          = {10.1016/j.jocs.2021.101410},
  journal      = {Journal of Computational Science},
  pages        = {101410},
  shortjournal = {J. Comput. Sci.},
  title        = {Simulation of the improvement in the performance of a silver-based surface plasmon resonance biosensor using experimental results of cold plasma treatment of glass substrate},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Corrigendum to “control optimization of an aerial robotic
swarm in a search task and its adaptation to different scenarios” [j.
Comput. Sci. 29 (2018) 107–118]. <em>JOCS</em>, <em>54</em>, 101258. (<a
href="https://doi.org/10.1016/j.jocs.2020.101258">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOCS},
  author       = {Pablo Garcia-Aunon and Antonio Barrientos Cruz},
  doi          = {10.1016/j.jocs.2020.101258},
  journal      = {Journal of Computational Science},
  pages        = {101258},
  shortjournal = {J. Comput. Sci.},
  title        = {Corrigendum to “Control optimization of an aerial robotic swarm in a search task and its adaptation to different scenarios” [J. comput. sci. 29 (2018) 107–118]},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Steady-state two-relaxation-time lattice boltzmann
formulation for transport and flow, closed with the compact
multi-reflection boundary and interface-conjugate schemes.
<em>JOCS</em>, <em>54</em>, 101215. (<a
href="https://doi.org/10.1016/j.jocs.2020.101215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce the steady-state two-relaxation-time (TRT) Lattice Boltzmann method. Owing to the symmetry argument, the bulk system and the closure equations are all expressed in terms of the equilibrium and non-equilibrium unknowns with the half discrete velocity set. The local mass-conservation solvability condition is adjusted to match the stationary, but also the quasi-stationary, solutions of the standard TRT solver. Additionally, the developed compact, boundary and interface-conjugate, multi-reflection (MR) concept preserves the efficient directional bulk structure and shares its parametrization properties. The method is exemplified in grid-inclined stratified slabs for two-phase Stokes flow and the linear advection-diffusion equation featuring the discontinuous coefficients and sources. The piece-wise parabolic benchmark solutions are matched exactly with the novel Dirichlet, pressure-stress, Neumann flux and Robin MR schemes. The popular, anti-bounce-back and shape-fitted Dirichlet continuity schemes are improved in the presence of both interface-parallel and perpendicular advection velocity fields. The steady-state method brings numerous advantages: it skips transient numerical instability, overpasses severe von Neumann parameter range limitations, tolerates high physical contrasts and arbitrary MR coefficients . The method is promising for faster computation of Stokes/Brinkman/Darcy linear flows in heterogeneous soil, but also heat and mass transfer problems governed by an accurate boundary and interface treatment.},
  archive      = {J_JOCS},
  author       = {Irina Ginzburg},
  doi          = {10.1016/j.jocs.2020.101215},
  journal      = {Journal of Computational Science},
  pages        = {101215},
  shortjournal = {J. Comput. Sci.},
  title        = {Steady-state two-relaxation-time lattice boltzmann formulation for transport and flow, closed with the compact multi-reflection boundary and interface-conjugate schemes},
  volume       = {54},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IA-CPS: Intelligent architecture for cyber-physical systems
management. <em>JOCS</em>, <em>53</em>, 101409. (<a
href="https://doi.org/10.1016/j.jocs.2021.101409">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the emergence of large-scale and highly distributed cyber-physical systems (CPSs) in applications including Internet of things (IoT), cloud computing , mobility, Big Data, and sensor networks involves that architecture models have to work in an open and highly dynamic world. This fact increasingly highlights the importance of designing real-time and intelligent CPSs that are capable of decision making. In this paper, an Intelligent Architecture model for CPS management (IA-CPS) based on online processing is proposed for this purpose. Specifically, it can manage simple and complex events based on a service-oriented architecture and directed by an event-driven architecture, using event processing technology as Complex Event Processing (CEP). The novelty of our approach relies on the fact that the proposed architecture is service-oriented, which models the functionalities of the event-driven system. This gives us the possibility to offer a flexible service catalog, allowing us to connect to the system on any kind of device and interact in different scenarios. The model has been applied to two use cases: processing images from video surveillance cameras , and processing of consumption data captured by water and energy sensors installed in end-user environments.},
  archive      = {J_JOCS},
  author       = {Henry Duque Gómez and Jose Garcia-Rodriguez and Jorge Azorin-Lopez and David Tomás and Andres Fuster-Guillo and Higinio Mora-Mora},
  doi          = {10.1016/j.jocs.2021.101409},
  journal      = {Journal of Computational Science},
  pages        = {101409},
  shortjournal = {J. Comput. Sci.},
  title        = {IA-CPS: Intelligent architecture for cyber-physical systems management},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reduced order modeling for parameterized time-dependent PDEs
using spatially and memory aware deep learning. <em>JOCS</em>,
<em>53</em>, 101408. (<a
href="https://doi.org/10.1016/j.jocs.2021.101408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel reduced order model (ROM) approach for parameterized time-dependent PDEs based on modern learning. The ROM is suitable for multi-query problems and is nonintrusive. It is divided into two distinct stages: a nonlinear dimensionality reduction stage that handles the spatially distributed degrees of freedom based on convolutional autoencoders, and a parameterized time-stepping stage based on memory aware neural networks (NNs), specifically causal convolutional and long short-term memory NNs. Strategies to ensure generalization and stability are discussed. To show the variety of problems the ROM can handle, the methodology is demonstrated on the advection equation, and the flow past a cylinder problem modeled by the incompressible Navier–Stokes equations.},
  archive      = {J_JOCS},
  author       = {Nikolaj T. Mücke and Sander M. Bohté and Cornelis W. Oosterlee},
  doi          = {10.1016/j.jocs.2021.101408},
  journal      = {Journal of Computational Science},
  pages        = {101408},
  shortjournal = {J. Comput. Sci.},
  title        = {Reduced order modeling for parameterized time-dependent PDEs using spatially and memory aware deep learning},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Helastic: On combining threshold-based and serverless
elasticity approaches for optimizing the execution of bioinformatics
applications. <em>JOCS</em>, <em>53</em>, 101407. (<a
href="https://doi.org/10.1016/j.jocs.2021.101407">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in Next Generation Gene Sequencing (NGS) technologies brought an abundance of bioinformatics and phylogenetics data. The available datasets create new opportunities for studies about the genetic relationships among organisms, which previously relied mainly on manual observations. The state-of-the-art shows that the software employed in this area is based on technologically outdated solutions with ample space for adopting modern computing techniques such as cloud resource elasticity and dynamic load balancing . This article aims to fill this gap with the proposal of Helastic, a model to explore cloud elasticity on jModelTest. The latter is a widely used software for performing statistical selection of nucleotide replacement models in phylogenetic analyzes. Helastic’s contributions appear in a dual elasticity layer that combines the traditional threshold-based, reactive approach with Serverless (also referred to in the literature as Function-as-a-Service, or FaaS). Design decisions include interoperability as a requirement, enabling existing jModelTest applications to benefit from Helastic without significant code changes. We evaluate our proposal through a prototype, which was tested on both elastic and non-elastic scenarios. Data regarding execution time and resource usage are presented in this article. Results demonstrate our solution’s feasibility and the benefits of working with a dual-elasticity approach rather than a single resource rearrangement technique.},
  archive      = {J_JOCS},
  author       = {Mateus Rauback Aubin and Rodrigo da Rosa Righi and Victor Hugo Valiati and Cristiano André da Costa and Rodolfo Stoffel Antunes and Guilherme Galante},
  doi          = {10.1016/j.jocs.2021.101407},
  journal      = {Journal of Computational Science},
  pages        = {101407},
  shortjournal = {J. Comput. Sci.},
  title        = {Helastic: On combining threshold-based and serverless elasticity approaches for optimizing the execution of bioinformatics applications},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observation data compression for variational assimilation of
dynamical systems. <em>JOCS</em>, <em>53</em>, 101405. (<a
href="https://doi.org/10.1016/j.jocs.2021.101405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of error covariances (both background and observation) is crucial for efficient observation compression approaches in data assimilation of large-scale dynamical problems. We propose a new combination of a covariance tuning algorithm with existing PCA-type data compression approaches, either observation- or information-based, with the aim of reducing the computational cost of real-time updating at each assimilation step. Relying on a local assumption of flow-independent error covariances , dynamical assimilation residuals are used to adjust the covariance in each assimilation window. The estimated covariances then contribute to better specify the principal components of either the observation dynamics or the state-observation sensitivity. The proposed approaches are first validated on a shallow water twin experiment with correlated and non-homogeneous observation error. Proper selection of flow-independent assimilation windows, together with sampling density for background error estimation, and sensitivity of the approaches to the observations error covariance knowledge, are also discussed and illustrated with various numerical tests and results. The method is then applied to a more challenging industrial hydrological model with real-world data and non-linear transformation operator provided by an operational precipitation-flow simulation software.},
  archive      = {J_JOCS},
  author       = {Sibo Cheng and Didier Lucor and Jean-Philippe Argaud},
  doi          = {10.1016/j.jocs.2021.101405},
  journal      = {Journal of Computational Science},
  pages        = {101405},
  shortjournal = {J. Comput. Sci.},
  title        = {Observation data compression for variational assimilation of dynamical systems},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Numerical modelling study of a modified sandbag system for
ballistic protection. <em>JOCS</em>, <em>53</em>, 101403. (<a
href="https://doi.org/10.1016/j.jocs.2021.101403">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern field fortification systems are very large and cause a logistical burden during setup, thus setting the requirement for their modification. A simulation study was conducted to study the correlation between the compaction of sand and the energy absorbed by it when impacted by a solid steel projectile at 850 m/s. Furthermore, the sandbag was modified by the addition of plates in the system to observe the change in projectile penetration and the energy absorption behaviour of the sand. The factors considered for this study were the plate thickness (15 mm, 25 mm), plate material (aluminium, concrete, plexiglass, polycarbonate, steel) and plate location (226 mm, 236 mm, 256 mm from the point of impact). It was observed that a layer of compressed sand is formed around the projectile, aiding the energy absorption and dissipation process during impact. Upon addition of the plate, it was observed that the modified system (plate and sand) absorbed maximum energy when the plate is placed closest to the point of maximum penetration without the plate. It was also noted that the addition of the plate enhanced energy absorption characteristics of the system compared to conventional sandbags because of increased compaction of sand. From the study, it was observed that the plexiglass and polycarbonate plates had the maximum energy absorption and maximum deformation. The steel plate had the least energy absorption and minimal deformation. Concrete and Aluminium had comparable areal density, energy absorption and lowest deformation, making them the preferred choice of plate material for a modified sandbag. The numerical studies were verified using a gas gun and a modified sandbag with Aluminium plates to show that the addition of a plate improves compaction behaviour of sand.},
  archive      = {J_JOCS},
  author       = {B. Thawani and R. Hazael and R. Critchley},
  doi          = {10.1016/j.jocs.2021.101403},
  journal      = {Journal of Computational Science},
  pages        = {101403},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical modelling study of a modified sandbag system for ballistic protection},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tutorial applications for verification, validation and
uncertainty quantification using VECMA toolkit. <em>JOCS</em>,
<em>53</em>, 101402. (<a
href="https://doi.org/10.1016/j.jocs.2021.101402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The VECMA toolkit enables automated Verification, Validation and Uncertainty Quantification (VVUQ) for complex applications that can be deployed on emerging exascale platforms and provides support for software applications for any domain of interest. The toolkit has four main components including EasyVVUQ for VVUQ workflows, FabSim3 for automation and tool integration, MUSCLE3 for coupling multiscale models and QCG tools to execute application workflows on high performance computing (HPC). A more recent addition to the VECMAtk is EasySurrogate for various types of surrogate methods. In this paper, we present five tutorials from different application domains that apply these VECMAtk components to perform uncertainty quantification analysis, use surrogate models, couple multiscale models and execute sensitivity analysis on HPC. This paper aims to provide hands-on experience for practitioners aiming to test and contrast with their own applications.},
  archive      = {J_JOCS},
  author       = {Diana Suleimenova and Hamid Arabnejad and Wouter N. Edeling and David Coster and Onnie O. Luk and Jalal Lakhlili and Vytautas Jancauskas and Michal Kulczewski and Lourens Veen and Dongwei Ye and Pavel Zun and Valeria Krzhizhanovskaya and Alfons Hoekstra and Daan Crommelin and Peter V. Coveney and Derek Groen},
  doi          = {10.1016/j.jocs.2021.101402},
  journal      = {Journal of Computational Science},
  pages        = {101402},
  shortjournal = {J. Comput. Sci.},
  title        = {Tutorial applications for verification, validation and uncertainty quantification using VECMA toolkit},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 20 years of computational science: Selected papers from 2020
international conference on computational science. <em>JOCS</em>,
<em>53</em>, 101395. (<a
href="https://doi.org/10.1016/j.jocs.2021.101395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOCS},
  author       = {Sergey V. Kovalchuk and Valeria V. Krzhizhanovskaya and Maciej Paszyński and Gábor Závodszky and Michael H. Lees and Jack Dongarra and Peter M.A. Sloot},
  doi          = {10.1016/j.jocs.2021.101395},
  journal      = {Journal of Computational Science},
  pages        = {101395},
  shortjournal = {J. Comput. Sci.},
  title        = {20 years of computational science: Selected papers from 2020 international conference on computational science},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Numerical study of the nonlinear anomalous
reaction–subdiffusion process arising in the electroanalytical
chemistry. <em>JOCS</em>, <em>53</em>, 101394. (<a
href="https://doi.org/10.1016/j.jocs.2021.101394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a meshless method based on the finite difference scheme derived from the local radial basis function (RBF-FD). The algorithm is used for finding the approximate solution of nonlinear anomalous reaction–diffusion models. The time discretization procedure is carried out by means of a weighted discrete scheme covering second-order approximation , while the spatial discretization is accomplished using the RBF-FD. The theoretical discussion validates the stability and convergence of the time-discretized formulation which are analyzed in the perspective to the H 1 H1 -norm. This approach benefits from a local collocation technique to estimate the differential operators using the weighted differences over local collection nodes through the RBF expansion. Two test problems illustrate the computational efficiency of the approach. Numerical simulations highlight the performance of the method that provides accurate solutions on complex domains with any distribution node type.},
  archive      = {J_JOCS},
  author       = {O. Nikan and Z. Avazzadeh and J.A. Tenreiro Machado},
  doi          = {10.1016/j.jocs.2021.101394},
  journal      = {Journal of Computational Science},
  pages        = {101394},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical study of the nonlinear anomalous reaction–subdiffusion process arising in the electroanalytical chemistry},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A simulation approach to evaluate the effect of demographic
changes on projected number of patients across disease categories.
<em>JOCS</em>, <em>53</em>, 101393. (<a
href="https://doi.org/10.1016/j.jocs.2021.101393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world’s changing demographic trends inevitably lead to new challenges in the delivery of healthcare services. As the population ages, the consequent demand for various types of medical treatments changes as well, but the process is not uniform, neither for particular age–gender cohorts nor for different diagnoses’ groups. A discrete event simulation (DES) model was built to forecast future healthcare demand based on population projections for one Polish administrative region. Population forecasts, formulated based on simulation experiments carried out in previous studies, were inputted into the DES model, together with patient data taken from the regional health fund. A simulation was run up to 2030 to predict future number of older patients across different diagnosis categories. The results show that a change in the demographic structure and in particular, in the population’s ageing, will lead to significant shifts in the distribution of health needs for hospital treatment.},
  archive      = {J_JOCS},
  author       = {Bożena Mielczarek},
  doi          = {10.1016/j.jocs.2021.101393},
  journal      = {Journal of Computational Science},
  pages        = {101393},
  shortjournal = {J. Comput. Sci.},
  title        = {A simulation approach to evaluate the effect of demographic changes on projected number of patients across disease categories},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Corrigendum to “hybrid meta-heuristic algorithm based deep
neural network for face recognition” [j. Comput. Sci. 51 (2021) 101352].
<em>JOCS</em>, <em>53</em>, 101391. (<a
href="https://doi.org/10.1016/j.jocs.2021.101391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOCS},
  author       = {Neha Soni and Enakshi Khular Sharma and Amita Kapoor},
  doi          = {10.1016/j.jocs.2021.101391},
  journal      = {Journal of Computational Science},
  pages        = {101391},
  shortjournal = {J. Comput. Sci.},
  title        = {Corrigendum to “Hybrid meta-heuristic algorithm based deep neural network for face recognition” [J. comput. sci. 51 (2021) 101352]},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge user allocation by FOA in edge computing environment.
<em>JOCS</em>, <em>53</em>, 101390. (<a
href="https://doi.org/10.1016/j.jocs.2021.101390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, edge computing (EC) has been widely studied as a new computing paradigm which extends cloud computing. It paves the way to further reduce the network latency between IoT/mobile devices (referred to as edge users hereafter) and service providers by pushing services and corresponding data from clouds to nearby edge servers located nearby edge users. The edge user allocation (EUA) problem is a new issue in EC environment. It aims at optimizing strategies to allocate edge users to those edge servers while fulfilling specific constraints, e.g., budget constraint, coverage constraint, etc. As the EUA problem is NP NP -hard, effectively and efficiently solving it is still intractable. In this paper, we take allocating maximum edge users and employing minimum edge servers as objectives, then take both the proximity constraint and capacity constraint into account, and propose EUA-FOA, an Fruit fly Optimization Algorithm (FOA)-based approach, to solve the EUA problem. To extensively evaluate EUA-FOA&#39;s performance, we employ a widely used real-world dataset to conduct two sets of experiments, including small-scale EUA scenarios and large-scale EUA scenarios. We compare EUA-FOA against four representative approaches and the experimental results demonstrate that EUA-FOA is highly effective as it outperforms the state-of-the-art approaches significantly.},
  archive      = {J_JOCS},
  author       = {Tingting Li and Wenqi Niu and Cun Ji},
  doi          = {10.1016/j.jocs.2021.101390},
  journal      = {Journal of Computational Science},
  pages        = {101390},
  shortjournal = {J. Comput. Sci.},
  title        = {Edge user allocation by FOA in edge computing environment},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Block-enhanced precision matrix estimation for large-scale
datasets. <em>JOCS</em>, <em>53</em>, 101389. (<a
href="https://doi.org/10.1016/j.jocs.2021.101389">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ℓ 1 -regularized Gaussian maximum likelihood method is a common approach for sparse precision matrix estimation, but one that poses a computational challenge for high-dimensional datasets. We present a novel ℓ 1 -regularized maximum likelihood method for performant large-scale sparse precision matrix estimation utilizing the block structures in the underlying computations. We identify the computational bottlenecks and contribute a block coordinate descent update as well as a block approximate matrix inversion routine, which is then parallelized using a shared-memory scheme. We demonstrate the effectiveness, accuracy, and performance of these algorithms. Our numerical examples and comparative results with various modern open-source packages reveal that these precision matrix estimation methods can accelerate the computation of covariance matrices by two to three orders of magnitude, while keeping memory requirements modest. Furthermore, we conduct large-scale case studies for applications from finance and medicine with several thousand random variables to demonstrate applicability for real-world datasets.},
  archive      = {J_JOCS},
  author       = {Aryan Eftekhari and Dimosthenis Pasadakis and Matthias Bollhöfer and Simon Scheidegger and Olaf Schenk},
  doi          = {10.1016/j.jocs.2021.101389},
  journal      = {Journal of Computational Science},
  pages        = {101389},
  shortjournal = {J. Comput. Sci.},
  title        = {Block-enhanced precision matrix estimation for large-scale datasets},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evaluating genetic algorithms through the approximability
hierarchy. <em>JOCS</em>, <em>53</em>, 101388. (<a
href="https://doi.org/10.1016/j.jocs.2021.101388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization problems frequently appear in any scientific domain. Most of the times, the corresponding decision problem turns out to be NP-hard, and in these cases genetic algorithms are often used to obtain approximated solutions. However, the difficulty to approximate different NP-hard problems can vary a lot. In this paper, we analyze the usefulness of using genetic algorithms depending on the approximation class the problem belongs to. In particular, we use the standard approximability hierarchy, showing that genetic algorithms are especially useful for the most pessimistic classes of the hierarchy.},
  archive      = {J_JOCS},
  author       = {Alba Muñoz and Fernando Rubio},
  doi          = {10.1016/j.jocs.2021.101388},
  journal      = {Journal of Computational Science},
  pages        = {101388},
  shortjournal = {J. Comput. Sci.},
  title        = {Evaluating genetic algorithms through the approximability hierarchy},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EB-DEVS: A formal framework for modeling and simulation of
emergent behavior in dynamic complex systems. <em>JOCS</em>,
<em>53</em>, 101387. (<a
href="https://doi.org/10.1016/j.jocs.2021.101387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emergent behavior is a key feature defining a system under study as a complex system. Simulation has been recognized as the only way to deal with the study of the emergence of properties (at a macroscopic level) among groups of system components (at a microscopic level), for the manifestations of emergent structures cannot be deduced from analyzing components in isolation. A systems-oriented generalization must consider the presence of feedback loops (micro components react to macro properties), interaction among components of different classes (modular composition) and layered interaction of subsystems operating at different spatio-temporal scales (hierarchical organization). In this work we introduce Emergent Behavior-DEVS (EB-DEVS) a Modeling and Simulation (M&amp;S) formalism that permits reasoning about complex systems where emergent behavior is placed at the forefront of the analysis activity. EB-DEVS builds on the DEVS formalism, adding upward/downward communication channels to well-established capabilities for modular and hierarchical M&amp;S of heterogeneous multi-formalism systems. EB-DEVS takes a minimalist stance on expressiveness, introducing a small set of extensions on Classic DEVS that can cope with emergent behavior, and making both formalisms interoperable (the modeler decides which subsystems deserve to be expressed via micro–macro dynamics). We present three case studies: flocks of birds with learning, population epidemics with vaccination and sub-cellular dynamics with homeostasis, through which we showcase how EB-DEVS performs by placing emergent properties at the center of the M&amp;S process.},
  archive      = {J_JOCS},
  author       = {Daniel Foguelman and Philipp Henning and Adelinde Uhrmacher and Rodrigo Castro},
  doi          = {10.1016/j.jocs.2021.101387},
  journal      = {Journal of Computational Science},
  pages        = {101387},
  shortjournal = {J. Comput. Sci.},
  title        = {EB-DEVS: A formal framework for modeling and simulation of emergent behavior in dynamic complex systems},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalization of change-point detection in time series data
based on direct density ratio estimation. <em>JOCS</em>, <em>53</em>,
101385. (<a href="https://doi.org/10.1016/j.jocs.2021.101385">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of the change-point detection is to discover changes of time series distribution. One of the state of the art approaches of change-point detection is based on direct density ratio estimation. In this work, we show how existing algorithms can be generalized using various binary classification and regression models. In particular, we show that the Gradient Boosting over Decision Trees and Neural Networks can be used for this purpose. The algorithms are tested on several synthetic and real-world datasets. The results show that the proposed methods outperform classical RuLSIF algorithm. Discussion of cases where the proposed algorithms have advantages over existing methods is also provided.},
  archive      = {J_JOCS},
  author       = {Mikhail Hushchyn and Andrey Ustyuzhanin},
  doi          = {10.1016/j.jocs.2021.101385},
  journal      = {Journal of Computational Science},
  pages        = {101385},
  shortjournal = {J. Comput. Sci.},
  title        = {Generalization of change-point detection in time series data based on direct density ratio estimation},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularization and the particles-on-demand method for the
solution of the discrete boltzmann equation. <em>JOCS</em>, <em>53</em>,
101376. (<a href="https://doi.org/10.1016/j.jocs.2021.101376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In its classical formulation, the lattice Boltzmann method (LBM) is applicable in the range of subsonic velocities and small temperature ratios. The novel Particle-on-demand method (PonD) allows to numerically solve the discrete Boltzmann equation for high Mach numbers. In comparison with the standard LBM, the collision step is simple, but the streaming step is implicit, not mass conserving and computationally heavy. A large part of the computational cost comes from matrix inversions during the rescaling of the discrete distribution functions (DF) from one gauge to another. To avoid matrix inversions, we propose another method of discrete DF rescaling, where the discrete DF are restored from the moments, while the conversion to a different reference frame is in the moment space. Results obtained by this improved method were compared to results, received by standard PonD for a number of problems. This improvement is validated to produce similar results to the original PonD, and is computationally cheaper in comparison with PonD.},
  archive      = {J_JOCS},
  author       = {E. Zipunova and A. Perepelkina and A. Zakirov and S. Khilkov},
  doi          = {10.1016/j.jocs.2021.101376},
  journal      = {Journal of Computational Science},
  pages        = {101376},
  shortjournal = {J. Comput. Sci.},
  title        = {Regularization and the particles-on-demand method for the solution of the discrete boltzmann equation},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Calibration of single-cell model parameters based on
membrane resistance improves the accuracy of cardiac tissue simulations.
<em>JOCS</em>, <em>53</em>, 101375. (<a
href="https://doi.org/10.1016/j.jocs.2021.101375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the calibration process, replicating some cellular properties is the main focus, while the importance of membrane resistance ( R m Rm ) that is primal in the tissue-level modeling is often underestimated. Previously, we presented a framework in which R m Rm in addition to action potential ( A P AP ) waveform was considered in the cellular model fitting. In this paper, we test the hypothesis that this approach for tuning cellular model parameters improves the accuracy of simulations at the tissue level. In doing so, two different sets of single-cell models are generated via independent realizations of our multi-objective optimization approach. In the first set of calibration ( Model I), root-mean-square error ( R M S E RMSE ) of A P AP , and absolute error ( A E AE ) of maximum upstroke velocity are included as optimization functions; however, in the second set of calibration ( Model II), R M S E RMSE of R m Rm curve in the repolarization phase is also added to the optimization functions. The calibrated cell models are then used in several tissue configurations of physiological relevance. We adopt well-defined evaluation metrics to compare tissue models tuned using Models I and II. In the source-sink mismatch configuration, the average absolute relative error ( A R E ARE ) of the critical transition border, defined as the smallest required window width between source and sink for A P AP propagation, is less than 4.7\% in Model II, while this error is increased to more than 8.9\% in Model I. In addition, in Model I, the average A R E ARE of total time for activation of tissue is 3.3–6.3\%; however, in Model II, this error is reduced to 0.7–1.6\%. In the Purkinje-myocardium configuration, the average of R M S E RMSE of activation time map is reduced approximately 75\% in Model II. Finally, in the transmural APD heterogeneity configuration, the average A R E s AREs of A P AP duration (APD) and APD dispersion (i.e., the difference between maximum and minimum of APD) are about 13.2\% and 17.4\% in Model I and 5.8\% and 6.8\% in Model II, respectively. Overall, our results demonstrate that consideration of R m Rm in the single-cell optimization procedure yields a substantial improvement in the accuracy of tissue models.},
  archive      = {J_JOCS},
  author       = {Elnaz Pouranbarani and Lucas Arantes Berg and Rafael Sachetto Oliveira and Rodrigo Weber dos Santos and Anders Nygren},
  doi          = {10.1016/j.jocs.2021.101375},
  journal      = {Journal of Computational Science},
  pages        = {101375},
  shortjournal = {J. Comput. Sci.},
  title        = {Calibration of single-cell model parameters based on membrane resistance improves the accuracy of cardiac tissue simulations},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diagnosis of lung cancer using hybrid deep neural network
with adaptive sine cosine crow search algorithm. <em>JOCS</em>,
<em>53</em>, 101374. (<a
href="https://doi.org/10.1016/j.jocs.2021.101374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lung cancer is a leading cause of cancer related deaths in all around the world. The identification of lung nodules is the significant step in the diagnosis of earlier lung cancer which can develop into a tumor. In the lung disease analysis, valuable information is provided by the Computed Tomography (CT) scan. The key objective is to find the malignant lung nodules and categorize the lung cancer whether it is benign or malignant. In this paper, propose a diagnosis of lung cancer using hybrid deep neural network with adaptive optimization algorithm . Initially, the preprocessing stage is performed using the fast non local means (FNLM) filter. For the segmentation process, the Masi entropy based multilevel thresholding using salp swarm algorithm (MasiEMT-SSA ) is used to segment the cancer nodule from the lung images. Using the grey-level run length matrix (GLRLM), different features are mined in the feature extraction. The binary grasshopper optimization algorithm (BGOA) is applied to select the optimum features for the feature selection (FS) process. Then the selected features are classified using the hybrid classifier named as deep neural network with adaptive sine cosine crow search(DNN-ASCCS) algorithm. The proposed hybrid classifier accurately detects the lung cancer. The proposed (DNN-ASCCS) is implemented by MATLAB using the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) datasets. The different performance metrics are evaluated and related to the existing classifiers and different state-of-art approaches. The simulation outcomes verified that the developed scheme is achieved a high classification accuracy (99.17\%) compared to other approaches.},
  archive      = {J_JOCS},
  author       = {Surendar P. and Ponni Bala M.},
  doi          = {10.1016/j.jocs.2021.101374},
  journal      = {Journal of Computational Science},
  pages        = {101374},
  shortjournal = {J. Comput. Sci.},
  title        = {Diagnosis of lung cancer using hybrid deep neural network with adaptive sine cosine crow search algorithm},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A line-search optimization method for non-gaussian data
assimilation via random quasi-orthogonal sub-spaces. <em>JOCS</em>,
<em>53</em>, 101373. (<a
href="https://doi.org/10.1016/j.jocs.2021.101373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper enhances the optimization method in [6] by using quasi-orthogonal vector bases and band matrices. Our approach employs the three-dimensional-variational (3D-Var) cost function to estimate posterior modes of error distributions. The proposed method works as follows: at each iteration, we estimate the 3D-Var cost function&#39;s negative gradient via a first-order Taylor approximation. This vector is then multiplied by random positive definite matrices to obtain a set of potential descent directions. We employ these directions to build an initial sub-space onto which partial analysis increments can be computed. Subsequently, we create a set of orthogonal directions to previous sub-spaces in a least-square sense; we search for additional analysis contributions onto the new directions via line-search optimization. Sub-space analysis increments are mapped back onto model spaces as they are found. We theoretically prove the convergence of our proposed optimization method. Experimental tests are performed by using the Lorenz-96 model. The results reveal that additional directions can improve the quality of analysis corrections during assimilation steps. Even more, as the sub-space dimension increases, the optimization method can converge faster to posterior modes of analysis distributions.},
  archive      = {J_JOCS},
  author       = {Elias D. Nino-Ruiz},
  doi          = {10.1016/j.jocs.2021.101373},
  journal      = {Journal of Computational Science},
  pages        = {101373},
  shortjournal = {J. Comput. Sci.},
  title        = {A line-search optimization method for non-gaussian data assimilation via random quasi-orthogonal sub-spaces},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting multidimensional data via tensor learning.
<em>JOCS</em>, <em>53</em>, 101372. (<a
href="https://doi.org/10.1016/j.jocs.2021.101372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of multidimensional data is becoming a more and more relevant topic in statistical and machine learning research. Given their complexity, such data objects are usually reshaped into matrices or vectors and then analysed. However, this methodology presents several drawbacks. First of all, it destroys the intrinsic interconnections among datapoints in the multidimensional space and, secondly, the number of parameters to be estimated in a model increases exponentially. We develop a model that overcomes such drawbacks. In particular, in this paper, we propose a parsimonious tensor regression model that retains the intrinsic multidimensional structure of the dataset. Tucker structure is employed to achieve parsimony and a shrinkage penalization is introduced to deal with over-fitting and collinearity. To estimate the model parameters, an Alternating Least Squares algorithm is developed. In order to validate the model performance and robustness, a simulation exercise is produced. Moreover, we perform an empirical analysis that highlight the forecasting power of the model with respect to benchmark models . This is achieved by implementing an autoregressive specification on the Foursquares spatio-temporal dataset together with a macroeconomic panel dataset. Overall, the proposed model is able to outperform benchmark models present in the forecasting literature.},
  archive      = {J_JOCS},
  author       = {Giuseppe Brandi and T. Di Matteo},
  doi          = {10.1016/j.jocs.2021.101372},
  journal      = {Journal of Computational Science},
  pages        = {101372},
  shortjournal = {J. Comput. Sci.},
  title        = {Predicting multidimensional data via tensor learning},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information transfer in finite flocks with topological
interactions. <em>JOCS</em>, <em>53</em>, 101370. (<a
href="https://doi.org/10.1016/j.jocs.2021.101370">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Vicsek model is a flocking model comprising simple point particles originally proposed with metric interactions: particles align to neighbours within a radius. Later, topological interactions were introduced such that particles align with their closest k k neighbours. We simulate the Vicsek model utilising topological neighbour interactions and estimate information theoretic quantities as a function of noise, the variability in the extent to which each particle aligns with its neighbours, and the flock direction. These quantities have been shown to be important in characterising phases transitions, such as that exhibited by the Vicsek model. We show that these quantities, mutual information and global transfer entropy, are in fact dependent on observation time, and in comparison to the canonical Vicsek model which utilises range-based interactions, the topological variant converges to the long-term limiting behaviour with smaller observation windows. Finally, we show that in contrast to the metric model, which exhibits maximal information transfer for the ordered regime, the topological model maintains this maximal information transfer dependent on noise and velocity, rather than the current phase.},
  archive      = {J_JOCS},
  author       = {Joshua M. Brown and Terry Bossomaier and Lionel Barnett},
  doi          = {10.1016/j.jocs.2021.101370},
  journal      = {Journal of Computational Science},
  pages        = {101370},
  shortjournal = {J. Comput. Sci.},
  title        = {Information transfer in finite flocks with topological interactions},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary rao algorithm. <em>JOCS</em>, <em>53</em>,
101368. (<a href="https://doi.org/10.1016/j.jocs.2021.101368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an evolutionary  Rao algorithm (ERA) to enhance three state-of-the-art metaheuristic Rao algorithms (Rao-1, Rao-2, Rao-3) by introducing two new schemes. Firstly, the population is split into two sub-populations based on their qualities: high and low, with a particular portion. The high-quality sub-population searches for an optimum solution in an exploitative manner using a movement scheme used in the Rao-3 algorithm. Meanwhile, the low-quality one does in an explorative fashion using a new random walk. Secondly, two evolutionary operators: crossover and mutation, are incorporated to provide both exploitation and exploration strategies. A fitness-based adaptation is introduced to dynamically tune the three parameters: the portion of high-quality individuals, mutation radius, and mutation rate throughout the evolution, based on the improvement of best-so-far fitness. In contrast, the crossover is implemented using a standard random scheme. Comprehensive examinations using 38 benchmarks: twenty-three classic functions, ten CEC-C06 2019 benchmarks, and five global trajectory optimization problems show that the proposed ERA generally outperforms the four competitors: Rao-1, Rao-2, Rao-3, and firefly algorithm with courtship learning (FA-CL). Detailed investigations indicate that both proposed schemes work very well to make ERA evolves in an exploitative manner, which is created by a high portion of high-quality individuals and the crossover operator, and avoids being trapped on the local optimum solutions in an explorative manner, which is generated by a high portion of low-quality individuals and the mutation operator. Finally, the adaptation scheme effectively controls the exploitation-exploration balance by dynamically tuning the portion, mutation radius, and mutation rate throughout the evolution process.},
  archive      = {J_JOCS},
  author       = {Suyanto Suyanto and Agung Toto Wibowo and Said Al Faraby and Siti Saadah and Rita Rismala},
  doi          = {10.1016/j.jocs.2021.101368},
  journal      = {Journal of Computational Science},
  pages        = {101368},
  shortjournal = {J. Comput. Sci.},
  title        = {Evolutionary rao algorithm},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling the boundary shape of the problems described by
navier–lamé equations using NURBS curves in parametric integral
equations system method. <em>JOCS</em>, <em>53</em>, 101367. (<a
href="https://doi.org/10.1016/j.jocs.2021.101367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is an extended version of the ICCS conference paper (Kapturczak et al., 2020, [1] ) and presents a way to improve the boundary shape modeling process in solving boundary value problems in elasticity. The inclusion of NURBS curves into the mathematical formalism of the parametric integral equations system method (PIES) is proposed. The advantages of such an application are widely discussed. Recently, the Bezier curves, mainly the cubic curves (of third-degree), were used. The segments of the boundary shape were modeled by such curves (with ensuring continuity at the connection points). Using NURBS curves, the boundary shape can be modeled with only one curve. So, continuity is automatically ensured. Additionally, the second degree NURBS curve is enough to obtain the shape with high accuracy (better than cubic Bezier curves). The NURBS curve is defined by points, their weights, and the knots vector. Such parameters significantly improve the shape modification process, which can directly improve e.g. the shape identification process. The examples of shape modification using such parameters are presented. The boundary shapes of the examples (even defined by both linear and curvilinear segments) can be defined using only one closed NURBS curve. The impact of modeling accuracy on the final PIES solutions is examined on examples described by the Navier–Lamé equations. To improve calculations, the PIES method using NURBS curves was implemented as a computer program. Then, it was decided to verify the accuracy of the obtained solutions. For comparison, the solutions were also obtained using analytical solutions, boundary element method , and PIES method (with the Bezier curves). An improvement in the boundary shape modeling was noticed. It significantly affects the accuracy of solutions. As a result, the consumption of computer resources was reduced, while the process of boundary shape modeling and the accuracy of the obtained results were improved.},
  archive      = {J_JOCS},
  author       = {Marta Kapturczak and Eugeniusz Zieniuk},
  doi          = {10.1016/j.jocs.2021.101367},
  journal      = {Journal of Computational Science},
  pages        = {101367},
  shortjournal = {J. Comput. Sci.},
  title        = {Modeling the boundary shape of the problems described by Navier–Lamé equations using NURBS curves in parametric integral equations system method},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A non-equilibrium bounce-back boundary condition for thermal
multispeed LBM. <em>JOCS</em>, <em>53</em>, 101364. (<a
href="https://doi.org/10.1016/j.jocs.2021.101364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-order lattice Boltzmann methods provide an elegant and systematic way to incorporate thermal and compressible effects and represent a promising approach for the study of beyond-hydrodynamics regimes characterized by finite Knudsen numbers. However, the presence of multiple layers makes the definition of boundary conditions non-trivial, since one needs to define the missing information for particle distributions across several boundary layers. In this work we present a thermal extension of a recently proposed non-equilibrium bounce-back boundary condition and compare it against established algorithms by simulating standard benchmarks with wall-bounded flows.},
  archive      = {J_JOCS},
  author       = {Friedemann Klass and Alessandro Gabbana and Andreas Bartel},
  doi          = {10.1016/j.jocs.2021.101364},
  journal      = {Journal of Computational Science},
  pages        = {101364},
  shortjournal = {J. Comput. Sci.},
  title        = {A non-equilibrium bounce-back boundary condition for thermal multispeed LBM},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flow through time–evolving porous media: Swelling and
erosion. <em>JOCS</em>, <em>53</em>, 101360. (<a
href="https://doi.org/10.1016/j.jocs.2021.101360">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The flow through a porous medium strongly depends on the boundary conditions, very often assumed to be static. Here, we consider changes in the medium due to swelling and erosion and extend existing lattice–Boltzmann models to include both. We study two boundary conditions: a constant pressure drop and a constant flow rate. For a constant flow rate, the steady state depends solely on the erosion dynamics while for a constant pressure drop it depends also on the timescale of swelling. We analyze the competition between swelling and erosion and identify a transition between regimes where either swelling or erosion dominate.},
  archive      = {J_JOCS},
  author       = {André F.V. Matias and Rodrigo C.V. Coelho and José S. Andrade Jr. and Nuno A.M. Araújo},
  doi          = {10.1016/j.jocs.2021.101360},
  journal      = {Journal of Computational Science},
  pages        = {101360},
  shortjournal = {J. Comput. Sci.},
  title        = {Flow through time–evolving porous media: Swelling and erosion},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multidimensional network link prediction algorithm and its
application for predicting social relationships. <em>JOCS</em>,
<em>53</em>, 101358. (<a
href="https://doi.org/10.1016/j.jocs.2021.101358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the &quot;We the Media&quot; era, the rules for forming social users&#39; following relationships are complex. Links generated between two social user nodes are influenced by not only the structural information of their social network nodes but also the users’ occupational environments, interests in opinions, topics, social psychology, etc. In the existing studies of link prediction in complex networks, predicting the possibility of link generation between two nodes that have not yet generated edges in a complex network is calculated mainly from the known network nodes and structural information. Such studies, in which the main predictors are the structural similarities among social nodes or user location nodes, cannot fully explore and utilize the social network node users’ public opinion characteristics. To quantitatively identify the influence of different dimensions of public opinion factors on predicting links between social user nodes, we present a study on the prediction of social network links in &quot;We the Media&quot; networks. Starting with the characteristics of the elements found in public opinions on “We the Media” networks, in which public opinions are multidimensional and multilayered and possess multiple attributes, we built a multidimensional network model oriented towards the topology of public opinions on “We the Media” networks. Combined with an analysis of the driving factors in the formation of user-node relationships in social networks, we designed a prediction algorithm that works on multidimensional network links. Furthermore, we conducted an empirical analysis of social relationship prediction, whose effectiveness has also been compared with baseline methods such as the Common-Neighbourhood-Driven model, the Jaccard index, and the SimRank method. We chose the area under the curve (AUC) as the indicator of link prediction and evaluation using “We the Media” public opinion data from Weibo.com. The research findings of this paper can be summarized as follows: (1) The effectiveness of the multidimensional network link prediction algorithm is significantly higher than those of the baseline methods. (2) The prediction algorithm presented in this paper works on multidimensional network links and can evaluate the effects of different dimensions of public opinion factors on the prediction of user-node links in social networks. (3) The element of occupational environment improves the accuracy much more than the element of user interest in opinions and topics when predicting user-nodes’ links, while the element of social psychology reduces the accuracy.},
  archive      = {J_JOCS},
  author       = {Wang Guanghui and Wang Yufei and Li Jimei and Liu Kaidi},
  doi          = {10.1016/j.jocs.2021.101358},
  journal      = {Journal of Computational Science},
  pages        = {101358},
  shortjournal = {J. Comput. Sci.},
  title        = {A multidimensional network link prediction algorithm and its application for predicting social relationships},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Managing crowded museums: Visitors flow measurement,
analysis, modeling, and optimization. <em>JOCS</em>, <em>53</em>,
101357. (<a href="https://doi.org/10.1016/j.jocs.2021.101357">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an all-around study of the visitors flow in crowded museums: a combination of Lagrangian field measurements and statistical analyses enable us to create stochastic digital-twins of the guest dynamics, unlocking comfort- and safety-driven optimizations. Our case study is the Galleria Borghese museum in Rome (Italy), in which we performed a real-life data acquisition campaign. We specifically employ a Lagrangian IoT-based visitor tracking system based on Raspberry Pi receivers, displaced in fixed positions throughout the museum rooms, and on portable Bluetooth Low Energy beacons handed over to the visitors. Thanks to two algorithms: a sliding window-based statistical analysis and an MLP neural network, we filter the beacons RSSI and accurately reconstruct visitor trajectories at room-scale. Via a clustering analysis, hinged on an original Wasserstein-like trajectory-space metric, we analyze the visitors paths to get behavioral insights, including the most common flow patterns. On these bases, we build the transition matrix describing, in probability, the room-scale visitor flows. Such a matrix is the cornerstone of a stochastic model capable of generating visitor trajectories in silico . We conclude by employing the simulator to enhance the museum fruition while respecting numerous logistic and safety constraints. This is possible thanks to optimized ticketing and new entrance/exit management.},
  archive      = {J_JOCS},
  author       = {P. Centorrino and A. Corbetta and E. Cristiani and E. Onofri},
  doi          = {10.1016/j.jocs.2021.101357},
  journal      = {Journal of Computational Science},
  pages        = {101357},
  shortjournal = {J. Comput. Sci.},
  title        = {Managing crowded museums: Visitors flow measurement, analysis, modeling, and optimization},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PalaCell2D: A framework for detailed tissue morphogenesis.
<em>JOCS</em>, <em>53</em>, 101353. (<a
href="https://doi.org/10.1016/j.jocs.2021.101353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In silico, cell based approaches for modeling biological morphogenesis are used to test and validate our understanding of the biological and mechanical processes that are at work during the growth and the organization of multi-cell tissues. As compared to in vivo experiments, computer based frameworks dedicated to tissue modeling allow us to easily test different hypotheses, and to quantify the impact of various biophysically relevant parameters. Here, we propose a formalism based on a detailed, yet simple, description of cells that accounts for intra-, inter- and extra-cellular mechanisms. More precisely, cell growth and division are described through the space and time evolution of the membrane vertices. These vertices follow a Newtonian dynamics, meaning that their evolution is controlled by different types of forces: a membrane force (spring and bending), an adherence force (inter-cellular spring), external and internal pressure forces. Different evolution laws can be applied to the internal pressure, depending on the intra-cellular mechanism of interest. In addition to the cells dynamics, our formalism further relies on a lattice Boltzmann method, using the Palabos library, to simulate the diffusion of chemical signals. The latter aims at driving the growth and migration of a tissue by simply changing the state of the cells. All of this leads to an accurate description of the growth and division of cells, with realistic cell shapes and where membranes can have different properties. While this work is mainly of methodological nature, we also propose to validate our framework through simple, yet biologically relevant benchmark tests at both single-cell and full tissue scales. This includes free and chemically controlled cell tissue growth in an unbounded domain. The ability of our framework to simulate cell migration, cell compression and morphogenesis under external constraints is also investigated in a qualitative manner.},
  archive      = {J_JOCS},
  author       = {Raphaël Conradin and Christophe Coreixas and Jonas Latt and Bastien Chopard},
  doi          = {10.1016/j.jocs.2021.101353},
  journal      = {Journal of Computational Science},
  pages        = {101353},
  shortjournal = {J. Comput. Sci.},
  title        = {PalaCell2D: A framework for detailed tissue morphogenesis},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-based multi-core higher-order time integration of
linear autonomous partial differential equations. <em>JOCS</em>,
<em>53</em>, 101349. (<a
href="https://doi.org/10.1016/j.jocs.2021.101349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern high-performance computing (HPC) systems rely on increasingly complex nodes with a steadily growing number of cores and matching deep memory hierarchies. In order to fully exploit them, algorithms must be explicitly designed to exploit these features. In this work we address this challenge for a widely used class of application kernels: polynomial-based time integration of linear autonomous partial differential equations. We build on prior work [1] of a cache-aware, yet sequential solution and provide an innovative way to parallelize it, while addressing cache-awareness across a large number of cores. For this, we introduce a dependency graph driven view of the algorithm and then use both static graph partitioning and dynamic scheduling to efficiently map the execution to the underlying platform. We implement our approach on top of the widely available Intel Threading Building Blocks (TBB) library, although the concepts are programming model agnostic and can apply to any task-driven parallel programming approach. We demonstrate the performance of our approach for a 2nd, 4th and 6th order time integration of the linear advection equation on three different architectures with widely varying memory systems and achieve an up to 60\% reduction of wall clock time compared to a conventional, state-of-the-art non-cache-aware approach.},
  archive      = {J_JOCS},
  author       = {Dominik Huber and Martin Schreiber and Martin Schulz},
  doi          = {10.1016/j.jocs.2021.101349},
  journal      = {Journal of Computational Science},
  pages        = {101349},
  shortjournal = {J. Comput. Sci.},
  title        = {Graph-based multi-core higher-order time integration of linear autonomous partial differential equations},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unit and regression tests of scientific software: A study on
SWMM. <em>JOCS</em>, <em>53</em>, 101347. (<a
href="https://doi.org/10.1016/j.jocs.2021.101347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Testing helps assure software quality by executing a program and uncovering bugs. Scientific software developers often find it challenging to carry out systematic and automated testing due to reasons like inherent model uncertainties and complex floating-point computations. Extending the recent work on analyzing the unit tests written by the developers of the Storm Water Management Model (SWMM) [32] , we report in this paper the investigation of both unit and regression tests of SWMM. The results show that the 2953 unit tests of SWMM have a 39.7\% statement-level code coverage and a 82.4\% user manual coverage. Meanwhile, an examination of 58 regression tests of SWMM shows a 44.9\% statement-level code coverage and a near 100\% user manual coverage. We also observe a “getter-setter-getter” testing pattern from the SWMM unit tests, and suggest a diversified way of executing regression tests.},
  archive      = {J_JOCS},
  author       = {Zedong Peng and Xuanyi Lin and Michelle Simon and Nan Niu},
  doi          = {10.1016/j.jocs.2021.101347},
  journal      = {Journal of Computational Science},
  pages        = {101347},
  shortjournal = {J. Comput. Sci.},
  title        = {Unit and regression tests of scientific software: A study on SWMM},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partial differential equations discovery with EPDE
framework: Application for real and synthetic data. <em>JOCS</em>,
<em>53</em>, 101345. (<a
href="https://doi.org/10.1016/j.jocs.2021.101345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven methods provide model creation tools for systems where the application of conventional analytical methods is restrained. The proposed method involves the data-driven derivation of a partial differential equation (PDE) for process dynamics, helping process simulation and study. The paper describes the methods that are used within the EPDE (Evolutionary Partial Differential Equations) partial differential equation discovery framework [1] . The framework involves a combination of evolutionary algorithms and sparse regression. Such an approach is versatile compared to other commonly used data-driven partial differential derivation methods by making fewer assumptions about the resulting equation. This paper highlights the algorithm features that allow data processing with noise, which is similar to the algorithm&#39;s real-world applications. This paper is an extended version of the ICCS-2020 conference paper [2] .},
  archive      = {J_JOCS},
  author       = {Mikhail Maslyaev and Alexander Hvatov and Anna V. Kalyuzhnaya},
  doi          = {10.1016/j.jocs.2021.101345},
  journal      = {Journal of Computational Science},
  pages        = {101345},
  shortjournal = {J. Comput. Sci.},
  title        = {Partial differential equations discovery with EPDE framework: Application for real and synthetic data},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-intrusive polynomial chaos methods for uncertainty
quantification in wave problems at high frequencies. <em>JOCS</em>,
<em>53</em>, 101344. (<a
href="https://doi.org/10.1016/j.jocs.2021.101344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Numerical solutions of wave problems are often influenced by uncertainties generated by a lack of knowledge of the input values related to the domain data and/or boundary conditions in the mathematical equations used in the modeling. Conventional methods for uncertainty quantification in modeling waves constitute severe challenges due to the high computational costs especially at high frequencies/wavenumbers. For a given accuracy and a high wavenumber it is necessary to perform a mesh convergence study by refining the discretization of the computational domain with an increased resolution, which leads to increasing the number of degrees of freedom at a much higher rate than the wavenumber. This effect also known as the pollution error often limits the computations to relatively small values of the wavenumber. To estimate the uncertainties, many model evaluations are required, but only a single surrogate model is created in the process. In the present work, we propose the use of a non-intrusive spectral projection applied to a finite element framework with enriched basis functions for the uncertainty quantification of waves at high frequencies. The method integrates (i) the partition of unity finite element method for effectively computing the solutions of waves at high frequencies; and (ii) a non-intrusive spectral projection for effectively propagating random wavenumbers that encode uncertainties in the wave problems. Compared to the conventional finite element methods, the proposed method is demonstrated to reduce the total cost of accurately computing uncertainties in waves with high values of the wavenumber. Numerical results are presented for two sets of numerical tests. First, the interference of plane waves in a squared domain and then a wave scattering by a circular cylinder are studied at high wavenumbers. Comparisons to the Monte Carlo simulations and the regression based polynomial chaos expansion confirm the computational effectiveness of the proposed approach.},
  archive      = {J_JOCS},
  author       = {Nabil El Mocayd and M Shadi Mohamed and Mohammed Seaid},
  doi          = {10.1016/j.jocs.2021.101344},
  journal      = {Journal of Computational Science},
  pages        = {101344},
  shortjournal = {J. Comput. Sci.},
  title        = {Non-intrusive polynomial chaos methods for uncertainty quantification in wave problems at high frequencies},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recursive filter based GPU algorithms in a data assimilation
scenario. <em>JOCS</em>, <em>53</em>, 101339. (<a
href="https://doi.org/10.1016/j.jocs.2021.101339">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data Assimilation process is generally used to estimate the best initial state of a system in order to improve accuracy of future states prediction. This powerful technique has been widely applied in investigations of the atmosphere, ocean, and land surface. In this work, we deal with the Gaussian convolution operation which is a central step of the Data Assimilation approach, as well as in several data analysis procedures. In particular, we consider the use of recursive filters to approximate the Gaussian convolution. In [1] we presented an accelerated first-order recursive filter to compute the Gaussian convolution kernel , in a very fast way. We present theory and results, and we provide a new GPU-parallel implementation which is based on the third order recursive filter. To observe the benefits in terms of performance, tests and experiments complete our work.},
  archive      = {J_JOCS},
  author       = {P. De Luca and A. Galletti and G. Giunta and L. Marcellino},
  doi          = {10.1016/j.jocs.2021.101339},
  journal      = {Journal of Computational Science},
  pages        = {101339},
  shortjournal = {J. Comput. Sci.},
  title        = {Recursive filter based GPU algorithms in a data assimilation scenario},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influence of the grid cell geometry on 3D cellular automata
behavior in intergranular corrosion. <em>JOCS</em>, <em>53</em>, 101322.
(<a href="https://doi.org/10.1016/j.jocs.2021.101322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bulk structure of stainless steels (SS) consists of mostly convex grains whose thin (one nm) planar interfaces are called grain boundaries (GB). There are industrial contexts where SS exposed to aggressive oxidative media undergo a fast degradation due to inter-granular corrosion (IGC), a preferential attack that occurs at the grain boundaries, propagating along them and leading to grains detachment. To address the IGC issue, we developed a 3D synchronous cellular automata (CA) model. Our first goal was to obtain a GB corrosion rate that could be as isotropic as possible. We performed full angular studies, with respect to the spatial orientation of a single grain boundary, in three different cases of grid (array of cells) geometry (cubic, hexagonal close-packed (HCP), face-centered cubic (FCC)). The HCP grid appears to be the best choice, as far as isotropy of the GB corrosion rate is concerned.},
  archive      = {J_JOCS},
  author       = {Simone Guiso and Dung di Caprio and Jacques de Lamare and Benoît Gwinner},
  doi          = {10.1016/j.jocs.2021.101322},
  journal      = {Journal of Computational Science},
  pages        = {101322},
  shortjournal = {J. Comput. Sci.},
  title        = {Influence of the grid cell geometry on 3D cellular automata behavior in intergranular corrosion},
  volume       = {53},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Translation computer science – overview of the special
issue. <em>JOCS</em>, <em>52</em>, 101227. (<a
href="https://doi.org/10.1016/j.jocs.2020.101227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_JOCS},
  author       = {David Abramson and Manish Parashar and Peter Arzberger},
  doi          = {10.1016/j.jocs.2020.101227},
  journal      = {Journal of Computational Science},
  pages        = {101227},
  shortjournal = {J. Comput. Sci.},
  title        = {Translation computer science – overview of the special issue},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Translational computer science at the scientific computing
and imaging institute. <em>JOCS</em>, <em>52</em>, 101217. (<a
href="https://doi.org/10.1016/j.jocs.2020.101217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Scientific Computing and Imaging (SCI) Institute at the University of Utah evolved from the SCI research group, started in 1994 by Professors Chris Johnson and Rob MacLeod. Over time, research centers funded by the National Institutes of Health, Department of Energy, and State of Utah significantly spurred growth, and SCI became a permanent interdisciplinary research institute in 2000. The SCI Institute is now home to more than 150 faculty, students, and staff. The history of the SCI Institute is underpinned by a culture of multidisciplinary, collaborative research, which led to its emergence as an internationally recognized leader in the development and use of visualization, scientific computing, and image analysis research to solve important problems in a broad range of domains in biomedicine, science, and engineering. A particular hallmark of SCI Institute research is the creation of open source software systems, including the SCIRun scientific problem-solving environment, Seg3D, ImageVis3D, Uintah, ViSUS, Nektar++, VisTrails, FluoRender, and FEBio. At this point, the SCI Institute has made more than 50 software packages broadly available to the scientific community under open-source licensing and supports them through web pages, documentation, and user groups. While the vast majority of academic research software is written and maintained by graduate students, the SCI Institute employs several professional software developers to help create, maintain, and document robust, tested, well-engineered open source software . The story of how and why we worked, and often struggled, to make professional software engineers an integral part of an academic research institute is crucial to the larger story of the SCI Institute’s success in translational computer science (TCS).},
  archive      = {J_JOCS},
  author       = {Chris Johnson},
  doi          = {10.1016/j.jocs.2020.101217},
  journal      = {Journal of Computational Science},
  pages        = {101217},
  shortjournal = {J. Comput. Sci.},
  title        = {Translational computer science at the scientific computing and imaging institute},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Translational process: Mathematical software perspective.
<em>JOCS</em>, <em>52</em>, 101216. (<a
href="https://doi.org/10.1016/j.jocs.2020.101216">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Each successive generation of computer architecture has brought new challenges to achieving high performance mathematical solvers, necessitating development and analysis of new algorithms, which are then embodied in software libraries. These libraries hide architectural details from applications, allowing them to achieve a level of portability across platforms from desktops to world-class high performance computing (HPC) systems. Thus there has been an informal translational computer science process of developing algorithms and distributing them in open source software libraries for adoption by applications and vendors. With the move to exascale, increasing intentionality about this process will benefit the long-term sustainability of the scientific software stack.},
  archive      = {J_JOCS},
  author       = {Jack Dongarra and Mark Gates and Piotr Luszczek and Stanimire Tomov},
  doi          = {10.1016/j.jocs.2020.101216},
  journal      = {Journal of Computational Science},
  pages        = {101216},
  shortjournal = {J. Comput. Sci.},
  title        = {Translational process: Mathematical software perspective},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Translating the grid: How a translational approach shaped
the development of grid computing. <em>JOCS</em>, <em>52</em>, 101214.
(<a href="https://doi.org/10.1016/j.jocs.2020.101214">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing gap between progress in biological knowledge and improved health outcomes inspired the new discipline of translational medicine, in which the application of new knowledge is an explicit part of a research plan. Abramson and Parashar argue that a similar gap between complex computational technologies and ever-more-challenging applications demands an analogous discipline of translational computer science, in which the deliberate movement of research results into large-scale practice becomes a central research focus rather than an afterthought. We revisit from this perspective the development and application of grid computing from the mid-1990s onwards, and find that a translational framing is useful for understanding the technology’s development and impact. We discuss how the development of grid computing infrastructure, and the Globus Toolkit, in particular, benefited from a translational approach. We identify lessons learned that can be applied to other translational computer science initiatives.},
  archive      = {J_JOCS},
  author       = {Ian Foster and Carl Kesselman},
  doi          = {10.1016/j.jocs.2020.101214},
  journal      = {Journal of Computational Science},
  pages        = {101214},
  shortjournal = {J. Comput. Sci.},
  title        = {Translating the grid: How a translational approach shaped the development of grid computing},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Principles, technologies, and time: The translational
journey of the HTCondor-CE. <em>JOCS</em>, <em>52</em>, 101213. (<a
href="https://doi.org/10.1016/j.jocs.2020.101213">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mechanisms for remote execution of computational tasks enable a distributed system to effectively utilize all available resources. This ability is essential to attaining the objectives of high availability, system reliability, and graceful degradation and directly contribute to flexibility, adaptability, and incremental growth. As part of a national fabric of Distributed High Throughput Computing (dHTC) services, remote execution is a cornerstone of the Open Science Grid (OSG) Compute Federation. Most of the organizations that harness the computing capacity provided by the OSG also deploy HTCondor pools on resources acquired from the OSG. The HTCondor Compute Entrypoint (CE) facilitates the remote acquisition of resources by all organizations. The HTCondor-CE is the product of a most recent translational cycle that is part of a multidecade translational process. The process is rooted in a partnership, between members of the High Energy Physics community and computer scientists, that evolved over three decades and involved testing and evaluation with active users and production infrastructures. Through several translational cycles that involved researchers from different organizations and continents, principles, ideas, frameworks and technologies were translated into a widely adopted software artifact that isresponsible for provisioning of approximately 9 million core hours per day across 170 endpoints.},
  archive      = {J_JOCS},
  author       = {Brian Bockelman and Miron Livny and Brian Lin and Francesco Prelz},
  doi          = {10.1016/j.jocs.2020.101213},
  journal      = {Journal of Computational Science},
  pages        = {101213},
  shortjournal = {J. Comput. Sci.},
  title        = {Principles, technologies, and time: The translational journey of the HTCondor-CE},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Translating novel HPC techniques into efficient geoscience
solutions. <em>JOCS</em>, <em>52</em>, 101212. (<a
href="https://doi.org/10.1016/j.jocs.2020.101212">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational geoscience is an established field for better understanding and protecting our planet. It covers a wide range of different fields that are closely related to Earth systems. As a popular research area that largely relies on high performance computing, the efficient translation of novel techniques from computer science to practical geoscience solutions has emerged as an important and challenging problem. Based on a series of efforts in conducting interdisciplinary research in computer science and geoscience, this paper summarizes the measures we have taken and the lessons we have learned to successfully translate selected computational laboratory innovations into practical solutions.},
  archive      = {J_JOCS},
  author       = {Lin Gan and Haohuan Fu and Guangwen Yang},
  doi          = {10.1016/j.jocs.2020.101212},
  journal      = {Journal of Computational Science},
  pages        = {101212},
  shortjournal = {J. Comput. Sci.},
  title        = {Translating novel HPC techniques into efficient geoscience solutions},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Computational analysis of cardiac structure and function in
congenital heart disease: Translating discoveries to clinical
strategies. <em>JOCS</em>, <em>52</em>, 101211. (<a
href="https://doi.org/10.1016/j.jocs.2020.101211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Increased availability and access to medical image data has enabled more quantitative approaches to clinical diagnosis, prognosis, and treatment planning for congenital heart disease. Here we present an overview of long-term clinical management of congenital heart disease and its intersection with novel computational and data science approaches to discovering biomarkers of functional and prognostic importance. Efforts in translational medicine that seek to address the clinical challenges associated with cardiovascular diseases using personalized and precision-based approaches are then discussed. The considerations and challenges of translational cardiovascular medicine are reviewed, and examples of digital platforms with collaborative, cloud-based, and scalable design are provided.},
  archive      = {J_JOCS},
  author       = {Nickolas Forsch and Sachin Govil and James C Perry and Sanjeet Hegde and Alistair A Young and Jeffrey H Omens and Andrew D McCulloch},
  doi          = {10.1016/j.jocs.2020.101211},
  journal      = {Journal of Computational Science},
  pages        = {101211},
  shortjournal = {J. Comput. Sci.},
  title        = {Computational analysis of cardiac structure and function in congenital heart disease: Translating discoveries to clinical strategies},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building cyberinfrastructure for translational impact: The
WIFIRE example. <em>JOCS</em>, <em>52</em>, 101210. (<a
href="https://doi.org/10.1016/j.jocs.2020.101210">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper overviews the enablers and phases for translational cyberinfrastructure for data-driven applications. In particular, it summarizes the translational process of and the lessons learned from the development of the NSF WIFIRE cyberinfrastructure. WIFIRE is an end-to-end cyberinfrastructure for real-time data fusion and data-driven simulation, prediction, and visualization of wildﬁre behavior. WIFIRE’s real-time data products and modeling services are routinely accessed by fire research and emergency response communities for modeling as well as the public for situational awareness. In this paper, WIFIRE’s approach to community-integrated innovation, product development and operationalization is described. Existing sustainability efforts and public/private partnerships as a result of this demand is also discussed.},
  archive      = {J_JOCS},
  author       = {Ilkay Altintas},
  doi          = {10.1016/j.jocs.2020.101210},
  journal      = {Journal of Computational Science},
  pages        = {101210},
  shortjournal = {J. Comput. Sci.},
  title        = {Building cyberinfrastructure for translational impact: The WIFIRE example},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The MVAPICH project: Transforming research into
high-performance MPI library for HPC community. <em>JOCS</em>,
<em>52</em>, 101208. (<a
href="https://doi.org/10.1016/j.jocs.2020.101208">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-Performance Computing (HPC) research, from hardware and software to the end applications, provides remarkable computing power to help scientists solve complex problems in science, engineering, or even daily business. Over the last decades, Message Passing Interface (MPI) libraries have been powering numerous scientific applications, such as weather forecasting, earthquake simulations, physic, and chemical simulations, to conduct ever-large-scale experiments. However, it is always challenging to practice HPC research. In this article, we use the well-established MVAPICH project to discuss how researchers can transform the HPC research into a high-performance MPI library and translate it to the HPC community.},
  archive      = {J_JOCS},
  author       = {Dhabaleswar Kumar Panda and Hari Subramoni and Ching-Hsiang Chu and Mohammadreza Bayatpour},
  doi          = {10.1016/j.jocs.2020.101208},
  journal      = {Journal of Computational Science},
  pages        = {101208},
  shortjournal = {J. Comput. Sci.},
  title        = {The MVAPICH project: Transforming research into high-performance MPI library for HPC community},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Translational research in the MPICH project. <em>JOCS</em>,
<em>52</em>, 101203. (<a
href="https://doi.org/10.1016/j.jocs.2020.101203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The MPICH project is an example of translational research in computer science before that term was well known or even coined. The project began in 1992 as an effort to develop a portable, high-performance implementation of the emerging Message-Passing Interface (MPI) Standard. It has enabled the widespread adoption of MPI as a way to write scalable parallel applications on systems of all sizes including upcoming exascale supercomputers . In this paper, we describe how the translational research process was used in MPICH, how that led to its success, the challenges encountered and lessons learned, and how the process could be applied to other similar projects.},
  archive      = {J_JOCS},
  author       = {William Gropp and Rajeev Thakur and Pavan Balaji},
  doi          = {10.1016/j.jocs.2020.101203},
  journal      = {Journal of Computational Science},
  pages        = {101203},
  shortjournal = {J. Comput. Sci.},
  title        = {Translational research in the MPICH project},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The virtual assay software for human in silico drug trials
to augment drug cardiac testing. <em>JOCS</em>, <em>52</em>, 101202. (<a
href="https://doi.org/10.1016/j.jocs.2020.101202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prediction of drug effects on the heart still represents a challenge in drug development, given potential adverse outcomes. Computer modelling and simulations of the human heart offer a powerful technology to augment existing animal and clinical methodologies. Here we describe the translation process that led to the development and uptake of Virtual Assay, a user-friendly software to perform in silico drug trials in population of human cardiac models. Through this work, we contributed to the uptake of in silico modelling and simulations in industry and regulatory paradigms, and demonstrated accurate and mechanistic predictions of drug-induced cardiac pro-arrhythmic toxicity.},
  archive      = {J_JOCS},
  author       = {Elisa Passini and Xin Zhou and Cristian Trovato and Oliver J Britton and Alfonso Bueno-Orovio and Blanca Rodriguez},
  doi          = {10.1016/j.jocs.2020.101202},
  journal      = {Journal of Computational Science},
  pages        = {101202},
  shortjournal = {J. Comput. Sci.},
  title        = {The virtual assay software for human in silico drug trials to augment drug cardiac testing},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The pegasus workflow management system: Translational
computer science in practice. <em>JOCS</em>, <em>52</em>, 101200. (<a
href="https://doi.org/10.1016/j.jocs.2020.101200">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Translational research (TR) has been extensively used in the health science domain, where results from laboratory research are translated to human studies and where evidence-based practices are adopted in real-world settings to reach broad communities. In computer science, much research stops at the result publication and dissemination stage without moving to the evaluation in real settings at scale and feeding the gained knowledge back to research. Additionally, there is a lack of steady funding and incentives to broadly promote translational computer science (TCS) in practice. In this paper, we present how, throughout its lifespan, the Pegasus workflow management system project has incorporated the principles of translational computer science. We report on our experience on building a strong, long-term engagement with a broad range of science communities to establish mutually beneficial relationships between the core R&amp;D team and these communities.},
  archive      = {J_JOCS},
  author       = {Ewa Deelman and Rafael Ferreira da Silva and Karan Vahi and Mats Rynge and Rajiv Mayani and Ryan Tanaka and Wendy Whitcup and Miron Livny},
  doi          = {10.1016/j.jocs.2020.101200},
  journal      = {Journal of Computational Science},
  pages        = {101200},
  shortjournal = {J. Comput. Sci.},
  title        = {The pegasus workflow management system: Translational computer science in practice},
  volume       = {52},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid predictive modelling: Thyrotoxic atrial fibrillation
case. <em>JOCS</em>, <em>51</em>, 101365. (<a
href="https://doi.org/10.1016/j.jocs.2021.101365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a new approach to predictive modelling of disease complications development. This approach is based on hybrid methods that have several advantages in comparison with classic methods. The main advantage is the inclusion of the complex information about the dynamics of a patient’s conditions using pathways analysis and graph-based predictive modelling method. Hybrid approaches integrate results of classic machine learning (ML) models and dynamic analysis methods for better modelling and prediction. We present this method’s application to the practical case of predictive modelling of Thyrotoxicosis Atrial Fibrillation (TAF) development. Medical specialists need tools to estimate the level of risk of developing TAF. Using the proposed predictive modelling method, our team developed such a tool. The method was validated using common ML metrics and expert evaluation and can be used as part of a decision support system for medical staff who work with thyrotoxicosis patients. This manuscript presents an extended version of the work described in the paper [ 1 ]. In this work, we proposed several methods for calculating the probability of TAF development. Our methods include arterial fibrillation risk questionnaire for use in practical diagnostic tasks and tools for analyzing TAF dynamic. The extended study presents further development of the approach within the hybrid modelling approach.},
  archive      = {J_JOCS},
  author       = {Ilia V. Derevitskii and Daria A. Savitskaya and Alina Yu. Babenko and Sergey V. Kovalchuk},
  doi          = {10.1016/j.jocs.2021.101365},
  journal      = {Journal of Computational Science},
  pages        = {101365},
  shortjournal = {J. Comput. Sci.},
  title        = {Hybrid predictive modelling: Thyrotoxic atrial fibrillation case},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lattice-boltzmann coupled models for advection–diffusion
flow on a wide range of péclet numbers. <em>JOCS</em>, <em>51</em>,
101363. (<a href="https://doi.org/10.1016/j.jocs.2021.101363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional Lattice-Boltzmann modelling of advection–diffusion flow is affected by numerical instability if the advective term becomes dominant over the diffusive ( i.e. , high-Péclet flow). To overcome the problem, two 3D one-way coupled models are proposed. In a traditional model, a Lattice-Boltzmann Navier–Stokes solver is coupled to a Lattice-Boltzmann advection–diffusion model. In a novel model, the Lattice-Boltzmann Navier–Stokes solver is coupled to an explicit finite-difference algorithm for advection–diffusion. The finite-difference algorithm also includes a novel approach to mitigate the numerical diffusivity connected with the upwind differentiation scheme. The models are validated using two non-trivial benchmarks, which includes discontinuous initial conditions and the case Pe g → ∞ Peg→∞ for the first time, where Pe g Peg is the grid Péclet number. The evaluation of Pe g Peg alongside Pe Pe is discussed. Accuracy, stability and the order of convergence are assessed for a wide range of Péclet numbers. Recommendations are then given as to which model to select depending on the value Pe g Peg —in particular, it is shown that the coupled finite-difference/Lattice-Boltzmann provide stable solutions in the case Pe → ∞ Pe→∞ , Pe g → ∞ Peg→∞ .},
  archive      = {J_JOCS},
  author       = {Davide Dapelo and Stephan Simonis and Mathias J. Krause and John Bridgeman},
  doi          = {10.1016/j.jocs.2021.101363},
  journal      = {Journal of Computational Science},
  pages        = {101363},
  shortjournal = {J. Comput. Sci.},
  title        = {Lattice-boltzmann coupled models for advection–diffusion flow on a wide range of péclet numbers},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling the effect of application-specific program
transformations on energy and performance improvements of parallel ODE
solvers. <em>JOCS</em>, <em>51</em>, 101356. (<a
href="https://doi.org/10.1016/j.jocs.2021.101356">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ordinary differential equations (ODEs) are important for modelling many problems from science and engineering and efficient ODE solvers are required, for example when solving time-dependent partial differential equations (PDEs) with the method of lines. Since an ODE solver may perform a large number of iteration steps, the execution time for solving an ODE problem might be quite large. Thus, a reduction of the execution time is desirable and should affect each iteration step of the simulation. Programming techniques to reduce the execution time of ODE solver are parallelism and modification of the memory access structure such that the memory access time decreases. In this article, we investigate multithreaded solution methods for ODEs with different memory access behavior and their influence on the performance. Additionally the energy consumption is considered. The parallelism is implemented as shared memory program for multicore processors. The memory access behavior is investigated using different program variants which result from application-specific program transformations changing the memory access order while guaranteeing the numerical correctness. For the investigation of the performance, experimental data have been gathered on five different recent multicore processors. Additionally, an analytical power and energy model for modeling the performance and energy consumption is introduced. As ODE solver, the popular embedded Runge-Kutta methods with error correction is used. The simulation problems are two different ODEs resulting from discretized PDEs. The experimental data give insight into the quite diverse performance behavior of the ODE solver variants solving the same problem on different platforms.},
  archive      = {J_JOCS},
  author       = {Thomas Rauber and Gudula Rünger},
  doi          = {10.1016/j.jocs.2021.101356},
  journal      = {Journal of Computational Science},
  pages        = {101356},
  shortjournal = {J. Comput. Sci.},
  title        = {Modeling the effect of application-specific program transformations on energy and performance improvements of parallel ODE solvers},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cubature rules for weakly and fully compressible off-lattice
boltzmann methods. <em>JOCS</em>, <em>51</em>, 101355. (<a
href="https://doi.org/10.1016/j.jocs.2021.101355">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Off-lattice Boltzmann methods increase the flexibility and applicability of lattice Boltzmann methods by decoupling the discretizations of time, space, and particle velocities. However, the velocity sets that are mostly used in off-lattice Boltzmann simulations were originally tailored to on-lattice Boltzmann methods. In this contribution, we show how the accuracy and efficiency of weakly and fully compressible semi-Lagrangian off-lattice Boltzmann simulations are increased by velocity sets derived from cubature rules, i.e., multivariate quadratures not produced by the Gauß-product rule. In particular, simulations of 2D shock-vortex interactions indicate that the cubature-derived degree-nine D2Q19 velocity set is capable of replacing the Gauß-product rule-derived D2Q25. Likewise, the degree-five velocity sets D3Q13 and D3Q21, as well as a degree-seven D3V27 velocity set were successfully tested for 3D Taylor–Green vortex flows to challenge and surpass the quality of the customary D3Q27 velocity set. In compressible 3D Taylor–Green vortex flows with Mach numbers Ma = { 0 . 5 ; 1 . 0 ; 1 . 5 ; 2 . 0 } Ma={0.5;1.0;1.5;2.0} on-lattice simulations with velocity sets D3Q103 and D3V107 showed only limited stability, while the off-lattice degree-nine D3Q45 velocity set accurately reproduced the kinetic energy provided by literature.},
  archive      = {J_JOCS},
  author       = {Dominik Wilde and Andreas Krämer and Mario Bedrunka and Dirk Reith and Holger Foysi},
  doi          = {10.1016/j.jocs.2021.101355},
  journal      = {Journal of Computational Science},
  pages        = {101355},
  shortjournal = {J. Comput. Sci.},
  title        = {Cubature rules for weakly and fully compressible off-lattice boltzmann methods},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Hybrid meta-heuristic algorithm based deep neural network
for face recognition. <em>JOCS</em>, <em>51</em>, 101352. (<a
href="https://doi.org/10.1016/j.jocs.2021.101352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition has been active research in the security domain. Human face recognition gains importance for developing a secured environment for the organization and also enhances the usage of artificial intelligence for security. Face recognition has been studied over the years for accurate recognition of complete face images. However, in the real case, the presence of occlusion and noise in the image significantly affects the performance of the recognition. Even though a lot of research has been carried out in handling the occluded and noisy image, more refinement is required to achieve high accuracy. This paper proposes a simple and efficient face recognition system with occlusion and noisy faces using the deep learning concept, as it has the advantage of handling all of it. The developed model undergoes four main steps like (a) preprocessing, (b) cascaded feature extraction, (c) optimal feature selection, and (d) recognition. Initially, the preprocessing of the face image is focused in terms of face detection by Viola-Jones algorithm. Further, a set of features termed as Local Diagonal Extrema Number Pattern (LDENP), Gradient-based directional features, and Gradient-based wavelet features are extracted for the cascaded feature extraction. As the collection of features is in a cascaded manner, it leads to providing irrelevant information of features. Hence, there is a need for optimal feature selection. The hybrid meta-heuristic concept, namely Multi-Verse with Colliding Bodies Optimization (MV-CBO), is developed with the integration of Colliding Bodies Optimization (CBO) and Multi-Verse Optimizer (MVO), and it is used for performing the optimal feature selection. Further, the optimally selected features are subjected to the optimized Deep Neural Network (DNN) for recognizing the faces, in which the proposed MV-CBO is used for optimizing the activation functions (sigmoid, tanh, Relu, ArcTan, and RRelu). The experimental findings on diverse datasets with occlusion and noises prove that the extensive experiments on several benchmark databases prove the ability of the proposed model over the existing face recognition approaches.},
  archive      = {J_JOCS},
  author       = {Neha Soni and Enakshi Khular Sharma and Amita Kapoor},
  doi          = {10.1016/j.jocs.2021.101352},
  journal      = {Journal of Computational Science},
  pages        = {101352},
  shortjournal = {J. Comput. Sci.},
  title        = {Hybrid meta-heuristic algorithm based deep neural network for face recognition},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Numerical simulation of tethered–wing power systems based on
variational integration. <em>JOCS</em>, <em>51</em>, 101351. (<a
href="https://doi.org/10.1016/j.jocs.2021.101351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes dynamic formulations for a multi-physics system consisting of an electrical generator and a finite element model of a variable-length cable attached at one end to a reeling mechanism and the other to a rigid body that represents a flying wing. Lie group methods are utilized to obtain singularity-free dynamics of the wing. Two different methods are employed for the derivation and integration of the Euler–Lagrange equations. In the first method, the equations of motion are derived in continuous-time and integrated by a general-purpose implicit ODE solver. The second is the application of the discrete analogue of Lagrange–d’Alembert principle that yields a variational integrator. Extensive simulations are carried out to calculate the computational complexity of the discrete integrator and compare the results for CPU time and accuracy to those of the ODE solver. It is shown that the variational integrator has a significant advantage in terms of preservation of the orthogonality of the wing’s attitude matrix and reduction of the CPU time. The descriptions of the implemented aerodynamic models and controllers, along with the results for the simulation of a tethered-wing system operating in a turbulent wind environment are also presented.},
  archive      = {J_JOCS},
  author       = {M. Kakavand and A. Nikoobin},
  doi          = {10.1016/j.jocs.2021.101351},
  journal      = {Journal of Computational Science},
  pages        = {101351},
  shortjournal = {J. Comput. Sci.},
  title        = {Numerical simulation of tethered–wing power systems based on variational integration},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effects of the number of channels and gyroscopic data on
the classification performance in EMG data acquired by myo armband.
<em>JOCS</em>, <em>51</em>, 101348. (<a
href="https://doi.org/10.1016/j.jocs.2021.101348">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Processing and classification of Electromyography (EMG) signals is a common practice in prosthetic arm design for hand amputees. This study investigates how reliable classification results may be obtained from less muscle data, as is the case for the muscle loss in hand amputees. In order to increase classification performance, features from gyroscopic data, not previously used in studies in the literature, were investigated. Data was acquired from 10 normal subjects using the Myo armband for 7 hand gestures: fist, fingers spread, wave-in, wave-out, pronation, supination, and rest. Subjects repeated each gesture 30 times. EMG signals were preprocessed to extract features. Twenty (20) features were used in the feature matrix; 14 time domain and 6 frequency domain. Features were selected to determine the highest accuracy using the Support Vector Machine (SVM) and k-Nearest Neighbor (KNN) as classification algorithm. The Classification Learner application in Matlab® was used for classification. The highest accuracy using all EMG channels was 98.38\%. When the number of channels was reduced to 3, the accuracy was over 90\%. It is observed that gyroscopic features increase the performance when a small number of EMG channels is used.},
  archive      = {J_JOCS},
  author       = {Cengiz Tepe and Mehmet Can Demir},
  doi          = {10.1016/j.jocs.2021.101348},
  journal      = {Journal of Computational Science},
  pages        = {101348},
  shortjournal = {J. Comput. Sci.},
  title        = {The effects of the number of channels and gyroscopic data on the classification performance in EMG data acquired by myo armband},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying prognostic markers for multiple myeloma through
integration and analysis of MMRF-CoMMpass data. <em>JOCS</em>,
<em>51</em>, 101346. (<a
href="https://doi.org/10.1016/j.jocs.2021.101346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple myeloma (MM) is the second most frequent haematological malignancy in the world although the related pathogenesis remains unclear. The study of how gene expression profiling (GEP) is correlated with patients’ survival could be important for understanding the initiation and progression of MM. In order to aid researchers in identifying new prognostic RNA biomarkers as targets for functional cell-based studies, the use of appropriate bioinformatic tools for integrative analysis is required. In this context, TCGABiolinks package represents a valid tool for integrative analysis of MM data if its functions are properly adapted for handling MMRF data. This paper aims to extend largely our previous work [1] in which we introduced some bridging functions to make TCGABiolinks package able to deal with Multiple Myeloma Research Foundation (MMRF) CoMMpass study data available at the NCI&#39;s Genomic Data Commons (GDC) Data Portal. Here we present an integrative analysis workflow based on the usage of a novel R-package, called MMRFBiolinks, that collects the set of the previously mentioned bridging functions besides of extending them. Our workflow leads towards a comparative analysis of MMRF data stored at GDC Data Portal that allows to carry out a Kaplan Meier (KM) Survival Analysis and an enrichment analysis for a differential gene expression (DGE) gene set. Furthermore, it leads towards an integrative analysis of MMRF Research Gateway (MMRF-RG) data. In order to show the potential of our workflow, we present two case studies. The former deals with RNA-Seq data of MM Bone Marrow sample types available at GDC Data Portal. The latter deals with MMRF-RG data for analyzing the correlation between canonical variants in a gene set obtained from the case study 1 and the treatment outcome as well as the treatment class.},
  archive      = {J_JOCS},
  author       = {Marzia Settino and Mariamena Arbitrio and Francesca Scionti and Daniele Caracciolo and Giuseppe Agapito and Pierfrancesco Tassone and Pierosandro Tagliaferri and Maria Teresa Di Martino and Mario Cannataro},
  doi          = {10.1016/j.jocs.2021.101346},
  journal      = {Journal of Computational Science},
  pages        = {101346},
  shortjournal = {J. Comput. Sci.},
  title        = {Identifying prognostic markers for multiple myeloma through integration and analysis of MMRF-CoMMpass data},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parametric integral equation system (PIES) for solving
problems with inclusions and non-homogeneous domains using bézier
surfaces. <em>JOCS</em>, <em>51</em>, 101343. (<a
href="https://doi.org/10.1016/j.jocs.2021.101343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper presents the approach for solving 2D elastic boundary value problems defined in domains with inclusions with different material properties using the parametric integral equation system (PIES). The main feature of the proposed strategy is using Bézier surfaces for global modeling of inclusions. Polygonal inclusions are defined by bilinear surfaces, while others by bicubic surfaces. It is beneficial over other numerical methods (such as FEM and BEM) due to the lack of discretization . Integration over inclusions defined by surfaces is also performed globally without division into subareas. The considered problem is solved iteratively in order to simulate different material properties by applying initial stresses within the inclusion. This way of solving avoids increasing the number of unknowns and can also be used for elasto-plastic problems without significant changes. Some numerical tests are presented, in which the results obtained are compared with those calculated by other numerical methods. This paper is an extended version of author&#39;s conference paper [1] . It has been enriched with, among others, the description of modeling more complex inclusions, as well as additional results obtained by PIES compared to other numerical methods.},
  archive      = {J_JOCS},
  author       = {Agnieszka Bołtuć and Eugeniusz Zieniuk},
  doi          = {10.1016/j.jocs.2021.101343},
  journal      = {Journal of Computational Science},
  pages        = {101343},
  shortjournal = {J. Comput. Sci.},
  title        = {Parametric integral equation system (PIES) for solving problems with inclusions and non-homogeneous domains using bézier surfaces},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wavelet collocation method based on legendre polynomials and
its application in solving the stochastic fractional
integro-differential equations. <em>JOCS</em>, <em>51</em>, 101342. (<a
href="https://doi.org/10.1016/j.jocs.2021.101342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work is an extended version of the ICCS 2020 conference paper [1] . The paper aims to present an efficient numerical method to quantify the uncertainty in the solution of stochastic fractional integro-differential equations. The numerical method presented here is a wavelet collocation method based on Legendre polynomials , and their deterministic and stochastic operational matrix of integration. The operational matrices are used to convert the stochastic fractional integro-differential equation to a linear system of algebraic equations. The accuracy and efficiency of the proposed method are validated through numerical experiments. Moreover, the results are compared with the numerical methods based on the Gaussian radial basis function (GA RBF) and thin plate splines radial basis function (TBS RBF) to show the superiority of the proposed method. Finally, concerning the real-world application, a stock market model has been simulated and the results are demonstrated.},
  archive      = {J_JOCS},
  author       = {Abhishek Kumar Singh and Mani Mehra},
  doi          = {10.1016/j.jocs.2021.101342},
  journal      = {Journal of Computational Science},
  pages        = {101342},
  shortjournal = {J. Comput. Sci.},
  title        = {Wavelet collocation method based on legendre polynomials and its application in solving the stochastic fractional integro-differential equations},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reconstruction of the local volatility function using the
black–scholes model. <em>JOCS</em>, <em>51</em>, 101341. (<a
href="https://doi.org/10.1016/j.jocs.2021.101341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a robust and accurate numerical algorithm to reconstruct a local volatility function using the Black–Scholes (BS) partial differential equation (PDE). Using the BS PDE and given market data, option prices at strike prices and expiry times, a time-dependent local volatility function is computed. The proposed algorithm consists of the following steps: (1) The time-dependent volatility function is computed using a recently developed method; (2) A Monte Carlo simulation technique is used to find the effective region which has a strong influence on option prices; and we partition the effective domain into several sub-regions and define a local volatility function based on the time-dependent volatility function on the sub-regions; and (3) Finally, we calibrate the local volatility function using the fully implicit finite difference method and the conjugate gradient optimization algorithm . We demonstrate the robustness and accuracy of the proposed local volatility reconstruction algorithm using manufactured volatility surface and real market data.},
  archive      = {J_JOCS},
  author       = {Sangkwon Kim and Hyunsoo Han and Hanbyeol Jang and Darae Jeong and Chaeyoung Lee and Wonjin Lee and Junseok Kim},
  doi          = {10.1016/j.jocs.2021.101341},
  journal      = {Journal of Computational Science},
  pages        = {101341},
  shortjournal = {J. Comput. Sci.},
  title        = {Reconstruction of the local volatility function using the Black–Scholes model},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of reactive power compensation algorithm for
large-scale street lighting. <em>JOCS</em>, <em>51</em>, 101338. (<a
href="https://doi.org/10.1016/j.jocs.2021.101338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {LED-based street and road lighting installations generate reactive power, particularly when they are dynamically dimmed. It contributes to power loss and efficiency reduction of the grid. Reactive power can be compensated by installing additional dynamically connected inductors in lighting control cabinets. However such an approach significantly increases the cost of the lighting infrastructure. The goal of this paper is to propose another, low cost approach to reactive power compensation for dynamically dimmed lighting installations. It is based on connecting fixed settings inductors at lighting control cabinets. The inductors settings are calculated by the proposed algorithm for city-scale lighting systems. A synthetic benchmark example with 798 circuits and 14,019 luminaires confirms its applicability. The algorithm objective is to completely eliminate capacitive reactive power and to keep inductive reactive power within acceptable limits. It is an extended version of the ICCS 2020 paper [9] .},
  archive      = {J_JOCS},
  author       = {Sebastian Ernst and Leszek Kotulski and Tomasz Lerch and Michał Rad and Adam Sędziwy and Igor Wojnicki},
  doi          = {10.1016/j.jocs.2021.101338},
  journal      = {Journal of Computational Science},
  pages        = {101338},
  shortjournal = {J. Comput. Sci.},
  title        = {Application of reactive power compensation algorithm for large-scale street lighting},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attractive community detection in academic social network.
<em>JOCS</em>, <em>51</em>, 101331. (<a
href="https://doi.org/10.1016/j.jocs.2021.101331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Academic social network analysis has attracted significant attention. For each researcher in such a network, he/she has several research interests. We regard these researchers sharing common interests as a research community. For each community, it may be attractive or not to researchers from other communities. In this paper, we study a new and interesting problem: which is the most attractive research community in the academic social network? Here, attractive research communities are those potentially valuable and increasingly popular communities, which are different from hot communities. To address this problem, we first extract both of the internal and external features of attractive research communities. The internal feature refers to the novelty of the topic in the research community and the external feature refers to the researchers’ transition among the communities. Intuitively, a community with a novel topic attracts the researchers from other research communities can be considered as the attractive community. Based on the extracted features, we design a novel Attractive Research community Ranking (ARTRank) algorithm to rank the research communities. The core idea of this algorithm lies in two measurements for each community: a positiveness score and a negativeness score, which measure the attractiveness of a community from the in-attention aspect and the out-attention aspect, respectively. Similar to HITS, these two scores are calculated in an iterative way until convergence. Through extensive experiments, we show that our proposed algorithm significantly outperforms the state-of-the-art algorithms in terms of the recommendation intensity.},
  archive      = {J_JOCS},
  author       = {Yakun Wang and Xiaodong Han},
  doi          = {10.1016/j.jocs.2021.101331},
  journal      = {Journal of Computational Science},
  pages        = {101331},
  shortjournal = {J. Comput. Sci.},
  title        = {Attractive community detection in academic social network},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid parallel iterative sparse linear solver framework for
reservoir geomechanical and flow simulation. <em>JOCS</em>, <em>51</em>,
101330. (<a href="https://doi.org/10.1016/j.jocs.2021.101330">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We discuss new developments of a hybrid parallel iterative sparse linear solver framework focused on petroleum reservoir flow and geomechanical simulation. It runs efficiently on several platforms, from desktop workstations to clusters of multicore nodes, with or without multiple GPUs, using a two-tier hierarchical architecture for distributed matrices and vectors. Results show good parallel scalability. Comparisons with a well-established library and a proprietary commercial solver indicate that our solver is competitive with the best available tools. We present results of the solver&#39;s application to simulations of real and synthetic reservoir models of up to billions of unknowns, running on CPUs and GPUs on up to 2000 processes.},
  archive      = {J_JOCS},
  author       = {Leonardo Gasparini and José R.P. Rodrigues and Douglas A. Augusto and Luiz M. Carvalho and Cesar Conopoima and Paulo Goldfeld and Jairo Panetta and João P. Ramirez and Michael Souza and Mateus O. Figueiredo and Victor M.D.M. Leite},
  doi          = {10.1016/j.jocs.2021.101330},
  journal      = {Journal of Computational Science},
  pages        = {101330},
  shortjournal = {J. Comput. Sci.},
  title        = {Hybrid parallel iterative sparse linear solver framework for reservoir geomechanical and flow simulation},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-based inter-code load balancing method for
partitioned solvers. <em>JOCS</em>, <em>51</em>, 101329. (<a
href="https://doi.org/10.1016/j.jocs.2021.101329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the inter-code load balancing in large-scale partitioned multi-physics/multi-scale simulations. More specifically, we consider partitioned simulations running separate codes for different physical phenomena. An additional software is used for technical and numerical coupling. A data-based approach is introduced to address load balancing between the involved codes and improve the performance of the coupled simulations. Performance Model Normal Form (PMNF) regression is considered to find an empirical performance model for each solver. Then, an appropriate optimization problem is derived and solved to find the optimal core distribution between solvers. The optimization problem directly depends on the equation coupling type (serial or parallel). To show the effectiveness of the proposed method, we use two test cases in the context of fluid acoustics coupling. Numerical scalability and performance analysis shows that the proposed method provides significant improvements in terms of load balancing and in most cases the load imbalance is almost removed (around 1\%). In addition, due to the optimal usage of computation capacity, the new method considerably improves the scalability. We also compare the load balancing results with a solver-specific scheme and show that, even though the data-based method does not explicitly use information about mesh size, discretization type and numerical methods used by solvers, it can achieve comparable results.},
  archive      = {J_JOCS},
  author       = {Amin Totounferoush and Neda Ebrahimi Pour and Juri Schröder and Sabine Roller and Miriam Mehl},
  doi          = {10.1016/j.jocs.2021.101329},
  journal      = {Journal of Computational Science},
  pages        = {101329},
  shortjournal = {J. Comput. Sci.},
  title        = {A data-based inter-code load balancing method for partitioned solvers},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A data-driven localization method for ensemble based data
assimilation. <em>JOCS</em>, <em>51</em>, 101328. (<a
href="https://doi.org/10.1016/j.jocs.2021.101328">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a dynamic localization method for ensemble-based data assimilation via a modified Cholesky decomposition . The method exploits the information brought by ensemble members to estimate optimal radius lengths of model components. This estimation process is performed by using Bayes’ Theorem; our prior beliefs and likelihood functions are modeled via Gamma distributions: in priors, hyper-parameters are fixed based on our prior knowledge of error dynamics while to build likelihood functions, model parameters are fitted with empirical statistics from background ensembles at assimilation steps. Once the optimal radius lengths are estimated, a modified Cholesky decomposition is employed to estimate precision covariances of background error distributions. The assimilation process is then performed similarly to that of the EnKF based on a modified Cholesky decomposition (EnKF-MC). Experimental tests are performed by using the Lorenz-96 model. To compare our results, we employ an EnKF-MC implementation with different structures of background error correlations. In terms of ℓ 2 ℓ2 -norm of errors, the proposed filter implementation can outperform the EnKF-MC method for fixed radius lengths across all model components, and even more, different hyper-parameters can be tried in our filter formulation without degrading its convergence.},
  archive      = {J_JOCS},
  author       = {Elias D. Nino-Ruiz},
  doi          = {10.1016/j.jocs.2021.101328},
  journal      = {Journal of Computational Science},
  pages        = {101328},
  shortjournal = {J. Comput. Sci.},
  title        = {A data-driven localization method for ensemble based data assimilation},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High fidelity fluid-structure interaction by radial basis
functions mesh adaption of moving walls: A workflow applied to an aortic
valve. <em>JOCS</em>, <em>51</em>, 101327. (<a
href="https://doi.org/10.1016/j.jocs.2021.101327">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fluid-Structure Interaction (FSI) can be investigated by means of non-linear Finite Element Models (FEM), suitable to capture large deflections of structural parts interacting with fluids, and Computational Fluid Dynamics (CFD). High fidelity simulations are obtained using the fine spatial resolution of both the structural and fluid computational grids. A key enabler to have a proper exchange of information between the structural solver and the fluid one is the management of the interface at wetted surfaces where the grids are usually non matching. A class of applications, known also as one-way FSI problems, involves a complex movement of the walls that is known in advance as measured or as computed by FEM, and that has to be imposed at the boundaries during a transient CFD solution. Effective methods for the time marching adaption of the whole computational grid of the CFD model according to the evolving shape of its boundaries are required. A very well established approach consists of a continuum update of the mesh that is regenerated by adding and removing cells to fit the evolution of the moving walls. In this paper, starting from the work originally presented in Meshfree Methods in Computational Sciences, ICCS 2020 [1] , an innovative method based on Radial Basis Functions (RBF) mesh morphing is proposed, allowing the retention of the same mesh topology suitable for a continuum update of the shape. The proposed method is exact at a set of given key configurations and relies on shape blending time interpolation between key frames. The study of the complex motion of a Polymeric-Prosthetic Heart Valve (P-PHV) is presented using the new framework and considering as a reference the established approach based on remeshing.},
  archive      = {J_JOCS},
  author       = {Leonardo Geronzi and Emanuele Gasparotti and Katia Capellini and Ubaldo Cella and Corrado Groth and Stefano Porziani and Andrea Chiappa and Simona Celi and Marco Evangelos Biancolini},
  doi          = {10.1016/j.jocs.2021.101327},
  journal      = {Journal of Computational Science},
  pages        = {101327},
  shortjournal = {J. Comput. Sci.},
  title        = {High fidelity fluid-structure interaction by radial basis functions mesh adaption of moving walls: A workflow applied to an aortic valve},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An agent based simulation system for analyzing stress
regulation policies at the workplace. <em>JOCS</em>, <em>51</em>,
101326. (<a href="https://doi.org/10.1016/j.jocs.2021.101326">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Workplace stress has a significant impact on productivity, since keeping workers’ stress on an adequate level results a key factor for companies to increase their performance. While a high stress level may conduct to anxiety or absenteeism, a low level may also have undesirable consequences, such as lack of motivation. To identify and understand all the elements which interfere on workers’ stress results a key factor in order to improve workers’ performance. However, the complexity of human behavior increases the difficulty of recognizing the influence of these stressors and finding a way to regulate workers’ stress. This paper proposes the use of agent-based simulation techniques for addressing the challenge of analyzing workers’ behavior and stress regulation policies. The main contributions of the paper are: (i) the definition of a stress model that takes into account work and ambient conditions to calculate the stress and the productivity of workers; (ii) the implementation of this model in an agent-based simulation system, enabling the analysis of workplace stress and productivity for different stress regulation policies; (iii) the analysis of four different stress regulation policies; and (iv) the validation of the model with a sensitivity analysis and with its application to a living lab.},
  archive      = {J_JOCS},
  author       = {Sergio Muñoz and Carlos A. Iglesias},
  doi          = {10.1016/j.jocs.2021.101326},
  journal      = {Journal of Computational Science},
  pages        = {101326},
  shortjournal = {J. Comput. Sci.},
  title        = {An agent based simulation system for analyzing stress regulation policies at the workplace},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary algorithm optimizes screen design for solar
cell metallization. <em>JOCS</em>, <em>51</em>, 101325. (<a
href="https://doi.org/10.1016/j.jocs.2021.101325">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today’s PV production chain heavily relies on screen printing as the predominant metallization process because of its robust production capabilities. However, the continuous demand to further increase throughput rates while at the same time decreasing printed structure sizes is going to create fundamental challenges in the upcoming years. In order to address this problem, robust fine-line screens at competitive production costs need to be developed. Throughout this study, we present an optimization of screen architectures by utilizing an evolutionary algorithm. Individual screen architectures are defined by genes that represent industrial manufacturing parameters. Our algorithm then solves for the optimal trade-off between printability of a screen, its mechanical stability and optimal mesh tension to ensure sufficient snap-off mechanics. Further, a computational fluid dynamics simulation is performed to find the optimal thickness of the corresponding emulsion layer in respect to the underlying optimized mesh architecture. Our results predict mesh configurations with mesh counts up to MC = 1268 1/inch and wire diameters down to d =6.7 μm in order to enable fine-line printing below 10 μm.},
  archive      = {J_JOCS},
  author       = {Sebastian Tepner and Linda Ney and Marius Singler and Maximilian Pospischil and Kenji Masuri and Florian Clement},
  doi          = {10.1016/j.jocs.2021.101325},
  journal      = {Journal of Computational Science},
  pages        = {101325},
  shortjournal = {J. Comput. Sci.},
  title        = {Evolutionary algorithm optimizes screen design for solar cell metallization},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Managing non-trivial internet-of-things systems with
conversational assistants: A prototype and a feasibility experiment.
<em>JOCS</em>, <em>51</em>, 101324. (<a
href="https://doi.org/10.1016/j.jocs.2021.101324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet-of-Things has reshaped the way people interact with their surroundings and automatize the once manual actions. In a smart home, controlling the Internet-connected lights is as simple as speaking to a nearby conversational assistant. However, specifying interaction rules, such as making the lamp turn on at specific times or when someone enters the space is not a straightforward task. The complexity of doing such increases as the number and variety of devices increases, along with the number of household members. Thus, managing such systems becomes a problem, including finding out why something has happened. This issue lead to the birth of several low-code development solutions that allow users to define rules to their systems, at the cost of discarding the easiness and accessibility of voice interaction. In this paper we extend the previous published work on Jarvis [1] , a conversational interface to manage IoT systems that attempts to address these issues by allowing users to specify time-based rules, use contextual awareness for more natural interactions, provide event management and support causality queries. A proof-of-concept is presented, detailing its architecture and natural language processing capabilities. A feasibility experiment was carried with mostly non-technical participants, providing evidence that Jarvis is intuitive enough to be used by common end-users, with participants showcasing an overall preference by conversational assistants over visual low-code solutions.},
  archive      = {J_JOCS},
  author       = {André Sousa Lago and João Pedro Dias and Hugo Sereno Ferreira},
  doi          = {10.1016/j.jocs.2021.101324},
  journal      = {Journal of Computational Science},
  pages        = {101324},
  shortjournal = {J. Comput. Sci.},
  title        = {Managing non-trivial internet-of-things systems with conversational assistants: A prototype and a feasibility experiment},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast data assimilation (FDA): Data assimilation by machine
learning for faster optimize model state. <em>JOCS</em>, <em>51</em>,
101323. (<a href="https://doi.org/10.1016/j.jocs.2021.101323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data assimilation (DA) can provide the more accurate initial state for numerical forecasting models. But traditional DA algorithms has the problem of long calculation time. This paper proposes fast data assimilation (FDA) based on machine learning . For training model, FDA uses 4DVAR, iForest, MLP , and also includes a modified model that does not require observations. This paper applies FDA in the Lorenz63 dynamical system . The experimental results show that the single analysis time of FDA is almost 524 times faster than 4DVAR. FDA greatly reduces the time of the DA process.},
  archive      = {J_JOCS},
  author       = {Pin Wu and Xuting Chang and Wenyan Yuan and Junwu Sun and Wenjie Zhang and Rossella Arcucci and Yike Guo},
  doi          = {10.1016/j.jocs.2021.101323},
  journal      = {Journal of Computational Science},
  pages        = {101323},
  shortjournal = {J. Comput. Sci.},
  title        = {Fast data assimilation (FDA): Data assimilation by machine learning for faster optimize model state},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lattice boltzmann method for relativistic rarefied flows
in (2+1) dimensions. <em>JOCS</em>, <em>51</em>, 101320. (<a
href="https://doi.org/10.1016/j.jocs.2021.101320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an extension to recently developed Relativistic Lattice Boltzmann solvers (RLBM), which allows the simulation of flows close to the free streaming limit. Following previous works Ambruş and Blaga (2018), we use product quadrature rules and select weights and nodes by separately discretizing the radial and the angular components. This procedure facilitates the development of quadrature-based RLBM with increased isotropy levels, thus improving the accuracy of the method for the simulation of flows beyond the hydrodynamic regime. In order to quantify the improvement of this discretization procedure over existing methods, we perform numerical tests of shock waves in one and two spatial dimensions in various kinetic regimes across the hydrodynamic and the free-streaming limits.},
  archive      = {J_JOCS},
  author       = {L. Bazzanini and A. Gabbana and D. Simeoni and S. Succi and R. Tripiccione},
  doi          = {10.1016/j.jocs.2021.101320},
  journal      = {Journal of Computational Science},
  pages        = {101320},
  shortjournal = {J. Comput. Sci.},
  title        = {A lattice boltzmann method for relativistic rarefied flows in (2+1) dimensions},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal allocation of energy storage system and its benefit
analysis for unbalanced distribution network with wind generation.
<em>JOCS</em>, <em>51</em>, 101319. (<a
href="https://doi.org/10.1016/j.jocs.2021.101319">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Battery energy storage system (BESS) can play a major role to overcome the challenges with renewable energy sources, especially in the context of Smart Grid (SG). In this manuscript, BESS optimal location and capacitance of wind power penetrations, and charging/discharging dispatches of BESS are determined using inherited competitive swarm optimization (ICSO) algorithm while improving the performance of the unbalanced distribution network subject to technical constraints. This approach utilizes the average feeder load from decisive criterion for charging or discharging battery. The wind turbine generator (WTG) charging and sustainable average load (SAL) charging methods for BESS are compared considering conservative mode of discharging. The proposed methodology is investigated on IEEE 37 bus unbalanced radial distribution system. The application outcomes displays that proposed methodology enhances various performance objectives of distribution system by optimally coordinating the dispatches of BESS.},
  archive      = {J_JOCS},
  author       = {Manas Ranjan Nayak and Diptimayee Behura and Kumari Kasturi},
  doi          = {10.1016/j.jocs.2021.101319},
  journal      = {Journal of Computational Science},
  pages        = {101319},
  shortjournal = {J. Comput. Sci.},
  title        = {Optimal allocation of energy storage system and its benefit analysis for unbalanced distribution network with wind generation},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive ensemble optimal interpolation for efficient data
assimilation in the red sea. <em>JOCS</em>, <em>51</em>, 101317. (<a
href="https://doi.org/10.1016/j.jocs.2021.101317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble optimal interpolation (EnOI) is a variant of the ensemble Kalman filter (EnKF) that operates with a static ensemble to drastically reduce its computational cost. The idea is to use a pre-selected ensemble to parameterize the background covariance matrix , which avoids the costly integration of the ensemble members with the dynamical model during the forecast step of the filtering process. To better represent the pronounced time-varying circulation of the Red Sea, we propose a new adaptive EnOI approach in which the ensemble members are adaptively selected at every assimilation cycle from a large dictionary of ocean states describing the Red Sea variability. We implement and test different schemes to select the ensemble members (i) based on the similarity to the forecast state according to some criteria, or (ii) in term of best representation of the forecast in an ensemble subspace using an Orthogonal Matching Pursuit (OMP) algorithm. The relevance of the schemes is first demonstrated with the Lorenz 63 and Lorenz 96 models. Then results of numerical experiments assimilating real remote sensing data into a high resolution MIT general circulation model (MITgcm) of the Red Sea using the Data Assimilation Research Testbed (DART) system are presented and discussed.},
  archive      = {J_JOCS},
  author       = {Habib Toye and Peng Zhan and Furrukh Sana and Sivareddy Sanikommu and Naila Raboudi and Ibrahim Hoteit},
  doi          = {10.1016/j.jocs.2021.101317},
  journal      = {Journal of Computational Science},
  pages        = {101317},
  shortjournal = {J. Comput. Sci.},
  title        = {Adaptive ensemble optimal interpolation for efficient data assimilation in the red sea},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization method for linear constraint problems.
<em>JOCS</em>, <em>51</em>, 101315. (<a
href="https://doi.org/10.1016/j.jocs.2021.101315">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are various optimization problems that involve different constraints. In this study, we propose an optimization method, called the error feedback method (EFM), for linear constraint problems. This method is used to calculate the errors that violate the constraints and then allocates the errors in proportion to each parameter, such that the new offspring satisfies the constraints. EFM has the advantages of saving computing resources and converging faster than the penalty function method . To verify the performance of the EFM, we use a typical benchmark function and three engineering models as examples. The models include a complex linear inequality constraint , a Markov prediction model with linear equality constraints, and two mathematical planar four-bar linkage models with inequality constraints. To optimize each model, we select three popular algorithms, namely, particle swarm optimization , teaching-learning-based optimization, and differential evolution algorithm . We compare the EFM with the penalty function method and other methods for handling linear constraint problems. The experimental results show that the EFM has significantly better stability and faster convergence than the compared methods.},
  archive      = {J_JOCS},
  author       = {Kai Zhang and Jiahao Zhu and Yimin Zhang and Qiujun Huang},
  doi          = {10.1016/j.jocs.2021.101315},
  journal      = {Journal of Computational Science},
  pages        = {101315},
  shortjournal = {J. Comput. Sci.},
  title        = {Optimization method for linear constraint problems},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hellinger distance weighted ensemble for imbalanced data
stream classification. <em>JOCS</em>, <em>51</em>, 101314. (<a
href="https://doi.org/10.1016/j.jocs.2021.101314">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The imbalanced data classification remains a vital problem. The key is to find such methods that classify both the minority and majority class correctly. The paper presents the classifier ensemble for classifying binary, non-stationary and imbalanced data streams where the Hellinger Distance is used to prune the ensemble. The paper includes an experimental evaluation of the method based on the conducted experiments. The first one checks the impact of the base classifier type on the quality of the classification. In the second experiment, the Hellinger Distance Weighted Ensemble ( HDWE ) method is compared to selected state-of-the-art methods using a statistical test with two base classifiers. The method was profoundly tested based on many imbalanced data streams and obtained results proved the HDWE method&#39;s usefulness.},
  archive      = {J_JOCS},
  author       = {Joanna Grzyb and Jakub Klikowski and Michał Woźniak},
  doi          = {10.1016/j.jocs.2021.101314},
  journal      = {Journal of Computational Science},
  pages        = {101314},
  shortjournal = {J. Comput. Sci.},
  title        = {Hellinger distance weighted ensemble for imbalanced data stream classification},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation of atmospheric cosmic-rays and their impacts
based on pre-calculated databases, physical models and computational
methods. <em>JOCS</em>, <em>51</em>, 101307. (<a
href="https://doi.org/10.1016/j.jocs.2021.101307">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The atmospheric cosmic-ray environment is composed of secondary particles produced when primary cosmic rays interact with the nucleus of atmospheric atoms. Modeling of atmospheric radiations is essential for investigating their impacts on human activities such as radiation risks in aviation or scientific fields such as cosmogenic dating. The nuclear transport codes are a common and accurate way to model the cosmic ray interaction in the atmosphere with minimal approximations . However, tracking all produced secondary particles in each event in the whole depth of the atmosphere and sampling many events to obtain the statistically meaningful results would be a computational challenge and disadvantageous from the point of view of time consumption. This paper presents a computational platform names ATMOS CORE based on pre-calculated databases coupled to physical models and computational methods. The fields of application concern the atmospheric cosmic-rays characterization as well as their effects on electronics systems, on the ambient dose for aircrews or the cosmogenic nuclide production for dating activities. Some comparisons between simulations and measurements are also presented and discussed.},
  archive      = {J_JOCS},
  author       = {G. Hubert and S. Aubry},
  doi          = {10.1016/j.jocs.2021.101307},
  journal      = {Journal of Computational Science},
  pages        = {101307},
  shortjournal = {J. Comput. Sci.},
  title        = {Simulation of atmospheric cosmic-rays and their impacts based on pre-calculated databases, physical models and computational methods},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Understanding mobility in rome by means of a multiplex
network with data. <em>JOCS</em>, <em>51</em>, 101305. (<a
href="https://doi.org/10.1016/j.jocs.2021.101305">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex networks provide a framework for modelling real-world systems. Based on a set of data on mobility by car between different urban areas of the city of Rome, we represent and analyze these mobility data coupled with urban public transport networks, augmenting the network nodes with data on commercial, economic, service and tourist activity in the city. In order to unravel the complex interdependencies of all these data, we propose a multiplex network consisting of four layers in which the nodes are defined by an urban grid subdividing the city into 1 × 1 1×1 km cells. Network centrality measures are then used to determine the most influential nodes or prominent areas of the city. In particular, we propose an adaptation of the APA centrality algorithm for multiplex networks. This adaptation of the algorithm for multiplex networks offers the possibility to assign the importance given to node data relative to the network topology in each layer when computing the centrality. This allows a wider control in studying the mobility network, particularly generating different centrality maps according to the choice of this control parameter in each layer. We carry out experiments and present the results of a study of the network centralities considering different choices of the parameter.},
  archive      = {J_JOCS},
  author       = {Manuel Curado and Leandro Tortosa and Jose F. Vicent and Gevorg Yeghikyan},
  doi          = {10.1016/j.jocs.2021.101305},
  journal      = {Journal of Computational Science},
  pages        = {101305},
  shortjournal = {J. Comput. Sci.},
  title        = {Understanding mobility in rome by means of a multiplex network with data},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coupling parallel asynchronous multisplitting methods with
krylov methods to solve pseudo-linear evolution 3D problems.
<em>JOCS</em>, <em>51</em>, 101303. (<a
href="https://doi.org/10.1016/j.jocs.2021.101303">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study deals with pseudo-linear problems solving using parallel asynchronous multisplitting methods combined with Krylov methods. With appropriate and realistic assumptions, the behavior of such parallel iterative algorithms will be analyzed by partial ordering techniques in relation with the discrete maximum principle. Applications to discretized boundary value problems are presented, the implementation of the algorithms is described and parallel experiments are analyzed.},
  archive      = {J_JOCS},
  author       = {T. Garcia and P. Spiteri and L. Ziane-Khodja and R. Couturier},
  doi          = {10.1016/j.jocs.2021.101303},
  journal      = {Journal of Computational Science},
  pages        = {101303},
  shortjournal = {J. Comput. Sci.},
  title        = {Coupling parallel asynchronous multisplitting methods with krylov methods to solve pseudo-linear evolution 3D problems},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A distributed chunk calculation approach for self-scheduling
of parallel applications on distributed-memory systems. <em>JOCS</em>,
<em>51</em>, 101284. (<a
href="https://doi.org/10.1016/j.jocs.2020.101284">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Loop scheduling techniques aim to achieve load-balanced executions of scientific applications. Dynamic loop self-scheduling (DLS) libraries for distributed-memory systems are typically MPI-based and employ a centralized chunk calculation approach (CCA) to assign variably-sized chunks of loop iterations. We present a distributed chunk calculation approach (DCA) that supports various types of DLS techniques. Using both CCA and DCA, twelve DLS techniques are implemented and evaluated in different CPU slowdown scenarios. The results show that the DLS techniques implemented using DCA outperform their corresponding ones implemented with CCA, especially in extreme system slowdown scenarios.},
  archive      = {J_JOCS},
  author       = {Ahmed Eleliemy and Florina M. Ciorba},
  doi          = {10.1016/j.jocs.2020.101284},
  journal      = {Journal of Computational Science},
  pages        = {101284},
  shortjournal = {J. Comput. Sci.},
  title        = {A distributed chunk calculation approach for self-scheduling of parallel applications on distributed-memory systems},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering of graphs using pseudo-guided random walk.
<em>JOCS</em>, <em>51</em>, 101281. (<a
href="https://doi.org/10.1016/j.jocs.2020.101281">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an unsupervised learning task that models data as coherent groups. Multiple approaches have been proposed in the past to cluster large volumes of data. Graphs provide a logical mapping of many real-world datasets rich enough to reflect various peculiarities of numerous domains. Apart from k -means, k -medoid, and other well-known clustering algorithms, utilization of random walk-based approaches to cluster data is a prominent area of data mining research. Markov clustering algorithm and limited random walk-based clustering are the prominent techniques that utilize the concept of random walk. The main goal of this work is to address the task of clustering graphs using an efficient random walk-based method. A novel walk approach in a graph is presented here that determines the weight of the edges and the degree of the nodes. This information is utilized by the pseudo-guidance model to guide the random walk procedure. This work introduces the friends-of-friends concept during the random walk process so that the edges’ weights are determined utilizing an inclusive criterion. This concept enables a random walk to be initiated from the highest degree node. The random walk continues until the walking agent cannot find any unvisited neighbor(s). The agent walks to its neighbors if it finds a weight of one or more, otherwise the agent’s stopping criteria is met. The nodes visited in this walk form a cluster. Once a walk comes to halt, the visited nodes are removed from the original graph and the next walk starts in the remaining graph. This process continues until all nodes of the graph are traversed. The focus of this work remains random walk-based clustering of graphs. The proposed approach is evaluated using 18 real-world benchmark datasets utilizing six cluster validity indices, namely Davies-Bouldin index (DBI), Dunn index (DI), Silhouette coefficient (SC), Calinski-Harabasz index (CHI), modularity index, and normalized cut. This proposal is compared with seven closely related approaches from the same domain, namely, limited random walk, pairwise clustering, personalized page rank clustering, GAKH (genetic algorithm krill herd) graph clustering, mixing time of random walks, density-based clustering of large probabilistic graphs, and Walktrap . Experiments suggest better performance of this work based on the evaluation metrics.},
  archive      = {J_JOCS},
  author       = {Zahid Halim and Hussain Mahmood Sargana and Aadam and Uzma and Muhammad Waqas},
  doi          = {10.1016/j.jocs.2020.101281},
  journal      = {Journal of Computational Science},
  pages        = {101281},
  shortjournal = {J. Comput. Sci.},
  title        = {Clustering of graphs using pseudo-guided random walk},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Electronic structure of the SrH+ and BaH+ molecules with
dipole moment and rovibrational calculations. <em>JOCS</em>,
<em>51</em>, 101264. (<a
href="https://doi.org/10.1016/j.jocs.2020.101264">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The alkaline-earth metal hydrides and their corresponding ions are heteronuclear molecules that are essential in many fields especially in astrophysics and spectroscopy such as sunspots, stars, nebulae, the interstellar medium and chemical engineering. They are important systems in spectroscopy due to their visible bands which emerge in the absorption spectrum of sun. Due to the importance of hydride species and the lack of theoretical studies on some astronomical diatomic molecules is a main reason to investigate their electronic structure. The adiabatic potential energy curves and the static dipole moment curves of the low-lying electronic states of strontium hydride cation SrH + and barium hydride cation BaH + have been investigated using ab initio CASSCF/(MRCI + Q) calculations. The spectroscopic parameters T e , R e , ω e , B e , the dipole moment μ e , and the dissociation energy D e were calculated for the bound states. Using the canonical function approach, the rovibrational constants E v , B v , D v and the turning points R min and R max for the ground and several excited states have been determined.},
  archive      = {J_JOCS},
  author       = {Nariman Abu el kher and Israa Zeid and Nayla El-Kork and Mahmoud Korek},
  doi          = {10.1016/j.jocs.2020.101264},
  journal      = {Journal of Computational Science},
  pages        = {101264},
  shortjournal = {J. Comput. Sci.},
  title        = {Electronic structure of the SrH+ and BaH+ molecules with dipole moment and rovibrational calculations},
  volume       = {51},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DGIRM: Discontinuous galerkin based isogeometric residual
minimization for the stokes problem. <em>JOCS</em>, <em>50</em>, 101306.
(<a href="https://doi.org/10.1016/j.jocs.2021.101306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we introduce a stable isogeometric analysis discretization of the Stokes system of equations. We use this standard constrained problem to demonstrate the flexibility and robustness of the residual minimization method on dual stable norms [16] , which unlocks the extraordinary approximation power of isogeometric analysis [44] . That is, we introduce an isogeometric residual minimization method (IRM) for the Stokes equations, which minimizes the residual in a dual discontinuous Galerkin norm; thus we use the acronym DGiRM. Following Calo et al. [16] , we start from an inf-sup stable discontinuous Galerkin (DG) formulation to approximate in a highly continuous trial space that minimizes the dual norm of the residual in a discontinuous test space. We demonstrate the performance and robustness of the methodology considering a manufactured solution and the well-known lid-driven cavity flow problem. First, we use a multi-frontal direct solver, and, using the Pareto front, compare the resulting numerical accuracy and the computational cost expressed by the number of floating-point operations performed by the direct solver algorithm. Second, we use an iterative solver. We measure the number of iterations required when increasing the mesh size and how the configuration of spaces affect the resulting accuracy. This paper is an extension of the paper A Stable Discontinuous Galerkin Based Isogeometric Residual Minimization for the Stokes Problem by M. Łoś, et al. (2020) published in Lecture Notes in Computer Science. In this extended version, we deepen in the mathematical aspects of the DGiRM, include the iterative solver algorithm and implementation, and discuss the influence of different discretization spaces on the iterative solver&#39;s convergence.},
  archive      = {J_JOCS},
  author       = {Marcin Łoś and Sergio Rojas and Maciej Paszyński and Ignacio Muga and Victor M. Calo},
  doi          = {10.1016/j.jocs.2021.101306},
  journal      = {Journal of Computational Science},
  pages        = {101306},
  shortjournal = {J. Comput. Sci.},
  title        = {DGIRM: Discontinuous galerkin based isogeometric residual minimization for the stokes problem},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A point interpolation algorithm resulting from weighted
linear regression. <em>JOCS</em>, <em>50</em>, 101304. (<a
href="https://doi.org/10.1016/j.jocs.2021.101304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a novel point interpolation algorithm that is derived from a simple weighted linear regression model. The resulting expression is similar to Inverse Distance Weighting (IDW), which is a widely adopted interpolation algorithm. The novel approach is compared to other methods on synthetic data and also over study cases related to solar radiation, surface elevation, well elevation, and precipitation. Relevant aspects of IDW are preserved while the novel algorithm achieves better results with statistical significance. Artifacts are alleviated in interpolated surfaces generated by the novel approach when compared to the respective surfaces from IDW. The novel method was also revealed, for some cases, as the best alternative among all methods tested in terms of root mean square error. Computational efficiency was shown as competitive or even superior to most of the alternatives under certain conditions. This work is an extended version of our previous conference paper [LNCS 12138 , 576 (2020)].},
  archive      = {J_JOCS},
  author       = {Leonardo Ramos Emmendorfer and Graçaliz Pereira Dimuro},
  doi          = {10.1016/j.jocs.2021.101304},
  journal      = {Journal of Computational Science},
  pages        = {101304},
  shortjournal = {J. Comput. Sci.},
  title        = {A point interpolation algorithm resulting from weighted linear regression},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Voronoi diagram and monte-carlo simulation based finite
element optimization for cost-effective 3D printing. <em>JOCS</em>,
<em>50</em>, 101301. (<a
href="https://doi.org/10.1016/j.jocs.2021.101301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By extending the work published at ICCS 2020 [ 1 ], in this paper we propose a method to achieve cost-effective 3D printing of stiffened thin-shell objects. Our proposed method consists of three parts. The first part integrates finite element analysis, Voronoi diagram, and conformal mapping to obtain stiffener distribution. The second part combines finite element analysis with optimization calculations to determine the optimal sizes of stiffeners. And the third part introduces Monte-Carlo simulation to find a global optimum. The experiments made in this paper indicate that our proposed method is effective in minimizing 3D printing material consumption of stiffened thin-shell objects.},
  archive      = {J_JOCS},
  author       = {A.Z. Zheng and S.J. Bian and E. Chaudhry and J. Chang and H. Haron and L.H. You and J.J. Zhang},
  doi          = {10.1016/j.jocs.2021.101301},
  journal      = {Journal of Computational Science},
  pages        = {101301},
  shortjournal = {J. Comput. Sci.},
  title        = {Voronoi diagram and monte-carlo simulation based finite element optimization for cost-effective 3D printing},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An advanced ALE-mixed finite element method for a
cardiovascular fluid–structure interaction problem with multiple moving
interfaces. <em>JOCS</em>, <em>50</em>, 101300. (<a
href="https://doi.org/10.1016/j.jocs.2021.101300">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An advanced arbitrary Lagrangian–Eulerian (ALE) mixed finite element method (FEM) is developed for a cardiovascular fluid–structure interaction (FSI) problem with multiple moving interfaces arising from cardiovascular diseases (CVDs), where the aneurysm on the artery wall and the implanted stent graft are involved as multi-structural domains, interacting with the blood fluid in different regions through multiple moving interfaces. A monolithic, fully discrete ALE-mixed finite element method is well developed to solve the moving multi-interface problem in the cardiovascular environment, where the blood fluid region is divided into two subregions by two structural domains: the artery wall and the stent graft, inducing three moving interfaces amongst them that are interacting with each other due to the motion of the blood fluid. Consequently, a FSI-induced saddle-point linear algebraic system from the developed ALE-FEM, in which velocity variables of both the fluid and the structure are combined, together with the fluid pressure variable, is thus formed and solved by some well developed preconditioned linear solvers. Numerical experiments are carried out for a modified FSI benchmark problem and two realistic cardiovascular problems to demonstrate the effectiveness and the strength of the developed monolithic ALE-mixed finite element method. This paper is a significant extension version of the authors’ conference paper (Sun et al., 2020) [1] .},
  archive      = {J_JOCS},
  author       = {Pengtao Sun and Chen-Song Zhang and Rihui Lan and Lin Li},
  doi          = {10.1016/j.jocs.2021.101300},
  journal      = {Journal of Computational Science},
  pages        = {101300},
  shortjournal = {J. Comput. Sci.},
  title        = {An advanced ALE-mixed finite element method for a cardiovascular fluid–structure interaction problem with multiple moving interfaces},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Massively-parallel column-level segmentation of depth
images. <em>JOCS</em>, <em>50</em>, 101298. (<a
href="https://doi.org/10.1016/j.jocs.2021.101298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Column-level segmentation of depth images is an energy-efficient strategy to perform 3D perception in autonomous-driving systems. These systems must perform 3D perception in real time through a pipeline of multiple tasks, which benefits from proposals that prioritize low complexity and short execution time over high levels of accuracy. For many years, column-level segmentation of depth images has been solved with the Stixels proposal, which uses an optimization algorithm with O ( n 2 ) O(n2) computational complexity . This manuscript is an extended version of the ICCS paper “GPU-accelerated RDP Algorithm for Data Segmentation” (Cebrian and Moure, 2020). We present an alternative column-level segmentation proposal based on the RDP split-and-merge strategy, which has O ( n ⋅ l o g n ) O(n⋅logn) computational complexity. The qualitative results obtained with the KITTI and Synthia image datasets evidence that our proposal can generate depth representations with greater compression and accuracy than the Stixels proposal. More importantly, we engineered a massively parallel design optimized for the low-power, GPU-accelerated embedded systems typically used for autonomous driving applications. For the datasets above, our proposal runs on a low-power NVIDIA Volta GPU 22 to 68 times faster than Stixels GPU-accelerated code. Additionally, our code achieves higher performance speedups as the computational capabilities and size of depth images increase.},
  archive      = {J_JOCS},
  author       = {P. Cebrian and J.C. Moure},
  doi          = {10.1016/j.jocs.2021.101298},
  journal      = {Journal of Computational Science},
  pages        = {101298},
  shortjournal = {J. Comput. Sci.},
  title        = {Massively-parallel column-level segmentation of depth images},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AutoPas in ls1 mardyn: Massively parallel particle
simulations with node-level auto-tuning. <em>JOCS</em>, <em>50</em>,
101296. (<a href="https://doi.org/10.1016/j.jocs.2020.101296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to computational cost, simulation software is confronted with the need to always use optimal building blocks — data structures, solver algorithms, parallelization schemes, and so forth — in terms of efficiency, while it typically needs to support a variety of hardware architectures. AutoPas implements the computationally most expensive molecular dynamics (MD) steps (e.g., force calculation) and chooses on-the-fly, i.e., at run time, the optimal combination of the previously mentioned building blocks. We detail decisions made in AutoPas to enable the interplay with MPI-parallel simulations and, to our knowledge, showcase the first MPI-parallel MD simulations that use dynamic tuning. We discuss the benefits of this approach for three simulation scenarios from process engineering, in which we obtain performance improvements of up to 50\%, compared to the baseline performance of the highly optimized ls1 mardyn software.},
  archive      = {J_JOCS},
  author       = {Steffen Seckler and Fabio Gratl and Matthias Heinen and Jadran Vrabec and Hans-Joachim Bungartz and Philipp Neumann},
  doi          = {10.1016/j.jocs.2020.101296},
  journal      = {Journal of Computational Science},
  pages        = {101296},
  shortjournal = {J. Comput. Sci.},
  title        = {AutoPas in ls1 mardyn: Massively parallel particle simulations with node-level auto-tuning},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning based algorithms for uncertainty
quantification in numerical weather prediction models. <em>JOCS</em>,
<em>50</em>, 101295. (<a
href="https://doi.org/10.1016/j.jocs.2020.101295">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complex numerical weather prediction models incorporate a variety of physical processes, each described by multiple alternative physical schemes with specific parameters. The selection of the physical schemes and the choice of the corresponding physical parameters during model configuration can significantly impact the accuracy of model forecasts. There is no combination of physical schemes that works best for all times, at all locations, and under all conditions. It is therefore of considerable interest to understand the interplay between the choice of physics and the accuracy of the resulting forecasts under different conditions. This paper demonstrates the use of machine learning techniques to study the uncertainty in numerical weather prediction models due to the interaction of multiple physical processes. The first problem addressed herein is the estimation of systematic model errors in output quantities of interest at future times, and the use of this information to improve the model forecasts. The second problem considered is the identification of those specific physical processes that contribute most to the forecast uncertainty in the quantity of interest under specified meteorological conditions. In order to address these questions we employ two machine learning approaches, random forests and artificial neural networks. The discrepancies between model results and observations at past times are used to learn the relationships between the choice of physical processes and the resulting forecast errors. Numerical experiments are carried out with the Weather Research and Forecasting (WRF) model. The output quantity of interest is the model precipitation, a variable that is both extremely important and very challenging to forecast. The physical processes under consideration include various micro-physics schemes, cumulus parameterizations, short wave, and long wave radiation schemes. The experiments demonstrate the strong potential of machine learning approaches to aid the study of model errors.},
  archive      = {J_JOCS},
  author       = {Azam Moosavi and Vishwas Rao and Adrian Sandu},
  doi          = {10.1016/j.jocs.2020.101295},
  journal      = {Journal of Computational Science},
  pages        = {101295},
  shortjournal = {J. Comput. Sci.},
  title        = {Machine learning based algorithms for uncertainty quantification in numerical weather prediction models},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extending bluff-and-fix estimates for polynomial chaos
expansions. <em>JOCS</em>, <em>50</em>, 101287. (<a
href="https://doi.org/10.1016/j.jocs.2020.101287">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Polynomial chaos methods, which are part of a broader class known as stochastic Galerkin schemes , can be used to approximate the solution to a PDE with uncertainties represented by stochastic inputs or parameters. The stochastic solution is expressed as an infinite polynomial expansion truncated to M + 1 M+1 terms. The approach is then to derive a resulting system of coupled, deterministic PDEs and solve this system with standard numerical techniques . Some challenges with conventional numeric techniques applied in this context are as follows: (1) the solution to a polynomial chaos M M system cannot easily reuse an already existing computer solution to an M 0 M0 system for some M 0 M0&amp;lt;M, and (2) there is no flexibility around choosing which variables in an M M system are more important or advantageous to estimate accurately. This latter point is especially relevant when, rather than focusing on the PDE solution itself, the objective is to approximate some function of the PDE solution that weights the solution variables with relative levels of importance. In Lyman and Iaccarino (2020) [1] , we first present a promising iterative strategy (bluff-and-fix) to address challenge (1); we find that numerical estimates of the accuracy and efficiency demonstrate that bluff-and-fix can be more effective than using monolithic methods to solve a whole M M system directly. This paper is an extended version of Lyman and Iaccarino (2020) [1] that showcases how bluff-and-fix successfully addresses challenge (2) as well by allowing for choice in which variables are approximated more accurately, in particular when estimating statistical properties such as the mean and variance of an M M system solution.},
  archive      = {J_JOCS},
  author       = {Laura Lyman and Gianluca Iaccarino},
  doi          = {10.1016/j.jocs.2020.101287},
  journal      = {Journal of Computational Science},
  pages        = {101287},
  shortjournal = {J. Comput. Sci.},
  title        = {Extending bluff-and-fix estimates for polynomial chaos expansions},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the computational complexity of dempster’s rule of
combination, a parallel computing approach. <em>JOCS</em>, <em>50</em>,
101283. (<a href="https://doi.org/10.1016/j.jocs.2020.101283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multisensor data fusion with Dempster–Shafer (D–S) theory is beneficial for context inference without any advanced information. D–S theory includes reasoning based on Dempster’s rule of combination of degrees of belief based on different pieces of evidence. Although, the computational complexity of Dempster’s rule of combination is enormous. Any change in the number of pieces of evidence or hypotheses causes a lot of additional computations. Dempster’s rule of combination is shown to be #P-complete. The combination rule of k k frames of evidence with n k nk elements, such that ( k ∈ N | k ≥ 2 k∈N|k≥2 ) has a time complexity of O ( 2 N ) O(2N) , where N = ∑ k n k N=∑knk . In this paper, we propose a parallel computing approach for Dempster’s rule of combination based on the concept of conquer and divide algorithms . The proportion of task benefiting from improvement is p = 1 − 2 k p=1−2k , hence k 2 k2 of theoretical maximum speed-up according to Amdahl’s law. We have tested our algorithm in different experimental settings and observed that the new parallel computing approach has not only achieved the best results in CPU version, but has also outperformed GPU version using Thrust CUDA in almost scenarios of the experiment.},
  archive      = {J_JOCS},
  author       = {Mohammed Benalla and Boujemâa Achchab and Hamid Hrimech},
  doi          = {10.1016/j.jocs.2020.101283},
  journal      = {Journal of Computational Science},
  pages        = {101283},
  shortjournal = {J. Comput. Sci.},
  title        = {On the computational complexity of dempster’s rule of combination, a parallel computing approach},
  volume       = {50},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ordered-fuzzy-numbers-driven approach to the milk-run
routing and scheduling problem. <em>JOCS</em>, <em>49</em>, 101288. (<a
href="https://doi.org/10.1016/j.jocs.2020.101288">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internal logistics systems aim at supplying the right materials at the right locations at the right time. This fact creates the need for the design of logistic-train-fleet-oriented, distributed and scalability-robust control policies ensuring deadlock-free operations. This paper presents a solution to a milk-run vehicle routing and scheduling problem subject to fuzzy pick-up and delivery transportation time constraints. Since this type of problem can be treated as a fuzzy constraint satisfaction problem , an elegant solution can be determined using both computer simulation and analytical ordered-fuzzy-number-driven calculations. In contrast to standard fuzzy numbers, the support of a fuzzy number obtained by algebraic operations performed on the ordered fuzzy numbers domain does not expand. The possibility of carrying out algebraic operations is limited to selected domains of the computability of these supports. The proposed sufficient conditions implying the calculability of arithmetic operations guarantee interpretability of the results obtained. Consequently, they confirm the competitiveness of the analytical approach in relation to time-consuming computer-simulation-based calculations of logistic train fleet schedules. Finally, it is demonstrated on the basis of the results obtained in the study that the proposed approach constitutes an effective solution to the problem discussed. In this context, the proposed paper is a continuation of the authors’ recent research presented at the International Conference on Computational Science 2020.},
  archive      = {J_JOCS},
  author       = {Grzegorz Bocewicz and Zbigniew Banaszak and Katarzyna Rudnik and Czeslaw Smutnicki and Marcin Witczak and Robert Wójcik},
  doi          = {10.1016/j.jocs.2020.101288},
  journal      = {Journal of Computational Science},
  pages        = {101288},
  shortjournal = {J. Comput. Sci.},
  title        = {An ordered-fuzzy-numbers-driven approach to the milk-run routing and scheduling problem},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating linear solvers for stokes problems with c++
metaprogramming. <em>JOCS</em>, <em>49</em>, 101285. (<a
href="https://doi.org/10.1016/j.jocs.2020.101285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The efficient solution of large sparse saddle point systems is very important in computational fluid mechanics. The discontinuous Galerkin finite element methods have become increasingly popular for incompressible flow problems but their application is limited due to high computational cost. We describe C++ programming techniques that may help to accelerate linear solvers for such problems. The approach is based on the policy-based design pattern and partial template specialization, and is implemented in the open source AMGCL library. The efficiency is demonstrated with the example of accelerating an iterative solver of a discontinuous Galerkin finite element method for the Stokes problem. The implementation allows selecting algorithmic components of the solver by adjusting template parameters without any changes to the codebase. It is possible to switch the system matrix to use small statically sized blocks to store the nonzero values, or use a mixed precision solution, which results in up to 4 times speedup, and reduces the memory footprint of the algorithm by about 40\%. We evaluate both monolithic and composite preconditioning strategies for 3 benchmark problems. The performance of the proposed solution is compared with a multithreaded direct Pardiso solver and a parallel iterative PETSc solver.},
  archive      = {J_JOCS},
  author       = {Denis Demidov and Lin Mu and Bin Wang},
  doi          = {10.1016/j.jocs.2020.101285},
  journal      = {Journal of Computational Science},
  pages        = {101285},
  shortjournal = {J. Comput. Sci.},
  title        = {Accelerating linear solvers for stokes problems with c++ metaprogramming},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Communication-efficient hierarchical distributed
optimization for multi-agent policy evaluation. <em>JOCS</em>,
<em>49</em>, 101280. (<a
href="https://doi.org/10.1016/j.jocs.2020.101280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Policy evaluation problems in multi-agent reinforcement learning (MARL) have attracted growing interest recently. In this setting, agents collaborate to learn the value of a given policy with private local rewards and jointly observed state-action pairs. However, existing fully decentralized algorithms treat each agent equally, without considering the communication structure of the agents over a given network, and the corresponding effects on communication and computation efficiency. In this paper, we propose a hierarchical distributed algorithm that differentiates the roles of each of the agents during the evaluation process. This method allows us to freely choose various mixing schemes (and corresponding mixing matrices that are not necessarily symmetric or doubly stochastic), in order to reduce the communication and computation cost, while still maintaining convergence at rates as fast as or even faster than the previous distributed algorithms. Theoretically, we show the proposed method, which contains existing distributed methods as a special case, achieves the same order of convergence rate as state-of-the-art methods. Extensive numerical experiments on real datasets verify that the performance of our approach indeed improves – sometimes significantly – over other advanced algorithms in terms of convergence and total communication efficiency.},
  archive      = {J_JOCS},
  author       = {Jineng Ren and Jarvis Haupt and Zehua Guo},
  doi          = {10.1016/j.jocs.2020.101280},
  journal      = {Journal of Computational Science},
  pages        = {101280},
  shortjournal = {J. Comput. Sci.},
  title        = {Communication-efficient hierarchical distributed optimization for multi-agent policy evaluation},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing the hypre solver for manycore and GPU
architectures. <em>JOCS</em>, <em>49</em>, 101279. (<a
href="https://doi.org/10.1016/j.jocs.2020.101279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The solution of large-scale combustion problems with codes such as Uintah on modern computer architectures requires the use of multithreading and GPUs to achieve performance. Uintah uses a low-Mach number approximation that requires iteratively solving a large system of linear equations. The Hypre iterative solver has solved such systems in a scalable way for Uintah, but the use of OpenMP with Hypre leads to at least 2 × 2× slowdown due to OpenMP overheads. The proposed solution uses the MPI Endpoints within Hypre, where each team of threads acts as a different MPI rank. This approach minimizes OpenMP synchronization overhead and performs as fast or (up to 1.44 × × ) faster than Hypre&#39;s MPI-only version, and allows the rest of Uintah to be optimized using OpenMP. The profiling of the GPU version of Hypre shows the bottleneck to be the launch overhead of thousands of micro-kernels. The GPU performance was improved by fusing these micro-kernels and was further optimized by using Cuda-aware MPI, resulting in an overall speedup of 1.16—1.44 × × compared to the baseline GPU implementation. The above optimization strategies were published in the International Conference on Computational Science 2020 [1] . This work extends the previously published research by carrying out the second phase of communication-centered optimizations in Hypre to improve its scalability on large-scale supercomputers. This includes an efficient non-blocking inter-thread communication scheme, communication-reducing patch assignment, and expression of logical communication parallelism to a new version of the MPICH library that utilizes the underlying network parallelism [2] . The above optimizations avoid communication bottlenecks previously observed during strong scaling and improve performance by up to 2 × × on 256 nodes of Intel Knight&#39;s Landing processor.},
  archive      = {J_JOCS},
  author       = {Damodar Sahasrabudhe and Rohit Zambre and Aparna Chandramowlishwaran and Martin Berzins},
  doi          = {10.1016/j.jocs.2020.101279},
  journal      = {Journal of Computational Science},
  pages        = {101279},
  shortjournal = {J. Comput. Sci.},
  title        = {Optimizing the hypre solver for manycore and GPU architectures},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Crediting pull requests to open source research software as
an academic contribution. <em>JOCS</em>, <em>49</em>, 101278. (<a
href="https://doi.org/10.1016/j.jocs.2020.101278">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Like any other scientific discipline, the High Performance Computing community suffers under the publish or perish paradigm. As a result, a significant portion of novel algorithm designs and hardware-optimized implementations never make it into production code but are instead abandoned once they served the purpose of yielding (another) publication. At the same time, community software packages driving scientific research lack the addition of new technology and hardware-specific implementations. This results in a very unsatisfying situation where researchers and software developers are working independently, and the traditional peer reviewing is reaching its capacity limits. A paradigm shift that accepts high-quality software pull requests to open source research software as conference contributions may create incentives to realize new and/or improved algorithms in community software ecosystems. In this paper, we propose to complement code reviews on pull requests to scientific open source software with scientific reviews, and allow the presentation and publication of high quality software contributions that present an academic improvement to the state-of-the-art at scientific conferences.},
  archive      = {J_JOCS},
  author       = {Hartwig Anzt and Eileen Kuehn and Goran Flegar},
  doi          = {10.1016/j.jocs.2020.101278},
  journal      = {Journal of Computational Science},
  pages        = {101278},
  shortjournal = {J. Comput. Sci.},
  title        = {Crediting pull requests to open source research software as an academic contribution},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-fidelity nonlinear low-order unstructured implicit
finite-element seismic simulation of important structures by accelerated
element-by-element method. <em>JOCS</em>, <em>49</em>, 101277. (<a
href="https://doi.org/10.1016/j.jocs.2020.101277">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We enable large-scale high-fidelity finite-element seismic response simulations of important structures, that are expected to contribute towards improvement in seismic design verification, by reducing cost of the nonlinear dynamic unstructured low-order implicit finite-element method. Most of the computational cost of this method is involved in the element-by-element (EBE) method, which is a typical example of a “low computation/(data load or store)” kernel that appears in many applications that is not straightforward to attain performance on current computer systems. Therefore, special care based on computer science is required to make use of the potential of computer architecture and achieve fast analysis. In this study, we developed a kernel algorithm and implementation suitable for the target Arm v8.2-A scalable vector extension (SVE) CPU-based supercomputer Fugaku. 5.11- and 8.69-fold speedup was attained by using the developed EBE kernel in a standard preconditioned conjugate gradient solver and a state-of-the-art SC14 massively parallel solver algorithm, respectively. Furthermore, by using the developed EBE kernel in the state-of-the-art solver, a 49 billion degrees-of-freedom high-fidelity seismic response analysis can be conducted in practical speed corresponding to 60,000 time-steps in half a day using Fugaku. The obtained insights are expected to be useful for accelerating other scientific computing methods with “low computation/(data load or store)” kernels.},
  archive      = {J_JOCS},
  author       = {Kohei Fujita and Kentaro Koyama and Kazuo Minami and Hikaru Inoue and Seiya Nishizawa and Miwako Tsuji and Tatsuo Nishiki and Tsuyoshi Ichimura and Muneo Hori and Lalith Maddegedara},
  doi          = {10.1016/j.jocs.2020.101277},
  journal      = {Journal of Computational Science},
  pages        = {101277},
  shortjournal = {J. Comput. Sci.},
  title        = {High-fidelity nonlinear low-order unstructured implicit finite-element seismic simulation of important structures by accelerated element-by-element method},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DSMC investigation of rarefied gas flow in a four-sided lid
driven cavity: Effect of rarefaction and lid velocities. <em>JOCS</em>,
<em>49</em>, 101276. (<a
href="https://doi.org/10.1016/j.jocs.2020.101276">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Direct Simulation Monte Carlo (DSMC) method is used to investigate the gaseous flow of monoatomic Argon in a four-sided lid-driven cavity in all the rarefaction regimes. The influence of wall movement direction and wall velocity magnitude on flow physics is studied. The Knudsen numbers selected are 0.01, 0.1, 1, 10, 20 and the Mach numbers employed are 0.03, 0.17, 0.35, and 0.70 respectively. The analysis showed that flow and thermal properties are directly proportional to the Mach number, whereas they varied less in the free-molecular regime. The results obtained are dependent on the viscous dissipation, compression, and rarefaction effects.},
  archive      = {J_JOCS},
  author       = {Deepak Nabapure and Ram Chandra Murthy K},
  doi          = {10.1016/j.jocs.2020.101276},
  journal      = {Journal of Computational Science},
  pages        = {101276},
  shortjournal = {J. Comput. Sci.},
  title        = {DSMC investigation of rarefied gas flow in a four-sided lid driven cavity: Effect of rarefaction and lid velocities},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lbmpy: Automatic code generation for efficient parallel
lattice boltzmann methods. <em>JOCS</em>, <em>49</em>, 101269. (<a
href="https://doi.org/10.1016/j.jocs.2020.101269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lattice Boltzmann methods are a popular mesoscopic alternative to classical computational fluid dynamics based on the macroscopic equations of continuum mechanics. Many variants of lattice Boltzmann methods have been developed that vary in complexity, accuracy, and computational cost. Extensions are available to simulate multi-phase, multi-component, turbulent, and non-Newtonian flows. In this work we present lbmpy , a code generation package that supports a wide variety of different lattice Boltzmann methods. Additionally, lbmpy provides a generic development environment for new schemes. A high-level domain-specific language allows the user to formulate, extend and test various lattice Boltzmann methods. In all cases, the lattice Boltzmann method can be specified in symbolic form. Transformations that operate on this symbolic representation yield highly efficient compute kernels. This is achieved by automatically parallelizing the methods, and by various application-specific automatized steps that optimize the resulting code. This pipeline of transformations can be applied to a wide range of lattice Boltzmann variants, including single- and two-relaxation-time schemes, multi-relaxation-time methods, as well as the more advanced cumulant methods, and entropically stabilized methods. lbmpy can be integrated into high-performance computing frameworks to enable massively parallel, distributed simulations. This is demonstrated using the waLBerla multiphysics package to conduct scaling experiments on the SuperMUC-NG supercomputing system on up to 147 456 compute cores.},
  archive      = {J_JOCS},
  author       = {Martin Bauer and Harald Köstler and Ulrich Rüde},
  doi          = {10.1016/j.jocs.2020.101269},
  journal      = {Journal of Computational Science},
  pages        = {101269},
  shortjournal = {J. Comput. Sci.},
  title        = {Lbmpy: Automatic code generation for efficient parallel lattice boltzmann methods},
  volume       = {49},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fault-tolerant hybrid resource allocation model for
dynamic computational grid. <em>JOCS</em>, <em>48</em>, 101268. (<a
href="https://doi.org/10.1016/j.jocs.2020.101268">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effectual allocation of resources with fault tolerance is one of the key targets in any computational grid environment to accomplish the task execution on time. In this paper, a Fault Tolerant Hybrid Resource allocation Model (FTHRM) has been proposed to minimize the Turnaround Time (TAT) for the batch of tasks while ensuring fault tolerance in a dynamic grid environment . The model uses the prior reservation mechanism to allocate the resources to tasks for guaranteed task execution. Furthermore, resources are reserved in advance for time slots with resource configuration as required by the batch of tasks. Alternate resources are provided by the system in the case of resource failures. Here, the resource with the least previous workload and lowest execution time will prefer over other resources for task accomplishment. The performance evaluation of FTHRM has been carried out by comparing it with Minimum Completion Time (MCT). The simulation study reveals that the proposed model viz. FTHRM outperforms MCT on considered parameters under study. Statistical testing has been conducted to test the level of significance using SPSS 20, which also confirms the conclusions drawn in the simulation.},
  archive      = {J_JOCS},
  author       = {Sophiya Sheikh and A. Nagaraju and Mohammad Shahid},
  doi          = {10.1016/j.jocs.2020.101268},
  journal      = {Journal of Computational Science},
  pages        = {101268},
  shortjournal = {J. Comput. Sci.},
  title        = {A fault-tolerant hybrid resource allocation model for dynamic computational grid},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adsorption of furan, hexanoic acid, and alkanes in a
hierarchical zeolite at reaction conditions: Insights from molecular
simulations. <em>JOCS</em>, <em>48</em>, 101267. (<a
href="https://doi.org/10.1016/j.jocs.2020.101267">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical zeolites containing both micropores and mesopores are valuable catalysts for facilitating reactions of large molecules. Furan acylation by fatty acids is a promising reaction for valorizing biomass, and the self-pillared pentasil (SPP) zeolite was found to perform particularly well for this reaction. To better understand the distribution of molecules in hierarchical zeolites at the elevated temperature ( T = 523 T=523 K) and the elevated pressure ( p &gt; 1 p&amp;gt;1 bar) associated with typical reaction conditions, unary and binary adsorption were predicted using Monte Carlo simulations in the isothermal–isobaric Gibbs ensemble. Adsorption of six species (furan, hexanoic acid, n n -hexane, n n -decane, n n -tetradecane, and 3,6-diethyloctane) was investigated from vapor, liquid, and supercritical phases, and loadings into the micropores, onto the mesopore surface, and in the mesopore interior of SPP were obtained. As pressure increases, n n -alkanes fill the micropores before loading the surface and then the interior of the mesopore, while furan and hexanoic acid adsorb strongly to the mesopore surface due to hydrogen bonding interactions with surface silanols. Hydrogen bonding interactions also draw hexanoic acid molecules in the micropore region toward the pore mouths, so their carboxylic acid group forms H-bonds with silanols, while the alkyl tails interact with the micropore walls. Mesopore condensation is observed for molecules below their critical point, and occurs when the Gibbs free energy of transfer into the mesopore interior and onto the mesopore surface converge. When hexanoic acid adsorption occurs in the presence of alkane solvents, then the selectivity and spatial distribution of hexanoic acid in the micropores and on the surface can be tuned by adjusting the fluid pressure and the alkane length and/or branching.},
  archive      = {J_JOCS},
  author       = {Tyler R. Josephson and Paul J. Dauenhauer and Michael Tsapatsis and J. Ilja Siepmann},
  doi          = {10.1016/j.jocs.2020.101267},
  journal      = {Journal of Computational Science},
  pages        = {101267},
  shortjournal = {J. Comput. Sci.},
  title        = {Adsorption of furan, hexanoic acid, and alkanes in a hierarchical zeolite at reaction conditions: Insights from molecular simulations},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast method based on GPU for solidification structure
simulation of continuous casting billets. <em>JOCS</em>, <em>48</em>,
101265. (<a href="https://doi.org/10.1016/j.jocs.2020.101265">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present paper develops a fast method to simulate the solidification structure of continuous billets with Cellular Automaton (CA) model. Traditional solution of the CA model on single CPU takes a long time for the massive datasets and complicated calculations, making it unrealistic to optimize the parameters through numerical simulation. In this paper, a parallel method based on Graphics Processing Units (GPU) was proposed to accelerate the calculation, which developed new algorithms for the solute redistribution and neighbor capture to avoid data race in parallel computing . This new method was applied to simulate the solidification structure of Fe-0.64C alloy, and the simulating results were in good agreement with the experiment results with the same parameters. The absolute computational time for the fast method implemented on Tesla P100 GPU is 277 s, while the traditional method implemented on Intel(R) Xeon(R) CPU E5−2680 v4 @ 2.40 GHz with single core is 24.57 h. The speedup, ratio between the absolute computational time of GPU-CA and CPU-CA, varies from 300 to 400 with the increase of the grids.},
  archive      = {J_JOCS},
  author       = {Jing Jing Wang and Hong Ji Meng and Jian Yang and Zhi Xie},
  doi          = {10.1016/j.jocs.2020.101265},
  journal      = {Journal of Computational Science},
  pages        = {101265},
  shortjournal = {J. Comput. Sci.},
  title        = {A fast method based on GPU for solidification structure simulation of continuous casting billets},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple swarm particles simulation algorithm applied to
coffee berry borer proliferation. <em>JOCS</em>, <em>48</em>, 101263.
(<a href="https://doi.org/10.1016/j.jocs.2020.101263">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Swarm intelligence enables simulation and exploration of different phenomena. In this work, it is designed a multiple swarm particles simulation algorithm (MSPSA), based on classical swarm particle interactions extended to a scenario with more than one swarm. It explicitly presents a mathematical and statistical analysis of experimental results. This MSPSA was applied to the simulation of the coffee berry borer proliferation in Colombian crops fields, representing properly the insect behavior under different factors as it happens with the diversity of the Colombian regions and climatic events during the year.},
  archive      = {J_JOCS},
  author       = {Nychol Bazurto-Gómez and Carlos Alberto Martínez-Morales and Helbert Eduardo Espitia-Cuchango},
  doi          = {10.1016/j.jocs.2020.101263},
  journal      = {Journal of Computational Science},
  pages        = {101263},
  shortjournal = {J. Comput. Sci.},
  title        = {Multiple swarm particles simulation algorithm applied to coffee berry borer proliferation},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multiobjective analysis of the potential of scheduling
electrical vehicle charging for flattening the duck curve.
<em>JOCS</em>, <em>48</em>, 101262. (<a
href="https://doi.org/10.1016/j.jocs.2020.101262">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the demand-flexibility of large-collections of electric vehicles (EVs) by scheduling their demand to flatten the electricity duck curve that emerge as a result of growing solar power production. The scheduling problem is investigated in a bi-objective setting and an additional objective function related to the amount of charge provided to EVs is also analyzed. The first objective is the minimization of the ramp-up requirements of the system. The second objective reflects the quality of service and the potential level of charging station&#39;s profit margins. An important characteristics of the proposed model is the effect of total charging capacity on the two objective functions. The analysis is carried out based on a quadratic programming model which is used to calculate the Pareto Front of the two objective functions. This is done through a case study based on real-world data for EV driver behavior, solar generation, and energy consumption. The computational experiments show that there is a high level of competition between these two objectives. Moreover, the effect of different maximal charging capacities on these objectives is observed.},
  archive      = {J_JOCS},
  author       = {Raka Jovanovic and Sertac Bayhan and Islam Safak Bayram},
  doi          = {10.1016/j.jocs.2020.101262},
  journal      = {Journal of Computational Science},
  pages        = {101262},
  shortjournal = {J. Comput. Sci.},
  title        = {A multiobjective analysis of the potential of scheduling electrical vehicle charging for flattening the duck curve},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Electronic transport through molecules containing pyrimidine
units: First-principles calculations. <em>JOCS</em>, <em>48</em>,
101261. (<a href="https://doi.org/10.1016/j.jocs.2020.101261">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using density functional theory in combination with Green&#39;s functional formalism we study the quantum transport through molecular junctions containing pyrimidine units characterized by a permanent dipole moment. The presence of the pyrimidine rings results in the enhanced current through the junctions for both polarities of the applied voltage . In addition, these systems show clear current rectification due to the polar nature of the molecules. The effect of dihedral angle between phenyl and pyrimidine rings on the current rectification is also studied. The obtained results are explained in terms of charge localization in the system as revealed in the transmission eigenvalues analysis. The obtained results can be useful in understanding the role of polar self-assembled monolayers in interface engineering.},
  archive      = {J_JOCS},
  author       = {G.R. Berdiyorov and H. Hamoudi},
  doi          = {10.1016/j.jocs.2020.101261},
  journal      = {Journal of Computational Science},
  pages        = {101261},
  shortjournal = {J. Comput. Sci.},
  title        = {Electronic transport through molecules containing pyrimidine units: First-principles calculations},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lightweight method for evaluating in situ workflow
efficiency. <em>JOCS</em>, <em>48</em>, 101259. (<a
href="https://doi.org/10.1016/j.jocs.2020.101259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Performance evaluation is crucial to understanding the behavior of scientific workflows. In this study, we target an emerging type of workflow, called in situ workflows. These workflows tightly couple components such as simulation and analysis to improve overall workflow performance. To understand the tradeoffs of various configurable parameters for coupling these heterogeneous tasks, namely simulation stride, and component placement, separately monitoring each component is insufficient to gain insights into the entire workflow behavior. Through an analysis of the state-of-the-art research, we propose a lightweight metric, derived from a defined in situ step, for assessing resource usage efficiency of an in situ workflow execution. By applying this metric to a synthetic workflow, which is parameterized to emulate behaviors of a molecular dynamics simulation, we explore two possible scenarios (Idle Simulation and Idle Analyzer) for the characterization of in situ workflow execution. In addition to preliminary results from a recently published study [11] , we further exploit the proposed metric to evaluate a practical in situ workflow with a real molecular dynamics application, i.e., GROMACS. Experimental results show that the in transit placement (analytics on dedicated nodes) sustains a higher frequency for performing in situ analysis compared to the helper-core configuration (analytics co-allocated with simulation).},
  archive      = {J_JOCS},
  author       = {Tu Mai Anh Do and Loïc Pottier and Silvina Caíno-Lores and Rafael Ferreira da Silva and Michel A. Cuendet and Harel Weinstein and Trilce Estrada and Michela Taufer and Ewa Deelman},
  doi          = {10.1016/j.jocs.2020.101259},
  journal      = {Journal of Computational Science},
  pages        = {101259},
  shortjournal = {J. Comput. Sci.},
  title        = {A lightweight method for evaluating in situ workflow efficiency},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An artificial intelligence model considering data imbalance
for ship selection in port state control based on detention
probabilities. <em>JOCS</em>, <em>48</em>, 101257. (<a
href="https://doi.org/10.1016/j.jocs.2020.101257">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Port state control inspection is seen as a safety net to guard marine safety, protect the marine environment, and guarantee decent onboard working and living conditions for seafarers. A substandard ship can be detained in an inspection if serious deficiencies are found onboard. Ship detention is regarded as a severe result in port state control inspection. However, developing accurate prediction models for ship detention based on ship’s generic factors (e.g. ship age, type, and flag), dynamic factors (e.g. times of ship flag changes), and inspection historical factors (e.g. total previous detentions in PSC inspection, last PSC inspection time, and last deficiency number in PSC inspection) before an inspection is conducted is not a trivial task as the low detention rate leads to a highly imbalanced inspection records dataset. To address this issue, this paper develops a classification model called balanced random forest (BRF) to predict ship detention by using 1,600 inspection records at the Hong Kong port for three years. Numerical experiments show that the proposed BRF model can identify 81.25\% of all the ships with detention in the test set which contains another 400 inspection records. Compared with the current ship selection method at the Hong Kong port, the BRF model is much more efficient and can achieve an average improvement of 73.72\% in detained ship identification.},
  archive      = {J_JOCS},
  author       = {Ran Yan and Shuaian Wang and Chuansheng Peng},
  doi          = {10.1016/j.jocs.2020.101257},
  journal      = {Journal of Computational Science},
  pages        = {101257},
  shortjournal = {J. Comput. Sci.},
  title        = {An artificial intelligence model considering data imbalance for ship selection in port state control based on detention probabilities},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction of the reaction forces of spiral-groove gas
journal bearings by artificial neural network regression models.
<em>JOCS</em>, <em>48</em>, 101256. (<a
href="https://doi.org/10.1016/j.jocs.2020.101256">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents neural network regression models for predicting the nonlinear static and linearized dynamic reaction forces of spiral grooved gas journal bearings. The partial differential equations (PDEs) are sampled, based on a full factorial and randomly spaced parameter set. Feed-forward neural network (FNN) architectures are developed for modeling the PDEs and therefore replacing the time-consuming discrete and iterative solution procedure used to this date. A significant speed-up factor of &gt;10 3 in computation time is achieved, compared to solving the PDE numerically. Furthermore, the FNN allows for multi-dimensional interpolation, which makes global system optimization easily possible. This is demonstrated by a real-case rotordynamic system optimization. By using the neural network meta-models, a complete rotordynamic system optimization time reduction of factor 300 is achieved.},
  archive      = {J_JOCS},
  author       = {Elia Iseli and Jürg Schiffmann},
  doi          = {10.1016/j.jocs.2020.101256},
  journal      = {Journal of Computational Science},
  pages        = {101256},
  shortjournal = {J. Comput. Sci.},
  title        = {Prediction of the reaction forces of spiral-groove gas journal bearings by artificial neural network regression models},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D parallel tiled code implementing a modified knuth’s
optimal binary search tree algorithm. <em>JOCS</em>, <em>48</em>,
101246. (<a href="https://doi.org/10.1016/j.jocs.2020.101246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an approach to generation of 3D parallel tiled code implementing an optimal binary search tree (OBST) algorithm. We demonstrate that the features of data dependences available in the code implementing Knuth&#39;s OBST algorithm allow us to generate only 2D tiled code. We suggest a way of transformation of Knuth&#39;s OBST algorithm to a modified one exposing dependences allowing us to generate 3D parallel tiled code. The polyhedral model and the corresponding tools supporting that model are used by us to generate 3D target tiled code on the basis of the modified Knuth&#39;s OBST algorithm. Program parallelism is based on the wavefront technique and it is presented in the OpenMP C/C++ standard. Experiments carried out by us with obtained 3D tiled code demonstrate that this code considerably outperforms 2D tiled code generated on the basis of serial code implementing classic Knuth&#39;s OBST algorithm. Increased code performance is achieved due to much larger locality of 3D tiled code in comparison with that of 2D one.},
  archive      = {J_JOCS},
  author       = {Wlodzimierz Bielecki and Piotr Blaszynski and Maciej Poliwoda},
  doi          = {10.1016/j.jocs.2020.101246},
  journal      = {Journal of Computational Science},
  pages        = {101246},
  shortjournal = {J. Comput. Sci.},
  title        = {3D parallel tiled code implementing a modified knuth&#39;s optimal binary search tree algorithm},
  volume       = {48},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
