<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NEUCOM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="neucom---1676">NEUCOM - 1676</h2>
<ul>
<li><details>
<summary>
(2021). Smoothing quantile regression for a distributed system.
<em>NEUCOM</em>, <em>466</em>, 311–326. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantile regression has become a popular alternative to least squares regression for providing a comprehensive description of the response distribution, and robustness against heavy-tailed error distributions. However, the nonsmooth quantile loss poses new challenges to distributed estimation in both computation and theoretical development. To address this challenge, we use a convolution-type smoothing approach and its Taylor expression to transform the nondifferentiable quantile loss function into a convex quadratic loss function , which admits a fast and scalable algorithm to perform optimization under massive and high-dimensional data. The proposed distributed estimators are both computationally and communication efficient. Moreover, only the gradient information is communicated at each iteration. Theoretically, we show that, after a certain number of iterations, the resulting estimator is statistically as efficient as the global estimator without any restriction on the number of machines. Both simulations and data analysis are conducted to illustrate the finite sample performance of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Rong Jiang and Keming Yu},
  doi          = {10.1016/j.neucom.2021.08.101},
  journal      = {Neurocomputing},
  pages        = {311-326},
  shortjournal = {Neurocomputing},
  title        = {Smoothing quantile regression for a distributed system},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facial depth descend: A generation paradigm for facial depth
map. <em>NEUCOM</em>, <em>466</em>, 298–310. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decades, three-dimensional(3D) face recognition has developed rapidly due to its intrinsic invariance to pose and illumination changes. Yet despite this, deep learning is rarely used in 3D face recognition due to lack of training dat a. Noting that the majority of the recognition processes are based on facial depth map instead of real 3D data, we focus on the generation of facial depth map to surmount the shortage of training data. In this paper, we present a novel paradigm, Facial Depth Descend, which generates facial depth map from existing 3D face data. The key to this generation paradigm is to recombine facial components from existing faces and thereafter generate brand new faces based on them. We then propose a learning framework RPC to generate recognition-friendly faces. First, it extracts three facial components (eyes, nose and mouth) from the 3D data of real faces. Then, with these components as input, a Relative Location Estimator (RLE) is used to predict the relative location among them so that they can be composed in a reasonable manner. Finally, the method feeds a Pix2Pix network with these composed facial components to extrapolate areas surrounding them and output a full facial depth map. We here enforce an identity preserving loss on the generation network to make the facial depth map more discriminative and favorable for recognition tasks. Since we can choose different identities’ different components as input, RPC is theoretically able to generate a vast number of novel 2.5D faces. More specifically, RPC can generate an enlarged face dataset as large as N 3 N3 identities, where N N is the number of identities in the original one. Experiments show that, adding the generated depth maps to the training dataset can help improve the recognition rate in 2.5D face recognition.},
  archive      = {J_NEUCOM},
  author       = {Yao Yan and Congying Han and Jin Qin and Hanqin Chen and Tiande Guo},
  doi          = {10.1016/j.neucom.2021.09.010},
  journal      = {Neurocomputing},
  pages        = {298-310},
  shortjournal = {Neurocomputing},
  title        = {Facial depth descend: A generation paradigm for facial depth map},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-target tracking for unmanned aerial vehicle swarms
using deep reinforcement learning. <em>NEUCOM</em>, <em>466</em>,
285–297. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep reinforcement learning (DRL) has proved its great potential in multi-agent cooperation. However, how to apply DRL to multi-target tracking (MTT) problem for unmanned aerial vehicle (UAV) swarms is challenging: 1) the scale of UAVs may be large, but the existing multi-agent reinforcement learning (MARL) methods that rely on global or joint information of all agents suffer from the dimensionality curse; 2) the dimension of each UAV’s received information is variable, which is incompatible with the neural networks with fixed input dimensions; 3) the UAVs are homogeneous and interchangeable that each UAV’s policy should be irrelevant to the permutation of its received information. To this end, we propose a DRL method for UAV swarms to solve the MTT problem. Firstly, a decentralized swarm-oriented Markov Decision Process (MDP) model is presented for UAV swarms, which involves each UAV’s local communication and partial observation. Secondly, to achieve better scalability, a cartogram feature representation (FR) is proposed to integrate the variable-dimensional information set into a fixed-shape input variable, and the cartogram FR can also maintain the permutation irrelevance to the information. Then, the double deep Q-learning network with dueling architecture is adapted to the MTT problem, and the experience-sharing training mechanism is adopted to learn the shared cooperative policy for UAV swarms. Extensive experiments are provided and the results show that our method can successfully learn a cooperative tracking policy for UAV swarms and outperforms the baseline method in the tracking ratio and scalability.},
  archive      = {J_NEUCOM},
  author       = {Wenhong Zhou and Zhihong Liu and Jie Li and Xin Xu and Lincheng Shen},
  doi          = {10.1016/j.neucom.2021.09.044},
  journal      = {Neurocomputing},
  pages        = {285-297},
  shortjournal = {Neurocomputing},
  title        = {Multi-target tracking for unmanned aerial vehicle swarms using deep reinforcement learning},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Towards embedding information diffusion data for
understanding big dynamic networks. <em>NEUCOM</em>, <em>466</em>,
265–284. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dynamic networks are popularly used to describe networks that change with time. Although there have been a large number of research works on understanding dynamic networks using link prediction, node classification and community detection, there is rare work that is specially designed to address the challenge of big network size of dynamic networks. To this end, we study in this paper an emerging and challenging problem of network coarsening in dynamic networks. Network coarsening refers to a class of network “zoom-out” operations where node pairs and edges are grouped together for efficient analysis on big networks. However, existing network coarsening approaches can only handle static networks where network structure weights have been predefined before the coarsening calculation. Under the observation that big networks are highly dynamic and naturally change over time, we consider in this paper to embed information diffusion data which reflect the dynamics of networks for network coarsening. Specifically, we present a new Semi-NetCoarsen approach that jointly maximizes the likelihood of observing the information diffusion data and minimizes the network regularization with respect to the predefined network structural data. The learning function is convex and we use the accelerated proximal gradient algorithm to obtain the global optimal solution . We conduct experiments on two synthetic and five real-world data sets to validate the performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hong Yang and Peng Zhang and Haishuai Wang and Chuan Zhou and Zhao Li and Li Gao and Qingfeng Tan},
  doi          = {10.1016/j.neucom.2021.09.024},
  journal      = {Neurocomputing},
  pages        = {265-284},
  shortjournal = {Neurocomputing},
  title        = {Towards embedding information diffusion data for understanding big dynamic networks},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An analysis of the impact of subsampling on the neural
network error surface. <em>NEUCOM</em>, <em>466</em>, 252–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper empirically analyses the impact of changes to the set of training examples on the neural network error surface. Specific quantitative characteristics of the error surface related to properties such as ruggedness, modality and structure are measured and visualized as the set of training examples changes. Both the case of random subsampling and active learning from a fixed dataset are examined, producing ten different training scenarios. For each scenario eleven error surface characteristics are calculated for five common benchmark problems. The results demonstrate that the error surface characteristics calculated using only a subsample of the available data commonly do not generalize to that of the full dataset. The observed error surface characteristics are significantly impacted by the particular set of examples used to calculate error. Some error surface characteristics are significantly altered by small changes in the set of examples used to calculate error. The main finding from this study is that when the set of training examples may change during training the training of a neural network is in essence a dynamic optimization problem , suggesting that optimization algorithms developed specifically to solve dynamic optimization problems may be more efficient at training neural networks under such conditions.},
  archive      = {J_NEUCOM},
  author       = {Cody Dennis and Andries Engelbrecht and Beatrice M. Ombuki-Berman},
  doi          = {10.1016/j.neucom.2021.09.023},
  journal      = {Neurocomputing},
  pages        = {252-264},
  shortjournal = {Neurocomputing},
  title        = {An analysis of the impact of subsampling on the neural network error surface},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning rates for multi-task regularization networks.
<em>NEUCOM</em>, <em>466</em>, 243–251. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning is an important trend of machine learning in facing the era of artificial intelligence and big data. Despite a large amount of researches on learning rate estimates of various single-task machine learning algorithms , there is little parallel work for multi-task learning. We present mathematical analysis on the learning rate estimate of multi-task learning based on the theory of vector-valued reproducing kernel Hilbert spaces and matrix-valued reproducing kernels. For the typical multi-task regularization networks, an explicit learning rate dependent both on the number of sample data and the number of tasks is obtained. It reveals that the generalization ability of multi-task learning algorithms is indeed affected as the number of tasks increases.},
  archive      = {J_NEUCOM},
  author       = {Jie Gui and Haizhang Zhang},
  doi          = {10.1016/j.neucom.2021.09.031},
  journal      = {Neurocomputing},
  pages        = {243-251},
  shortjournal = {Neurocomputing},
  title        = {Learning rates for multi-task regularization networks},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble learning-based approach for improving
generalization capability of machine reading comprehension systems.
<em>NEUCOM</em>, <em>466</em>, 229–242. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine Reading Comprehension (MRC) is an active field in natural language processing with many successful developed models in recent years. Despite their high in-distribution accuracy, these models suffer from two issues: high training cost and low out-of-distribution accuracy. Even though some approaches have been presented to tackle the generalization problem, they have high, intolerable training costs. In this paper, we investigate the effect of ensemble learning as a light approach to improve out-of-distribution generalization of MRC systems by aggregating the outputs of some pre-trained base models without retraining a big model. After separately training the base models with different structures on different datasets, they are ensembled using weighting and stacking approaches in probabilistic and non-probabilistic settings. Three configurations are investigated including heterogeneous, homogeneous, and hybrid on eight datasets and six state-of-the-art models. We identify the important factors in the effectiveness of ensemble methods . Also, we compare the robustness of ensemble and fine-tuned models against data distribution shifts. The experimental results show the effectiveness and robustness of the ensemble approach in improving the out-of-distribution accuracy of MRC systems, especially when the base models are similar in accuracies.},
  archive      = {J_NEUCOM},
  author       = {Razieh Baradaran and Hossein Amirkhani},
  doi          = {10.1016/j.neucom.2021.08.095},
  journal      = {Neurocomputing},
  pages        = {229-242},
  shortjournal = {Neurocomputing},
  title        = {Ensemble learning-based approach for improving generalization capability of machine reading comprehension systems},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Free-weighting-matrix inequality for exponential stability
for neural networks with time-varying delay. <em>NEUCOM</em>,
<em>466</em>, 221–228. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exponential stability for neural networks with time-varying delay is considered in this paper. By extending the generalized free-weighting-matrix integral inequality, a novel integral inequality is derived by using weighted orthogonal functions . Then the new inequality is applied to investigate the exponential stability of time delay neural networks via an improved Lyapunov–Krasovskii functional. Numerical examples are given to verify the advantages of the proposed criterion.},
  archive      = {J_NEUCOM},
  author       = {Chenyang Shi and Kachon Hoi and Seakweng Vong},
  doi          = {10.1016/j.neucom.2021.09.028},
  journal      = {Neurocomputing},
  pages        = {221-228},
  shortjournal = {Neurocomputing},
  title        = {Free-weighting-matrix inequality for exponential stability for neural networks with time-varying delay},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Global2Salient: Self-adaptive feature aggregation for remote
sensing smoke detection. <em>NEUCOM</em>, <em>466</em>, 202–220. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing (RS) images have been widely used in disaster monitoring due to their wide observation and timeliness. Wildfire is a type of destructive disaster, and smoke is an important signal of the occurrence of wildfires; therefore, it is necessary to perform smoke detection in RS images. Smoke-like scenes such as clouds captured by satellites make RS smoke detection a tough task. Differences in resolution and the complexity of the geographical environment further increases the difficulty of detection: smoke in some images only occupies a small area, while in other images it may fill the whole image. Thus, global information and salient features are both essential for RS smoke detection. From this point of view, we design a self-adaptive feature aggregation (SAFA) network to distinguish smoke from other scenes in RS images. SAFA has two pathways: the global information extraction pathway (GIEP) for capturing global information and the salient feature extraction pathway (SFEP) for extracting salient features. The self-adaptive aggregation means GIEP and SFEP are summed up by trainable weight coefficients to make the final prediction. We conducted experiments on USTC_SmokeRS data, which are specially set up for RS smoke detection. This dataset contains smoke and other smoke-like scenes such as clouds, dust and haze. The experimental results show that SAFA achieves the new state-of-the-art classification accuracy of 96.22\% on this dataset.},
  archive      = {J_NEUCOM},
  author       = {Shikun Chen and Yichao Cao and Xiaoqiang Feng and Xiaobo Lu},
  doi          = {10.1016/j.neucom.2021.09.026},
  journal      = {Neurocomputing},
  pages        = {202-220},
  shortjournal = {Neurocomputing},
  title        = {Global2Salient: Self-adaptive feature aggregation for remote sensing smoke detection},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Integrating vertex and edge features with graph
convolutional networks for skeleton-based action recognition.
<em>NEUCOM</em>, <em>466</em>, 190–201. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Methods based on Graph Convolutional Networks(GCN) for skeleton-based action recognition have achieved great success due to their ability to exploit graph structural information from skeleton data. Recently, the bone information has attracted considerable attention as an effective modality which complements the more conventional joint information for action recognition. However, most existing GCN-based methods extract the joint and bone features with two separate GCN networks, ignoring the dependencies between them. In this paper, a novel GCN model is proposed to exploit the information across joints, bones and their relationship collaboratively on a single undirected graph instead of two separate networks. We call the proposed model Vertex-Edge Graph Convolutional Network (VE-GCN) since it conducts the graph convolution operation on the sampling area containing the designated vertexes from joints and edges from bones, respectively. In addition to conducting the Vertex-Edge graph convolution based on the physical connections of the skeleton, we further apply the Vertex-Edge graph convolution to the non-physical joint-joint and joint-bone connections to capture the distal dependencies, and then the convolution results on the non-physical connections are incorporated into the VE-GCN. Moreover, the Conditional Random Field (CRF) is adopted as the loss function to achieve the task of action recognition. Experimental results on four challenging benchmarks (NTU RGB+D, NTU RGB+D 120, N-UCLA, SYSU) show that the proposed model achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Kai Liu and Lei Gao and Naimul Mefraz Khan and Lin Qi and Ling Guan},
  doi          = {10.1016/j.neucom.2021.09.034},
  journal      = {Neurocomputing},
  pages        = {190-201},
  shortjournal = {Neurocomputing},
  title        = {Integrating vertex and edge features with graph convolutional networks for skeleton-based action recognition},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Adaptive sliding window LSTM NN based RUL prediction for
lithium-ion batteries integrating LTSA feature reconstruction.
<em>NEUCOM</em>, <em>466</em>, 178–189. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The extraction and prediction of health indicators (HIs) are two vital aspects in remaining useful life (RUL) prediction of lithium-ion batteries (LIBs). Aiming to estimate the RUL precisely, a novel integrated prediction method is proposed for LIBs on the basis of local tangent space alignment (LTSA) feature extraction and adaptive sliding window long short-term memory neural networks (ASW LSTM NN). In the proposed method, the indirect HI is first extracted by LTSA automatically to replace the unmeasurable capacity, and a strong correlation between them is verified by the Spearman correlation coefficient. Following that, with the extracted HI, an adaptive sliding window LSTM is constructed to conduct the RUL estimation of LIBs in routine environment. For the structured neural network, corresponding inputs are dynamically selected by the sliding window, while a varying length window mechanism is devised to update the window data along with the predicting cycle. Hence, the designed predicting method can learn the long-term dependencies by means of the inherent nature of LSTM and simultaneously capture the local fluctuations via the adaptive sliding window. Eventually, extensive experiments are conducted and corresponding results are compared with those obtained by existed approaches. The effectiveness of the integrated prediction method is validated, and our proposed model is proved to be more accurate in predicting the RUL compared with existed approaches.},
  archive      = {J_NEUCOM},
  author       = {Zhuqing Wang and Ning Liu and Yangming Guo},
  doi          = {10.1016/j.neucom.2021.09.025},
  journal      = {Neurocomputing},
  pages        = {178-189},
  shortjournal = {Neurocomputing},
  title        = {Adaptive sliding window LSTM NN based RUL prediction for lithium-ion batteries integrating LTSA feature reconstruction},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DCA based approaches for bi-level variable selection and
application for estimate multiple sparse covariance matrices.
<em>NEUCOM</em>, <em>466</em>, 162–177. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variable selection plays an important role in analyzing high dimensional data and is a fundamental problem in machine learning. When the data possesses certain group structures in which individual variables are also meaningful scientifically, we are naturally interested in selecting important groups as well as important variables within the selected groups. This is referred to as the bi-level variable selection which is much more complex than the selection of individual variables. In recent years, research on the topic of variable selection is very active, but the majority of the work is focused on the individual variable selection. There is therefore a need to further develop more effective approaches for bi-level variable selection. Since DC (Difference of Convex functions) programming and DCA (DC Algorithm), powerful tools in nonconvex programming framework, have been successfully investigated for individual variable selection, we believe that they could be efficiently exploited for the more difficult bi-level variable selection task. In that direction, we investigate in this work DC approximations of the mixed zero norm ( ℓ 0 , 0 ℓ0,0 ) and the combined norm ( ℓ 0 + ℓ q , 0 ℓ0+ℓq,0 ). The resulting approximate problems are then formulated as DC programs for which DCA based algorithms are introduced. As an application, these DCA schemes are developed for estimating multiple sparse covariance matrices sharing some common structures such as the locations or weights of non-zero elements. The experimental results on both simulated and real datasets indicate the efficiency of our algorithms.},
  archive      = {J_NEUCOM},
  author       = {Hoai An Le Thi and Duy Nhat Phan and Tao Pham Dinh},
  doi          = {10.1016/j.neucom.2021.09.039},
  journal      = {Neurocomputing},
  pages        = {162-177},
  shortjournal = {Neurocomputing},
  title        = {DCA based approaches for bi-level variable selection and application for estimate multiple sparse covariance matrices},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Text removal network based on comprehensive loss evaluation
and its application. <em>NEUCOM</em>, <em>466</em>, 148–161. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a text removal model, Text Remove Network (TRNet), which achieves an unprecedented clearing effect of picture text. The network uses a jump-connected U-net structure to encode and decode the generator, so as to obtain clearer and sharper texture details of the original image. To solve the problem of color distortion, the generator removes the batch normalization layer and uses ELUs as the activation layer of all convolutional layers . Through the comprehensive loss, which include reconstruction, content, style, total variation, and structural similarity (SSIM) loss, we can clear the image text and preserve the image information of the background, which solves the problem of incomplete text removal and loss of background texture. The local discriminator is used to evaluate the local consistency of the text erasure area. In a text elimination experiment on a synthetic dataset and the ICDAR 2013 dataset, this method had a good effect on foreground text erasure and background authenticity restoration. Experiments on a comprehensive dataset of real documents also showed good results. To achieve targeted removal of sensitive text information on pictures, we collected datasets based on real and synthetic documents, and experimental results were satisfactory. Compared to current and classic algorithms, our text removal algorithm performs best in Image Quality Assessment (IQA).},
  archive      = {J_NEUCOM},
  author       = {Zhangdao Huang and Jinglin Zhou},
  doi          = {10.1016/j.neucom.2021.09.030},
  journal      = {Neurocomputing},
  pages        = {148-161},
  shortjournal = {Neurocomputing},
  title        = {Text removal network based on comprehensive loss evaluation and its application},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A time-varying neural network for solving minimum spanning
tree problem on time-varying network. <em>NEUCOM</em>, <em>466</em>,
139–147. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a time-varying neural network (TVNN) for solving the time-varying minimum spanning tree problem with constraints (CTMST), which is a variant of the time-varying network minimum spanning tree problem (TNMSTP), a well-known NP-hard problem. Unlike traditional algorithms that use heuristic search , the proposed TVNN is based on time-varying neurons and can achieve parallel computing without any training requirements. Time-varying neurons are novel computational neurons designed in this work. They consist of six parts: input, wave receiver, neuron state, wave generator, wave sender, and output. The parallel computing strategy and self-feedback mechanism of the proposed algorithm greatly improve the response speed and solution accuracy on large-scale time-varying networks. The analysis of time complexity and experimental results on the New York City dataset show that the performance of the proposed algorithm is significantly improved compared with the existing methods.},
  archive      = {J_NEUCOM},
  author       = {Zhilei Xu and Wei Huang and Jinsong Wang},
  doi          = {10.1016/j.neucom.2021.09.040},
  journal      = {Neurocomputing},
  pages        = {139-147},
  shortjournal = {Neurocomputing},
  title        = {A time-varying neural network for solving minimum spanning tree problem on time-varying network},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memory augmented convolutional neural network and its
application in bioimages. <em>NEUCOM</em>, <em>466</em>, 128–138. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The long short-term memory (LSTM) network underpins many achievements and breakthroughs especially in natural language processing fields. Essentially, it is endowed with certain memory capabilities to boost its performance. Currently, the volume and speed of big data generation are increasing exponentially, and such data require efficient models to acquire memory augmented knowledge. In this paper, we propose a memory augmented convolutional neural network (MACNN) with utilizing self-organizing maps (SOM) as the memory module. First, we depict the potential challenge about just applying solely a convolutional neural network (CNN) so as to highlight the advantage of augmenting SOM memory for better network generalization. Then, we dissert a corresponding network architecture incorporating memory to instantiate the distributed knowledge representation machanism, which tactically combines both SOM and CNN. Each component of the input vector is connected with a neuron in a two-dimensional lattice. Finally, we test the proposed network on various datasets and the experimental results reveal that MACNN can achieve competitive performance, especially for bioimages datasets. Meanwhile, we further illustrate the learned representations to interpret the SOM behavior and to comprehend the achieved results, which indicates that the proposed memory-incorporating model can exhibit the better performance.},
  archive      = {J_NEUCOM},
  author       = {Weiping Ding and Yurui Ming and Yu-Kai Wang and Chin-Teng Lin},
  doi          = {10.1016/j.neucom.2021.09.012},
  journal      = {Neurocomputing},
  pages        = {128-138},
  shortjournal = {Neurocomputing},
  title        = {Memory augmented convolutional neural network and its application in bioimages},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic camera configuration learning for high-confidence
active object detection. <em>NEUCOM</em>, <em>466</em>, 113–127. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of object detection is closely related to the quality of input images. However, the current image acquisition is purely guided by human visual perception, and such camera imaging process ignores the subsequent application. In this context, detection performance is impacted by imaging configuration and dynamic camera motion. To address the above problems, an active object detection framework is proposed in this paper, which aims to build the bridge between imaging configuration and object detection task. Within the proposed framework, a dynamic camera configuration learning approach is presented based on deep reinforcement learning , where the camera is actively controlled to maximize the detection performance. Through iterated interactions between imaging, control and object detection, the deep gap between perception and cognition in the object detection system is eliminated, and the transformation from physical imaging to purposeful imaging is realized. The effectiveness and advantages of the proposed framework are demonstrated in three dynamic environments.},
  archive      = {J_NEUCOM},
  author       = {Nuo Xu and Chunlei Huo and Xin Zhang and Yong Cao and Gaofeng Meng and Chunhong Pan},
  doi          = {10.1016/j.neucom.2021.09.037},
  journal      = {Neurocomputing},
  pages        = {113-127},
  shortjournal = {Neurocomputing},
  title        = {Dynamic camera configuration learning for high-confidence active object detection},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature-enhanced generation and multi-modality fusion based
deep neural network for brain tumor segmentation with missing MR
modalities. <em>NEUCOM</em>, <em>466</em>, 102–112. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using multimodal Magnetic Resonance Imaging (MRI) is necessary for accurate brain tumor segmentation. The main problem is that not all types of MRIs are always available in clinical exams. Based on the fact that there is a strong correlation between MR modalities of the same patient, in this work, we propose a novel brain tumor segmentation network in the case of missing one or more modalities. The proposed network consists of three sub-networks: a feature-enhanced generator, a correlation constraint block and a segmentation network . The feature-enhanced generator utilizes the available modalities to generate 3D feature-enhanced image representing the missing modality. The correlation constraint block can exploit the multi-source correlation between the modalities and also constrain the generator to synthesize a feature-enhanced modality which must have a coherent correlation with the available modalities. The segmentation network is a multi-encoder based U-Net to achieve the final brain tumor segmentation. The proposed method is evaluated on BraTS 2018 dataset. Experimental results demonstrate the effectiveness of the proposed method which achieves the average Dice Score of 82.9, 74.9 and 59.1 on whole tumor, tumor core and enhancing tumor, respectively across all the situations, and outperforms the best method by 3.5\%, 17\% and 18.2\%.},
  archive      = {J_NEUCOM},
  author       = {Tongxue Zhou and Stéphane Canu and Pierre Vera and Su Ruan},
  doi          = {10.1016/j.neucom.2021.09.032},
  journal      = {Neurocomputing},
  pages        = {102-112},
  shortjournal = {Neurocomputing},
  title        = {Feature-enhanced generation and multi-modality fusion based deep neural network for brain tumor segmentation with missing MR modalities},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed discrete-time optimization of heterogeneous
multi-agent networks with unbounded position constraints and nonconvex
velocity constraints. <em>NEUCOM</em>, <em>466</em>, 92–101. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The distributed discrete-time heterogeneous multi-agent optimization problem with unbounded position constraints and nonconvex velocity constraints was considered in this paper, where the models of agents are described by first- or second- order difference equations, the position constraints are assumed to be unbounded and convex and the velocity constraints are assumed to be bounded, closed and nonconvex. An improved distributed algorithm is adopted, under which, all agents could collaboratively minimize the entire objective function and the positions and velocities could always stay at the corresponding constraint sets. Then the convergence analysis is completed by the coordination transformation and the properties of projection operator and constraint operator. Finally, we give examples to illustrate the correctness of results.},
  archive      = {J_NEUCOM},
  author       = {Lipo Mo and Zixin Zhang and Yongguang Yu},
  doi          = {10.1016/j.neucom.2021.09.042},
  journal      = {Neurocomputing},
  pages        = {92-101},
  shortjournal = {Neurocomputing},
  title        = {Distributed discrete-time optimization of heterogeneous multi-agent networks with unbounded position constraints and nonconvex velocity constraints},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Verification mechanism to obtain an elaborate answer span in
machine reading comprehension. <em>NEUCOM</em>, <em>466</em>, 80–91. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine reading comprehension (MRC) is a challenging task in natural language processing (NLP), which requires machine to determine the corresponding answer to a given passage and question. Whereas, there always exist unanswerable questions in the real world, which poses a new challenge to MRC tasks. Abundant research work has been carried out on the verification mechanism for the answerability of passage-question pairs. However, these researches only focus on its design and implementation, which has limitations in real-world scenarios. Thus, the method proposed in this paper not only verifies the answerability, but also validates and adjusts the predicted answer to obtain an elaborate answer span. Using powerful pre-trained model as encoder block, this paper explores a more comprehensive verification mechanism. Similar to how humans read passages and give answers, we propose a three-stage mechanism called ”Verification for an Elaborate Span” (V4ES): 1) sketchy reading that the model briefly browses the overall information of the passage and question, and then generates an initial answer; 2) intensive reading that it reads the passage and question again, judges the answerability of the question and gives an answer at this stage; 3) verification that it verifies these two answers produced at the previous two stages, and then gives the final prediction. Moreover, the proposed model is evaluated on two MRC challenge datasets: SQuAD2.0 and CMRC2018, and the experiment results show that our model has achieved great improvement compared with the ALBERT and BERT baselines. In conclusion, our proposed verification mechanism has demonstrated its effectiveness through a series of experiments and analysis.},
  archive      = {J_NEUCOM},
  author       = {Yu Peng and Xiaoyu Li and Jingkuan Song and Yu Luo and Shijie Hu and Weizhong Qian},
  doi          = {10.1016/j.neucom.2021.08.084},
  journal      = {Neurocomputing},
  pages        = {80-91},
  shortjournal = {Neurocomputing},
  title        = {Verification mechanism to obtain an elaborate answer span in machine reading comprehension},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep robust image deblurring via blur distilling and
information comparison in latent space. <em>NEUCOM</em>, <em>466</em>,
69–79. (<a href="https://doi.org/10.1016/j.neucom.2021.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current deep deblurring methods pay main attention to learning a transferring network to transfer synthetic blurred images to clean ones. Though achieving significant performance on the training datasets, they still suffer from a weaker generalization capability from training datasets to others with different synthetic blurs, thus resulting in significantly inferior performance on testing datasets. In order to alleviate this problem, we propose a latent contrastive model, Blur Distilling and Information Reconstruction Networks ( BDIRNet ), to learn image prior and improve the robustness of deep deblurring. The proposed BDIRNet consists of a blur removing network ( DistillNet ) and a reconstruction network ( RecNet ). Two kinds of images with almost the same information but different qualities are input into DistillNet to extract identical structure information via contrast latent information and purify the perturbations from other unimportant information like blur. While the RecNet is utilized to reconstruct sharp images based on the extracted information. In addition, inside the DistillNet and RecNet, a statistical anti-interference distilling ( SAID ) and anti-interference reconstruction ( SAIR ) modules are proposed to further enhance the robustness of our methods, respectively. Extensive experiments on different datasets show that the proposed methods achieve improved and robust results compared to recent state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Wenjia Niu and Kaihao Zhang and Wenhan Luo and Yiran Zhong and Hongdong Li},
  doi          = {10.1016/j.neucom.2021.09.019},
  journal      = {Neurocomputing},
  pages        = {69-79},
  shortjournal = {Neurocomputing},
  title        = {Deep robust image deblurring via blur distilling and information comparison in latent space},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-based sequence to sequence model for machine
remaining useful life prediction. <em>NEUCOM</em>, <em>466</em>, 58–68.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate estimation of remaining useful life (RUL) of industrial equipment can enable advanced maintenance schedules, increase equipment availability and reduce operational costs. However, existing deep learning methods for RUL prediction are not completely successful due to the following two reasons. First, relying on a single objective function to estimate the RUL will limit the learned representations and thus affect the prediction accuracy. Second, while longer sequences are more informative for modelling the sensor dynamics of equipment, existing methods are less effective to deal with very long sequences, as they mainly focus on the latest information. To address these two problems, we develop a novel attention-based sequence to sequence with auxiliary task (ATS2S) model. In particular, our model jointly optimizes both reconstruction loss to empower our model with predictive capabilities (by predicting next input sequence given current input sequence) and RUL prediction loss to minimize the difference between the predicted RUL and actual RUL. Furthermore, to better handle longer sequences, we employ the attention mechanism to focus on all the important input information during the training process. Finally, we propose a new dual-latent feature representation to integrate the encoder features and decoder hidden states, to capture rich semantic information in data. We conduct extensive experiments on four real datasets to evaluate the efficacy of the proposed method. Experimental results show that our proposed method can achieve superior performance over 13 state-of-the-art methods consistently.},
  archive      = {J_NEUCOM},
  author       = {Mohamed Ragab and Zhenghua Chen and Min Wu and Chee-Keong Kwoh and Ruqiang Yan and Xiaoli Li},
  doi          = {10.1016/j.neucom.2021.09.022},
  journal      = {Neurocomputing},
  pages        = {58-68},
  shortjournal = {Neurocomputing},
  title        = {Attention-based sequence to sequence model for machine remaining useful life prediction},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leader-following consensus of delayed multi-agent systems
with aperiodically intermittent communications. <em>NEUCOM</em>,
<em>466</em>, 49–57. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the leader-following consensus of nonlinear multi-agent systems with time delay and aperiodically intermittent communications is investigated. Compared with the intermittent communications for multi-agent systems in previous literature, we relax the periodicity or quasi-periodicity of the intermittent communications and render the intermittent communications to be completely aperiodic. The concepts of average communication ratio and average communication period are adapted to characterize the distributions of communication time and non-communication time. Then the consensus problem for the studied systems with large time delay and small time delay is studied, respectively. Especially, for the case of small time delay, the upper bound of time delay is assumed to be less than the average communication length (average communication ratio × × average communication period), but can be larger than some communication lengths, which is less conservative. Finally, numerical examples are provided to show the effectiveness of the main results.},
  archive      = {J_NEUCOM},
  author       = {Ying Guo and Yan Qian and Pengfei Wang},
  doi          = {10.1016/j.neucom.2021.09.014},
  journal      = {Neurocomputing},
  pages        = {49-57},
  shortjournal = {Neurocomputing},
  title        = {Leader-following consensus of delayed multi-agent systems with aperiodically intermittent communications},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-document detection via corner localization and
association. <em>NEUCOM</em>, <em>466</em>, 37–48. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of hand-held photographic devices, document images in unconstrained environments can be captured in high-speed and high-resolution. It will be more efficient to process the text information of multiple documents simultaneously. In this paper, we propose a multi-document detection approach. It can estimate the amount of documents and also detect their accurate locations via iteratively searching the four corners and their direction maps from individual document in the image. Even for slightly occluded documents, the proposed method can infer the hidden corner positions. The model is designed to jointly learn the corner categories, locations and their directions in attentional regions via two branches of the same sequential prediction process. The association score is calculated based on the them between two corner connections. The graph theory, considering corners as nodes and association scores as edges, is applied to get the quadrangle for each document in image. For evaluation, we collect a Multi-Doc data set which contains 2,200 document images in various natural scenes. We show that the baseline model trained on this collected data and bench-mark SmartDoc 2015 can detect both single and multiple documents accurately and effectively.},
  archive      = {J_NEUCOM},
  author       = {Runqiu Pan and Anna Zhu},
  doi          = {10.1016/j.neucom.2021.09.033},
  journal      = {Neurocomputing},
  pages        = {37-48},
  shortjournal = {Neurocomputing},
  title        = {Multi-document detection via corner localization and association},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Adversarial point cloud perturbations against 3D object
detection in autonomous driving systems. <em>NEUCOM</em>, <em>466</em>,
27–36. (<a href="https://doi.org/10.1016/j.neucom.2021.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models have been demonstrated vulnerable to adversarial attacks even with imperceptible perturbations. As such, the reliability of existing deep neural networks-based autonomous driving systems can suffer. However, deep 3D models have applications in various Cyber-Physical Systems (CPSs) with safety-critical requirements, particularly autonomous driving systems. In this paper, the robustness of deep 3D object detection models under adversarial point cloud perturbations has been investigated. A novel method is developed to generate 3D adversarial examples from point cloud perturbations, which are common due to the intrinsic characteristics of the data captured by 3D sensors, e.g., LiDAR. The generation of adversarial samples is supervised by a dual loss, which constitutes an adversarial loss and a perturbation loss. The adversarial loss produces a point cloud with the property of aggressiveness, while the perturbation loss enforces the produced point cloud subject to visual imperception. We demonstrate that the method can successfully attack 3D object detection models in most cases, and expose their vulnerability to physical-world attacks in the form of point cloud perturbations. We perform a thorough evaluation of popular deep 3D object detectors in an adversarial setting on the KITTI vision benchmark. Experimental results show that current deep 3D object detection models are susceptible to adversarial attacks in the context of autonomous driving, and their performances are degraded by a large margin in the presence of adversarial point clouds generated by the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xupeng Wang and Mumuxin Cai and Ferdous Sohel and Nan Sang and Zhengwei Chang},
  doi          = {10.1016/j.neucom.2021.09.027},
  journal      = {Neurocomputing},
  pages        = {27-36},
  shortjournal = {Neurocomputing},
  title        = {Adversarial point cloud perturbations against 3D object detection in autonomous driving systems},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Fine-grained few shot learning with foreground object
transformation. <em>NEUCOM</em>, <em>466</em>, 16–26. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional fine-grained image classification generally requires abundant labeled samples to deal with the low inter-class variance but high intra-class variance problem. However, in many scenarios we may have limited samples for some novel sub-categories, leading to the fine-grained few shot learning (FG-FSL) setting. To address this challenging task, we propose a novel method named foreground object transformation (FOT), which is composed of a foreground object extractor and a posture transformation generator. The former aims to remove image background, which tends to increase the difficulty of fine-grained image classification as it amplifies the intra-class variance while reduces inter-class variance. The latter transforms the posture of the foreground object to generate additional samples for the novel sub-category. As a data augmentation method, FOT can be conveniently applied to any existing few shot learning algorithm and greatly improve its performance on FG-FSL tasks. In particular, in combination with FOT, simple fine-tuning baseline methods can be competitive with the state-of-the-art methods both in inductive setting and transductive setting. Moreover, FOT can further boost the performances of latest excellent methods and bring them up to the new state-of-the-art. In addition, we also show the effectiveness of FOT on general FSL tasks.},
  archive      = {J_NEUCOM},
  author       = {Chaofei Wang and Shiji Song and Qisen Yang and Xiang Li and Gao Huang},
  doi          = {10.1016/j.neucom.2021.09.016},
  journal      = {Neurocomputing},
  pages        = {16-26},
  shortjournal = {Neurocomputing},
  title        = {Fine-grained few shot learning with foreground object transformation},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Learning various length dependence by dual recurrent neural
networks. <em>NEUCOM</em>, <em>466</em>, 1–15. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) are widely used as a memory model for sequence-related problems. Many variants of RNN have been proposed to solve the gradient problems of training RNNs and process long sequences. Although some classical models have been proposed, capturing long-term dependence while responding to short-term changes remains a challenge. To address this problem, we propose a new model named Dual Recurrent Neural Networks (DuRNN). The DuRNN consists of two parts to learn the short-term dependence and progressively learn the long-term dependence. The first part is a recurrent neural network with constrained full recurrent connections to deal with short-term dependence in sequence and generate short-term memory. Another part is a recurrent neural network with independent recurrent connections which helps to learn long-term dependence and generate long-term memory. A selection mechanism is added between two parts to transfer the needed long-term information to the independent neurons. Multiple modules can be stacked to form a multi-layer model for better performance. Our contributions are: 1) a new recurrent model developed based on the divide-and-conquer strategy to learn long and short-term dependence separately, and 2) a selection mechanism to enhance the separating and learning of different temporal scales of dependence. Both theoretical analysis and extensive experiments are conducted to validate the performance of our model. Experimental results indicate that the proposed DuRNN model can handle not only very long sequences (over 5,000 time steps), but also short sequences very well.},
  archive      = {J_NEUCOM},
  author       = {Chenpeng Zhang and Shuai Li and Mao Ye and Ce Zhu and Xue Li},
  doi          = {10.1016/j.neucom.2021.09.043},
  journal      = {Neurocomputing},
  pages        = {1-15},
  shortjournal = {Neurocomputing},
  title        = {Learning various length dependence by dual recurrent neural networks},
  volume       = {466},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IBNet: Interactive branch network for salient object
detection. <em>NEUCOM</em>, <em>465</em>, 574–583. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, saliency detection methods have achieved gratifying progress benefiting from the development of deep learning . However, the existing methods always fail to make full use of the label information. To address this problem, we focus on the complementarity of salient body information and salient detail information within the labels and propose the Interactive Branch Network (IBNet) in this paper. Generally, IBNet contains three components of Label Redefinition Module (LRM), Information Exchange Module (IEM) and Connected Flow Loss (CFL). These three components all play an enormously important role in the complementary performance of detection. In LRM, enough useful and meaningful heuristic knowledge from the given labels is expanded for dynamic and collaborative supervised learning. In IEM, different derived branches are assigned to collect different types of features for interactive fusion. In CFL, the losses from all connected branches are merged to calculate the total loss. Extensive experiments on benchmark datasets exhibit the effectiveness and efficiency of the proposed method against the state-of-the-art approaches. The source code is publicly available at https://github.com/xianfangfx/IBNet .},
  archive      = {J_NEUCOM},
  author       = {Xian Fang and Jinchao Zhu and Ruixun Zhang and Xiuli Shao and Hongpeng Wang},
  doi          = {10.1016/j.neucom.2021.09.013},
  journal      = {Neurocomputing},
  pages        = {574-583},
  shortjournal = {Neurocomputing},
  title        = {IBNet: Interactive branch network for salient object detection},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mask-guided contrastive attention and two-stream metric
co-learning for person re-identification. <em>NEUCOM</em>, <em>465</em>,
561–573. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person Re-identification (ReID) is an important yet challenging task in computer vision. Due to diverse background clutters, variations of viewpoints and body poses, it is far from being solved. How to extract discriminative and robust features invariant to background clutters is one of the core problems. In this paper, we first introduce a set of binary segmentation masks to construct synthetic RGB-Mask pairs as inputs, and then design a mask-guided contrastive attention model (MGCAM) to learn features separately from the body and background regions. Moreover, we propose a novel region-level triplet loss to guide the features learning , i.e., pulling the features from the full image and body region close, whereas pushing the features from backgrounds away. To learn the similarities from multiple features of the proposed MGCAM, we further introduce the instance-level two-stream metric co-learning (TSMCL) to help learn pair-wise relations between features from not only different regions but also different instances. TSMCL could help learn more compact features across full and body streams, enhancing the performance of MGCAM. We evaluate the proposed method on four public datasets, including MARS, Market-1501, CUHK03, and DukeMTMC-reID. Extensive experiments show that the proposed method is effective and achieves satisfying results.},
  archive      = {J_NEUCOM},
  author       = {Chunfeng Song and Caifeng Shan and Yan Huang and Liang Wang},
  doi          = {10.1016/j.neucom.2021.09.038},
  journal      = {Neurocomputing},
  pages        = {561-573},
  shortjournal = {Neurocomputing},
  title        = {Mask-guided contrastive attention and two-stream metric co-learning for person re-identification},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hierarchical and parallel framework for end-to-end
aspect-based sentiment analysis. <em>NEUCOM</em>, <em>465</em>, 549–560.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pipeline, joint, and collapsed models are three major approaches to solving End-to-End Aspect-based Sentiment Analysis (E2E-ABSA) task. Prior works found that joint models were consistently surpassed by the other two. To explore the potential of joint model for E2E-ABSA, we propose a hierarchical and parallel joint framework on the basis of exploiting the hierarchical nature of the pre-trained language model and performing parallel inference of the subtasks. Our framework: (1) shares the same pre-trained backbone network between two subtasks, ensuring the associations and commonalities between them; (2) considers the hierarchical feature of the deep neural network and introduces two joint approaches, namely the specific-layer joint model and multiple-layer joint model, coupling two specific layers or multiple task-related layers with subtasks; (3) carries out parallel execution in both training and inference processes, improving the inference throughput and al-leviating the target-polarity mismatch problem. The experimental results on three benchmark datasets demonstrate that our approach outperforms the state-of-the-art works.},
  archive      = {J_NEUCOM},
  author       = {Ding Xiao and Feiyang Ren and Xiaoxuan Pang and Ming Cai and Qianyu Wang and Ming He and Jiawei Peng and Hao Fu},
  doi          = {10.1016/j.neucom.2021.09.021},
  journal      = {Neurocomputing},
  pages        = {549-560},
  shortjournal = {Neurocomputing},
  title        = {A hierarchical and parallel framework for end-to-end aspect-based sentiment analysis},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TimNet: A text-image matching network integrating
multi-stage feature extraction with multi-scale metrics.
<em>NEUCOM</em>, <em>465</em>, 540–548. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text image comparison is a core component in web consistency testing across browsers. Previous studies mainly focused on general image comparison, which could not best suit the proposed task since text images share unique properties. In this paper, we introduce a novel Text-Image Matching Network (TimNet) to detect text differences in image pairs. A Multi-Stage Feature Extraction module (MFE) is integrated in TimNet to extract not only non-textual content features but also text-like features that are temporally aligned. Moreover, TimNet is composed of a Multi-Scale Metric module (MM) to measure the similarity between two text images with various scales and aspect ratios. Accordingly, a Text-Image Similarity Database (TISDB) consisting of 615.6 k text-image pairs of English characters, Chinese characters, and Arabic numbers was established. Extensive experiments were conducted to demonstrate that our TimNet outperforms existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqi Zheng and Yingfan Tao and Ruikai Zhang and Wenming Yang and Qingmin Liao},
  doi          = {10.1016/j.neucom.2021.09.001},
  journal      = {Neurocomputing},
  pages        = {540-548},
  shortjournal = {Neurocomputing},
  title        = {TimNet: A text-image matching network integrating multi-stage feature extraction with multi-scale metrics},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). Improved almost sure stability criteria of stochastic
complex-valued dynamical networks with hybrid impulses. <em>NEUCOM</em>,
<em>465</em>, 525–539. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, exponential stability of stochastic complex-valued dynamical networks with hybrid impulses is considered. Therein, different from the existing works on the moment stability of stochastic complex-valued systems, almost sure exponential stability is studied, in which noise contributes to the stability of the system. Hybrid impulses, which allows that a kind of impulsive sequence includes stabilizing and destabilizing impulses simultaneously, are first exerted on stochastic complex-valued networks. In light of Lyapunov method, stochastic analysis theory, average impulsive interval and average impulsive gain, we establish improved almost sure exponential stability criteria under the two situations that average impulsive interval T a Ta satisfies T a Ta&amp;lt;+∞ and T a = + ∞ Ta=+∞ separately. The stability criteria we addressed possess two characteristics as follows. Firstly, time-derivatives of the Lyapunov functions are permitted to be indefinite, even unbounded, based on indefinite Lyapunov functions , which results in lower conservative consequence. Secondly, it is worth noting that the mutual restrains among average impulsive gain, average impulsive interval and the noise intensity are represented in the improved criteria. Besides, the theoretical results are directly applied to study the stability of stochastic systems with aperiodically intermittent noise. Finally, an application to inertial complex-valued neural networks and several numerical examples are provided to show the feasibility and advantages of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Sen Li and Jiankun Sun and Xiaohua Ding},
  doi          = {10.1016/j.neucom.2021.08.043},
  journal      = {Neurocomputing},
  pages        = {525-539},
  shortjournal = {Neurocomputing},
  title        = {Improved almost sure stability criteria of stochastic complex-valued dynamical networks with hybrid impulses},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring attention mechanisms based on summary information
for end-to-end automatic speech recognition. <em>NEUCOM</em>,
<em>465</em>, 514–524. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have confirmed that attention mechanisms with location constraint strategy are helpful to reduce the misrecognition caused by incorrect alignments in attention-based end-to-end automatic speech recognition (E2E ASR) systems. The significant advantage of these mechanisms is that they consider the monotonicity of the alignment by employing a location constraint vector. This vector is directly obtained from historical attention scores for most such attention mechanisms . However, an unreasonable vector may become an additional interference when an inaccurate historical attention score occurs. Moreover, the subsequent process of attention scoring will be affected by the interference continuously. To address the problem, we obtain a reasonable location constraint vector from the matching relationship between the historical output information and the summary information, where the summary information includes content and temporal information about speech sequence. We further propose an enhanced location constrained attention mechanism, i.e., summary constrained (SC) attention mechanism, to generate the vector by a matching relationship-based neural network . We use a summary subspace embedding learned by a linear subspace projection to represent the summary information. Furthermore, considering the complementarity of the SC and typical location constrained attention mechanisms, a fused attention mechanism is used to generate a more reasonable vector by combining the two mechanisms. The SC and fused attention mechanisms-based E2E ASR systems were evaluated on a Switchboard conversational telephone speech recognition. The experimental results show that our mechanisms obtained the relative reductions of 10.6\% 10.6\% and 16.7\% 16.7\% in the word error rate compared with the baseline system.},
  archive      = {J_NEUCOM},
  author       = {Jiabin Xue and Tieran Zheng and Jiqing Han},
  doi          = {10.1016/j.neucom.2021.09.017},
  journal      = {Neurocomputing},
  pages        = {514-524},
  shortjournal = {Neurocomputing},
  title        = {Exploring attention mechanisms based on summary information for end-to-end automatic speech recognition},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flocking of uncertain nonlinear multi-agent systems via
distributed adaptive event-triggered control. <em>NEUCOM</em>,
<em>465</em>, 503–513. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates flocking problems with uncertain nonlinear multi-agent systems. Two distributed adaptive event-triggered control algorithms are proposed for leaderless and leader-follower flocking, separately. According to Lyapunov stability theory , under the proposed control protocols, we obtain some sufficient conditions to ensure stable flocking motion and maintain connectivity of network topology . And it is proven that there is a positive lower limit of the interval between any two trigger events, which indicates that the Zeno behavior will not occur. As a result, communication bandwidth resources are effectively saved on the premise of stable flocking. Lastly, numerical simulations are presented to verify the availability of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Yong Zou and Qing An and Suoxia Miao and Shiming Chen and Xiaoming Wang and Housheng Su},
  doi          = {10.1016/j.neucom.2021.09.005},
  journal      = {Neurocomputing},
  pages        = {503-513},
  shortjournal = {Neurocomputing},
  title        = {Flocking of uncertain nonlinear multi-agent systems via distributed adaptive event-triggered control},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BINet: Bidirectional interactive network for salient object
detection. <em>NEUCOM</em>, <em>465</em>, 490–502. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing state-of-the-art methods for salient object detection mainly achieve significant progress by integrating multi-level features. However, most of them simply resize the multi-level features to the same spatial resolution and aggregate them by channel-wise concatenation or element-wise addition. Thus, they are limited to integrating features of adjacent layers due to large discrepancy between these multi-level features. Besides, most existing methods adopt the U-shape architecture where high-level semantic information is gradually transmitted to shallower layers to suppress the background noises. Nonetheless, little attention has been paid to refine high-level features. In this paper, we propose the BINet to solve the above problems. Specifically, we design the feature interaction module (FIM) to exploit complementary information between multiple features, which is then utilized to simultaneously refine these features. Besides, we propose the cascaded bidirectional interaction decoder (CBID) to further refine multi-level features iteratively. Our CBID progressively refines multi-level features with feedback mechanisms and employs a channel attention module (CAM) to assign larger weights to channels showing higher response to salient regions . Equipped with these modules, our BINet is capable of segmenting salient regions accurately and quickly. Experimental results on six widely used benchmark datasets validate that our BINet outperforms 16 other state-of-the-art methods in terms of 7 standard evaluation metrics . Our code will be publicly available at https://github.com/clelouch/BINet .},
  archive      = {J_NEUCOM},
  author       = {Tianyou Chen and Xiaoguang Hu and Jin Xiao and Guofeng Zhang and Shaojie Wang},
  doi          = {10.1016/j.neucom.2021.09.020},
  journal      = {Neurocomputing},
  pages        = {490-502},
  shortjournal = {Neurocomputing},
  title        = {BINet: Bidirectional interactive network for salient object detection},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble deep neural network based quality of service
prediction for cloud service recommendation. <em>NEUCOM</em>,
<em>465</em>, 476–489. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applications of Cloud Services are increasing day by day, and so is the difficulty of choosing the best-suited service for a customer. Quality of Service (QoS) parameters can be used for quality assurance and evaluation; further, a service can be recommended based on these QoS parameters’ values. Recommendation systems are getting much attention lately. It has a crucial role in almost all the major commercial platforms and many improvements are being made to make the recommendations more precise and closer to the user’s requirements. Conventional Machine Learning algorithms and statistical analysis methods, presently are not that efficient in learning the complex correlation between data elements. Lately, Deep Learning models have proven to be practical and precise in areas like natural language processing, image processing, data mining, &amp; data interpretation. However, there are not many examples of complete Deep Learning applications for cloud service recommendation systems, though some works partially use Deep Learning. We propose the Ensemble of Deep Neural Networks (EDNN) method, which is of the hybrid type, i.e., the fusion of neighborhood-based and neural network model-based methods. The output obtained from both the models are combined using another different neural network model. Our approach for predicting QoS values is simple and different from previous works, and the results show that it outperforms other classical methods marginally.},
  archive      = {J_NEUCOM},
  author       = {Parth Sahu and S. Raghavan and K. Chandrasekaran},
  doi          = {10.1016/j.neucom.2021.08.110},
  journal      = {Neurocomputing},
  pages        = {476-489},
  shortjournal = {Neurocomputing},
  title        = {Ensemble deep neural network based quality of service prediction for cloud service recommendation},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-sensitive zero-shot semantic segmentation model
based on meta-learning. <em>NEUCOM</em>, <em>465</em>, 465–475. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The zero-shot semantic segmentation requires models with a strong image understanding ability. The majority of current solutions are based on direct mapping or generation. These schemes are effective in dealing with the zero-shot recognition, but they cannot fully transfer the visual dependence between objects in more complex scenarios of semantic segmentation . More importantly, the predicted results become seriously biased to the seen-category in the training set, which makes it difficult to accurately recognize the unseen-category. In view of the above two problems, we propose a novel zero-shot semantic segmentation model based on meta-learning. It is observed that the pure semantic space expression has certain limitations for the zero-shot learning. Therefore, based on the original semantic migration, we first migrate the shared information in the visual space by adding a context-module, and then migrate it in the visual and semantic dual space. At the same time, in order to solve the problem of biasness, we improve the adaptability of the model parameters by adjusting the parameters of the dual-space through the meta-learning, so that it can successfully complete the segmentation even in the face of new categories without reference samples. Experiments show that our algorithm outperforms the existing best methods in the zero-shot segmentation on three datasets of Pascal-VOC 2012, Pascal-Context and Coco-stuff.},
  archive      = {J_NEUCOM},
  author       = {Wenjian Wang and Lijuan Duan and Qing En and Baochang Zhang},
  doi          = {10.1016/j.neucom.2021.08.120},
  journal      = {Neurocomputing},
  pages        = {465-475},
  shortjournal = {Neurocomputing},
  title        = {Context-sensitive zero-shot semantic segmentation model based on meta-learning},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi visual and textual embedding on visual question
answering for blind people. <em>NEUCOM</em>, <em>465</em>, 451–464. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual impairment community, especially blind people have a thirst for assistance from advanced technologies for understanding and answering the image. Through the development and intersection between vision and language, Visual Question Answering (VQA) is to predict an answer from a textual question on an image. It is essential and ideal to help blind people with capturing the image and answering their questions automatically. Traditional approaches often utilize the strength of convolution and recurrent networks, which requires a great effort for learning and optimizing. A key challenge in VQA is finding an effective way to extract and combine textual and visual features. To take advantage of previous knowledge in different domains, we propose BERT-RG, the delicate integration of pre-trained models into feature extractors, which relies on the interaction between residual and global features in the image and linguistic features in the question. Moreover, our architecture integrates a stacked attention mechanism that exploits the relationship between textual and visual objects. Specifically, the partial regions of images interact with partial keywords in question to enhance the text-vision representation. Besides, we also propose a novel perspective by considering a specific question type in VQA. Our proposal is significantly meaningful enough to develop a specialized system instead of putting forth the effort to dig for unlimited and unrealistic approaches. Experiments on VizWiz-VQA, a practical benchmark dataset, show that our proposed model outperforms existing models on the VizWiz VQA dataset in the Yes/No question type.},
  archive      = {J_NEUCOM},
  author       = {Tung Le and Huy Tien Nguyen and Minh Le Nguyen},
  doi          = {10.1016/j.neucom.2021.08.117},
  journal      = {Neurocomputing},
  pages        = {451-464},
  shortjournal = {Neurocomputing},
  title        = {Multi visual and textual embedding on visual question answering for blind people},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MVSN: A multi-view stack network for human parsing.
<em>NEUCOM</em>, <em>465</em>, 437–450. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human parsing task is dedicated to allocating pixel-level fine-grained semantic labels . However, recent solutions are limited to fully utilize the prior information (poses and edges) and the potential information of the image data, remaining problems with ambiguous boundaries, incomplete human parts, and redundant labels. To solve the above problems, we propose a novel Multi-view Stack Network (MVSN), which is constructed by three stacks with multiple views of features included parts, edges, and pre-segmentation. Meanwhile, a channel correlator is developed to acquire the correlation between local and global information better. Comprehensive experiments and corresponding results on three public datasets show that the proposed MVSN performs favorably against the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhuo Su and Minshi Chen and Enbo Huang and Ge Lin and Fan Zhou},
  doi          = {10.1016/j.neucom.2021.08.124},
  journal      = {Neurocomputing},
  pages        = {437-450},
  shortjournal = {Neurocomputing},
  title        = {MVSN: A multi-view stack network for human parsing},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Surface mounted devices classification using a mixture
network of DCNN and DFCN. <em>NEUCOM</em>, <em>465</em>, 428–436. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In tradition, surface mounted devices (SMD) are classified and registered manually in surface mount technology (SMT). Manual classification is inefficient and relies on the experience of the operators. We propose a novel SMD classification method based on a mixture neural network. The network contains two modules, one is a convolutional neural network with a gray image as input, and the other is a fully connected network with a Hand-Crafted feature as input. The lighting environment of chip has a great impact on chip imaging, and the classification method should maintain sufficient robustness against light changes in SMT. However, there is a lack of a robust feature extraction method for SMT classification against illumination changes. A novel feature extraction method based the characteristics of the binary chip image is first proposed, which is composed of the mathematical statistical pin parameters of SMD. As the light changes, the binary image is relatively stable, making the proposed feature is invariant to light changes. An SMD dataset in SMT contains 61 kinds of chips is built for training and testing. Experiments on this dataset demonstrate that our method is more effective than the state-of-the-art methods in terms of performance measures.},
  archive      = {J_NEUCOM},
  author       = {Weihua Liu and Hao Sun and Zhixiang Jia and Xinghu Yu},
  doi          = {10.1016/j.neucom.2021.09.011},
  journal      = {Neurocomputing},
  pages        = {428-436},
  shortjournal = {Neurocomputing},
  title        = {Surface mounted devices classification using a mixture network of DCNN and DFCN},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive anatomically constrained deep neural network for
3D deformable medical image registration. <em>NEUCOM</em>, <em>465</em>,
417–427. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 3D deformable image registration is one of the most challenging tasks in medical image analysis. Due to the large and complex deformation in 3D medical images, many deep neural network based methods have been proposed to improve the image similarity after registration, among which recursive cascading network structure is one of the state-of-the-art. However, most existing works rely on the pixel-level image similarities to achieve anatomical rationality and overlook the global-level resemblance between the two structures. Therefore, the resulting registration is not quite clinically valuable. To this end, in this work, we propose a Progressive Anatomically Constrained deep neural Network (PACN) to incorporate the anatomical priors into a progressive cascading registration network to improve the anatomical plausibility as well as the pixel-level similarity of the registration results. Specifically, an Anatomical Constraint Encoder (ACE) network is proposed to encode the global context of the anatomical segmentations and attached to the dense registration network to form a registration unit. Repeated such units forming a cascading framework progressively warps the moving image toward the fixed one, with the output warped image of one unit as the input of the next unit. In this design, the global anatomical priors along with the pixel-level local information are used to guide the model learning process to produce high quality deformation field . Based on this, we explore two frameworks to investigate their registration effectiveness, one attaches the anatomical constraint encoder (ACE) to every dense registration sub-network and the other one attaches ACE only to the last dense registration unit. We test the two frameworks on benchmarks of three liver image datasets SLIVER, LiTS and LSPIG, and one brain dataset LPBA. Our two frameworks have achieved significantly better results in terms of average Dice score than the state-of-the-art baseline method on three liver datasets and comparable on LPBA when both tested with up to three cascades.},
  archive      = {J_NEUCOM},
  author       = {Zhiyuan Zheng and Wenming Cao and Zhiquan He and Yi Luo},
  doi          = {10.1016/j.neucom.2021.08.097},
  journal      = {Neurocomputing},
  pages        = {417-427},
  shortjournal = {Neurocomputing},
  title        = {Progressive anatomically constrained deep neural network for 3D deformable medical image registration},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IAE-ClusterGAN: A new inverse autoencoder for generative
adversarial attention clustering network. <em>NEUCOM</em>, <em>465</em>,
406–416. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a challenging and crucial task in unsupervised learning . Recently, though many clustering algorithms combined with deep learning have been proposed, we observe that the existing deep clustering algorithms do not considerably preserve the clustering structure and information of raw data in the learned latent space. To address this issue, we propose a Generative Adversarial Attention Clustering network Based on Inverse autoencoder (IAE-ClusterGAN), which can control the distribution type of the learned latent code without additional constraints so that unsupervised clustering tasks can be done efficiently. Meanwhile, we integrate the attention mechanism into the network to make the latent code contain more useful clustering information. Moreover, we utilize hyperspherical mapping in the discriminator to improve the stability of model training and reduce the training parameters. Experimental results demonstrate that IAE-ClusterGAN achieves competitive results compared to the state-of-the-art models on five benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Chao Ling and Guitao Cao and Wenming Cao and Hong Wang and He Ren},
  doi          = {10.1016/j.neucom.2021.08.128},
  journal      = {Neurocomputing},
  pages        = {406-416},
  shortjournal = {Neurocomputing},
  title        = {IAE-ClusterGAN: A new inverse autoencoder for generative adversarial attention clustering network},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Statistical generalization performance guarantee for
meta-learning with data dependent prior. <em>NEUCOM</em>, <em>465</em>,
391–405. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Meta-learning aims to leverage experience from previous tasks to achieve an effective and fast adaptation ability when encountering new tasks. However, it is unclear how the generalization property applies to new tasks. Probably approximately correct (PAC) Bayes bound theory provides a theoretical framework to analyze the generalization performance for meta-learning with an explicit numerical generalization error upper bound. A tighter upper bound may achieve better generalization performance. However, for the PAC-Bayes meta-learning bound, the prior distribution is selected randomly which results in poor generalization performance. In this paper, we derive three novel generalization error upper bounds for meta-learning based on the PAC-Bayes relative entropy bound. Furthermore, in order to avoid randomly prior distribution, based on the empirical risk minimization (ERM) method, a data-dependent prior for the PAC-Bayes meta-learning bound algorithm is developed and the sample complexity and computational complexity are analyzed. The experiments illustrate that the proposed three PAC-Bayes bounds for meta-learning achieve a competitive generalization guarantee, and the extended PAC-Bayes bound with a data-dependent prior can achieve rapid convergence ability.},
  archive      = {J_NEUCOM},
  author       = {Tianyu Liu and Jie Lu and Zheng Yan and Guangquan Zhang},
  doi          = {10.1016/j.neucom.2021.09.018},
  journal      = {Neurocomputing},
  pages        = {391-405},
  shortjournal = {Neurocomputing},
  title        = {Statistical generalization performance guarantee for meta-learning with data dependent prior},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Federated learning on non-IID data: A survey.
<em>NEUCOM</em>, <em>465</em>, 371–390. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning is an emerging distributed machine learning framework for privacy preservation . However, models trained in federated learning usually have worse performance than those trained in the standard centralized learning mode, especially when the training data are not independent and identically distributed (Non-IID) on the local devices. In this survey, we provide a detailed analysis of the influence of Non-IID data on both parametric and non-parametric machine learning models in both horizontal and vertical federated learning. In addition, current research work on handling challenges of Non-IID data in federated learning are reviewed, and both advantages and disadvantages of these approaches are discussed. Finally, we suggest several future research directions before concluding the paper.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Jinjin Xu and Shiqing Liu and Yaochu Jin},
  doi          = {10.1016/j.neucom.2021.07.098},
  journal      = {Neurocomputing},
  pages        = {371-390},
  shortjournal = {Neurocomputing},
  title        = {Federated learning on non-IID data: A survey},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ER-SQL: Learning enhanced representation for text-to-SQL
using table contents. <em>NEUCOM</em>, <em>465</em>, 359–370. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text-to-SQL emerges to play an important role in interactive data analysis, which provides a friendly interface for converting natural language into relational database language (i.e., SQL). In order to translate a user’s query into an executable SQL statement, semantic parsing is essential to the transformation process. In particular, existing efforts provide some feasible solutions, and state-of-the-art models mainly adopt the sketch-based paradigm such that template values are to be filled. To this end, most methods extract values based on column representations. However, if the query contains multiple values that belong to different columns, these methods may fail to extract the values accurately. Moreover, it can be difficult to infer the right values when the query does not explicitly mention the corresponding column names. To bridge the gap, we propose a novel neural architecture, namely, ER-SQL for learning enhanced representations for Text-to-SQL. Based on pre-trained model BERT , ER-SQL uses column contents to better extract features of columns. Moreover, ER-SQL harnesses the column representations to latently reformulate the query. To verify the effectiveness of ER-SQL , comprehensive experiments demonstrate that ER-SQL achieves better results than existing models on the benchmark dataset WikiSQL , as well as on a representative Chinese dataset TableQA .},
  archive      = {J_NEUCOM},
  author       = {Aibo Guo and Xiang Zhao and Wubin Ma},
  doi          = {10.1016/j.neucom.2021.08.134},
  journal      = {Neurocomputing},
  pages        = {359-370},
  shortjournal = {Neurocomputing},
  title        = {ER-SQL: Learning enhanced representation for text-to-SQL using table contents},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An area and energy efficient LIF neuron model with spike
frequency adaptation mechanism. <em>NEUCOM</em>, <em>465</em>, 350–358.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As neuron is the fundamental unit of the nervous system , it is one of the main building blocks in the spiking neural networks hardware implementation. To implement hardware that consists of many thousands of neurons and accurately mimics the brain functions, an energy and area-efficient design for the neuron is essential. In this paper, we propose a VLSI circuit for the leaky integrate and fire (LIF) neuron model, in 130 nm CMOS technology. The proposed neuron has some important features: first, it consumes very low energy; second, it is simple and area-efficient. Third, it has the spike frequency adaptation capability that makes it more biologically plausible. The spike frequency adaptation mechanism is added to the model only by one additional transistor, and it is done just by one parameter. The energy per spike of the neuron circuit in the worst case is only 0.67 fJ/spike. The spike frequency is in the MHz range, which enables attractive hardware acceleration .},
  archive      = {J_NEUCOM},
  author       = {Maryam Zare and Elnaz Zafarkhah and Nima S. Anzabi-Nezhad},
  doi          = {10.1016/j.neucom.2021.09.004},
  journal      = {Neurocomputing},
  pages        = {350-358},
  shortjournal = {Neurocomputing},
  title        = {An area and energy efficient LIF neuron model with spike frequency adaptation mechanism},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Geometric and semantic analysis of road image sequences for
traffic scene construction. <em>NEUCOM</em>, <em>465</em>, 336–349. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a traffic scene construction framework is proposed based on geometric and semantic analysis of road image sequences using convolutional neural networks (CNNs). For geometric analysis branch of the framework, the image features and heatmaps are extracted to locate the keypoints of road boundaries by CNN. The recurrent module is employed to refine the heatmap prediction to generate more accurate keypoints. The scene layout is then specified according to the keypoints. For semantic segmentation branch of the framework, an encoder-decoder mechanism is utilized to divide the scene layout. A hall module is developed to connect the encoder and decoder parts, which improves the segmentation performance for tiny objects with lower computation cost. Furthermore, the 3D traffic scene models are constructed according to the geometric and semantic analysis results. The traffic simulation can be implemented based on the scene models. The extensive evaluations and comparisons demonstrate the effectiveness of the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Yaochen Li and Chao Zhu and Yuehu Liu and Yuhui Hong and Jianji Wang},
  doi          = {10.1016/j.neucom.2021.09.002},
  journal      = {Neurocomputing},
  pages        = {336-349},
  shortjournal = {Neurocomputing},
  title        = {Geometric and semantic analysis of road image sequences for traffic scene construction},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Component-mixing strategy: A decomposition-based data
augmentation algorithm for motor imagery signals. <em>NEUCOM</em>,
<em>465</em>, 325–335. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has achieved a remarkable success in areas such as brain-computer interface systems (BCI). However, electroencephalography (EEG) signals evoked by motor imagery (MI) are sometimes limited in their amount due to invalid data caused by the subjects’ fatigue, leading to a performance degradation . To this end, in this work we extend empirical mode decomposition into multivariate empirical mode decomposition and intrinsic time-scale decomposition, proposing a component-mixing strategy (CMS) for MI data augmentation . Compared to commonly used data augmentation methods such as generative adversarial networks , CMS can generate artificial trials from a few training samples without any required training . We claim that raw and artificial data generated by CMS are consistent with respect to the distribution and power spectral density . Experiments done on the BCI Competition IV dataset 2b show that CMS can achieve a considerable improvement on the binary classification accuracy and the area under the curve score using EEGNet, wavelet neural networks and a support vector machine .},
  archive      = {J_NEUCOM},
  author       = {Binghua Li and Zhiwen Zhang and Feng Duan and Zhenglu Yang and Qibin Zhao and Zhe Sun and Jordi Solé-Casals},
  doi          = {10.1016/j.neucom.2021.08.119},
  journal      = {Neurocomputing},
  pages        = {325-335},
  shortjournal = {Neurocomputing},
  title        = {Component-mixing strategy: A decomposition-based data augmentation algorithm for motor imagery signals},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulated annealing for optimization of graphs and
sequences. <em>NEUCOM</em>, <em>465</em>, 310–324. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization of discrete structures aims at generating a new structure with the better property given an existing one, which is a fundamental problem in machine learning . Different from the continuous optimization , the realistic applications of discrete optimization (e.g., text generation) are very challenging due to the complex and long-range constraints, including both syntax and semantics, in discrete structures. In this work, we present SAGS, a novel Simulated Annealing framework for Graph and Sequence optimization. The key idea is to integrate powerful neural networks into metaheuristics (e.g., simulated annealing, SA) to restrict the search space in discrete optimization. We start by defining a sophisticated objective function, involving the property of interest and pre-defined constraints (e.g., grammar validity). SAGS searches from the discrete space towards this objective by performing a sequence of local edits, where deep generative neural networks propose the editing content and thus can control the quality of editing. We evaluate SAGS on paraphrase generation and molecule generation for sequence optimization and graph optimization, respectively. Extensive results show that our approach achieves state-of-the-art performance compared with existing paraphrase generation methods in terms of both automatic and human evaluations. Further, SAGS also significantly outperforms all the previous methods in molecule generation.},
  archive      = {J_NEUCOM},
  author       = {Xianggen Liu and Pengyong Li and Fandong Meng and Hao Zhou and Huasong Zhong and Jie Zhou and Lili Mou and Sen Song},
  doi          = {10.1016/j.neucom.2021.09.003},
  journal      = {Neurocomputing},
  pages        = {310-324},
  shortjournal = {Neurocomputing},
  title        = {Simulated annealing for optimization of graphs and sequences},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recognition of grammatical class of imagined words from EEG
signals using convolutional neural network. <em>NEUCOM</em>,
<em>465</em>, 301–309. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a framework using multi-channel convolutional neural network (MC–CNN) for recognizing the grammatical class (verb or noun) of covertly-spoken words from electroencephalogram (EEG) signals. Our proposed network extracts features by taking into account spatial, temporal, and spectral properties of the EEG signal. Further, sets of signals acquired from different regions of the brain are processed separately within the proposed framework and are subsequently combined at the classification stage. This approach enables the network to effectively learn discriminative features from the locations of the brain where imagined speech is processed. Our network was tested using challenging experiments, including cases where the test subject did not take part in system training. In our main application scenario, where no instance of a specific noun or verb was used during training, our method achieved 85.7\% recognition. Further, our proposed method was evaluated on a publicly available EEG dataset and achieved recognition rate of 93.8\% in binary classification . These results demonstrate the potential of our method.},
  archive      = {J_NEUCOM},
  author       = {Sahil Datta and Nikolaos V. Boulgouris},
  doi          = {10.1016/j.neucom.2021.08.035},
  journal      = {Neurocomputing},
  pages        = {301-309},
  shortjournal = {Neurocomputing},
  title        = {Recognition of grammatical class of imagined words from EEG signals using convolutional neural network},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep graph alignment network. <em>NEUCOM</em>, <em>465</em>,
289–300. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph alignment, also known as network alignment has many applications in data mining tasks. It aims to find the node correspondence across disjoint graphs. Recently, various methods like representation learning methods, spectral methods have been proposed to solve the graph alignment problem, but they either only consider the local structure information but ignore the neighborhood similarity, or their alignment process is easy to be disturbed by nodes with similar structure or attribute. In this paper, we consider both center and neighborhood similarities, aiming to reduce the inconsistency between them and enlarge the difference among node representations. We further propose model DGAN( D eep G raph A lignment N etwork) containing the DNN module and GCN module to learn more unique node representations under the guidance of the attribute-supervised module. Moreover, we theoretically prove that most spectral methods can be unified into a linear GCN model. By extensive experiments on public benchmarks, we show that our model achieves a good balance between alignment accuracy and speed over multiple datasets compared with existing methods.},
  archive      = {J_NEUCOM},
  author       = {Wei Tang and Jingyu Wang and Qi Qi and Haifeng Sun and Shimin Tao and Hao Yang},
  doi          = {10.1016/j.neucom.2021.08.135},
  journal      = {Neurocomputing},
  pages        = {289-300},
  shortjournal = {Neurocomputing},
  title        = {Deep graph alignment network},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interval joint robust regression method. <em>NEUCOM</em>,
<em>465</em>, 265–288. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interval-valued data are needed to manage either the uncertainty related to measurements, or the variability inherent to the description of complex objects representing group of individuals. A number of regression methods suitable to interval variables describing variability of complex objects are already available. However, less attention has been given to methods that, simultaneously, take into account the full interval information and are resistant to interval outlier observations, even with the frequent presence of atypical observations on interval-valued data sets. This paper proposes a new robust linear regression method for interval variables, where the presence of outliers either in the center or in the radius penalize both the center and the radius regression models. Moreover, the interval observations with outliers on both center and radius are more penalized than those observations with outliers only in the center (or in the radius). Besides, this paper provides a suitable iterative algorithm to estimate the parameters of the proposed method. The algorithm estimates the parameters of the center (or of the radius) model taking into account both information of the center and the radius. The convergence and time complexity of the iterative algorithm are also presented. Finally, the performance of the new method is compared with some previous robust regression approaches and evaluated on synthetic and real interval-valued data sets.},
  archive      = {J_NEUCOM},
  author       = {Francisco de A.T. de Carvalho and Eufrásio de A. Lima Neto and Ullysses da N. Rosendo},
  doi          = {10.1016/j.neucom.2021.08.129},
  journal      = {Neurocomputing},
  pages        = {265-288},
  shortjournal = {Neurocomputing},
  title        = {Interval joint robust regression method},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards information-rich, logical dialogue systems with
knowledge-enhanced neural models. <em>NEUCOM</em>, <em>465</em>,
248–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue systems have made massive promising progress contributed by deep learning techniques and have been widely applied in our life. However, existing end-to-end neural models suffer from the problem of tending to generate uninformative and generic responses because they cannot ground dialogue context with background knowledge. In order to solve this problem, many researchers begin to consider combining external knowledge in dialogue systems, namely knowledge-enhanced dialogue systems. The challenges of knowledge-enhanced dialogue systems include how to select the appropriate knowledge from large-scale knowledge bases, how to read and understand extracted knowledge, and how to integrate knowledge into responses generation process. Combined with external knowledge, dialogue systems can deeply understand the dialogue context, and generate more informative and logical responses. This survey gives a comprehensive review of knowledge-enhanced dialogue systems, summarizes research progress to solve these challenges and proposes some open issues and research directions.},
  archive      = {J_NEUCOM},
  author       = {Hao Wang and Bin Guo and Wei Wu and Sicong Liu and Zhiwen Yu},
  doi          = {10.1016/j.neucom.2021.08.131},
  journal      = {Neurocomputing},
  pages        = {248-264},
  shortjournal = {Neurocomputing},
  title        = {Towards information-rich, logical dialogue systems with knowledge-enhanced neural models},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SGUNet: Style-guided UNet for adversely conditioned fundus
image super-resolution. <em>NEUCOM</em>, <em>465</em>, 238–247. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution from low-resolution fundus image has valuable applications in clinical practices. The popular methods yield unsatisfactory results when the fundus images are contaminated due to the bleeding or plaques caused by eye diseases . To this end, we propose a style-guided UNet (SGUNet) which incorporates a series of style-guided U-shape block (SUB) for fundus image super-resolution. Each SUB consists of trunk and mask branches. The proposed trunk branch is a U-shape structure that intends to enlarge the receptive field by down-sampling via large-stride convolution, and fuses the complementary information under the different receptive fields. The mask branch then dynamically estimates the relative importance of individual potential styles to reweigh the feature maps according to the significance of the potential styles. To fully leverage the hierarchical features, a dense feature fusion scheme is introduced by concatenating the output of preceding SUBs. We extensively validate the proposed network on low-resolution retina dataset with adversely affected by diseases. The experimental results demonstrate that our SGUNet achieves superior performance with excellent robustness and high accuracy by comparing with six popular methods.},
  archive      = {J_NEUCOM},
  author       = {Zhihao Fan and Tingting Dan and Baoyi Liu and Xiaoqi Sheng and Honghua Yu and Hongmin Cai},
  doi          = {10.1016/j.neucom.2021.08.137},
  journal      = {Neurocomputing},
  pages        = {238-247},
  shortjournal = {Neurocomputing},
  title        = {SGUNet: Style-guided UNet for adversely conditioned fundus image super-resolution},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting video engagement using heterogeneous DeepWalk.
<em>NEUCOM</em>, <em>465</em>, 228–237. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video engagement is important in online advertisements where there is no physical interaction with the consumer. Engagement can be directly measured as the number of seconds after which a consumer skips an advertisement. In this paper, we propose a model to predict video engagement of an advertisement using only a few samples. This allows for early identification of poor quality videos. This can also help identify advertisement frauds where a robot runs fake videos behind the name of well-known brands. We leverage on the fact that videos with high engagement have similar viewing patterns over time. Hence, we can create a similarity network of videos and use a graph-embedding model called DeepWalk to cluster videos into significant communities. The learned embedding is able to identify viewing patterns of fraud and popular videos. In order to assess the impact of a video, we also consider how the view counts increase or decrease over time. This results in a heterogeneous graph where an edge indicates similar video engagement or history of view counts between two videos. Since it is difficult to find labelled samples for ‘fraud’ video, we leverage on a one-class model that can determine ‘fraud’ videos with outlier or abnormal behavior. The proposed model outperforms baselines in F-measure by over 20\%\% .},
  archive      = {J_NEUCOM},
  author       = {Iti Chaturvedi and Kishor Thapa and Sandro Cavallari and Erik Cambria and Roy E. Welsch},
  doi          = {10.1016/j.neucom.2021.08.127},
  journal      = {Neurocomputing},
  pages        = {228-237},
  shortjournal = {Neurocomputing},
  title        = {Predicting video engagement using heterogeneous DeepWalk},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel few-shot learning method for synthetic aperture
radar image recognition. <em>NEUCOM</em>, <em>465</em>, 215–227. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthetic aperture radar (SAR) image recognition is an important stage of SAR image interpretation. The standard convolutional neural network (CNN) has been successfully applied in the SAR image recognition due to its powerful feature extraction capability. Nevertheless, the CNN requires numerous labeled samples for satisfactory recognition performance, while the performance of the CNN decreases greatly with insufficient labeled samples. Aiming at improving the SAR image recognition accuracy with a small number of labeled samples, a new few-shot learning method is proposed in this paper. We first utilize the attention prototypical network (APN) to calculate the average features of the support images from each category, which are adopted as the prototypes. Afterwards, the feature extraction is performed on the query images using the attention convolutional neural network (ACNN). Finally, the feature matching classifier (FMC) is adopted for calculating the similarity scores between the feature maps and the prototypes. We embed the attention model SENet to the APN, ACNN, and FMC, which effectively enhances the expression of the prototypes and the feature maps. Besides, the loss function of our method consists of cross-entropy and prototype-separability losses. In the training process, this loss function increases the separability of different prototypes, which contributes to higher recognition accuracy. We perform experiments on the Moving and Stationary Target Acquisition and Recognition (MSTAR) and the Vehicle and Aircraft (VA) datasets. It has been proved that our method is superior to the related state-of-the-art few-shot image recognition methods.},
  archive      = {J_NEUCOM},
  author       = {Zhenyu Yue and Fei Gao and Qingxu Xiong and Jinping Sun and Amir Hussain and Huiyu Zhou},
  doi          = {10.1016/j.neucom.2021.09.009},
  journal      = {Neurocomputing},
  pages        = {215-227},
  shortjournal = {Neurocomputing},
  title        = {A novel few-shot learning method for synthetic aperture radar image recognition},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast intent prediction of multi-cyclists in 3D point cloud
data using deep neural networks. <em>NEUCOM</em>, <em>465</em>, 205–214.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring the intended actions of road-sharing users with autonomous ground vehicles in particularly vulnerable ones like cyclists is considered one of the tough tasks facing the wide-spread deployment of autonomous ground vehicles. One of the main reasons for that is the scarcity of the available datasets for that task due to the difficulty in obtaining those datasets in real environments. In this work, we first propose a pipeline that can synthetically produce 3D LiDAR data of cyclists hand-signalling a set of intended actions that are commonly done in real environments. Given the synthetically-produced labelled 3D LiDAR data sequences, we trained a framework that can simultaneously detect, track and give predictions about the intended actions of multi-cyclists in the scene on time. The proposed framework was evaluated using both synthetic and real data from a physical 3D LiDAR sensor. Our proposed framework has scored competitive and robust results in both synthetic and real environments with 88\% in F 1 F1 measure with higher frame per second rate (12.9 FPS) than the 3D LiDAR sensor frame rate (10 Hz).},
  archive      = {J_NEUCOM},
  author       = {Khaled Saleh and Ahmed Abobakr and Mohammed Hossny and Darius Nahavandi and Julie Iskander and Mohammed Attia and Saeid Nahavandi},
  doi          = {10.1016/j.neucom.2021.09.008},
  journal      = {Neurocomputing},
  pages        = {205-214},
  shortjournal = {Neurocomputing},
  title        = {Fast intent prediction of multi-cyclists in 3D point cloud data using deep neural networks},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aspect term extraction for opinion mining using a
hierarchical self-attention network. <em>NEUCOM</em>, <em>465</em>,
195–204. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect identification is one of the important sub-tasks in opinion mining and this task can be considered as a token-level sequencing problem. Most recent approaches employ BERT based network to identify the aspect term, which is often complex, consumes a lot of memory, and needs more training time. In this paper, we propose a novel Hierarchical Self-Attention Network (HSAN) which performs well, needs lesser memory and training time. HSAN hierarchically applies a self-attention mechanism to first capture the importance of each word in the context of the overall meaning of the sentence and then it explores the internal dependency of the words in the same sentence to identify interdependent collocated words. A fusion of these two-attention mechanisms helps HSAN to predict multiple aspect terms effectively in the given sentence along with multi-token aspect terms. Our proposed network uses word embeddings, which is a combination of general-purpose embeddings and domain-specific embeddings. We evaluate the performance of HSAN on SemEval-2014 datasets, experimental results demonstrate the efficiency and effectiveness of our model.},
  archive      = {J_NEUCOM},
  author       = {Avinash Kumar and Aditya Srikanth Veerubhotla and Vishnu Teja Narapareddy and Vamshi Aruru and Lalita Bhanu Murthy Neti and Aruna Malapati},
  doi          = {10.1016/j.neucom.2021.08.133},
  journal      = {Neurocomputing},
  pages        = {195-204},
  shortjournal = {Neurocomputing},
  title        = {Aspect term extraction for opinion mining using a hierarchical self-attention network},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph similarity rectification for person search.
<em>NEUCOM</em>, <em>465</em>, 184–194. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In person search task, it is hard to retrieve the query persons undergoing large visual changes. To tackle this problem, we propose to exploit the context information to rectify the original individual similarity for better retrieval. To this end, we propose to model a query frame and a gallery frame as a graph pair, and then design the Siamese Residual Graph Convolutional Networks (SR-GCN) to aggregate context information to generate graph similarity as a complement of the original similarity. To model the relationships between context persons, we define the joint similarity adjacency matrix which assigns the proposed joint similarity as the edge weight to measure the contributions a context person makes to the aggregation. Therefore, the context node with a higher possibility to be a co-traveler of the target node makes more contributions to the matching of the target node. To further enhance the discriminative power of individual features, we also design a Random Proxy Center loss which explicitly constrains the intra-class variations to be smaller than the inter-class variations in the feature space and could make use of unlabeled samples . Experimental results on two public datasets show that our approach performs favorably against the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Chuang Liu and Hua Yang and Ji Zhu and Xinzhe Li and Zhigang Chang and Shibao Zheng},
  doi          = {10.1016/j.neucom.2021.08.136},
  journal      = {Neurocomputing},
  pages        = {184-194},
  shortjournal = {Neurocomputing},
  title        = {Graph similarity rectification for person search},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Actuator saturating intermittent control for
synchronization of stochastic multi-links network with sampled-data.
<em>NEUCOM</em>, <em>465</em>, 167–183. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a kind of aperiodically sampled-data intermittent control to investigate the synchronization issue of stochastic multi-links network. Therein, the sampling intervals are variable in the aperiodically intermittent control, while the actuator saturation is taken into consideration. Distinguish from previous control methods , by combining with the advantages of both the sampled-data and actuator saturating control and the aperiodically actuator saturating intermittent control, we design the sampled-data and actuator saturating intermittent control. Meanwhile, the aperiodically sampled-data intermittent control and the sampled-data and actuator saturating control are used to settle the synchronization problem of stochastic multi-links network. After that, some sufficient conditions are obtained based on Lyapunov method, some techniques of inequalities and a graph-theoretic approach. The control law is determined simultaneously, which depends on the coupling strength, the perturbed intensity of noise, the upper and lower bounds of sampling intervals, the lower bound of intermittent control intervals and the maximum rest time ratio. Then, our theoretical results are used in the synchronization issue of stochastic multi-links Chua’s circuits network. Ultimately, a numerical example is presented to illustrate the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Hui Zhou and Siyue Ma and Wenxue Li},
  doi          = {10.1016/j.neucom.2021.08.123},
  journal      = {Neurocomputing},
  pages        = {167-183},
  shortjournal = {Neurocomputing},
  title        = {Actuator saturating intermittent control for synchronization of stochastic multi-links network with sampled-data},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using volatile/non-volatile memristor for emulating the
short-and long-term adaptation behavior of the biological neurons.
<em>NEUCOM</em>, <em>465</em>, 157–166. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive response to the timely constant stimulus is the common feature of real neurons. The circuit of the adaptive neuron model consumes less power and requires less data transmission bandwidth compared to the circuit of the non-adaptive neuron model, especially for encoding time-varying signals. Memristor is a good candidate for mimicking the behavior of neurons so that the simple memristor-based circuit can directly emulate many specific behaviors of the neurons with low power and low area consumption. In this work, for the first time, we show that as the nonvolatile switching property of the memristor can be useful for representing long-term adaptation behavior in the memristor-based neuron, the short-term adaptation behavior can also be emulated directly using the same memristor-based circuit due to the volatile switching property of the memristor. Here, short term adaptation is realized using the volatile property of memristor, unlike neuron circuits where adaptation is realized using leakage modulation. As a result, in the memristor-based neuron extra power dissipation can be reduced. Two different types of memristors are used for implementing the proposed circuit of adaptive leaky integrate-and-fire neuron, the volatile/non-volatile memristor and threshold switching memristor are in the charge and discharge path of the capacitor, respectively. Results show that the volatile or non-volatile resistance change of charging memristor upon different input patterns to the neuron circuit determines the type of adaptive behavior of the neuron response, i.e. the neuron may show short-term adaptation or long-term adaptation or does not show an adaptation behavior at all. Comparison with similar works shows that the energy consumption per spiking of the proposed neuron is relatively low, while the circuit is very area-efficient.},
  archive      = {J_NEUCOM},
  author       = {Mohammad Saeed Feali},
  doi          = {10.1016/j.neucom.2021.08.132},
  journal      = {Neurocomputing},
  pages        = {157-166},
  shortjournal = {Neurocomputing},
  title        = {Using volatile/non-volatile memristor for emulating the short-and long-term adaptation behavior of the biological neurons},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AMDFNet: Adaptive multi-level deformable fusion network for
RGB-d saliency detection. <em>NEUCOM</em>, <em>465</em>, 141–156. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective exploration of useful contextual information in multi-modal images is an essential task in salient object detection. Nevertheless, the existing methods based on the early-fusion or the late-fusion schemes cannot address this problem as they are unable to effectively resolve the distribution gap and information loss. In this paper, we propose an adaptive multi-level deformable fusion network (AMDFNet) to exploit the cross-modality information. We use a cross-modality deformable convolution module to dynamically adjust the boundaries of salient objects by exploring the extra input from another modality. This enables incorporating the existing features and propagating more contexts so as to strengthen the model’s ability to perceiving scenes. To accurately refine the predicted maps, a multi-scaled feature refinement module is proposed to enhance the intermediate features with multi-level prediction in the decoder part. Furthermore, we introduce a selective cross-modality attention module in the fusion process to exploit the attention mechanism . This module captures dense long-range cross-modality dependencies from a multi-modal hierarchical feature’s perspective. This strategy enables the network to select more informative details and suppress the contamination caused by the negative depth maps. Experimental results on eight benchmark datasets demonstrate the effectiveness of the components in our proposed model, as well as the overall saliency model.},
  archive      = {J_NEUCOM},
  author       = {Fei Li and Jiangbin Zheng and Yuan-fang Zhang and Nian Liu and Wenjing Jia},
  doi          = {10.1016/j.neucom.2021.08.116},
  journal      = {Neurocomputing},
  pages        = {141-156},
  shortjournal = {Neurocomputing},
  title        = {AMDFNet: Adaptive multi-level deformable fusion network for RGB-D saliency detection},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy rough discrimination and label weighting for
multi-label feature selection. <em>NEUCOM</em>, <em>465</em>, 128–140.
(<a href="https://doi.org/10.1016/j.neucom.2021.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy rough set is a theoretical framework of fuzzy uncertainty management, and discernibility matrix offers a mathematical foundation for algorithm construction of feature learning . The approaches of fuzzy rough set and discernibility matrix have been successfully applied in single-label learning. However, few works have been done on investigating the foundation of fuzzy rough discernibility matrix on multi-label data. There will be two pivotal problems to be addressed when using fuzzy rough discernibility matrix for multi-label data analysis. One is how to extract sample-level and label-level correlations; and the other is how to utilize the discernibility matrix for algorithm construction . For this reason, in this paper the fuzzy rough discrimination matrix is introduced to deal with the problem of multi-label feature selection. First, the significance of labels in the label space is captured based on the label correlation. Labels with different significances contribute to different weights for measuring the similarity between samples. Hence, a sample similarity matrix in the label space is computed based on the label weighting strategy. Then, a framework of a fuzzy decision system is formalized, in which the discernibility matrix of fuzzy rough sets is introduced as a foundation to evaluate the sample discrimination ability of features. Under the discernibility matrix criterion, a multi-label learning algorithm is developed to select discriminative features from multi-label data. A series of experimental analysis verifies the effectiveness and efficiency of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Anhui Tan and Jiye Liang and Wei-Zhi Wu and Jia Zhang and Lin Sun and Chao Chen},
  doi          = {10.1016/j.neucom.2021.09.007},
  journal      = {Neurocomputing},
  pages        = {128-140},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy rough discrimination and label weighting for multi-label feature selection},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PortraitNET: Photo-realistic portrait cartoon style transfer
with self-supervised semantic supervision. <em>NEUCOM</em>,
<em>465</em>, 114–127. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel framework to transfer the portrait image into its correspondence with photo-realistic and cartoon style. The existing work on neural style transfer conducts impressive results on artistic style transfer; however, the lack of semantic clues will lead to the color artifacts in photo-realistic style transfer because of the complex background and noise issues. In this work, we re-define the semantics as the pixel motion field according to the color displacement between adjacent animation frames along the optical direction and initiatively propose the self-supervised semantic network (SSNet) to learn semantic maps without human inference or any priories. The SSNet shares parameters with the style transfer network; thus, the superior alternatives can preserve the semantic completeness in the styled image. To solve the content missing and blur problems common in NST, we propose the bilateral convolution block (B-block) and feature fusion strategy (F-block) for visual smoothness to meet the perceptive satisfaction. The ablation studies are provided to validate the effectiveness, and comparative experiments with the state-of-the-art baselines demonstrate the advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {J. Cui and Y.Q. Liu and H.J. Lu and Q.Q. Cai and M.X. Tang and M. Qi and Z.Y. Gu},
  doi          = {10.1016/j.neucom.2021.08.088},
  journal      = {Neurocomputing},
  pages        = {114-127},
  shortjournal = {Neurocomputing},
  title        = {PortraitNET: Photo-realistic portrait cartoon style transfer with self-supervised semantic supervision},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HuRAI: A brain-inspired computational model for human-robot
auditory interface. <em>NEUCOM</em>, <em>465</em>, 103–113. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The deep learning era endows immense opportunities for ubiquitous robotic applications by leveraging big data generated from widespread sensors and ever-growing computing capability. While the growing demands for natural human-robot interaction (HRI) as well as concerns for energy efficiency, real-time performance, and data security motive novel solutions. In this paper, we present a brain-inspired spiking neural network (SNN) based Human-Robot Auditory Interface, namely HuRAI. The HuRAI integrates the voice activity detection , speaker localization and voice command recognition systems into a unified framework that can be implemented on the emerging low-power neuromorphic computing (NC) devices. Our experimental results demonstrate superior modeling capabilities of SNNs, achieving accurate and rapid prediction for each task. Moreover, the energy efficiency analysis reveals a compelling prospect, with up to three orders of magnitude energy savings , over the equivalent artificial neural networks that running on the state-of-the-art Nvidia graphics processing unit (GPU). Therefore, integrating the algorithmic power of large-scale SNN models and the energy efficiency of NC devices offers an attractive solution for real-time, low-power robotic applications .},
  archive      = {J_NEUCOM},
  author       = {Jibin Wu and Qi Liu and Malu Zhang and Zihan Pan and Haizhou Li and Kay Chen Tan},
  doi          = {10.1016/j.neucom.2021.08.115},
  journal      = {Neurocomputing},
  pages        = {103-113},
  shortjournal = {Neurocomputing},
  title        = {HuRAI: A brain-inspired computational model for human-robot auditory interface},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A focus measure in discrete cosine transform domain for
multi-focus image fast fusion. <em>NEUCOM</em>, <em>465</em>, 93–102.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Under the Joint Photographic Experts Group (JPEG) framework, this paper proposes a simple yet efficient focus measure (FM) in discrete cosine transform (DCT) domain for fast multi-focus image fusion. At first, the DCT coefficients of multi-focus source images in JPEG format are read directly. Then, the initial decision map is constructed according to the proposed FM using only a few low-order DCT coefficients. Finally, the final decision map is refined with morphological operation , and the fused image is achieved by a simple fusion rule. The experimental results demonstrate that the proposed method takes at least 1\% 1\% less fusion time than the existing fastest methods by neural network while ensuring the fusion effect in both visual perception and objective evaluations. Therefore, the proposed method is more suitable for wireless visual sensor network (WVSN) nodes with edge computing than the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xixi Nie and Bin Xiao and Xiuli Bi and Weisheng Li and Xinbo Gao},
  doi          = {10.1016/j.neucom.2021.08.109},
  journal      = {Neurocomputing},
  pages        = {93-102},
  shortjournal = {Neurocomputing},
  title        = {A focus measure in discrete cosine transform domain for multi-focus image fast fusion},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AttributeNet: Attribute enhanced vehicle re-identification.
<em>NEUCOM</em>, <em>465</em>, 84–92. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle Re-Identification (V-ReID) is a critical task that associates the same vehicle across images from different camera viewpoints. Many works explore attribute clues to enhance V-ReID; however, there is usually a lack of effective interaction between the attribute-related modules and final V-ReID objective. In this work, we propose a new method to efficiently explore discriminative information from vehicle attributes (for instance, color and type). We introduce AttributeNet (ANet) that jointly extracts identity-relevant features and attribute features. We enable the interaction by distilling the ReID-helpful attribute feature and adding it into the general ReID feature to increase the discrimination power. Moreover, we propose a constraint, named Amelioration Constraint (AC), which encourages the feature after adding attribute features onto the general ReID feature to be more discriminative than the original general ReID feature. We validate the effectiveness of our framework on three challenging datasets. Experimental results show that our method achieves the state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Rodolfo Quispe and Cuiling Lan and Wenjun Zeng and Helio Pedrini},
  doi          = {10.1016/j.neucom.2021.08.126},
  journal      = {Neurocomputing},
  pages        = {84-92},
  shortjournal = {Neurocomputing},
  title        = {AttributeNet: Attribute enhanced vehicle re-identification},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spectral mapping with adversarial learning for unsupervised
hyperspectral change detection. <em>NEUCOM</em>, <em>465</em>, 71–83.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unlike the existing change detection approaches based on the multispectral (MS) image and synthetic aperture radar (SAR) image datasets, a novel unsupervised hyperspectral change detection (UHCD) framework is proposed in this paper. The UHCD framework is designed for hyperspectral images with high dimensions and low availability. This framework consists of two modules: the spectral mapping with adversarial learning and the discriminant analysis with spatial attribute optimization. In comparison with other advanced change detection methods, the proposed framework possesses three distinctive properties: (1) The unsupervised spectral mapping is leveraged to exploit underlying spectral features without the requirement of pseudo-training datasets in the change detection task; (2) We introduce spectral constraint loss into reconstruction space and adversarial loss into latent space to enhance the quality of the features extracted by the spectral mapping network; (3) Spatial attribute optimization uses the spatial correlation to further improve the performance of the proposed UHCD method. The experimental results on two real datasets show that the proposed UHCD achieves competitive performance.},
  archive      = {J_NEUCOM},
  author       = {Jie Lei and Meiqi Li and Weiying Xie and Yunsong Li and Xiuping Jia},
  doi          = {10.1016/j.neucom.2021.08.130},
  journal      = {Neurocomputing},
  pages        = {71-83},
  shortjournal = {Neurocomputing},
  title        = {Spectral mapping with adversarial learning for unsupervised hyperspectral change detection},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks based on vectorized neurons.
<em>NEUCOM</em>, <em>465</em>, 63–70. (<a
href="https://doi.org/10.1016/j.neucom.2021.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the main research content of artificial intelligence , the artificial neural network has been widely concerned because of its excellent performance in the fields such as computer vision and natural language processing since it was proposed in the 1940s. The neuron model of the traditional neural network was proposed by McCulloch and Pitts in 1943 (MP neurons), But MP neurons is too simple to representing biological neurons. Based on this, this paper studies the attention mechanism and proposes vectorized neuron and its activation function . Firstly, we propose vectorized neurons, then use the attention mechanism to dynamically generate connection weights between vectorized neurons. Nextly, we construct a new type of neural network with vectorized neurons, which we called neural functional group (NFG). Finally, we tested the proposed neural functional group model on two tasks: image classifcation and few-shot learning. The vectorized neuron can be conditionally activated through its activation function. Besides, the vectorized neuron has the potential of representing complex biological neurons, which is difficult for MP neuron. The experimental results show that it can achieve higher accuracy with fewer parameters than convolutional neural networks (CNN) and capsule networks in image classication task; it also competitive to CNN based feature extractor in few-shot learning task.},
  archive      = {J_NEUCOM},
  author       = {Ji He and Hongwei Yang and Lei He and Lina Zhao},
  doi          = {10.1016/j.neucom.2021.09.006},
  journal      = {Neurocomputing},
  pages        = {63-70},
  shortjournal = {Neurocomputing},
  title        = {Neural networks based on vectorized neurons},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mittag-leffler stability and asymptotic ω-periodicity of
fractional-order inertial neural networks with time-delays.
<em>NEUCOM</em>, <em>465</em>, 53–62. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the stability for a class fractional-order inertial neural networks with time-delay are investigated. Moreover, some sufficient conditions for the Mittag-Leffler stability and the asymptotical ω ω -periodicity are obtained, by the appropriate transformation, using the property of the Riemann-Liouville fractional integral and derivative. In the end, results of the theoretical derivation are verified by virtue of two numerical simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Liang Ke},
  doi          = {10.1016/j.neucom.2021.08.121},
  journal      = {Neurocomputing},
  pages        = {53-62},
  shortjournal = {Neurocomputing},
  title        = {Mittag-leffler stability and asymptotic ω-periodicity of fractional-order inertial neural networks with time-delays},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEAttack: A differential evolution based attack method for
the robustness evaluation of medical image segmentation.
<em>NEUCOM</em>, <em>465</em>, 38–52. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is an effective tool to assist doctors with many time-consuming and error-prone medical image analytical tasks. However, deep models are shown to be vulnerable to adversarial attacks , posing significant challenges to clinical applications. Existing works regarding the robustness of deep learning models are scarce, where most of them focus on the attack of medical image classification models . In this paper, a differential evolution attack (DEAttack) method is proposed to generate adversarial examples for medical image segmentation models. Our method does not require extra information such as the network’s structures and weights compared with the most widely investigated gradient-based attack methods. Additionally, benefit from the embedded differential evolution algorithm , which can preserve diversities of the optimization space . The proposed method can achieve better results than gradient-based methods, which can successfully attack the segmentation model with only perturbing a small fraction of the image pixels, demonstrating that the medical image segmentation model is more susceptible to adversarial examples . In addition to evaluating model robustness attack with public datasets, our DEAttack method was also tested on the clinical diagnostic dataset, demonstrating its superior performance and elegant process for the robustness evaluation of deep models in medical image segmentation.},
  archive      = {J_NEUCOM},
  author       = {Xiangxiang Cui and Shi Chang and Chen Li and Bin Kong and Lihua Tian and Hongqiang Wang and Peng Huang and Meng Yang and Yenan Wu and Zhongyu Li},
  doi          = {10.1016/j.neucom.2021.08.118},
  journal      = {Neurocomputing},
  pages        = {38-52},
  shortjournal = {Neurocomputing},
  title        = {DEAttack: A differential evolution based attack method for the robustness evaluation of medical image segmentation},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A segment enhanced span-based model for nested named entity
recognition. <em>NEUCOM</em>, <em>465</em>, 26–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Named entity recognition (NER) is a fundamental problem in natural language processing . In particular, nested entities are commonly existed in real-life textual data for the NER task. However, the current span-based methods for nested NER are computationally expensive, lacking of explicit boundary supervision and generating many negative samples for span classification, which affect their overall performance. In this paper, we propose a Segment Enhanced Span-based model for nested NER (SESNER). The proposed model treats the nested NER task as a segment covering problem. First, it models entities as segments, detects the segment endpoints and identifies the positional relationship between neighboring endpoints. Then, it detects the outermost segments to generate candidate entity spans nested in it for span classification. Our proposed model has the advantages of enhancing boundary supervision in learning span representations by detecting segment endpoints, reducing the number of negative samples without losing long entities that are ignored by most span-based methods, and improving runtime performance. Moreover, a novel augmented training mechanism is also proposed to further improve the model performance by extending the training dataset with data that were wrongly predicted before. Experimental results show that our proposed SESNER model has achieved promising performance with near linear time complexity on the benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Fei Li and Zheng Wang and Siu Cheung Hui and Lejian Liao and Xinhua Zhu and Heyan Huang},
  doi          = {10.1016/j.neucom.2021.08.094},
  journal      = {Neurocomputing},
  pages        = {26-37},
  shortjournal = {Neurocomputing},
  title        = {A segment enhanced span-based model for nested named entity recognition},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Lane-DeepLab: Lane semantic segmentation in automatic
driving scenarios for high-definition maps. <em>NEUCOM</em>,
<em>465</em>, 15–25. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate high-definition maps with lane markings are often used as the navigation back-end for commercial autonomous vehicles. Currently, most high-definition maps are manually constructed by human labelling. Therefore, it is urgently required to propose a multi-class lane detection method that can automatically mark the road lanes to assist in generating high-precision maps for autonomous driving . We propose a lane segmentation detection method, named Lane-DeepLab, which is based on semantic segmentation for detecting multi-class lane lines in unmanned driving scenarios. The proposed method is based on the DeepLabv3+ network as the baseline, and we have redesigned the encoder-decoder structure to generate more accurate lane line detection results. More specifically, we restructure the atrous convolution at multi-scale by applying attention mechanism . Subsequently, we employ the Semantic Embedding Branch (SEB) to combine the high-level and low-level semantic information to obtain more abundant features, and use the Single Stage Headless (SSH) context module to obtain multi-scale information. Finally, we fuse the results to generate automatic high-precision mapping results. Our method has improved performance compared with other methods in the ApolloScape part of the dataset. Besides, in the database of Cityscapes, our approach has also achieved good results in semantic segmentation . Experimental results demonstrate that our proposed Lane-DeepLab can provide excellent performance in real traffic scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jingyu Li and Fengling Jiang and Jing Yang and Bin Kong and Mandar Gogate and Kia Dashtipour and Amir Hussain},
  doi          = {10.1016/j.neucom.2021.08.105},
  journal      = {Neurocomputing},
  pages        = {15-25},
  shortjournal = {Neurocomputing},
  title        = {Lane-DeepLab: Lane semantic segmentation in automatic driving scenarios for high-definition maps},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-modal discrete tensor decomposition hashing for
efficient multimedia retrieval. <em>NEUCOM</em>, <em>465</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the research field of multimedia retrieval , unsupervised multi-modal hashing has received widespread attention because of its high retrieval efficiency, low storage cost and semantic label independence. However, there are still several problems that need to be resolved: 1) All existing methods are based on matrix factorizations , which has limited capability on fusing heterogeneous multi-modal features under the unsupervised learning paradigm. 2) Most methods adopt two-step learning strategy to separately learn the hash codes and functions, which may generate sub-optimal hash functions . 3) The optimization strategies used by most methods produce significant quantization loss and computation cost. In this paper, an efficient unsupervised Multi-modal Discrete Tensor Decomposition Hashing (MDTDH) approach is proposed to solve the above problems. Specifically, all multi-modal features are first stacked together into a three-dimensional tensor after nonlinear mapping , and then it is decomposed further into a core tensor and two factor matrices by Tucker decomposition. A series of hash functions are learned simultaneously by mapping the nonlinear features of the training instances to their corresponding hash codes. To reduce the quantization loss and computation cost, a fast discrete optimization strategy is proposed to generate hash codes directly without relaxing quantization loss. Extensive experimental results on three benchmarks demonstrate that our proposed MDTDH obtains superior performance than state-of-the-art unsupervised baselines, and even defeats several supervised baselines. Our source codes and testing datasets are available at https://github.com/XizeWu/MDTDH .},
  archive      = {J_NEUCOM},
  author       = {Xize Wu and Lei Zhu and Liang Xie and Zheng Zhang and Huaxiang Zhang},
  doi          = {10.1016/j.neucom.2021.08.125},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal discrete tensor decomposition hashing for efficient multimedia retrieval},
  volume       = {465},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based incremental backstepping sliding-mode
fault-tolerant control for blended-wing-body aircrafts. <em>NEUCOM</em>,
<em>464</em>, 546–561. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents an adaptive incremental nonlinear backstepping sliding-mode (INBSM) controller, for fault tolerant tracking control of a blended wing body (BWB) aircraft with unknown disturbances and actuator faults . The INBSM controller is based on a nonlinear dynamics model of the BWB aircraft. In addition, a radial basis function neural network disturbance observer (RBF-NNDO) is proposed to enhance the disturbance attenuation ability. A fault estimator is suggested to improve actuator fault tolerant control level. The closed-loop control system of the BWB aircraft is proved to be globally asymptotically stable using Lyapunov theory . Simulations of the combined NNDO-INBSM controller are presented and compared with both the INBSM design and an adaptive fuzzy controller. The results demonstrate an improved capability of the NNDO-INBSM control for the BWB aircraft to execute realistic attitude tracking missions, even in the presence of center of gravity movement, unknown disturbances, model uncertainties and actuator faults .},
  archive      = {J_NEUCOM},
  author       = {Shi Qian Liu and James F. Whidborne},
  doi          = {10.1016/j.neucom.2021.08.069},
  journal      = {Neurocomputing},
  pages        = {546-561},
  shortjournal = {Neurocomputing},
  title        = {Observer-based incremental backstepping sliding-mode fault-tolerant control for blended-wing-body aircrafts},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). COP: Customized correlation-based filter level pruning
method for deep CNN compression. <em>NEUCOM</em>, <em>464</em>, 533–545.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As deep CNNs get larger, it becomes more challenging to deploy them on resource-restricted mobile devices . Filter-level pruning is one of the most popular methods to compress deep models for mobile deployment. It prunes unimportant filters in the pre-trained CNN to reduce its storage and computational cost, yielding a smaller and more efficient model. Though having made some progress, most filter-level pruning methods still suffer from at least one of the following two problems: 1) High redundancy: some methods pick out unimportant filters without considering their correlations, and thus many highly correlated filters are not pruned, yielding a model still with high redundancy. 2) Sub-optimal: all existing pruning methods achieve sub-optimal pruning plan because they neglect that a high parameters reduction ratio (PRR) does not always mean a high FLOPs reduction ratio (FRR). In this paper, we propose our customized correlation-based pruning (COP) to solve these problems. In particular, we observe redundant filters through their correlations. Moreover, to achieve the optimal pruning plan, PRR and FRR are considered when evaluating filters’ importance. Besides, we also propose a new pruning pipeline, which improves the accuracy of the pruned model. Extensive experiments show that our proposed method has outperformed the state-of-the-art on several popular architectures and datasets.},
  archive      = {J_NEUCOM},
  author       = {Wenxiao Wang and Zhengxu Yu and Cong Fu and Deng Cai and Xiaofei He},
  doi          = {10.1016/j.neucom.2021.08.098},
  journal      = {Neurocomputing},
  pages        = {533-545},
  shortjournal = {Neurocomputing},
  title        = {COP: Customized correlation-based filter level pruning method for deep CNN compression},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning robot anomaly recovery skills from multiple
time-driven demonstrations. <em>NEUCOM</em>, <em>464</em>, 522–532. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robots are prone to making anomalies when performing manipulation tasks in unstructured environments, it is often desirable to rapidly adapt the robotic behavior to avoid environmental changes by learning from experts’ demonstrations. We propose a framework for learning robot anomaly recovery skills from time-driven demonstrations based on a Gaussian process regression with prior mean derived by Gaussian mixture regression, named as mean-prior GPR (MP-GPR), which allows an end-user to adjust the anomalous trajectory intuitively by simultaneously considering the variability of the demonstrations and the adaptation of recovery skills. Evaluations are divided into two phases, a benchmarking dataset with robot reaching, pushing, writing, and pressing tasks are first used to verify the path accuracy and variability, and then a real-time robot bin-picking task for evaluating the adaptation of the framework. Our method has a fair comparison with probabilistic-based methods in the field of robot learning from demonstrations, including Gaussian mixture regression, probabilistic movement primitives, and kernelized movement primitives. The results indicate that our proposed method can efficiently encode the variability from multiple demonstrations and rapidly anomaly recovery skills learning by modulating a learned trajectory to safe via-points.},
  archive      = {J_NEUCOM},
  author       = {Hongmin Wu and Wu Yan and Zhihao Xu and Shuai Li and Xuefeng Zhou},
  doi          = {10.1016/j.neucom.2021.08.036},
  journal      = {Neurocomputing},
  pages        = {522-532},
  shortjournal = {Neurocomputing},
  title        = {Learning robot anomaly recovery skills from multiple time-driven demonstrations},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural weight coordination-based vector-valued neural
network synchronization. <em>NEUCOM</em>, <em>464</em>, 507–521. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, Harris’ Hawks weight optimization-guided artificial neural learning-based quicker session key coordination for Industrial Internet-of-Things (IIoT) to enhance the security of Critical Energy Infrastructure (CEI) is proposed. Transportation, telecommunications, healthcare, finance, and defense are all being revolutionized by the energy industry’s digitization. CEI is widely dispersed, resulting in complex cyber-physical networks that require constant monitoring and quick recovery to avoid cyberattacks. Substantial efforts were made in this regard to tackle the key exchange problem in IIoT devices, the majority of which have depended on traditional approaches. Existing solutions fail to adequately resolve the security and privacy issues that IIoT systems face. This study proposes a Triple Layer Vector-Valued Neural Network (TLVVNN) to cope with the problem. However, research into optimizing the value of neural weights for quicker neural synchronization is rare. In this case, Harris’ Hawks is used to optimizing the neural network’s weight vector for quicker coordination. The coordinated weight becomes the session key once this process is accomplished. This technique has several advantages, including (1) Generation of session key via mutual neural synchronization over the public channel. (2) It enables Harris’ Hawks-based neural weight vector optimization for faster neural synchronization across public channels. (3) Vector inputs and weights are taken into consideration for TLVVNN networks. (4) The internal structure of the TLVVNN is complex by three hidden layers. As a result, the attacker might have a lot of difficulties determining the internal architecture. (5) Several pairs of variable-length session keys are generated by TLVVNN. (6) It prevents impersonation, geometric, brute force, and majority assaults. Tests to validate the performance of the proposed methodology are carried out, and the results show that the proposed methodology outperforms similar approaches already in use.},
  archive      = {J_NEUCOM},
  author       = {Arindam Sarkar and Mohammad Zubair Khan and Ahmed h. Alahmadi},
  doi          = {10.1016/j.neucom.2021.08.111},
  journal      = {Neurocomputing},
  pages        = {507-521},
  shortjournal = {Neurocomputing},
  title        = {Neural weight coordination-based vector-valued neural network synchronization},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble learning with siamese networks for visual tracking.
<em>NEUCOM</em>, <em>464</em>, 497–506. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble learning (EL) is an effective and commonly used technique to improve visual tasks’ accuracy, such as classification and detection. However, EL is rarely used in visual tracking. To fill this knowledge gap, we first have completed some research to investigate why knowledge distillation was ineffective in visual tracking tasks. Comparing the difference between the classification and visual tracking, conclusions are given: (i) Numerous simple negative examples are redundant, while only a few hard negative samples are valid for visual tracking knowledge distillation. (ii) The hint knowledge flows differently between classification and visual tracking. To solve the above problems, we design two new loss functions and integrate them into the proposed Ensemble Learning (EL) framework that can be employed in Siamese architectures such as SiamFC, SiamRPN, SiamFC+, and SiamRPN+. The EL treats two Siamese networks as students and enables them to learn collaboratively. A better solution is yielded by the EL framework than training students individually. Experiments on OTB-2013 , OTB-2015 , VOT2015 , VOT2016 , VOT2017 , VOT2018 , LaSOT and TrackingNet have verified the effectiveness of our proposed technique on boosting the performance for the four Siamese algorithms. The EL-SiamRPN+ achieves leading performance in the challenges.},
  archive      = {J_NEUCOM},
  author       = {Junfei Zhuang and Yuan Dong and Hongliang Bai},
  doi          = {10.1016/j.neucom.2021.08.025},
  journal      = {Neurocomputing},
  pages        = {497-506},
  shortjournal = {Neurocomputing},
  title        = {Ensemble learning with siamese networks for visual tracking},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep representation alignment network for pose-invariant
face recognition. <em>NEUCOM</em>, <em>464</em>, 485–496. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent developments in convolutional neural networks and the increasing amount of data, there has been great progress in face recognition. Nevertheless, unconstrained situations remain challenging, given their variations in illumination, expression, and pose. To handle such pose variation, we propose the deep representation alignment network (DRA-Net), which aligns the deep representation of the profile face with that of the frontal face. Comprised of a denoising autoencoder (DAE) and a deep representation transformation (DRT) block, DRA-Net uses end-to-end training. DAE recovers deep representations of large pose angle in not visible face areas, and the DRT block transforms the recovered deep representation from profile into near-frontal poses. Also, we implement cosine loss and use pairwise training to mitigate the gap between frontal and profile representations and reduce intra-class variation. In experimental results, DRA-Net outperforms other state-of-the-art methods, particularly for large pose angle on LFW, YTF, Multi-PIE, CFP, IJB-A, and M 2 FPA benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Chun-Hsien Lin and Wei-Jia Huang and Bing-Fei Wu},
  doi          = {10.1016/j.neucom.2021.08.103},
  journal      = {Neurocomputing},
  pages        = {485-496},
  shortjournal = {Neurocomputing},
  title        = {Deep representation alignment network for pose-invariant face recognition},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Competing ratio loss for discriminative multi-class image
classification. <em>NEUCOM</em>, <em>464</em>, 473–484. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of deep convolutional neural network architecture is critical to the improvement of image classification task performance. Many image classification studies use deep convolutional neural network and focus on modifying the network structure to improve image classification performance. Conversely, our study focuses on loss function design. Cross-entropy Loss (CEL) has been widely used for training deep convolutional neural network for the task of multi-class classification. Although CEL has been successfully implemented in several image classification tasks, it only focuses on the posterior probability of the correct class. For this reason, a negative log likelihood ratio loss (NLLR) was proposed to better differentiate between the correct class and the competing incorrect ones. However, during the training of the deep convolutional neural network, the value of NLLR is not always positive or negative, which severely affects the convergence of NLLR. Our proposed competing ratio loss (CRL) calculates the posterior probability ratio between the correct class and the competing incorrect classes to further enlarge the probability difference between the correct and incorrect classes. We added hyperparameters to CRL, thereby ensuring its value to be positive and that the update size of backpropagation is suitable for the CRL’s fast convergence. To demonstrate the performance of CRL, we conducted experiments on general image classification tasks (CIFAR10/100, SVHN, ImageNet), the fine-grained image classification tasks (CUB200–2011, and Stanford Car), and the challenging face age estimation task (using Adience). Experimental results showed the effectiveness and robustness of the proposed loss function on different deep convolutional neural network architectures and different image classification tasks. Code is released at https://github.com/guoyurong0104/CRL-code .},
  archive      = {J_NEUCOM},
  author       = {Ke Zhang and Yurong Guo and Xinsheng Wang and Dongliang Chang and Zhenbing Zhao and Zhanyu Ma and Tony X. Han},
  doi          = {10.1016/j.neucom.2021.08.106},
  journal      = {Neurocomputing},
  pages        = {473-484},
  shortjournal = {Neurocomputing},
  title        = {Competing ratio loss for discriminative multi-class image classification},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Enhancing neural sign language translation by highlighting
the facial expression information. <em>NEUCOM</em>, <em>464</em>,
462–472. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural Sign Language Translation (SLT), which is an important cross-modal task to bridge the communication gap between the deaf and the hearing people, has attracted great attention in the field of artificial intelligence, computer vision, and multimedia, etc. Although some great progress has been achieved recently, current neural SLT models still suffer from translation errors caused by under-consideration of non-manual features such as facial expressions , which can carry critical information during communication among the deaf. This paper aims to enhance the traditional neural SLT models by highlighting the facial expression information in the CNN-based sign video representing part. Two novel schemes have been proposed. The first scheme is based on a Multi-stream Architecture, which extracts and represents the facial expression information in an additional stream and aggregates it with the information from the main stream. The second scheme is a pre-trained scheme based on Regions of Interest (RoIs), which first trains a multi-region detection module for recognizing the features of faces and bodies and then transfers the pre-trained parameters to the module in SLT model. To validate the proposed models, we conducted the experiments upon the publicly available SLT benchmark dataset: RWTH-PHOENIX-Weather-2014T . Experimental results showed that both the above-mentioned schemes can improve the performance of SLT models. Especially, the RoIs-based scheme can achieve an improvement up to 1.6+ BLEU-4 score gains, while the multi-stream scheme quantitatively analyzed the importance of the face mainly through flexible components, providing a sufficient theoretical basis for the RoIs-based scheme.},
  archive      = {J_NEUCOM},
  author       = {Jiangbin Zheng and Yidong Chen and Chong Wu and Xiaodong Shi and Suhail Muhammad Kamal},
  doi          = {10.1016/j.neucom.2021.08.079},
  journal      = {Neurocomputing},
  pages        = {462-472},
  shortjournal = {Neurocomputing},
  title        = {Enhancing neural sign language translation by highlighting the facial expression information},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detector–tracker integration framework and attention
mechanism for multi–object tracking. <em>NEUCOM</em>, <em>464</em>,
450–461. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online multi-object tracking is a process of extending multi-object trajectories with only past information. In this process, tracking drift, missing detection, and occlusion among objects are common problems. To address the problem of tracking drift, in this paper, a detector–tracker integration framework is proposed and the framework includes the linear regression model ( LRM ) that can detect and track objects simultaneously. The two kinds of results are combined using LRM to suppress tracking drift. Moreover, to overcoming missing detection and the occlusion, a structural similarity calculation based on the attention mechanism is proposed. The attention mechanism is utilized to learn the discriminative features of each object, and a structural similarity calculation are used to improve the ability to extend the objects’ trajectories. Based on these, we design a multi-object tracking strategy, enabling the trajectory’s initialization, extension, and termination. Finally, experiments and analysis are executed on MOT16 and MOT17 benchmarks datasets, and the proposed method obtains multi-object tracking accuracy of 60\%.},
  archive      = {J_NEUCOM},
  author       = {Chunjiang Li and Guangzhu Chen and Rongsong Gou and Zaizuo Tang},
  doi          = {10.1016/j.neucom.2021.08.107},
  journal      = {Neurocomputing},
  pages        = {450-461},
  shortjournal = {Neurocomputing},
  title        = {Detector–tracker integration framework and attention mechanism for multi–object tracking},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online robust echo state broad learning system.
<em>NEUCOM</em>, <em>464</em>, 438–449. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent broad learning system (RBLS) is an effective learning method for processing sequential data. By replacing the enhancement nodes of the broad learning system with recurrent structure , RBLS obtains the capacity to capture the dynamic characteristics of time series data . However, RBLS is derived under the minimum mean square error (MMSE) criterion, which is sensitive to outliers. Moreover, RBLS is insufficient for online sequential learning . To address these limitations, we propose a novel online robust echo state structure based RBLS (OR-ESBLS). In OR-ESBLS, kernel recursive maximum correntropy (KRMC) is introduced to both enhance the robustness and discover the nonlinear characteristics of feature nodes in an online manner. To reduce the heavy computational requirements caused by the kernel method , a Quasi-Monte Carlo (QMC) based Random Fourier Feature (RFF) is utilized for kernel approximation . Furthermore, we adopt the randomized sparse reservoir as the enhancement nodes of RBLS, which can much more efficiently capture dynamic information of the data in the sequential learning setting. Experiments on both synthetic and real-world datasets are reported. The results show that the proposed OR-ESBLS can provide superior performance in online sequential time series prediction.},
  archive      = {J_NEUCOM},
  author       = {Yu Guo and Xiaoxiao Yang and Yinuo Wang and Fei Wang and Badong Chen},
  doi          = {10.1016/j.neucom.2021.08.099},
  journal      = {Neurocomputing},
  pages        = {438-449},
  shortjournal = {Neurocomputing},
  title        = {Online robust echo state broad learning system},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approx-SMOTE: Fast SMOTE for big data on apache spark.
<em>NEUCOM</em>, <em>464</em>, 432–437. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the main goals of Big Data research, is to find new data mining methods that are able to process large amounts of data in acceptable times. In Big Data classification, as in traditional classification, class imbalance is a common problem that must be addressed, in the case of Big Data also looking for a solution that can be applied in an acceptable execution time. In this paper we present Approx-SMOTE, a parallel implementation of the SMOTE algorithm for the Apache Spark framework. The key difference with the original SMOTE, besides parallelism, is that it uses an approximated version of k -Nearest Neighbor which makes it highly scalable. Although an implementation of SMOTE for Big Data already exists (SMOTE-BD), it uses an exact Nearest Neighbor search, which does not make it entirely scalable. Approx-SMOTE on the other hand is able to achieve up to 30 times faster run times without sacrificing the improved classification performance offered by the original SMOTE.},
  archive      = {J_NEUCOM},
  author       = {Mario Juez-Gil and Álvar Arnaiz-González and Juan J. Rodríguez and Carlos López-Nozal and César García-Osorio},
  doi          = {10.1016/j.neucom.2021.08.086},
  journal      = {Neurocomputing},
  pages        = {432-437},
  shortjournal = {Neurocomputing},
  title        = {Approx-SMOTE: Fast SMOTE for big data on apache spark},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging label hierarchy using transfer and multi-task
learning: A case study on patent classification. <em>NEUCOM</em>,
<em>464</em>, 421–431. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When labels are organized into a meaningful taxonomy, the parent-child relationship between labels at different levels can give the classifier additional information not deducible from the data alone, especially with limited training data. As a case study, we illustrate this effect on the task of patent classification—the task of categorizing patent documents based on their technical content. Existing approaches do not take into consideration this additional information. Experiments on two patent classification datasets, WIPO-alpha and USPTO-2M, show that our regularized Gated Recurrent Unit (GRU) architecture already gives a performance improvement with a micro-averaged precision score using the top prediction of 0.5191 and 0.5740 on the two datasets, respectively. However, knowledge transfer along the label hierarchy gives further significant improvement on WIPO-alpha, raising the score to 0.5376, and a small improvement on USPTO-2M to 0.5743. Our analyses reveal that incorporating label information improves performance on classes with fewer examples and makes model robust to errors that result from predicting closely related labels.},
  archive      = {J_NEUCOM},
  author       = {Segun Taofeek Aroyehun PhD and Jason Angel MSc and Navonil Majumder PhD and Alexander Gelbukh PhD and Amir Hussain PhD},
  doi          = {10.1016/j.neucom.2021.07.057},
  journal      = {Neurocomputing},
  pages        = {421-431},
  shortjournal = {Neurocomputing},
  title        = {Leveraging label hierarchy using transfer and multi-task learning: A case study on patent classification},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Balanced distortion and perception in single-image
super-resolution based on optimal transport in wavelet domain.
<em>NEUCOM</em>, <em>464</em>, 408–420. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image super-resolution (SISR) is a classic ill-posed problem in computer vision. In recent years, deep-learning-based (DL-based) models have achieved promising results with the SISR problem. However, most existing methods suffer from an intrinsic trade-off between distortion and perceptual quality . To satisfy the requirements in different real-world situations, the balance of distortion and visual quality for image super-resolution is a critical issue. In DL-based models, the uses of hybrid loss (i.e., the combination of the distortion loss and the perceptual loss) and network interpolation are two common approaches to balancing the distortion and perceptual quality of super-resolved images. However, these two kinds of methods lack flexibility and hold strict constraints on network architectures . In this paper, we propose an image-fusion interpolation method for image super-resolution, which can balance the distortion and visual quality of super-resolved images, based on the optimal transport theory in the wavelet domain . The advantage of our proposed method is that it can be applied to any pretrained DL-based model, without any requirement from the network architecture and parameters. In addition, our proposed method is parameter-free and can run fast without using a GPU. Compared with existing state-of-the-art SISR methods, experiment results show that our proposed method can achieve a better balance between the distortion and visual quality in super-resolved images.},
  archive      = {J_NEUCOM},
  author       = {Jun Xiao and Tianshan Liu and Rui Zhao and Kin-Man Lam},
  doi          = {10.1016/j.neucom.2021.08.073},
  journal      = {Neurocomputing},
  pages        = {408-420},
  shortjournal = {Neurocomputing},
  title        = {Balanced distortion and perception in single-image super-resolution based on optimal transport in wavelet domain},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Entropy-aware self-training for graph convolutional
networks. <em>NEUCOM</em>, <em>464</em>, 394–407. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, graph convolutional networks (GCNs) have achieved significant success in many graph-based learning tasks, especially for node classification , due to its excellent ability in representation learning. Nevertheless, it remains challenging for GCN models to obtain satisfying predictions on graphs where only few nodes are with known labels. In this paper, we propose a novel entropy-aware self-training algorithm to boost semi-supervised node classification on graphs with little supervised information. Firstly, an entropy-aggregation layer is developed to strengthen the reasoning ability of GCN models. To the best of our knowledge, this is the first work to combine the entropy-based random walk theory with GCN design. Furthermore, we propose an ingenious checking part to add new nodes as supervision after each training round to enhance node prediction. In particular, the checking part is designed based on aggregated features, which is demonstrated more effective than previous methods and boosts node classification significantly. The proposed algorithm is validated on six public benchmarks in comparison with several state-of-the-art baseline algorithms, and the results illustrate its excellent performance.},
  archive      = {J_NEUCOM},
  author       = {Gongpei Zhao and Tao Wang and Yidong Li and Yi Jin and Congyan Lang},
  doi          = {10.1016/j.neucom.2021.08.092},
  journal      = {Neurocomputing},
  pages        = {394-407},
  shortjournal = {Neurocomputing},
  title        = {Entropy-aware self-training for graph convolutional networks},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Skin disease diagnosis with deep learning: A review.
<em>NEUCOM</em>, <em>464</em>, 364–393. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skin cancer is one of the most threatening diseases worldwide. However, diagnosing skin cancer correctly is challenging. Recently, deep learning algorithms have emerged to achieve excellent performance in various tasks. Particularly, they have been applied to the skin disease diagnosis tasks. In this paper, we present a review on deep learning methods and their applications in skin disease diagnosis. We first present a brief introduction to skin diseases and image acquisition methods in dermatology, and list several publicly available skin datasets. Then, we introduce the conception of deep learning, and review popular deep learning architectures and popular frameworks facilitating the implementation of deep learning algorithms . Thereafter, performance evaluation metrics are presented. As an important part of this article, we then review the literature involving deep learning methods for skin disease diagnosis from several aspects according to the specific tasks. Additionally, we discuss the challenges faced in the area and suggest possible future research directions. The major purpose of this article is to provide a conceptual and systematically review of the recent works on skin disease diagnosis with deep learning. Given the popularity of deep learning, there remains great challenges in the area, as well as opportunities that we can explore in the future.},
  archive      = {J_NEUCOM},
  author       = {Hongfeng Li and Yini Pan and Jie Zhao and Li Zhang},
  doi          = {10.1016/j.neucom.2021.08.096},
  journal      = {Neurocomputing},
  pages        = {364-393},
  shortjournal = {Neurocomputing},
  title        = {Skin disease diagnosis with deep learning: A review},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Re-weighted multi-view clustering via triplex regularized
non-negative matrix factorization. <em>NEUCOM</em>, <em>464</em>,
352–363. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering, which aims at dividing data with similar structures into their respective groups, is a popular research subject in computer vision and machine learning . In recent years, Non-negative matrix factorization (NMF) has received constant concern in multi-view clustering due to its ability to deal with high-dimensional data. However, most existing NMF methods may fail to integrate valuable information from multi-view data adequately, and the local geometry structure in data is also not fully considered. Thus, it’s still a crucial but challenging problem, which effectively extracts multi-view information while maintaining the low-dimensional geometry structure. In this paper, we propose an innovative multi-view clustering method , referred to as re-weighted multi-view clustering via triplex regularized non-negative matrix factorization (SMCTN), which is a unified framework and provides the following contributions: 1) pairwise regularization can extract complementary information between views and is suitable for both homogeneous and heterogeneous perspectives; 2) consensus regularization can process the consistent information between views; 3) graph regularization can preserve the geometric structure of data. Specifically, SMCTN applies a re-weighted strategy to assign suitable weights for multiple views according to their contributions. Besides, an effective iterative updating algorithm is developed to solve the non-convex optimization problem in SMCTN. Extensive experimental results on textual and image datasets indicate that the superior performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Lin Feng and Wenzhe Liu and Xiangzhu Meng and Yong Zhang},
  doi          = {10.1016/j.neucom.2021.08.113},
  journal      = {Neurocomputing},
  pages        = {352-363},
  shortjournal = {Neurocomputing},
  title        = {Re-weighted multi-view clustering via triplex regularized non-negative matrix factorization},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cluster-based deep convolutional networks for spectral
reconstruction from RGB images. <em>NEUCOM</em>, <em>464</em>, 342–351.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spectral reconstruction is an important task in the field of computer vision with growing attraction and scope of applications. This task aims to generate hyperspectral images (HSIs) with the same spatial resolution by improving the spectral resolution from RGB images . With the successful application of convolutional neural network , some researchers introduce this idea into the task of spectral reconstruction. In this paper, we propose a novel method with a cluster-based deep residual convolutional neural network (DRCNN) for spectral reconstruction from RGB images . To make full use of the local feature on the residual branches, we propose a hierarchical feature fusion (HFF) module to propagate the useful information of preceding blocks to the end of the module. In the training phase, we use RGB images that contain pixels belonging to the same cluster to train the specific DRCNN. In the testing phase, we apply the trained model to reconstruct the corresponding HSIs. As a postprocess, element-wise addition is utilized to generate the complete HSI. Extensive experiments show that the proposed method, compared with the state-of-the-art spectral reconstruction approaches, achieves superior reconstruction performance in three hyperspectral datasets: CAVE, Harvard, and ICVL.},
  archive      = {J_NEUCOM},
  author       = {Changzhong Zou and Minghui Wei},
  doi          = {10.1016/j.neucom.2021.08.104},
  journal      = {Neurocomputing},
  pages        = {342-351},
  shortjournal = {Neurocomputing},
  title        = {Cluster-based deep convolutional networks for spectral reconstruction from RGB images},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep level set learning for optic disc and cup segmentation.
<em>NEUCOM</em>, <em>464</em>, 330–341. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optic disc and cup segmentation play an essential step towards automatic retinal diagnose system. The task is very challenging since the boundary between optic disc and cup is weak and the existing segmentation network with cross-entropy loss is hard to inject domain-specific knowledge. To solve the problem, we propose a level set based deep learning method for optic disc and cup segmentation. Particularly, we treat the output of the neural network as a level set and add several constraints to make the predicted level set satisfy some characteristics, such as the length constraint and region constraint. The length term lets the boundary tend to smooth while the region term lets the response inside the predicted area tend to be the same. The region term considers the relationship between pixels inside optic disc or cup while the cross-entropy loss treats the segmentation as a pixel-wise classification without considering the relationship between pixels. We conduct extensive experiments on several datasets including ORIGA and REFUGE and DRISHTI-GS dataset. The experiment results verify the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Pengshuai Yin and Yanwu Xu and Jinhui Zhu and Jiang Liu and Chang’an Yi and Huichou Huang and Qingyao Wu},
  doi          = {10.1016/j.neucom.2021.08.102},
  journal      = {Neurocomputing},
  pages        = {330-341},
  shortjournal = {Neurocomputing},
  title        = {Deep level set learning for optic disc and cup segmentation},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint nuclear- and ℓ2,1-norm regularized heterogeneous
tensor decomposition for robust classification. <em>NEUCOM</em>,
<em>464</em>, 317–329. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional approaches that represent observations in vector or matrix notation easily lead to structure information losses and dependency destruction between elements. Tensors are the generalizations of matrices, providing a natural representation of rich structure in real-world multiway arrays. Although tensor decomposition has been verified and used in classification tasks , the heterogeneity gap among different orders is often neglected. In this paper, we exploited tensor decomposition framework and presented a heterogeneous tensor decomposition for robust classification (HTDRC) approach, which integrates nuclear and ℓ 2 , 1 ℓ2,1 -norm for intrinsic representation learning . Specifically, to obtain the lowest-rank intrinsic representations of tensorial data from an underlying low-dimensional subspace, HTDRC simultaneously learns a set of orthogonality constrained factor matrices and a low-rank constrained representation matrix . To better guide the decomposition process, a robust discriminant feature selection scheme is utilized by imposing ℓ 2 , 1 ℓ2,1 -norm penalty on the constructed classification loss and the regularized terms simultaneously. Experiments on four datasets demonstrated the superior performance of our proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Peiguang Jing and Yaxin Li and Xinhui Li and Yuting Wu and Yuting Su},
  doi          = {10.1016/j.neucom.2021.08.112},
  journal      = {Neurocomputing},
  pages        = {317-329},
  shortjournal = {Neurocomputing},
  title        = {Joint nuclear- and ℓ2,1-norm regularized heterogeneous tensor decomposition for robust classification},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CapsNet meets SIFT: A robust framework for distorted target
categorization. <em>NEUCOM</em>, <em>464</em>, 290–316. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to overexposure, jitter, motion, and other spatiotemporal-varying perturbations, the collected images always undergo various visual distortions (e.g., deformation, partially occluded signs, fisheye respective, affine or 3D projections, in-plane and out-of-plane rotation) during acquisition or transmission procedure. Deep neural networks (DNNs) perform poorly on such pristine images in terms of high-level abstract operations, e.g., object categorization and semantic segmentation. To conquer this legacy, a distortion-tolerant model denoted as CapsNetSIFT is proposed to enhance representability and detectability of target in distorted imagery. We modify and integrate capsule network (CapsNet) with scale invariant feature transform (SIFT) together, both of which boast innate invariance to spacial-scale transformations. Two key insights, the customized multi-dimensional CapsNet (MD-CapsNet) and vector matching SIFT (VM-SIFT), can cooperate together and reinforce each other: the former encodes and provides representative feature vectors for the later, whilst the later localizes space-scale invariant interval dimensions (instead of pixels) and establish correspondence between source standard images (high-quality training images) and distorted ones (testing images). Thus, the category of one source standard image owning the most associations is the ground-truth category. Evaluation results reveal that employing CapsNetSIFT for distorted target recognition (CUB-200–2011, Stanford Dogs, Stanford Cars, and our hand-crafted dataset), significantly improves the resistance against various simulated distortions, and outperforms state-of-the-arts with relatively higher training and testing accuracy (93.97\% and 91.03\%).},
  archive      = {J_NEUCOM},
  author       = {Zhongqi Lin and Wanlin Gao and Jingdun Jia and Feng Huang},
  doi          = {10.1016/j.neucom.2021.08.087},
  journal      = {Neurocomputing},
  pages        = {290-316},
  shortjournal = {Neurocomputing},
  title        = {CapsNet meets SIFT: A robust framework for distorted target categorization},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Stability analysis for delayed neural networks: A
fractional-order function method. <em>NEUCOM</em>, <em>464</em>,
282–289. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the stability of delayed neural networks (DNNs). An extended version of reciprocally convex inequality named exponential type reciprocally convex inequality (ETRCI) is proposed, which covers some existing results as its special cases. By constructing some intermediary fractional-order polynomials, a set of novel functions named fractional order-polynomial-based functions (FOPFs) are proposed. From the structure of FOPFs, the relationship among system states and time-varying delay can be fully coupled without higher order time delays and zero components. Two merits are first contained in FOPFs compared with the related functions, i) the nonintegral, single, double, and triple integral terms are all introduced in augmentation forms and ii) the delay-product-type integral quadratic terms are constructed. Based on ETRCI and FOPFs, a new stability criterion is obtained for DNNs, in which the potential capacities of advanced bounding techniques are adequately explored and the system information is sufficiently captured. An example is illustrated to demonstrate the effectiveness of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Yufeng Tian and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2021.08.077},
  journal      = {Neurocomputing},
  pages        = {282-289},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis for delayed neural networks: A fractional-order function method},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fully distributed event-triggered pinning group consensus
control for heterogeneous multi-agent systems with
cooperative-competitive interaction strength. <em>NEUCOM</em>,
<em>464</em>, 273–281. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly studies the group consensus problem of the heterogeneous multi-agent systems with cooperative and competitive interactions and their strength among the agents. And both event-triggered mechanism and pinning control method are considered based on the system’s topology with connected components. Besides, the novel fully distributed event-triggered conditions which only contain the local information for each agent are designed. Then, some sufficient conditions and the corresponding pinning control strategies are obtained via using algebraic graph theory and Lyapunov stability theorem, which can guarantee the system to reach multiple group consensus. In addition, Zeno-behavior for each agent is strictly excluded by utilizing time-correlation function. Finally, several simulations illustrate that our findings and the proposed methods are effective. Moreover, the results show that the convergence rate of the system will increase with the appropriate change of the cooperative or competitive interaction or their strength.},
  archive      = {J_NEUCOM},
  author       = {Kangying Li and Lianghao Ji and Cuijuan Zhang and Huaqing Li},
  doi          = {10.1016/j.neucom.2021.08.114},
  journal      = {Neurocomputing},
  pages        = {273-281},
  shortjournal = {Neurocomputing},
  title        = {Fully distributed event-triggered pinning group consensus control for heterogeneous multi-agent systems with cooperative-competitive interaction strength},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mode-dependent guaranteed cost event-triggered
synchronization for singular semi-markov jump neural networks with time
delays. <em>NEUCOM</em>, <em>464</em>, 265–272. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the drive-response synchronization problem for singular semi-Markov jump neural networks with time delays . Furthermore, the mode-dependent event-triggered scheme is applied to improve data transmission efficiency. Sufficient criterion is derived by a designed mode-dependent Lyapunov–Krasovskii functional for synchronization error system. Then, synchronization controller gains matrix and event-triggered weight matrix are co-designed simultaneously assisted by linear matrix inequality, such that proposed guaranteed cost performance can be achieved in the mean-square sense. Finally, the usefulness of our synchronization design is verified by numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Yidao Ji and Hang Fu and Chenan Wang and Wei Wu},
  doi          = {10.1016/j.neucom.2021.08.061},
  journal      = {Neurocomputing},
  pages        = {265-272},
  shortjournal = {Neurocomputing},
  title        = {Mode-dependent guaranteed cost event-triggered synchronization for singular semi-markov jump neural networks with time delays},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conceptual text region network: Cognition-inspired accurate
scene text detection. <em>NEUCOM</em>, <em>464</em>, 252–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation-based methods are widely used for scene text detection due to their superiority in describing arbitrary-shaped text instances. However, two major problems still exist: (1) current label generation techniques are mostly empirical and lack theoretical support, discouraging elaborate label design; and (2) as a result, most methods rely heavily on text kernel segmentation which is unstable and requires deliberate tuning. To address these challenges, we propose a human cognition-inspired framework, termed, Conceptual Text Region Network (CTRNet). The framework utilizes Conceptual Text Regions (CTRs), which is a class of cognition-based tools inheriting good mathematical properties , allowing for sophisticated label design. Another component of CTRNet is an inference pipeline that, with the help of CTRs, completely omits the need for text kernel segmentation. Compared with previous segmentation-based methods, our approach is not only more interpretable but also more accurate. Experiment results show that CTRNet achieves state-of-the-art performance on benchmark CTW1500, Total-Text, MSRA-TD500, and ICDAR 2015 datasets, yielding performance gains of up to 2.0\%. Notably, to the best of our knowledge, CTRNet is among the first detection models to achieve F-measures higher than 85.0\% on all four of the benchmarks, demonstrating remarkable consistency and stability.},
  archive      = {J_NEUCOM},
  author       = {Chenwei Cui and Liangfu Lu and Zhiyuan Tan and Amir Hussain},
  doi          = {10.1016/j.neucom.2021.08.026},
  journal      = {Neurocomputing},
  pages        = {252-264},
  shortjournal = {Neurocomputing},
  title        = {Conceptual text region network: Cognition-inspired accurate scene text detection},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DiaNet: An elastic neural network for effectively
re-configurable implementation. <em>NEUCOM</em>, <em>464</em>, 242–251.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An elastic neural network is developed and evolved towards effectively re-configurable hardware in fully parallel on chip. The original prototype of DiaNet is organized as a symmetrical bisection neural network, which is feasible to be partitioned into arbitrary pieces of neural networks (NNs) without redundancy. To prevent the depth explosion in implementing complex tasks (complicated pattern recognition for instance), the evolution of DiaNets is investigated in this work. By using the I/O layer integration technology which enables all neurons in the hidden layer of DiaNet to receive inputs, the number of layers is reduced to 8.8\% 8.8\% of DiaNet prototype. In this manner, the DiaNet topology is feasible to implement complex NNs without the risk of depth explosion. Moreover, the skip connection technology is proposed to avoid the gradient vanishing due to deep learning , which is significant to DiaNets especially. Compared with the LeNet5 model as state-of-the-art, the evolved DiaNet topology achieves the parameter reduction of 90.86\% 90.86\% for MNIST recognition with the negligible loss of accuracy. To reduce hardware utilization, the sensitivity to the decline of computational precision and bit-width is investigated to suggest the guideline for efficient hardware implementations. Finally, the effectiveness of DiaNet is verified by the proposed re-configurable architecture on FPGA with the power reduction of 10.8\% 10.8\% compared to state-of-the-art implementations.},
  archive      = {J_NEUCOM},
  author       = {Man Wu and Yirong Kan and Tati Erlina and Renyuan Zhang and Yasuhiko Nakashima},
  doi          = {10.1016/j.neucom.2021.08.059},
  journal      = {Neurocomputing},
  pages        = {242-251},
  shortjournal = {Neurocomputing},
  title        = {DiaNet: An elastic neural network for effectively re-configurable implementation},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active learning from label proportions via pSVM.
<em>NEUCOM</em>, <em>464</em>, 227–241. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning from label proportions (LLP), in which the training data is divided into different bags and only the proportions of samples belonging to certain categories in each bag are known, has attracted widespread interest in many application scenarios. However, the existing researches ignore the importance of part instances in which the labels can be easily obtained. In this paper, we propose a novel method called active-pSVM, which incorporates active learning into the large margin framework to solve LLP problem. In detail, we first label the most valuable instances that are selected by QUIRE or uncertainty sampling query strategy. Then, the obtained labeled instances and the given unlabeled data are simultaneously used to construct the prediction model under the large margin framework. Extensive experiments on benchmark datasets show that the proposed active-pSVM outperforms the state-of-the-art approaches for solving LLP problem, i.e. InvCal, alter-∝SVM and LLP-NPSVM.},
  archive      = {J_NEUCOM},
  author       = {Yue Qiu and Mingjie Yan and Zhensong Chen},
  doi          = {10.1016/j.neucom.2021.08.091},
  journal      = {Neurocomputing},
  pages        = {227-241},
  shortjournal = {Neurocomputing},
  title        = {Active learning from label proportions via pSVM},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Representation learning of graphs using graph convolutional
multilayer networks based on motifs. <em>NEUCOM</em>, <em>464</em>,
218–226. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph structure is a commonly used data storage mode, and it turns out that the low-dimensional embedded representation of nodes in the graph is extremely useful in various typical tasks, such as node classification , link prediction, etc. However, most of the existing approaches start from the binary relationship (i.e., edges) in the graph and have not leveraged higher order local structure (i.e., motifs) of the graph. Here, we propose mGCMN – a novel framework which utilizes node feature information and the higher order local structure of the graph to effectively generate node embeddings for previously unseen data. Through research we have found that different types of networks have different key motifs. And the advantages of our method over the baseline methods have been demonstrated in a large number of experiments on citation network and social network datasets. At the same time, a positive correlation between increase of the classification accuracy and the clustering coefficient is revealed. It is believed that using high order structural information can truly manifest the potential of the network, which will greatly improve the learning efficiency of the graph neural network and promote a brand-new learning mode establishment.},
  archive      = {J_NEUCOM},
  author       = {Xing Li and Wei Wei and Xiangnan Feng and Xue Liu and Zhiming Zheng},
  doi          = {10.1016/j.neucom.2021.08.028},
  journal      = {Neurocomputing},
  pages        = {218-226},
  shortjournal = {Neurocomputing},
  title        = {Representation learning of graphs using graph convolutional multilayer networks based on motifs},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensor train decomposition for solving large-scale linear
equations. <em>NEUCOM</em>, <em>464</em>, 203–217. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Solving large-scale linear equations is an important problem in signal processing, machine vision, financial mathematics, quantum physics, chemistry, and many other areas. Due to the curse of dimensionality, classic numerical treatments of such problems are difficult and inefficient, which are usually addressed by low rank approximation methods. Tensor train decomposition (TTD) is one of these methods that can reduce the execution cost theoretically. In this work, we present a TTD based batch alternating least squares (BALS) method, termed as TTD-BALS, for solving large-scale linear equations . TTD-BALS makes the computation efficient and stable, since it can convert the large-scale optimization problem into sequential optimization subproblems with smaller scale. We further uncover that all existing TTD-based methods together with our TTD-BALS are not universal and can be troubled by local minima, and therefore they are not suitable for general and arbitrary linear equations. Fortunately, based on our analysis, if some specific requirements we identified can be satisfied, TTD-BALS is able to provide a very good solution. In fact these requirements can be satisfied in a wide range of domains such as signal processing and scientific computing. Furthermore, we prove that the proposed method is able to reduce the computational complexity , and conduct numerical experiments to confirm its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Hengnu Chen and Lei Deng and Zheng Qu and Ling Liang and Tianyi Yan and Yuan Xie and Guoqi Li},
  doi          = {10.1016/j.neucom.2021.08.034},
  journal      = {Neurocomputing},
  pages        = {203-217},
  shortjournal = {Neurocomputing},
  title        = {Tensor train decomposition for solving large-scale linear equations},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An in-depth comparison of methods handling mixed-attribute
data for general fuzzy min–max neural network. <em>NEUCOM</em>,
<em>464</em>, 175–202. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A general fuzzy min–max (GFMM) neural network is one of the efficient neuro-fuzzy systems for classification problems. However, a disadvantage of most of the current learning algorithms for GFMM is that they can handle effectively numerical valued features only. Therefore, this paper provides some potential approaches to adapting GFMM learning algorithms for classification problems with mixed-type or only categorical features as they are very common in practical applications and often carry very useful information. We will compare and assess three main methods of handling datasets with mixed features, including the use of encoding methods, the combination of the GFMM model with other classifiers, and employing the specific learning algorithms for both types of features. The experimental results showed that the target and James–Stein are appropriate categorical encoding methods for learning algorithms of GFMM models, while the combination of GFMM neural networks and decision trees is a flexible way to enhance the classification performance of GFMM models on datasets with the mixed features. The learning algorithms with the mixed-type feature abilities are potential approaches to deal with mixed-attribute data in a natural way, but they need further improvement to achieve a better classification accuracy. Based on the analysis, we also identify the strong and weak points of different methods and propose potential research directions.},
  archive      = {J_NEUCOM},
  author       = {Thanh Tung Khuat and Bogdan Gabrys},
  doi          = {10.1016/j.neucom.2021.08.083},
  journal      = {Neurocomputing},
  pages        = {175-202},
  shortjournal = {Neurocomputing},
  title        = {An in-depth comparison of methods handling mixed-attribute data for general fuzzy min–max neural network},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CIMask: Segmenting instances by class-specific semantic
feature extraction and instance-specific attribute discrimination.
<em>NEUCOM</em>, <em>464</em>, 164–174. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance segmentation is one of the general but challenging tasks in computer vision. In this paper, we present a novel fast single-stage instance segmentation method, called CIMask, which is faster and more accurate than a few recent competitive approaches, including Mask R-CNN baselines. In our approach, the object mask generation is decoupled into class-specific semantic feature extraction and instance-specific attribute discrimination in parallel, responsible for generating powerful feature representation and identifying individuals, respectively. Then, the final masks are generated by distinguishing individuals with the same class-specific semantic. Furthermore, to better deal with the ambiguous samples in natural scenes, a center-aware sampling scheme for ground truth is introduced, which significantly improves the performance without adding extra parameters. Our comprehensive experiments on MS COCO dataset show the effectiveness of the proposed contributions, leading to state-of-the-art single-stage instance segmentation performance. The center-aware sampling scheme obtains a 1\% steady performance gain on the Cityscapes dataset.},
  archive      = {J_NEUCOM},
  author       = {Canqun Xiang and Wenbin Zou and Chen Xu},
  doi          = {10.1016/j.neucom.2021.08.033},
  journal      = {Neurocomputing},
  pages        = {164-174},
  shortjournal = {Neurocomputing},
  title        = {CIMask: Segmenting instances by class-specific semantic feature extraction and instance-specific attribute discrimination},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive cooperative control of nonlinear multi-agent
systems with uncertain time-varying control directions and dead-zone
nonlinearity. <em>NEUCOM</em>, <em>464</em>, 151–163. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the development of an adaptive cooperative control scheme for the consensus of uncertain nonlinear multi-agent systems subjected to uncertain time-varying control direction, disturbances, and dead-zone nonlinearity. The dead-zone nonlinearity is described by an uncertain nonlinear function of the control input which can represent a wide class of practical input nonlinearities. It is assumed that no prior knowledge about the uncertain nonlinearities of agents, disturbances, dead-zone parameters, magnitude and sign of the control gain is available. In this paper, a Nussbaum function is used to deal with the unknown time-varying control directions problem and a disturbance-like term in the dead-zone description is approximated by an adaptive TSK-type fuzzy system. Then, by using the dynamic surface control approach and radial-basis function neural network , an adaptive distributed controller is designed for each follower agent. Stability analysis shows that all signals of the closed-loop multi-agent system are semi-globally uniformly ultimately bounded and the consensus error can be made arbitrary small by the proper selection of design parameters. Simulation and comparison results demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Maryam Shahriari-kahkeshi and Nader Meskin},
  doi          = {10.1016/j.neucom.2021.08.065},
  journal      = {Neurocomputing},
  pages        = {151-163},
  shortjournal = {Neurocomputing},
  title        = {Adaptive cooperative control of nonlinear multi-agent systems with uncertain time-varying control directions and dead-zone nonlinearity},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring user historical semantic and sentiment preference
for microblog sentiment classification. <em>NEUCOM</em>, <em>464</em>,
141–150. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Microblog text is usually very short, thereby challenging existing sentiment classification methods by providing models with little context. Recently, historical user information has been widely used in many real-world applications, such as recommender systems. However, few research works consider user historical states in the loop of microblog sentiment analysis . In this work, we propose to involve historical user information for microblog sentiment analysis to alleviate the context sparsity problem. In particular, we propose a novel neural microblog sentiment classification method which learns informative representations of microblog posts by exploiting both a user’s contextual information and his/her historical state information. The proposed method consists of four components, i.e., a micropost encoder, a user historical sentiment encoder, a User Historical Semantic Encoder, and a micropost sentiment classification component. Extensive experiments are conducted on real-world data collected from Weibo, and experimental results show that the proposed approach achieves superior performance as compared to state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Xiaofei Zhu and Jie Wu and Ling Zhu and Jiafeng Guo and Ran Yu and Katarina Boland and Stefan Dietze},
  doi          = {10.1016/j.neucom.2021.08.089},
  journal      = {Neurocomputing},
  pages        = {141-150},
  shortjournal = {Neurocomputing},
  title        = {Exploring user historical semantic and sentiment preference for microblog sentiment classification},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning semantic priors for texture-realistic
sketch-to-image synthesis. <em>NEUCOM</em>, <em>464</em>, 130–140. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch-to-image synthesis is a challenging task in the field of computer vision that generates photo-realistic images from given sketches. Existing methods of this kind are unable to discover the inherent semantic information contained in an image and use it to guide the synthesis process , substantially reduce their capacity to generate photo-realistic images. Accordingly, in this paper, we propose a novel framework that explores and leverages semantic information to generate realistic textures in synthesized images for this task. More specifically, the segmentation maps generation network is designed to learn the relationships between sketches and segmentation maps in order to obtain the semantic segmentation maps from the sketches. Taking semantic segmentation maps as the condition, a feature-wise affine transformation is then executed to change the feature maps of intermediate layers in the network, which can efficiently generate the texture required to synthesize more photo-realistic images. Extensive experiments demonstrate that when compared to other state-of-the-art sketch-to-image synthesis methods, our approach can not only synthesize images with significantly superior visual quality but is also able to achieve better results on quantitative metrics.},
  archive      = {J_NEUCOM},
  author       = {Zeyu Li and Cheng Deng and Kun Wei and Wei Liu and Dacheng Tao},
  doi          = {10.1016/j.neucom.2021.08.085},
  journal      = {Neurocomputing},
  pages        = {130-140},
  shortjournal = {Neurocomputing},
  title        = {Learning semantic priors for texture-realistic sketch-to-image synthesis},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unpredictable oscillations of SICNNs with delay.
<em>NEUCOM</em>, <em>464</em>, 119–129. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We rigorously prove that unpredictable oscillations take place in the dynamics of shunting inhibitory cellular neural networks (SICNNs) with delay when rectangular input currents generated by an unpredictable sequence are utilized. The existence, uniqueness, and exponential stability of such oscillations are discussed. The contraction mapping principle is applied to achieve the theoretical results. Numerical simulations supporting the presence of unpredictable oscillations are provided, and the transfer of unpredictable behavior between SICNNs under unidirectional coupling is demonstrated. It is also shown by means of the delayed feedback control method that the obtained unpredictable behavior is controllable. Moreover, an application to secure communication is discussed.},
  archive      = {J_NEUCOM},
  author       = {Mehmet Onur Fen and Fatma Tokmak Fen},
  doi          = {10.1016/j.neucom.2021.08.093},
  journal      = {Neurocomputing},
  pages        = {119-129},
  shortjournal = {Neurocomputing},
  title        = {Unpredictable oscillations of SICNNs with delay},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Atrous spatial pyramid convolution for object detection with
encoder-decoder. <em>NEUCOM</em>, <em>464</em>, 107–118. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, atrous spatial pyramid module and encoder-decoder structure are widely investigated for many computer vision tasks to address the scale variation challenge in deep convolutional networks . The atrous spatial pyramid module aims at capturing local and global cues together with various sampling rates in convolutional or pooling layers. At the same time, encoder-decoder structure propagates context features from low-resolution, strong-semantic features to high-resolution, weak-semantic ones, while maintaining the detail object boundaries. However, the aforementioned two strategies have their own drawbacks, and the previous object detectors only employ one of them to handle scale variation. In this work, we propose to cooperate atrous spatial pyramid convolution (ASPC) with encoder-decoder structure (ED) for object detection, termed ASPC-ED, which combines the complementary advantages from both modules in an end-to-endfashion. Specifically, the proposed method is consist of three components: encoder, ASPC and decoder. The extensive experiments on PASCAL VOC and MS COCO benchmarks demonstrate that our method with various backbone achieves the state-of-the-art results for object detection, instance segmentation and panoptic segmentation.},
  archive      = {J_NEUCOM},
  author       = {Feiran Jie and Qingfeng Nie and Mingsuo Li and Ming Yin and Taisong Jin},
  doi          = {10.1016/j.neucom.2021.07.064},
  journal      = {Neurocomputing},
  pages        = {107-118},
  shortjournal = {Neurocomputing},
  title        = {Atrous spatial pyramid convolution for object detection with encoder-decoder},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep weibull hashing with maximum mean discrepancy
quantization for image retrieval. <em>NEUCOM</em>, <em>464</em>, 95–106.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing has been a promising technology for fast nearest neighbor retrieval in large-scale datasets due to the low storage cost and fast retrieval speed. Most existing deep hashing approaches learn compact hash codes through pair-based deep metric learning such as the triplet loss. However, these methods often consider that the intra-class and inter-class similarity make the same contribution, and consequently it is difficult to assign larger weights for informative samples during the training procedure. Furthermore, only imposing relative distance constraint increases the possibility of being clustered with larger average intra-class distance for similar pairs, which is harmful to learning a high separability Hamming space. To tackle the issues, we put forward deep Weibull hashing with maximum mean discrepancy quantization (DWH), which jointly performs neighborhood structure optimization and error-minimizing quantization to learn high-quality hash codes in a unified framework. Specifically, DWH learns the desired neighborhood structure in conjunction with a flexible pair similarity optimization strategy and a Weibull distribution-based constraint between anchors and their neighbors in Hamming space. More importantly, we design a maximum mean discrepancy quantization objective function to preserve the pairwise similarity when performing binary quantization. Besides, a class-level loss is introduced to mine the semantic structural information of images by using supervision information. The encouraging experimental results on various benchmark datasets demonstrate the efficacy of the proposed DWH.},
  archive      = {J_NEUCOM},
  author       = {Hao Feng and Nian Wang and Jun Tang},
  doi          = {10.1016/j.neucom.2021.08.090},
  journal      = {Neurocomputing},
  pages        = {95-106},
  shortjournal = {Neurocomputing},
  title        = {Deep weibull hashing with maximum mean discrepancy quantization for image retrieval},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards understanding the effect of leak in spiking neural
networks. <em>NEUCOM</em>, <em>464</em>, 83–94. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are being explored to emulate the astounding capabilities of human brain that can learn to perform robust and efficient computations with noisy spikes. A variety of spiking neuron models have been proposed to resemble biological neuronal functionalities. The simplest and most commonly used among these SNNs are leaky-integrate-and-fire (LIF), which contain a leak path in their membrane potential and integrate-and-fire (IF), where the leakage path is absent. While the LIF models have been argued as more bio-plausible, a comparative analysis between models with and without leak from a purely computational point of view demands attention, which we try to address in this paper. Our results reveal that LIF model provides improved robustness and better generalization compared to IF. Frequency domain analysis demonstrates that leak aids in eliminating high-frequency components from the input, thus enhancing noise-robustness of SNNs. Additionally, we compare the sparsity of computation between these models. In general, for the same input, the LIF model would be expected to achieve higher sparsity compared to IF due to the layer-wise decay of spikes caused by membrane potential leak with time. However, contrary to this expectation, we observe that leak decreases the sparsity of computation. Therefore, there exists a trade-off between robustness and energy-efficiency in SNNs which can be optimized through suitable choice of amount of leak in the models.},
  archive      = {J_NEUCOM},
  author       = {Sayeed Shafayet Chowdhury and Chankyu Lee and Kaushik Roy},
  doi          = {10.1016/j.neucom.2021.07.091},
  journal      = {Neurocomputing},
  pages        = {83-94},
  shortjournal = {Neurocomputing},
  title        = {Towards understanding the effect of leak in spiking neural networks},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Capturing combination patterns of long- and short-term
dependencies in multivariate time series forecasting. <em>NEUCOM</em>,
<em>464</em>, 72–82. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series forecasting has typically been a relevant and interesting topic in many fields, including economics, electricity consumption, solar energy, and traffic management. In these domains, owing to the complex dependencies among multiple variables and the mixed dependencies in the time dimension, it is challenging to forecast a multivariate time series precisely. Furthermore, most of the forecasting methods fail to capture the mixed influence of the different time-length dependencies among multiple variables. In this paper, a new deep learning framework is proposed for dealing with this challenging problem, named as mixed dependence time-series network (MDTNet). In this framework, stacked dilated convolutions and recurrent units are applied to extract the complex patterns in the long- and short-term mixed dependencies among multiple variables. The experiments show that our proposed framework yields significant results, outperforming the state-of-the-art baseline methods on three of the four benchmark datasets in large horizons and achieving a competitive performance in short horizons on all the benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Wen Song and Shigeru Fujimura},
  doi          = {10.1016/j.neucom.2021.08.100},
  journal      = {Neurocomputing},
  pages        = {72-82},
  shortjournal = {Neurocomputing},
  title        = {Capturing combination patterns of long- and short-term dependencies in multivariate time series forecasting},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reweighted discriminative optimization for least-squares
problems with point cloud registration. <em>NEUCOM</em>, <em>464</em>,
48–71. (<a href="https://doi.org/10.1016/j.neucom.2021.08.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimization plays a pivotal role in computer graphics and vision. Learning-based optimization algorithms have emerged as a powerful optimization technique for solving problems with robustness and accuracy because it learns gradients from data without calculating the Jacobian and Hessian matrices. The key aspect of the algorithms is the least-squares method, which formulates a general parametrized model of unconstrained optimizations and makes a residual vector approach to zeros to approximate a solution. The method may suffer from undesirable local optima for many applications, especially for point cloud registration, where each element of transformation vectors has a different impact on registration. In this paper, Reweighted Discriminative Optimization (RDO) method is proposed. By assigning different weights to components of the parameter vector, RDO explores the impact of each component and the asymmetrical contributions of the components on fitting results. The weights of parameter vectors are adjusted according to the characteristics of the mean square error of fitting results over the parameter vector space at per iteration. Theoretical analysis for the convergence of RDO is provided, and the benefits of RDO are demonstrated with tasks of 3D point cloud registrations and multi-views stitching. The experimental results show that RDO outperforms state-of-the-art registration methods in terms of accuracy and robustness to perturbations and achieves further improvement than non-weighting learning-based optimization.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhao and Wen Tang and Jun Feng and TaoRuan Wan and Long Xi},
  doi          = {10.1016/j.neucom.2021.08.080},
  journal      = {Neurocomputing},
  pages        = {48-71},
  shortjournal = {Neurocomputing},
  title        = {Reweighted discriminative optimization for least-squares problems with point cloud registration},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Determining learning direction via multi-controller model
for stably searching generative adversarial networks. <em>NEUCOM</em>,
<em>464</em>, 37–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The data generated by Generative Adversarial Network (GAN) inevitably contains noise, which can be reduced by searching and optimizing the architecture of GAN. To search for generative adversarial networks architectures stably, a neural architecture search (NAS) method, StableAutoGAN, is proposed based on the existing algorithm, AutoGAN. The stability of conventional reinforcement learning (RL)-based NAS methods for GAN is adversely influenced by the uncertainty of direction, where the controller will go forward once receiving inaccurate rewards. In StableAutoGAN, a multi-controller model is employed to mitigate this problem via comparing the performance of controllers after receiving rewards. During the search process, each controller independently learns the sampling policy. Meanwhile, the learning effect is measured by the credibility score, which further determines the usage of controllers. Our experiments show that the standard deviation of Frchet Inception Distance (FID) scores of the GANs discovered by StableAutoGAN is approximately 1/16 and 1/8 of that by AutoGAN on CIFAR-10 and on STL-10 respectively, while the effects remain similar to AutoGAN.},
  archive      = {J_NEUCOM},
  author       = {Yi Fan and Quoqiang Zhou and Weifeng Zhang and Shudi Bao and Jun Shen},
  doi          = {10.1016/j.neucom.2021.08.070},
  journal      = {Neurocomputing},
  pages        = {37-47},
  shortjournal = {Neurocomputing},
  title        = {Determining learning direction via multi-controller model for stably searching generative adversarial networks},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). High-order-interaction for weakly supervised fine-grained
visual categorization. <em>NEUCOM</em>, <em>464</em>, 27–36. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-Grained Visual Categorization (FGVC) is a challenging task due to the large intra-subcategory and small inter-subcategory variances. Recent studies tackle this task through a weakly supervised manner without using the part annotation from the experts. Of those, methods based on bilinear pooling are one of the main categories for computing the interaction between deep features and have shown high effectiveness. However, these methods mainly focus on the correlation within one specific layer but largely ignore the high interactions between multiple layers. In this study, we argue that considering the high interaction between the features from multiple layers can help to learn more distinguishing fine-grained features. To this end, we propose a High-Order-Interaction (HOI) method for FGVC. In our HOI, an efficient cross-layer trilinear pooling is introduced to calculate the third-order interaction between three different layers. Third-order interactions of different combinations are then fused to form the final representation. HOI can produce more discriminative representations and be readily integrated with the two popular techniques, attention mechanism and triplet loss, to obtain superposed improvement. Extensive experiments conducted on four FGVC datasets show the great superiority of our method over bilinear-based methods and demonstrate that the proposed method achieves the state of the art.},
  archive      = {J_NEUCOM},
  author       = {Junzheng Wang and Nanyu Li and Zhiming Luo and Zhun Zhong and Shaozi Li},
  doi          = {10.1016/j.neucom.2021.08.108},
  journal      = {Neurocomputing},
  pages        = {27-36},
  shortjournal = {Neurocomputing},
  title        = {High-order-interaction for weakly supervised fine-grained visual categorization},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cephalometric landmark detection by considering
translational invariance in the two-stage framework. <em>NEUCOM</em>,
<em>464</em>, 15–26. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, intelligent cephalometric landmark detection systems that employ deep convolutional neural networks (DCNNs) have been widely developed. In this paper, we concentrate on two challenging difficulties of DCNNs based cephalometric landmark detection. First, previous DCNN methods usually decreased the resolution of high-resolution cephalometric images. Hence, the trained DCNNs missed the detailed local features of original images. Moreover, the detected landmarks’ locations were recovered using a fixed ratio, so location error was increased after recovery. Second, the performance of cephalometric landmark detection is dependent on DCNNs’ translational invariance because the target landmarks’ locations are influenced by any shift of the cephalometric images. However, modern DCNNs have limited translational invariance, and previous DCNN methods did not take translational invariance into consideration. In this paper, we developed the widely used two-stage framework to resolve the above two challenges. In the first stage, we train a global detection network, which receives the whole images as input, to generate candidate landmarks. In the second stage, we split the input image into patches and train a local refine network, which receives image patches as input, to refine the landmarks’ locations. The proposed local refine network can produce accurate landmarks’ locations because it entirely focuses on the detailed local features of high-resolution cephalometric images. The global detection network and local refine network are structured with translational invariance as their primary consideration. The proposed method achieved robust performance on a private dataset and the public Automatic Cephalometric X-ray Landmark Detection Challenge 2015 dataset.},
  archive      = {J_NEUCOM},
  author       = {Tao He and Jie Yao and Weidong Tian and Zhang Yi and Wei Tang and Jixiang Guo},
  doi          = {10.1016/j.neucom.2021.08.042},
  journal      = {Neurocomputing},
  pages        = {15-26},
  shortjournal = {Neurocomputing},
  title        = {Cephalometric landmark detection by considering translational invariance in the two-stage framework},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A brightness-adaptive kernel prediction network for inverse
tone mapping. <em>NEUCOM</em>, <em>464</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The inverse tone mapping (iTM) technique that produces a high dynamic range (HDR) image from one single standard dynamic range (SDR) image has received much attention in industry and academia recently. However, existing methods to recover HDR images mainly focus on overexposed regions but ignore underexposed regions. The underexposed regions in an image are susceptible to noise and artifacts, which will reduce the quality of the image and the user’s visual experience. Therefore, in this paper, we propose a brightness-adaptive iTM model based on deep learning to focus on the content restoration of both the overexposed and underexposed regions in an SDR image simultaneously. In this model, instead of directly predicting the HDR output, we adopt an encoder-decoder network to predict spatially adaptive kernels, which further convolute the input SDR image to produce the HDR result. With the spatially adaptive kernels, the input regions with different exposures can be adaptively mapped by making full use of neighborhood information. Importantly, brightness-adaptive skip connections in the encoder-decoder network, as well as a region loss, are designed to force the proposed model to attach importance to overexposed and underexposed regions. Besides, a global branch is employed in our encoder to exploit both the global and local brightness. Extensive qualitative and quantitative experiments demonstrate that the proposed approach outperforms recent methods on multiple metrics.},
  archive      = {J_NEUCOM},
  author       = {Gaofeng Cao and Fei Zhou and Kanglin Liu and Bozhi, Liu},
  doi          = {10.1016/j.neucom.2021.08.057},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {A brightness-adaptive kernel prediction network for inverse tone mapping},
  volume       = {464},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Category-consistent deep network learning for accurate
vehicle logo recognition. <em>NEUCOM</em>, <em>463</em>, 623–636. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle logo recognition (VLR) is essential in intelligent transportation systems . Although many VLR algorithms have been proposed, efficient and accurate VLR remains challenging in machine vision. Many VLR algorithms explicitly detect the coarse region of the vehicle logo either by offsetting the detected location of the license plate or by training on numerous images with manual bounding-box annotations. However, the results of license plate detection can significantly influence the VLR accuracy, whereas bounding-box annotations are considerably labor-intensive. Thus, we propose a novel category-consistent deep network learning framework for accurate VLR. A convolutional-neural-network-based vehicle logo feature extraction model is proposed to extract deep features by considering both high- and low-level features in an image. Moreover, a novel category-consistent mask learning module is proposed to help the framework to focus on category-consistent regions without relying on license plate detection or manual box annotations. The deep network is trained and optimized iteratively with the objective function incorporating classification loss and category-consistency loss. Extensive experimental evaluations and comparisons on the publicly available HFUT, XMU, CompCars, and VLD-45 datasets demonstrate the feasibility and superiority of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Wanglong Lu and Hanli Zhao and Qi He and Hui Huang and Xiaogang Jin},
  doi          = {10.1016/j.neucom.2021.08.030},
  journal      = {Neurocomputing},
  pages        = {623-636},
  shortjournal = {Neurocomputing},
  title        = {Category-consistent deep network learning for accurate vehicle logo recognition},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PGNet: Panoptic parsing guided deep stereo matching.
<em>NEUCOM</em>, <em>463</em>, 609–622. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an intensive research area of computer vision, stereovision has a wide range of applications. With the development of deep learning , the performance of stereo matching has been greatly improved. Despite of great progress, it is still very challenging to obtain accurate disparities in the complex scenes with low texture, occlusion or large illumination changes. Panoptic parsing , also known as the combination of semantic and instance segmentation , has the probability to provide valuable high-level scene clues to tackle these challenges. In this paper, we propose a panoptic parsing guided deep network (PGNet) to fulfill the stereo matching task. Upon the PSMNet backbone, three novel modules are designed to embed the panoptic guidance. The confidence module generates the confidence value of cost volume to adjust the probability of candidate disparities. The residual module refines the initial disparity results according to their semantic categories and instance layout. Lastly, the loss module supervises the training of network by inducing extra boundary and smooth constraints from semantic and instance groundtruth. The proposed network has been evaluated on various public datasets like KITTI 2015, KITTI 2012, Virtual KITTI and DrivingStereo, and achieves the state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Shuya Chen and Zhiyu Xiang and Chengyu Qiao and Yiman Chen and Tingming Bai},
  doi          = {10.1016/j.neucom.2021.08.041},
  journal      = {Neurocomputing},
  pages        = {609-622},
  shortjournal = {Neurocomputing},
  title        = {PGNet: Panoptic parsing guided deep stereo matching},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic topic labeling using graph-based pre-trained
neural embedding. <em>NEUCOM</em>, <em>463</em>, 596–608. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is necessary to reduce the cognitive overhead of interpreting the native topic term list of the Latent Dirichlet Allocation (LDA) style topic model. In this regard, automatic topic labeling has become an effective approach to generate meaningful alternative representations of topics discovered for end-users. In this study, we introduced a novel two-phase neural embedding framework with the redundancy-aware graph-based ranking process. It demonstrated how pre-trained neural embedding could be usefully applied in topic terms, sentence presentations, and automatic topic labeling tasks. Moreover, reranking the topic terms optimized the discovered topics with fewer yet more representative terms while retaining the topic information integrality and fidelity. It further decreased the burden of computation caused by neural embedding and improved the overall effectiveness of the labeling system. Compared with the prevailing state-of-the-art and classical labeling systems, our efficient model boosted the quality of the topic labels generated and discovered more meaningful topic labels.},
  archive      = {J_NEUCOM},
  author       = {Dongbin He and Yanzhao Ren and Abdul Mateen Khattak and Xinliang Liu and Sha Tao and Wanlin Gao},
  doi          = {10.1016/j.neucom.2021.08.078},
  journal      = {Neurocomputing},
  pages        = {596-608},
  shortjournal = {Neurocomputing},
  title        = {Automatic topic labeling using graph-based pre-trained neural embedding},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hypergraph wavelet neural networks for 3D object
classification. <em>NEUCOM</em>, <em>463</em>, 580–595. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, hypergraph learning has shown great potential in a variety of classification tasks. However, existing hypergraph neural networks lack flexibility in modeling and extracting high-order relationships among data. To solve this problem, we propose a novel framework called hypergraph wavelet neural networks (HGWNN) to explore the high-order correlation in 3D data. Firstly, considering the non-uniformity of most data sets in the real world, we propose a “data-driven” hypergraph construction scheme, which is more efficient than some commonly used hypergraph construction methods. Secondly, in order to efficiently learn deep embeddings from the constructed hypergraph, we propose a hypergraph wavelet convolution operator. It enables efficient information aggregation by fully exploiting the localization property of wavelets. This convolution operator is suitable for both non-uniform and uniform hypergraphs. Finally, we design a new hypergraph regularizer based on the sparse prior of wavelet coefficients to promote local smoothness and avoid network overfitting. We have conducted experiments on object classification tasks on two 3D benchmark datasets: the National Taiwan University (NTU) 3D model dataset and the ModelNet40 dataset. Experimental results demonstrate the effectiveness of the proposed method compared with the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Liping Nong and Junyi Wang and Jiming Lin and Hongbing Qiu and Lin Zheng and Wenhui Zhang},
  doi          = {10.1016/j.neucom.2021.08.006},
  journal      = {Neurocomputing},
  pages        = {580-595},
  shortjournal = {Neurocomputing},
  title        = {Hypergraph wavelet neural networks for 3D object classification},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse learning of band power features with genetic channel
selection for effective classification of EEG signals. <em>NEUCOM</em>,
<em>463</em>, 566–579. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a genetic algorithm (GA) based band power feature sparse learning (SL) approach for classification of electroencephalogram (EEG) (GABSLEEG) in motor imagery (MI) based brain-computer interfacing (BCI). The band power in the alpha and beta bands was extracted from the EEG segments and used as features to construct the SL dictionary, in which the GA was employed for channel selection. The GABSLEEG system was tested in three functional areas: i) classification of MI data and idle state data; ii) performance with decreased training data size; and iii) computational efficiency. The system was evaluated by dividing the data into training, validation, and testing sets. The proposed GABSLEEG model is found to significantly outperform conventional classifiers, including the support vector machine (SVM) classifier in (i-iii), and the random forest (RF) and the k -nearest neighbour ( k -NN) classifiers in (i-ii). The GABSLEEG system consistently had a higher classification accuracy, sensitivity, and specificity. The average accuracy of the proposed system was 99.65\%, on BCI Competition IV dataset 1 and 96.08\% for BCI Competition III dataset IVa with the idle state included as a class, which was on a par with state-of-the-art SL and even deep learning approaches.},
  archive      = {J_NEUCOM},
  author       = {Natasha Padfield and Jinchang Ren and Paul Murray and Huimin Zhao},
  doi          = {10.1016/j.neucom.2021.08.067},
  journal      = {Neurocomputing},
  pages        = {566-579},
  shortjournal = {Neurocomputing},
  title        = {Sparse learning of band power features with genetic channel selection for effective classification of EEG signals},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensor LISTA: Differentiable sparse representation learning
for multi-dimensional tensor. <em>NEUCOM</em>, <em>463</em>, 554–565.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing algorithms for sparse coding, which aim to seek sparse representation for given multi-dimensional signal, suffer from two main defects. Vector-based algorithms, e.g., LISTA, couldn’t handle the signal in tensor form well. On the other hand, tensor-based algorithms are not learnable yet, leading to high computational cost. Towards this dilemma, we propose Tensor LISTA (TLISTA) bA to a multi-dimensional tensor-based model. Benefiting from tensor representation and differentiable programming, TLISTA achieves rapid inference speed and acquires more valuable representation for the data primarily organized in tensor form. Theoretical analysis about the convergence of TLISTA is then introduced, showing that TLISTA can attain the linear convergence rate. Extensive experiments confirm the effectiveness and efficiency of TLISTA for tensor sparse coding.},
  archive      = {J_NEUCOM},
  author       = {Qi Zhao and Guangcan Liu and Qingshan Liu},
  doi          = {10.1016/j.neucom.2021.08.024},
  journal      = {Neurocomputing},
  pages        = {554-565},
  shortjournal = {Neurocomputing},
  title        = {Tensor LISTA: Differentiable sparse representation learning for multi-dimensional tensor},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). No routing needed between capsules. <em>NEUCOM</em>,
<em>463</em>, 545–553. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most capsule network designs rely on traditional matrix multiplication between capsule layers and computationally expensive routing mechanisms to deal with the capsule dimensional entanglement that the matrix multiplication introduces. By using Homogeneous Vector Capsules (HVCs), which use element-wise multiplication rather than matrix multiplication, the dimensions of the capsules remain unentangled. In this work, we study HVCs as applied to the highly structured MNIST dataset in order to produce a direct comparison to the capsule research direction of Geoffrey Hinton, et al. In our study, we show that a simple convolutional neural network using HVCs performs as well as the prior best performing capsule network on MNIST using 5.5× fewer parameters, 4× fewer training epochs, no reconstruction sub-network, and requiring no routing mechanism. The addition of multiple classification branches to the network establishes a new state of the art for the MNIST dataset with an accuracy of 99.87\% for an ensemble of these models, as well as establishing a new state of the art for a single model (99.83\% accurate).},
  archive      = {J_NEUCOM},
  author       = {Adam Byerly and Tatiana Kalganova and Ian Dear},
  doi          = {10.1016/j.neucom.2021.08.064},
  journal      = {Neurocomputing},
  pages        = {545-553},
  shortjournal = {Neurocomputing},
  title        = {No routing needed between capsules},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Graph-based broad learning system for classification.
<em>NEUCOM</em>, <em>463</em>, 535–544. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) is viewed as an alternative method of deep neural network (DNN). Comparing with DNN, BLS can reach a similar performance with much faster learning speed. BLS contains two kinds of features: the mapped features and the enhancement nodes. The mapped features are obtained by randomly generated connecting weights and biases which are then fine-tuned by sparse autoencoder . But sparse autoencoder , as an unsupervised leaning algorithm, will lose the information of ground truths. The enhancement nodes are formed based on the mapped features with randomly generated weights and biases. However, this random process cannot guarantee the quality of these formed nodes. It means BLS may be unable to learn useful enough representations of original data. Considering the effectiveness of extreme learning machine based autoencoder (ELM-AE), we first propose a novel graph-based ELM-AE (GBEAE) method. Then, a GBEAE-based broad learning system (GBEAE-BLS) is introduced to overcome the disadvantages discussed above. Finally, we use 23 datasets to test the performance of GBEAE-BLS. Experimental results demonstrate that GBEAE-BLS has evident superiorities on these datasets, comparing with related learning algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zheng Liu and Shiluo Huang and Wei Jin and Ying Mu},
  doi          = {10.1016/j.neucom.2021.07.065},
  journal      = {Neurocomputing},
  pages        = {535-544},
  shortjournal = {Neurocomputing},
  title        = {Graph-based broad learning system for classification},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blind image super-resolution based on prior correction
network. <em>NEUCOM</em>, <em>463</em>, 525–534. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) based super-resolution (SR) methods have achieved remarkable progress in recent years. Most of these methods assume that the degradation is known and fixed, such as bicubic downsampling. However, the performance of CNNs-based methods suffers from a severe drop when the actual degradation mismatch the training one. This paper proposes a prior correction network (PCNet) to solve the blind SR problem, which makes CNNs-based super-resolvers trained in a fixed blur kernel but applied to other unknown blur kernels. The PCNet consists of a kernel estimation network, a correction filter module, and a correction refinement network. The kernel estimation network aims to estimate unknown blur kernel from the input low-resolution (LR) image. The correction filter module then transfers the estimated degraded domains to adapt to specific degradations (e.g., bicubic downsampling). Finally, the correction refinement network adjusts the corrected LR image to eliminate the influence of blur kernel mismatch or misestimate. Experimental results on diverse datasets show that the proposed PCNet, combined with existing CNNs-based SR methods, outperforms other state-of-the-art algorithms for blind SR. Code is available at: \url{ https://github.com/caoxiang104/PCNet }.},
  archive      = {J_NEUCOM},
  author       = {Xiang Cao and Yihao Luo and Yi Xiao and Xianyi Zhu and Tianjiang Wang and Qi Feng and Zehan Tan},
  doi          = {10.1016/j.neucom.2021.07.070},
  journal      = {Neurocomputing},
  pages        = {525-534},
  shortjournal = {Neurocomputing},
  title        = {Blind image super-resolution based on prior correction network},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning interpretable multi-class models by means of
hierarchical decomposition: Threshold control for nested dichotomies.
<em>NEUCOM</em>, <em>463</em>, 514–524. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of Artificial Intelligence at solving real-world problems poses the need for interpretable models, especially in human-centered applications. The multi-class scenario is often present in these environments; however, the majority of research on interpretability has focused on binary classification. In this work, a novel method based on hierarchical decompositions to obtain interpretable multi-class models is introduced. The proposal, named Threshold Control for Nested Dichotomies (TC-ND) method, creates a binary-based hierarchical class structure. Then, it discards meta-classes at each dichotomy of the structure according to a certain level of confidence, pursuing a modular and more comprehensible decomposition of the multi-class problem. The approach presents internal parameters that are optimized using the Differential Evolution algorithm. The goodness of our proposal is assessed using a twofold approach: performance is evaluated by comparing against other state-of-the-art multi-class methods; interpretability is supported by practical examples with counterfactual explanations and a discussion of the advantages that the TC-ND method presents regarding its transparency and auditability.},
  archive      = {J_NEUCOM},
  author       = {J.A. Fdez-Sánchez and J.D. Pascual-Triana and A. Fernández and F. Herrera},
  doi          = {10.1016/j.neucom.2021.07.097},
  journal      = {Neurocomputing},
  pages        = {514-524},
  shortjournal = {Neurocomputing},
  title        = {Learning interpretable multi-class models by means of hierarchical decomposition: Threshold control for nested dichotomies},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leakage delay on stabilization of finite-time complex-valued
BAM neural network: Decomposition approach. <em>NEUCOM</em>,
<em>463</em>, 505–513. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the finite-time stabilization (FTS) problem of leakage delay on complex-valued bidirectional associative memory (BAM) neural networks (CVBAMNNs) with time delays via decomposition approach. This analysis is on the basis of some novel sufficient conditions that the FTS of CVBAMNNs are obtained via Lyapunov functional and upper right Dini derivative concepts. The complex-valued nonlinear function is divided into its real and imaginary components to a set of criteria for the FTS using decomposition technique of CVBAMNNs. We develop feedback controllers in the context of the double-layer structure of the CVBAMNNs. Finally, one numerical example is offered to show the availability of the findings achieved.},
  archive      = {J_NEUCOM},
  author       = {Yang Cao and S. Ramajayam and R. Sriraman and R. Samidurai},
  doi          = {10.1016/j.neucom.2021.08.056},
  journal      = {Neurocomputing},
  pages        = {505-513},
  shortjournal = {Neurocomputing},
  title        = {Leakage delay on stabilization of finite-time complex-valued BAM neural network: Decomposition approach},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Determination of confidence bounds and artificial neural
networks in non-linear optimization problems. <em>NEUCOM</em>,
<em>463</em>, 495–504. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feedforward is a type of ANN (artificial neural network) widely used in modeling linear and non-linear systems. This type of ANN is found in system identification, system control, and optimization. In most works on optimization with ANN embedded, the purpose of the ANN is to provide a surrogate model that approximates the objective function. Since the ANN is an algorithm that is trained with an experimental/actual data set, it is imperative to know the limits of the data set and therefore avoid the extrapolation of the ANN. This work proposes a procedure where the network model domain is limited using the Quickhull algorithm, avoiding extrapolation. Also, this procedure allows for the quantification of the accuracy in the network&#39;s predictions, while taking into account the density of the training data within the network model domain. The procedure considers four essential steps: the modeling of the objective function, the model domain determination, the application of the operational constraints, and the optimization. Two examples of optimization are solved using this procedure, where the results are assessed according to the width of the confidence bounds, measuring how far or near the actual value is.},
  archive      = {J_NEUCOM},
  author       = {Luis R. Pineda and Alberto L. Serpa},
  doi          = {10.1016/j.neucom.2021.08.075},
  journal      = {Neurocomputing},
  pages        = {495-504},
  shortjournal = {Neurocomputing},
  title        = {Determination of confidence bounds and artificial neural networks in non-linear optimization problems},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-time adaptive observer-based time-varying formation
control for multi-agent systems with directed topologies.
<em>NEUCOM</em>, <em>463</em>, 483–494. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel time-varying formation tracking control scheme in fixed-time framework under directed topologies is proposed for multi-agent systems (MASs), with consideration of uncertainties and the absence of the leader’s velocity measurements (LVMs). First, a novel cascaded fixed-time state observer (CFTSO) under directed topologies without LVMs is developed for each follower to acquire the estimates of the leader’s states (LSs) in a fixed time. Then, minimal learning parameter (MLP) methods combining with radial basis function neural networks (RBFNNs) are utilized to cope with the uncertainties. Finally, on the basis of the designed CFTSO and MLP, a new formation control scheme in fixed-time framework under directed topologies is established to solve the time-varying formation tracking control problem.},
  archive      = {J_NEUCOM},
  author       = {Tianyi Xiong and Zhou Gu and Jianqiang Yi and Zhiqiang Pu},
  doi          = {10.1016/j.neucom.2021.08.081},
  journal      = {Neurocomputing},
  pages        = {483-494},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time adaptive observer-based time-varying formation control for multi-agent systems with directed topologies},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised multi-body scene flow estimation.
<em>NEUCOM</em>, <em>463</em>, 472–482. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of scene flow estimation from consecutive stereo pairs . In contrast to the state-of-the-art supervised learning based methods, we propose a self-supervised learning based pipeline that removes the requirement of large-scale ground truth annotations. Specifically, we employ a shared encoder StereoFlowNet to simultaneously learn optical flow estimation and disparity estimation, which not only achieves a compact network representation but also exploits the inherent connections between optical flow estimation and disparity estimation. To leverage the scene structure and motion representations, we propose to utilize a piece-wise planar model based disparity computation and multiple rigid body motion representation of the dynamic scene. In this way, the geometric and motion constraints play strong regularizations for the underlying problem. Experimental results on benchmarking dataset show that our proposed method achieves state-of-the-art performance in both optical flow and disparity estimation.},
  archive      = {J_NEUCOM},
  author       = {Jihuang Dai and Yuchao Dai and Bin Fan},
  doi          = {10.1016/j.neucom.2021.08.008},
  journal      = {Neurocomputing},
  pages        = {472-482},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised multi-body scene flow estimation},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Temporal convolutional networks for just-in-time design
smells prediction using fine-grained software metrics. <em>NEUCOM</em>,
<em>463</em>, 454–471. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software systems quality is strongly influenced by the presence of design problems and wrong constructs introduced during software evolution. Design smells are recognized to be indicators of such problems since their presence can indicate violations of the fundamental software design principles. This explains the interest of software researchers and developers in new approaches performing design smell early detection. In this paper, the adoption of a just-in-time design smell prediction approach is proposed. The approach uses a variant of Temporal Convolutional Networks (TCN) to predict the presence of design smells before they are introduced in the model. In comparison to other studies, in the proposed approach we focus on commit-level fine-grained product metrics and process metrics (i.e., ownership and seniority) to make deep neural networks training suitable. The validation is performed on a large dataset composed of six open source systems . The results show good prediction performance for some design smells and for all the considered design smells categories. The experiment performed shows that, with respect to baseline prediction models (i.e., LSTM ,CNN and RF), the proposed TCN variant trained on the identified metrics, gives better results.},
  archive      = {J_NEUCOM},
  author       = {Pasquale Ardimento and Lerina Aversano and Mario Luca Bernardi and Marta Cimitile and Martina Iammarino},
  doi          = {10.1016/j.neucom.2021.08.010},
  journal      = {Neurocomputing},
  pages        = {454-471},
  shortjournal = {Neurocomputing},
  title        = {Temporal convolutional networks for just-in-time design smells prediction using fine-grained software metrics},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward 3D object reconstruction from stereo images.
<em>NEUCOM</em>, <em>463</em>, 444–453. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring the complete 3D shape of an object from an RGB image has shown impressive results, however, existing methods rely primarily on recognizing the most similar 3D model from the training set to solve the problem. These methods suffer from poor generalization and may lead to low-quality reconstructions for unseen objects. Nowadays, stereo cameras are pervasive in emerging devices such as dual-lens smartphones and robots, which enables the use of the two-view nature of stereo images to explore the 3D structure and thus improve the reconstruction performance. In this paper, we propose a new deep learning framework for reconstructing the 3D shape of an object from a pair of stereo images , which reasons about the 3D structure of the object by taking bidirectional disparities and feature correspondences between the two views into account. Besides, we present a large-scale synthetic benchmarking dataset , namely StereoShapeNet , containing 1,052,976 pairs of stereo images rendered from ShapeNet along with the corresponding bidirectional depth and disparity maps. Experimental results on the StereoShapeNet benchmark demonstrate that the proposed framework outperforms the state-of-the-art methods. The project page is available at https://haozhexie.com/project/stereo-3d-reconstruction .},
  archive      = {J_NEUCOM},
  author       = {Haozhe Xie and Hongxun Yao and Shangchen Zhou and Shengping Zhang and Xiaojun Tong and Wenxiu Sun},
  doi          = {10.1016/j.neucom.2021.07.089},
  journal      = {Neurocomputing},
  pages        = {444-453},
  shortjournal = {Neurocomputing},
  title        = {Toward 3D object reconstruction from stereo images},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). New asymptotic stability analysis for generalized neural
networks with additive time-varying delays and general activation
function. <em>NEUCOM</em>, <em>463</em>, 437–443. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the asymptotic stability problems of the generalized neural networks (GNNs) with two additive time-varying delays (ATDs) and general activation function . First of all, a simple Lyapunov-Krasovskii functional (LKF) is established. Then not only the generalized free-weighting-matrix-based (GFWM-based) inequality together with its optimization strategy on choosing an arbitrary vector is utilized to estimate the single integral terms in derivative of the constructed LKF, but also the general activation function method is applied to introduce more information on cross terms of neuron activation function. Finally, a less conservative stability criterion together with its corollary is derived with convex combination technique, whose feasibility and superiority can be demonstrated with two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Fang Liu and Haitao Liu and Kangzhi Liu},
  doi          = {10.1016/j.neucom.2021.08.066},
  journal      = {Neurocomputing},
  pages        = {437-443},
  shortjournal = {Neurocomputing},
  title        = {New asymptotic stability analysis for generalized neural networks with additive time-varying delays and general activation function},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reinforced knowledge distillation: Multi-class imbalanced
classifier based on policy gradient reinforcement learning.
<em>NEUCOM</em>, <em>463</em>, 422–436. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The real-world datasets often exhibit imbalanced class distribution, which is a common challenge for multi-class classification algorithms. To settle the multi-class imbalanced classification problem of class imbalance learning, a novel reinforced knowledge distillation method is proposed in this paper. In the reinforced knowledge distillation , an improved fine-grained classification architecture based on knowledge distillation strategy and policy gradient reinforcement learning is proposed. In addition, reinforced knowledge distillation uses a newly designed reward signal and a novel sample weights update strategy to train the policies to find the optimal student-network, which makes reinforced knowledge distillation more powerful in handling the multi-class imbalanced classification problem. The effectiveness and practicability of the proposed reinforced knowledge distillation method are verified through its application to a simulated industrial process benchmark and extensive real-world datasets.},
  archive      = {J_NEUCOM},
  author       = {Saite Fan and Xinmin Zhang and Zhihuan Song},
  doi          = {10.1016/j.neucom.2021.08.040},
  journal      = {Neurocomputing},
  pages        = {422-436},
  shortjournal = {Neurocomputing},
  title        = {Reinforced knowledge distillation: Multi-class imbalanced classifier based on policy gradient reinforcement learning},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential convolutional network for behavioral pattern
extraction in gait recognition. <em>NEUCOM</em>, <em>463</em>, 411–421.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a unique and promising biometric , video-based gait recognition has broad applications. The key step of this methodology is to learn the walking pattern of individuals, which, however, often suffers challenges to extract the behavioral feature from a sequence directly. Most existing methods just focus on either the appearance or the motion pattern. To overcome these limitations, we propose a sequential convolutional network (SCN) from a novel perspective, where spatiotemporal features can be learned by a basic convolutional backbone. In SCN, behavioral information extractors (BIE) are constructed to comprehend intermediate feature maps in time series through motion templates where the relation between frames can be analyzed, thereby distilling the information of the walking pattern. Furthermore, a multi-frame aggregator in SCN performs feature integration on a sequence whose length is uncertain, via a mobile 3D convolutional layer . To demonstrate the effectiveness, experiments have been conducted on two popular public benchmarks, CASIA-B and OU-MVLP, and our approach is demonstrated excellent performance, comparing with the state-of-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xinnan Ding and Kejun Wang and Chenhui Wang and Tianyi Lan and Liangliang Liu},
  doi          = {10.1016/j.neucom.2021.08.054},
  journal      = {Neurocomputing},
  pages        = {411-421},
  shortjournal = {Neurocomputing},
  title        = {Sequential convolutional network for behavioral pattern extraction in gait recognition},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coarse-grained generalized zero-shot learning with efficient
self-focus mechanism. <em>NEUCOM</em>, <em>463</em>, 400–410. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For image classification in computer vision, the performance of conventional deep neural networks (DNN) may usually drop when labeled training samples are limited. In this case, few-shot learning (FSL) or particularly zero-shot learning (ZSL), i.e. classification of target classes with few or zero labeled training samples, was proposed to imitate the strong learning ability of human. However, recent investigations show that most existing ZSL models may easily overfit and they tend to misclassify the target instance as one class seen in the training set. To alleviate this problem, we proposed an embedding based ZSL method with a self-focus mechanism, i.e. a focus-ratio that introduces the importance of each dimension, into the model optimization process. The objective function will be reconstructed according to these focus-ratios encouraging that the embedding model focus exclusively on important dimensions in the target space. As the self-focus module only takes part in the training process, the over-fitting knowledge is apportioned, and hence the rest embedding model can become more generalized for the new classes during test. Experimental results on four benchmarks, including AwA1, AwA2, aPY and CUB, show that our method outperforms the state-of-the-art methods on coarse-grained ZSL tasks while not affecting the performance of fine-grained ZSL. Additionally, several comparisons demonstrate the superiority of the proposed mechanism.},
  archive      = {J_NEUCOM},
  author       = {Guanyu Yang and Kaizhu Huang and Rui Zhang and John Y. Goulermas and Amir Hussain},
  doi          = {10.1016/j.neucom.2021.08.027},
  journal      = {Neurocomputing},
  pages        = {400-410},
  shortjournal = {Neurocomputing},
  title        = {Coarse-grained generalized zero-shot learning with efficient self-focus mechanism},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Divide-and-merge the embedding space for cross-modality
person search. <em>NEUCOM</em>, <em>463</em>, 388–399. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the problem of text-based person search, which aims to find the corresponding person of a given text description in an image gallery. Existing methods usually learn a similarity mapping of local parts between image and text, or embed the whole image and text into a unified embedding space. However, the relevance between local and the whole is largely underexplored. In this paper, we design a Divide-and-Merge Embedding (DME) learning framework for text-based person search. DME explicitly 1) models the relations between local parts and global embedding, 2) incorporates local details into global embedding. Specifically, we design a Feature Dividing Network (FDN) to embed the input into K K locally guided semantic representations by self-attentive embedding, each representation depicts a local part of the person. Then, we propose a Relevance based Subspace Projection (RSP) method for merging diverse local representations to a compact global embedding. RSP helps the model to obtain discriminative embedding by jointly minimizing the redundancy of local parts and maximizing the relevance between local parts and global embedding. Extensive experimental results on three challenging benchmarks, i.e., CUHK-PEDES, CUB and Flowers datasets, have demonstrated the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Chengji Wang and Zhiming Luo and Zhun Zhong and Shaozi Li},
  doi          = {10.1016/j.neucom.2021.08.058},
  journal      = {Neurocomputing},
  pages        = {388-399},
  shortjournal = {Neurocomputing},
  title        = {Divide-and-merge the embedding space for cross-modality person search},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning with smooth hinge losses. <em>NEUCOM</em>,
<em>463</em>, 379–387. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the non-smoothness of the Hinge loss in SVM , it is difficult to obtain a faster convergence rate with modern optimization algorithms . In this paper, we introduce two smooth Hinge losses ψ G ( α ; σ ) ψG(α;σ) and ψ M ( α ; σ ) ψM(α;σ) which are infinitely differentiable and converge to the Hinge loss uniformly in α α as σ σ tends to 0 0 . By replacing the Hinge loss with these two smooth Hinge losses, we obtain two smooth support vector machines (SSVMs), respectively. Solving the SSVMs with the Trust Region Newton method (TRON) leads to two quadratically convergent algorithms. Experiments in text classification tasks show that the proposed SSVMs are effective in real-world applications. We also introduce a general smooth convex loss function to unify several commonly-used convex loss functions in machine learning . The general framework provides smooth approximation functions to non-smooth convex loss functions, which can be used to obtain smooth models that can be solved with faster convergent optimization algorithms .},
  archive      = {J_NEUCOM},
  author       = {JunRu Luo and Hong Qiao and Bo Zhang},
  doi          = {10.1016/j.neucom.2021.08.060},
  journal      = {Neurocomputing},
  pages        = {379-387},
  shortjournal = {Neurocomputing},
  title        = {Learning with smooth hinge losses},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving neural machine translation with latent features
feedback. <em>NEUCOM</em>, <em>463</em>, 368–378. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most state-of-the-art neural machine translation (NMT) models progressively encode feature representation in a bottom-up feed-forward fashion. This traditional encoding mechanism has no guidance from external signals. In computer vision tasks , the feedback connection plays a crucial role, particularly for understanding tasks. In this paper, we propose a simple but effective approach to learn latent feature representations explicitly from input sentences via a latent feature encoder (LFE), which are fed back to an NMT encoder via a top-down feedback mechanism. Through the feedback mechanism, the representations in one layer are influenced by representations of both lower and higher layers, resulting in a more effective encoding mechanism. Besides, to enhance the capability of the LFE in better capturing latent features from the source sentences, we pre-train the LFE via a Denoising Auto-Encoder (DAE) strategy. Experimentation on the large-scale WMT 2014 English-to-German and WMT 2017 Chinese-to-English translation tasks demonstrates that our proposed LFE, either pre-trained with the DAE or not, significantly outperforms the strong baseline.},
  archive      = {J_NEUCOM},
  author       = {Yachao Li and Junhui Li and Min Zhang},
  doi          = {10.1016/j.neucom.2021.08.019},
  journal      = {Neurocomputing},
  pages        = {368-378},
  shortjournal = {Neurocomputing},
  title        = {Improving neural machine translation with latent features feedback},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cost-effective batch-mode multi-label active learning.
<em>NEUCOM</em>, <em>463</em>, 355–367. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active learning aims to select the most valuable unlabeled instances for annotations and thus to maximize the performance of a learner with the selected instances. Batch-mode active learning methods can select a batch of unlabeled instances with informativeness and low redundancy at each iteration, they are more efficient than myopic active learning methods, which typically have to retrain the model after querying each instance. However, Batch-mode Multi-label Active Learning is not well explored yet, since it is quite difficult to select a batch of instances or instance-label pairs with high informativeness but low redundancy for query and budget saving. In this paper, we propose a novel approach CBMAL (Cost-effective Batch-mode Multi-label Active Learning) to address this challenge. CBMAL firstly selects a batch of informative instance-label pairs using uncertainty, label correlation and label space sparsity . Next, CBMAL leverages the information from the feature and label dimensions to pick out a small batch of instance-label pairs with the highest information and lowest redundancy from the first batch. These instance-label pairs are then queried and used to update the learner for the next iteration. Experimental results on six benchmark datasets demonstrate that CBMAL can reduce both the query and time costs while achieve a better performance than state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqiang Gui and Xudong Lu and Guoxian Yu},
  doi          = {10.1016/j.neucom.2021.08.063},
  journal      = {Neurocomputing},
  pages        = {355-367},
  shortjournal = {Neurocomputing},
  title        = {Cost-effective batch-mode multi-label active learning},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A memristor-based circuit design of pavlov associative
memory with secondary conditional reflex and its application.
<em>NEUCOM</em>, <em>463</em>, 341–354. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existing Pavlov associative memory circuit only realizes the simple conditioned reflex process, secondary conditional reflex can make the simple conditioning process more complicated and make the circuit more bionic, but there is a lack of relevant circuit implementation. In this paper, a Pavlov associative memory circuit with secondary conditional reflex is proposed by utilizing the memristor . The proposed circuit can respond to a conditional stimulus after initial learning and have two kinds of forgetting process. Besides, this circuit can indirectly establish conditioned reflexes through conditioned stimuli, instead of directly establishing conditioned reflex with unconditioned stimulus . The realization of secondary conditional reflex is confirmed in the PSPICE simulation results. Meanwhile, an extended classification circuit based on secondary conditioned reflex is proposed. Based on the features of objects as input, the output of the circuit is used to achieve the function of classification. The accuracy of application circuit proposed in this paper can be verified by the simulation results in PSPICE.},
  archive      = {J_NEUCOM},
  author       = {Sichun Du and Qing Deng and Qinghui Hong and Chunhua Wang},
  doi          = {10.1016/j.neucom.2021.08.045},
  journal      = {Neurocomputing},
  pages        = {341-354},
  shortjournal = {Neurocomputing},
  title        = {A memristor-based circuit design of pavlov associative memory with secondary conditional reflex and its application},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). A direct parameterized approach to global exponential
stability of neutral-type cohen–grossberg neural networks with multiple
discrete and neutral delays. <em>NEUCOM</em>, <em>463</em>, 334–340. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a class of neutral-type Cohen–Grossberg neural networks with multiple discrete and neutral delays, the existence and uniqueness of equilibrium point are derived by the homeomorphism mapping theory between topology spaces. By proposing a direct parameterized approach that is based on a parameterized estimation of solutions, it is the first time to investigate a sufficient condition guaranteeing that the unique equilibrium point is globally exponentially stable. The stability condition contains only some very simple inequalities, which is easily solved by applying the toolbox YALMIP of MATLAB.Three numerical examples in literature are employed to demonstrate the effectiveness of the obtained criterion over the previously achieved ones. In addition, the proposed approach is different from the popular linear matrix inequality approach, since no Lyapunov–Krasovskii functional is required. Therefore, the obtained criterion can be evaluated as an important contribution to the stability issue of the considered neural networks . It is potential that the proposed approach is applied to stability issues of various types of neural networks.},
  archive      = {J_NEUCOM},
  author       = {Xian Zhang and Yantao Wang and Xin Wang},
  doi          = {10.1016/j.neucom.2021.08.068},
  journal      = {Neurocomputing},
  pages        = {334-340},
  shortjournal = {Neurocomputing},
  title        = {A direct parameterized approach to global exponential stability of neutral-type Cohen–Grossberg neural networks with multiple discrete and neutral delays},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning causal structures using hidden compact
representation. <em>NEUCOM</em>, <em>463</em>, 328–333. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning causal structures from observational data is of great challenge and interest in many disciplines. Various methods have demonstrated their effectiveness for causal structure learning on different types of data, but most of them are suffered from the indeterminacy of Markov equivalence classes, especially on discrete data. A recent breakthrough formulates the problem as finding a hidden compact representation (HCR) with lower cardinality to distinguish the correct causal direction. However, method based on the HCR model is only applicable in bivariate cases. In this paper, we generalize the HCR model to multivariate cases and provide an effective likelihood-based algorithm for causal structure learning in presence of hidden compact representation. Our theoretical results show that under some weak technique conditions about the underlying causal mechanism , causal directions are still identifiable even in multivariate cases. Our empirical studies demonstrate the effectiveness of proposed methods on various types of data and structures.},
  archive      = {J_NEUCOM},
  author       = {Jie Qiao and Yiming Bai and Ruichu Cai and Zhifeng Hao},
  doi          = {10.1016/j.neucom.2021.08.074},
  journal      = {Neurocomputing},
  pages        = {328-333},
  shortjournal = {Neurocomputing},
  title        = {Learning causal structures using hidden compact representation},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed additive encryption and quantization for privacy
preserving federated deep learning. <em>NEUCOM</em>, <em>463</em>,
309–327. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Homomorphic encryption is a very useful gradient protection technique used in privacy preserving federated learning . However, existing encrypted federated learning systems need a trusted third party to generate and distribute key pairs to connected participants, making them unsuited for federated learning and vulnerable to security risks. Moreover, encrypting all model parameters is computationally intensive, especially for large machine learning models such as deep neural networks . In order to mitigate these issues, we develop a practical, computationally efficient encryption based protocol for federated deep learning , where the key pairs are collaboratively generated without the help of a trusted third party. By quantization of the model parameters on the clients and an approximated aggregation on the server, the proposed method avoids encryption and decryption of the entire model. In addition, a threshold based secret sharing technique is designed so that no one can hold the global private key for decryption, while aggregated ciphertexts can be successfully decrypted by a threshold number of clients even if some clients are offline. Our experimental results confirm that the proposed method significantly reduces the communication costs and computational complexity compared to existing encrypted federated learning without compromising the performance and security.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Zhu and Rui Wang and Yaochu Jin and Kaitai Liang and Jianting Ning},
  doi          = {10.1016/j.neucom.2021.08.062},
  journal      = {Neurocomputing},
  pages        = {309-327},
  shortjournal = {Neurocomputing},
  title        = {Distributed additive encryption and quantization for privacy preserving federated deep learning},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-layer adversarial domain adaptation with feature joint
distribution constraint. <em>NEUCOM</em>, <em>463</em>, 298–308. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The domain-invariant constraint is usually exerted on a single layer of a convolutional neural network (CNN). This scheme may help the constrained layer learn domain-invariant features at the cost of sacrificing the other layers’ learning ability. In this paper, we propose a novel method called multi-layer adversarial domain adaptation (MLADA), which incorporates information of all the layers by a hierarchical scheme. To the convolutional layers of the CNN model, a feature-level domain classifier is introduced to learn domain-invariant representation. To the fully connected layer of the CNN model, a prediction-level domain classifier is set to reduce domain discrepancy in the decision layer. An union domain classifier is then mounted to balance the joint distribution constraints between the feature-level and the prediction-level domain classifiers. So the MLADA can gain domain-invariant representation through sufficient training over all layers of the model. Experimental results indicate that MLADA outperforms other methods on multiple classic tasks in domain adaptation. The ablation study proves the necessity of three domain classifiers in the architecture of MLADA.},
  archive      = {J_NEUCOM},
  author       = {Yuchun Fang and Zhengye Xiao and Wei Zhang},
  doi          = {10.1016/j.neucom.2021.07.068},
  journal      = {Neurocomputing},
  pages        = {298-308},
  shortjournal = {Neurocomputing},
  title        = {Multi-layer adversarial domain adaptation with feature joint distribution constraint},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). α2-dependent reciprocally convex inequality for stability
and dissipativity analysis of neural networks with time-varying delay.
<em>NEUCOM</em>, <em>463</em>, 292–297. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the stability and dissipativity issue for neural networks (NNs) with time-varying delay. Firstly, an α 2 α2 -dependent reciprocally convex inequality is presented, which unifies the traditional reciprocally convex inequality and the improved reciprocally convex inequality as its special cases. Secondly, by using the α 2 α2 -dependent reciprocally convex inequality, a tight upper bound on the time-derivative of the Lyapunov-Krasovskii functional (LKF) is obtained, then the analysis and calculation is simplified due to no other nonlinear terms being introduced. As a result, some sufficient conditions are obtained which can be used to ensure the stability and dissipativity of delayed NNs. Finally, simulations are provided to verify the superiority of the presented method.},
  archive      = {J_NEUCOM},
  author       = {Guoqiang Tan and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2021.08.071},
  journal      = {Neurocomputing},
  pages        = {292-297},
  shortjournal = {Neurocomputing},
  title        = {α2-dependent reciprocally convex inequality for stability and dissipativity analysis of neural networks with time-varying delay},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). MASG-GAN: A multi-view attention superpixel-guided
generative adversarial network for efficient and simultaneous
histopathology image segmentation and classification. <em>NEUCOM</em>,
<em>463</em>, 275–291. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Efficient analysis of Haematoxylin and Eosin stained histopathology images has become a challenge in digital pathology work-flow. We propose a Multi-view Attention Superpixel-guided Generative Adversarial Network (MASG-GAN) to achieve the multi-task learning for nuclei segmentation and benign-malignant tissue classification. Firstly, a novel superpixel segmentation approach driven by Bounded Asymmetric Gaussian Mixture Model (BAGMM) is presented for generating superpixel-prior probability map with high-level semantics. Then, we develop a generator network that integrates student-branch and teacher-branch. Concretely, the teacher-branch takes superpixel-prior probability map as input and guides the student-branch for accurate segmentation and classification. Then in generator, we build a light-weight U-shaped block (LUB) that consists of depthwise separable convolutions with mini encoding-decoding structure to reduce network computational cost. Finally, a Multi-view Attention Module (MVAM) is designed for further enhance the segmentation quality of nuclei with small area and unclear boundary. Extensive experiments on five benchmark datasets demonstrate that our pipeline outperforms some state-of-the-art methods, especially in terms of efficiency.},
  archive      = {J_NEUCOM},
  author       = {Huaqi Zhang and Jie Liu and Zekuan Yu and Pengyu Wang},
  doi          = {10.1016/j.neucom.2021.08.039},
  journal      = {Neurocomputing},
  pages        = {275-291},
  shortjournal = {Neurocomputing},
  title        = {MASG-GAN: A multi-view attention superpixel-guided generative adversarial network for efficient and simultaneous histopathology image segmentation and classification},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ATTCry: Attention-based neural network model for protein
crystallization prediction. <em>NEUCOM</em>, <em>463</em>, 265–274. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein crystallization is the fundamental approach to solve the structure of protein. However, only a few (2\%–10\%) of these protein can be good crystallization. Recently, several computational methods have been proposed to predict protein crystallization. However, their model needs to select and extract thousands of physicochemical and structural handcrafted features, and the performances are modest. According to the properties of protein structure, we proposed a novel end-to-end attention-based deep neural network protein crystallization predictor called ATTCry. To capture the local k-mers feature of the raw protein sequence, We designed multi-scale convolutional neural networks (CNN) layer. Furthermore, to obtain more complex global spatial long-distance dependence of protein structure, we add multi-head self-attention layers to joint information from different representation subspaces at different positions parallelly. By integrating multi-scale and multi-head self-attention mechanisms, our method can capture both local and global features of protein sequences efficiently, thus enhance the robustness and generalization of protein crystallization prediction. Compared with other deep learning models for protein crystallization prediction, ATTCry reduces the amount of training parameters, and the model can be trained more efficiently. The experiments demonstrate that ATTCry outperforms significantly on three different test sets than all known crystallization predictors. It shows that ATTCry obtains relatively good predictive performance and outperforms existing methods. ATTCry is free available at https://github.com/zhanglabNKU/ATTCry},
  archive      = {J_NEUCOM},
  author       = {Chen Jin and Jianzhao Gao and Zhuangwei Shi and Han Zhang},
  doi          = {10.1016/j.neucom.2021.08.029},
  journal      = {Neurocomputing},
  pages        = {265-274},
  shortjournal = {Neurocomputing},
  title        = {ATTCry: Attention-based neural network model for protein crystallization prediction},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). In-situ learning in multilayer locally-connected memristive
spiking neural network. <em>NEUCOM</em>, <em>463</em>, 251–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memristive spiking neural networks (MSNNs) have great potential to process information with higher efficiency and lower time latency than conventional artificial neural networks (ANNs). However, MSNNs still lack effective hardware-based training algorithms to achieve comparable performance to the mature ANNs. Therefore, a multilayer locally-connected (LC) MSNN is proposed to realize high performance with self-adaptive and in-situ learning. In the LC-MSNN, spatial and temporal interactions are introduced to activate hidden neurons spontaneously; synaptic weights are updated locally with spike-time-dependent plasticity (STDP) by pulse scheme including processing and updating phases; nonlinear conductance response (CR) is utilized to realize the adjustive learning rate . The LC-MSNN is comprehensively verified and benchmarked with the MNIST dataset. Moreover, self-adaptive activations of the hidden neurons are investigated by extracting and visualizing their internal states and related features; the adjustive learning rate is studied in different nonlinear CR. Effects of non-idealities including finite resolution, device-to-device variation, and yield, are also taken into consideration in the LC-MSNN. Simulation results show the LC-MSNN has better performance (maximum recognition rate of 97.4\%) and robustness to non-idealities. Therefore, this method is a hardware-friendly algorithm and can be applied to realize high-performance SNNs in a memristor-based hardware system.},
  archive      = {J_NEUCOM},
  author       = {Jiwei Li and Hui Xu and Sheng-Yang Sun and Zhiwei Li and Qingjiang Li and Haijun Liu and Nan Li},
  doi          = {10.1016/j.neucom.2021.08.011},
  journal      = {Neurocomputing},
  pages        = {251-264},
  shortjournal = {Neurocomputing},
  title        = {In-situ learning in multilayer locally-connected memristive spiking neural network},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A biological-like controller using improved spiking neural
networks. <em>NEUCOM</em>, <em>463</em>, 237–250. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to developing a biological-based algorithm to simulate the control of a human arm by means of a Spiking Neural Network (SNN) with a pre-set structure similar to those found in reflex arcs . The replication of the behavior of biological systems is a primary step to understand how the brain and the neural networks that comprise it work. The study of these systems began with the analysis of animals with low neural complexity as well as with small control neural networks such as those present in the reflex acts of the human body. However, the study of the brain, due to its intricate structure, still presents many unknowns and challenges to be solved. Meanwhile, one way to understand how biological systems work is to emulate their behavior through computer simulations. Artificial neural networks (ANNs) offered the opportunity to replicate neural structures to understand and reproduce their behavior and performance. Many types of ANNs are based on the use of activation functions . However, these ANNs are simplified models that do not replicate the behavior of complex biological neural systems accurately. For this reason, spike-based models have been developed to reproduce real biological systems more faithfully. This work proposes simulating the motor behavior of the central nervous system to control the position of an arm. To this end, a spiking neural network has been developed to emulate motion control using a fixed structure that reproduces reflex arcs . A channel-based synapse model and a control scheme based on the equilibrium point hypothesis have been proposed to improve biological similarity of the controller. Furthermore, the developed controller has learning capabilities thanks to the reproduction of the synapse plasticity process that takes place in real biological systems through a supervised Spike-Timing Dependent Plasticity (STDP) learning strategy. The performance of the proposed approach has been demonstrated by simulating the control of the movement of an arm using Hill’s Muscle Model. Results suggest that the proposed control algorithm resembles the response of biological systems adequately in terms of speed and temporal response.},
  archive      = {J_NEUCOM},
  author       = {Javier Pérez Fernández and Manuel Alcázar Vargas and Juan M. Velasco García and Juan A. Cabrera Carrillo and Juan J. Castillo Aguilar},
  doi          = {10.1016/j.neucom.2021.08.005},
  journal      = {Neurocomputing},
  pages        = {237-250},
  shortjournal = {Neurocomputing},
  title        = {A biological-like controller using improved spiking neural networks},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). AMC-net: Attentive modality-consistent network for
visible-infrared person re-identification. <em>NEUCOM</em>,
<em>463</em>, 226–236. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI-ReID) aims at matching people across images from RGB and infrared modality. Existing methods tend to utilize the readily available models to extract features, ignoring mining spatial and channel information of features. In this paper, we propose an attentive modality-consistent network (AMC-Net) for VI-ReID. Firstly, to avoid the damage to discriminability of features caused by overfitting of local regions in the network, a context-aware attention block (CAB) is designed to mine the spatial information of the whole person region by magnifying the perception scope of convolution layers . Secondly, the attentive channel aggregation block (ACB) is adopted to mine the channel information with richer semantic cues by considering local cross-channel interactive information. Thirdly, we propose a modality-consistent regularizer to narrow down the discrepancy of high order features between heterogeneous images. Extensive experiments on two datasets indicate that the proposed method outperforms the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Hanzheng Wang and Jiaqi Zhao and Yong Zhou and Rui Yao and Ying Chen and Silin Chen},
  doi          = {10.1016/j.neucom.2021.08.053},
  journal      = {Neurocomputing},
  pages        = {226-236},
  shortjournal = {Neurocomputing},
  title        = {AMC-net: Attentive modality-consistent network for visible-infrared person re-identification},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A joint object detection and semantic segmentation model
with cross-attention and inner-attention mechanisms. <em>NEUCOM</em>,
<em>463</em>, 212–225. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection and semantic segmentation are two fundamental techniques for Intelligent Vehicles (IV) and Advanced Driving Assistance System (ADAS). Motivated by recent studies demonstrating that object detection and semantic segmentation are two highly-correlated tasks, this paper handles the problem of joint object detection and semantic segmentation in traffic scenes. Existing methods perform the joint object detection and semantic segmentation by sharing the same backbone network , but always ignore the interactive connection between the subdividing detection branch and segmentation branch, leading to the insufficient interaction between the two branches. Considering this situation, this paper proposes a joint object detection and semantic segmentation model with the cross-attention and inner-attention mechanisms. The cross-attention mechanism enables to build up the essential interaction between the subdividing detection branch and segmentation branch to fully make use of their correlation. In addition, the inner-attention contributes to strengthening the representations of feature maps in the model. Given an image, an encoder-decoder network is firstly used to extract initial feature maps. Then, the inner-attention mechanism is applied to strengthen the initial feature maps to obtain segmentation feature maps. Subsequently, the cross-attention mechanism utilizes the segmentation feature maps to guide the generation of object detection feature maps. Finally, the semantic segmentation is performed on the segmentation feature maps and object detection is performed on the detection feature maps. In the experiments, two well-known public traffic datasets are used to evaluate our model. Our model achieves the highest performance in comparison with several recently-proposed methods. In addition, some ablation studies are conducted to evaluate the proposed inner-attention and cross-attention mechanisms, and experiment results validate their effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Zhixiong Nan and Jizhi Peng and Jingjing Jiang and Hui Chen and Ben Yang and Jingmin Xin and Nanning Zheng},
  doi          = {10.1016/j.neucom.2021.08.031},
  journal      = {Neurocomputing},
  pages        = {212-225},
  shortjournal = {Neurocomputing},
  title        = {A joint object detection and semantic segmentation model with cross-attention and inner-attention mechanisms},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A light-weight, efficient, and general cross-modal image
fusion network. <em>NEUCOM</em>, <em>463</em>, 198–211. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing cross-modal image fusion methods pay limited research attention to image fusion efficiency and network architecture . However, the efficiency and accuracy of image fusion have an important impact on practical applications. To solve this problem, we propose a light-weight, efficient, and general cross-modal image fusion network, termed as AE-Netv2. Firstly, we analyze the influence of different network architectures (e.g., group convolution, depth-wise convolution, inceptionNet, squeezeNet, shuffleNet, and multi-scale module) on image fusion quality and efficiency, which provides a reference for the design of image fusion architecture. Secondly, we explore the commonness and characteristics of different image fusion tasks, which provides a research basis for further research on the continuous learning characteristics of the human brain. Finally, positive sample loss is added to the similarity loss to reduce the difference of data distribution of different cross-modal image fusion tasks. Comprehensive experiments demonstrate the superiority of our method compared to state-of-the-art methods in different fusion tasks at a real-time speed of 100+ FPS on GTX 2070. Compared with the fastest image fusion method based on deep learning , the efficiency of AE-Netv2 is improved by 2.14 times. Compared with the image fusion model with the smallest model size, the size of our model is reduced by 11.59 times.},
  archive      = {J_NEUCOM},
  author       = {Aiqing Fang and Xinbo Zhao and Jiaqi Yang and Beibei Qin and Yanning Zhang},
  doi          = {10.1016/j.neucom.2021.08.044},
  journal      = {Neurocomputing},
  pages        = {198-211},
  shortjournal = {Neurocomputing},
  title        = {A light-weight, efficient, and general cross-modal image fusion network},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse additive discriminant canonical correlation analysis
for multiple features fusion. <em>NEUCOM</em>, <em>463</em>, 185–197.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Canonical correlation analysis (CCA) is an unsupervised representation learning technique to correlate multi-view data by learning a set of projection matrices. Being complementary with CCA, many discriminant methods are proposed to extract discriminative features of multi-view data by introducing the supervised class information. However, the learned projection matrices in these methods are mathematically constrained to be equal rank to the class number, and thus cannot represent the original data comprehensively. In this paper, we propose a general multi-view information fusion technique, named sparse additive discriminative canonical correlation analysis (SaDCCA). On one hand, SaDCCA is equipped with a strong degree of discrimination by defining a new affinity matrix that reflects the high-order characteristics of intra-class and the separability of inter-class. On the other hand, SaDCCA can exploit the correlation among multi-view data by maintaining the spirit of CCA. The discrimination among classes and the correlation among views are integrated in an additive manner. To obtain the sparse solutions , we first establish the relationship between the objective function and the underdetermined linear system equations, and then obtain the ℓ 1 ℓ1 -norm solution by accelerated Bregman iteration with matrix form. SaDCCA has no rank constraint on the projection matrices and is capable to provide accurate recognition performance. Experiments conducted on some publicly available datasets demonstrate the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Zhan Wang and Lizhi Wang and Hua Huang},
  doi          = {10.1016/j.neucom.2021.08.013},
  journal      = {Neurocomputing},
  pages        = {185-197},
  shortjournal = {Neurocomputing},
  title        = {Sparse additive discriminant canonical correlation analysis for multiple features fusion},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ScalingNet: Extracting features from raw EEG data for
emotion recognition. <em>NEUCOM</em>, <em>463</em>, 177–184. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional Neural Networks (CNNs) have achieved remarkable performance breakthroughs in a variety of tasks. Recently, CNN-based methods that are fed with hand-extracted EEG features have steadily improved their performance on the emotion recognition task. In this paper, we propose a novel convolutional layer , called the Scaling Layer, which can adaptively extract effective data-driven spectrogram-like features from raw EEG signals. Furthermore, it exploits convolutional kernels scaled from one data-driven pattern to exposed a frequency-like dimension to address the shortcomings of prior methods requiring hand-extracted features or their approximations . ScalingNet, the proposed neural network architecture based on the Scaling Layer, has achieved state-of-the-art results across the established DEAP and AMIGOS benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Jingzhao Hu and Chen Wang and Qiaomei Jia and Qirong Bu and Richard Sutcliffe and Jun Feng},
  doi          = {10.1016/j.neucom.2021.08.018},
  journal      = {Neurocomputing},
  pages        = {177-184},
  shortjournal = {Neurocomputing},
  title        = {ScalingNet: Extracting features from raw EEG data for emotion recognition},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Sampled-data non-fragile state estimation for delayed
genetic regulatory networks under stochastically switching sampling
periods. <em>NEUCOM</em>, <em>463</em>, 168–176. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the non-fragile state estimation (NFSE) problem for a class of delayed genetic regulatory networks (GRNs) under stochastic sampling mechanisms. The measurement output is sampled before being transmitted to the estimator where the sampling period switches between two different values in a random way. By transforming the sampling periods into bounded time-delays, the issue of designing a non-fragile state estimator based on stochastically sampled measurements is converted into the NFSE problem for GRNs with multiple probabilistic interval delays. Then, by constructing a Lyapunov–Krasovskii functional and employing the Gronwall’s inequality together with Jensen’s inequality, a sufficient criterion is obtained to ensure the exponential mean-square stability of the corresponding estimation error dynamics. Furthermore, the desired non-fragile estimator gain is obtained via solving a convex optimization problem . Finally, the validity of the developed stochastic sampled-data NFSE scheme is verified via a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Jiahui Li and Hongli Dong and Hongjian Liu and Fei Han},
  doi          = {10.1016/j.neucom.2021.07.093},
  journal      = {Neurocomputing},
  pages        = {168-176},
  shortjournal = {Neurocomputing},
  title        = {Sampled-data non-fragile state estimation for delayed genetic regulatory networks under stochastically switching sampling periods},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). HRCP: High-ratio channel pruning for real-time object
detection on resource-limited platform. <em>NEUCOM</em>, <em>463</em>,
155–167. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning algorithms have demonstrated remarkable performance in object detection tasks and have applied to many fields such as intelligent networked vehicles and drones. Different from other fields like video surveillance, the fields of intelligent networked vehicles and drones only have resource-limited platform and have high requirements in model storage and real-time inference. To satisfy these requirements, model compression approaches are developed to reduce model parameters and computation. As channel pruning is a coarse-grained hardware-friendly weight pruning method, it is widely used in model compression . Most studies have only focused on utilizing the scale factor of Batch Normalization (BN) layers to determine whether to prune a certain channel. However, the shift factor turns to very important when its value is large. The channel with large shift factor has a great influence on subsequent layers. In our paper, we take shift factor into consideration to protect these channels. We first introduce network building blocks to analyze YOLOv3-SPP3 model and demonstrate the importance of shift factor on the channel saliency in the pruning process. Then we present a new pruning method called high-ratio channel pruning (HRCP) to improve the performance of the pruned model based on definition of the channel saliency with scale factor and shift factor of BN layer. Our experimental results show that HRCP performs better than SlimYOLOv3 when model volumes are reduced by 50\%, 88\%, and 92\% accordingly. In high-ratio pruning, our HRCP can be pruned more 9.7\% volumes than SlimYOLOv3 under the same performance condition.},
  archive      = {J_NEUCOM},
  author       = {Yijie Chen and Rui Li and Renfa Li},
  doi          = {10.1016/j.neucom.2021.08.046},
  journal      = {Neurocomputing},
  pages        = {155-167},
  shortjournal = {Neurocomputing},
  title        = {HRCP: High-ratio channel pruning for real-time object detection on resource-limited platform},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An abnormal event detection method based on the riemannian
manifold and LSTM network. <em>NEUCOM</em>, <em>463</em>, 144–154. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an abnormal event detection method based on the combination of Riemannian manifold and LSTM network. We divide the video into a series of non overlapping regions, and extract HOG and HOF as original appearance and motion features. Because the existing abnormal event detection methods pay little attention to the changes rate of appearance and motion, we propose a new feature called Riemannian manifold distance feature that can represent the topological relationship of features at different moment in the same position and capture the change rate of the current feature. Once the change rate of the current features changes, the topological relationship of features will change. We use ISOMAP algorithm to embed manifold into low dimensional Euclidean space. In the training phase, the dimension-reduced features of the same position at different historical moment are used as the input of each time step of the LSTM network, and the dimension-reduced feature of the current moment is used as expected output. And in this stage, we only use the normal video, so the LSTM will learn the changing rules of the features contained in normal events. In the testing phase, we use LSTM network to predict current dimension-reduced HOG and HOF features. After that, we can obtain the Riemannian manifold distance feature of actual dimension-reduced feature and predicted dimension-reduced feature. In order to detect abnormal events, we propose an abnormal score, which is used to measure whether the appearance/ movement and the change rate of them are close to the expectation. The abnormal score can detect the abnormal event according to dimension-reduced appearance feature, dimension-reduced motion feature, appearance Riemannian manifold distance feature and motion Riemannian manifold distance feature. Experiments on four benchmark datasets show the competitive performance of our method with the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Limin Xia and Zhenmin Li},
  doi          = {10.1016/j.neucom.2021.08.017},
  journal      = {Neurocomputing},
  pages        = {144-154},
  shortjournal = {Neurocomputing},
  title        = {An abnormal event detection method based on the riemannian manifold and LSTM network},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Broad learning system with manifold regularized sparse
features for semi-supervised classification. <em>NEUCOM</em>,
<em>463</em>, 133–143. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Broad learning system (BLS) is an efficient neural network , and is proven to be effective in fields like remote sensing, fault diagnosis, etc. As a critical branch of BLS, semi-supervised BLS has drawn increasing attention. Exploiting the information within additional unlabeled instances is key to semi-supervised learning. Studies have shown that incorporating this information into the feature nodes is a good way to implement semi-supervised BLS. However, the existing methods could not retain the sparsity of feature nodes. Besides that, these methods become computation consuming when dealing with the large scale datasets. To address these problems, a broad learning system with manifold regularized sparse features (BLS-MS) is proposed. We first propose a manifold regularized sparse autoencoder based on extreme learning machine (MS-ELM-AE) for feature mapping. Then, a subset training approach is introduced to alleviate the efficiency decline caused by large data size. Finally, the proposed BLS-MS is further modified to utilize the discriminant information of labeled data, namely discriminative BLS-MS (DBLS-MS). The proposed methods have been evaluated on 14 datasets. Experiment results have demonstrated both the effectiveness and the efficiency of proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Shiluo Huang and Zheng Liu and Wei Jin and Ying Mu},
  doi          = {10.1016/j.neucom.2021.08.052},
  journal      = {Neurocomputing},
  pages        = {133-143},
  shortjournal = {Neurocomputing},
  title        = {Broad learning system with manifold regularized sparse features for semi-supervised classification},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LABNet: Local graph aggregation network with class balanced
loss for vehicle re-identification. <em>NEUCOM</em>, <em>463</em>,
122–132. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vehicle re-identification is an important computer vision task where the objective is to identify a specific vehicle among a set of vehicles seen at various viewpoints. Recent methods based on deep learning utilize a global average pooling layer after the backbone feature extractor, however, this ignores any spatial reasoning on the feature map. In this paper, we propose local graph aggregation on the backbone feature map, to learn associations of local information and hence improve feature learning as well as reduce the effects of partial occlusion and background clutter. Our local graph aggregation network considers spatial regions of the feature map as nodes and builds a local neighborhood graph that performs local feature aggregation before the global average pooling layer. We further utilize a batch normalization layer to improve the system effectiveness. Additionally, we introduce a class balanced loss to compensate for the imbalance in the sample distributions found in the most widely used vehicle re-identification datasets. Finally, we evaluate our method in three popular benchmarks and show that our approach outperforms many state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Abu Md Niamul Taufique and Andreas Savakis},
  doi          = {10.1016/j.neucom.2021.07.082},
  journal      = {Neurocomputing},
  pages        = {122-132},
  shortjournal = {Neurocomputing},
  title        = {LABNet: Local graph aggregation network with class balanced loss for vehicle re-identification},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Learning frame-level affinity with video-level labels for
weakly supervised temporal action detection. <em>NEUCOM</em>,
<em>463</em>, 109–121. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised temporal action detection aims at localizing actions with only video-level labels rather than lots of frame-level labels. To this end, previous methods train a classification network for mining discernible action frames as detection results. However, the classification network is known to only concentrate on local discernible frames rather than the entire action instance. Therefore, substantial numbers of indiscernible action frames are not detected and the detection results are incomplete. To alleviate this issue, we propose a novel method to facilitate the detection of indiscernible frames based on learning frame-level affinities. In the proposed method, we design a network (named Affinity Network) for predicting affinities between pairs of adjacent frames. Then, the affinities are used as transition probabilities to propagate local responses to indiscernible frames. As a result, the responses of indiscernible frames can be enhanced and the detection of them can be facilitated. For learning the network, we propose strategies to synthesize frame-pair and video-pair training samples, which are conducive to learn frame-level affinities with only video-level labels. The experimental results on THUMOS14 dataset and ActivityNet1.2 dataset show that the detection performance of our framework outperforms most previous weakly supervised action detection methods, and is even as competitive as some fully supervised action detection methods.},
  archive      = {J_NEUCOM},
  author       = {Bairong Li and Yuesheng Zhu and Ruixin Liu and Zhenyu Weng},
  doi          = {10.1016/j.neucom.2021.07.059},
  journal      = {Neurocomputing},
  pages        = {109-121},
  shortjournal = {Neurocomputing},
  title        = {Learning frame-level affinity with video-level labels for weakly supervised temporal action detection},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unattached irregular scene text rectification with refined
objective. <em>NEUCOM</em>, <em>463</em>, 101–108. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, text recognition tasks have reached a high level with deep learning-based methods. The techniques are widely applied in different fields, and nowadays most researchers aim to build an effective approach to deal with irregular text in scene images. In this work, we propose a GAN-based framework to rectify scene text with rotation, curving, or other distortions. Unlike previous rectification modules that rely on the recognition networks , our model can be utilized either as an independent model or an extra component. Therefore, annotations of the text content are not required to train the model. And we utilize a refined training objective with the proposed sample loss, which is able to effectively control pixels in the output images that are supposed to be sampled from input ones. Experiments on public benchmarks demonstrate the effectiveness of our method. The code will be publicly available on github soon.},
  archive      = {J_NEUCOM},
  author       = {Yanxiang Gong and Linjie Deng and Zhiqiang Zhang and Guozhen Duan and Zheng Ma and Mei Xie},
  doi          = {10.1016/j.neucom.2021.08.047},
  journal      = {Neurocomputing},
  pages        = {101-108},
  shortjournal = {Neurocomputing},
  title        = {Unattached irregular scene text rectification with refined objective},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph transformer networks based text representation.
<em>NEUCOM</em>, <em>463</em>, 91–100. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks (GNN) has been used to exploit global features in text representation learning for natural language processing (NLP) tasks, including text classification , sequence tagging, neural machine translation and relational reasoning. However, GNN based models usually build a graph for the entire corpus, they have high memory consumption, ignoring the order of words and containing test documents in the training graph. Thus, these models are inherently transductive and have difficulties in inductive learning. In order to solve the above problems, we propose a Graph Transformer Networks based Text representation (GTNT) model. It first constructs a degree-centric text graph, which generates a text graph for each document in the corpus. Then it adopts a graph transformer network to model the graph to obtain node embeddings . When we apply our proposed GTNT model to citation recommendation and text classification tasks, the experimental results show that our model outperforms other state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Xin Mei and Xiaoyan Cai and Libin Yang and Nanxin Wang},
  doi          = {10.1016/j.neucom.2021.08.032},
  journal      = {Neurocomputing},
  pages        = {91-100},
  shortjournal = {Neurocomputing},
  title        = {Graph transformer networks based text representation},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collectiveness analysis with visual attributes.
<em>NEUCOM</em>, <em>463</em>, 77–90. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individuals within crowd scenes tend to move unconsciously in a collective manner. The nature of this phenomenon surges motivations in collectiveness analysis to quantify and detect the collective behavior within the crowds. Due to the complexity of crowd scenes, most studies focus on the collective motion of individuals. However, it requires the extraction of temporal information, i.e., motion attributes, in consecutive video frames. Based on the approach, collectiveness analysis relies on the total number of motion attributes that could not represent the total number of individuals and limits mid-level understanding within crowd scenes. Alternatively, this study proposes a novel framework for collectiveness analysis using visual attributes. It is based on visual attributes extraction approach to facilitate individual-level understanding based on still image input. By localizing individuals and classifying individuals’ head pose, the proposed framework alleviates the need to rely on temporal information and explores topological relationship propagation among individuals to infer collectiveness analysis. Inclusive experiments on various crowd densities illustrate the aims of the proposed framework to infer high-level crowd analysis with visual attributes. Its efficacy is evaluated on real crowd scenes and compared with the state-of-the-art approaches including achieving estimation of group with Average Difference (AD) = 1.68 and Mean Square Error (MSE) = 1.71. Its potential applicability is demonstrated in the context of crowd estimation and collectiveness analysis.},
  archive      = {J_NEUCOM},
  author       = {Nurul Japar and Ven Jyn Kok and Chee Seng Chan},
  doi          = {10.1016/j.neucom.2021.08.038},
  journal      = {Neurocomputing},
  pages        = {77-90},
  shortjournal = {Neurocomputing},
  title        = {Collectiveness analysis with visual attributes},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lexicographic cooperative co-evolutionary approach for
feature selection. <em>NEUCOM</em>, <em>463</em>, 59–76. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper starts with two hypotheses. The first one is that the simultaneous optimization of the hyperparameters regulating the classifier within a wrapper method, while the best subset of features is being determined, should improve the results with respect to those obtained with a pre-parameterized classifier. The second one is that solving these two problems can be formulated as a lexicographic optimization problem, allowing the use of a simple single-objective evolutionary algorithm to solve this multi-objective problem. The fitness function is of key importance for such wrapper methods. It is responsible for guiding the search towards potentially good solutions and it also consumes most of the runtime. Having these issues in mind, this paper also proposes a new lexicographic fitness function, designed to minimize the runtime of the algorithm and also to avoid over-fitting. Furthermore, the execution time and the quality of the results obtained by the wrapper procedure also depend on some algorithmic hyperparameters: the similarity thresholds used when comparing two different solutions lexicographically and the percentage of data samples used for validation during the training process. Thus, an experimental analysis has been carried out to find adequate values for these hyperparameters. Finally, the lexicographic cooperative co-evolutionary wrapper approach, using the new fitness function proposed in this paper, has been tested with several datasets belonging to the University of California, Irvine (UCI) repository and also with some real high-dimensional datasets, obtaining quite good results, compared to other state-of-the-art wrapper methods. The comparison has also been made lexicographically, with a new methodology proposed in this paper.},
  archive      = {J_NEUCOM},
  author       = {Jesús González and Julio Ortega and Juan José Escobar and Miguel Damas},
  doi          = {10.1016/j.neucom.2021.08.003},
  journal      = {Neurocomputing},
  pages        = {59-76},
  shortjournal = {Neurocomputing},
  title        = {A lexicographic cooperative co-evolutionary approach for feature selection},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural transition model for aspect-based sentiment triplet
extraction with triplet memory. <em>NEUCOM</em>, <em>463</em>, 45–58.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aspect-based sentiment triplet extraction (ASTE), as a complete sentiment analysis task, aims to recognize the aspect term, the opinion expression, and the sentiment polarity in a sentence. Current state-of-the-art ASTE models employ a joint extracting scheme for better task improvements. However, how to better solve the triplet overlap issues in the task, and effectively model the mutual interactions between the triplet structures remain challenging. In this work, we explore a neural transition model for end-to-end ASTE. We model the triplet prediction as a graph structure, based on which we implement a transition system with neural design. We further propose a triplet memory mechanism to fully leverage the underlying interactions from the previously recognized triplets relevant to the current parse. We experiment on the benchmark datasets, and the results show that our model achieved state-of-the-art performances against current baselines, meanwhile being more efficient on decoding. Further analysis is conducted to verify the effectiveness of our transition framework.},
  archive      = {J_NEUCOM},
  author       = {Shengqiong Wu and Bobo Li and Dongdong Xie and Chong Teng and Donghong Ji},
  doi          = {10.1016/j.neucom.2021.08.004},
  journal      = {Neurocomputing},
  pages        = {45-58},
  shortjournal = {Neurocomputing},
  title        = {Neural transition model for aspect-based sentiment triplet extraction with triplet memory},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An LSH-based k-representatives clustering method for large
categorical data. <em>NEUCOM</em>, <em>463</em>, 29–44. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering categorical data remains a challenging problem in the era of big data, due to the difficulty in measuring dis/similarity meaningfully for categorical data and the high computational complexity of existing clustering algorithms that makes it difficult to be applied in practical use for big data mining applications. In this paper, we propose an integrated approach that incorporates the Locality-Sensitive Hashing (LSH) technique into the k k -means-like clustering so as to make it capable of predicting the better initial clusters for boosting clustering effectiveness. To this end, we first utilize a data-driven dissimilarity measure for categorical data to construct a family of binary hash functions that are then used to generate the initial clusters. We also propose to use a nearest neighbor search at each iteration for cluster reassignment of data objects to improve the clustering complexity. These solutions are incorporated into the k k -representatives algorithm resulting in the so-called LSH- k k -representatives algorithm. Extensive experiments conducted on multiple real-world and synthetic datasets have demonstrated the effectiveness of the proposed method. It is shown that the newly developed algorithm yields comparable or better clustering results in comparison to the existing closely related works, yet it is significantly more efficient by a factor of between 2 × × and 32 × × .},
  archive      = {J_NEUCOM},
  author       = {Toan Nguyen Mau and Van-Nam Huynh},
  doi          = {10.1016/j.neucom.2021.08.050},
  journal      = {Neurocomputing},
  pages        = {29-44},
  shortjournal = {Neurocomputing},
  title        = {An LSH-based k-representatives clustering method for large categorical data},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VP-NIQE: An opinion-unaware visual perception natural image
quality evaluator. <em>NEUCOM</em>, <em>463</em>, 17–28. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The opinion-unaware (OU) blind image quality assessment (IQA) method shows broad application prospects due to the explosive growth of unlabelled images. Under a local quality perception framework, many works have focused on extracting more complex natural scene statistical (NSS) features to boost the performance. The framework, however, is seldom studied. In addition, NSS features are designed using the prior knowledge of the human visual system (HVS), which is insufficiently powerful for broad types of distortions. Therefore, this paper proposes a visual perception nature image quality evaluation (VP-NIQE) model. Specifically, we propose an understanding-based global–local structure IQA model to simulate the top-down structure of the HVS in image perception. Furthermore, we enriched the feature types from a more comprehensive perspective in local distortion detection. In addition to the NSS features, histogram and deep-learned features are incorporated to detect the distortions. NSS and histogram features represent the low-level prior knowledge of the HVS, while deep-learned features represent the high-level information behind the data. The proposed method is evaluated on six benchmark databases. The evaluation results demonstrate that the proposed method achieves state-of-the-art performance compared with existing OU methods and even generates competitive performance compared with classical full-reference methods.},
  archive      = {J_NEUCOM},
  author       = {Leyuan Wu and Xiaogang Zhang and Hua Chen and Dingxiang Wang and Jingfang Deng},
  doi          = {10.1016/j.neucom.2021.08.048},
  journal      = {Neurocomputing},
  pages        = {17-28},
  shortjournal = {Neurocomputing},
  title        = {VP-NIQE: An opinion-unaware visual perception natural image quality evaluator},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development and deployment of a generative model-based
framework for text to photorealistic image generation. <em>NEUCOM</em>,
<em>463</em>, 1–16. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of generating photorealistic images from their textual descriptions is quite challenging. Most existing tasks in this domain are focused on the generation of images such as flowers or birds from their textual description, especially for validating the generative models based on Generative Adversarial Network (GAN) variants and for recreational purposes. However, such work is limited in the domain of photorealistic face image generation and the results obtained have not been satisfactory. This is partly due to the absence of concrete data in this domain and a large number of highly specific features/attributes involved in face generation compared to birds or flowers. In this paper, we propose an Attention Generative Adversarial Network (AttnGAN) for a fine-grained text-to-face generation that enables attention-driven multi-stage refinement by employing Deep Attentional Multimodal Similarity Model (DAMSM). Through extensive experimentation on the CelebA dataset, we evaluated our approach using the Frechet Inception Distance (FID) score. The output files for the Face2Text Dataset are also compare with that of the T2F Github project. According to the visual comparison, AttnGAN generated higher-quality images than T2F. Additionally, we compare our methodology with existing approaches with a specific focus on CelebA dataset and demonstrate that our approach generates a better FID score facilitating more realistic image generation . The application of such an approach can be found in criminal identification, where faces are generated from the textual description from an eyewitness. Such a method can bring consistency and eliminate the individual biases of an artist drawing the faces from the description given by the eyewitness. Finally, we discuss the deployment of the models on a Raspberry Pi to test how effective the models would be on a standalone device to facilitate portability and timely task completion.},
  archive      = {J_NEUCOM},
  author       = {Sharad Pande and Srishti Chouhan and Ritesh Sonavane and Rahee Walambe and George Ghinea and Ketan Kotecha},
  doi          = {10.1016/j.neucom.2021.08.055},
  journal      = {Neurocomputing},
  pages        = {1-16},
  shortjournal = {Neurocomputing},
  title        = {Development and deployment of a generative model-based framework for text to photorealistic image generation},
  volume       = {463},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mondrian conformal anomaly detection for fault sequence
identification in heterogeneous fleets. <em>NEUCOM</em>, <em>462</em>,
591–606. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We considered the case of monitoring a large fleet where heterogeneity in the operational behavior among its constituent units (i.e., systems or machines) is non-negligible, and no labeled data is available. Each unit in the fleet, referred to as a target, is tracked by its sub-fleet. A conformal sub-fleet (CSF) is a set of units that act as a proxy for the normal operational behavior of a target unit by relying on the Mondrian conformal anomaly detection framework. Two approaches, the k -nearest neighbors and conformal clustering, were investigated for constructing such a sub-fleet by formulating a stability criterion. Moreover, it is important to discover the sub-sequence of events that describes an anomalous behavior in a target unit. Hence, we proposed to extract such sub-sequences for further investigation without pre-specifying their length. We refer to it as a conformal anomaly sequence (CAS). Furthermore, different nonconformity measures were evaluated for their efficiency, i.e., their ability to detect anomalous behavior in a target unit, based on the length of the observed CAS and the S -criterion value. The CSF approach was evaluated in the context of monitoring district heating substations. Anomalous behavior sub-sequences were corroborated with the domain expert leading to the conclusion that the proposed approach has the potential to be useful for both diagnostic and knowledge extraction purposes, especially in domains where labeled data is not available or hard to obtain.},
  archive      = {J_NEUCOM},
  author       = {Shiraz Farouq and Stefan Byttner and Mohamed-Rafik Bouguelia and Henrik Gadd},
  doi          = {10.1016/j.neucom.2021.08.016},
  journal      = {Neurocomputing},
  pages        = {591-606},
  shortjournal = {Neurocomputing},
  title        = {Mondrian conformal anomaly detection for fault sequence identification in heterogeneous fleets},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memristor-based neural network circuit with weighted sum
simultaneous perturbation training and its applications.
<em>NEUCOM</em>, <em>462</em>, 581–590. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a full circuit of memristor-based neural network with weighted sum simultaneous perturbation training is proposed. Firstly, a synaptic circuit is designed by using a pair of memristors, which can represent negative, zero, and positive synaptic weights . Secondly, a full circuit of the neural network is designed, with all operations being completed on the circuit without any computer aid. The neural network is trained with the weighted sum simultaneous perturbation algorithm. The algorithm does not involve complex derivative calculation and error back propagation , and it only applies perturbations to weighted sum, so the circuit implementation is more simple. Finally, application simulations of the proposed neural network circuit are performed via PSpice. The results of simulation indicate that the memristor-based neural network is practical and effective.},
  archive      = {J_NEUCOM},
  author       = {Cong Xu and Chunhua Wang and Yichuang Sun and Qinghui Hong and Quanli Deng and Haowen Chen},
  doi          = {10.1016/j.neucom.2021.08.072},
  journal      = {Neurocomputing},
  pages        = {581-590},
  shortjournal = {Neurocomputing},
  title        = {Memristor-based neural network circuit with weighted sum simultaneous perturbation training and its applications},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RGB×d: Learning depth-weighted RGB patches for RGB-d indoor
semantic segmentation. <em>NEUCOM</em>, <em>462</em>, 568–580. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Significant advances have been made in designing CNNs for RGB semantic segmentation . However, these CNNs are not widely adopted for RGB-D segmentation, due to the asymmetry between the RGB and depth modalities. Instead, dedicated architectures are designed to fuse them for effective RGB-D segmentation, wherein complex structures are often employed, resulting in much increased computational cost. In this paper, we propose a novel way to learn the fusion of RGB and depth information in an early stage. This enables our method to easily adopt existing RGB segmentation networks with minimal modification. Our method is simple yet effective to build a bridge between RGB and RGBD semantic segmentation , so as to avoid designing a far more complex network structure for RGBD segmentation. The proposed method treats RGB and depth information in an inherently asymmetric manner, and to the best of our knowledge, this is the first approach that learns to fuse them in a multiplicative manner for RGB-D segmentation; thus, we call it RGB × × D . Extensive experiments and ablation studies on the challenging NYUDv2, SUN RGB-D and Cityscapes semantic segmentation benchmarks show that the proposed RGB × × D offers a consistent improvement over several baselines.},
  archive      = {J_NEUCOM},
  author       = {Jinming Cao and Hanchao Leng and Daniel Cohen-Or and Dani Lischinski and Ying Chen and Changhe Tu and Yangyan Li},
  doi          = {10.1016/j.neucom.2021.08.009},
  journal      = {Neurocomputing},
  pages        = {568-580},
  shortjournal = {Neurocomputing},
  title        = {RGB×D: Learning depth-weighted RGB patches for RGB-D indoor semantic segmentation},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic weight pruning and the role of regularization in
shaping network structure. <em>NEUCOM</em>, <em>462</em>, 555–567. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The pressing need to reduce the capacity of deep neural networks has stimulated the development of network dilution methods and their analysis. In this study we present a framework for neural network pruning by sampling from a probability function that favors the zeroing of smaller parameters. This procedure of stochastically setting network weights to zero is done after each parameter updating step in the network learning algorithm. As part of the proposed framework, we examine the contribution of L 1 L1 and L 2 L2 regularization to the dynamics of pruning larger network structures such as neurons and filters while optimizing for weight pruning. We then demonstrate the effectiveness of the proposed stochastic pruning framework when used together with regularization terms for different network architectures and image analysis tasks. Specifically, we show that using our method we can successfully remove more than 50\% of the channels/filters in VGG-16 and MobileNetV2 for CIFAR10 classification; in ResNet56 for CIFAR100 classification; in a U-Net for instance segmentation of biological cells; and in a CNN model tailored for COVID-19 detection. For these filter-pruned networks, we also present competitive weight pruning results while maintaining the accuracy levels of the original, dense networks.},
  archive      = {J_NEUCOM},
  author       = {Yael Ziv and Jacob Goldberger and Tammy Riklin Raviv},
  doi          = {10.1016/j.neucom.2021.08.007},
  journal      = {Neurocomputing},
  pages        = {555-567},
  shortjournal = {Neurocomputing},
  title        = {Stochastic weight pruning and the role of regularization in shaping network structure},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoU-guided siamese region proposal network for real-time
visual tracking. <em>NEUCOM</em>, <em>462</em>, 544–554. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, region proposal network (RPN) has been combined with the Siamese network for tracking and shown excellent accuracy and high efficiency. However, the low correlation between the classification score and localization accuracy in tracking has weakened the performance of the tracking model. In this paper, we propose an IoU-guided Siamese RPN (SiamIG) to address this problem. Specifically, SiamIG predicts the intersection-over-union (IoU) with the ground truth for each regressed anchor by using an IoU predictor. Then the predicted IoU is multiplied with the classification score to compute the final score, which is more suitable for localization accuracy. Furthermore, each anchor in the regression branch is assigned an IoU-based weighting factor such that the tracking accuracy can be further improved. Specifically, anchor boxes with high IoU are given more attention because of the IoU-based weighting factor, which helps the model pay more attention to an anchor box with a high IoU. Experiments demonstrate that the proposed method runs at over 200 fps and achieves up to 2.4\%(AUC), 3\%(EAO) and 2.3\%(AUC) improvements over the baseline on the OTB-100, VOT-2016 and UAV123 datasets respectively.},
  archive      = {J_NEUCOM},
  author       = {Lifang Zhou and Yu He and Weisheng Li and Jianxun Mi and Bangjun Lei},
  doi          = {10.1016/j.neucom.2021.05.111},
  journal      = {Neurocomputing},
  pages        = {544-554},
  shortjournal = {Neurocomputing},
  title        = {IoU-guided siamese region proposal network for real-time visual tracking},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synaptic metaplasticity for image processing enhancement in
convolutional neural networks. <em>NEUCOM</em>, <em>462</em>, 534–543.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synaptic metaplasticity is a biological phenomenon shortly defined as the plasticity of synaptic plasticity, meaning that the previous history of the synaptic activity determines its current plasticity. This phenomenon interferes with some of the underlying mechanisms that are considered important in memory and learning processes, such as long-term potentiation and long-term depression. In this work, we provide an approach to include metaplasticity in convolutional neural networks to enhance learning in image classification problems. This approach consists of including metaplasticity as a weight update function in the backpropagation stage of convolutional layers . To validate this proposal, we have been used eight different award-winning convolutional neural networks architectures: LeNet-5, AlexNet, GoogLeNet, VGG16, VGG32, ResNet50 , DenseNet121 and DenseNet169; trained with four different popular datasets for benchmarking: MNIST, Fashion MNIST, CIFAR-10 and CIFAR-100. Experimental results show that there is a performance enhancement for each of the convolution neural network architectures in all the datasets used.},
  archive      = {J_NEUCOM},
  author       = {Víctor Vives-Boix and Daniel Ruiz-Fernández},
  doi          = {10.1016/j.neucom.2021.08.021},
  journal      = {Neurocomputing},
  pages        = {534-543},
  shortjournal = {Neurocomputing},
  title        = {Synaptic metaplasticity for image processing enhancement in convolutional neural networks},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving video anomaly detection performance by mining
useful data from unseen video frames. <em>NEUCOM</em>, <em>462</em>,
523–533. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing s tate- o f- t he- a rt (SOTA) video anomaly detection methods have mainly focused on the network design for obtaining their performance improvements. Different to the main research trend, this paper focuses on the data perspective, where the key idea is to mine useful ‘normal’ data from the unseen video frames. For any off-the-shelf anomaly deep model, these newly mined data could help the deep model in familiarizing more normal feature patterns. Thus, those previously miss-detected abnormal patterns and false-alarms detections would have more chances to be rectified if the target anomaly detection deep model has been finetuned on these newly mined normal data. Extensive quantitative evaluations have verified the effectiveness of the proposed approach in achieving persistent performance improvement by almost 7\% AUC improvement.},
  archive      = {J_NEUCOM},
  author       = {Renzhi Wu and Shuai Li and Chenglizhao Chen and Aimin Hao},
  doi          = {10.1016/j.neucom.2021.05.112},
  journal      = {Neurocomputing},
  pages        = {523-533},
  shortjournal = {Neurocomputing},
  title        = {Improving video anomaly detection performance by mining useful data from unseen video frames},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-level improved circle pooling for scene
classification of high-resolution remote sensing imagery.
<em>NEUCOM</em>, <em>462</em>, 506–522. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene classification of high-spatial resolution imagery (HSRI) includes various potential applications in various fields. Recently, deep convolutional neural networks (CNNs) have achieved competitive performance as a result of the powerful capability of feature extraction. In this paper, we propose a multi-level improved circle pooling (MICP) method with the pre-trained CNN-based model to enhance the discriminative power of CNN activations for scene classification. Specifically, an improved pooling strategy is presented to generate annular subregions without padding operations in traditional concentric circle pooling. Then, we extract the pooling features in these subregions under different levels and build a holistic representation by fusing these multi-level features. MICP is an effective and simple strategy enriching rotation insensitivity and multiscale spatial information. According to the experiments conducted on three challenging HRSI scene data sets, the proposed pooling method achieves similar or better classification accuracy compared to the other CNN-based scene classification methods. Moreover, a comprehensive discussion regarding the effect of data augmentation reveals that the proposed method can enhance the rotation insensitivity of CNNs for the HRSI scene classification.},
  archive      = {J_NEUCOM},
  author       = {Kunlun Qi and Chao Yang and Chuli Hu and Han Zhai and Qingfeng Guan and Shengyu Shen},
  doi          = {10.1016/j.neucom.2021.08.022},
  journal      = {Neurocomputing},
  pages        = {506-522},
  shortjournal = {Neurocomputing},
  title        = {A multi-level improved circle pooling for scene classification of high-resolution remote sensing imagery},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Twin self-supervision based semi-supervised learning
(TS-SSL): Retinal anomaly classification in SD-OCT images.
<em>NEUCOM</em>, <em>462</em>, 491–505. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of supervised deep learning significantly relies on the volume of training samples. However, the vast majority of medical images lacks manual expert annotations. Compared to natural image annotation, the cost of medical image annotation is more expensive as it requires professional medical knowledge guidance. To tackle the predicament, semi-supervised learning and self-supervised learning are very effective technologies. In this paper, we present a twin self-supervision based semi-supervised learning (TS-SSL) approach that embeds two types of self-supervised strategies (namely generative self-supervised learning and discriminative self-supervised learning) into semi-supervised framework to simultaneously learn from few-shot labeled images and vast unlabeled images. TS-SSL is an end-to-end classification model , in which semi-supervision and self-supervision can be jointly trained. The proposed TS-SSL is applied to perform retinal anomaly classification based on spectral-domain optical coherence tomography (SD-OCT) images. The experiments demonstrate that TS-SSL yields the good classification performance on one public SD-OCT dataset and two private SD-OCT datasets with only 10\% labels. We also claim that TS-SSL can be transferred to other medical imaging modalities . The code is available at https://github.com/ZhangYH0502/TS-SSL .},
  archive      = {J_NEUCOM},
  author       = {Yuhan Zhang and Mingchao Li and Zexuan Ji and Wen Fan and Songtao Yuan and Qinghuai Liu and Qiang Chen},
  doi          = {10.1016/j.neucom.2021.08.051},
  journal      = {Neurocomputing},
  pages        = {491-505},
  shortjournal = {Neurocomputing},
  title        = {Twin self-supervision based semi-supervised learning (TS-SSL): Retinal anomaly classification in SD-OCT images},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantic and detail collaborative learning network for
salient object detection. <em>NEUCOM</em>, <em>462</em>, 478–490. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To obtain more accurate saliency maps, current methods mainly focus on aggregating multi-level features with structures like U-Net and introducing edge information as auxiliary supervision. Different from the focus of existing methods, in the paper, we study the different roles of semantics and details in saliency detection . The task is decomposed into two parallel sub-tasks: internal semantic estimation and boundary detail prediction, and these sub-goals are optimized simultaneously via explicit constraints. Specifically, we propose a novel semantic and detail collaborative learning network (SDCLNet) for salient object detection. To this end, a backbone network (e.g., VGG-16) with an additional layer is first adopted as a shared encoder to extract features from each image. And then two asymmetric decoders without bells and whistles are designed, in which the semantic decoder generates a coarse semantic mask, and the detail decoder generates a fine-grained object boundary. Finally, a collaborative learning block with some meaningful design adaptively selects the discriminative features to undertake the task of saliency prediction. In this way, both the semantic and detailed information can effectively fused, and the final accurate and consistent saliency maps are generated. SDCLNet is easy to be trained in an end-to-end style, and it does not need any post-processing. Extensive experiments demonstrate the effectiveness and superiority of the proposed method in terms of both subjective visual perception and objective evaluation metrics on six benchmark datasets. SDCLNet achieves a real-time speed of 51 FPS when it is run on one GPU.},
  archive      = {J_NEUCOM},
  author       = {Yanhua Liang and Guihe Qin and Minghui Sun and Jun Qin and Jie Yan and Zhonghan Zhang},
  doi          = {10.1016/j.neucom.2021.08.037},
  journal      = {Neurocomputing},
  pages        = {478-490},
  shortjournal = {Neurocomputing},
  title        = {Semantic and detail collaborative learning network for salient object detection},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel sparse filtering for intelligent fault diagnosis
using acoustic signal processing. <em>NEUCOM</em>, <em>462</em>,
466–477. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acoustic signals have attracted considerable attention in mechanical fault diagnosis because of their advantages in non-invasive technique, instant measurement and low cost. However, traditional fault diagnosis methods could not achieve accurate feature extraction because of the strong noise environment of acoustic signals. In view of this, this study aims to provide a method that could accurately extract effectiveness features under noisy environment . Sparse representation is a research hotspot in intelligent fault diagnosis and has shown great power in feature extraction. In this paper, a novel fault diagnosis method based on parallel sparse filtering is presented to achieve sparse feature extraction from acoustic signals. Specially, parallel sparse filtering achieves sparse feature exaction by adding another normalization direction based on sparse filtering, and the derivation of parallel sparse filtering is also presented in detail. Then Z-score normalization is used to activate the training and testing data in fault classification process. The superiority of the proposed method is validated by simulated and experimental data. The results show that PSF is a promising sparse feature extraction method that can be used for mechanical fault diagnosis under acoustic signals.},
  archive      = {J_NEUCOM},
  author       = {Shanshan Ji and Baokun Han and Zongzhen Zhang and Jinrui Wang and Bo Lu and Jiawei Yang and Xingxing Jiang},
  doi          = {10.1016/j.neucom.2021.08.049},
  journal      = {Neurocomputing},
  pages        = {466-477},
  shortjournal = {Neurocomputing},
  title        = {Parallel sparse filtering for intelligent fault diagnosis using acoustic signal processing},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint nonnegative matrix factorization and network embedding
for graph co-clustering. <em>NEUCOM</em>, <em>462</em>, 453–465. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph co-clustering aims to simultaneously group heterogeneous vertices in bipartite networks. The current algorithms measure similarity of vertices by either topology or latent feature of networks, which is insufficient to fully characterize the structure of bipartite graphs . To overcome this problem, we propose a novel co-clustering algorithm by jointly integrating network embedding and NMF (called NENMF ) based on the fact that graph representation learning implicitly implies matrix factorizations , where multiple views of bipartite networks are integrated for graph co-clustering. Specifically, the equivalence between nonnegative matrix factorization (NMF) graph embedding for co-clustering is proven, which serves as the theoretical foundation for the proposed algorithm. Then, two auxiliary graphs are generated to fully characterize the topology structure of bipartite networks. Finally, NENMF jointly learns low-rank approximation matrices for bipartite networks and network embedding of auxiliary graphs, where network embedding is regularized into objective function of NMF. The main advantage of the proposed algorithm is to boost the accuracy by combining the low-dimensional approximation and graph representation of bipartite networks without increasing time complexity. The experimental results demonstrate that NENMF outperforms state-of-the-art approaches in terms of accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yan Wang and Xiaoke Ma},
  doi          = {10.1016/j.neucom.2021.08.014},
  journal      = {Neurocomputing},
  pages        = {453-465},
  shortjournal = {Neurocomputing},
  title        = {Joint nonnegative matrix factorization and network embedding for graph co-clustering},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anomaly detection in predictive maintenance: A new
evaluation framework for temporal unsupervised anomaly detection
algorithms. <em>NEUCOM</em>, <em>462</em>, 440–452. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The research in anomaly detection lacks a unified definition of what represents an anomalous instance. Discrepancies in the nature itself of an anomaly lead to multiple paradigms of algorithms design and experimentation. Predictive maintenance is a special case, where the anomaly represents a failure that must be prevented. Related time series research as outlier and novelty detection or time series classification does not apply to the concept of an anomaly in this field, because they are not single points which have not been seen previously and may not be precisely annotated. Moreover, due to the lack of annotated anomalous data, many benchmarks are adapted from supervised scenarios. To address these issues, we generalise the concept of positive and negative instances to intervals to be able to evaluate unsupervised anomaly detection algorithms. We also preserve the imbalance scheme for evaluation through the proposal of the Preceding Window ROC, a generalisation for the calculation of ROC curves for time series scenarios. We also adapt the mechanism from a established time series anomaly detection benchmark to the proposed generalisations to reward early detection. Therefore, the proposal represents a flexible evaluation framework for the different scenarios. To show the usefulness of this definition, we include a case study of Big Data algorithms with a real-world time series problem provided by the company ArcelorMittal, and compare the proposal with an evaluation method.},
  archive      = {J_NEUCOM},
  author       = {Jacinto Carrasco and David López and Ignacio Aguilera-Martos and Diego García-Gil and Irina Markova and Marta García-Barzana and Manuel Arias-Rodil and Julián Luengo and Francisco Herrera},
  doi          = {10.1016/j.neucom.2021.07.095},
  journal      = {Neurocomputing},
  pages        = {440-452},
  shortjournal = {Neurocomputing},
  title        = {Anomaly detection in predictive maintenance: A new evaluation framework for temporal unsupervised anomaly detection algorithms},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolving gaussian process kernels from elementary
mathematical expressions for time series extrapolation. <em>NEUCOM</em>,
<em>462</em>, 426–439. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Choosing the best kernel is crucial in many Machine Learning applications. Gaussian Processes are a state-of-the-art technique for regression and classification that heavily relies on a kernel function. However, in the Gaussian Processes literature, kernels have usually been either ad hoc designed, selected from a predefined set, or searched for in a space of compositions of kernels which have been defined a priori. In this paper, we propose a Genetic Programming algorithm that represents a kernel function as a tree of elementary mathematical expressions. By means of this representation, a wider set of kernels can be modeled, where potentially better solutions can be found, although new challenges also arise. The proposed algorithm is able to overcome these difficulties and find kernels that accurately model the characteristics of the data. This method has been tested in several real-world time series extrapolation problems, improving the state-of-the-art results while reducing the complexity of the kernels.},
  archive      = {J_NEUCOM},
  author       = {Ibai Roman and Roberto Santana and Alexander Mendiburu and Jose A. Lozano},
  doi          = {10.1016/j.neucom.2021.08.020},
  journal      = {Neurocomputing},
  pages        = {426-439},
  shortjournal = {Neurocomputing},
  title        = {Evolving gaussian process kernels from elementary mathematical expressions for time series extrapolation},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-supervised selective clustering ensemble based on
constraint information. <em>NEUCOM</em>, <em>462</em>, 412–425. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is an important research direction in data mining. However, there is no one clustering algorithm that can be applied efficiently in all situation. Clustering ensemble is the best way to solve the above-mentioned problems. It combines the results of multiple clustering algorithms, and the final result is significantly better than a single clustering algorithm . Although there is a lot of constraint information, the existing clustering ensemble algorithm does not utilize it. This paper uses constraint information in consensus function and proposes a Semi-supervised Selective Clustering Ensemble based on Chameleon (SSCEC) and Semi-supervised Selective Clustering Ensemble based on Ncut (SSCEN) to solve the above problem. SSCEC uses the chameleon algorithm as consensus function, and processes constraint information in subgraph partition and subgraph combining. SSCEN uses the Normalized cut algorithm as consensus function, and processes constraint information in the process of graph dichotomy. The experiment results show that our proposed two semi-supervised member selection clustering ensemble algorithms are better than other semi-supervised algorithms.},
  archive      = {J_NEUCOM},
  author       = {Tinghuai Ma and Zheng Zhang and Lei Guo and Xin Wang and Yurong Qian and Najla Al-Nabhan},
  doi          = {10.1016/j.neucom.2021.07.056},
  journal      = {Neurocomputing},
  pages        = {412-425},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised selective clustering ensemble based on constraint information},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Selective region enlargement network for fast object
detection in high resolution images. <em>NEUCOM</em>, <em>462</em>,
402–411. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting objects of varied sizes in high resolution images is difficult due to the challenges of high memory requirement and huge computation burden. Existing state-of-the-art detectors perform well on low resolution images . However, its performance is greatly limited on high resolution images. In this paper, we propose a selective region enlargement network, called SRENet, which significantly reduces processing time and memory requirement while remaining high detection accuracy. The proposed SRENet does not need to conduct detection on original high resolution images but only needs to conduct detection on down-sampled images and some zoom-in regions selected from high resolution images. SRENet first conducts coarse detection on a low resolution image, and then sequentially selects promising regions that are expected to be analyzed at a higher resolution. Specifically, SRENet is built upon Deep Q-learning Network (DQN) and it outputs an action-reward map. The value of the reward map indicates the possibility that the action can improve detection accuracy. The region selected by the action with the maximum reward value will be analyzed further at a higher resolution. Extensive experiments are conducted to demonstrate SRENet on two challenging datasets obtaining high resolution images. Experimental results show that SRENet achieves state-of-the-art detection performance with high efficiency.},
  archive      = {J_NEUCOM},
  author       = {Jiaxu Leng and Ying Liu and Xinbo Gao and Senior Member, IEEE},
  doi          = {10.1016/j.neucom.2021.08.015},
  journal      = {Neurocomputing},
  pages        = {402-411},
  shortjournal = {Neurocomputing},
  title        = {Selective region enlargement network for fast object detection in high resolution images},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-efficient goal-directed deep reinforcement learning
method for robot visuomotor skill. <em>NEUCOM</em>, <em>462</em>,
389–401. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep reinforcement learning (DRL) has provided an effective end to end approach for autonomous robot skill learning. However, the task goal in most DRL approaches is always single and fixed which restricts the flexibility of policy. In addition, the data inefficiency also makes it impractical to applied on real-world robots. To address these problems, this paper proposes a data-efficient goal-directed DRL method for robotic skill learning. First, an asymmetric deep deterministic policy gradients algorithm is constructed as the basic framework of the method by taking advantage of the low-dimensional physical state accessible in simulations. Then, a Siamese representation learning network is designed to embed the RGB observation and the human intention at the same feature space to realize human-robot intention transfer. And, an auxiliary similarity evaluation network is added to the DRL algorithm to accelerate representation learning . Finally, a domain randomization method is employed to transfer the learned policies from simulation to reality. In experiments, two typical robotic tasks are set up to evaluate the proposed method. The experimental results validate the effectiveness of the proposed method. The trained robot can switch among multiple goals automatically according to human intentions. And, the Siamese representation learning network and auxiliary similarity evaluation network can improve data efficiency effectively.},
  archive      = {J_NEUCOM},
  author       = {Rong Jiang and Zhipeng Wang and Bin He and Yanmin Zhou and Gang Li and Zhongpan Zhu},
  doi          = {10.1016/j.neucom.2021.08.023},
  journal      = {Neurocomputing},
  pages        = {389-401},
  shortjournal = {Neurocomputing},
  title        = {A data-efficient goal-directed deep reinforcement learning method for robot visuomotor skill},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GiGAN: Gate in GAN, could gate mechanism filter the features
in image-to-image translation? <em>NEUCOM</em>, <em>462</em>, 376–388.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-to-image translation techniques have been used in many different fields and have obtained remarkable performance in recent years. However, in many image-to-image translation tasks, only certain parts of the image need to be converted instead of the whole image. Traditional GAN-based methods often reconstruct the entire image, which may lead to artifacts and low-quality results. To address this issue, we propose a novel model, named GiGAN: Gate in GAN , which utilizes special Residual Blocks embedded with Gate Cells to filter and extract the features for facial attribute transfer and facial expression synthesis tasks. Specifically, we treat the intermediate feature from source domain to target domain as a sequence, and introduce the gate mechanism into this sequential task. To achieve this, we introduce the convolutional layers into gate cell and modify the stream in traditional gate cell to suit for image-to-image translation task. We designed two types of methods based on reusing parameters in the residual blocks or not, namely GiGAN-reuse and GiGAN-non-reuse. Experimental results and quantitative evaluations show that our model has superior performance against state-of-the-arts. And ablation studies demonstrate the effectiveness of our method. Furthermore, visualization of the features in Gate Cells shows that Gate Mechanism can filter the features in image-to-image translation effectively.},
  archive      = {J_NEUCOM},
  author       = {Xuan Nie and Jianchao Jia and Haoxuan Ding and Edward K. Wong},
  doi          = {10.1016/j.neucom.2021.07.085},
  journal      = {Neurocomputing},
  pages        = {376-388},
  shortjournal = {Neurocomputing},
  title        = {GiGAN: Gate in GAN, could gate mechanism filter the features in image-to-image translation?},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RGBT tracking via cross-modality message passing.
<em>NEUCOM</em>, <em>462</em>, 365–375. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many RGBT trackers utilize adaptive weighting mechanism to treat dual modalities differently and obtain more robust feature representations for tracking. Although these trackers work well under certain conditions, however, they ignore the information interactions in feature learning , which might limit tracking performance. In this paper, we propose a novel cross-modality message passing model to interactively learn robust deep representations of dual modalities for RGBT tracking. Specifically, we extract features of dual modalities by backbone network and take each channel of these features as a node of a graph. Therefore, all channels of dual modalities can explicitly communicate with each other by the graph learning, and the outputted features are thus more diverse and discriminative. Moreover, we introduce the gate mechanism to control the propagation of information flow to achieve more intelligent fusion. The features generated from the interactive cross-modality message passing model will be passed selectively through the gate layer and concatenated with original features as the final representation. We extend the ATOM tracker into its dual-modality version and combine it with our proposed module for final tracking. Extensive experiments on two RGBT benchmark datasets validate the effectiveness and efficiency of our proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Rui Yang and Xiao Wang and Chenglong Li and Jinmin Hu and Jin Tang},
  doi          = {10.1016/j.neucom.2021.08.012},
  journal      = {Neurocomputing},
  pages        = {365-375},
  shortjournal = {Neurocomputing},
  title        = {RGBT tracking via cross-modality message passing},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MiniExpNet: A small and effective facial expression
recognition network based on facial local regions. <em>NEUCOM</em>,
<em>462</em>, 353–364. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep networks based Facial Expression Recognition (FER) have shown excellent performance. Due to high computational cost and memory resources, it is hard to develop these FER models in practical scenarios. In this paper, we design a small and effective deep network for FER based on facial local regions. Firstly, Regions of Interest (ROIs) related to facial Action Units (AUs) are cropped by facial landmarks and represented by Histogram Local Binary Pattern (HLBP) feature. Secondly, an effective and efficient light-weight network named MiniExpNet, is proposed by human–machine collaborative strategy, and only has 60 K parameters. To further improve the performance, we extend the MiniExpNet by integrating the Attention Block and self-distillation mechanism. The Attention Block exploits the importance of different ROIs for FER. The self-distillation mechanism is used for enhancing generalization ability during training. Extensive comparisons are made on three widely-used FER datasets, CK+, RaFD and Oulu-CASIA. Compared to exiting light-weight networks, the proposed model provides a better balance between accuracy, model size and speed.},
  archive      = {J_NEUCOM},
  author       = {Xing Jin and Zhong Jin},
  doi          = {10.1016/j.neucom.2021.07.079},
  journal      = {Neurocomputing},
  pages        = {353-364},
  shortjournal = {Neurocomputing},
  title        = {MiniExpNet: A small and effective facial expression recognition network based on facial local regions},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph matching based point correspondence with alternating
direction method of multipliers. <em>NEUCOM</em>, <em>462</em>, 344–352.
(<a href="https://doi.org/10.1016/j.neucom.2021.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph matching is a fundamental problem in image processing and computer vision tasks , which can be used to solve the feature correspondence problem. Most graph matching tasks have been proved to be NP-Complete problems which are generally solved by approximate algorithms based on the continuous relaxation scheme. Targeting at these problems, this paper proposes a novel graph matching algorithm based on the alternating direction method of multipliers (ADMM) which typically decomposes a difficult problem into relatively simpler subproblems. Specifically, the matching constraints are decomposed into four continuous constraints and the assignment vector is decomposed into different vectors according to the constraints. Then the transformed objective function is iteratively optimized under the framework of ADMM. The proposed method achieves the state of the art performance, while maintaining a comparable computational complexity . And a discrete solution can be directly obtained without the projection process. Experimental results on both synthetic points and real images demonstrate the effectiveness of the proposed method by comparing it with the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jing Yang and Xu Yang and Zhang-Bing Zhou and Zhi-Yong Liu and Ming-Yu Fan},
  doi          = {10.1016/j.neucom.2021.08.002},
  journal      = {Neurocomputing},
  pages        = {344-352},
  shortjournal = {Neurocomputing},
  title        = {Graph matching based point correspondence with alternating direction method of multipliers},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient density-based clustering algorithm for face
groping. <em>NEUCOM</em>, <em>462</em>, 331–343. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the following problem: Given a large number of unlabeled face images, group them into individual clusters, and the number of clusters cannot be known in advance. To this end, an Efficient Density-based clustering incorporated with the model of Graph partitioning (EDG) is proposed. 1. Inspired by the progress of graph partitioning clustering, a novel criterion that can be seen as a variant of the Normalized-cut model is employed to measure the similarity between two samples. 2. We only consider the similarities and connections on a subset of all possible pairs, i.e. the top- K nearest neighbors for each sample. Therefore, the computing and storage costs are linear w.r.t. the number of samples. In order to assess the performance of EDG on face images, extensive experiments based on a two-stage framework have been conducted on 19 benchmark datasets (14 middle-scale and 5 large-scale) from the literature. The experimental results have shown the effectiveness and robustness of our model, compared with the state-of-the-art methods. [code]},
  archive      = {J_NEUCOM},
  author       = {Shenfei Pei and Feiping Nie and Rong Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.07.074},
  journal      = {Neurocomputing},
  pages        = {331-343},
  shortjournal = {Neurocomputing},
  title        = {An efficient density-based clustering algorithm for face groping},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SG-DSN: A semantic graph-based dual-stream network for
facial expression recognition. <em>NEUCOM</em>, <em>462</em>, 320–330.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression recognition (FER) is a crucial task for human emotion analysis and has attracted wide interest in the field of computer vision and affective computing . General convolutional-based FER methods rely on the powerful pattern abstraction of deep models, but they lack the ability to use semantic information behind significant facial areas in physiological anatomy and cognitive neurology. In this work, we propose a novel approach for expression feature learning called Semantic Graph-based Dual-Stream Network (SG-DSN), which designs a graph representation to model key appearance and geometric facial changes as well as their semantic relationships . A dual-stream network (DSN) with stacked graph convolutional attention blocks (GCABs) is introduced to automatically learn discriminative features from the organized graph representation and finally predict expressions. Experiments on three lab-controlled datasets and two in-the-wild datasets demonstrate that the proposed SG-DSN achieves competitive performance compared with several latest methods.},
  archive      = {J_NEUCOM},
  author       = {Yang Liu and Xingming Zhang and Jinzhao Zhou and Lunkai Fu},
  doi          = {10.1016/j.neucom.2021.07.017},
  journal      = {Neurocomputing},
  pages        = {320-330},
  shortjournal = {Neurocomputing},
  title        = {SG-DSN: A semantic graph-based dual-stream network for facial expression recognition},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online event-triggered adaptive critic design for
multi-player zero-sum games of partially unknown nonlinear systems with
input constraints. <em>NEUCOM</em>, <em>462</em>, 309–319. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the design of online event-triggered optimal control strategy for multi-player zero-sum games (MP-ZSGs) with control constraints when the system model is partially unknown. Non-quadratic functions are utilized to construct the cost functions under the condition of control constraints. The proposed algorithm is designed based on the framework of identifier-critic networks. The unknown drift dynamics model is reconstructed by an identifier neural network (INN) using the input and output data. The near-optimal event-based controls and time-based disturbances are designed by training a critic neural network (CNN). With the aid of the designed event-triggered mechanism (ETM), the needless computing and communication actions of the system signals have been reduced so as to save computing/communication resources. Meanwhile, to remove the persistence of excitation (PE) condition, the historical and current data are utilized to construct a modified tuning law of CNN. Theoretically, the uniform ultimate boundedness (UUB) properties of the system states and the critic weights errors are proved by Lyapunov approach. Moreover, the Zeno behavior is proved to be excluded under the designed triggering condition. Finally, the convergence and performance of the online method are verified by simulating a representative example.},
  archive      = {J_NEUCOM},
  author       = {Pengda Liu and Huaguang Zhang and He Ren and Chong Liu},
  doi          = {10.1016/j.neucom.2021.07.058},
  journal      = {Neurocomputing},
  pages        = {309-319},
  shortjournal = {Neurocomputing},
  title        = {Online event-triggered adaptive critic design for multi-player zero-sum games of partially unknown nonlinear systems with input constraints},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Influence of bio-inspired activity regulation through neural
thresholds learning in the performance of neural networks.
<em>NEUCOM</em>, <em>462</em>, 294–308. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies on Kenyon Cells (KCs) in the olfactory system of locust have found evidence that some of them are more responsive towards stimuli than others. This variability suggests that there could be a heterogeneous neural threshold distribution among KCs. This work explores the hypothesis that the heterogeneity in neural thresholds could control the activity level of populations of neurons and facilitate the generation of sparse code to achieve a better representation of stimuli. In order to study this hypothesis, an artificial neural network that adapts many of the strategies observed in the locust olfactory system is proposed, including a new learning algorithm capable of finding the best neural threshold distribution to resolve a certain classification problem and a gain control term that keeps the activity level of the neurons in the hidden layer under a certain limit. The bio-inspired neural network gets the best results when the activity level in the hidden layer is low, for which neural thresholds are more important for a better performance than the connections between the neurons in different layers. Also, it was found that the separability of the internal representations of the different patterns in the classification problem improves when the thresholds are adjusted by the learning algorithm in order to control the activity level. Finally, the performance of this network was compared to SVMs and MLP when applied to resolve a complex classification task with data collected by electronic noses and affected by sensor drift, for which the bio-inspired network obtains very satisfactory results, reaching a performance similar or even better than SVMs and MLP.},
  archive      = {J_NEUCOM},
  author       = {Jessica Lopez-Hazas and Aaron Montero and Francisco B. Rodriguez},
  doi          = {10.1016/j.neucom.2021.08.001},
  journal      = {Neurocomputing},
  pages        = {294-308},
  shortjournal = {Neurocomputing},
  title        = {Influence of bio-inspired activity regulation through neural thresholds learning in the performance of neural networks},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Cross-task feature alignment for seeing pedestrians in the
dark. <em>NEUCOM</em>, <em>462</em>, 282–293. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pedestrian detection in low-light environments has been an extremely challenging task because of the serious degradation of color and texture information. In the latest research, multi-task learning is introduced into image relighting and pedestrian detection tasks, which improves the performance of detecting pedestrians in low-light environments significantly. However, many problems in the multi-task learning period, including the misalignment of scale and channel of features from image relighting and pedestrian detection tasks, remain unresolved, thereby resulting in insufficient feature representation. In this paper, we propose a novel cross-task feature alignment method to tackle the aforementioned problems. Specifically, the proposed method imposes four feature alignment (FA) layers before the feature fusing and sharing step in multi-task learning period to align the scale and channel of features across tasks and fine-tune feature representation iteratively. In addition, we design a novel multi-scale feature-enhanced detection network to further improve the performance of the detector. Experimental results from simulated and real-world scenarios prove that our method prominently boosts the ability to detect pedestrians in the dark.},
  archive      = {J_NEUCOM},
  author       = {Yuanzhi Wang and Tao Lu and Yanduo Zhang and Wenhua Fang and Yuntao Wu and Zhongyuan Wang},
  doi          = {10.1016/j.neucom.2021.07.096},
  journal      = {Neurocomputing},
  pages        = {282-293},
  shortjournal = {Neurocomputing},
  title        = {Cross-task feature alignment for seeing pedestrians in the dark},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LLA: Loss-aware label assignment for dense pedestrian
detection. <em>NEUCOM</em>, <em>462</em>, 272–281. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label assignment has been widely studied in general object detection because of its great impact on detectors’ performance. In the field of dense pedestrian detection, human bodies are often heavily entangled, making label assignment more important. However, none of the existing label assignment method focuses on crowd scenarios. Motivated by this, we propose L oss-aware L abel A ssignment (LLA) to boost the performance of pedestrian detectors in crowd scenarios. Concretely, LLA first calculates classification (cls) and regression (reg) losses between each anchor and ground-truth (GT) pair. A joint loss is then defined as the weighted summation of cls and reg losses as the assigning indicator. Finally, anchors with top K minimum joint losses for a certain GT box are assigned as its positive anchors. Anchors that are not assigned to any GT box are considered negative. LLA is simple but effective. Experiments on CrowdHuman and CityPersons show that such a simple label assigning strategy can boost MR by 9.53\% and 5.47\% on two famous one-stage detectors – RetinaNet and FCOS, becoming the first one-stage detector that surpasses Faster R-CNN in crowd scenarios.},
  archive      = {J_NEUCOM},
  author       = {Zheng Ge and Jianfeng Wang and Xin Huang and Songtao Liu and Osamu Yoshie},
  doi          = {10.1016/j.neucom.2021.07.094},
  journal      = {Neurocomputing},
  pages        = {272-281},
  shortjournal = {Neurocomputing},
  title        = {LLA: Loss-aware label assignment for dense pedestrian detection},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anti-injury function of complex spiking neural networks
under targeted attack. <em>NEUCOM</em>, <em>462</em>, 260–271. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-like intelligence is to simulate the structure and function of the biological brain as much as possible based on the latest findings in brain science. The biological brain has strong robustness under external attacks. In this study, two complex spiking neural networks (CSNNs) are constructed: a spiking neural network (SNN) with small-world topology and a SNN with scale-free topology, in which the nodes are Izhikevich neuron model, and the edges are the synaptic plasticity model including excitatory and inhibitory synapses. For the targeted attack, the anti-injury function of two CSNNs is comparatively analyzed. On this basis, the anti-injury mechanism of CSNN is explored. The experimental results show that: (1) Small-world SNN (SWSNN) has better performance than scale-free SNN (SFSNN) in the anti-injury ability under targeted attack on high-degree nodes, and they are similar in the anti-injury ability under targeted attack on intermediate and low-degree nodes; the results of the robustness of topology are consistent with the results of anti-injury function of CSNNs, which indicates that the anti-injury ability of two kinds of CSNNs is affected by topology. (2) The dynamic evolutions of neuron firing, synaptic weight , and topological characteristic in the information processing of CSNN have a linkage effect under targeted attack; the dynamic evolution of synaptic weight is significantly related to the anti-injury ability of CSNNs, which clues synaptic plasticity is the intrinsic factor of the anti-injury function of CSNNs.},
  archive      = {J_NEUCOM},
  author       = {Lei Guo and RuiXue Man and YouXi Wu and HongLi Yu and GuiZhi Xu},
  doi          = {10.1016/j.neucom.2021.07.092},
  journal      = {Neurocomputing},
  pages        = {260-271},
  shortjournal = {Neurocomputing},
  title        = {Anti-injury function of complex spiking neural networks under targeted attack},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An effective compression algorithm for real-time
transmission data using predictive coding with mixed models of LSTM and
XGBoost. <em>NEUCOM</em>, <em>462</em>, 247–259. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a compression and decompression algorithm is proposed for real-time transmission data by combining discrete wavelet decomposition and reconstruction, hybrid model prediction of long short-term memory (LSTM) and extreme gradient boosting (XGBoost), and the development of quantization sequences. The forward compression and reverse decompression are achieved by continuously acquiring the prediction error and data series with quantization error through the iterative shifting approach. To accurately forecast data series with quantization errors, three classes of data with specific distribution characteristics collected from the measurement-while-drilling (MWD) operation field are decomposed into approximate data and detailed data, which are then predicted by autoregressive integrated moving average (ARIMA), support vector regression (SVR), XGBoost , backpropagation neural network (BPNN), radial basis function neural network (RBFNN), and LSTM models. Particularly, the LSTM model and the XGBoost model are proven to be suitable strategies for working with approximate data and detailed data separately by comparing with conventional approaches in terms of the mean absolute error ( MAE ), root mean square error ( RMSE ), and coefficient of determination ( R 2 ) predictive indexes. Besides, experiment studies show that almost 50\% compression performance can be reached under one in ten thousand distortions. It is verified that the proposed algorithm is appropriate and efficient for real-time data transmission applications with high performance.},
  archive      = {J_NEUCOM},
  author       = {Zhidan Yan and Junfei Wang and Li Sheng and Zhenyu Yang},
  doi          = {10.1016/j.neucom.2021.07.071},
  journal      = {Neurocomputing},
  pages        = {247-259},
  shortjournal = {Neurocomputing},
  title        = {An effective compression algorithm for real-time transmission data using predictive coding with mixed models of LSTM and XGBoost},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed output tracking of nonlinear multi-agent systems
by linear sampled-data control. <em>NEUCOM</em>, <em>462</em>, 238–246.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed output tracking problem via linear sampled-data control for a class of uncertain nonlinear multi-agent systems. Specifically, for the case where the graph topology is directed and the leader is the neighbor of only a small portion of followers, by combining the backstepping method with sampled-data method, a series of linear sampled-data controllers are obtained. Stability analysis is performed by using calculus, comparison principle and so on. The main results of this paper are concluded that all the states of the closed-loop system are globally bounded and the output tracking errors can be tuned arbitrarily small. Finally, a numerical example is given to verify the validity of the conclusion.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu Xu and Wuquan Li and Meiqiao Wang},
  doi          = {10.1016/j.neucom.2021.07.060},
  journal      = {Neurocomputing},
  pages        = {238-246},
  shortjournal = {Neurocomputing},
  title        = {Distributed output tracking of nonlinear multi-agent systems by linear sampled-data control},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Time-frequency deep metric learning for multivariate time
series classification. <em>NEUCOM</em>, <em>462</em>, 221–237. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multivariate time series (MTS) data exist in various fields of studies and MTS classification is an important research topic in the machine learning community. Researchers have proposed many MTS classification models over the years and the distance-based methods along with nearest neighbor classifier achieve good performance. However, the current methods mainly focus on defining distance metric on time-domain of MTS and ignore frequency information. Besides, these methods usually define the same linear distance metric for different datasets, which is not suitable for capturing the nonlinear relationship of MTS and degrades the discriminative power of the distance metric. In this paper, we propose a time–frequency deep metric learning (TFDM) approach for MTS classification. The multilevel discrete wavelet decomposition is first adopted to decompose an MTS into a group of sub-MTS so as to extract multilevel time–frequency representations. Then, a deep convolutional neural network is developed for each level to learn level-specific nonlinear features and a metric learning layer is added on the top of the network to learn the semantic similarity of MTS. Moreover, a cross-level consistency regularization term is designed to encourage the distance metrics of different levels to be consistent for capturing the correlations among different levels. Finally, we use 1-nearest neighbor to classify MTS according to the learned distance metrics. Extensive experiments on 18 benchmark datasets show the effectiveness of our approach.},
  archive      = {J_NEUCOM},
  author       = {Zhi Chen and Yongguo Liu and Jiajing Zhu and Yun Zhang and Rongjiang Jin and Xia He and Jing Tao and Lidian Chen},
  doi          = {10.1016/j.neucom.2021.07.073},
  journal      = {Neurocomputing},
  pages        = {221-237},
  shortjournal = {Neurocomputing},
  title        = {Time-frequency deep metric learning for multivariate time series classification},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperspectral image classification using cluster based graph
regularized low rank representation and dictionary learning.
<em>NEUCOM</em>, <em>462</em>, 208–220. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important processes on hyperspectral images (HSI) is classification. Extracting low-dimensional subspace structures and obtaining discriminative representations are among the significant goals in the hyperspectral image classification. The low-rank representation (LRR) method obtains low-dimensional data structures; however, it cannot accurately find the intrinsic and discriminative structure in a nonlinear structure. In this paper, the cluster-based graph regularized LRR with dictionary learning (CLRRDL) is proposed for HSI classification. The data manifold structure is combined with the LRR model in the form of manifold regularization to improve LRR. The information of segments in each cluster is used in the proposed method to obtain the graph. Also, the geodesic distance is used to express the graph similarity with the nonlinear structure. In this model, each pixel is expressed as a linear combination of dictionary components. Moreover, rather than working on the entire image, it first clusters the image by considering the pixels in a cluster to be often composed of the same materials and their linear combination to be limited to common components from the dictionary. Then, the proposed method is separately applied to each cluster. Highly discriminative features are obtained using this factor and dictionary learning. The experimental results show that the proposed method performs better compared to other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Fatemeh Hajiani and Naser Parhizgar and Ahmad Keshavarz},
  doi          = {10.1016/j.neucom.2021.07.075},
  journal      = {Neurocomputing},
  pages        = {208-220},
  shortjournal = {Neurocomputing},
  title        = {Hyperspectral image classification using cluster based graph regularized low rank representation and dictionary learning},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A data-driven degradation prognostic strategy for
aero-engine under various operational conditions. <em>NEUCOM</em>,
<em>462</em>, 195–207. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Practical degradation prognostics for aero engines is difficult owing to the degradation features covered by the continuous switching among various operational conditions. A novel degradation prognostics strategy for aero engines under various operating conditions is proposed in this study. Specifically, to remove the influence of different operational conditions, degradation features, which are hidden in raw data, are extracted. This strategy can realize health state estimation, degradation trend prediction and remaining useful life (RUL) estimation. First, a k-means algorithm and three defined indicators are combined to distinguish different operational conditions, extract preferably monotonic and trendable degradation features. A linear logistic regression model is utilized to construct a synthesized health index (SHI) library. Second, a deep forest classifier (DFC) and long short-term memory (LSTM) are utilized to establish an offline health state estimation model and a degradation trend prediction model. Finally, a dynamic time warping algorithm (DTW) is adopted to obtain a new SHI for online RUL estimation based on the two aforementioned offline models. Verification results using the NASA Prognostics Center dataset show that the proposed strategy for aero engines under various operating conditions is effective and feasible.},
  archive      = {J_NEUCOM},
  author       = {Cunsong Wang and Zhenghong Zhu and Ningyun Lu and Yuehua Cheng and Bin Jiang},
  doi          = {10.1016/j.neucom.2021.07.080},
  journal      = {Neurocomputing},
  pages        = {195-207},
  shortjournal = {Neurocomputing},
  title        = {A data-driven degradation prognostic strategy for aero-engine under various operational conditions},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Filter pruning via separation of sparsity search and model
training. <em>NEUCOM</em>, <em>462</em>, 185–194. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network pruning has been widely used in the field of model compression and inference acceleration for convolutional neural networks(CNN). Existing methods generally follow a “training-pruning-retraining” paradigm, known as a three-stage pipeline. However, it cannot play an effective role in a pre-trained model with a larger pruning rate. In addition, prevailing methods usually set pruning rates as super parameters, which fail to consider the sensitivity of different convolution layers . In this paper, a novel pruning approach, based on the separation of sparsity search and model training(SST), is proposed to solve the above problems. Specifically, an evolutionary algorithm is introduced into the process of searching for the most suitable number of pruned filters for every layer. After obtaining the best sparsity structure, a new pruning strategy, called the one-pruning pipeline, is utilized to prune the pre-trained model. Experiments on multiple advanced CNN architectures show that SST can greatly improve the pruning rate with a slight loss of accuracy, which is found to universally reduce more than 60\% FLOPs on CIFAR-10. Notably, on ILSVRC-2012, pruning based on ResNet18 reduces FLOPs by 42.8\%, while top-1 and top-5 accuracy only lose 1.19\% and 0.62\%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Youzao Lian and Peng Peng and Weisheng Xu},
  doi          = {10.1016/j.neucom.2021.07.083},
  journal      = {Neurocomputing},
  pages        = {185-194},
  shortjournal = {Neurocomputing},
  title        = {Filter pruning via separation of sparsity search and model training},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wind power forecasting based on stacking ensemble model,
decomposition and intelligent optimization algorithm. <em>NEUCOM</em>,
<em>462</em>, 169–184. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wind power forecasting has high application value in power systems. However, due to the intermittence and fluctuation of wind power, it is difficult to predict wind power effectively using a single forecasting model. Therefore, to improve the accuracy and stability of wind power forecasting, an ensemble learning model based on stacking framework is proposed in this paper. First, several decomposition techniques are used to pre-process the original wind power data and an optimal decomposition method is selected through experiments. Then, a quadratic interpolation based on state transition algorithm is proposed to optimize the parameters of the Bernstein polynomial model and the weights of the Hermite neural network (HNN) to obtain two base learners. Finally, the Spearman correlation coefficient is used to analyze the correlation of several base learners. The base learners with low correlation and strong prediction ability are selected as the first-layer forecasting model of the stacking model, and the HNN is used as the second-layer prediction model to obtain the stacking ensemble model. To verify the effectiveness of the proposed model, a large number of comprehensive experiments are carried out with wind power data from a wind farm in Xinjiang, China. Experimental results show that the proposed model has higher prediction accuracy and stability than other single forecasting models.},
  archive      = {J_NEUCOM},
  author       = {Yingchao Dong and Hongli Zhang and Cong Wang and Xiaojun Zhou},
  doi          = {10.1016/j.neucom.2021.07.084},
  journal      = {Neurocomputing},
  pages        = {169-184},
  shortjournal = {Neurocomputing},
  title        = {Wind power forecasting based on stacking ensemble model, decomposition and intelligent optimization algorithm},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble deep relevant learning framework for
semi-supervised soft sensor modeling of industrial processes.
<em>NEUCOM</em>, <em>462</em>, 154–168. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has been growing in popularity for soft sensor modeling of nonlinear industrial processes, infeuality-related variables. However, applications may be highly nonlinear, and the quantity of labeled samples is considerably limited. The extraction of relevant information from abundant unlabeled data is becoming an area of increasing interest in soft-sensor development. A novel ensemble deep relevant learning soft sensor (EDRLSS) modeling framework based on stacked autoencoder (SAE), mutual information (MI), and bagging-based strategy is proposed. SAE is trained layer-by-layer with MI analysis conducted between targeted outputs and learned hidden representations to evaluate and weight the current layer representations. The proposed method eliminates irrelevant information and weights the retained features to highlight the most relevant representations. Thus, the approach extracts deep representative information. Besides, a bagging-based ensemble strategy is applied to improve the soft-sensor performance and reliability. Two real-world industrial nonlinear processes are used to evaluate the EDRLSS framework performance. The results show enhanced prediction performance compared to other state-of-the-art and traditional methods.},
  archive      = {J_NEUCOM},
  author       = {Jean Mario Moreira de Lima and Fabio Meneghetti Ugulino de Araujo},
  doi          = {10.1016/j.neucom.2021.07.086},
  journal      = {Neurocomputing},
  pages        = {154-168},
  shortjournal = {Neurocomputing},
  title        = {Ensemble deep relevant learning framework for semi-supervised soft sensor modeling of industrial processes},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ToStaGAN: An end-to-end two-stage generative adversarial
network for brain tumor segmentation. <em>NEUCOM</em>, <em>462</em>,
141–153. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation using MRI data remains challenging for some reasons. Hence, how to accurately segment the brain tumor is kept as a significant topic in the area of medical image segmentation . To follow the idea of “coarse-to-fine” in practice, this paper proposes an end-to-end two-stage generative adversarial neural network (ToStaGAN) to improve the braintumor is kept as a significant topic in the area of medical image segmentation . To follow the idea of “coarse-to-fine” in practice, this paper proposes an end-to-end two-stage generative adversarial neural network (ToStaGAN) to improve the brain tumor segmentation performance by making full use of semantic information in high-level.In the proposed ToStaGAN, the UNET network is adopted as the “coarse” generation network in the first stage, while a U-Shaped contextual autoencoder (ConEnDer), which consists of the proposed fine-grained extraction module (FEM) and dense skip connection, is proposed as the “fine” generation network in the second stage. To be more specific, the FEM is mainly used to effectively extract “fine-grained” features that plays a crucial role in semantic segmentation with only increasing a few parameters. Furthermore, it has the ability to obtain more diverse and abstract features. And by further utilizing the features extracted from the FEM and the coarse prediction map from the first stage, the ConEnDer holds the great potential to generate the optimized segmentation results. We then evaluate the performance of ToStaGAN on the BARATS 2015. Findings from the evaluations suggest that the proposed two-stage generation network achieves a better performance than the one-stage network; thus, also implying the effectiveness of the proposed ConEnder for “fine” segmentation. A comparative summary also shows that the ToStaGAN achieves a better segmentation performance in comparison to other competing approaches.},
  archive      = {J_NEUCOM},
  author       = {Yi Ding and Chao Zhang and Mingsheng Cao and Yilei Wang and Dajiang Chen and Ning Zhang and Zhiguang Qin},
  doi          = {10.1016/j.neucom.2021.07.066},
  journal      = {Neurocomputing},
  pages        = {141-153},
  shortjournal = {Neurocomputing},
  title        = {ToStaGAN: An end-to-end two-stage generative adversarial network for brain tumor segmentation},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimization scheme for segmented-memory neural network.
<em>NEUCOM</em>, <em>462</em>, 132–140. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capture of long-term dependencies is a core task in sequence learning, and imitating the way of human memorization is a promising orientation. The existing algorithms can fractionate the sequence into segments with fixed length according to a prior knowledge, but the segmentation depends on the context and is difficult to assign length before network training. Thus in this paper, we propose a variant of segmented-memory neural network which can segment the sequence into arbitrary lengths and then perform cascade via a binarized mask of memory slots. For optimization of the network, we deduce an optimal mask theoretically, and then apply it in a novel scheme based on a sparsity regularizer. In experiments, we conduct ablation analysis and evaluation on some algorithmic or classification tasks , several models including the proposed one optimized by using lasso regularizer are adopted for comparison. Both of the fixed- and variable-length sequences are tested, and the results in different criteria have demonstrated the superiority of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Dongjing Shan and Chao Zhang and Yongjian Nian},
  doi          = {10.1016/j.neucom.2021.07.076},
  journal      = {Neurocomputing},
  pages        = {132-140},
  shortjournal = {Neurocomputing},
  title        = {An optimization scheme for segmented-memory neural network},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view clustering by joint spectral embedding and
spectral rotation. <em>NEUCOM</em>, <em>462</em>, 123–131. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discrete Spectral clustering is an effective tool for directly getting discrete labels. However, existing spectral clustering carry out spectral embedding and spectral rotation separately, which may limit their clustering performance. Seamlessly connecting above two processes is challenging. In this paper, we propose a new multi-view clustering framework, namely Multi-view Clustering by Joint Spectral Embedding and Spectral Rotation. In the framework, the differences of Laplacian matrices from different views are learned adaptively. Moreover, the real-valued cluster indicator matrix is approximated by continuous orthogonalization of the discrete clustering index matrix. By doing so, our method has better convergence, which is also strictly mathematically proven. Extensive experiments indicate that our method is superior to several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhizhen Wan and Huiling Xu and Quanxue Gao},
  doi          = {10.1016/j.neucom.2021.07.090},
  journal      = {Neurocomputing},
  pages        = {123-131},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering by joint spectral embedding and spectral rotation},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Distance constraint between features for unsupervised
domain adaptive person re-identification. <em>NEUCOM</em>, <em>462</em>,
113–122. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many superior person re-identification (re-ID) approaches face a challenge: their performance show disastrous when all supervised models are generalized to a new domain. Some researchers have recently proposed domain adaptive person re-ID methods to address this difficulty, whereas they directly leveraged the target-domain data that would generate lots of noisy pseudo labels. Hence, this paper proposes a distance constraint between features (DCF) method, which clusters the feature distribution fitted the real target-domain data. We assemble different parts of one person for multi-scale self-supervised learning. After introducing domain invariance and designing the inter-image and inter-class distance constraint to regulate distances between target samples, the feature distribution extracted from the encoder trained by the source data can fit the real target data distribution, which leads our domain adaptive model to enjoy the more reliable clustering results and thus obtain a great identification performance in target domain. Extensive experiments demonstrate our approach outperforms state-of-the-art methods on three large-scale released datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhihao Li and Bing Han and Xinbo Gao and Biao Hou and Zongyuan Liu},
  doi          = {10.1016/j.neucom.2021.07.061},
  journal      = {Neurocomputing},
  pages        = {113-122},
  shortjournal = {Neurocomputing},
  title        = {Distance constraint between features for unsupervised domain adaptive person re-identification},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conciseness is better: Recurrent attention LSTM model for
document-level sentiment analysis. <em>NEUCOM</em>, <em>462</em>,
101–112. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long short-term memory (LSTM) or gated recurrent units (GRUs) are usually employed to recurrently learn variable-length sentence representations with long-range dependency in document-level sentiment analysis. However, LSTM and GRUs are biased models in which the words in the tail of sentences are dominant over the words at the beginning. Although some reweighting methods, such as self-attention, are useful for reweighting each word according to its importance, when processing a document with many tokens, they tend to assign equally smaller weights to each word, leading to the keywords being covered by nonsentiment words. In this paper, a recurrent attention LSTM neural network is presented to iteratively locate an attention region covering the key sentiment words. By gradually reducing the range of attention and the number of tokens, the model can leverage the weight of the key sentiment words for final classification. Additionally, a joint loss function is implemented to highlight both keywords and appropriate attention regions. The comparative experiments are conducted on the IMDB, Yelp and Amazon document-level corpora. The results show that the proposed model outperforms several state-of-the-art methods in document-level sentiment classification.},
  archive      = {J_NEUCOM},
  author       = {You Zhang and Jin Wang and Xuejie Zhang},
  doi          = {10.1016/j.neucom.2021.07.072},
  journal      = {Neurocomputing},
  pages        = {101-112},
  shortjournal = {Neurocomputing},
  title        = {Conciseness is better: Recurrent attention LSTM model for document-level sentiment analysis},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge augmented transformer for adversarial multidomain
multiclassification multimodal fake news detection. <em>NEUCOM</em>,
<em>462</em>, 88–100. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spread of disinformation and fake news on social platforms has an unfavorable impact on social harmony and stability. The timely and accurate identification of fake news might help restrain the propagation of fake news and mitigate its influence on society. In this paper, we propose a novel multimodal fake news detection framework: the K nowledge A ugmented T ransformer for adversarial M ultidomain multiclassification multimodal F ake news detection framework (KATMF). In contrast to most of the existing studies, which ignore the differences among news articles from different domains in terms of the feature distribution, the KATMF employs a multimodal adversarial multitask learning module to capture these differences. Moreover, because social media news entities generally lack sufficient background knowledge, to enrich news with knowledge information in a homogeneous embedding space, we use the K nowledge A ugmented T ransformer (KAT) to selectively encode the information of entities from an external knowledge source into the representation of news. We evaluate our approach on a large-scale real-world dataset, and the experimental results demonstrate that our proposed model outperforms state-of-the-art fake news detection methods.},
  archive      = {J_NEUCOM},
  author       = {Chenguang Song and Nianwen Ning and Yunlei Zhang and Bin Wu},
  doi          = {10.1016/j.neucom.2021.07.077},
  journal      = {Neurocomputing},
  pages        = {88-100},
  shortjournal = {Neurocomputing},
  title        = {Knowledge augmented transformer for adversarial multidomain multiclassification multimodal fake news detection},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual focal loss to address class imbalance in semantic
segmentation. <em>NEUCOM</em>, <em>462</em>, 69–87. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common problem in pixelwise classification or semantic segmentation is class imbalance, which tends to reduce the classification accuracy of minority-class regions. An effective way to address this is to tune the loss function, particularly when Cross Entropy (CE), is used for classification. Although several CE variants have been reported in previous studies to address this problem, for example, Weighted Cross Entropy (WCE), Dual Cross Entropy (DCE), and Focal Loss (FL), each has their own limitations, such as introducing a vanishing gradient, penalizing negative classes inversely, or a sub-optimal loss weighting between classes. This limits their ability to improve classification accuracy or reduces their ease of use. Focal Loss has proven to be effective at balancing loss by increasing the loss on hard-to-classify classes. However, it tends to produce a vanishing gradient during backpropagation . To address these limitations, a Dual Focal Loss (DFL) function is proposed to improve the classification accuracy of the unbalanced classes in a dataset. The proposed loss function modifies the loss scaling method of FL to be effective against a vanishing gradient. In addition, inspired by DCE, a regularization term has also been added to DFL to constrain the negative class labels to further reduce the vanishing gradient effect and increase the loss on hard-to-classify classes. Experimental results show that DFL has better training performance, and provides greater accuracy compared to CE, WCE, FL and DCE in every test run conducted over a variety of different network models and datasets.},
  archive      = {J_NEUCOM},
  author       = {Md Sazzad Hossain and John M. Betts and Andrew P. Paplinski},
  doi          = {10.1016/j.neucom.2021.07.055},
  journal      = {Neurocomputing},
  pages        = {69-87},
  shortjournal = {Neurocomputing},
  title        = {Dual focal loss to address class imbalance in semantic segmentation},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video saliency prediction via spatio-temporal reasoning.
<em>NEUCOM</em>, <em>462</em>, 59–68. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video saliency detection often suffers from two issues: hard to disentangle the temporal motion patterns and spatial layout patterns, and hard to capture the temporal motion patterns. Thus a novel deep learning network architecture is proposed for video saliency in this paper. The proposed network consists of three parts: high-level representation module, attention module, and memory and reasoning module. The high-level representation module and attention module are used for capturing spatial saliency that is mainly learned from static images. The memory and reasoning module is used to infer the saliency from the information about spatial layout in frames and temporal motion between frames. Because high-level representation module and attention module could concentrate on high-level representation of spatial patterns, and the memory and reasoning module could concentrate on spatial and temporal saliency reasoning, the temporal patterns and spatial patterns could be disentangled efficiently. The quantitative and qualitative results show the proposed method achieves a promising results across a wide of metrics.},
  archive      = {J_NEUCOM},
  author       = {Jiazhong Chen and Zongyi Li and Yi Jin and Dakai Ren and Hefei Ling},
  doi          = {10.1016/j.neucom.2021.07.088},
  journal      = {Neurocomputing},
  pages        = {59-68},
  shortjournal = {Neurocomputing},
  title        = {Video saliency prediction via spatio-temporal reasoning},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). GeneCGAN: A conditional generative adversarial network
based on genetic tree for point cloud reconstruction. <em>NEUCOM</em>,
<em>462</em>, 46–58. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an end-to-end conditional generative adversarial model for 3D point clouds reconstruction, called GeneCGAN. Recently, utilizing deep neural networks to generate 3D data has attracted increasing attention in the research community. Generative models of point clouds are used extensively for many tasks ranging from upsampling to shape completion or reconstruction. Our work addresses 3D reconstruction from a latent representation, generating a particular output corresponding to the ground truth point cloud. It is well known that graph convolutional networks (GCNs) require a tremendous amount of computational complexity to compute the graph connectivity dynamically. To reduce this, a simulated genetic (SG) layer is introduced in the generator of the GeneCGAN from a heredity perspective. It performs within a hierarchical rooted tree by leveraging ancestor information and neighbor relationships. Moreover, with a prior fusing operation, global features regarded as the conditional information are added to the root node in a hierarchical rooted tree for learning a conditional probability distribution of the input datasets. It leads to a controllable point cloud output. Experimental results reveal the important fact that the proposed method can achieve a better performance than other existing methods listed in the literature.},
  archive      = {J_NEUCOM},
  author       = {Chuanchuan Chen and Dongrui Liu and Changqing Xu and Trieu-Kien Truong},
  doi          = {10.1016/j.neucom.2021.07.087},
  journal      = {Neurocomputing},
  pages        = {46-58},
  shortjournal = {Neurocomputing},
  title        = {GeneCGAN: A conditional generative adversarial network based on genetic tree for point cloud reconstruction},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intelligent adaptive learning and control for discrete-time
nonlinear uncertain systems in multiple environments. <em>NEUCOM</em>,
<em>462</em>, 31–45. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on an adaptive learning and control problem for a class of discrete-time nonlinear uncertain systems operating under multiple environments. A novel intelligent learning control framework is proposed by using a combination of offline and online learning methods. Specifically, in the offline learning mode, a deterministic learning (DL) based adaptive dynamics learning approach is first proposed to achieve locally-accurate identification of associated nonlinear uncertain system dynamics under each anticipated individual environment, and the learned knowledge is obtained and stored in a set of constant radial basis function neural network models. Then, with the learned knowledge, an online adaptive learning control scheme is further developed, which consists of: (i) an online adaptive learning control mechanism composed of multiple experience-based controllers and a DL-based adaptive learning controller, aiming to provide desired control performance for the plant operating under each individual environment; and (ii) a learning-based recognition mechanism composed of multiple recognition estimators and a DL-based identifier, aiming to recognize the active environment and schedule appropriate control strategies in real time. To guarantee the system stability during environment transition, a robust quasi-sliding-mode controller is further developed and embedded in the overall controller architecture. With this new intelligent adaptive learning control framework, the overall system is capable of adapting not only to any anticipated (pre-defined) environment by re-utilizing the knowledge obtained from both offline and online learning, but also to unanticipated (new) environments by actively acquiring new knowledge online. Simulation studies are conducted to verify the effectiveness and advantages of this new framework.},
  archive      = {J_NEUCOM},
  author       = {Jingting Zhang and Chengzhi Yuan and Cong Wang and Wei Zeng and Shi-Lu Dai},
  doi          = {10.1016/j.neucom.2021.07.046},
  journal      = {Neurocomputing},
  pages        = {31-45},
  shortjournal = {Neurocomputing},
  title        = {Intelligent adaptive learning and control for discrete-time nonlinear uncertain systems in multiple environments},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). FMRI-SI-STBF: An fMRI-informed bayesian electromagnetic
spatio-temporal extended source imaging. <em>NEUCOM</em>, <em>462</em>,
14–30. (<a href="https://doi.org/10.1016/j.neucom.2021.06.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal functional neuroimaging by integrating functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) has the promise of recovering brain activities with high spatiotemporal resolution, which is crucial for neuroscience research and clinical diagnosis. However, the misalignment of the localizations between fMRI and EEG activities may degrade the accuracy of the fMRI-constrained EEG source imaging (ESI) technique. To leverage the complementary spatiotemporal resolution of fMRI and EEG in a data-driven fashion, we propose an asymmetric approach for EEG/fMRI fusion, termed fMRI-informed source imaging based on spatiotemporal basis functions (fMRI-SI-STBF). fMRI-SI-STBF employs the covariance components (CCs) derived from clusters defined by fMRI and EEG signals as spatial priors within the empirical Bayesian framework . Additionally, fMRI-SI-STBF represents the current source matrix as a linear combination of several unknown temporal basis functions (TBFs) by matrix decomposition . The relative contribution of each of the fMRI-informed and EEG-informed CCs, as well as the number and profiles of the TBFs, are all automatically determined based on the EEG data using variational Bayesian inference. Our results demonstrate that fMRI-SI-STBF can effectively utilize valid fMRI information for ESI and is robust to invalid fMRI priors. This robustness is essential for practical ESI since the validity of fMRI priors is often unclear considering that fMRI is an indirect measure of neural activity. Moreover, fMRI-SI-STBF can achieve performance improvement by incorporating temporal constraints compared to methods that use spatial constraints only. For the numerical simulations, fMRI-SI-STBF reconstructs the source extents, locations and time courses more accurately than existing EEG-fMRI ESI methods (i.e., fwMNE, fMRI-SI-SBF) and ESI methods without fMRI priors (i.e., wMNE, LORETA, SBL , SI-STBF, SI-SBF), indicated by the smaller spatial dispersion (average SD &amp;lt;5 mm), distance of localization error (average DLE &amp;lt;2 mm), shape error (average SE &amp;lt;0.9 ) and larger model evidence values.},
  archive      = {J_NEUCOM},
  author       = {Ke Liu and Zhu Liang Yu and Wei Wu and Xun Chen and Zhenghui Gu and Cuntai Guan},
  doi          = {10.1016/j.neucom.2021.06.066},
  journal      = {Neurocomputing},
  pages        = {14-30},
  shortjournal = {Neurocomputing},
  title        = {FMRI-SI-STBF: An fMRI-informed bayesian electromagnetic spatio-temporal extended source imaging},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging graph neural networks for point-of-interest
recommendations. <em>NEUCOM</em>, <em>462</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-of-Interest (POI) recommendation, i.e., suggesting POIs that a user is likely to visit, is a key task to improve user experience in location based social networks (LBSNs). Existing models either focus on geographical influence without considering other factors such as social influence and temporal influence or rely on linear methods to combine different modeling factors, lacking a sophisticated and systematical way to learn representations for users and POIs for recommendation. To remedy these issues, in this work we propose GNN-POI, a generic POI recommendation framework that leverages Graph Neural Networks (GNNs), which demonstrate powerful modeling capacity to learn node representations from node information and topological structure to improve POI recommendation. Specifically, we construct a LBSN graph comprising of two types of nodes, i.e., user node and POI node. For a target user, her preference representation is learned by combining (1) representations of her social connection nodes and (2) representations of the visited POI nodes. For social connection nodes integration, in order to model the complicated and multifaceted social influence, an attention mechanism is applied to learn strengths of heterogeneous social relations; for location nodes integration, we utilize Bi-directional Long Short-Term Memory (Bi-LSTM) to model users’ sequential check-in behavior , taking into account geographical and temporal features. Extensive experiments conducted over three real LBSN datasets show that the proposed GNN based framework significantly outperforms the state-of-the-art POI recommendation models in terms of precision, recall and Normalized Discounted Cumulative Gain (NDCG).},
  archive      = {J_NEUCOM},
  author       = {Jiyong Zhang and Xin Liu and Xiaofei Zhou and Xiaowen Chu},
  doi          = {10.1016/j.neucom.2021.07.063},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Leveraging graph neural networks for point-of-interest recommendations},
  volume       = {462},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Small variation in dynamic functional connectivity in
cerebellar networks. <em>NEUCOM</em>, <em>461</em>, 751–761. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain networks can be defined and explored through their connectivity. Here, we analyzed the relationship between structural connectivity (SC) across 2,514 regions that cover the entire brain and brainstem , and their dynamic functional connectivity (DFC). To do so, we focused on a combination of two metrics: the first assesses the degree of SC-DFC similarity -i.e. the extent to which the dynamic functional correlations can be explained by structural pathways-; and the second is the intrinsic variability of the DFC networks over time. Overall, we found that cerebellar networks have a smaller DFC variability than other networks in the brain. Moreover, the internal structure of the cerebellum could be clearly divided in two distinct posterior and anterior parts, the latter also connected to the brainstem . The mechanism to maintain small variability of the DFC in the posterior part of the cerebellum is consistent with another of our findings, namely, that this structure exhibits the highest SC-DFC similarity relative to the other networks studied, i.e. structure constrains the variation in dynamics. By contrast, the anterior part of the cerebellum also exhibits small DFC variability but it has the lowest SC-DFC similarity, suggesting a different mechanism is at play. Because this structure connects to the brainstem, which regulates sleep cycles, cardiac and respiratory functioning, we suggest that such critical functionality drives the low variability in the DFC. Overall, the low variability detected in DFC expands our current knowledge of cerebellar networks, which are extremely rich and complex, participating in a wide range of cognitive functions, from movement control and coordination to executive function or emotional regulation. Moreover, the association between such low variability and structure suggests that differentiated computational principles can be applied in the cerebellum as opposed to other structures, such as the cerebral cortex .},
  archive      = {J_NEUCOM},
  author       = {Izaro Fernandez-Iriondo and Antonio Jimenez-Marin and Ibai Diez and Paolo Bonifazi and Stephan P. Swinnen and Miguel A. Muñoz and Jesus M. Cortes},
  doi          = {10.1016/j.neucom.2020.09.092},
  journal      = {Neurocomputing},
  pages        = {751-761},
  shortjournal = {Neurocomputing},
  title        = {Small variation in dynamic functional connectivity in cerebellar networks},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Persistence of hierarchical network organization and
emergent topologies in models of functional connectivity.
<em>NEUCOM</em>, <em>461</em>, 743–750. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Functional networks provide a topological description of activity patterns in the brain, as they stem from the propagation of neural activity on the underlying anatomical or structural network of synaptic connections. This latter is well known to be organized in hierarchical and modular way. While it is assumed that structural networks shape their functional counterparts, it is also hypothesized that alterations of brain dynamics come with transformations of functional connectivity . In this computational study, we introduce a novel methodology to monitor the persistence and breakdown of hierarchical order in functional networks, generated from computational models of activity spreading on both synthetic and real structural connectomes. We show that hierarchical connectivity appears in functional networks in a persistent way if the dynamics is set to be in the quasi-critical regime associated with optimal processing capabilities and normal brain function, while it breaks down in other (supercritical) dynamical regimes, often associated with pathological conditions . Our results offer important clues for the study of optimal neurocomputing architectures and processes, which are capable of controlling patterns of activity and information flow. We conclude that functional connectivity patterns achieve optimal balance between local specialized processing (i.e. segregation) and global integration by inheriting the hierarchical organization of the underlying structural architecture.},
  archive      = {J_NEUCOM},
  author       = {Ali Safari and Paolo Moretti and Ibai Diez and Jesus M. Cortes and Miguel A. Muñoz},
  doi          = {10.1016/j.neucom.2021.02.096},
  journal      = {Neurocomputing},
  pages        = {743-750},
  shortjournal = {Neurocomputing},
  title        = {Persistence of hierarchical network organization and emergent topologies in models of functional connectivity},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emergent population activity in metric-free and metric
networks of neurons with stochastic spontaneous spikes and dynamic
synapses. <em>NEUCOM</em>, <em>461</em>, 727–742. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that networks of excitatory neurons with stochastic spontaneous spiking activity and short-term synaptic plasticity can exhibit spontaneous repetitive synchronization in so-called population spikes. The major reason for this is that synaptic plasticity nonlinearly modulates the interaction between neurons. For large-scale two-dimensional networks, where the connection probability decreases exponentially with increasing distance between the neurons resulting in a small-world network connectome, a population spike occurs in the form of circular traveling waves diverging from seemingly non-stationary nucleation sites. The latter is in drastic contrast to the case of networks with a fixed fraction of steady pacemaker neurons, where the set of a few spontaneously formed nucleation sites is stationary. Despite the spatial non-stationarity of their nucleation, population spikes may occur surprisingly regularly. From a theoretical viewpoint, these findings show that the regime of nearly-periodic population spikes, which mimics respiratory rhythm, can occur strictly without stochastic resonance . In addition, the observed spatiotemporal effects serve as an example of transient chimera patterns.},
  archive      = {J_NEUCOM},
  author       = {Dmitrii Zendrikov and Alexander Paraskevov},
  doi          = {10.1016/j.neucom.2020.11.073},
  journal      = {Neurocomputing},
  pages        = {727-742},
  shortjournal = {Neurocomputing},
  title        = {Emergent population activity in metric-free and metric networks of neurons with stochastic spontaneous spikes and dynamic synapses},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emergence of synchronised and amplified oscillations in
neuromorphic networks with long-range interactions. <em>NEUCOM</em>,
<em>461</em>, 716–726. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.162">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuromorphic networks can be described in terms of coarse-grained variables, where emergent sustained behaviours spontaneously arise if stochasticity is properly taken into account. For example it has been recently found that a directed linear chain of connected patch of neurons amplifies an input signal, also tuning its characteristic frequency. Here we study a generalization of such a simple model, introducing heterogeneity and variability in the parameter space and long-range interactions, breaking, in turn, the preferential direction of information transmission of a directed chain. On one hand, enlarging the region of parameters leads to a more complex state space that we analytically characterise; moreover, we explicitly link the strength distribution of the non-local interactions with the frequency distribution of the network oscillations. On the other hand, we found that adding long-range interactions can cause the onset of novel phenomena, as coherent and synchronous oscillations among all the interacting units, which can also coexist with the amplification of the signal.},
  archive      = {J_NEUCOM},
  author       = {I. Apicella and D.M. Busiello and S. Scarpetta and S. Suweis},
  doi          = {10.1016/j.neucom.2020.04.162},
  journal      = {Neurocomputing},
  pages        = {716-726},
  shortjournal = {Neurocomputing},
  title        = {Emergence of synchronised and amplified oscillations in neuromorphic networks with long-range interactions},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unveiling the role of plasticity rules in reservoir
computing. <em>NEUCOM</em>, <em>461</em>, 705–715. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reservoir Computing (RC) is an appealing approach in Machine Learning that combines the high computational capabilities of Recurrent Neural Networks with a fast and easy training method. Likewise, successful implementation of neuro-inspired plasticity rules into RC artificial networks has boosted the performance of the original models. In this manuscript, we analyze the role that plasticity rules play on the changes that lead to a better performance of RC. To this end, we implement synaptic and non-synaptic plasticity rules in a paradigmatic example of RC model: the Echo State Network . Testing on nonlinear time series prediction tasks, we show evidence that improved performance in all plastic models are linked to a decrease of the pair-wise correlations in the reservoir, as well as a significant increase of individual neurons ability to separate similar inputs in their activity space. Here we provide new insights on this observed improvement through the study of different stages on the plastic learning. From the perspective of the reservoir dynamics, optimal performance is found to occur close to the so-called edge of instability. Our results also show that it is possible to combine different forms of plasticity (namely synaptic and non-synaptic rules) to further improve the performance on prediction tasks, obtaining better results than those achieved with single-plasticity models.},
  archive      = {J_NEUCOM},
  author       = {Guillermo B. Morales and Claudio R. Mirasso and Miguel C. Soriano},
  doi          = {10.1016/j.neucom.2020.05.127},
  journal      = {Neurocomputing},
  pages        = {705-715},
  shortjournal = {Neurocomputing},
  title        = {Unveiling the role of plasticity rules in reservoir computing},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of noise on the synchronization dynamics of the
kuramoto model on a large human connectome graph. <em>NEUCOM</em>,
<em>461</em>, 696–704. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.161">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We have extended the study of the Kuramoto model with additive Gaussian noise running on the KKI-18 large human connectome graph. We determined the dynamical behavior of this model by solving it numerically in an assumed homeostatic state, below the synchronization crossover point we determined previously. The de-synchronization duration distributions exhibit power-law tails, characterized by the exponent in the range 1.1 1.1&amp;lt;τt&amp;lt;2 , overlapping the in vivo human brain activity experiments by Palva et al. We show that these scaling results remain valid, by a transformation of the ultra-slow eigen-frequencies to Gaussian with unit variance. We also compare the connectome results with those, obtained on a regular cube with N = 10 6 N=106 nodes, related to the embedding space, and show that the quenched internal frequencies themselves can cause frustrated synchronization scaling in an extended coupling space.},
  archive      = {J_NEUCOM},
  author       = {Géza Ódor and Jeffrey Kelling and Gustavo Deco},
  doi          = {10.1016/j.neucom.2020.04.161},
  journal      = {Neurocomputing},
  pages        = {696-704},
  shortjournal = {Neurocomputing},
  title        = {The effect of noise on the synchronization dynamics of the kuramoto model on a large human connectome graph},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Routes to tripod gait movement in hexapods. <em>NEUCOM</em>,
<em>461</em>, 679–695. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of hierarchical networks in motor pattern generation in hexapod robots and in insect movement provides ways to understand and control both systems. In this paper we consider the Central Pattern Generator (CPG) of insect movement consisting of six coupled neurons developed by Ghigliazza and Holmes (2004) that produces the global leg coordination pattern. We provide a detailed study of the possible gaits generated by the CPG through different numerical techniques recently developed for the study of small networks, which allow us to consider the complete model without any simplification. We combine the analysis of isolated neurons (using several three dimensional parameter spaces) to give a roadmap of the dynamics of the neurons involved, lateral phase lag plots to show the convergence and transitions towards particular patterns and a quasi-Monte Carlo sweeping method to describe different pattern routes in the parametric phase space. In all of our studies we have found the same final result: most of the observed patterns follow routes that lead to the stable tripod gait. We obtain several routes made of symmetrical patterns, but despite considering mainly a symmetric leg CPG we detect non-symmetrical patterns that provide (minor) routes present in the model. The bifurcations of the main pattern routes detected in the parameter space are studied in detail using continuation techniques. This study reveals the bifurcations that create and destroy the different routes and how for large values of some parameters only the tripod gait is present. Based on the symmetric case, a preliminary study of asymmetric configurations is done revealing the robustness of the already located patterns and routes. Due to the relevance of the tripod gait, and since more parameters are included in this study, we introduce an algorithm to locate the limit of the tripod gait in the parameter space, which shows that there is a large three parametric region where the tripod pattern is ubiquitous and highly dominant in rapidly moving insect regimes.},
  archive      = {J_NEUCOM},
  author       = {R. Barrio and Á. Lozano and M.A. Martínez and M. Rodríguez and S. Serrano},
  doi          = {10.1016/j.neucom.2020.06.151},
  journal      = {Neurocomputing},
  pages        = {679-695},
  shortjournal = {Neurocomputing},
  title        = {Routes to tripod gait movement in hexapods},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Characterization of interval variability in the sequential
activity of a central pattern generator model. <em>NEUCOM</em>,
<em>461</em>, 667–678. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Central pattern generators (CPG) are neural circuits that generate robust sequences of coordinated neural activity to control motor rhythms. We have recently revealed the presence of dynamical invariants in the relationships between specific intervals that build the CPG sequence and the instantaneous period of the rhythm in the pyloric CPG of crustacean. In this paper, we analyze the variability of the intervals comprising the rhythm in a model of a mollusk feeding CPG. We measured the cycle-by-cycle time intervals of the CPG rhythm under distinct single neuron stimulation. We characterized interval variability and report dynamical invariants found only for specific time intervals building the sequence of the feeding CPG. Together with our previous findings, the results reported in this paper indicate that dynamical invariants can be a universal feature of any sequence generating circuit.},
  archive      = {J_NEUCOM},
  author       = {Alicia Garrido-Peña and Irene Elices and Pablo Varona},
  doi          = {10.1016/j.neucom.2020.08.093},
  journal      = {Neurocomputing},
  pages        = {667-678},
  shortjournal = {Neurocomputing},
  title        = {Characterization of interval variability in the sequential activity of a central pattern generator model},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long-range temporal correlations in the broadband resting
state activity of the human brain revealed by neuronal avalanches.
<em>NEUCOM</em>, <em>461</em>, 657–666. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Resting-state brain activity is characterized by the presence of neuronal avalanches showing absence of characteristic size. Such evidence has been interpreted in the context of criticality and associated with the normal functioning of the brain. A distinctive attribute of systems at criticality is the presence of long-range correlations. Thus, to verify the hypothesis that the brain operates close to a critical point and consequently assess deviations from criticality for diagnostic purposes , it is of primary importance to robustly and reliably characterize correlations in resting-state brain activity. Recent works focused on the analysis of narrow-band electroencephalography (EEG) and magnetoencephalography (MEG) signal amplitude envelope, showing evidence of long-range temporal correlations (LRTC) in neural oscillations . However, brain activity is a broadband phenomenon, and a significant piece of information useful to precisely discriminate between normal (critical) and pathological behavior (non-critical), may be encoded in the broadband spatio-temporal cortical dynamics. Here we propose to characterize the temporal correlations in the broadband brain activity through the lens of neuronal avalanches. To this end, we consider resting-state EEG and long-term MEG recordings, extract the corresponding neuronal avalanche sequences, and study their temporal correlations. We demonstrate that the broadband resting-state brain activity consistently exhibits long-range power-law correlations in both EEG and MEG recordings, with similar values of the scaling exponents . Importantly, although we observe that the avalanche size distribution depends on scale parameters, scaling exponents characterizing long-range correlations are quite robust. In particular, they are independent of the temporal binning (scale of analysis), indicating that our analysis captures intrinsic characteristics of the underlying dynamics. Because neuronal avalanches constitute a fundamental feature of neural systems with universal characteristics, the proposed approach may serve as a general, systems- and experiment-independent procedure to infer the existence of underlying long-range correlations in extended neural systems, and identify pathological behaviors in the complex spatio-temporal interplay of cortical rhythms.},
  archive      = {J_NEUCOM},
  author       = {Fabrizio Lombardi and Oren Shriki and Hans J. Herrmann and Lucilla de Arcangelis},
  doi          = {10.1016/j.neucom.2020.05.126},
  journal      = {Neurocomputing},
  pages        = {657-666},
  shortjournal = {Neurocomputing},
  title        = {Long-range temporal correlations in the broadband resting state activity of the human brain revealed by neuronal avalanches},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning continuous-time working memory tasks with on-policy
neural reinforcement learning. <em>NEUCOM</em>, <em>461</em>, 635–656.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An animals’ ability to learn how to make decisions based on sensory evidence is often well described by Reinforcement Learning (RL) frameworks. These frameworks, however, typically apply to event-based representations and lack the explicit and fine-grained notion of time needed to study psychophysically relevant measures like reaction times and psychometric curves. Here, we develop and use a biologically plausible continuous-time RL scheme of CT-AuGMEnT (Continuous-Time Attention-Gated MEmory Tagging) to study these behavioural quantities. We show how CT-AuGMEnT implements on-policy SARSA learning as a biologically plausible form of reinforcement learning with working memory units using ‘attentional’ feedback. We show that the CT-AuGMEnT model efficiently learns tasks in continuous time and can learn to accumulate relevant evidence through time. This allows the model to link task difficulty to psychophysical measurements such as accuracy and reaction-times. We further show how the implementation of a separate accessory network for feedback allows the model to learn continuously, also in case of significant transmission delays between the network’s feedforward and feedback layers and even when the accessory network is randomly initialized. Our results demonstrate that CT-AuGMEnT represents a fully time-continuous biologically plausible end-to-end RL model for learning to integrate evidence and make decisions.},
  archive      = {J_NEUCOM},
  author       = {Davide Zambrano and Pieter R. Roelfsema and Sander Bohte},
  doi          = {10.1016/j.neucom.2020.11.072},
  journal      = {Neurocomputing},
  pages        = {635-656},
  shortjournal = {Neurocomputing},
  title        = {Learning continuous-time working memory tasks with on-policy neural reinforcement learning},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on emergent effects in stochastic neural
networks with application to learning and information processing.
<em>NEUCOM</em>, <em>461</em>, 632–634. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Joaquín J. Torres and Miguel A. Muñoz and Jesús M. Cortés and Jorge F. Mejías},
  doi          = {10.1016/j.neucom.2021.02.097},
  journal      = {Neurocomputing},
  pages        = {632-634},
  shortjournal = {Neurocomputing},
  title        = {Special issue on emergent effects in stochastic neural networks with application to learning and information processing},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification of drug-target interactions via multi-view
graph regularized link propagation model. <em>NEUCOM</em>, <em>461</em>,
618–631. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diseases are usually caused by body’s own defects protein or the functional structure of viral proteins . Effective drugs can be combined with these proteins well and remove original functions to achieve the therapeutic effect. The biochemical approaches of drug-target interactions (DTIs) determination is expensive and time-consuming. Therefnal-based methods have been proposed to predict new DTIs. In order to solve the problem of multiple information fusion, we propose a multi-view graph regularized link propagation model (MvGRLP) to predict new DTIs. Multi-view learning could use the complementary and correlated information between different views (features). Compared with existing models, our method achieves comparable and best results on four benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Yijie Ding and Jijun Tang and Fei Guo},
  doi          = {10.1016/j.neucom.2021.05.100},
  journal      = {Neurocomputing},
  pages        = {618-631},
  shortjournal = {Neurocomputing},
  title        = {Identification of drug-target interactions via multi-view graph regularized link propagation model},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DSKRL: A dissimilarity-support-aware knowledge
representation learning framework on noisy knowledge graph.
<em>NEUCOM</em>, <em>461</em>, 608–617. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graphs are widely used in a variety of knowledge-driven applications. Due to the inefficiency of manual construction of knowledge graphs, automatic construction mechanism has become the dominant method, which introduces noise. However, most knowledge representation learning approaches assume that there is no noise in the knowledge graph and hence ignore noise detection. In this paper, we propose a dissimilarity-support-aware knowledge representation learning framework, which accomplishes knowledge representation learning and noise detection simultaneously. Specifically, we introduce triple dissimilarity and triple support to construct the model energy function which is based on translation-based methods. The triple dissimilarity measures the matching extent of entities and relations in triples and the triple support measures the credibility of the matching extent. In order to make triple dissimilarity and triple support estimation effective and comprehensive, we synthesize structural information and auxiliary information (entity hierarchical type and relation path information) in triple dissimilarity and triple support. We conduct experiments on three datasets for the knowledge graph noise detection task and the knowledge graph completion task. The experimental results show that our model achieves significant and consistent improvements compared to all baseline methods .},
  archive      = {J_NEUCOM},
  author       = {Tianyang Shao and Xinyi Li and Xiang Zhao and Hao Xu and Weidong Xiao},
  doi          = {10.1016/j.neucom.2021.02.099},
  journal      = {Neurocomputing},
  pages        = {608-617},
  shortjournal = {Neurocomputing},
  title        = {DSKRL: A dissimilarity-support-aware knowledge representation learning framework on noisy knowledge graph},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-modal entity alignment in hyperbolic space.
<em>NEUCOM</em>, <em>461</em>, 598–607. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many AI-related tasks involve the interactions of data in multiple modalities. It has been a new trend to merge multi-modal information into knowledge graph (KG), resulting in multi-modal knowledge graphs (MMKG). However, MMKGs usually suffer from low coverage and incompleteness. To mitigate this problem, a viable approach is to integrate complementary knowledge from other MMKGs. To this end, although existing entity alignment approaches could be adopted, they operate in the Euclidean space, and the resulting Euclidean entity representations can lead to large distortion of KG’s hierarchical structure. Besides, the visual information has yet not been well exploited. In response to these issues, in this work, we propose a novel multi-modal entity alignment approach, Hyperbolic multi-modal entity alignment ( HMEA ), which extends the Euclidean representation to hyperboloid manifold. We first adopt the Hyperbolic Graph Convolutional Networks ( HGCNs ) to learn structural representations of entities. Regarding the visual information, we generate image embeddings using the densenet model, which are also projected into the hyperbolic space using HGCNs . Finally, we combine the structure and visual representations in the hyperbolic space and use the aggregated embeddings to predict potential alignment results. Extensive experiments and ablation studies demonstrate the effectiveness of our proposed model and its components.},
  archive      = {J_NEUCOM},
  author       = {Hao Guo and Jiuyang Tang and Weixin Zeng and Xiang Zhao and Li Liu},
  doi          = {10.1016/j.neucom.2021.03.132},
  journal      = {Neurocomputing},
  pages        = {598-607},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal entity alignment in hyperbolic space},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A subgraph-based knowledge reasoning method for collective
fraud detection in e-commerce. <em>NEUCOM</em>, <em>461</em>, 587–597.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud detection is essential for e-commerce platforms to maintain a fair business environment. Many existing works propose manually designed methods such as label propagation and dense block mining rules on built user-item graphs to detect fraud behaviours , but they are always heuristic and thus have limited performance. Other learning-based methods can either handle only the fraud detection problem well in the transductive scenario when there is only structural information or require rich content features to obtain a good inductive ability. Considering that content features are not always available in practice and there are usually many fraudulent behaviours that belong to newly emerging users and items, how to learn effective inductive rules with structures only is still underexplored. In this paper, we propose a subgraph-based method named SubGNN for collective fraud detection. In SubGNN, first, we extract the subgraphs around the given edges (user behaviours) to be tested. Then, we remove nodes’ global IDs so that SubGNN is entity-independent. Finally, by learning knowledge reasoning rules on extracted heterogeneous subgraphs using our proposed relational graph isomorphism network (R-GIN), a powerful graph neural network (GNN) model, SubGNN can achieve precise fraud detection. Experiments are conducted on publicly available Amazon and Yelp datasets and a newly collected Taobao dataset. The results clearly show the advantages and prospects of our method. When using SubGNN to detect fraudulent transactions on Taobao, the precision is higher than 0.99 0.99 and more than 90\% 90\% of fraud samples are recalled.},
  archive      = {J_NEUCOM},
  author       = {Junshuai Song and Xiaoru Qu and Zehong Hu and Zhao Li and Jun Gao and Ji Zhang},
  doi          = {10.1016/j.neucom.2021.03.134},
  journal      = {Neurocomputing},
  pages        = {587-597},
  shortjournal = {Neurocomputing},
  title        = {A subgraph-based knowledge reasoning method for collective fraud detection in E-commerce},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Target relational attention-oriented knowledge graph
reasoning. <em>NEUCOM</em>, <em>461</em>, 577–586. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In knowledge graph reasoning, the existing graph attention mechanisms tend to distribute attention to certain high-frequency relations. In this work, we design a target relational attention-oriented reasoning model, which focuses more on the relations that match the target relation. We propose a hierarchical ( node-level and relational subgraph-level ) attention mechanism to aggregate the information of multi-hop neighbors, and to thereby obtain a better node-embedding representation, (with high-order propagation characteristics). The mechanism also relieves over-smoothing to a certain extent. Node-level information aggregation uses the classical graph-attention mechanism, and the distribution of attention in the subgraph-level information aggregation is determined according to the relation in the reasoning task. In other words, we must give these relations different attentions according to the reasoning relation in the task. Experiments show that our model significantly outperforms current state-of-the-art methods. We further study the influence of encoder parameters on the model performance; increasing the number of attention-heads , layers, or hidden out-dimensions can effectively improve the performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaojuan Zhao and Yan Jia and Aiping Li and Rong Jiang and Kai Chen and Ye Wang},
  doi          = {10.1016/j.neucom.2021.03.135},
  journal      = {Neurocomputing},
  pages        = {577-586},
  shortjournal = {Neurocomputing},
  title        = {Target relational attention-oriented knowledge graph reasoning},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). PILHNB: Popularity, interests, location used hidden naive
bayesian-based model for link prediction in dynamic social networks.
<em>NEUCOM</em>, <em>461</em>, 562–576. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction aims to predict the missing interactions in evolving networks that may appear in the future. It has practical importance in various real-world applications, ranging from friendship recommendation, knowledge graph completion, target advertising, and protein–protein interaction prediction. Most of the recent efforts focus on the structure of the network while ignoring many other essential factors. In this paper, we present a modified Latent Dirichlet Allocation (LDA), and Hidden Naive Bayesian (HNB) based link prediction technique named PILHNB model for link prediction in dynamic social networks by considering behavioral controlling elements like relationship network structure, nodes’ attributes, location-based information of nodes, nodes’ popularity, users’ interests, and learning the evolution pattern of these factors in the networks. Experimental results on six real-world networks demonstrate our proposed models’ effectiveness and efficiency compared with existing state-of-the-art link prediction techniques.},
  archive      = {J_NEUCOM},
  author       = {Ashwini Kumar Singh and Lakshmanan Kailasam},
  doi          = {10.1016/j.neucom.2021.02.101},
  journal      = {Neurocomputing},
  pages        = {562-576},
  shortjournal = {Neurocomputing},
  title        = {PILHNB: Popularity, interests, location used hidden naive bayesian-based model for link prediction in dynamic social networks},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Distant supervised relation extraction with position
feature attention and selective bag attention. <em>NEUCOM</em>,
<em>461</em>, 552–561. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distant supervision greatly reduces manual consumption by automatically labeling data. The relation extraction methods under distant supervision divide sentences with the same entity pair into a bag, and perform training and testing on these sentence bags. The existing distant supervised relation extraction methods ignore two facts. First, there are many sentences where the target entity pairs appear multiple times. Second, the noise between sentence bags is different, and the sentences of some bags are even all mislabeled. To solve these two problems, we propose a novel relation extraction method with position feature attention and selective bag attention. The position feature attention is employed to obtain the weighted sentence representation with different position features by calculating all position combinations of the target entity pair. A bag with large noise and a bag with small noise are selected through the selective bag attention mechanism to form a bag pair, and training is performed at the level of the bag pair, which denoises at the bag level and at the same time balances the noise between different bag pairs. The experimental results show that our method is effective and outperforms several competitive baseline methods .},
  archive      = {J_NEUCOM},
  author       = {Jiasheng Wang and Qiongxin Liu},
  doi          = {10.1016/j.neucom.2021.04.127},
  journal      = {Neurocomputing},
  pages        = {552-561},
  shortjournal = {Neurocomputing},
  title        = {Distant supervised relation extraction with position feature attention and selective bag attention},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generative adversarial network for single and multi-hop
distributional knowledge base completion. <em>NEUCOM</em>, <em>461</em>,
543–551. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge bases (KBs) inherently lack reasoning ability, limiting their effectiveness for tasks such as question–answering and query expansion . Machine-learning is hence commonly employed for representation learning in order to learn semantic features useful for generalization. Most existing methods utilize discriminative models that require both positive and negative samples to learn a decision boundary. KBs, by contrast, contain only positive samples, necessitating that negative samples are generated by replacing the head/tail of predicates with randomly-chosen entities. They are thus frequently easily discriminable from positive samples, which can prevent learning of sufficiently robust classifiers. Generative models , however, do not require negative samples to learn the distribution of positive samples; stimulated by recent developments in Generative Adversarial Networks (GANs), we propose a novel framework, Knowledge Completion GANs (KCGANs), for competitively training generative link prediction models against discriminative belief prediction models. KCGAN thus invokes a game between generator-network G G and discriminator-network D D in which G G aims to understand underlying KB structure by learning to perform link prediction while D D tries to gain knowledge about the KB by learning predicate/triplet classification. Two key challenges are addressed: 1) Classical GAN architectures’ inability to easily generate samples over discrete entities; 2) the inefficiency of softmax for learning distributions over large sets of entities. As a step toward full first-order logical reasoning we further extend KCGAN to learn multi-hop logical entailment relations between entities by enabling G G to compose a multi-hop relational path between entities and D D to discriminate between real and fake paths. KCGAN is tested on benchmarks WordNet and FreeBase datasets and evaluated on link prediction and belief prediction tasks using MRR and HIT@ 10, achieving best-in-class performance.},
  archive      = {J_NEUCOM},
  author       = {Tehseen Zia and David Windridge},
  doi          = {10.1016/j.neucom.2021.04.128},
  journal      = {Neurocomputing},
  pages        = {543-551},
  shortjournal = {Neurocomputing},
  title        = {A generative adversarial network for single and multi-hop distributional knowledge base completion},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Trans4E: Link prediction on scholarly knowledge graphs.
<em>NEUCOM</em>, <em>461</em>, 530–542. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the quality of AI-based services. In the scholarly domain, KGs describing research publications typically lack important information, hindering our ability to analyse and predict research dynamics. In recent years, link prediction approaches based on Knowledge Graph Embedding models became the first aid for this issue. In this work, we present Trans4E, a novel embedding model that is particularly fit for KGs which include N to M relations with N ≫ ≫ M. This is typical for KGs that categorize a large number of entities (e.g., research articles, patents, persons) according to a relatively small set of categories. Trans4E was applied on two large-scale knowledge graphs, the Academia/Industry DynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the information about Fields of Study (e.g., ‘neural networks’, ‘machine learning’, ‘artificial intelligence’), and affiliation types (e.g., ‘education’, ‘company’, ‘government’), improving the scope and accuracy of the resulting data. We evaluated our approach against alternative solutions on AIDA, MAG, and four other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms the other models when using low embedding dimensions and obtains competitive results in high dimensions.},
  archive      = {J_NEUCOM},
  author       = {Mojtaba Nayyeri and Gokce Muge Cil and Sahar Vahdati and Francesco Osborne and Mahfuzur Rahman and Simone Angioni and Angelo Salatino and Diego Reforgiato Recupero and Nadezhda Vassilyeva and Enrico Motta and Jens Lehmann},
  doi          = {10.1016/j.neucom.2021.02.100},
  journal      = {Neurocomputing},
  pages        = {530-542},
  shortjournal = {Neurocomputing},
  title        = {Trans4E: Link prediction on scholarly knowledge graphs},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning graph attention-aware knowledge graph embedding.
<em>NEUCOM</em>, <em>461</em>, 516–529. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The knowledge graph, which utilizes graph structure to represent multi-relational data, has been widely used in the reasoning and prediction tasks, attracting considerable research efforts recently. However, most existing works still concentrate on learning knowledge graph embeddings straightforwardly and intuitively without subtly considering the context of knowledge. Specifically, recent models deal with each single triple independently or consider contexts indiscriminately, which is one-sided as each knowledge unit (i.e., triple) can be derived from its partial surrounding triples. In this paper, we propose a graph-attention-based model to encode entities, which formulates a knowledge graph as an irregular graph and explores a number of concrete and interpretable knowledge compositions by integrating the graph-structured information via multiple independent channels. To measure the correlation between entities from different angles (i.e., entity pair, relation, and structure), we respectively develop three attention metrics. By making use of our enhanced entity embeddings, we further introduce several improved factorization functions for updating relation embeddings and evaluating candidate triples. We conduct extensive experiments on downstream tasks including entity classification, entity typing, and link prediction to validate our methods. Empirical results validate the importance of our introduced attention metrics and demonstrate that our proposed method can improve the performance of factorization models on large-scale knowledge graphs.},
  archive      = {J_NEUCOM},
  author       = {Chen Li and Xutan Peng and Yuhang Niu and Shanghang Zhang and Hao Peng and Chuan Zhou and Jianxin Li},
  doi          = {10.1016/j.neucom.2021.01.139},
  journal      = {Neurocomputing},
  pages        = {516-529},
  shortjournal = {Neurocomputing},
  title        = {Learning graph attention-aware knowledge graph embedding},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topic analysis and development in knowledge graph research:
A bibliometric review on three decades. <em>NEUCOM</em>, <em>461</em>,
497–515. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph as a research topic is increasingly popular to represent structural relations between entities. Recent years have witnessed the release of various open-source and enterprise-supported knowledge graphs with dramatic growth in applying knowledge representation and reasoning into different areas like natural language processing and computer vision. This study aims to comprehensively explore the status and trends – particularly the thematic research structure – of knowledge graphs. Specifically, based on 386 research articles published from 1991 to 2020, we conducted analyses in terms of the (1) visualization of the trends of annual article and citation counts, (2) recognition of major institutions, countries/regions, and publication sources, (3) visualization of scientific collaborations of major institutions and countries/regions, and (4) detection of major research themes and their developmental tendencies. Interest in knowledge graph research has clearly increased from 1991 to 2020 and is continually expanding. China is the most prolific country in knowledge graph research. Moreover, countries/regions and institutions that have higher levels of international collaboration are more impactful. Several widely studied issues such as knowledge graph embedding , search and query based on knowledge graphs , and knowledge graphs for intangible cultural heritage are highlighted. Based on the results, we further summarize perspective directions and suggestions for researchers, practitioners, and project managers to facilitate future research on knowledge graphs.},
  archive      = {J_NEUCOM},
  author       = {Xieling Chen and Haoran Xie and Zongxi Li and Gary Cheng},
  doi          = {10.1016/j.neucom.2021.02.098},
  journal      = {Neurocomputing},
  pages        = {497-515},
  shortjournal = {Neurocomputing},
  title        = {Topic analysis and development in knowledge graph research: A bibliometric review on three decades},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge graph representation and reasoning.
<em>NEUCOM</em>, <em>461</em>, 494–496. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Erik Cambria and Shaoxiong Ji and Shirui Pan and Philip S. Yu},
  doi          = {10.1016/j.neucom.2021.05.101},
  journal      = {Neurocomputing},
  pages        = {494-496},
  shortjournal = {Neurocomputing},
  title        = {Knowledge graph representation and reasoning},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Content-aware listwise collaborative filtering.
<em>NEUCOM</em>, <em>461</em>, 479–493. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, listwise collaborative filtering (CF) algorithms are attracting increasing interest due to their efficiency and prediction quality. Different from rating-oriented (pointwise) CF, they recommend a preference ranking of items to each user without estimating the absolute value of the ratings. In practice, there are extensive side information about users and items in many corpora that can improve recommendation performance and specially help CF methods to address the cold-start problem. However, a model has not been proposed that incorporates side information to listwise CF. Therefore, in this work, a Bayesian graphical model, called Content-Aware Listwise Collaborative Filtering (CALCF), is developed which incorporates text information, represented as a bag of words, to listwise CF using topic models. We propose a Gibbs sampler with closed-form samples using data augmentation techniques to infer the latent variables. CALCF has been validated by comparison with previous listwise and pointwise algorithms on implicit (click, view, purchase) and explicit (numeric ratings) feedback data in both cold-start and warm-start scenarios. The results demonstrate that in most cases CALCF achieves better Normalized Discounted Cumulative Gain (NDCG) and Recall at top M recommendation compared with the previous models.},
  archive      = {J_NEUCOM},
  author       = {Rabeh Ravanifard and Abdolreza Mirzaei and Wray Buntine and Mehran Safayani},
  doi          = {10.1016/j.neucom.2021.08.076},
  journal      = {Neurocomputing},
  pages        = {479-493},
  shortjournal = {Neurocomputing},
  title        = {Content-aware listwise collaborative filtering},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Multi-pathway feature integration network for salient
object detection. <em>NEUCOM</em>, <em>461</em>, 462–478. (<a
href="https://doi.org/10.1016/j.neucom.2021.08.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saliency detection is a computer vision task that has been studied for a long time. Although the recent methods continuously improve detection accuracy, most of them do not consider the interactions of different feature layers sufficiently, and deep- and shallow-level features are not fused effectively. To combine the advantages of multi-layer features for detection, we propose a novel multi-pathway feature integration network (MFINet) by extracting and fusing information from multiple feature layers. Different from the top-down and bottom-up fusion styles, our proposed feature fusion is divided into two stages and three pathways are finally formed. All three pathways integrate multiple original backbone feature layers, where they integrate features in three different orders. The diversity of feature fusion compensates for the limitations of the top-down and bottom-up fusion approaches, effectively preventing the loss of useful information in the transmission process. In addition, we propose a cross-feature hierarchical fusion module. This module combines the saliency cues in two feature layers adaptively and reduces the representation of redundant information. Therefore, multiple such modules are embedded in the MFINet to enable the network to further learn salient object information accurately. To strengthen the response of boundary information in the salient object information, we also propose a boundary information enhancement strategy. Unlike existing methods that use an independent branch to extract boundary features, we directly capture boundary features from a boundary map. Experimental results on 5 benchmark datasets show that our method achieves better performance in different scenarios, consistently outperforming 12 state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhaojian Yao and Luping Wang},
  doi          = {10.1016/j.neucom.2021.08.082},
  journal      = {Neurocomputing},
  pages        = {462-478},
  shortjournal = {Neurocomputing},
  title        = {Multi-pathway feature integration network for salient object detection},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A semi-supervised semantic-enhanced framework for scientific
literature retrieval. <em>NEUCOM</em>, <em>461</em>, 450–461. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scientific literature retrieval provides convenience for researchers to find scientific literature related to the query. It is an important part of scientific research to search related papers given a paper title as query. However, for scientific literature retrieval tasks, most of the existing retrieval methods do not consider sentence-level semantic matching so that the retrieval performance is limited. With the success of neural networks , neural information retrieval methods have been widely studied and achieved good retrieval results. In this paper, we propose a semi-supervised semantic-enhanced scientific literature retrieval framework. The framework is composed of two networks: a self-attention convolutional encoder-decoder network and a sentence-level attention scientific literature retrieval network. By joint training of the two networks, the proposed semi-supervised semantic-enhanced scientific literature retrieval model can fully capture the rich semantic information of scientific text data and leverages human labeled scientific text data to improve the discriminativeness of the learned semantic representation . The retrieval results on two scientific literature datasets demonstrate that the proposed method significantly and consistently outperforms the other baseline methods .},
  archive      = {J_NEUCOM},
  author       = {Mingying Xu and Junping Du and Zhe Xue and Feifei Kou and Xin Xu},
  doi          = {10.1016/j.neucom.2021.07.081},
  journal      = {Neurocomputing},
  pages        = {450-461},
  shortjournal = {Neurocomputing},
  title        = {A semi-supervised semantic-enhanced framework for scientific literature retrieval},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Path-based reasoning over heterogeneous networks for
recommendation via bidirectional modeling. <em>NEUCOM</em>,
<em>461</em>, 438–449. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous Information Network (HIN) is a natural and general representation of data in recommender systems . Combining HIN and recommender systems can not only help model user behaviors but also make the recommendation results explainable by aligning the users/items with various types of entities in the network. Over the past few years, path-based reasoning models have shown great capacity in HIN-based recommendation. The basic idea of these models is to explore HIN with predefined path schemes. Despite their effectiveness, these models are often confronted with the following limitations: (1) Most prior path-based reasoning models only consider the influence of the predecessors on the subsequent nodes when modeling the sequences, and ignore the reciprocity between the nodes in a path; (2) The weights of nodes in the same path instance are usually assumed to be constant, whereas varied weights of nodes can bring more flexibility and lead to expressive modeling; (3) User-item interactions are noisy, but they are often indiscriminately exploited. To overcome the aforementioned issues, in this paper, we propose a novel path-based reasoning approach for recommendation over HIN. Concretely, we use a bidirectional LSTM to enable the two-way modeling of paths and capture the reciprocity between nodes. Then an attention mechanism is employed to learn the dynamical influence of nodes in different contexts. Finally, the adversarial regularization terms are imposed on the loss function of the model to mitigate the effects of noise and enhance HIN-based recommendation. Extensive experiments conducted on three public datasets show that our model outperforms the state-of-the-art baselines. The case study further demonstrates the feasibility of our model on the explainable recommendation task.},
  archive      = {J_NEUCOM},
  author       = {Junwei Zhang and Min Gao and Junliang Yu and Linda Yang and Zongwei Wang and Qingyu Xiong},
  doi          = {10.1016/j.neucom.2021.07.038},
  journal      = {Neurocomputing},
  pages        = {438-449},
  shortjournal = {Neurocomputing},
  title        = {Path-based reasoning over heterogeneous networks for recommendation via bidirectional modeling},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Differentially private empirical risk minimization for AUC
maximization. <em>NEUCOM</em>, <em>461</em>, 419–437. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Area under the ROC curve (AUC) is a widely used performance measure for imbalanced classification. Oftentimes, the ubiquitous imbalanced data such as financial records from fraud detection or genomic data from cancer diagnosis contains sensitive information , and therefore it is of practical and theoretical importance to develop privacy-preserving AUC maximization algorithms. In this paper, we propose differentially private empirical risk minimization (ERM) for AUC maximization, and systematically study their privacy and utility guarantees. In particular, we establish guarantees on the generalization (utility) performance of the proposed algorithms with fast rates. The technical novelty contains fast rates for the regularized ERM in AUC maximization, which is established using the peeling techniques for Rademacher averages [1] and properties of U-Statistics [2,3] to handle statistically non-independent pairs of examples in the objective function, and a new error decomposition to handle strongly smooth losses (e.g. least square loss). In addition, we revisit the private ERM with pointwise loss [4,5] and show optimal rates can be obtained using the uniform convergence approach.},
  archive      = {J_NEUCOM},
  author       = {Puyu Wang and Zhenhuan Yang and Yunwen Lei and Yiming Ying and Hai Zhang},
  doi          = {10.1016/j.neucom.2021.07.001},
  journal      = {Neurocomputing},
  pages        = {419-437},
  shortjournal = {Neurocomputing},
  title        = {Differentially private empirical risk minimization for AUC maximization},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning sufficient scene representation for unsupervised
cross-modal retrieval. <em>NEUCOM</em>, <em>461</em>, 404–418. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel unsupervised C ross- M odal retrieval method via S ufficient S cene R epresentation (CMSSR) is proposed. Distinguished from the existing methods which mainly focus on simultaneously preserving the mutually-constrained intra- and inter-modal similarity relation, CMSSR considers data of different modalities as the descriptions of a scene from different views and accordingly integrates information of different modalities to learn a complete common representation containing sufficient information of the corresponding scene. To obtain such common representation, Gaussian Mixture Model (GMM) is firstly utilized to generate statistic representation of each uni-modal data, while the uni-modal spaces are accordingly abstracted as uni-modal statistical manifolds. In addition, the common space is assumed to be a high-dimensional statistical manifold with different uni-modal statistical manifolds as its sub-manifolds. In order to generate sufficient scene representation from uni-modal data, a representation completion strategy based on logistic regression is proposed to effectively complete the missing representation of another modality. Then, the similarity between different multi-modal data can be more accurately reflected by the distance metric in common statistical manifold. Based on the distance metric in common statistical manifold, Iterative Quantization is utilized to further generate binary code for fast cross-modal retrieval. Extensive experiments on three standard benchmark datasets fully demonstrate the superiority of CMSSR compared with several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jieting Luo and Yan Wo and Bicheng Wu and Guoqiang Han},
  doi          = {10.1016/j.neucom.2021.07.078},
  journal      = {Neurocomputing},
  pages        = {404-418},
  shortjournal = {Neurocomputing},
  title        = {Learning sufficient scene representation for unsupervised cross-modal retrieval},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pruning and quantization for deep neural network
acceleration: A survey. <em>NEUCOM</em>, <em>461</em>, 370–403. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have been applied in many applications exhibiting extraordinary abilities in the field of computer vision. However, complex network architectures challenge efficient real-time deployment and require significant computation resources and energy costs. These challenges can be overcome through optimizations such as network compression. Network compression can often be realized with little loss of accuracy. In some cases accuracy may even improve. This paper provides a survey on two types of network compression: pruning and quantization. Pruning can be categorized as static if it is performed offline or dynamic if it is performed at run-time. We compare pruning techniques and describe criteria used to remove redundant computations. We discuss trade-offs in element-wise, channel-wise, shape-wise, filter-wise, layer-wise and even network-wise pruning. Quantization reduces computations by reducing the precision of the datatype. Weights, biases, and activations may be quantized typically to 8-bit integers although lower bit width implementations are also discussed including binary neural networks . Both pruning and quantization can be used independently or combined. We compare current techniques, analyze their strengths and weaknesses, present compressed network accuracy results on a number of frameworks, and provide practical guidance for compressing networks.},
  archive      = {J_NEUCOM},
  author       = {Tailin Liang and John Glossner and Lei Wang and Shaobo Shi and Xiaotong Zhang},
  doi          = {10.1016/j.neucom.2021.07.045},
  journal      = {Neurocomputing},
  pages        = {370-403},
  shortjournal = {Neurocomputing},
  title        = {Pruning and quantization for deep neural network acceleration: A survey},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matrix projective synchronization for a class of
discrete-time complex networks with commonality via controlling the
crucial node. <em>NEUCOM</em>, <em>461</em>, 360–369. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes two control strategies to realize matrix projective synchronization (MPS) for a class of discrete-time complex dynamical networks (DTCDNs). It is worth pointing out that our network model is composed of nodes with different state dimensions and its outer coupling configuration matrix can be asymmetric. In addition, since a small percentage of nodes that play more important role than others usually exist in a network, thus, one important node, which is named as crucial node in this paper, is taken into account in our network model. Besides, the commonality between each node and the crucial node is also precisely expressed. Further, based on the crucial node and the commonality and associated with the Lyapunov stability theory , two control strategies are addressed to realize the exponential matrix projective synchronization (EMPS) and asymptotic matrix projective synchronization (AMPS), respectively. It should be stressed that only the crucial node is controlled and only the state of the crucial node is applied to design the EMPS and AMPS controllers. This is promising to reduce the control cost as much as possible and to improve the feasibility of our MPS strategies. The effectiveness and feasibility of our MPS schemes are rigorously proved in theory as well as verified by two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Lili Zhang and Xiaoyun Fu and Yinhe Wang and Youfa Lei and Xuesong Chen},
  doi          = {10.1016/j.neucom.2021.07.069},
  journal      = {Neurocomputing},
  pages        = {360-369},
  shortjournal = {Neurocomputing},
  title        = {Matrix projective synchronization for a class of discrete-time complex networks with commonality via controlling the crucial node},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Separated smooth sampling for fine-grained image
classification. <em>NEUCOM</em>, <em>461</em>, 350–359. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Discovering diverse significant regions ( e.g. , beaks and wings for some bird species) and extracting discriminative features from them is vitally important in fine-grained image recognition. Currently, the attention-based approaches present promising performance, which generally extract the fine-grained features by cropping or sampling significant parts. However, the cropping methods usually suffer from a fixed number of parts and difficulty to highlight irregular regions, and existing sampling methods may produce extremely distorted images. To effectively capture the fine-grained features, we propose an end-to-end separated smooth sampling network (SSSNet) in this paper. Specifically, we propose a separated smooth sampling module to highlight diverse significant regions of an image. Different from previous methods, we adopt smooth sampling on two separated coordinates to process images, which can effectively highlight discriminative contents and meanwhile avoid extreme distortion. We further propose an iterative masking method to embed into SSSNet, which can produce multiple attention maps without overlap to represent different significant regions. We conduct extensive experiments on CUB-200–2011, Stanford-Cars, and FGVC-Aircraft datasets. The results show the effectiveness of separated smooth sampling, and our SSSNet achieves better performance against previous state-of-the-art approaches under the same settings.},
  archive      = {J_NEUCOM},
  author       = {Shenghai Rong and Zilei Wang and Jie Wang},
  doi          = {10.1016/j.neucom.2021.07.067},
  journal      = {Neurocomputing},
  pages        = {350-359},
  shortjournal = {Neurocomputing},
  title        = {Separated smooth sampling for fine-grained image classification},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Contextual similarity-based multi-level second-order
attention network for semi-supervised few-shot learning.
<em>NEUCOM</em>, <em>461</em>, 336–349. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we tackle the few-shot learning problem in a semi-supervised setting where a limited number of labeled data-points and a number of low-cost unlabeled samples are assumed to be available. In particular, some of the unlabeled samples share the same label space with the support set, referring to as known samples, while some of them are from distracter classes, referring to as unknown ones. The keys are how to learn a powerful representation and how to pick and label unlabeled known instances to construct discriminative classifiers. We address both issues by learning multi-level second-order attention representation followed by a contextual similarity. We first develop a novel trainable multi-level second-order attention network(MSAN) to adaptively learn more powerful feature representation by using second-order feature statistics. Our proposed MSAN is able to better represent the samples while the parameter is not increased. Then we introduce a contextual measure that considers not only the pair-wise relationship but also the task-specific condition, to calculate the similarity between unlabeled samples and each support class, thus to label and pick the quasi-known samples. The hypothesis is that the known unlabeled sample should not only be strongly similar to one particular class, but also be significantly dissimilar to other classes. With the combination of support set and pseudo-labeled set, we train an episodic linear classifier for each episode and the parameters of multi-level second-order attention network are updated by minimizing the loss of the query set. Extensive experiments on four popular benchmarks (Omniglot, miniImageNet, tieredImageNet, and CUB-200-2011) demonstrate that our simple yet effective approach can achieve competitive accuracy compared to the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Wenjing Li and Tingting Ren and Fang Li and Jun Zhang and Zhongcheng Wu},
  doi          = {10.1016/j.neucom.2021.07.062},
  journal      = {Neurocomputing},
  pages        = {336-349},
  shortjournal = {Neurocomputing},
  title        = {Contextual similarity-based multi-level second-order attention network for semi-supervised few-shot learning},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ZstGAN: An adversarial approach for unsupervised zero-shot
image-to-image translation. <em>NEUCOM</em>, <em>461</em>, 327–335. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-to-image translation models have shown remarkable ability on transferring images among different domains. Most of existing work follows the setting that the source domain and target domain keep the same at training and inference phases, which cannot be generalized to the scenarios for translating an image from an unseen domain to another unseen domain. In this work, we propose the Unsupervised Zero-Shot Image-to-image Translation (UZSIT) problem, which aims to learn a model that can translate samples from image domains that are not observed during training. Accordingly, we propose a framework called ZstGAN: By introducing an adversarial training scheme, ZstGAN learns to model each domain with domain-specific feature distribution that is semantically consistent on vision and attribute modalities. Then the domain-invariant features are disentangled with an shared encoder for image generation . We carry out extensive experiments on CUB and FLO datasets, and the results demonstrate the effectiveness of proposed method on UZSIT task. Moreover, ZstGAN shows significant accuracy improvements over state-of-the-art zero-shot learning methods on CUB and FLO.},
  archive      = {J_NEUCOM},
  author       = {Jianxin Lin and Yingce Xia and Sen Liu and Shuxin Zhao and Zhibo Chen},
  doi          = {10.1016/j.neucom.2021.07.037},
  journal      = {Neurocomputing},
  pages        = {327-335},
  shortjournal = {Neurocomputing},
  title        = {ZstGAN: An adversarial approach for unsupervised zero-shot image-to-image translation},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving neural network’s performance using bayesian
inference. <em>NEUCOM</em>, <em>461</em>, 319–326. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks can be used as a data-driven model for system identification. But the probability properties of the training data are not included. The Bayesian approach can model the input and output probability distribution, but it cannot give points estimation. In this paper, we propose a special neural model, which combines the neural model and Bayesian inference. The probability distributions of input and output are obtained by the Bayesian approach . This statistical model changes the neural network’s structure and improve the accuracy of the neural modeling. We also propose a neural network training method using Bayesian inference. The approach capabilities are analyzed. We use three examples to compare our method with the other black box methods. The results show that this new model is much better, when there are large noises, and the dynamics of the system is complex.},
  archive      = {J_NEUCOM},
  author       = {Jorge Morales and Wen Yu},
  doi          = {10.1016/j.neucom.2021.07.054},
  journal      = {Neurocomputing},
  pages        = {319-326},
  shortjournal = {Neurocomputing},
  title        = {Improving neural network’s performance using bayesian inference},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-orientation scene text detection with scale-guided
regression. <em>NEUCOM</em>, <em>461</em>, 310–318. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing multi-orientation scene text detection methods generally contain two crucial components: regression prediction for text bounding boxes and classification prediction for text/non-text. However, these methods always regard classification prediction and regression prediction as two independent procedures, neglecting fully exploring their mutual relations. Based on this key observation, we propose an innovative Scale-Guided Regression Module (SRM), specially for multi-orientation scene text detection. Equipped with width-guided kernels and height-guided kernels of different sizes, our SRM can generate a series of scale feature maps of candidate texts by capturing their shape information in classification prediction. The scale feature maps are used to predict the width and height of candidate texts, which can serve as guides for regressing bounding boxes. In this way, the procedures of classification and regression can be coherently integrated. In addition, we adopt IoU loss to train our network and then integrate IoU loss and l 1 l1 -smooth loss for fine-tuning. Extensive experiments on publicly available datasets demonstrate the state-of-the-art performance of our method. Notably, our method achieves significant improvement of performance on long texts, e.g., on MSRA-TD500, our method outperforms Basemodel with a great margin (4.86\%\% in terms of Recall).},
  archive      = {J_NEUCOM},
  author       = {Min Liang and Jie-Bo Hou and Xiaobin Zhu and Chun Yang and Jingyan Qin and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2021.07.026},
  journal      = {Neurocomputing},
  pages        = {310-318},
  shortjournal = {Neurocomputing},
  title        = {Multi-orientation scene text detection with scale-guided regression},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Class distribution-aware adaptive margins and cluster
embedding for classification of fruit and vegetables at supermarket
self-checkouts. <em>NEUCOM</em>, <em>461</em>, 292–309. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex task of vision based fruit and vegetables classification at a supermarket self-checkout poses significant challenges. These challenges include the highly variable physical features of fruit and vegetables i.e. colour, texture shape and size which are dependent upon ripeness and storage conditions in a supermarket as well as general product variation. Supermarket environments are also significantly variable with respect to lighting conditions. Attempting to build an exhaustive dataset to capture all these variations, for example a dataset of a fruit consisting of all possible colour variations, is nearly impossible. Moreover, some fruit and vegetable classes have significant similar physical features e.g. the colour and texture of cabbage and lettuce. Current state-of-the-art classification techniques such as those based on Deep Convolutional Neural Networks (DCNNs) are highly prone to errors resulting from the inter-class similarities and intra-class variations of fruit and vegetable images. The deep features of highly variable classes can invade the features of neighbouring similar classes in a learned feature space of the DCNN, resulting in confused classification hyper-planes. To overcome these limitations of current classification techniques we have proposed a class distribution-aware adaptive margins approach with cluster embedding for classification of fruit and vegetables. We have tested the proposed technique for cluster-based feature embedding and classification effectiveness. It is observed that introduction of adaptive classification margins proportional to the class distribution can achieve significant improvements in clustering and classification effectiveness. The proposed technique is tested for both clustering and classification, and promising results have been obtained.},
  archive      = {J_NEUCOM},
  author       = {Khurram Hameed and Douglas Chai and Alexander Rassau},
  doi          = {10.1016/j.neucom.2021.07.040},
  journal      = {Neurocomputing},
  pages        = {292-309},
  shortjournal = {Neurocomputing},
  title        = {Class distribution-aware adaptive margins and cluster embedding for classification of fruit and vegetables at supermarket self-checkouts},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Investigating the performance of multi-objective
optimization when learning bayesian networks. <em>NEUCOM</em>,
<em>461</em>, 281–291. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Networks have been widely used in the last decades in many fields, to describe statistical dependencies among random variables. In general, learning the structure of such models is a problem with considerable theoretical interest that poses many challenges. On the one hand, it is a well-known NP-complete problem, practically hardened by the huge search space of possible solutions. On the other hand, the phenomenon of I-equivalence, i.e., different graphical structures underpinning the same set of statistical dependencies, may lead to multimodal fitness landscapes further hindering maximum likelihood approaches to solve the task. Despite all these difficulties, greedy search methods based on a likelihood score coupled with a regularizator score to account for model complexity, have been shown to be surprisingly effective in practice. In this paper, we consider the formulation of the task of learning the structure of Bayesian Networks as an optimization problem based on a likelihood score, without complexity terms to regularize it. In particular, we exploit the NSGA-II multi-objective optimization procedure in order to explicitly account for both the likelihood of a solution and the number of selected arcs, by setting these as the two objective functions of the method. The aim of this work is to investigate the behavior of NSGA-II and analyse the quality of its solutions. We thus thoroughly examined the optimization results obtained on a wide set of simulated data, by considering both the goodness of the inferred solutions in terms of the objective functions values achieved, and by comparing the retrieved structures with the ground truth, i.e., the networks used to generate the target data. Our results show that NSGA-II can converge to solutions characterized by better likelihood and less arcs than classic approaches, although paradoxically characterized in many cases by a lower similarity with the target network.},
  archive      = {J_NEUCOM},
  author       = {Marco S. Nobile and Paolo Cazzaniga and Daniele Ramazzotti},
  doi          = {10.1016/j.neucom.2021.07.049},
  journal      = {Neurocomputing},
  pages        = {281-291},
  shortjournal = {Neurocomputing},
  title        = {Investigating the performance of multi-objective optimization when learning bayesian networks},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gene selection for microarray data classification via dual
latent representation learning. <em>NEUCOM</em>, <em>461</em>, 266–280.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of genetic sequencing and DNA microarray technologies, a large number of gene expression data has been generated, which provides an important reference for tumor diagnosis. However, it is challenging to classify these gene expression data due to the high-dimensionality and small number of data samples. In this work, we propose an effective method to select the most discriminative genes from high-dimensional microarray data for benefiting tumor classification. In detail, each gene is regarded as a feature dimension and we build a novel computational model based on dual latent feature representation learning , referred as DLRL briefly, which can capture both the internal association of data samples and the relationship between different genes. Instead of measuring the importance of genes in original data space, we perform gene selection in the learned latent representation space which is more robust to noisy and redundant information. We first construct the affinity matrices for both samples and genes, which can represent the correlation information between data samples and genes, respectively. Then the dual latent representation learning is modelled via non-negative matrix factorization of the two affinity matrices . The low-dimensional latent representation matrix of sample space is treated as a pseudo-label matrix to guide the latent space projection of original data. Meanwhile, the sample projection matrix is unified with the latent representation matrix of gene space. An alternating algorithm is carefully designed to solve the resultant optimization problem . Extensive experiments on six commonly used publicly microarray datasets are conducted to demonstrate that the proposed method can steadily outperform other state-of-the-art methods in terms of microarray data classification. In addition, we also test the proposed model on a face image dataset as well as a digit image dataset to validate its efficacy for general unsupervised feature selection.},
  archive      = {J_NEUCOM},
  author       = {Xiao Zheng and Chujie Zhang},
  doi          = {10.1016/j.neucom.2021.07.047},
  journal      = {Neurocomputing},
  pages        = {266-280},
  shortjournal = {Neurocomputing},
  title        = {Gene selection for microarray data classification via dual latent representation learning},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel class restriction loss for unsupervised domain
adaptation. <em>NEUCOM</em>, <em>461</em>, 254–265. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation has demonstrated promising performance to learn models in new environments. It aims to transfer the knowledge learned in labeled source domain to a new target domain, avoiding expensive efforts of label annotation. Many popular methods attempt to assign pseudo labels to unlabeled target samples and train the models as if they are true labels. However, the pseudo labels contain inevitable noises while their training strategies would enlarge and accumulate the errors, so that the model easily overfits to noisy data. Instead of focusing on assigning correct pseudo labels, in this paper, an unsupervised domain adaptation approach is proposed by preventing the model from overfitting false samples. Two different types of restrictions are considered on the training data to leverage the intra-class centralization and inter-class normalization. Each training sample and individual category are equally treated, where each point has the same opportunity to contribute to the model learning. A novel class restriction loss is proposed, which is further integrated into a teacher-student architecture, where the outputs from the teacher are treated as the pseudo labels for the student. The whole framework is trained in an end-to-end manner. Extensive experiments conducted on several image classification benchmarks demonstrate that the proposed method can significantly improve the performance, which outperforms the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Qi He and Qi Dai and Xiao Wu and Jun-Yan He},
  doi          = {10.1016/j.neucom.2021.07.033},
  journal      = {Neurocomputing},
  pages        = {254-265},
  shortjournal = {Neurocomputing},
  title        = {A novel class restriction loss for unsupervised domain adaptation},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HEMP: High-order entropy minimization for neural network
compression. <em>NEUCOM</em>, <em>461</em>, 244–253. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We formulate the entropy of a quantized artificial neural network as a differentiable function that can be plugged as a regularization term into the cost function minimized by gradient descent . Our formulation scales efficiently beyond the first order and is agnostic of the quantization scheme. The network can then be trained to minimize the entropy of the quantized parameters, so that they can be optimally compressed via entropy coding. We experiment with our entropy formulation at quantizing and compressing well-known network architectures over multiple datasets. Our approach compares favorably over similar methods, enjoying the benefits of higher order entropy estimate, showing flexibility towards non-uniform quantization (we use Lloyd-max quantization), scalability towards any entropy order to be minimized and efficiency in terms of compression. We show that HEMP is able to work in synergy with other approaches aiming at pruning or quantizing the model itself, delivering significant benefits in terms of storage size compressibility without harming the model’s performance.},
  archive      = {J_NEUCOM},
  author       = {Enzo Tartaglione and Stéphane Lathuilière and Attilio Fiandrotti and Marco Cagnazzo and Marco Grangetto},
  doi          = {10.1016/j.neucom.2021.07.022},
  journal      = {Neurocomputing},
  pages        = {244-253},
  shortjournal = {Neurocomputing},
  title        = {HEMP: High-order entropy minimization for neural network compression},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MSGSE-net: Multi-scale guided squeeze-and-excitation network
for subcortical brain structure segmentation. <em>NEUCOM</em>,
<em>461</em>, 228–243. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been achieving remarkable results in medical image segmentation . However, for accurate segmentation of subcortical brain structure in MR images, it is still a challenge due to the ambiguous boundaries, the complex structures, and the various shapes, which limits their clinical application. In this paper, we focus on utilizing multi-scale image contexts and attention mechanisms to improve networks’ ability to learn discriminative feature representation for accurate segmentation and present a novel FCNN architecture called multis-scale guided squeeze-and-excitation network (MSGSE-Net). In particular, we first propose the multi-scale guided squeeze-and-excitation (MSGSE) attention module which can progressively and selectively aggregate discriminative features. In contrast to existing attention modules, the MSGSE module performs an adaptive recalibration that features at different locations of the feature map are recalibrated under the guidance of multi-scale contexts. Then multi-scale spatial attention supervision is adopted to enhance the intra-class homogeneity and inter-class distinction of the attention weights. Moreover, we propose a novel entropy-weighted Dice loss (EDL) to force the network to focus on the ambiguous voxels around the boundaries of subcortical structures . We evaluate the proposed method on two challenging benchmark datasets (the IBSR dataset and the MALC dataset). The experimental results show that our model consistently yields better segmentation performance than several state-of-the-art methods and improves the segmentation Dice score by 1.6\% at most compared with baseline method U-Net. Our code is available at https://github.com/neulxlx/MSGSE-Net .},
  archive      = {J_NEUCOM},
  author       = {Xiang Li and Ying Wei and Lin Wang and Shidi Fu and Chuyuan Wang},
  doi          = {10.1016/j.neucom.2021.07.018},
  journal      = {Neurocomputing},
  pages        = {228-243},
  shortjournal = {Neurocomputing},
  title        = {MSGSE-net: Multi-scale guided squeeze-and-excitation network for subcortical brain structure segmentation},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain-adaptive modules for stereo matching network.
<em>NEUCOM</em>, <em>461</em>, 217–227. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have been widely used in end-to-end stereo matching networks in recent years. However, most stereo networks are not robust to variations in the environment and thus are difficult to be extended to practical applications. In this paper, an inherent factor that hinders the adaptive performance of stereo matching networks is first determined. Then we propose a domain-adaptive feature extractor (DAFE) that can extract the features of images on different domains and a feature normalization method to reduce the variances of features in across-domain situations. Moreover, the influence of various modules on the performance of the domain-adaptive network (DANet) is investigated. When trained on Sceneflow data and generalized to the real test sets, the method performs significantly better than state-of-the-art models and even better than some latest disparity networks fine-tuned on the target domain.},
  archive      = {J_NEUCOM},
  author       = {Zhi Ling and Kai Yang and Jinlong Li and Yu Zhang and Xiaorong Gao and Lin Luo and Liming Xie},
  doi          = {10.1016/j.neucom.2021.06.004},
  journal      = {Neurocomputing},
  pages        = {217-227},
  shortjournal = {Neurocomputing},
  title        = {Domain-adaptive modules for stereo matching network},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Robust hyperspectral unmixing based on dual views with
adaptive weights. <em>NEUCOM</em>, <em>461</em>, 204–216. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral unmixing (HU) is regarded as an indispensable preprocessing procedure for many field of spectral data analysis because of the existence of mixed pixels. However, the unmixing algorithms are implemented under the presupposition of special mixing models. In other words, any unmixing algorithm only works on a special mixing model of the spectra. This leads to low generalization performance of most unmixing algorithms. To mitigate this problem, a robust unmixing method is proposed, which exploits dual views with adaptive weights for HU (AwDvHU). The proposed method utilizes multi-kernel learning to construct a high-dimensional space that can reflect the nonlinear interaction between spectra optimally. Then, through fusing the unmixing object of original data and the mapped high-dimensional features, the AwDvHU method takes full advantage of the complementary characteristics of features in dual views. Moreover, the AwDvHU method automatically learns the weights for dual views according to the importance of different feature spaces. Its effectiveness in unmixing is verified by experimental results both on the synthetic and real data.},
  archive      = {J_NEUCOM},
  author       = {Xinxin Zhang and Xuelong Li and Yongsheng Dong},
  doi          = {10.1016/j.neucom.2021.07.041},
  journal      = {Neurocomputing},
  pages        = {204-216},
  shortjournal = {Neurocomputing},
  title        = {Robust hyperspectral unmixing based on dual views with adaptive weights},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving task-agnostic BERT distillation with layer mapping
search. <em>NEUCOM</em>, <em>461</em>, 194–203. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) which transfers the knowledge from a large teacher model to a small student model, has been widely used to compress the BERT model recently. Besides the supervision in the output in the original KD, recent works show that layer-level supervision is crucial to the performance of the student BERT model. However, previous works designed the layer mapping strategy heuristically (e.g., uniform or last-layer), which can lead to inferior performance. In this paper, we propose to use the genetic algorithm (GA) to search for the optimal layer mapping automatically. To accelerate the search process, we further propose a proxy setting where a small portion of the training corpus are sampled for distillation, and three representative tasks are chosen for evaluation. After obtaining the optimal layer mapping, we perform the task-agnostic BERT distillation with it on the whole corpus to build a compact student model, which can be directly fine-tuned on downstream tasks. Comprehensive experiments on the evaluation benchmarks demonstrate that 1) layer mapping strategy has a significant effect on task-agnostic BERT distillation and different layer mappings can result in quite different performances; 2) the optimal layer mapping strategy from the proposed search process consistently outperforms the other heuristic ones; 3) with the optimal layer mapping, our student model achieves state-of-the-art performance on the GLUE tasks.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqi Jiao and Huating Chang and Yichun Yin and Lifeng Shang and Xin Jiang and Xiao Chen and Linlin Li and Fang Wang and Qun Liu},
  doi          = {10.1016/j.neucom.2021.07.050},
  journal      = {Neurocomputing},
  pages        = {194-203},
  shortjournal = {Neurocomputing},
  title        = {Improving task-agnostic BERT distillation with layer mapping search},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of deep neural network watermarking techniques.
<em>NEUCOM</em>, <em>461</em>, 171–193. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protecting the Intellectual Property Rights (IPR) associated to Deep Neural Networks (DNNs) is a pressing need pushed by the high costs required to train such networks and by the importance that DNNs are gaining in our society. Following its use for Multimedia (MM) IPR protection, digital watermarking has recently been considered as a mean to protect the IPR of DNNs. While DNN watermarking inherits some basic concepts and methods from MM watermarking, there are significant differences between the two application areas, thus calling for the adaptation of media watermarking techniques to the DNN scenario and the development of completely new methods. In this paper, we overview the most recent advances in DNN watermarking, by paying attention to cast them into the bulk of watermarking theory developed during the last two decades, while at the same time highlighting the new challenges and opportunities characterising DNN watermarking. Rather than trying to present a comprehensive description of all the methods proposed so far, we introduce a new taxonomy of DNN watermarking and present a few exemplary methods belonging to each class. We hope that this paper will inspire new research in this exciting area and will help researchers to focus on the most innovative and challenging problems in the field.},
  archive      = {J_NEUCOM},
  author       = {Yue Li and Hongxia Wang and Mauro Barni},
  doi          = {10.1016/j.neucom.2021.07.051},
  journal      = {Neurocomputing},
  pages        = {171-193},
  shortjournal = {Neurocomputing},
  title        = {A survey of deep neural network watermarking techniques},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disassembling object representations without labels.
<em>NEUCOM</em>, <em>461</em>, 162–170. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study a new representation-learning task, which we termed as disassembling object representations. Given an image featuring multiple objects, the goal of disassembling is to acquire a latent representation, of which each part corresponds to one category of objects. Disassembling thus finds its application in a wide domain such as image editing and few- or zero-shot learning, as it enables category-specific modularity in the learned representations. To this end, we propose an unsupervised approach to achieving disassembling, named Unsupervised Disassembling Object Representation (UDOR). UDOR follows a double auto-encoder architecture, in which a fuzzy classification and an object-removing operation are imposed. The fuzzy classification constrains each part of the latent representation to encode features of up to one object category, while the object-removing, combined with a generative adversarial network , enforces the modularity of the representations and integrity of the reconstructed image. Furthermore, we devise two metrics to respectively measure the modularity of disassembled representations and the visual integrity of reconstructed images. Experimental results demonstrate that the proposed UDOR, despite unsupervised, achieves truly encouraging results on par with those of supervised methods.},
  archive      = {J_NEUCOM},
  author       = {Zunlei Feng and Yongming He and Yike Yuan and Li Sun and Huiqiong Wang and Mingli Song},
  doi          = {10.1016/j.neucom.2021.07.004},
  journal      = {Neurocomputing},
  pages        = {162-170},
  shortjournal = {Neurocomputing},
  title        = {Disassembling object representations without labels},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Adaptive neural network control for a class of
interconnected pure-feedback time-delay nonlinear systems with
full-state constraints and unknown measurement sensitivities.
<em>NEUCOM</em>, <em>461</em>, 147–161. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of the adaptive neural network control design for full state constrained interconnected pure-feedback time-delay systems with unknown measurement sensitivity. Based on the dynamic surface design approach, constrained transform functions are used to deal with the asymmetric state constraints, which can remove the feasibility conditions. The problem of unknown measurement sensitivity is considered in interconnected systems, and the inaccurate information of states and output brings more difficulties and challenges to this design. Through transforming the nonlinearities caused by unknown measurement sensitivity into bounded nonlinear functions , radial basis function neural network can be utilized to approximate the unknown nonlinear terms. And the proposed control strategy can ensure all signals of the system are semi-globally ultimately uniformly bounded and the asymmetric state constraints are strictly maintained. Finally, simulation examples are given to show the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Liuliu Zhang and Lingchen Zhu and Changchun Hua and Cheng Qian},
  doi          = {10.1016/j.neucom.2021.07.043},
  journal      = {Neurocomputing},
  pages        = {147-161},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural network control for a class of interconnected pure-feedback time-delay nonlinear systems with full-state constraints and unknown measurement sensitivities},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel finite-time q-power recurrent neural network and its
application to uncertain portfolio model. <em>NEUCOM</em>, <em>461</em>,
137–146. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel finite-time q-power recurrent neural network (FT-QPNN) for uncertain portfolio model . An uncertain mean–variance-skewness model under concave transaction costs is discussed. This portfolio model is essentially a nonconvex nonlinear optimization problem with a non-positive definite Hessian matrix of the Lagrange function. The non-positive definite Hessian matrix leads to the failure of many recurrent neural network methods in solving the problem, and many recurrent neural networks cannot converge to the equilibrium point in finite time. To overcome these difficulties, the FT-QPNN is proposed. Combined with finite-time activation function and local convexification method, the FT-QPNN can solve the optimization problem with non-positive definite Hessian matrix and converge to the equilibrium point in finite time. The global finite-time stability and robustness properties of the FT-QPNN are proved theoretically and verified by numerical experiments. Furthermore, the proposed FT-QPNN is applied to solve the uncertain portfolio model. The application simulation results and comparative experiments with other methods respectively illustrate the feasibility and superiority of the FT-QPNN.},
  archive      = {J_NEUCOM},
  author       = {Mingjie Ma and Jianhui Yang},
  doi          = {10.1016/j.neucom.2021.07.036},
  journal      = {Neurocomputing},
  pages        = {137-146},
  shortjournal = {Neurocomputing},
  title        = {A novel finite-time q-power recurrent neural network and its application to uncertain portfolio model},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A mixed-kernel, variable-dimension memristive CNN for
electronic nose recognition. <em>NEUCOM</em>, <em>461</em>, 129–136. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the dynamic characteristics, memristors have great potential for implementing various neural network training and applications. By applying memristors to neural networks as a strategy, the hardware architecture can be taken full advantage of to accelerate matrix operations . A mixed-kernel, variable-dimension memristive convolutional neural network (MixVMCNN), which can identify and classify six gases detected by the electronic nose, is proposed. To generate better gas recognition technique, we provide various receptive fields for the network by using different sizes of convolutional kernels in the same layer. We propose a novel variable-dimension convolutional approach that extracts features in different dimensions. Furthermore, we make use of memristor arrays to make the most of the hardware structure to speed up calculation. Experimental results indicate that the designed network, using only 56 weights, achieves the electronic nose gas classification with high accuracy of 99.72\%, based on the Chemical gas sensor array dataset. To further exam the effectiveness of the model, supplemental experiments show that this model has stronger noise-robustness than other networks.},
  archive      = {J_NEUCOM},
  author       = {Jiahao Chen and Lidan Wang and Shukai Duan},
  doi          = {10.1016/j.neucom.2021.07.009},
  journal      = {Neurocomputing},
  pages        = {129-136},
  shortjournal = {Neurocomputing},
  title        = {A mixed-kernel, variable-dimension memristive CNN for electronic nose recognition},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RANSP: Ranking attention network for saliency prediction on
omnidirectional images. <em>NEUCOM</em>, <em>461</em>, 118–128. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various convolutional neural network (CNN)-based methods have shown the ability to boost the performance of saliency prediction on omnidirectional images (ODIs). However, these methods are limited by sub-optimal accuracy, because not all the features extracted by the CNN model are useful for the final fine-grained saliency prediction. Some features are redundant and may have negative impact on the final fine-grained saliency prediction. To tackle this problem, we propose a novel Ranking Attention Network for saliency prediction (RANSP) of head fixations on ODIs. Specifically, the part-guided attention (PA) module and channel-wise feature (CF) extraction module are integrated in a unified framework and are trained in an end-to-end manner for fine-grained saliency prediction. To better utilize the channel-wise feature maps, we further propose a new Ranking Attention Module (RAM), which automatically ranks and selects these feature maps based on scores for fine-grained saliency prediction. Extensive experiments and ablation studies are conducted to show the effectiveness of our method for saliency prediction on ODIs.},
  archive      = {J_NEUCOM},
  author       = {Dandan Zhu and Yongqing Chen and Xiongkuo Min and Yucheng Zhu and Guokai Zhang and Qiangqiang Zhou and Guangtao Zhai and Xiaokang Yang},
  doi          = {10.1016/j.neucom.2021.06.029},
  journal      = {Neurocomputing},
  pages        = {118-128},
  shortjournal = {Neurocomputing},
  title        = {RANSP: Ranking attention network for saliency prediction on omnidirectional images},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple dynamic graph based traffic speed prediction
method. <em>NEUCOM</em>, <em>461</em>, 109–117. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic speed prediction is a crucial and challenging task for intelligent transportation systems . The prediction task can be accomplished via graph neural networks with structured data, but accurate traffic speed prediction is challenging due to the complexity of traffic systems and the constantly dynamic changing nature. To address these issues, a novel evolution temporal graph convolutional network (ETGCN) model is proposed in this paper. The ETGCN model first fuses multiple graph structures, and utilizes graph convolutional network (GCN) to model spatial correlation . Then, the spatial–temporal dependence and their dynamical changes are learned simultaneously to predict traffic speed on a road network graph. Especially, a similarity-based attention method is proposed to fuse multiple graph adjacency matrices . Then, the gated recurrent unit is combined with GCN to capture spatial–temporal correlations and their changing status, simultaneously. Extensive experiments on two large-scale datasets show that our methods provide more accurate prediction results than the existing state-of-the-art methods in every prediction horizon.},
  archive      = {J_NEUCOM},
  author       = {Zikai Zhang and Yidong Li and Haifeng Song and Hairong Dong},
  doi          = {10.1016/j.neucom.2021.07.052},
  journal      = {Neurocomputing},
  pages        = {109-117},
  shortjournal = {Neurocomputing},
  title        = {Multiple dynamic graph based traffic speed prediction method},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning local descriptors with multi-level feature
aggregation and spatial context pyramid. <em>NEUCOM</em>, <em>461</em>,
99–108. (<a href="https://doi.org/10.1016/j.neucom.2021.07.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite that efforts have shifted to learning local descriptors with convolutional neural network (CNN) from hand-crafted realm, the inherent feature hierarchy within CNN has been rarely explored. To increase both the invariant and discriminative abilities of the CNN-based local descriptors by making use of the complementary representation powers of the feature maps at different levels of CNN, in this paper, we design a multi-level feature aggregation (MLFA) module to communicate information across pyramid levels effectively. Then, each level extracts a feature vector after feature fusion and the final descriptor concatenates these outputs. Moreover, to leverage the spatial structure within a local patch, we propose a novel spatial context pyramid (SCP) module to capture the spatial information. SCP is devised in a residual manner and only several additional parameters are introduced to the model. We implement our algorithm based on the HardNet framework and carry out comprehensive evaluation on the UBC Phototour, HPatches and ETH datasets. The experimental results demonstrate that the proposed method performs favorably against the state-of-the-art ones. Ablation study is also provided to show the effectiveness of each component.},
  archive      = {J_NEUCOM},
  author       = {Pengpeng Liang and Haoxuanye Ji and Erkang Cheng and Yumei Chai and Liming Wang and Haibin Ling},
  doi          = {10.1016/j.neucom.2021.07.030},
  journal      = {Neurocomputing},
  pages        = {99-108},
  shortjournal = {Neurocomputing},
  title        = {Learning local descriptors with multi-level feature aggregation and spatial context pyramid},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving the backpropagation algorithm with
consequentialism weight updates over mini-batches. <em>NEUCOM</em>,
<em>461</em>, 86–98. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Normalized least mean squares (NLMS) and affine projection algorithm (APA) are two successful algorithms that improve the stability of least mean squares (LMS) by reducing the necessity to change the learning rate during the training process. In this paper, we extend them to multi-layer neural networks . We first prove that it is possible to consider a multi-layer neural network as a stack of adaptive filters. It opens the door to bring successful algorithms from adaptive filters to neural networks . We additionally introduce a more comprehensible interpretation than the complicated geometric interpretation in APA for a single fully-connected (FC) layer that can easily be generalized, for instance, to convolutional neural networks and mini-batch training. With this new viewpoint, we introduce a more robust algorithm by predicting and then amending the adverse consequences of some actions that take place in mini-batch backpropagation (BP), even before they happen. The proposed method is a modification to the BP that can be used alongside stochastic gradient descent (SGD) and its momentum variants like Adam and Nesterov. Our experiments show the usefulness of the proposed method in the training of deep neural networks. It is less sensitive to hyper-parameters and needs less intervention during the training process. Besides, it usually converges more smoothly and in fewer iterations. Such predictable behavior helps it to get tuned easier, be resilient during the training, and reduce or eliminate its reliance on other techniques such as momentum.},
  archive      = {J_NEUCOM},
  author       = {Naeem Paeedeh and Kamaledin Ghiasi-Shirazi},
  doi          = {10.1016/j.neucom.2021.07.010},
  journal      = {Neurocomputing},
  pages        = {86-98},
  shortjournal = {Neurocomputing},
  title        = {Improving the backpropagation algorithm with consequentialism weight updates over mini-batches},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asymptotical stability of fractional neutral-type delayed
neural networks with reaction-diffusion terms. <em>NEUCOM</em>,
<em>461</em>, 77–85. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates the asymptotical stability of the equilibrium point for a class of fractional neutral-type delayed neural networks with reaction-diffusion terms in sense of Riemann–Liouville. In terms of linear matrix inequalities approach, inequality scaling techniques and Green’s theorem, by constructing a suitable Lyapunov functional, some less conservative criterion of asymptotical stability for the neural networks system are given. Inspired by some achievements, the results obtained in this paper are more general and can easily test the stability of practical neural networks systems. Finally, two numerical examples are elaborated to substantiate the validity and conciseness of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xiang Wu and Shutang Liu and Yin Wang and Zhibin Liu},
  doi          = {10.1016/j.neucom.2021.07.042},
  journal      = {Neurocomputing},
  pages        = {77-85},
  shortjournal = {Neurocomputing},
  title        = {Asymptotical stability of fractional neutral-type delayed neural networks with reaction-diffusion terms},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Example-feature graph convolutional networks for
semi-supervised classification. <em>NEUCOM</em>, <em>461</em>, 63–76.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional networks (GCNs) successfully generalize convolutional neural networks to handle the graphs with high-order arbitrary structures. However, most existing GCNs variants consider only the local geometry of row vectors of high-dimensional data via example graph Laplacian, while neglecting the manifold structure information of column vectors. To address this problem, we propose the example-feature graph convolutional networks (EFGCNs) for semi-supervised classification. Particularly, we introduce the definition of the spectral example-feature graph (EFG) convolution that simultaneously utilizes the example graph Laplacian and feature graph Laplacian to better preserve the local geometry distributions of data. After optimizing the spectral EFG convolution with the first-order approximation , a single-layer EFGCNs is obtained. It is then further extended to build a multi-layer EFGCNs. Extensive experiments on remote sensing and citation networks datasets demonstrate the proposed EFGCNs show superior performance in semi-supervised classification compared with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Sichao Fu and Weifeng Liu and Kai Zhang and Yicong Zhou},
  doi          = {10.1016/j.neucom.2021.07.048},
  journal      = {Neurocomputing},
  pages        = {63-76},
  shortjournal = {Neurocomputing},
  title        = {Example-feature graph convolutional networks for semi-supervised classification},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FFPointNet: Local and global fused feature for 3D point
clouds analysis. <em>NEUCOM</em>, <em>461</em>, 55–62. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a lot of attention is given to deep learning on raw 3D point clouds. Existing approaches, however, either exploit the global shape feature without paying attention to the local features or hierarchically exploit local features with little attention to the global shape feature. In this paper, we proposed Fused Feature Point Network (FFPointNet), a deep neural network for learning on raw point clouds that exploits both local and global shape features. Specifically, we designed a novel module, ChannelNet, a simple and effective module that exploits global shape features using 1D convolutions. ChannelNet uses only 0.041 million parameters, making it easy to plug in the generic PointNet++ backbone to exploits both local and global shape structures for better contextual representation. Experiments carried out showed that by fusing PointNet++ feature with ChannelNet feature, we gained an improved classification accuracy over PointNet++ by 2.2\% on the popular ModelNet40 dataset; and an improved class mean intersection over union of 1.4\% on the popular ShapeNetParts dataset.},
  archive      = {J_NEUCOM},
  author       = {Saifullahi Aminu Bello and Cheng Wang and Naftaly Muriuki Wambugu and Jibril Muhammad Adam},
  doi          = {10.1016/j.neucom.2021.07.044},
  journal      = {Neurocomputing},
  pages        = {55-62},
  shortjournal = {Neurocomputing},
  title        = {FFPointNet: Local and global fused feature for 3D point clouds analysis},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Filter pruning with a feature map entropy importance
criterion for convolution neural networks compressing. <em>NEUCOM</em>,
<em>461</em>, 41–54. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Neural Networks (DNN) has made significant progress in recent years. However, its high computing and storage costs make it challenging to apply on resource-limited platforms or edge computation scenarios. Recent studies have shown that model pruning is an effective method to solve this problem. Typically, the model pruning method is a three-stage pipeline: training, pruning, and fine-tuning. In this work, a novel structured pruning method for Convolutional Neural Networks (CNN) compression is proposed, where filter-level redundant weights are pruned according to entropy importance criteria (termed FPEI). In short, the FPEI criterion, which works in the stage of pruning, defines the importance of the filter according to the entropy of feature maps. If a feature map contains very little information, it should not contribute much to the whole network. By removing these uninformative feature maps, their corresponding filters in the current layer and kernels in the next layer can be removed simultaneously. Consequently, the computing and storage costs are significantly reduced. Moreover, because our method cannot show the advantages of the existing ResNet pruning strategy, we propose a dimensionality reduction (DR) pruning strategy for ResNet structured networks. Experiments on several datasets demonstrate that our method is effective. In the experiment about the VGG-16 model on the SVHN dataset, we removed 91.31\% of the parameters, from 14.73M to 1.28M, achieving a 63.77\% reduction in the FLOPs, from 313.4M to 113.5M, and 1.73 times speedups of model inference.},
  archive      = {J_NEUCOM},
  author       = {Jielei Wang and Ting Jiang and Zongyong Cui and Zongjie Cao},
  doi          = {10.1016/j.neucom.2021.07.034},
  journal      = {Neurocomputing},
  pages        = {41-54},
  shortjournal = {Neurocomputing},
  title        = {Filter pruning with a feature map entropy importance criterion for convolution neural networks compressing},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dimension reduction of multimodal data by auto-weighted
local discriminant analysis. <em>NEUCOM</em>, <em>461</em>, 27–40. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimension reduction technology is playing an increasingly important role in machine learning . One of the most important reduction technologies is linear discriminant analysis (LDA), but the main disadvantage of LDA is that it is unable to find the local manifold structure, which means that it may fail to dispose of multimodal data. However, high-dimensional multimodal data are ubiquitous in many rations. In this paper, we propose a new dimensionality reduction method called auto-weighted local discriminant analysis (ALDA). Our method learns the similarity matrix and updates in the subspace simultaneously so that the neighborships can be evaluated in the optimal subspaces instead of in the original space. Furthermore, the new model is built based on the ℓ 2 , 1 ℓ2,1 -norm and automatically assigns a small weight to the pairwise points with large distance, and vice versa; thus, the local structure information can be captured by the ALDA. Additionally, an iterative re-weighted optimization algorithm is provided to efficiently solve the proposed model. Finally, extensive experiments conducted on several benchmark datasets and some synthetic datasets demonstrate the effectiveness of ALDA when comparing with some state-of-the-art dimensionality reduction methods.},
  archive      = {J_NEUCOM},
  author       = {Rongxiu Lu and Yingjie Cai and Jianyong Zhu and Feiping Nie and Hui Yang},
  doi          = {10.1016/j.neucom.2021.06.035},
  journal      = {Neurocomputing},
  pages        = {27-40},
  shortjournal = {Neurocomputing},
  title        = {Dimension reduction of multimodal data by auto-weighted local discriminant analysis},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sketched quantile additive functional regression.
<em>NEUCOM</em>, <em>461</em>, 17–26. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quantile additive functional regression (QAFR) relates the response to the integral of F ( t , X ( t ) ) F(t,X(t)) over t , where F is an unknown function and X ( t ) X(t) is the predictor in the form of a curve (function). This model incorporates functional linear quantile regression as a special case and the appearance of the integration as a smoothing operator makes regularization necessary to obtain a meaningful estimate as in typical inverse problems . It is conventional to perform ridge regression over the reproducing kernel Hilbert space . However, the computational complexity grows very fast when the problem scale gets large. We are thus motivated to consider the random sketching method as an approximation for this class of models. Sketching has become very popular recently and was previously used in some learning problems including kernel ridge regression . We established the optimal theoretical risk bound showing that the sketched estimator can converge as fast as the standard estimator. Numerical studies are carried out to examine the performance of sketched estimation.},
  archive      = {J_NEUCOM},
  author       = {Yingying Zhang and Heng Lian},
  doi          = {10.1016/j.neucom.2021.07.032},
  journal      = {Neurocomputing},
  pages        = {17-26},
  shortjournal = {Neurocomputing},
  title        = {Sketched quantile additive functional regression},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards point cloud completion: Point rank sampling and
cross-cascade graph CNN. <em>NEUCOM</em>, <em>461</em>, 1–16. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Point Fractal Network (PF-Net) is a seminal work with capability of completing the missing regions of point clouds. However, the multi-resolution structure of PF-Net neglects effective feature fusion between each resolution, which makes the resulting shape lack local geometric details . To tackle this problem, we design a novel shape completion network named PRSCN. We first present Point Rank Sampling to rate and sample feature points more objectively through local outline form. In this way, the sampled points can facilitate the downstream tasks. Subsequently, considering the correlation between features from different scales, we design a Cross-Cascade Module to combine features hierarchically. Moreover, we propose Leap-type EdgeConv to enlarge the receptive field while maintain the kernel size unchanged. These improvements together make our CD error 3\%\% lower than that of state-of-the-art method on ShapeNet-part dataset.},
  archive      = {J_NEUCOM},
  author       = {Liping Zhu and Bingyao Wang and Gangyi Tian and Wenjie Wang and Chengyang Li},
  doi          = {10.1016/j.neucom.2021.07.035},
  journal      = {Neurocomputing},
  pages        = {1-16},
  shortjournal = {Neurocomputing},
  title        = {Towards point cloud completion: Point rank sampling and cross-cascade graph CNN},
  volume       = {461},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Environment sound classification using an attention-based
residual neural network. <em>NEUCOM</em>, <em>460</em>, 409–423. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Complexity of environmental sounds impose numerous challenges for their classification. The performance of Environmental Sound Classification (ESC) depends greatly on how good the feature extraction technique employed to extract generic and prototypical features from a sound is. The presence of silent and semantically irrelevant frames is ubiquitous during the classification of environmental sounds. To deal with such issues that persist in environmental sound classification, we introduce a novel attention-based deep model that supports focusing on semantically relevant frames. The proposed attention guided deep model efficiently learns spatio-temporal relationships that exist in the spectrogram of a signal. The efficacy of the proposed method is evaluated on two widely used Environmental Sound Classification datasets: ESC-10 and DCASE 2019 Task-1(A) datasets. The experiments performed and their results demonstrate that the proposed method yields comparable performance to state-of-the-art techniques. We obtained improvements of 11.50\% and 19.50\% in accuracy as compared to the accuracy of the baseline models of the ESC-10 and DCASE 2019 Task-1(A) datasets respectively. To support the attention outcomes that have focused on relevant regions, visual analysis of the attention feature map has also been presented. The resultant attention feature map conveys that the model focuses only on the spectrogram’s semantically relevant regions while skipping the irrelevant regions.},
  archive      = {J_NEUCOM},
  author       = {Achyut Mani Tripathi and Aakansha Mishra},
  doi          = {10.1016/j.neucom.2021.06.031},
  journal      = {Neurocomputing},
  pages        = {409-423},
  shortjournal = {Neurocomputing},
  title        = {Environment sound classification using an attention-based residual neural network},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-fragile extended dissipative synchronization of markov
jump inertial neural networks: An event-triggered control strategy.
<em>NEUCOM</em>, <em>460</em>, 399–408. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the non-fragile extended dissipative synchronization issue is studied for Markov jump neural networks with inertial term. With regard to the inertial neural networks described by a second-order differential equation, an appropriate variable substitution is applied to transform the original system into a first-order differential system. Considering that the data transmissions are proceed in the shared band-limited digital communication networks when designing a controller to achieve synchronization. In order to alleviate the burden of networked communication, a controller based on an event-triggered strategy is used to achieve this goal. Furthermore, a non-fragile controller design scheme governed by Bernoulli distribution is proposed to deal with the uncertainty that may occur in the implementation process of the designed controller. Then, on the basis of the Lyapunov stability theory and an improved inequality technique, sufficient conditions are obtained to ensure that the error system meets the extended dissipative synchronization. Finally, two examples are provided to verify the effectiveness of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Tian Fang and Shiyu Jiao and Dongmei Fu and Jing Wang},
  doi          = {10.1016/j.neucom.2021.07.016},
  journal      = {Neurocomputing},
  pages        = {399-408},
  shortjournal = {Neurocomputing},
  title        = {Non-fragile extended dissipative synchronization of markov jump inertial neural networks: An event-triggered control strategy},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Multi-label text classification via joint learning from
label embedding and label correlation. <em>NEUCOM</em>, <em>460</em>,
385–398. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the multi-label text classification problems with many classes, many existing multi-label classification algorithms become infeasible or suffer an unaffordable cost. Some researches hence perform the Label Space Dimension Reduction(LSDR) to solve this problem, but a number of methods ignore the sequence information of texts and the label correlation in the original label space, and treat the label as a meaningless multi-hot vector. In this paper, we put forward a multi-label text classification algorithm LELC(joint learning from L abel E mbedding and L abel C orrelation) based on the multi-layer attention and label correlation to solve the issue of multi-label text classification with a large number of class labels. Specifically, we firstly extract features through Bidirectional Gated Recurrent Unit Network(Bi-GRU), multi-layer attention and linear layers. Bi-GRU will capture the content information and sequence information of the text at the same time, and the attention mechanism can help us select the valid features related to labels. Then, we use matrix factorization to perform LSDR, and consider label correlation of the original label space in this process, which allows us to implicitly encode the latent space and simplify the model learning. Finally, Deep Canonical Correlation Analysis(CCA) technology is exploited to couple features and the latent space in an end-to-end pattern, so that these two can influence each other to learn the mapping of feature space to latent space. Experiments on 11 real-world datasets show the comparability between our proposed model and the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Huiting Liu and Geng Chen and Peipei Li and Peng Zhao and Xindong Wu},
  doi          = {10.1016/j.neucom.2021.07.031},
  journal      = {Neurocomputing},
  pages        = {385-398},
  shortjournal = {Neurocomputing},
  title        = {Multi-label text classification via joint learning from label embedding and label correlation},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Grabbing the long tail: A data normalization method for
diverse and informative dialogue generation. <em>NEUCOM</em>,
<em>460</em>, 374–384. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent neural models have shown significant progress in dialogue generation. Among those models, most of them are based on language models , yielding the generation word by word according to the previous context. Due to the inherent mechanism in language models, as well as the most frequently used cross-entropy function ( making the distribution of generations approximate that of training data continuously ), trained generation models inevitably tend to generate frequent words in training datasets, leading to low diversity and poor informativeness issues. By investigating a few mainstream dialogue generation models, we find that the probable cause is the intrinsic Long Tail Phenomenon in linguistics. To address these issues of low diversity and poor informativeness, we explore and analyze a large corpus from Wikipedia, and then propose an efficient frequency-based data normalization method, i.e., Log Normalization. Furthermore, we explore another two methods, Mutual Normalization and Log-Mutual Normalization, to eliminate the mutual information effect. In order to validate the effectiveness of the proposed methods, we conduct extensive experiments on three datasets with different subjects, including social media, film subtitles, and online customer service. Compared with the vanilla transformers, generation models augmented with our proposed methods achieve significant improvements in generated responses, in terms of both diversity and informativeness. Specifically, the unigram and bigram diversity in the responses are improved by 8.5\%–14.1\% and 19.7\%–25.8\% on the three datasets, respectively. The informativeness ( defined as amounts of nouns and verbs ) is increased by 13.1\%–31.0\% and 30.4\%–59.0\%, respectively. Moreover, our methods can be adapted to new generation models efficiently and effectively, with their model-agnostic characteristics.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Zhan and Jianyu Zhao and Yang Zhang and Jiangtao Gong and Qianying Wang and Qi Shen and Liuxin Zhang},
  doi          = {10.1016/j.neucom.2021.07.039},
  journal      = {Neurocomputing},
  pages        = {374-384},
  shortjournal = {Neurocomputing},
  title        = {Grabbing the long tail: A data normalization method for diverse and informative dialogue generation},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep q-network based real-time active disturbance rejection
controller parameter tuning for multi-area interconnected power systems.
<em>NEUCOM</em>, <em>460</em>, 360–373. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the problem of load frequency control (LFC) in multi-area interconnected power systems, a method of linear active disturbance rejection control (LADRC) that uses Deep Q-Network (DQN) to obtain controller parameters in real-time is designed. The main idea of combining the DQN and the LADRC is to equate the state and action in the environment of Reinforcement Learning (RL) to the output of the power system and the parameters of the controller, which will make the controller have learning ability and better adaptability. In order to achieve a better training effect, some improvements have been made to the action selection strategy and reward function. The proposed method is applied to the three-area and four-area interconnected power systems under the influence of disturbances, and the simulation results show the effectiveness of the proposed method. Compared with Proportional-Integral-Derivative (PID) controller and LADRC with fixed parameters, the method proposed in this paper has a better response effect in terms of overshoot and settling time of the power system.},
  archive      = {J_NEUCOM},
  author       = {Yuemin Zheng and Qinglin Sun and Zengqiang Chen and Mingwei Sun and Jin Tao and Hao Sun},
  doi          = {10.1016/j.neucom.2021.06.063},
  journal      = {Neurocomputing},
  pages        = {360-373},
  shortjournal = {Neurocomputing},
  title        = {Deep Q-network based real-time active disturbance rejection controller parameter tuning for multi-area interconnected power systems},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Person image generation with attention-based injection
network. <em>NEUCOM</em>, <em>460</em>, 345–359. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person image generation becomes a challenging problem due to the content ambiguity and style inconsistency. In this paper, we propose a novel Attention-based Injection Network (AIN) to address this issue. Instead of directly learning the relationship between the source and target image, we decompose the process into two accessible modules, namely Semantic-guided Attention Network (SAN) and Pose-guided Attention Network (PAN). SAN is proposed to capture the semantic information which can embed the human attributes into the latent space via the semantic layout. PAN enables a natural re-coupling of the pose and appearance, which can selectively integrate features to complete the human pose transformation. Additionally, a semantic layout loss is proposed to focus on the semantic content similarity between the source and generated images. Compared with other methods, our networks can enforce the local textures and styles consistency between the source and generated image. Experiments show that superior both qualitative and quantitative results are obtained on Market-1501 and DeepFashion datasets. On the basis of AIN, our network can further achieve the data augmentation for person re-identification (Re-ID) with dramatically improving the person Re-ID accuracy.},
  archive      = {J_NEUCOM},
  author       = {Meichen Liu and Kejun Wang and Ruihang Ji and Shuzhi Sam Ge and Jing Chen},
  doi          = {10.1016/j.neucom.2021.06.077},
  journal      = {Neurocomputing},
  pages        = {345-359},
  shortjournal = {Neurocomputing},
  title        = {Person image generation with attention-based injection network},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-constrained zeroing neural network for
time-dependent nonlinear optimization with application to mobile robot
tracking control. <em>NEUCOM</em>, <em>460</em>, 331–344. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Because of the strong dynamic behavior and computing power, zeroing neural networks (ZNNs) have been dee different time-dependent issues. However, due to the high nonlinearity and complexity, the research on finding a feasible ZNN to address time-dependent nonlinear optimization with multiple types of constraints still remains stagnant. To simultaneously handle multiple types of constraints for the time-dependent nonlinear optimization, this paper proposes a novel neural-network based model in a unified framework of ZNN. By using leveraging the Lagrange method, the time-dependent nonlinear optimization problem with multiple types of constraints is converted to a time-dependent equality system. The proposed multi-constrained ZNN (termed MZNN) inherently possesses the effectiveness of exponential convergence property by utilizing the time-derivative information. Theoretical analyses on the global stability and exponential convergence property are rigorously provided. Then, three general numerical examples in time-independent and time-dependent cases verify the computational performance of the proposed MZNN. An application based on the mobile robot for nonlinear optimization control sufficiently demonstrates the physical effectiveness of the proposed MZNN for the control of mobile robot with both performance-index optimization and multiple physical-limit constraints. Finally, comparisons with existing neural networks such as gradient neural network (GNN), and performance tests with investigation on computational complexity substantiate the superiority of the MZNN for the time-dependent nonlinear optimization subject to multiple types of constraints.},
  archive      = {J_NEUCOM},
  author       = {Dechao Chen and Xinwei Cao and Shuai Li},
  doi          = {10.1016/j.neucom.2021.06.089},
  journal      = {Neurocomputing},
  pages        = {331-344},
  shortjournal = {Neurocomputing},
  title        = {A multi-constrained zeroing neural network for time-dependent nonlinear optimization with application to mobile robot tracking control},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis and modeling conditional mutual dependency of
metrics in software defect prediction using latent variables.
<em>NEUCOM</em>, <em>460</em>, 309–330. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software defect prediction constitutes an important discipline in software development life-cycle. Among the techniques employed in this domain, Naive Bayes (NB) classifier is cited by a large number of researchers for its simple structure and remarkable classification performance notwithstanding the concern of whether it is theoretically justified or not. More concisely, NB is fundamentally built on the strong assumption of conditional independence of attributes, and the major question here is the compliance of software metrics with this assumption. To address this question, we propose a novel framework “MLMNB-SDP” equipped with a statistical hypothesis testing method to detect those software metrics with a significant conditional dependency. MLMNB-SDP is designed to handle conditional dependencies via a single latent variable in a predefined structure which is responsible for preserving the connection between pairs of software metrics when the class variables are instantiated. We evaluate the effectiveness of our approach based on its capability to measure conditional dependency of software metrics and defect prediction performance. For the former one, we employ Conditional Mutual Information (CMI), and for the later one we use three settings for defect prediction; (1) Within-Project Defect-Prediction (WPDP), (2) Cross-Project Defect-Prediction (CPDP), and (3) stratified k-fold cross-validation. Our metrics dependency analysis results indicate that traditional file-level software metrics demonstrate a significant conditional mutual dependency and the application of naive Bayes classifier in this domain is not theoretically acceptable. Our results based on the three settings indicate that MLMNB-SDP improves naive Bayes classifier 5.45\% to 75.86\% and outperforms well-known benchmark classifiers, i.e., Random Forest and Logistic Regression , regarding a significant increase in Precision, Recall, and F1 Score, Mathew’s Correlation Coefficient (MCC), and area under the ROC curve (AUC) values.},
  archive      = {J_NEUCOM},
  author       = {Nima Shiri Harzevili and Sasan H. Alizadeh},
  doi          = {10.1016/j.neucom.2021.05.043},
  journal      = {Neurocomputing},
  pages        = {309-330},
  shortjournal = {Neurocomputing},
  title        = {Analysis and modeling conditional mutual dependency of metrics in software defect prediction using latent variables},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Event-triggered consensus control and fault estimation for
time-delayed multi-agent systems with markov switching topologies.
<em>NEUCOM</em>, <em>460</em>, 292–308. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the consensus control and fault estimation problems for a class of time-delayed multi-agent systems with Markov switching topologies . Two different event-triggered mechanisms are adopted with hope to reduce burden of shared network and improve energy efficiency. Under Markov process , by establishing the consensus control protocol and designing a novel adaptive fault estimation observer, the consensus control and fault estimation problems are transformed into two stochastic stability problems in different forms. Then, according to the switching Lyapunov function method and free-weighting matrix technique, two delay-dependent stability criteria on the consensus control and fault estimation are derived, respectively. However, the two criteria containing nonlinear coupling terms are not standard linear matrix inequalities (LMIs) and cannot be solved directly with the LMI toolbox. In order to eliminate the coupling terms, two improved path-following algorithms are presented. These algorithms depend on the initial conditions, so it is very crucial to choose the appropriate preset parameters. The computational complexity is increasing with the number of iterations, system size and matrix dimension, which is a fully new challenge for the study of consensus control and fault estimation of multi-agent systems. Based on the algorithms, the switching consensus controller gains and model gain matrices of fault estimation can be efficiently solved out. Finally, a simulation example of tailless fighter airplanes is given to illustrate the practicality and validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Shanglin Li and Yangzhou Chen and Jingyuan Zhan},
  doi          = {10.1016/j.neucom.2021.07.027},
  journal      = {Neurocomputing},
  pages        = {292-308},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered consensus control and fault estimation for time-delayed multi-agent systems with markov switching topologies},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards histopathological stain invariance by unsupervised
domain augmentation using generative adversarial networks.
<em>NEUCOM</em>, <em>460</em>, 277–291. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The application of supervised deep learning methods in digital pathology is limited due to their sensitivity to domain shift. Digital Pathology is an area prone to high variability due to many sources, including the common practice of evaluating several consecutive tissue sections stained with different staining protocols. Obtaining labels for each stain is very expensive and time consuming as it requires a high level of domain knowledge. In this article, we propose an unsupervised augmentation approach based on adversarial image-to-image translation, which facilitates the training of stain invariant supervised convolutional neural networks. By training the network on one commonly used staining modality and applying it to images that include corresponding, but differently stained, tissue structures, the presented method demonstrates significant improvements over other approaches. These benefits are illustrated in the problem of glomeruli segmentation in seven different staining modalities (PAS, Jones H&amp;E, CD68, Sirius Red, CD34, H&amp;E and CD3) and analysis of the learned representations demonstrate their stain invariance.},
  archive      = {J_NEUCOM},
  author       = {Jelica Vasiljević and Friedrich Feuerhake and Cédric Wemmert and Thomas Lampert},
  doi          = {10.1016/j.neucom.2021.07.005},
  journal      = {Neurocomputing},
  pages        = {277-291},
  shortjournal = {Neurocomputing},
  title        = {Towards histopathological stain invariance by unsupervised domain augmentation using generative adversarial networks},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FinerPCN: High fidelity point cloud completion network using
pointwise convolution. <em>NEUCOM</em>, <em>460</em>, 266–276. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D scanners often obtain partial point clouds due to occlusion and limitation of viewing angles. Point cloud completion aims at inferring the full shape of an object from an incomplete point set. Existing deep learning models either do not consider local information or easily degrade the sharp details of the input, thereby losing some existing structures. In this paper, we propose a high fidelity point cloud completion network using pointwise convolution, called FinerPCN. FinerPCN generates complete and fine point clouds in a coarse-to-fine manner. FinerPCN consists of two subnetworks : an encoder-decoder for generating a coarse shape and pointwise convolution for refining its local structure. By repeatedly feeding partial input into the second subnetwork, FinerPCN effectively considers local information and alleviates structural blur of input while maintaining global shape. Experimental results show that FinerPCN generates finer detailed completion results than state-of-the-art methods while successfully keeping the shape of the input.},
  archive      = {J_NEUCOM},
  author       = {Yakun Chang and Cheolkon Jung and Yuanquan Xu},
  doi          = {10.1016/j.neucom.2021.06.080},
  journal      = {Neurocomputing},
  pages        = {266-276},
  shortjournal = {Neurocomputing},
  title        = {FinerPCN: High fidelity point cloud completion network using pointwise convolution},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cali-sketch: Stroke calibration and completion for
high-quality face image generation from human-like sketches.
<em>NEUCOM</em>, <em>460</em>, 256–265. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image generation has received increasing attention because of its wide application in security and entertainment. Sketch-based face generation brings more fun and better quality of image generation due to supervised interaction. However, when a sketch poorly aligned with the true face is given as input, existing supervised image-to-image translation methods often cannot generate acceptable photo-realistic face images. To address this problem, in this paper we propose Cali-Sketch, a human-like-sketch to photo-realistic-image generation method. Cali-Sketch explicitly models stroke calibration and image generation using two constituent networks: a Stroke Calibration Network (SCN), which calibrates strokes of facial features and enriches facial details while preserving the original intent features; and an Image Synthesis Network (ISN), which translates the calibrated and enriched sketches to photo-realistic face images. In this way, we manage to decouple a difficult cross-domain translation problem into two easier steps. Extensive experiments verify that the face photos generated by Cali-Sketch are both photo-realistic and faithful to the input sketches, compared with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Weihao Xia and Yujiu Yang and Jing-Hao Xue},
  doi          = {10.1016/j.neucom.2021.07.029},
  journal      = {Neurocomputing},
  pages        = {256-265},
  shortjournal = {Neurocomputing},
  title        = {Cali-sketch: Stroke calibration and completion for high-quality face image generation from human-like sketches},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive trajectory tracking control for quadrotors with
disturbances by using generalized regression neural networks.
<em>NEUCOM</em>, <em>460</em>, 243–255. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this document, the development and experimental validation of a nonlinear controller with an adaptive disturbance compensation system applied on a quadrotor are presented. The introduced scheme relies on a generalized regression neural network (GRNN). The proposed scheme has a structure consisting of an inner control loop inaccessible to the user ( i.e. , an embedded controller) and an outer control loop which generates commands for the inner control loop. The adaptive GRNN is applied in the outer control loop. The proposed approach lies in the aptitude of the GRNN to estimate the disturbances and unmodeled dynamic effects without requiring accurate knowledge of the quadrotor parameters. The adaptation laws are deduced from a rigorous convergence analysis ensuring asymptotic trajectory tracking. The proposed control scheme is implemented on the QBall 2 quadrotor. Comparisons with respect to a PD-based control, an adaptive model regressor-based scheme, and an adaptive neural-network controller are carried out. The experimental results validate the functionality of the novel control scheme and show a performance improvement since smaller tracking error values are produced.},
  archive      = {J_NEUCOM},
  author       = {Ivan Lopez-Sanchez and Francisco Rossomando and Ricardo Pérez-Alcocer and Carlos Soria and Ricardo Carelli and Javier Moreno-Valenzuela},
  doi          = {10.1016/j.neucom.2021.06.079},
  journal      = {Neurocomputing},
  pages        = {243-255},
  shortjournal = {Neurocomputing},
  title        = {Adaptive trajectory tracking control for quadrotors with disturbances by using generalized regression neural networks},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic classification method of thyroid pathological
images using multiple magnification factors. <em>NEUCOM</em>,
<em>460</em>, 231–242. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Thyroid cancer is the most common form of endocrine malignancy, and the informative pathological images are critical for thyroid cancer risk stratification, prognosis and treatment guidance. Deep learning methods have achieved promising results on pathology image classification benchmarks. However, due to the complexity of thyroid carcinoma pathological images and the lack of labeled data, there are few researches study on the auto-classification of thyroid cancer. Inspired by the diagnostic process of pathologists, this paper proposes an active classification method for papillary thyroid carcinoma (PTC) pathological images classification to divide thyroid pathological images into PTC and normal thyroid pathological images. We employ the attention mechanism to combine pathological images with different magnification factors, which imitates the diagnosis procedures of thyroid cancer under the microscope. At the same time, we utilize the uncertainty and representative information provided by the convolutional neural network to determine the most valuable samples for annotation that can reduce the labeling cost. Besides, a pathological image dataset named VIP-TCHis is conducted from thyroid tissues of 55 real cases. The experimental results show that our method can obtain good performance of PTC recognition on the VIP-TCHis dataset.},
  archive      = {J_NEUCOM},
  author       = {Bing Han and Meng Zhang and Xinbo Gao and Zhe Wang and Fusheng You and Haoran Li},
  doi          = {10.1016/j.neucom.2021.07.024},
  journal      = {Neurocomputing},
  pages        = {231-242},
  shortjournal = {Neurocomputing},
  title        = {Automatic classification method of thyroid pathological images using multiple magnification factors},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Underwater image enhancement by combining color constancy
and dehazing based on depth estimation. <em>NEUCOM</em>, <em>460</em>,
211–230. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The physical properties which are present in the underwater environment affects the images captured by the visual sensors. As a consequence of these properties, the captured image includes non-uniform illumination. This non-uniform illumination cause color distortion, low contrast, white regions, and color casts. An underwater image enhancement method is proposed by combining a color constancy framework and dehazing. In the color constancy framework, both the white patch retinex and gamma correction are used to illuminate a non-hardware based balanced artificial illumination in the reference image. A chromatic adaptation technique (CAT) is adapted to correct the color cast caused by the non-uniform illumination. The color transferred image is then transformed into HSI with gamma correction in the Intensity (I)-component. This gamma correction enhances the intensity of the color transferred image. The gamma-corrected HSI image is converted to an RGB image . The dehazing is based on the estimation of artificial background light and transmission map depth. The depth is estimated from the difference of channel intensity prior (DCIP), which is the difference between the maximum and minimum intensity priors. Further, normalization of the DCIP with the histogram stretching enhances the contrast of the estimated depth . A saturation correction factor is proposed for color correction. This correction factor, estimates the artificial background light, and solves the non-uniform illumination limitations in the turbid image. A guided and rolling guidance filter is adapted to refine the estimated transmission map depth. Finally, the recovered image is transformed into HSI image with gamma correction on the I-component. The gamma-corrected HSI image is transformed to an RGB image . The recovered RGB image results with enhanced contrast and brightness. The proposed method enhances the contrast, preserves the visual information such as texture smoothing, edge-preserving, no halo effect, and decreases artifacts. We experimented the proposed method with that of the existing methods and observed that the proposed method resulted in a substantially improved image quality for the human visual perception.},
  archive      = {J_NEUCOM},
  author       = {Manigandan Muniraj and Vaithiyanathan Dhandapani},
  doi          = {10.1016/j.neucom.2021.07.003},
  journal      = {Neurocomputing},
  pages        = {211-230},
  shortjournal = {Neurocomputing},
  title        = {Underwater image enhancement by combining color constancy and dehazing based on depth estimation},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). All optical XOR logic gate formed by unsupervised optical
neuron networks. <em>NEUCOM</em>, <em>460</em>, 205–210. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a design for an all-optical logic exclusive-OR (XOR) gate in terms of intensity-modulation or phase-modulation approaches. In this study, the unsupervised optical neuron networks (ONNs) are based on reservoir computing (RC) and the echo state networks (ESNs). Thanks to the optical interfering effect in the directional coupler , it provides a nonlinear function for the reservoir computing. By scanning the phase through the phase shifter in our optical neuron networks, we find the optimized results and demonstrate the relationship between the input and output signals. The simulated results match the truth logic table in XOR gate. We also demonstrate the bit error ratio (BER) of the all-optical logic XOR gate. The BER for intensity-modulation approach is 1.55\% at 90 degree, and the phase-modulation approach is 1.78\% at 91 degree. Thus, the simulated results also indicate that the optical neuron network has potential to achieve an optical integrated circuit. If this idea could be fabricated as an optical logic device, the processing rate in the ONN is in light frequency. It will help us to process the binary data sequence more efficiently.},
  archive      = {J_NEUCOM},
  author       = {Chu-En Lin and Yueh-Heng Lu and Yu-Tung Lin and Ya-Fan Chen and Ching-Pao Sun and Chii-Chang Chen},
  doi          = {10.1016/j.neucom.2021.07.028},
  journal      = {Neurocomputing},
  pages        = {205-210},
  shortjournal = {Neurocomputing},
  title        = {All optical XOR logic gate formed by unsupervised optical neuron networks},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RapidFuzz: Accelerating fuzzing via generative adversarial
networks. <em>NEUCOM</em>, <em>460</em>, 195–204. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We implement a Generative Adversarial Network (GAN) based fuzzer called RapidFuzz to generate synthetic testcase, which can precisely catch the data structure feature in a relatively shorter time than the state-of-art fuzzers . RapidFuzz provides potential seeds generated by GAN. i.e., The generated seeds with similar but different numerical distributions accelerate the mutation process. An algorithm is elaborately designed to locate the hot-points generated by GAN. The generated testcases make structural features easier to be identified, which makes the whole process faster. In our experiment, RapidFuzz considerably improves the performance of American Fuzzy Lop(AFL) in speed, coverage, and mapsize. We select 9 open-sourced programs with different highly-structured inputs to demonstrate the effectiveness of RapidFuzz. As a result, code coverage is significantly improved. For tiff2pdf and tiffdump, coverage increase exceeds over 20\%. We also observe that RapidFuzz achieves the same coverage with less time than AFL. Furthermore, AFL absorbs 21\% of generated seed files in tiff2pdf with an average absorption rate around 15\% in other programs.},
  archive      = {J_NEUCOM},
  author       = {Aoshuang Ye and Lina Wang and Lei Zhao and Jianpeng Ke and Wenqi Wang and Qinliang Liu},
  doi          = {10.1016/j.neucom.2021.06.082},
  journal      = {Neurocomputing},
  pages        = {195-204},
  shortjournal = {Neurocomputing},
  title        = {RapidFuzz: Accelerating fuzzing via generative adversarial networks},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neurobiologically inspired mapping and navigating
framework for mobile robots. <em>NEUCOM</em>, <em>460</em>, 181–194. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the cognitive ability of the mobile robot in an unknown environment, this paper proposes an episodic memory based self-organizing learning (EM-SOL) framework for robotic experiences learning , cognitive map building and navigation. This EM-SOL framework uses the spatial cells in the hippocampus and entorhinal cortex to path integrate the robotic kinesthetic cues for dead reckoning , and meanwhile extracts the visual cues to activate state neurons for state recognition. By updating the state neurons network, this framework constructs the robotic episodic memory to store these particular experiences created along the exploration process, and achieves the robotic self-organizing learning. The framework based map building method can optimize the cumulative error by introducing the spatial cells phase reset mechanism, and build an episodic-cognitive map that describes not only the topology relationship but also the cognition relationship between these particular experiences in the environment. Furthermore, a combined topological and metric vector navigation method is presented, which can locate the robot relative to its previous experiences in the memory space, anticipate a preferred global path to the target, and guide the mobile robot to navigate to the target accurately. Finally, the proposed EM-SOL framework based methods are evaluated in both the physical environments and the standard KITTI dataset. The results show that the mobile robot can keep on learning to adapt to the changes in an unknown environment, construct valid episodic memory to store these particular learned experiences, build an episodic-cognitive map and execute the target navigation task with high efficiency and accuracy.},
  archive      = {J_NEUCOM},
  author       = {Qiang Zou and Ming Cong and Dong Liu and Yu Du},
  doi          = {10.1016/j.neucom.2021.07.025},
  journal      = {Neurocomputing},
  pages        = {181-194},
  shortjournal = {Neurocomputing},
  title        = {A neurobiologically inspired mapping and navigating framework for mobile robots},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Element graph-augmented abstractive summarization for legal
public opinion news with graph transformer. <em>NEUCOM</em>,
<em>460</em>, 166–180. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic summarization for legal public opinion news has been an attractive research problem in recent years. Compared with the open-domain, summarization for legal public opinion news has two essential constraints: (1) the key information (e.g., the case elements) of the news should be summarized; (2) the factual errors should be avoided in the generated summary. To address these challenges, the summarizer should learn a structured representation of the news (event plan), making it better to understand the event information implied in the news. This paper proposes a novel element graph-augmented abstractive summarization model, which first constructs the structural graph by extracting elements from the source document and then produces graph representation via graph transformer network. Finally, the structural representation is taken as an essential complementary component of the conventional sequence-to-sequence model to guide the decoding process simultaneously. Furthermore, the pre-trained language model is introduced to enhance the sequential and structural encoder, which further promotes the summarization model’s performance. For evaluation, we build a large-scale legal public opinion news (LPO-news) corpus. Experimental results on LPO-news and another news-oriented CNN/Daily mail dataset show that our model significantly outperforms other baselines in terms of both ROUGE scores and Bert scores. We also perform a human evaluation to demonstrate our model’s effectiveness by evaluating the generated summary using several subjective metrics.},
  archive      = {J_NEUCOM},
  author       = {Yuxin Huang and Zhengtao Yu and Junjun Guo and Yan Xiang and Yantuan Xian},
  doi          = {10.1016/j.neucom.2021.07.013},
  journal      = {Neurocomputing},
  pages        = {166-180},
  shortjournal = {Neurocomputing},
  title        = {Element graph-augmented abstractive summarization for legal public opinion news with graph transformer},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PGM-face: Pose-guided margin loss for cross-pose face
recognition. <em>NEUCOM</em>, <em>460</em>, 154–165. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-pose face recognition has been a challenging task due to the diversity and arbitrariness of the head pose. Current methods addressing this task can be divided into two categories. One is learning pose-robust face representation, and another is rotating the faces via face synthesis. Unlike the common methods, our proposed Pose-Guided Margin Loss (PGM-Face) extends the dimensions of the linear transformation matrix for each class to estimate the head poses, therefore the learned features of each class are soft clustered guided by the head pose, and the inter margin of two classes under the same pose is larger than where the face features are erratic (see Fig. 1). The similarity of the learned features is measured after transformed into the same target pose via our proposed Pose-Guided Representation Transfer Network (PGRT-Net). Compared with pose-robust face representation learning methods, our method learns more separable face features under the arbitrarily specified poses. Compared with face rotation methods, our proposed method rotates the face features instead of the face images, which can reduce the loss of identity information during the synthesis. Quantitative and qualitative experiments on several challenging databases for verification and recognition show that the proposed method achieves state-of-the-art performance, and its individual components yield substantial improvements.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Keren Fu and Cong Han and Peng Cheng and Shanmin Yang and Xiao Yang},
  doi          = {10.1016/j.neucom.2021.07.006},
  journal      = {Neurocomputing},
  pages        = {154-165},
  shortjournal = {Neurocomputing},
  title        = {PGM-face: Pose-guided margin loss for cross-pose face recognition},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerating reinforcement learning using EEG-based implicit
human feedback. <em>NEUCOM</em>, <em>460</em>, 139–153. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Providing Reinforcement Learning (RL) agents with human feedback can dramatically improve various aspects of learning. However, previous methods require human observer to give inputs explicitly (e.g., press buttons, voice interface), burdening the human in the loop of RL agent’s learning process. Further, providing explicit human advise (feedback) continuously is not always possible or too restrictive, e.g., autonomous driving , disabled rehabilitation, etc. In this work, we investigate capturing human’s intrinsic reactions as implicit (and natural) feedback through EEG in the form of error-related potentials (ErrP), providing a natural and direct way for humans to improve the RL agent learning. As such, the human intelligence can be integrated via implicit feedback with RL algorithms to accelerate the learning of RL agent. We develop three reasonably complex 2D discrete navigational games to experimentally evaluate the overall performance of the proposed work. And the motivation of using ErrPs as feedbacks is also verified by subjective experiments. Major contributions of our work are as follows, (i) we propose and experimentally validate the zero-shot learning of ErrPs, where the ErrPs can be learned for one game, and transferred to other unseen games, (ii) we propose a novel RL framework for integrating implicit human feedbacks via ErrPs with RL agent, improving the label efficiency and robustness to human mistakes, and (iii) compared to prior works, we scale the application of ErrPs to reasonably complex environments, and demonstrate the significance of our approach for accelerated learning through real user experiments.},
  archive      = {J_NEUCOM},
  author       = {Duo Xu and Mohit Agarwal and Ekansh Gupta and Faramarz Fekri and Raghupathy Sivakumar},
  doi          = {10.1016/j.neucom.2021.06.064},
  journal      = {Neurocomputing},
  pages        = {139-153},
  shortjournal = {Neurocomputing},
  title        = {Accelerating reinforcement learning using EEG-based implicit human feedback},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nondiscriminatory treatment: A straightforward framework for
multi-human parsing. <em>NEUCOM</em>, <em>460</em>, 126–138. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-human parsing aims to segment every body part of every human instance. Nearly all state-of-the-art methods follow the “detection first” or “segmentation first” pipelines. Different from them, we present an end-to-end and box-free pipeline from a new and more human-intuitive perspective. In training time, we directly do instance segmentation on humans and parts. More specifically, we introduce a notion of “indiscriminate objects with categories” which treats humans and parts without distinction and regards them both as instances with categories. In the mask prediction, each binary mask is obtained by a combination of prototypes shared among all human and part categories. In inference time, we design a brand-new grouping post-processing method that relates each part instance with one single human instance and groups them together to obtain the final human-level parsing result. We name our method as Nondiscriminatory Treatment between Humans and Parts for Human Parsing (NTHP). Experiments show that our network performs superiorly against state-of-the-art methods by a large margin on the MHP v2.0 and PASCAL-Person-Part datasets.},
  archive      = {J_NEUCOM},
  author       = {Min Yan and Guoshan Zhang and Tong Zhang and Yueming Zhang},
  doi          = {10.1016/j.neucom.2021.07.023},
  journal      = {Neurocomputing},
  pages        = {126-138},
  shortjournal = {Neurocomputing},
  title        = {Nondiscriminatory treatment: A straightforward framework for multi-human parsing},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Emotion model of associative memory possessing variable
learning rates with time delay. <em>NEUCOM</em>, <em>460</em>, 117–125.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lots of researchers have used memristors to realize the emotion model of associative memory . In previous works, researchers analyzed this associative memory from two perspectives—forgetting and variable learning rate . In the previous emotion model, neutral stimulus(message notification) and unconditioned reflex(good or bad message) were applied simultaneously. But the variable learning rate with time delay is not considered in the emotion model. When the unconditioned reflex lags behind the neutral stimulus, the associative memory can also be formed. This article proposes an emotion model of variable learning rate with time delay . We also consider three kinds of forgetting: only a stimulus of unconditioned reflex applied, only a neutral stimulus applied and neither stimulus of unconditioned reflex nor neutral stimulus applied. In the end, the software PSPICE is used to simulate the whole circuit. This paper provides an option to realize emotional learning based on memristor.},
  archive      = {J_NEUCOM},
  author       = {Linmao Yang and Chunhua Wang},
  doi          = {10.1016/j.neucom.2021.07.011},
  journal      = {Neurocomputing},
  pages        = {117-125},
  shortjournal = {Neurocomputing},
  title        = {Emotion model of associative memory possessing variable learning rates with time delay},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating emotional response by conditional variational
auto-encoder in open-domain dialogue system. <em>NEUCOM</em>,
<em>460</em>, 106–116. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important goal in open-domain dialogue research is to make chatbot generate emotional responses given a context. To achieve this, some researchers have attempted to introduce affective information into neural dialogue models. However, these neural dialogue models containing affective information still suffer from the problem of generating safe but meaningless responses, such as I don’t know , which makes users lose interest in chatting quickly. Fortunately, the latest research has proven that conditional variational auto-encoder (CVAE) can solve this problem and enhance the responses’ diversity. In this paper, we combine affective knowledge into the CVAE-based model to generate diverse and affective responses. First, we use an affective lexicon to understand each word’s emotion in the input sentences and feed the affective vector with its embedding vector together into the CVAE-based model. Next, we construct semantic and affective loss functions, enabling the model to simultaneously learn the response’s semantic and affective distributions. Additionally, we formulate a ranking rule to help rank the candidate responses according to their syntax, semantics, and affection scores, thereby enhancing the emotion and relevance while retaining the response’s diversity. Finally, we evaluate the proposed model on the DailyDialog dataset and Reddit dataset. The experimental results show that our model can generate more emotional, diverse, and context-relevant responses compared to the baselines.},
  archive      = {J_NEUCOM},
  author       = {Mengjuan Liu and Xiaoming Bao and Jiang Liu and Pei Zhao and Yuchen Shen},
  doi          = {10.1016/j.neucom.2021.07.007},
  journal      = {Neurocomputing},
  pages        = {106-116},
  shortjournal = {Neurocomputing},
  title        = {Generating emotional response by conditional variational auto-encoder in open-domain dialogue system},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale network (MsSG-CNN) for joint image and saliency
map learning-based compression. <em>NEUCOM</em>, <em>460</em>, 95–105.
(<a href="https://doi.org/10.1016/j.neucom.2021.07.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lossy image compression is likely to produce blurred images which leads to erroneous image-level understanding. The human visual system (HVS) is focused on the area of interest present in the image. Motivated by this fact, we propose a compression-decompression algorithm focusing on the important content present in different parts of the image. Using the concept of the Guided Grad-CAM (Gradient-weighted Class Activation Mapping) technique to produce heat maps with the help of a heat map generator trained on ResNet-50, a saliency-guided encoding–decoding algorithm is developed. A wider multi-scale saliency guided convolutional neural network (MsSG-CNN) is designed, in which the notion of convolution with different size filters helps to obtain unique but different features. The feature extraction followed by multilevel fusion of features helps deep neural network (DNN) to capture contextual information and obtain high quality, good resolution, visually pleasing images with fine details. The proposed algorithm is tested on the Kodak benchmark dataset, CLIC 2019 challenging dataset, and FDDB facial images dataset. At low bit rates, the MS-SSIM of the proposed algorithm is found to be superior to JPEG, JPEG2000 , BPG, WebP, and Minnen’s approaches with approximately up to 60\%, 24.80\%, 11.43\%, 23.08\% &amp; 75\% gains respectively, which is quite a significant improvement, when tested on the Kodak dataset. Similarly, at high bit rates, the improvement in MS-SSIM is approximately up to 41.67\%, 37.30\%, 23.90\% 34.21\% &amp; 13.33\% when compared with JPEG, JPEG2000 , BPG, WebP, and Minnen’s approaches respectively. The improvement in PSNR at low and high bit rates is approximately up to 11.32\%, 5\%, 5.26\% and 5.6\%, 10.29\%, 8.7\% as compared to JPEG, Balle’s, and Lee’s algorithms respectively. The PSNR-HVS has been improved by approximately up to 27.27\%, 19.15\%, and 28.33\%, 28\% as compared to JPEG and Toderici’s algorithms respectively at low and high bit-rates. A similar type of improvement is obtained with FDDB and CLIC 2019 datasets also, which is discussed in the paper.},
  archive      = {J_NEUCOM},
  author       = {Dipti Mishra and Satish Kumar Singh and Rajat Kumar Singh and Divanshu Kedia},
  doi          = {10.1016/j.neucom.2021.07.012},
  journal      = {Neurocomputing},
  pages        = {95-105},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale network (MsSG-CNN) for joint image and saliency map learning-based compression},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BERT-JAM: Maximizing the utilization of BERT for neural
machine translation. <em>NEUCOM</em>, <em>460</em>, 84–94. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training based approaches have been demonstrated effective for a wide range of natural language processing tasks. Leveraging BERT for neural machine translation (NMT), which we refer to as BERT-enhanced NMT, has received increasing interest in recent years. However, there still exists a research gap in studying how to maximize the utilization of BERT for NMT tasks. Firstly, previous studies mostly focus on utilizing BERT’s last-layer representation, neglecting the linguistic features encoded by the intermediate layers. Secondly, it requires further architectural exploration to integrate the BERT representation with the NMT encoder/decoder layers efficiently. And thirdly, existing methods keep the BERT parameters fixed during training to avoid the catastrophic forgetting problem, wasting the chances of boosting the performance via fine-tuning. In this paper, we propose BERT-JAM to fill the research gap from three aspects: 1) we equip BERT-JAM with fusion modules for composing BERT’s multi-layer representations into a fused representation that can be leveraged by the NMT model, 2) BERT-JAM utilizes joint-attention modules to allow the BERT representation to be dynamically integrated with the encoder/decoder representations, and 3) we train BERT-JAM with a three-phase optimization strategy that progressively unfreezes different components to overcome catastrophic forgetting during fine-tuning. Experimental results show that BERT-JAM achieves state-of-the-art BLEU scores on multiple translation tasks.},
  archive      = {J_NEUCOM},
  author       = {Zhebin Zhang and Sai Wu and Dawei Jiang and Gang Chen},
  doi          = {10.1016/j.neucom.2021.07.002},
  journal      = {Neurocomputing},
  pages        = {84-94},
  shortjournal = {Neurocomputing},
  title        = {BERT-JAM: Maximizing the utilization of BERT for neural machine translation},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ContrastNet: Unsupervised feature learning by autoencoder
and prototypical contrastive learning for hyperspectral imagery
classification. <em>NEUCOM</em>, <em>460</em>, 71–83. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral classification is a fundamental problem for applying hyperspectral technology, and unsupervised learning is a promising direction to address the issue. Unsupervised feature learning algorithm extracts representative features, which help efficiently classify the hyperspectral pixels. This paper combines the popular contrastive learning method (prototypical contrastive learning) and the classic representation learning method (autoencoder) to design an unsupervised feature learning network for hyperspectral classification. First, two different encoders are used to extract different features as augmentation function in a contrastive network (ContrastNet). Second, the prototypical contrastive learning method is adopted to train a contrastive network. Third, features extracted by the contrastive network are used for classification. Experiments have proved that our two proposed autoencoder networks show good feature learning capabilities by themselves and the designed contrastive learning network can further learn better representative features from the two modules. The three modules compose an efficient framework for unsupervised feature learning. Our method also performs reasonably fast in the testing phase, which implies that it is applicable in practice under specific conditions.},
  archive      = {J_NEUCOM},
  author       = {Zeyu Cao and Xiaorun Li and Yueming Feng and Shuhan Chen and Chaoqun Xia and Liaoying Zhao},
  doi          = {10.1016/j.neucom.2021.07.015},
  journal      = {Neurocomputing},
  pages        = {71-83},
  shortjournal = {Neurocomputing},
  title        = {ContrastNet: Unsupervised feature learning by autoencoder and prototypical contrastive learning for hyperspectral imagery classification},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A study on the effects of recursive convolutional layers in
convolutional neural networks. <em>NEUCOM</em>, <em>460</em>, 59–70. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To overcome problems with the design of large networks, particularly with respect to the depth of the network, this paper presents a new model of convolutional neural networks (CNN) which features fully recursive convolutional layers (RCLs). An RCL is a generalization of the classic one-stage feedforward convolutional layer (CL) to fully direct feedback connections between the outputs of the CL and its inputs. A traditional deep CNN consisting of many CLs, can then be generalized to include some CLs, and some RCLs in the intermediate stages. We call the corresponding network a Convolutional Neural Network with Fully Recursive Perceptron Network (C-FRPN). Through an analysis of results obtained from applications of the C-FRPN to three benchmark image classification datasets: CIFAR-10, SVHN, ISIC, it is found that (i) in general, the performance of a C-FRPN, even with only one RCL, is better than the performance of the corresponding deep CNN with all CLs, under the constraint of having the same number of unknown parameters; (ii) the performance of the C-FRPN varies with respect to (a) where the RCLs are located, and (b) the number of RCLs in the C-FRPN; and, (iii) the effectiveness of the RCLs depends on the size of the training dataset. The results suggest that: (a) it is advisable to use RCLs particularly when training very large sets of data, (b) it is best to prioritize placement of RCLs close to the input layer of the C-FRPN, and (c) it is advisable to increase the number of RCLs as long as the training dataset can sustain without overfitting being observed.},
  archive      = {J_NEUCOM},
  author       = {Alberto Rossi and Markus Hagenbuchner and Franco Scarselli and Ah Chung Tsoi},
  doi          = {10.1016/j.neucom.2021.07.021},
  journal      = {Neurocomputing},
  pages        = {59-70},
  shortjournal = {Neurocomputing},
  title        = {A study on the effects of recursive convolutional layers in convolutional neural networks},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Two-stream network for infrared and visible images fusion.
<em>NEUCOM</em>, <em>460</em>, 50–58. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-wave infrared(thermal) images distinguish the target and background according to different thermal radiation. They are insensitive to light conditions, and cannot present details obtained from reflected light. By contrast, the visible images have high spatial resolution and texture details, but they are easily affected by the occlusion and light conditions. Combining the advantages of the two sources may generate a new image with clear targets and high resolution, which satisfy requirements in all-weather and all-day/night conditions. Most of the existing methods cannot fully capture the underlying characteristics in the infrared and visible images, and ignore complementary information between the sources. In this paper, we propose an end-to-end model (TSFNet) for infrared and visible image fusion, which is able to handle the sources simultaneously. In addition, it adopts an adaptive weight allocation strategy to capture the informative global features. Experiments on public datasets demonstrate the proposed fusion method achieves state-of-the-art performance, in both global visual quality and quantitative comparison .},
  archive      = {J_NEUCOM},
  author       = {Luolin Liu and Mulin Chen and Mingliang Xu and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.05.034},
  journal      = {Neurocomputing},
  pages        = {50-58},
  shortjournal = {Neurocomputing},
  title        = {Two-stream network for infrared and visible images fusion},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). Adaptive multi-scale dual attention network for semantic
segmentation. <em>NEUCOM</em>, <em>460</em>, 39–49. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation in complex traffic scenes is a challenging research topic in the field of computer vision. Algorithms based on convolutional neural network has achieved more outstanding results than traditional algorithms, but their segmentation performance needs to be further improved when faced with real scenes with complex backgrounds and variable scales. In response to this issue, this study proposes a fully convolutional network architecture based on an multi-scale attention pyramid to improve the performance of the semantic segmentation algorithm from several perspectives. Firstly, a lightweight dual attention module based on depth separable convolution is designed. This module uses depth separable convolution to simplify the modeling of semantic correlation between the spatial dimension and the channel dimension, and reduces the parameter quantity of the original dual attention module. Secondly, we constructed a multi-scale attention pyramid module, which uses feature maps of different receptive fields or different scales to output multiple prediction results. Finally, an adaptive multi-scale prediction fusion module is designed. This module adaptively fuses the prediction results of multiple different receptive fields or different scales. It further enhances the network’s predictive capabilities and generates detailed high-resolution predictive maps. Compared to the baseline DANet, we have achieved better results on the Cityscapes, PASCAL VOC 2012, and COCO Stuff datasets. We make the code publicly available at https://github.com/Exception-star/AMDANet.},
  archive      = {J_NEUCOM},
  author       = {Weizhen Wang and Suyu Wang and Yue Li and Yishu Jin},
  doi          = {10.1016/j.neucom.2021.06.068},
  journal      = {Neurocomputing},
  pages        = {39-49},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multi-scale dual attention network for semantic segmentation},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Integral reinforcement learning-based optimal output
feedback control for linear continuous-time systems with input delay.
<em>NEUCOM</em>, <em>460</em>, 31–38. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an integral reinforcement learning (IRL)-based model-free optimal output-feedback (OPFB) control scheme is developed for linear continuous-time systems with input delay, where the input and past output data are employed rather than the system dynamic model . First, the equivalence between the delayed optimal control and delay-free case is analyzed. Subsequently, the system state is constructed with output signal and the Bellman equation is written in the form of past outputs. Therefore, the IRL algorithm is developed to learn the OPFB control policy, where the iterative policy is evaluated and improved simultaneously. It is proved that the obtained optimal OPFB controller gives the same solution as the optimal state-feedback. Finally, the presented simulation results illustrate the effectiveness of the developed control method .},
  archive      = {J_NEUCOM},
  author       = {Gao Wang and Biao Luo and Shan Xue},
  doi          = {10.1016/j.neucom.2021.06.073},
  journal      = {Neurocomputing},
  pages        = {31-38},
  shortjournal = {Neurocomputing},
  title        = {Integral reinforcement learning-based optimal output feedback control for linear continuous-time systems with input delay},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive conditional GAN-based augmentation for 3D object
recognition. <em>NEUCOM</em>, <em>460</em>, 20–30. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the 3D object recognition problem from the perspective of the lack of labelled data. In this paper, we propose a novel progressive conditional generative adversarial network (PC-GAN) for 3D object recognition by conditioning the input with progressive learning strategies. PC-GAN is a powerful adversarial model whose generator automatically produces realistic 3D objects with annotations, and the discriminator distinguishes them from the training distribution and recognizes their categories. We train the discriminative classifier simultaneously with the generator to predict the class label by embedding a SoftMax classifier. Progressive learning uses input samples from lower to higher resolutions to increase the generator performance gradually and produce informative objects for a certain class of objects. The key idea of adopting progressing learning is to mitigate overshoots issues of the discriminator and increase variations in the generated objects by learning progressively. This strategy helps the generator to produce more realistic synthetic objects and improve the active classification performance of the discriminator. Our proposed PC-GAN is trained for object classification in a supervised manner and the performance is evaluated on two public datasets. Experimental results demonstrate that our adversarial PC-GAN outperforms the existing volumetric discriminative classifiers in term of classification accuracy .},
  archive      = {J_NEUCOM},
  author       = {A.A.M. Muzahid and Wan Wanggen and Ferdous Sohel and Mohammed Bennamoun and Li Hou and Hidayat Ullah},
  doi          = {10.1016/j.neucom.2021.06.091},
  journal      = {Neurocomputing},
  pages        = {20-30},
  shortjournal = {Neurocomputing},
  title        = {Progressive conditional GAN-based augmentation for 3D object recognition},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A tile-fusion method for accelerating winograd convolutions.
<em>NEUCOM</em>, <em>460</em>, 9–19. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with fast convolution methods such as im2col and the fast Fourier transform , Winograd-based convolution, which has been widely applied to accelerate convolutional neural networks (CNNs), can provide high performance with smaller filters. Although there are several reported studies on the algorithmic optimization of CNNs, most of them are targeted at hardware architectures. The existing implementations of the Winograd method perform well below what one would expect, due to the fact that the tile size of Winograd-based convolution is usually empirical and the features of each convolution layer are ignored. This study aims to fill this gap and focuses on the efficient implementation of Winograd-based convolution in the CNN model. Specifically, we discuss the causes of poor performance, calculate the coefficient of computation complexity model and demonstrate a speedup in the inference process using an elaborate tile-fusion method, which derives the optimal tile size for each convolution layer in a CNN model. Compared with the representative existing implementations of CuDNN with a 4 × 4 tile, Arm Compute Library with a 6 × 6 tile, and NNPACK with an 8 × 8 tile, the results show significant performance improvements on of up to 1.89 × , 1.29 ×  and 1.17 × , respectively.},
  archive      = {J_NEUCOM},
  author       = {Zeyu Ji and Xingjun Zhang and Zheng Wei and Jingbo Li and Jia Wei},
  doi          = {10.1016/j.neucom.2021.06.003},
  journal      = {Neurocomputing},
  pages        = {9-19},
  shortjournal = {Neurocomputing},
  title        = {A tile-fusion method for accelerating winograd convolutions},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-robot competitive tracking based on k-WTA neural
network with one single neuron. <em>NEUCOM</em>, <em>460</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A k -winners-take-all ( k -WTA) neural network is designed and applied to a task assignment problem in a multi-robot competitive target tracking scenario in this paper. The proposed neural network features a single neuron and a non-hard-limiting activation function , which greatly simplifies the model structure and reduces the computation cost. This neural network has finite-time convergence property and can be applied to real-time situations. The stability and convergence property of the neural network is theoretically analyzed. Simulations of handling a situation that a target moves at a higher speed than tracking robots are conducted to demonstrate the effectiveness of the designed scheme.},
  archive      = {J_NEUCOM},
  author       = {Bo Peng and Long Jin and Mingsheng Shang},
  doi          = {10.1016/j.neucom.2021.07.020},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {Multi-robot competitive tracking based on k-WTA neural network with one single neuron},
  volume       = {460},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Imbalanced data learning by minority class augmentation
using capsule adversarial networks. <em>NEUCOM</em>, <em>459</em>,
481–493. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fact that image datasets are often imbalanced poses an intense challenge for deep learning techniques . In this paper, we propose a method to restore the balance in imbalanced images, by coalescing two concurrent methods, generative adversarial networks (GANs) and capsule network. In our model, generative and discriminative networks play a novel competitive game, in which the generator generates samples towards specific classes from multivariate probabilities distribution. The discriminator of our model is designed in a way that while recognizing the real and fake samples, it is also requires to assign classes to the inputs. Since GAN approaches require fully observed data during training, when the training samples are imbalanced, the approaches might generate similar samples which leading to data overfitting. This problem is addressed by providing all the available information from both the class components jointly in the adversarial training . It improves learning from imbalanced data by incorporating the majority distribution structure in the generation of new minority samples. Furthermore, the generator is trained with feature matching loss function to improve the training convergence. In addition, prevents generation of outliers and does not affect majority class space. The evaluations show the effectiveness of our proposed methodology; in particular, the coalescing of capsule-GAN is effective at recognizing highly overlapping classes with much fewer parameters compared with the convolutional-GAN.},
  archive      = {J_NEUCOM},
  author       = {Pourya Shamsolmoali and Masoumeh Zareapoor and Linlin Shen and Abdul Hamid Sadka and Jie Yang},
  doi          = {10.1016/j.neucom.2020.01.119},
  journal      = {Neurocomputing},
  pages        = {481-493},
  shortjournal = {Neurocomputing},
  title        = {Imbalanced data learning by minority class augmentation using capsule adversarial networks},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group incremental adaptive clustering based on neural
network and rough set theory for crime report categorization.
<em>NEUCOM</em>, <em>459</em>, 465–480. (<a
href="https://doi.org/10.1016/j.neucom.2019.10.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explosively growing online text reports are mostly unstructured in nature. Many state-of-the-art techniques involving supervised, unsupervised or semi-supervised approaches have been developed in the recent years for automatic clustering of these reports. Annotation of online crime reports is a challenging task as various types of crime reports are frequently generated over time. To the best of the authors’ knowledge, this is the first attempt taken for group incremental adaptive clustering of crime reports integrating neural network and rough set theory . The proposed work initially identifies the named entities and selects only the context words within a pair of entities as a phrase. Thus every report is described by a collection of phrases. The phrases are vectorized using GloVe and a graph based clustering algorithm is applied to cluster all the collected phrases. The phrases within a cluster are considered as the similar type of phrases, called paraphrases and each report is represented by a binary vector of dimension equal to the number of clusters obtained. If a phrase of the report lies in a cluster then a ‘1’ is set at the corresponding position of the binary vector; otherwise it is set as ‘0’. Next, an adaptive resonance theory neural network is applied on the binary vector representation of the crime reports to generate a set of clusters of crime reports. When a new group of reports is available, the reports are transformed into binary form in the similar way and the rough set theory is applied on them. It puts many reports into existing clusters and for the remaining reports, adaptive resonance theory is further applied to modify the existing clusters and possibly generate the new clusters. Thus, in the dynamic environment when data are generated gradually over time, the proposed group incremental clustering algorithm is adapted to provide the updated set of clusters. The method has been applied on various crime report datasets and validated with the help of several cluster validation indices. The method is also compared with some state-of-the-art clustering algorithms to express its effectiveness and statistical significance in the domain of crime corpora.},
  archive      = {J_NEUCOM},
  author       = {Priyanka Das and Asit Kumar Das and Janmenjoy Nayak and Danilo Pelusi and Weiping Ding},
  doi          = {10.1016/j.neucom.2019.10.109},
  journal      = {Neurocomputing},
  pages        = {465-480},
  shortjournal = {Neurocomputing},
  title        = {Group incremental adaptive clustering based on neural network and rough set theory for crime report categorization},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Least squares KNN-based weighted multiclass twin SVM.
<em>NEUCOM</em>, <em>459</em>, 454–464. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {K -nearest neighbor (KNN) based weighted multi-class twin support vector machines (KWMTSVM) is a novel multi-class classification method. In this paper, we propose a novel least squares version of KWMTSVM called LS-KWMTSVM by replacing the inequality constraints with equality constraints and minimized the slack variables using squares of 2-norm instead of conventional 1-norm. This simple modification leads to a very fast algorithm with much better results. The modified primal problems in the proposed LS-KWMTSVM solves only two systems of linear equations whereas two quadratic programming problems (QPPs) need to solve in KWMTSVM. The proposed LS-KWMTSVM, same as KWMTSVM, employed the weight matrix in the objective function to exploit the local information of the training samples. To exploit the inter class information, we use weight vectors in the constraints of the proposed LS-KWMTSVM. If any component of vectors is zero then the corresponding constraint is redundant and thus we can avoid it. Elimination of redundant constraints and solving a system of linear equations instead of QPPs makes the proposed LS-KWMTSVM more robust and faster than KWMTSVM. The proposed LS-KWMTSVM, commensurate as the KWMTSVM, all the training data points into a “1-versus-1-versus-rest” structure, and thus our LS-KWMTSVM generate ternary output { - 1 , 0 , + 1 } {-1,0,+1} which helps to deal with imbalance datasets. Numerical experiments on several UCI and KEEL imbalance datasets(with high imbalance ratio) clearly indicate that the proposed LS-KWMTSVM has better classification accuracy compared with other baseline methods but with remarkably less computational time.},
  archive      = {J_NEUCOM},
  author       = {M. Tanveer and A. Sharma and P.N. Suganthan},
  doi          = {10.1016/j.neucom.2020.02.132},
  journal      = {Neurocomputing},
  pages        = {454-464},
  shortjournal = {Neurocomputing},
  title        = {Least squares KNN-based weighted multiclass twin SVM},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical study to investigate the impact of data
resampling techniques on the performance of class maintainability
prediction models. <em>NEUCOM</em>, <em>459</em>, 432–453. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of the software systems nowadays, the trend has been shifted to object-oriented (OO) development. The classes are the central construct in an OO software that are expected to be of utmost quality and high maintainability . The maintainability of a class is the probability that a class can be effortlessly modifiable in the maintenance phase. Unfortunately, it is very tough to determine the maintainability of a class with confidence before the release of the software. However, maintainability can be predicted with the help of internal quality attributes (viz. complexity, cohesion coupling, inheritance, etc.). The researchers in the literature have studied the relation amongst the internal quality attributes and class maintainability. Many class maintainability prediction models have been developed in the past with the help of internal quality attributes. Effective prediction models are vital to forecast class maintainability accurately. However, various datasets used to build prediction models for class maintainability suffer from imbalanced data problem. In that scenario, a model trained with imbalanced data gives erroneous predictions of class maintainability, which results in the inaccurate allocation of testing and maintenance resources to the misclassified classes. Therefore towards this direction, this study assesses the applicability of techniques to take care of imbalanced data. In this study the imbalanced data is treated with nine oversampling and three undersampling methods. A comprehensive comparison of fourteen machine learning (ML) techniques and fourteen search based (SB) techniques is conducted for class maintainability prediction. The results of the study support the applicability Safe-Level Synthetic Minority Oversampling Technique (Safe-SMOTE) to handle the imbalanced data for class maintainability prediction.},
  archive      = {J_NEUCOM},
  author       = {Ruchika Malhotra and Kusum Lata},
  doi          = {10.1016/j.neucom.2020.01.120},
  journal      = {Neurocomputing},
  pages        = {432-453},
  shortjournal = {Neurocomputing},
  title        = {An empirical study to investigate the impact of data resampling techniques on the performance of class maintainability prediction models},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving the detection of robot anomalies by handling data
irregularities. <em>NEUCOM</em>, <em>459</em>, 419–431. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing complexity of robots causes failures of them as a side effect. Successful detection of anomalies in robotic systems is a key issue in order to improve their maintenance and consequently reducing economic costs and downtime. Going one step further in the detection of anomalies in robots, different mechanisms to deal with data irregularities are proposed and validated in present paper in order to increase detection rates. More precisely, strategies to overcome missing values and class imbalance are considered as complementary tools to get better one-class classification results . The effect of such strategies is evaluated through cross-validation when applying a standard supervised learning model, the Support Vector Machine . Experiments are run on an up-to-date and public dataset that contains some examples of different software anomalies that the middleware of the robot under analysis may experience.},
  archive      = {J_NEUCOM},
  author       = {Nuño Basurto and Carlos Cambra and Álvaro Herrero},
  doi          = {10.1016/j.neucom.2020.05.101},
  journal      = {Neurocomputing},
  pages        = {419-431},
  shortjournal = {Neurocomputing},
  title        = {Improving the detection of robot anomalies by handling data irregularities},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A knowledge-guide hierarchical learning method for
long-tailed image classification. <em>NEUCOM</em>, <em>459</em>,
408–418. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep visual recognition methods have achieved excellent performance on artificially constructed image datasets where the data distribution is balanced. However, in real-world scenarios, data distribution is usually extremely imbalanced and exhibit a long-tailed distribution where data in each head class is more than the class in the tail. Many efficient deep learning methods fail to work normally, i.e., they perform well in the head class while poor in the tail class. In this paper, we propose a two-layer Hierarchical-Learning Long-Tailed Recognition (HL-LTR) algorithm which transforms the long-tailed problem into a hierarchical classification problem by constructing a hierarchical superclass tree in which each layer corresponds to a recognition task. In the first layer of the tree, the degree of data imbalance is largely decreased. The recognition task of the second layer is the original long-tailed recognition problem. The training of HL-LTR is top-down. The knowledge learned by the first layer transfers to classes of the second layer and guides the feature learning of the second layer by using attention mechanism module and knowledge distillation method. Compared with directly solving the most difficult long-tailed recognition task, HL-LTR achieves better performance due to its progressive learning method from easy to difficult and effective knowledge transfer strategy.},
  archive      = {J_NEUCOM},
  author       = {Qiong Chen and Qingfa Liu and Enlu Lin},
  doi          = {10.1016/j.neucom.2021.07.008},
  journal      = {Neurocomputing},
  pages        = {408-418},
  shortjournal = {Neurocomputing},
  title        = {A knowledge-guide hierarchical learning method for long-tailed image classification},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-representation and matrix factorization based
multi-view clustering. <em>NEUCOM</em>, <em>459</em>, 395–407. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the promising clustering performance, existing self-representation based multi-view subspace clustering methods directly minimize the divergence between affinity matrices to learn the consensus affinity matrix. This does not make sense for multi-view clustering due to the facts that multi-view data are often a collection of distinct attributes of the objects, and each view includes some contents of the objects that other views do not. Thus, the learned affinity representation is sub-optimal and cannot well characterize the cluster structure. To handle this problem, drawing the inspiration from matrix factorization , which lends embedding representation to clustering interpretation, we propose a novel multi-view subspace clustering method. Our method learns affinity representation between data by joint self-representation and matrix factorization with weighted tensor Schatten p -norm constraint. Moreover, auto-weighted strategy is introduced to adaptively characterize the difference between singular values to improve the stableness of the algorithm. To further characterize class-specificity distribution, which well encodes cluster structure, we employ the ℓ 1 , 2 ℓ1,2 -norm regularization on affinity representation. Experimental results on several data sets indicate that our method outperforms state-of-the-art self-representation based multi-view subspace clustering methods .},
  archive      = {J_NEUCOM},
  author       = {Ying Dou and Yu Yun and Quanxue Gao and Xiangdong Zhang},
  doi          = {10.1016/j.neucom.2021.06.092},
  journal      = {Neurocomputing},
  pages        = {395-407},
  shortjournal = {Neurocomputing},
  title        = {Self-representation and matrix factorization based multi-view clustering},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Structural relational inference actor-critic for
multi-agent reinforcement learning. <em>NEUCOM</em>, <em>459</em>,
383–394. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-agent reinforcement learning (MARL) is essential for a wide range of high-dimensional scenarios and complicated tasks with multiple agents. Many attempts have been made for agents with prior domain knowledge and predefined structure. However, the interaction relationship between agents in a multi-agent system (MAS) in general is usually unknown, and previous methods could not tackle dynamical activities in an ever-changing environment. Here we propose a multi-agent Actor-Critic algorithm called Structural Relational Inference Actor-Critic (SRI-AC), which is based on the framework of centralized training and decentralized execution. SRI-AC utilizes the latent codes in variational autoencoder (VAE) to represent interactions between paired agents, and the reconstruction error is based on Graph Neural Network (GNN). With this framework, we test whether the reinforcement learning learners could form an interpretable structure while achieving better performance in both cooperative and competitive scenarios. The results indicate that SRI-AC could be applied to complex dynamic environments to find an interpretable structure while obtaining better performance compared to baseline algorithms.},
  archive      = {J_NEUCOM},
  author       = {Xianjie Zhang and Yu Liu and Xiujuan Xu and Qiong Huang and Hangyu Mao and Anil Carie},
  doi          = {10.1016/j.neucom.2021.07.014},
  journal      = {Neurocomputing},
  pages        = {383-394},
  shortjournal = {Neurocomputing},
  title        = {Structural relational inference actor-critic for multi-agent reinforcement learning},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fusion of multi-source retinal fundus images via automatic
registration for clinical diagnosis. <em>NEUCOM</em>, <em>459</em>,
370–382. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic retinopathy, age-related macular degeneration and glaucoma, are the leading causes of visual impairment or blindness of the population across different ages. Retinal fundus imaging is a clinically regular tool for the diagnosis of retinal diseases . In the interest of having a comprehensive understanding of the fundus condition, it is valuable to leverage multiple fundus images from different modalities. However, a direct fusion of the multi-source fundus images eases to mis-align the physiological structure or spatial position due to possible eyeball rotations or head movements. The problem turns out to be more severe if the images were corrupted by ill conditions on eyes, such as micro-bleeding and plaques. To tackle this problem, we propose a multi-source registration model for retinal fundus images. Our proposed method considers multiple correspondences and dual structural constraints during the registration process. The method firstly selects adequate feature points by an adjustable threshold selection strategy. Then a feature-guided correspondence estimation model is established to build complementary features. Finally, their spatial transformation is built by using mean shift evolution. The evolution is guided by Tikhonov regularization on dual geometric structures. It overcomes the mess of mean shift vector field and mitigating the ill-posed displacement in field recovery. We have conducted our method on the collected 220 multi-source retinal fundus image pairs, which involve minor and larger displacement or severe retinopathy lesions, as well as additive different intensities of Gaussian noises. Extensive experiments demonstrate that the proposed method consistently outperforms seven feature-based methods.},
  archive      = {J_NEUCOM},
  author       = {Tingting Dan and Yu Hu and Chu Han and Zhihao Fan and Zhuobin Huang and Bin Zhang and Guihua Tao and Baoyi Liu and Honghua Yu and Hongmin Cai},
  doi          = {10.1016/j.neucom.2021.05.091},
  journal      = {Neurocomputing},
  pages        = {370-382},
  shortjournal = {Neurocomputing},
  title        = {Fusion of multi-source retinal fundus images via automatic registration for clinical diagnosis},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial network with object detector
discriminator for enhanced defect detection on ultrasonic b-scans.
<em>NEUCOM</em>, <em>459</em>, 361–369. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-destructive testing is a set of techniques for defect detection in materials. While the set of imaging techniques is manifold, ultrasonic imaging is the one used the most. The analysis is mainly performed by human inspectors manually analyzing the acquired images. A low number of defects in real ultrasonic inspections and legal issues concerning data from such inspections make it difficult to obtain proper results from automatic ultrasonic image (B-scan) analysis. The goal of presented research is to obtain an improvement of the detection results by expanding the training data set with realistic synthetic samples. In this paper, we present a novel deep learning Generative Adversarial Network model for generating realistic ultrasonic B-scans with defects in distinct locations. Furthermore, we show that generated B-scans can be used for synthetic data augmentation, and can improve the performances of deep convolutional neural object detection networks. Our novel method was developed on a dataset with almost 4000 images and more than 6000 annotated defects. When trained only on real data, detector can achieve an average precision of 70\%. By training only on generated data the results increased to 72\%, and by mixing generated and real data we achieve almost 76\% average precision. We believe that synthetic data generation can generalize to other tasks with limited data. It could also be used for training human personnel.},
  archive      = {J_NEUCOM},
  author       = {Luka Posilović and Duje Medak and Marko Subašić and Marko Budimir and Sven Lončarić},
  doi          = {10.1016/j.neucom.2021.06.094},
  journal      = {Neurocomputing},
  pages        = {361-369},
  shortjournal = {Neurocomputing},
  title        = {Generative adversarial network with object detector discriminator for enhanced defect detection on ultrasonic B-scans},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LRDNet: A lightweight and efficient network with refined
dual attention decorder for real-time semantic segmentation.
<em>NEUCOM</em>, <em>459</em>, 349–360. (<a
href="https://doi.org/10.1016/j.neucom.2021.07.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the current popular semantic segmentation convolutional networks are focus on accuracy and require large amount of computation, which is using complex models. In order to realize real-time performance in practical applications, such as embedded systems and mobile devices, lightweight semantic segmentation has become a new need, where the network model should keep good accuracy in very limited computing budget. In this paper, we propose a lightweight network with the refined dual attention decorder (termed LRDNet) for better balance between computational speed and segmentation accuracy. In the encoding part of LRDNet, we offer an asymmetric module based on the residual network for lightweight and efficiency. In this module, a combination of decomposition convolution and deep convolution is used to improve the efficiency of feature extraction. In the decoding part of LRDNet, we use a refined dual attention mechanism to reduce the complexity of the entire network. Our network attained precise real-time segmentation results on Cityscapes, CamVid datasets. Without additional processing and pretraining, the LRDNet model achieves 70.1 Mean IoU in the Cityscapes test set. With a parameter value below 0.66 M, it can be up to 77 FPS.},
  archive      = {J_NEUCOM},
  author       = {Mingxi Zhuang and Xunyu Zhong and Dongbing Gu and Liying Feng and Xungao Zhong and Huosheng Hu},
  doi          = {10.1016/j.neucom.2021.07.019},
  journal      = {Neurocomputing},
  pages        = {349-360},
  shortjournal = {Neurocomputing},
  title        = {LRDNet: A lightweight and efficient network with refined dual attention decorder for real-time semantic segmentation},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nesting spatiotemporal attention networks for action
recognition. <em>NEUCOM</em>, <em>459</em>, 338–348. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action recognition is an important yet challenging problem. While attention mechanism is widely used to extract informative features for action recognition, most previous attention models regard spatial attention and temporal attention to be independent. In this paper, we propose a novel nesting spatiotemporal attention network (NST) model in which the spatial attention and the temporal attention closely nests and interact with each other. A nesting spatiotemporal attention block contains a spatial attention module and a nested temporal attention module. The spatial attention module learns features to assign different weights for the spatial areas in each video frame. Based on the spatial attention areas, the temporal attention module assigns different weights for different frames. In this way, the most informative regions in each frame and the most key frames in the video sequence are jointly mined and enhanced. An overall architecture is constructed by inserting the nesting spatiotemporal attention blocks into base networks for action recognition. The proposed model was tested on challenging datasets and the experimental results show that our method outperforms other comparison methods.},
  archive      = {J_NEUCOM},
  author       = {Jiapeng Li and Ping Wei and Nanning Zheng},
  doi          = {10.1016/j.neucom.2021.06.088},
  journal      = {Neurocomputing},
  pages        = {338-348},
  shortjournal = {Neurocomputing},
  title        = {Nesting spatiotemporal attention networks for action recognition},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient-PrototypicalNet with self knowledge distillation
for few-shot learning. <em>NEUCOM</em>, <em>459</em>, 327–337. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of recent few-shot learning research has been on the development of learning methods that can quickly adapt to unseen tasks with small amounts of data and low computational cost. In order to achieve higher performance in few-shot learning tasks, the generalizability of the method is essential to enable it generalize well from seen tasks to unseen tasks with limited number of samples. In this work, we investigate a new metric-based few-shot learning framework which transfers the knowledge from another effective classification model to produce well generalized embedding and improve the effectiveness in handling unseen tasks. The idea of our proposed Efficient-PrototypicalNet involves transfer learning, knowledge distillation, and few-shot learning. We employed a pre-trained model as a feature extractor to obtain useful features from tasks and decrease the task complexity. These features reduce the training difficulty in few-shot learning and increase the performance. Besides that, we further apply knowledge distillation to our framework and achieve extra performance improvement. The proposed Efficient-PrototypicalNet was evaluated on five benchmark datasets, i.e., Omniglot, mini ImageNet, tiered ImageNet, CIFAR-FS, and FC100. The proposed Efficient-PrototypicalNet achieved the state-of-the-art performance on most datasets in the 5-way K-shot image classification task, especially on the mini ImageNet dataset.},
  archive      = {J_NEUCOM},
  author       = {Jit Yan Lim and Kian Ming Lim and Shih Yin Ooi and Chin Poo Lee},
  doi          = {10.1016/j.neucom.2021.06.090},
  journal      = {Neurocomputing},
  pages        = {327-337},
  shortjournal = {Neurocomputing},
  title        = {Efficient-PrototypicalNet with self knowledge distillation for few-shot learning},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). WRTRe: Weighted relative position transformer for joint
entity and relation extraction. <em>NEUCOM</em>, <em>459</em>, 315–326.
(<a href="https://doi.org/10.1016/j.neucom.2021.06.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity and relation extraction is a critical task of information extraction in natural language processing . With fast developments of deep learning , this area has attracted great research attention. In spite of these achievements, however, due to the limited feature extraction ability of previous models, extracting overlapping and multiple relation triplets from a sentence is still an enormous challenge. Aim to this issue, here we propose a sequence-to-sequence method, which includes a weighted relative position Transformer encoder to flexibly capture the semantic relationship between entities. To prove the effectiveness of this suggested method, we conduct experiments on two publicly available datasets NYT24 and NYT29. The experimental results show that the proposed approach outperforms previous methods and achieves state-of-the-art performance. Such a framework may shed novel light into knowledge graph construction under complex situations and its potential applications.},
  archive      = {J_NEUCOM},
  author       = {Wei Zheng and Zhen Wang and Quanming Yao and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.06.071},
  journal      = {Neurocomputing},
  pages        = {315-326},
  shortjournal = {Neurocomputing},
  title        = {WRTRe: Weighted relative position transformer for joint entity and relation extraction},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Multi-scale graph attention subspace clustering network.
<em>NEUCOM</em>, <em>459</em>, 302–314. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep subspace clustering (DSC) network which uses deep auto-encoders (DAE) mapping raw data into a latent space for clustering has achieved significant performance. However, when it comes to graph-based clustering, it fails to encode the node attribute and graph structure simultaneously, which degrades the clustering performance. Meanwhile, existing graph convolutional network (GCN) based clustering methods usually do not have a clustering-oriented objection function since the process of learning representation and clustering are separated. In addition, both aforementioned methods can neither catch the multi-scale information nor use the current clustering labels effectively, which lead to the suboptimal performance. To this end, we proposed a novel end-to-end framework called Multi-Scale Graph Attention Subspace Clustering Network (MSGA). By employing a novel GCN-based feature extraction module, it can effectively capture the node representation on graph-based datasets. Moreover, a multi-scale self-expression module is designed for obtaining a more discriminative coefficient representation from each layer of the encoder and a self-supervised module is introduced for supervising the learning of node representation. Specifically, we train and optimize them in a unified framework so that different modules can benefit from each other. Extensive experiments demonstrate the superiority of our method compared with several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Tong Wang and Junhua Wu and Zhenquan Zhang and Wen Zhou and Guang Chen and Shasha Liu},
  doi          = {10.1016/j.neucom.2021.06.058},
  journal      = {Neurocomputing},
  pages        = {302-314},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale graph attention subspace clustering network},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probabilistic faster r-CNN with stochastic region proposing:
Towards object detection and recognition in remote sensing imagery.
<em>NEUCOM</em>, <em>459</em>, 290–301. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection is one of the most important tasks involved in intelligent agriculture systems, especially in pest detection. This paper focuses on a most devastated agricultural disaster: grasshopper plagues. Grasshopper detection and monitoring is of paramount importance in preventing grasshopper plagues. This paper proposes a probabilistic faster R-CNN algorithm with stochastic region proposing, where a probabilistic region proposal network, an image classification network, and an object detection network are integrated to detect and locate grasshoppers. More specifically, in the proposed framework, the probabilistic region proposal network considers attributes (e.g. size, shape) of region proposals and the image classification network identifies the existence of grasshoppers while the object detection network scores recognition confidence for a region proposal. By integrating these three networks, the uncertainty can be passed from end to end, and the final confidence is obtained for each region proposal can be explicitly quantified. To enhance algorithm robustness, a stochastic region proposing algorithm is developed to screen region proposals rather than using a predetermined threshold. The proposed algorithm is validated by recently collected grasshopper datasets. The experimental results demonstrate that the proposed algorithm not only outperforms competing algorithms in terms of average precision (0.91), average missed rate (0.36), and maximum F 1 -score (0.9263), but also reduces the false positive rate of recognising the existence of grasshoppers in an open field.},
  archive      = {J_NEUCOM},
  author       = {Dewei Yi and Jinya Su and Wen-Hua Chen},
  doi          = {10.1016/j.neucom.2021.06.072},
  journal      = {Neurocomputing},
  pages        = {290-301},
  shortjournal = {Neurocomputing},
  title        = {Probabilistic faster R-CNN with stochastic region proposing: Towards object detection and recognition in remote sensing imagery},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online learning: A comprehensive survey. <em>NEUCOM</em>,
<em>459</em>, 249–289. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online learning represents a family of machine learning methods, where a learner attempts to tackle some predictive (or any type of decision-making) task by learning from a sequence of data instances one by one at each time. The goal of online learning is to maximize the accuracy/correctness for the sequence of predictions/decisions made by the online learner given the knowledge of correct answers to previous prediction/learning tasks and possibly additional information. This is in contrast to traditional batch or offline machine learning methods that are often designed to learn a model from the entire training data set at once. Online learning has become a promising technique for learning from continuous streams of data in many real-world applications. This survey aims to provide a comprehensive survey of the online machine learning literature through a systematic review of basic ideas and key principles and a proper categorization of different algorithms and techniques. Generally speaking, according to the types of learning tasks and the forms of feedback information, the existing online learning works can be classified into three major categories: (i) online supervised learning where full feedback information is always available, (ii) online learning with limited feedback, and (iii) online unsupervised learning where no feedback is available. Due to space limitation, the survey will be mainly focused on the first category, but also briefly cover some basics of the other two categories. Finally, we also discuss some open issues and attempt to shed light on potential future research directions in this field.},
  archive      = {J_NEUCOM},
  author       = {Steven C.H. Hoi and Doyen Sahoo and Jing Lu and Peilin Zhao},
  doi          = {10.1016/j.neucom.2021.04.112},
  journal      = {Neurocomputing},
  pages        = {249-289},
  shortjournal = {Neurocomputing},
  title        = {Online learning: A comprehensive survey},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Error-feedback stochastic modeling strategy for time series
forecasting with convolutional neural networks. <em>NEUCOM</em>,
<em>459</em>, 234–248. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the superiority of convolutional neural networks demonstrated in time series modeling and forecasting, it has not been fully explored on the design of the neural network architecture and the tuning of the hyper-parameters. Inspired by the incremental construction strategy for building a random multilayer perceptron , we propose a novel Error-feedback Stochastic Modeling (ESM) strategy to construct a random Convolutional Neural Network (ESM-CNN) for time series forecasting task, which builds the network architecture adaptively. The ESM strategy suggests that random filters and neurons of the error-feedback fully connected layer are incrementally added to steadily compensate the prediction error during the construction process, and then a filter selection strategy is introduced to enable ESM-CNN to extract the different size of temporal features, providing helpful information at each iterative process for the prediction. The performance of ESM-CNN is justified on its prediction accuracy of one-step-ahead and multi-step-ahead forecasting tasks respectively. Comprehensive experiments on both the synthetic and real-world datasets show that the proposed ESM-CNN not only outperforms the state-of-art random neural networks , but also exhibits stronger predictive power and less computing overhead in comparison to trained state-of-art deep neural network models.},
  archive      = {J_NEUCOM},
  author       = {Xinze Zhang and Kun He and Yukun Bao},
  doi          = {10.1016/j.neucom.2021.06.051},
  journal      = {Neurocomputing},
  pages        = {234-248},
  shortjournal = {Neurocomputing},
  title        = {Error-feedback stochastic modeling strategy for time series forecasting with convolutional neural networks},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse estimation of linear non-gaussian acyclic model for
causal discovery. <em>NEUCOM</em>, <em>459</em>, 223–233. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We consider the problem of inferring the causal structure from observational data, especially when the structure is sparse. This type of problem is usually formulated as an inference of a Directed Acyclic Graph (DAG) model. The Linear Non-Gaussian Acyclic Model (LiNGAM) is one of the most successful DAG models, and various estimation methods have been developed. However, existing methods are not efficient for some reasons: (i) the sparse structure is not always incorporated in causal order estimation, and (ii) the information of higher-order moments of the data is not used in parameter estimation. To address these issues, we propose a new estimation method for a linear DAG model with non-Gaussian noises. The proposed method is based on a single statistical criterion that includes the log-likelihood of independent component analysis (ICA) and two penalty terms. The two penalties are related to the sparsity and the consistency condition, respectively. This criterion enables us to leverage the sparse structure and the information of higher-order moments throughout the estimation. For stable and efficient optimization, we propose some devices, such as a modified natural gradient. Numerical experiments show that the proposed method outperforms the existing methods.},
  archive      = {J_NEUCOM},
  author       = {Kazuharu Harada and Hironori Fujisawa},
  doi          = {10.1016/j.neucom.2021.06.083},
  journal      = {Neurocomputing},
  pages        = {223-233},
  shortjournal = {Neurocomputing},
  title        = {Sparse estimation of linear non-gaussian acyclic model for causal discovery},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One dimensional convolutional neural networks for seizure
onset detection using long-term scalp and intracranial EEG.
<em>NEUCOM</em>, <em>459</em>, 212–222. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epileptic seizure detection using scalp electroencephalogram (sEEG) and intracranial electroencephalogram (iEEG) has attracted widespread attention in recent two decades. The accurate and rapid detection of seizures not only reflects the efficiency of the algorithm, but also greatly reduces the burden of manual detection during long-term electroencephalogram (EEG) recording. In this work, a stacked one-dimensional convolutional neural network (1D-CNN) model combined with a random selection and data augmentation (RS-DA) strategy is proposed for seizure onset detection. Firstly, we segmented the long-term EEG signals using 2-s sliding windows. Then, the 2-s interictal and ictal segments were classified by the stacked 1D-CNN model. During model training, a RS-DA strategy was applied to solve the problem of sample imbalance, and the patient-specific model was trained with event-based K -fold ( K is the number of seizures per patient) cross validation for detecting all seizures of each patient. Finally, we evaluated the performances of the proposed approach in the two levels: the segment-based level and the event-based level. The proposed method was tested on two long-term EEG datasets: the CHB-MIT sEEG dataset and the SWEC-ETHZ iEEG dataset. For the CHB-MIT sEEG dataset, we achieved 88.14\% sensitivity, 99.62\% specificity and 99.54\% accuracy in the segment-based level. From the perspective of the event-based level, 99.31\% sensitivity, 0.2/h false detection rate (FDR) and mean 8.1-s latency were achieved. For the SWEC-ETHZ iEEG dataset, in the segment-based level, 90.09\% sensitivity, 99.81\% specificity and 99.73\% accuracy were obtained. In the event-based level, 97.52\% sensitivity, 0.07/h FDR and mean 13.2-s latency were attained. From these results, we can see that our method can effectively use both sEEG and iEEG data to detect epileptic seizures, and this may provide a reference for the clinical application of seizure onset detection.},
  archive      = {J_NEUCOM},
  author       = {Xiaoshuang Wang and Xiulin Wang and Wenya Liu and Zheng Chang and Tommi Kärkkäinen and Fengyu Cong},
  doi          = {10.1016/j.neucom.2021.06.048},
  journal      = {Neurocomputing},
  pages        = {212-222},
  shortjournal = {Neurocomputing},
  title        = {One dimensional convolutional neural networks for seizure onset detection using long-term scalp and intracranial EEG},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DVFENet: Dual-branch voxel feature extraction network for 3D
object detection. <em>NEUCOM</em>, <em>459</em>, 201–211. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection based on LiDAR point cloud has wide applications in autonomous driving and robotics. Recently, many approaches use voxelization representation in feature extraction and apply 3D convolution neural networks for 3D object detection . How to get expressive 3D voxelization representation is important for the detection performance. Therefore, we propose a new 3D object detection framework (DVFENet) based on dual-branch voxel feature extraction, which can provide rich and complete 3D information. The first branch is a graph-attention-network-based voxel feature extraction, which applies an improved voxel graph attention feature extractor (VGAFE) on large-scale voxelization. This branch uses graph convolution networks with an attention mechanism to extract more local neighborhood and context information. The second branch is a 3D-sparse-convolution-based voxel feature extraction that captures finer geometric features based on small-scale voxelization. We also design a decoupled RPN module that can obtain task-specific features to reduce the task conflict. Experiments on the challenging KITTI 3D object detection benchmark and nuScenes detection task show that our method achieve good performance. At the same time, we conduct extensive experiments to verify the effectiveness of each component.},
  archive      = {J_NEUCOM},
  author       = {Yunqian He and Guihua Xia and Yongkang Luo and Li Su and Zhi Zhang and Wanyi Li and Peng Wang},
  doi          = {10.1016/j.neucom.2021.06.046},
  journal      = {Neurocomputing},
  pages        = {201-211},
  shortjournal = {Neurocomputing},
  title        = {DVFENet: Dual-branch voxel feature extraction network for 3D object detection},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Type-2 fuzzy broad learning controller for wastewater
treatment process. <em>NEUCOM</em>, <em>459</em>, 188–200. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affected by multiple operation conditions, wastewater treatment process (WWTP) is a complex industrial process with strong nonlinearity and disturbance. How to enhance the rapid tracking response-ability and robustness of the controller is still a challenge when the operation conditions change. To solve this problem, a type-2 fuzzy broad learning controller (T2FBLC) is proposed in this paper. First, a type-2 fuzzy broad learning system (T2FBLS) is constructed in T2FBLC by replacing nodes in feature window with a group of interval type-2 fuzzy submodules. Then, the proposed T2FBLC can take tracking error as inputs while its outputs acting on WWTP to directly obtain a control law, and the controller makes a quick tracking response in different operation conditions. Second, the weight parameters of T2FBLC are adjusted by using the gradient descent method to ensure the control performance. In this way, the developed T2FBLC can realize online learning to reduce tracking errors. Third, according to the Lyapunov function theory, the stability of control strategy is proved. Finally, benchmark simulation model 1 (BSM1) is adopted to verify the effectiveness of T2FBLC. The experimental results prove the applicability and superior tracking performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hong-Gui Han and Fei-Fan Yang and Hong-Yan Yang and Xiao-Long Wu},
  doi          = {10.1016/j.neucom.2021.06.074},
  journal      = {Neurocomputing},
  pages        = {188-200},
  shortjournal = {Neurocomputing},
  title        = {Type-2 fuzzy broad learning controller for wastewater treatment process},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing two-view correspondence learning by local-global
self-attention. <em>NEUCOM</em>, <em>459</em>, 176–187. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seeking reliable correspondences is a fundamental and significant work in computer vision. Recent work has demonstrated that the task can be effectively accomplished by utilizing a deep learning network based on multi-layer perceptrons , which uses the context normalization to deal with the input. However, the context normalization treats each correspondence equally, which will reduce the representation capability of potential inliers. To solve this problem, we propose a novel and effective Local-Global Self-Attention (LAGA) layer based on the self-attention mechanism, to capture contextual information of potential inliers from coarse to fine, and suppress outliers at the same time in processing the input. The global self-attention module is able to capture abundant global contextual information in the whole image, and the local self-attention module is used to obtain rich local contextual information in the local region. After that, to obtain richer contextual information and feature maps with stronger representative capacity, we combine global and local contextual information. The extensive experiments have shown that the networks with our proposed LAGA layer perform better than the original and other comparative networks in outdoor and indoor scenes for outlier removal and camera pose estimation tasks.},
  archive      = {J_NEUCOM},
  author       = {Luanyuan Dai and Xin Liu and Yizhang Liu and Changcai Yang and Lifang Wei and Yaohai Lin and Riqing Chen},
  doi          = {10.1016/j.neucom.2021.06.084},
  journal      = {Neurocomputing},
  pages        = {176-187},
  shortjournal = {Neurocomputing},
  title        = {Enhancing two-view correspondence learning by local-global self-attention},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault identification and fault-tolerant control for unmanned
autonomous helicopter with global neural finite-time convergence.
<em>NEUCOM</em>, <em>459</em>, 165–175. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the issue of global neural finite-time fault-tolerant control (FTC) is investigated for the medium-scale unmanned autonomous helicopter (UAH). To recognize the actuator bias and loss of effectiveness (LOE) faults, a novel fault detection and identification (FDI) strategy is proposed, which consists of a fault detection observer, two adaptive fault observers and a decision-making algorithm. The neural network (NN) technique is employed to deal with the unknown system uncertainty. In view of the backstepping approach and Lyapunov theory , a finite-time FTC scheme is developed to assure that all closed-loop system tracking errors converge to a small range of zero after a limited amount of time. Meanwhile, by integrating a switching mechanism into the control design, the traditional semi-globally uniformly ultimately bounded (SGUUB) stability is extended to globally uniformly ultimately bounded (GUUB) stability, such that the constraints on initial conditions of the NN controller is moderated. Simulation studies are implemented to demonstrate the usefulness of the presented controller.},
  archive      = {J_NEUCOM},
  author       = {Kun Yan and Hai-Peng Ren},
  doi          = {10.1016/j.neucom.2021.06.081},
  journal      = {Neurocomputing},
  pages        = {165-175},
  shortjournal = {Neurocomputing},
  title        = {Fault identification and fault-tolerant control for unmanned autonomous helicopter with global neural finite-time convergence},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clustering-driven deep adversarial hashing for scalable
unsupervised cross-modal retrieval. <em>NEUCOM</em>, <em>459</em>,
152–164. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of the big data era, multimedia data is growing rapidly, and its data modalities is also becoming diversified. Therefore, the demand for the speed and accuracy of cross-modal information retrieval is increasing. Hashing-based cross-modal retrieval technology attracts widespread attention, it encodes multimedia data into a common binary hash space, thereby effectively measuring the correlation between samples from different modalities. In this paper, we propose a novel end-to-end deep cross-modal retrieval framework, namely Clustering-driven Deep Adversarial Hashing (CDAH), which has three main characteristics. Firstly, CDAH learns discriminative clusters recursively through a soft clustering model. It attempts to generate modal-invariant representations in a common space by obfuscating the modality classifier, which tries to distinguish different modalities according to the generated representations. Secondly, in order to minimize the modal gap between feature representations from different modalities with the same semantic label , and to maximize the distance between images and texts with different labels, CDAH constructs a fused-semantics matrix to integrate the original domain information from different modalities, serving as self-supervised information to refine the binary codes. Finally, CDAH skillfully uses a scaled tanh function to adaptively learn the binary codes, which will gradually converge to the original tricky binary coding problem. We conduct comprehensive experiments on four popular datasets, and the experimental results demonstrate the superiority of our model against the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiao Shen and Haofeng Zhang and Lunbo Li and Zheng Zhang and Debao Chen and Li Liu},
  doi          = {10.1016/j.neucom.2021.06.087},
  journal      = {Neurocomputing},
  pages        = {152-164},
  shortjournal = {Neurocomputing},
  title        = {Clustering-driven deep adversarial hashing for scalable unsupervised cross-modal retrieval},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SKR-QA: Semantic ranking and knowledge revise for
multi-choice question answering. <em>NEUCOM</em>, <em>459</em>, 142–151.
(<a href="https://doi.org/10.1016/j.neucom.2021.06.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge has long been cosnsidered a crucial part of natural language understanding . Many knowledge bases have been constructed, but none of them will ever be complete. Nevertheless, we argue that complete knowledge already exists in natural language. Most previous work on question answering retrieved such knowledge using traditional statistical methods, and consequently, the knowledge retrieved contained co-occurring phrases and could not provide guidance for model understanding and reasoning. Therefore, in addition to demonstrating the effectiveness of natural language knowledge in machine understanding, this study presents a novel knowledge retrieval approach that evaluates the importance of knowledge from a semantic perspective. Furthermore, we propose a knowledge revise mechanism that allows the model to revise the retrieved knowledge from local and global perspectives. We demonstrate our Semantic-rank-and-Knowledge-Revise-based Question Answering (SKR-QA) approach on two challenging multi-choice question and answering tasks: ARC–Challenge and OpenbookQA. Compared with the previous State-of-the-Art (SOTA) models, our work achieves consistent improvements. Moreover, the knowledge obtained by our method is more conducive to machine understanding, thus providing certain interpretability .},
  archive      = {J_NEUCOM},
  author       = {Mucheng Ren and Heyan Huang and Yang Gao},
  doi          = {10.1016/j.neucom.2021.06.076},
  journal      = {Neurocomputing},
  pages        = {142-151},
  shortjournal = {Neurocomputing},
  title        = {SKR-QA: Semantic ranking and knowledge revise for multi-choice question answering},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High frequency patterns play a key role in the generation of
adversarial examples. <em>NEUCOM</em>, <em>459</em>, 131–141. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have made significant progress in many fields, but the black-box nature hinders their application in critical areas. The emergence of adversarial examples raises serious questions about the safety of neural networks particularly. The interpretability of neural networks has become a research hotspot in the field of deep learning . It is significant to study what features DNNs have learned and how these features evolve within DNNs. Taking adversarial examples as the research object, we find that feature activations of all categories have relatively stable expectations at each layer, and adversarial examples have undergone a feature trajectory from origins to targets, generating the feature activations similar to those of the target category. Using image frequency spectrum, we prove that adversarial examples are mainly caused by the formation of high-frequency patterns widely present in the target category images. The conclusions of this paper contribute to a deeper understanding of feature learning and the generation of adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Yue Zhou and Xiaofang Hu and Jiaqi Han and Lidan Wang and Shukai Duan},
  doi          = {10.1016/j.neucom.2021.06.078},
  journal      = {Neurocomputing},
  pages        = {131-141},
  shortjournal = {Neurocomputing},
  title        = {High frequency patterns play a key role in the generation of adversarial examples},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Emotion-sensitive deep dyna-q learning for task-completion
dialogue policy learning. <em>NEUCOM</em>, <em>459</em>, 122–130. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, task-oriented dialogue systems have received extensive attention from academia and industry. Training a dialogue agent through reinforcement learning is often costly because it requires many interactions with real users. Although the Deep Dyna-Q (DDQ) framework uses simulation experience to alleviate the cost of direct reinforcement learning , it still suffers from challenges such as delayed rewards and policy degradation. This paper proposes an Emotion-Sensitive Deep Dyna-Q (ES-DDQ) model which: (1) presents an emotional world model that considers emotion-related cues to improve the ability of the traditional DDQ framework to model and simulate users, and (2) designs two kinds of emotion-related immediate rewards to mitigate the delayed reward problem. Experimental results show that our proposed approach effectively simulates users’ behaviors and is superior to the state-of-the-art benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Rui Zhang and Zhenyu Wang and Mengdan Zheng and Yangyang Zhao and Zhenhua Huang},
  doi          = {10.1016/j.neucom.2021.06.075},
  journal      = {Neurocomputing},
  pages        = {122-130},
  shortjournal = {Neurocomputing},
  title        = {Emotion-sensitive deep dyna-Q learning for task-completion dialogue policy learning},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EDENet: Elaborate density estimation network for crowd
counting. <em>NEUCOM</em>, <em>459</em>, 108–121. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the CNN-based density estimation approaches in the field of crowd counting, how to generate a high-quality density map with accurate counting performance and detailed spatial description is still an open question. In this paper, to tackle the aforementioned contradiction, we propose an end-to-end trainable architecture called Elaborate Density Estimation Network for Crowd Counting (EDENet), which can gradually generate high-quality density estimation maps based on distributed supervision. Specifically, EDENet is composed of Feature Extraction Network (FEN), Feature Fusion Network (FFN), Double-Head Network (DHN) and Adaptive Density Fusion Network (ADFN). The FEN adopts VGG as the backbone network and employs Spatial Adaptive Pooling (SAP) to extract coarse-grained features. The FFN can effectively fuse contextual information and localization information for enhancing the spatial description ability of fine-grained features. In the DHN, the Density Attention Module (DAM) can provide attention masks of foreground-background, thereby urging the Density Regression Module (DRM) to focus on the pixels around the head annotations to regress density maps with different resolutions. The ADFN constructed on the basis of the adaptive weighting mechanism can directly introduce coarse-grained density representation into high-resolution density maps to strengthen the commonality and dependency among density maps. Extensive experiments on four benchmark crowd datasets (the ShanghaiTech, the UCF-QNRF, the JHU-CRWORD++ and the NWPU-Crowd) indicate that EDENet can achieve state-of-the-art recognition performance and high robustness. Not only that, the density map with the highest Peak Signal to Noise Ratio (PSNR) can be considered to be of high quality.},
  archive      = {J_NEUCOM},
  author       = {Yinfeng Xia and Yuqiang He and Sifan Peng and Xiaoliang Hao and Qianqian Yang and Baoqun Yin},
  doi          = {10.1016/j.neucom.2021.06.086},
  journal      = {Neurocomputing},
  pages        = {108-121},
  shortjournal = {Neurocomputing},
  title        = {EDENet: Elaborate density estimation network for crowd counting},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CoreGen: Contextualized code representation learning for
commit message generation. <em>NEUCOM</em>, <em>459</em>, 97–107. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic generation of high-quality commit messages for code commits can substantially facilitate software developers’ works and coordination. However, the semantic gap between source code and natural language poses a major challenge for the task. Several studies have been proposed to alleviate the challenge but none explicitly involves code contextual information during commit message generation. Specifically, existing research adopts static embedding for code tokens, which maps a token to the same vector regardless of its context . In this paper, we propose a novel Co ntextualized code re presentation learning strategy for commit message Gen eration (CoreGen). CoreGen first learns contextualized code representations which exploit the contextual information behind code commit sequences. The learned representations of code commits built upon Transformer are then fine-tuned for downstream commit message generation. Experiments on the benchmark dataset demonstrate the superior effectiveness of our model over the baseline models with at least 28.18\% improvement in terms of BLEU-4 score. Furthermore, we also highlight the future opportunities in training contextualized code representations on larger code corpus as a solution to low-resource tasks and adapting the contextualized code representation framework to other code-to-text generation tasks.},
  archive      = {J_NEUCOM},
  author       = {Lun Yiu Nie and Cuiyun Gao and Zhicong Zhong and Wai Lam and Yang Liu and Zenglin Xu},
  doi          = {10.1016/j.neucom.2021.05.039},
  journal      = {Neurocomputing},
  pages        = {97-107},
  shortjournal = {Neurocomputing},
  title        = {CoreGen: Contextualized code representation learning for commit message generation},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). X-net: Multi-branch UNet-like network for liver and tumor
segmentation from 3D abdominal CT scans. <em>NEUCOM</em>, <em>459</em>,
81–96. (<a href="https://doi.org/10.1016/j.neucom.2021.06.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diagnosis of liver cancer is one of the most attractive fields in clinical practice for its high mortality. Accurate segmentation of liver and tumor has been publicly accepted to be an effective method to assist doctors in determining the disease condition and planning the subsequent treatments. Recently, deep learning based methods have been widely used in tumor segmentation and provided good performance. However, current methods cannot fully reflect the differences between tumor, inside-liver tissues and outside-liver organs simultaneously, while the extraction of features reflecting axial changes of liver and tumor is always discounted by the heavy computational burden, resulting in limited learning effects and efficiencies. To solve these problems, in this paper, we propose a novel framework to segment liver and tumors in abdominal CT volumes, which consists of two parts: 1) we propose a multi-branch network where an up-sampling branch for liver region recognition and a pyramid-like convolution structure for inner-liver feature extraction are integrated into the back-bone Dense UNet structure for better extracting intra-slice features of liver and tumors; 2) we simplify the traditional 3D UNet by using the convolutional kernels with the fixed size 3 × 3 3×3 in x-y plane and apply it as a 3D counterpart for aggregating contextual information along the z-axis from the stacked, filtered CT slices, with the advantages of inhibiting the influence from neighboring pixels and alleviating the computational burden greatly. The above two parts are formulated as a unified end-to-end network so that the intra-slice feature representation and the inter-slice information aggregation can be learned and optimized jointly. Furthermore, we novely define a loss function combining a modified dice loss and a contour-detection based loss, so that the region features and contour features of the predicted segmentation of liver and tumors are jointly considered for network training and parameters optimization. Experimental results on the MICCAI 2017 Liver Tumor Segmentation Challenge dataset and 3DIRCADb dataset have demonstrated that the proposed method can provide superior performance to the state-of-the-art methods with respect to the certain benchmarks for liver and tumor segmentation.},
  archive      = {J_NEUCOM},
  author       = {Jianning Chi and Xiaoying Han and Chengdong Wu and Huan Wang and Peng Ji},
  doi          = {10.1016/j.neucom.2021.06.021},
  journal      = {Neurocomputing},
  pages        = {81-96},
  shortjournal = {Neurocomputing},
  title        = {X-net: Multi-branch UNet-like network for liver and tumor segmentation from 3D abdominal CT scans},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CNN-based visual processing approach for biological sample
microinjection systems. <em>NEUCOM</em>, <em>459</em>, 70–80. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vitro microinjection is one of the main approaches to deliver the specimens to the target. However, conventional microinjection is mostly operated by very experienced technicians and the successful rate is relatively low. Moreover, the manual injection process is also very time consuming and tiring because extra attention needs to be paid for precise operation. As a result, the workers suffer from fatigue and the efficiency remains low. To improve the efficiency, researchers have developed automated microinjection systems to free the technicians from this laborious work. Zebrafish has been more popular than ever for the last decade due to its genetic advantages. It is claimed that the gene of Zebrafish highly resembles to human, which results in the fact that more biological and medical practice has been carried out with Zebrafish larvae or embryos. This paper proposes an innovation convolutional neural network based visual processing strategy for biological sample manipulation and microinjection systems. The proposed approach allows high throughput injection with considerable injecting precision. The strategy is to firstly locate a number of biological samples in the visual field, then the proposed visual algorithm identifies the number of the samples and detects the orientation of each sample. After which the samples are rotated one after another by a rotation plate to the desired angle for injection. An optimized rotation strategy is performed to achieve minimum total rotation angle . A path free of collision is also generated by A-star algorithm for the holding pipette. The experiment results show significant improvement in orientation efficiency and the accuracy of multi-sample rotation is enhanced to some extent.},
  archive      = {J_NEUCOM},
  author       = {Cheng Qian and Mingsi Tong and Xinghu Yu and Songlin Zhuang},
  doi          = {10.1016/j.neucom.2021.06.085},
  journal      = {Neurocomputing},
  pages        = {70-80},
  shortjournal = {Neurocomputing},
  title        = {CNN-based visual processing approach for biological sample microinjection systems},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Intermittent dynamic event-triggered state estimation for
delayed complex networks based on partial nodes. <em>NEUCOM</em>,
<em>459</em>, 59–69. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the intermittent dynamic event-based state estimation problem is investigated for a class of delayed complex dynamic networks (CDNs). The estimate is implemented based on the measurements from a fraction of network nodes. In the framework of aperiodic intermittent measurement outputs, a dynamic event-triggered mechanism is introduced to save communication resources and reduce actuation burden. The aim of this work is to design a dynamic event-based state estimator by adopting intermittent dynamic event-triggered (IDET) strategy, such that the dynamics of estimation error system is exponentially stable. By resorting to Halanay inequality and switched system method, the sufficient conditions are derived for ensuring the existence of the desired state estimator, and are characterized by the ratio of the average working time to the average rest time. In the meanwhile, the estimator gains for partial nodes are explicitly obtained by solving some matrix inequalities. Furthermore, it is also proven that Zeno behavior can be excluded under the proposed IDET strategy. Finally, a numerical simulation is provided to verify the effectiveness of the derived results.},
  archive      = {J_NEUCOM},
  author       = {Luyang Yu and Yurong Liu and Ying Cui and Naif D. Alotaibi and Fawaz E. Alsaadi},
  doi          = {10.1016/j.neucom.2021.06.017},
  journal      = {Neurocomputing},
  pages        = {59-69},
  shortjournal = {Neurocomputing},
  title        = {Intermittent dynamic event-triggered state estimation for delayed complex networks based on partial nodes},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Routing optimization meets machine intelligence: A
perspective for the future network. <em>NEUCOM</em>, <em>459</em>,
44–58. (<a href="https://doi.org/10.1016/j.neucom.2021.06.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The future network is expected to support extremely large bandwidth, ultra-low latency or deterministic delay, extremely high reliability, and massive connectivity for novel forward-looking scenarios. As one of the most fundamental parts of the network, routing plays a vital role in a well-performed network. Recently, some new techniques using machine intelligence to optimize the network routing have been proposed. Although they have demonstrated great potential to improve the network performance, it is still a great challenge to apply machine intelligence-based routing in real network environment due to the limitations of current network architectures and protocols. Fortunately, the future network research program is on-going for designing new network paradigms, which provides an opportunity to address those limitations. In this paper, we investigate state-of-the-art techniques in machine intelligence-enabled network routing and discuss the development trends of machine intelligence-enabled routing optimization techniques for the future network.},
  archive      = {J_NEUCOM},
  author       = {Bin Dai and Yuanyuan Cao and Zhongli Wu and Zhewei Dai and Ruyi Yao and Yang Xu},
  doi          = {10.1016/j.neucom.2021.06.093},
  journal      = {Neurocomputing},
  pages        = {44-58},
  shortjournal = {Neurocomputing},
  title        = {Routing optimization meets machine intelligence: A perspective for the future network},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A smartly simple way for joint crowd counting and
localization. <em>NEUCOM</em>, <em>459</em>, 35–43. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A growing number of state-of-the-art crowd counting methods employ the regression model. Such a model learns a person-density map first and its integral is further calculated to obtain the final count. However, this learned density map is uninterpretable and could deviate largely from the true person distribution even when the final count is accurate. In comparison, we present a conceptually interpretable and technically simple classification model for crowd counting, which consists of three novel modules: Deep Integrated Module (DIM), Scale Adaptive Module (SAM), and Interval Aware Module (IAM). Different from the traditional density map, the proposed pedestrian-aware density map (PADM) in our model can reveal the true people density, and meanwhile tackle the rarely-explored crowd localization task simultaneously. The proposed joint crowd counting and localization method does not require extra pretraining or fine-tuning for individual components of the network, and we train our model end-to-end in a single step. Without bells and whistles but a few lines of code, our simple yet effective method achieves better performances on both crowd counting and localization tasks when compared with state-of-the-art methods. The code is available online.},
  archive      = {J_NEUCOM},
  author       = {Minyang Jiang and Jianzhe Lin and Z. Jane Wang},
  doi          = {10.1016/j.neucom.2021.06.055},
  journal      = {Neurocomputing},
  pages        = {35-43},
  shortjournal = {Neurocomputing},
  title        = {A smartly simple way for joint crowd counting and localization},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Context-aware visual abstraction of crowded parallel
coordinates. <em>NEUCOM</em>, <em>459</em>, 23–34. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As the size of dataset increases, it has become a difficult task to explore structures of interest from crowded parallel coordinates due to visual clutter. Numerous methods have been proposed to simplify the visualization of crowded parallel coordinates, such as filtering, bundling and sampling. However, contextual structures are hardly preserved in the course of simplification, which make significant features easily lost in the simplified parallel coordinates. In this paper, we propose a context-aware visual sampling method for the exploration of crowded parallel coordinates. A Doc2Vec model, widely used in the field of Natural Language Processing (NLP), is utilized to represent the contextual structures across a series of attribute axes with quantifiable vectors. Then, an adaptive blue noise sampling model is employed to reduce the size of original dataset in the vectorized space, guarantying that data items with different contextual structures would be retained in the simplified parallel coordinates. A set of meaningful visual interfaces are designed, enabling users to easily capture the contextual features and evaluate the sampled parallel coordinates. Case studies based on real-world datasets and quantitative comparison have demonstrated the effectiveness of our method in the simplification of crowded parallel coordinates and the exploration of large scale multi-dimensional datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhiguang Zhou and Yuming Ma and Yong Zhang and Yanan Liu and Yuhua Liu and Lin Zhang and Shengchun Deng},
  doi          = {10.1016/j.neucom.2021.05.005},
  journal      = {Neurocomputing},
  pages        = {23-34},
  shortjournal = {Neurocomputing},
  title        = {Context-aware visual abstraction of crowded parallel coordinates},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Community structure exploration considering latent link
patterns in complex networks. <em>NEUCOM</em>, <em>459</em>, 10–22. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection using statistical models is a promising research area in network analysis. Most existing statistical models for this task cannot be fitted well for various community structures. In this paper, we propose a model incorporating the latent link patterns for detecting effectively various community structures. It can automatically discover the number and the sizes of communities by grouping the vertices owning the same latent link pattern, which is meaningful and explainable. An inference approach based on collapsed Gibbs sampling is proposed to estimate the parameters of our model. Experiments on 13 real-world networks demonstrate our model outperforms four state-of-the-art approaches on most of the datasets and is competent to explore various community structures. In addition, our model can detect some hidden link patterns that offer extra information for network analysis.},
  archive      = {J_NEUCOM},
  author       = {Jing Wang and Kan Li},
  doi          = {10.1016/j.neucom.2021.06.032},
  journal      = {Neurocomputing},
  pages        = {10-22},
  shortjournal = {Neurocomputing},
  title        = {Community structure exploration considering latent link patterns in complex networks},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). JTSG: A joint term-sentiment generator for aspect-based
sentiment analysis. <em>NEUCOM</em>, <em>459</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on two related sub-tasks of aspect-based sentiment analysis, namely aspect-term extraction and aspect sentiment classification. The former aims to extract aspect-terms from given sentences and the latter aims to identify the sentiment polarity expressed on the extracted terms. Considering the practical application, researchers use more joint methods rather than pipeline methods. However, existing joint methods cannot model the interaction between aspect-terms and the sentence they belong to, or consider the relevance among the sentiments of different aspect-terms. In this paper, a novel end-to-end generative model based on encoder-decoder, namely Joint Term-Sentiment Generator (JTSG), is presented to generate all aspect term-polarity pairs. Specifically, a pre-trained model based encoder is used to encode the sentences, and specially, the decoder generates the start and end position to determine an aspect-term, rather than generate aspect-terms themselves. This new generative method contributes to avoid generating incomplete aspect-terms. Experimental results demonstrate that the proposed approach yields competitive performance on three benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Zuocheng Li and Lishuang Li and Anqiao Zhou and Hongbin Lu},
  doi          = {10.1016/j.neucom.2021.06.045},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {JTSG: A joint term-sentiment generator for aspect-based sentiment analysis},
  volume       = {459},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weighted dual hesitant fuzzy set and its application in
group decision making. <em>NEUCOM</em>, <em>458</em>, 714–726. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dual hesitant fuzzy set(DHFS) is a useful tool to deal with situations in which people are hesitant about providing their satisfaction degree and dissatisfaction degree. In this paper, we introduce the concepts of weighted dual hesitant fuzzy set(WDHFS) and weighted dual hesitant fuzzy element(WDHFE). Furthermore, we introduce some basic operations such as union, intersection, complement, multiplication and power operation of weighted dual hesitant fuzzy elements, investigate their operation properties, propose the score function and the accuracy function of WDHFE to compare two weighted dual hesitant fuzzy elements, and present two kinds of aggregation operators such as WDHFWA operator and WDHFWG operator to fuse weighted dual hesitant fuzzy information. Besides, we introduce the concept of hesitance degree of WDHFE, and propose a distance measure between weighted dual hesitant fuzzy elements based on the feature vector of WDHFE, which satisfies the four properties including triangle inequality . In addition, we develop an approach to group decision making based on the weighted dual hesitant fuzzy environment. Finally, two numerical examples are used to illustrate the effectiveness and practicality of our proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Wenyi Zeng and Yue Xi and Qian Yin and Ping Guo},
  doi          = {10.1016/j.neucom.2020.07.134},
  journal      = {Neurocomputing},
  pages        = {714-726},
  shortjournal = {Neurocomputing},
  title        = {Weighted dual hesitant fuzzy set and its application in group decision making},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous neural metric learning for spatio-temporal
modeling of infectious diseases with incomplete data. <em>NEUCOM</em>,
<em>458</em>, 701–713. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infectious disease data, recording the numbers of infection cases in different locations and time, is one of the most typical categories of spatio-temporal data and plays an important role in the infectious disease control and prevention. However, due to the insufficient resources and manpower, the observations and records of infection cases are inevitably missing in some locations and time, which brings difficulties to the accurate risk assessment and timely disease control. Imputing the missing infectious disease data is challenging as the infectious disease diffusion can be potentially caused and affected by many risk factors. To address the above-mentioned challenges, a novel machine learning method, Heterogeneous Neural Metric Learning (HNML), is developed to restore the integrity of case reporting data using both the incomplete reported cases and the underlying disease-related risk factors from heterogeneous data sources. We empirically validate the effectiveness of our developed method on a representative infectious disease, malaria. We test the developed method under three common real-life data missing patterns with different levels of missing rates. By incorporating the disease-related risk factors as external resources through the proposed HNML method, we demonstrate significant accuracy improvement over the baseline and state-of-the-art inference methods for predicting unobserved malaria cases based on the incomplete reporting data. The results suggest that the disease-related risk factors can provide valuable information about the transmission patterns of infectious diseases and should be taken into account when implementing the surveillance.},
  archive      = {J_NEUCOM},
  author       = {Qi Tan and Yang Liu and Jiming Liu and Benyun Shi and Shang Xia and Xiao-Nong Zhou},
  doi          = {10.1016/j.neucom.2019.12.145},
  journal      = {Neurocomputing},
  pages        = {701-713},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous neural metric learning for spatio-temporal modeling of infectious diseases with incomplete data},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Local feature extracted by the improved bag of features
method for person re-identification. <em>NEUCOM</em>, <em>458</em>,
690–700. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification is to recognize a pedestrian who has been observed at different places in monitoring system, which is done by computer automatically. Important practical significance can be found in this paper on improving the intelligence of monitoring system. There are two challenging problems needed to be solved for person re-identification, which is feature representation and matching. Designing a suitable feature representation method is both challenging and crucial. Ideally, the extracted features should be robust enough to cope with the various situations of the monitoring environment, such as posture difference, illumination changing, and shooting angle difference, etc. There are a lot of challenges for feature matching too, such as small sample size, inter-class confusion, and intra-class variation, etc. In order to meet these challenges, a new person re-identification scheme was put forward in this paper. The following three aspects would be used to describe it. First, an improved BOF feature extraction algorithm based on SURF was put forwarded, SURF algorithm extracts the preliminary feature descriptor and generates visual dictionary, so the influence factors such as illumination and scale invariants can be deal with. And then, covariance descriptor was adopted by the algorithm. It has high robustness, and matching accuracy can be improved too for the case of small sample. Finally, an effective classifier was designed by LIBSVM based on improved BOF algorithm, so the efficiency of the person re-identification algorithm can be improved. The proposed method was compared with the current mainstream algorithm through experiment, and it can be found through the experimental results that it is effective to solve the difficult problems for person re-identification.},
  archive      = {J_NEUCOM},
  author       = {Lixia Zhang and Kangshun Li and Yu Qi and Fubin Wang},
  doi          = {10.1016/j.neucom.2019.12.142},
  journal      = {Neurocomputing},
  pages        = {690-700},
  shortjournal = {Neurocomputing},
  title        = {Local feature extracted by the improved bag of features method for person re-identification},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized dirichlet-process-means for f-separable
distortion measures. <em>NEUCOM</em>, <em>458</em>, 667–689. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DP-means clustering was obtained as an extension of K -means clustering. While it is implemented with a simple and efficient algorithm, it can estimate the number of clusters simultaneously. However, DP-means is specifically designed for the average distortion measure. Therefore, it is vulnerable to outliers in data, and can cause large maximum distortion in clusters. In this work, we extend the objective function of the DP-means to f -separable distortion measures and propose a unified learning algorithm to overcome the above problems by selecting the function f . Further, the influence function of the estimated cluster center is analyzed to evaluate the robustness against outliers. We demonstrate the performance of the generalized method by numerical experiments using real datasets.},
  archive      = {J_NEUCOM},
  author       = {Masahiro Kobayashi and Kazuho Watanabe},
  doi          = {10.1016/j.neucom.2020.03.123},
  journal      = {Neurocomputing},
  pages        = {667-689},
  shortjournal = {Neurocomputing},
  title        = {Generalized dirichlet-process-means for f-separable distortion measures},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A density-peak-based clustering algorithm of automatically
determining the number of clusters. <em>NEUCOM</em>, <em>458</em>,
655–666. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering is a typical and important method to discover new structures and knowledge from data sets. Most existing clustering methods need to know the number of clusters in advance, which is difficult. Some algorithms claim they do not need to know the number of clusters in advance. Among these algorithms, however, some need to manually determine the cluster centers in a decision graph, which is not easy; some assume that the number of initial cluster centers given is greater than the actual number of classes, but in fact the true number of clusters is not known. In order to tackle this issue, we propose a density-peak-based clustering algorithm of automatically determining the number of clusters. First, we design a density metric by using a continuous function which can well distinguish the densities of different data points. Then, we design a pre-clustering method which can get the initial cluster centers and the corresponding clusters. Furthermore, we propose an automatic clustering method which can automatically determine the final cluster centers and the corresponding clusters. Experiments are conducted on widely used data sets, and the results show the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Wuning Tong and Sen Liu and Xiao-Zhi Gao},
  doi          = {10.1016/j.neucom.2020.03.125},
  journal      = {Neurocomputing},
  pages        = {655-666},
  shortjournal = {Neurocomputing},
  title        = {A density-peak-based clustering algorithm of automatically determining the number of clusters},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Image decomposition and completion using relative total
variation and schatten quasi-norm regularization. <em>NEUCOM</em>,
<em>458</em>, 639–654. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Both image decomposition and data completion are not only ubiquitous but also challenging tasks in the study of computer vision. In this paper, different from existing approaches, we propose a novel regularization model for image decomposition and data completion, which integrates relative total variation (RTV) with Schatten- 1 / 2 1/2 or Schatten- 2 / 3 2/3 norm, respectively. RTV is shown to be able to extract the fundamental structure effectively from the complicated texture patterns and largely to avoid the drawback of oil painting artifacts. Schatten quasi-norm is used to capture texture patterns in a completely-separated manner. The proposed model is in essence divided into “RTV+ double nuclear norm” and “RTV+ Frobenius/nuclear hybrid norm”, which can be solved by splitting variables and then by using the alternating direction method of multiplier (ADMM). Convergence of the algorithm is discussed in detail. The proposed approach is applied to several benchmark low-level vision problems: gray-scale image decomposition and reconstruction, text removal, color natural scene image completion, and visual data completion, demonstrating the distinguishable effectiveness of the new model, comparing to the latest developments in literature.},
  archive      = {J_NEUCOM},
  author       = {Min Li and Weiqiang Zhang and Mingqing Xiao and Chen Xu},
  doi          = {10.1016/j.neucom.2019.11.123},
  journal      = {Neurocomputing},
  pages        = {639-654},
  shortjournal = {Neurocomputing},
  title        = {Image decomposition and completion using relative total variation and schatten quasi-norm regularization},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gallery-sensitive single sample face recognition based on
domain adaptation. <em>NEUCOM</em>, <em>458</em>, 626–638. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Taking advantage of labeled auxiliary training data whose distribution is similar to the distribution of the gallery, single sample face recognition (SSFR) has achieved encouraging performance. However, in many real-world applications, it is difficult to collect such an auxiliary training dataset, while it may be easier to collect an unlabeled target training dataset whose distribution is similar to the distribution of the gallery and a labeled source training dataset whose distribution may be different to the distribution of the gallery. How can these three datasets be effectively leveraged to handle SSFR? To address this issue, this paper proposes a new method of G allery- S ensitive Single Sample Face Recognition based on D omain A daptation (GS-DA). First, GS-DA employs the method of TSD (targetize the source domain) to construct a common subspace and a targetized source domain. Secondly, it projects each gallery image into the common subspace and obtains the sparse representation of each gallery image in the common subspace. Thirdly, it reconstructs each gallery image from the targetized source domain to estimate the within-class scatter matrix and the between-class scatter matrix of the gallery. Lastly, it learns a discriminant model by maximizing the sum of the traces of the between-class scatter matrix of the gallery and the between-class scatter matrix of the targetized source domain as well as minimizing the sum of the traces of the total scatter matrix of the gallery and the total scatter matrix of the target training data. The experimental results on five datasets illustrate the superiority of GS-DA in leveraging these three datasets for SSFR.},
  archive      = {J_NEUCOM},
  author       = {Yimin Wen and Haiyang Yi and Zhigang Fan and Zhi Xu and Yun Xue and Yujian Li},
  doi          = {10.1016/j.neucom.2020.06.136},
  journal      = {Neurocomputing},
  pages        = {626-638},
  shortjournal = {Neurocomputing},
  title        = {Gallery-sensitive single sample face recognition based on domain adaptation},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Effective template update mechanism in visual tracking with
background clutter. <em>NEUCOM</em>, <em>458</em>, 615–625. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, artificial intelligence is everywhere in people’s daily lives. Visual tracking, which is used to identify and continuously track specific targets, is an important research domain in the study of artificial intelligence . However, current visual tracking methods are not accurate enough for object tracking with background clutter, which can easily lead to tracking failures. Therefore, in this paper, in order to solve the problem of tracking failure in clutter background, we propose a template update mechanism to improve the accuracy of visual tracking. First, an original template is saved when the background clutter is detected. During background clutter, we use both the original template and the current template at the location estimated by the optical flow and choose better one. Next, the original template is reused after the background clutter is ended. Finally, the proposed mechanism is used both in the KCF and BACF algorithm to verify the effectiveness of the mechanism. With experiments on the OTB2015 dataset, results show that the proposed mechanism has improved accuracy and success rate of the two baseline algorithms. Meanwhile, in state-of-the-art algorithms, the algorithm using the proposed mechanism also has excellent tracking performance. In addition, this method also has strong tracking robustness and adaptation capability to sequential learning for video data.},
  archive      = {J_NEUCOM},
  author       = {Shuai Liu and Dongye Liu and Khan Muhammad and Weiping Ding},
  doi          = {10.1016/j.neucom.2019.12.143},
  journal      = {Neurocomputing},
  pages        = {615-625},
  shortjournal = {Neurocomputing},
  title        = {Effective template update mechanism in visual tracking with background clutter},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time video dehazing via incremental transmission
learning and spatial-temporally coherent regularization.
<em>NEUCOM</em>, <em>458</em>, 602–614. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video dehazing is of crucial importance to the outdoor surveillance, and its main challenges mainly come from the spatial-temporal coherence and computational efficiency. This paper presents an efficient real-time video dehazing approach via incremental transmission learning and spatial-temporally coherent regularization , while explicitly suppressing the possible visual artifacts. First, we propose to initialize the transmission map frame-by-frame by a boundary constrained open dark channel model. Then, supposing a scene point yields highly correlated transmission values between adjacent frames, we impose a temporally coherent term to maintain the temporal consistency of consecutive transmission values, and simultaneously derive an incremental transmission adjusting term to adapt the abrupt scene depth changes between the adjacent frames. Accordingly, the highly correlated and spatial-temporally coherent transmission maps can be optimized for each video frame dehazing, whereby the flickering artifacts can be well reduced. Finally, we group each haze/haze-free images in pair and further utilize the guided joint bilateral filter to suppress the visual artifacts that possibly amplified during the dehazing process. The experimental results show that the proposed video dehazing approach is able to well preserve the spatial-temporal coherence, runs sufficiently fast, and also performs favorably compared to the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Shu-Juan Peng and He Zhang and Xin Liu and Wentao Fan and Bineng Zhong and Ji-Xiang Du},
  doi          = {10.1016/j.neucom.2020.02.134},
  journal      = {Neurocomputing},
  pages        = {602-614},
  shortjournal = {Neurocomputing},
  title        = {Real-time video dehazing via incremental transmission learning and spatial-temporally coherent regularization},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method of traffic police detection based on attention
mechanism in natural scene. <em>NEUCOM</em>, <em>458</em>, 592–601. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The complex and varied urban road conditions have always been a difficult and a pivotal component in the study of driverless technology especially at intersections. In China, it is necessary for driverless cars to understand the gestures of traffic police. To identify the traffic police gesture at the intersection, the key step is to detect the traffic police at the intersection. At present, the research on traffic police detection is still in its infancy, there exists common problems such as slow detection speed and other real time problems in this method, and there is not a standardized traffic police data set ether. For the real time problems, this paper introduces the attention mechanism, and proposes a new real-time detection method of traffic police based on attention mechanism. The method proposed in this paper has strong robustness and can quickly complete the target detection task. For the data set problem, this paper analyzes and discloses similar data sets published through research. In the meanwhile, this paper collects 24,530 video data on the actual road, and it extracts and saves 12,000 pictures containing traffic police at frame rate of 30FPS as traffic police detection training and validated data set.},
  archive      = {J_NEUCOM},
  author       = {Ying Zheng and Hong Bao and Chaochao Meng and Nan Ma},
  doi          = {10.1016/j.neucom.2019.12.144},
  journal      = {Neurocomputing},
  pages        = {592-601},
  shortjournal = {Neurocomputing},
  title        = {A method of traffic police detection based on attention mechanism in natural scene},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-installment scheduling for large-scale workload
computation with result retrieval. <em>NEUCOM</em>, <em>458</em>,
579–591. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-installment scheduling (MIS) has made great strides in minimizing the makespan of large-scale workloads on distributed systems. By the makespan is meant the total time it takes for workload distribution , computation and result retrieval. However, existing studies have hardly taken result retrieval time into consideration due to an idealistic assumption that the amount of result generated after workload computation is so small that the retrieval time could be neglected. This unrealistic assumption may have a seriously negative effect on task-scheduling strategies especially for big-data-related applications nowadays. In view of this, this paper studies the MIS problem with result retrieval on heterogeneous distributed systems. We propose a new MIS model referred to as MIS-RR and solve three crucial issues: (1) we obtain, for the first time, a closed-form solution to an optimal load partition by strict mathematical derivation for this problem; (2) we get an optimal number of installments by designing a heuristic algorithm ; (3) we obtain an optimal scheduling sequence of servers involved in computation by proposing an evolutionary algorithm . Experimental results clearly show that our proposed strategy can achieve the shortest makespan as well as the highest average CPU utilization and system utilization compared to existing scheduling strategies.},
  archive      = {J_NEUCOM},
  author       = {Xiaoli Wang and Bharadwaj Veeravalli and Jiaming Song},
  doi          = {10.1016/j.neucom.2020.03.124},
  journal      = {Neurocomputing},
  pages        = {579-591},
  shortjournal = {Neurocomputing},
  title        = {Multi-installment scheduling for large-scale workload computation with result retrieval},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method of repairing single node failure in the distributed
storage system based on the regenerating-code and a hybrid genetic
algorithm. <em>NEUCOM</em>, <em>458</em>, 566–578. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To ensure the reliability and security of the data, the large-scale distributed storage system usually adopts the data redundancy mechanism to repair the data on the faulty nodes. Comparing with the replication-based method, the data redundancy mechanism of erasure code can effectively improve the use of storage space, but it may result in the large network overhead when recovering the data. The regenerating code is an improved erasure code, which can reduce the quantity of data transmission compared to that of the erasure code. Adopting the regenerating code to repair the data on a faulty node requires constructing an optimal repair tree to maximum the bandwidth of the bottleneck link , which is an NP-hard problem. To construct the optimal repair tree, a hybrid genetic algorithm is proposed in this paper. In particular, our proposal comprehensively considers the network topology and link bandwidth of storage nodes and designs a problem-specific cross-correlation operator, mutation operator and local search operator. In addition, we provided the mathematical proof of the global convergence with probability one with respect to the proposed hybrid genetic algorithm . Through a series of simulation experiments, the results show that our proposal is able to determine the optimal repair tree, which effectively reduces the delay of faulty node repair in distributed storage systems, and improve the repairing efficiency.},
  archive      = {J_NEUCOM},
  author       = {Miao Ye and Hongbing Qiu and Yong Wang and Zou Zhou and Fei Zheng and Tianxin Ma},
  doi          = {10.1016/j.neucom.2019.11.124},
  journal      = {Neurocomputing},
  pages        = {566-578},
  shortjournal = {Neurocomputing},
  title        = {A method of repairing single node failure in the distributed storage system based on the regenerating-code and a hybrid genetic algorithm},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the smoothing of the norm objective penalty function for
two-cardinality sparse constrained optimization problems.
<em>NEUCOM</em>, <em>458</em>, 559–565. (<a
href="https://doi.org/10.1016/j.neucom.2019.09.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies a smoothing norm objective penalty function for two-cardinality sparse constrained optimization problems . Good properties are proved for the smoothing norm objective penalty functions in solving two-cardinality sparse constrained optimization problems, after which an algorithm is presented. Furthermore, its convergence is also proved under some conditions. The proposed algorithm can solve a satisfactory approximate optimal solution in a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Jiang Min and Zhiqing Meng and Gengui Zhou and Rui Shen},
  doi          = {10.1016/j.neucom.2019.09.119},
  journal      = {Neurocomputing},
  pages        = {559-565},
  shortjournal = {Neurocomputing},
  title        = {On the smoothing of the norm objective penalty function for two-cardinality sparse constrained optimization problems},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance investigation of i∊-indicator and i∊+-indicator
based on lp-norm. <em>NEUCOM</em>, <em>458</em>, 546–558. (<a
href="https://doi.org/10.1016/j.neucom.2019.10.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we generalize the usual multiplicative ∊ ∊ ∊ -indicator I ∊ ∊ I∊ and additive ∊ ∊ ∊ -indicator I ∊ + ∊ I∊+ to the forms with L p Lp -norm, i.e. I ∊ p ∊ I∊p -indicator and I ∊ + p ∊ I∊+p -indicator, and investigate their properties under different p . From the analysis, we find that both I ∊ p ∊ I∊p -indicator and I ∊ + p ∊ I∊+p -indicator have a good performance on measuring the population convergence and diversity, especially when p is set to be infinity. In order to show their differences more intuitively, we implement a series of comparative experiments by the proposed I ∊ p ∊ I∊p -indicator and I ∊ + p ∊ I∊+p -indicator based evolutionary algorithm. The experimental results confirm that all these ∊ ∊ ∊ -indicators have good performances, particulary as p is set to be infinity. We also compare the proposed indicator-based evolutionary algorithm with five existing algorithms. The experimental results demonstrate that our algorithm is effective. In addition, considering that the usual IGD metric is not accurate in measuring the convergence of a population, we adopt the measure based on I ∊ + p ∊ I∊+p -indicator and propose a more effective performance metric, which is denoted as IGD ∊ + ∊ IGD∊+ .},
  archive      = {J_NEUCOM},
  author       = {Ning Yang and Hai-Lin Liu and Jiawei Yuan},
  doi          = {10.1016/j.neucom.2019.10.122},
  journal      = {Neurocomputing},
  pages        = {546-558},
  shortjournal = {Neurocomputing},
  title        = {Performance investigation of i∊-indicator and i∊+-indicator based on lp-norm},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MOEA/UE: A novel multi-objective evolutionary algorithm
using a uniformly evolving scheme. <em>NEUCOM</em>, <em>458</em>,
535–545. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-objective optimization, the Pareto-optimal solutions must be widely and uniformly distributed on the Pareto-optimal front. When this condition is satisfied, decision makers can choose satisfactory solutions. In this paper, gaps in the evolving nondominated front are filled by a multi-objective evolutionary algorithm using a uniformly evolving scheme (MOEA/UE), thus generating a uniform and wide Pareto-optimal front. The MOEA/UE first calculates the distance between the points on the nondominated front and identifies those with relatively wide gaps. At the widely spaced points, the objective and constraint functions are approximated by linear functions expressed as Taylor series in auxiliary linear programs . Finally, the MOEA/UE solves these auxiliary linear programs and retains the optimal or intermediate solutions as the potentially superior individuals that will be selected in the next generation of the population. Convergence toward potentially superior solutions is accelerated by a mutation operator (a basic differential evolution operator). In constrained multi-objective optimization problems , the MOEA/UE implements a new constraint-handling strategy that pulls infeasible solutions into or nearby the feasible domain. Experimental results illustrate that MOEA/UE obtains wider and more uniform Pareto-optimal fronts and better Pareto-optimal solutions.},
  archive      = {J_NEUCOM},
  author       = {Zhicang Wang and Hecheng Li and Huifang Yu},
  doi          = {10.1016/j.neucom.2020.04.149},
  journal      = {Neurocomputing},
  pages        = {535-545},
  shortjournal = {Neurocomputing},
  title        = {MOEA/UE: A novel multi-objective evolutionary algorithm using a uniformly evolving scheme},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matching biomedical ontologies through compact differential
evolution algorithm with compact adaption schemes on control parameters.
<em>NEUCOM</em>, <em>458</em>, 526–534. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biomedical ontology is a unified model for describing biomedical knowledge, which can be of help to solve the issues of heterogeneity in different biomedical databases. However, the existing biomedical ontologies could define the same biomedical concept in different ways, which yields the biomedical ontology heterogeneous problem. To implement the inter-operability among the biomedical ontologies, it is critical to establish the semantic links between heterogenous biomedical concepts, so-called biomedical ontology matching . Evolution Algorithm (EA) is a state-of-the-art methodology for matching ontologies, but two main shortcomings, i.e. the huge memory consumption and long runtime, make it incapable of effectively matching biomedical ontologies. In this work, a novel Adaptive Compact Differential Evolution algorithm (ACDE) is proposed to solve the biomedical ontology matching problem, which utilizes a compact encoding mechanism to save the memory consumption and introduces the compact adaption schemes on control parameters to improve the algorithm’s converging speed. The experiment exploits four biomedical ontology matching tracks, which are provided by the famous Ontology Alignment Evaluation Initiative (OAEI), to test ACDE’s performance. The experimental results show that ACDE can effectively reduce EA-based ontology matcher’s memory consumption and runtime, and its results significantly outperform other EA-based matchers and OAEI’s participants.},
  archive      = {J_NEUCOM},
  author       = {Xingsi Xue and Junfeng Chen},
  doi          = {10.1016/j.neucom.2020.03.122},
  journal      = {Neurocomputing},
  pages        = {526-534},
  shortjournal = {Neurocomputing},
  title        = {Matching biomedical ontologies through compact differential evolution algorithm with compact adaption schemes on control parameters},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fitness distance correlation and mixed search strategy for
differential evolution. <em>NEUCOM</em>, <em>458</em>, 514–525. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fitness landscape is a theory applied to the evolutionary dynamics of biological evolution to explain the behavior of evolutionary algorithms in the solution of optimization problems . With the continuous advancement of evolutionary algorithm optimization, a fitness landscape can present more abundant feature information, such as the local fitness, fitness distance correlation, and landscape roughness. These landscape features reflect the optimal solution distribution, quantity, and local unimodal topology of the optimization problem from various angles. This paper expresses the adaptability landscape features of typical optimization problems , engages in a quantitative analysis of the fitness distance correlation information, evaluates the difficulty of solving the problem within the search space, and obtains the correlation degree classification result . The search strategy adapts the mixed mutation and the fitness distance correlation for differential evolution. Empirical studies show that, the fitness distance correlation search strategy for the differential evolution algorithm can avoid falling into the local optimum, improve accuracy and convergence, and solve the single-objective optimization problem in a more comprehensive manner.},
  archive      = {J_NEUCOM},
  author       = {Wei Li and Xiang Meng and Ying Huang},
  doi          = {10.1016/j.neucom.2019.12.141},
  journal      = {Neurocomputing},
  pages        = {514-525},
  shortjournal = {Neurocomputing},
  title        = {Fitness distance correlation and mixed search strategy for differential evolution},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Special issue on advanced methods in
optimization and machine learning for heterogeneous data analytics.
<em>NEUCOM</em>, <em>458</em>, 511–513. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Yiu-ming Cheung and Yuping Wang},
  doi          = {10.1016/j.neucom.2020.10.073},
  journal      = {Neurocomputing},
  pages        = {511-513},
  shortjournal = {Neurocomputing},
  title        = {Guest editorial: Special issue on advanced methods in optimization and machine learning for heterogeneous data analytics},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved adaptive genetic algorithm based on DV-hop for
locating nodes in wireless sensor networks. <em>NEUCOM</em>,
<em>458</em>, 500–510. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The localization problem of unknown nodes in wireless sensor networks (WSN) has drawn increasing scholarly attention along together the popularity of meta-heuristic algorithms. To overcome the shortcomings of low accuracy that traditional least square method (LSM) inevitably produces, this paper introduces an improved adaptive genetic algorithm (IAGA) to handle the aforementioned problem and uses a modified evaluation function to reduce the error of distance measurement in a topological structure . The experimental results prove that the IAGA algorithm based on DV-Hop has superior performance in comparison of original DV-Hop and other meta-heuristic algorithms. The conclusion can be drawn that meta-heuristic algorithms have an better superiority over DV-Hop in locating nodes in WSN and the IAGA is more promising than other meta-heuristic algorithms.},
  archive      = {J_NEUCOM},
  author       = {Aijia Ouyang and Yinsheng Lu and Yanmin Liu and Meng Wu and Xuyu Peng},
  doi          = {10.1016/j.neucom.2020.04.156},
  journal      = {Neurocomputing},
  pages        = {500-510},
  shortjournal = {Neurocomputing},
  title        = {An improved adaptive genetic algorithm based on DV-hop for locating nodes in wireless sensor networks},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Logish: A new nonlinear nonmonotonic activation function for
convolutional neural network. <em>NEUCOM</em>, <em>458</em>, 490–499.
(<a href="https://doi.org/10.1016/j.neucom.2021.06.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Activation function is an important component of the convolutional neural network . Recently, nonlinear nonmonotonic activation functions such as Swish and Mish have illustrated good performance in deep learning structures. In this paper, we propose a new nonlinear nonmonotonic activation function called Logish, which can be represented by f ( x ) = x · ln [ 1 + sigmoid ( x ) ] f(x)=x·ln[1+sigmoid(x)] . Firstly, we take the logarithmic operation to reduce the numerical range of sigmoid ( x ) + 1 sigmoid(x)+1 , then we employ variable x x to make the negative output have a strong regularization effect. Furthermore, we evaluate the image classification performance of Logish and its variant f ( x ) = α x · ln [ 1 + sigmoid ( β x ) ] f(x)=αx·ln[1+sigmoid(βx)] in simple and complex networks with top–1 accuracy. Experimental results demonstrate that Logish’s variant ( α = 1 , β = 10 α=1,β=10 ) can achieve 94.8\% top-1 accuracy with ResNet–50 network on CIFAR 10 dataset, and can reach 99.24\% top-1 accuracy with DenseNet on MNIST dataset and 88.52\% top-1 accuracy with SE-Inception-v4 network on SVHN dataset respectively. It is higher than the Sigmoid, Tanh, ReLU, Swish and Mish activation functions in the corresponding dataset. It also verifies the performance and effectiveness of Logish.},
  archive      = {J_NEUCOM},
  author       = {Hegui Zhu and Huimin Zeng and Jinhai Liu and Xiangde Zhang},
  doi          = {10.1016/j.neucom.2021.06.067},
  journal      = {Neurocomputing},
  pages        = {490-499},
  shortjournal = {Neurocomputing},
  title        = {Logish: A new nonlinear nonmonotonic activation function for convolutional neural network},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuro-adaptive optimized control for full active suspension
systems with full state constraints. <em>NEUCOM</em>, <em>458</em>,
478–489. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive neural network (NN) optimized control strategy is presented to improve the inherent tradeoff between ride comfort of passengers and the suspension travel for full vehicle active suspension system with state constraints. To the best of our knowledge, the automotive suspension system control using hydraulic actuators is a highly complex nonlinear control task, involving external disturbances and uncertainties. To address it, this paper develops the virtual and actual optimal controllers based on backstepping technique and the identifier-actor-critic structure. Meanwhile, the Barrier Lyapunov functions are developed to prevent the systems from the state constraints and the systems states are limited in the preselected compact sets. It is particularly worth mentioning that the proposed optimal control strategy ensures that all the closed-loop signals remain bounded, while the power of the control input as well as the amplitude of the vertical displacement has been minimized. The simulation results show how the full-car system can be controlled optimally and satisfactorily, and confirm the superiority of proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jiaxin Zhang and Kewen Li and Yongming Li},
  doi          = {10.1016/j.neucom.2021.06.069},
  journal      = {Neurocomputing},
  pages        = {478-489},
  shortjournal = {Neurocomputing},
  title        = {Neuro-adaptive optimized control for full active suspension systems with full state constraints},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lightweight propagation path aggregating network with
neural topic model for rumor detection. <em>NEUCOM</em>, <em>458</em>,
468–477. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structure information associated with message propagation has been proved to be effective to distinguish false and true rumors. However, existing methods lack an efficient way to learn the representation of the whole rumors which captures the intrinsic mechanism of rumor propagation structures and semantics. In this study, we propose a lightweight propagation path aggregating (PPA) neural network for rumor embedding and classification. In the network, we first model the propagation structure of each rumor as an independent set of propagation paths in which each path represents the source post in a different talking context. We then aggregate all paths to obtain the representation of the whole propagation structure. Besides, we utilize a neural topic model in the Wasserstein autoencoder (WAE) framework to capture event insensitive stance patterns in response propagation trees where no source post is included. Empirical studies demonstrate that 1) PPA achieves the state-of-the-art performance with much less parameters and training time, 2) PPA can further benefit from the pre-trained neural topic model which enables to fully use unlabeled data , thus improves the performance of PPA especially when labeled samples are limited or rumors are spreading at early stage. Meanwhile, this topic model offers an explicit interpretation of stance patterns in the form of topics, consequently improves interpretability of the PPA network. The source code can be available at https://github.com/zperfet/PathFakeGit.},
  archive      = {J_NEUCOM},
  author       = {Pengfei Zhang and Hongyan Ran and Caiyan Jia and Xuanya Li and Xueming Han},
  doi          = {10.1016/j.neucom.2021.06.062},
  journal      = {Neurocomputing},
  pages        = {468-477},
  shortjournal = {Neurocomputing},
  title        = {A lightweight propagation path aggregating network with neural topic model for rumor detection},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy reinforced polynomial neural networks constructed with
the aid of PNN architecture and fuzzy hybrid predictor based on
nonlinear function. <em>NEUCOM</em>, <em>458</em>, 454–467. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of dynamic system identification and prediction, linear models (e.g., autoregressive models), nonlinear models (namely, neural networks models), and hybrid predictors (HPs) that are a hybridization of linear and nonlinear models have been proposed in the past. However, they are not completely free from limitations: they exhibit difficulties to describe high-order nonlinear relations between input and output variables. In this study, we propose fuzzy reinforced polynomial neural networks (FRPNNs), which are polynomial neural network architecture-based on fuzzy reinforced polynomial neurons (FRPNs) to overcome this limitation. The proposed FRPNs that consist of approximation part (AP) and compensation part (CP) arise as novel HPs. Here the CP for modeling nonlinear patterns can be regarded as forming the reinforced part for the AP that aims at capturing linear patterns, while AP is the linear polynomial neuron used in the conventional polynomial neural networks. In some sense, the overall FRPNNs are essentially generalized polynomial neural network architecture with novel HPs. The parameters considered in the design of the proposed fuzzy reinforced polynomial neural networks are optimized with the aid of the particle swarm optimization (PSO). The performance of FRPNNs is discussed involving time series and system identification datasets. Experimental results demonstrate that the proposed FRPNNs achieve at most the accuracy of 43.6\% higher in comparison with the accuracy produced by some classical models reported in the literature.},
  archive      = {J_NEUCOM},
  author       = {Wei Huang and Sung-Kwun Oh and Witold Pedrycz},
  doi          = {10.1016/j.neucom.2021.06.047},
  journal      = {Neurocomputing},
  pages        = {454-467},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy reinforced polynomial neural networks constructed with the aid of PNN architecture and fuzzy hybrid predictor based on nonlinear function},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lithium-ion battery diagnostics and prognostics enhanced
with dempster-shafer decision fusion. <em>NEUCOM</em>, <em>458</em>,
440–453. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Prognostics is the discipline of predicting the remaining useful life of a component or system in order to optimize the maintenance planning or the mission execution. Prognostics-enabled systems likely reduce the overall life-cycle cost and increase the reliability. In the Bayesian estimation framework, the widely used techniques are the traditional Kalman filter , along with its non-linear extensions, and the particle filter. Each technique has different advantages. This paper investigates the fusion of prognostic results from different techniques in order to achieve a more trustworthy remaining useful life (RUL) prediction, as measured by a reduction in uncertainty. Models for extended Kalman filter (EKF) and particle filter (PF) are developed from the feature data. The results from EKF and PF are then fused using an application of Dempster-Shafer theory (DST). Separate models are utilized for EKF and PF in order to introduce multi-model prognostics and to optimize the performance of each technique for both diagnosis and RUL prediction. Prognostics is triggered when degradation is detected by diagnosis. DST is then applied to the prognostic results from EKF and PF. The result of DST is a density function whose performance can be compared with that of EKF and PF. DST allows for the fusion of multiple sensors and state estimates. The proposed method is verified with the prognosis of a set of lithium-ion batteries.},
  archive      = {J_NEUCOM},
  author       = {John Weddington and Guangxing Niu and Renxiang Chen and Wuzhao Yan and Bin Zhang},
  doi          = {10.1016/j.neucom.2021.06.057},
  journal      = {Neurocomputing},
  pages        = {440-453},
  shortjournal = {Neurocomputing},
  title        = {Lithium-ion battery diagnostics and prognostics enhanced with dempster-shafer decision fusion},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A more efficient deterministic annealing neural network
algorithm for the max-bisection problem. <em>NEUCOM</em>, <em>458</em>,
428–439. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The max-bisection problem has extensive applications in network engineering, making it imperative to develop effective methods to solve this problem. However, the efficient computation on this problem remains challenging due to its NP-hard computational complexity. To address this question, in this paper, we transform the max-bisection problem to an artificial linearly constrained optimization problem and develop a modified deterministic annealing neural network algorithm by introducing a barrier function. The barrier parameter of this function acts as the temperature in the annealing process and decreases from a large positive number to zero. The initial value of the barrier parameter promises that the artificial problem is convex and can be easily solved at the beginning of the descending process. The solution to the original max-bisection problem is finally obtained through a descent algorithm, in which the bound limit of the solution is always satisfied as long as the iteration step length is less than one. We have proved the theoretical convergence of the proposed algorithm. Numerical results demonstrate that the proposed algorithm has several advantages over both the approximation algorithms and metaheuristic methods.},
  archive      = {J_NEUCOM},
  author       = {Shicong Jiang and Chuangyin Dang},
  doi          = {10.1016/j.neucom.2021.06.050},
  journal      = {Neurocomputing},
  pages        = {428-439},
  shortjournal = {Neurocomputing},
  title        = {A more efficient deterministic annealing neural network algorithm for the max-bisection problem},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Silicone mask face anti-spoofing detection based on visual
saliency and facial motion. <em>NEUCOM</em>, <em>458</em>, 416–427. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face recognition systems are widely used for target recognition and identity authentication , such as automated teller machines, mobile phones, and entrance guard systems. However, face recognition systems are vulnerable to presentation attacks, such as photo, replay, and 3D mask attacks. In particular, silicone mask attacks pose a greater threat to face recognition systems because high-quality silicone masks do living properties. To promote the development of face anti-spoofing detection algorithms for silicone mask attacks, this paper constructs a Silicone Mask Face Motion Video Dataset (SMFMVD) containing 200 real face videos and 200 silicone mask face videos. These videos include different facial motions collected from 20 subjects. Moreover, inspired by the observation that the silicone mask face’s facial movement is not so natural as the real face, we propose a novel silicone mask face anti-spoofing detection method based on visual saliency and facial motion characteristics. Specifically, we compute the visual saliency map of a given face image by simulating two kinds of eye movement behaviors , namely “gaze” and “saccade”. Then, we propose a saliency-weighted histogram of local binary pattern operator to extract facial texture features in spatial domain and a saliency-guided histogram of oriented optical flow operator to extract facial motion features in temporal domain. Finally, the support vector machine is used to fuse two groups of facial features to distinguish real and spoof faces. Extensive experiments on public and self-built datasets show its superiority over the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Guangcheng Wang and Zhongyuan Wang and Kui Jiang and Baojin Huang and Zheng He and Ruimin Hu},
  doi          = {10.1016/j.neucom.2021.06.033},
  journal      = {Neurocomputing},
  pages        = {416-427},
  shortjournal = {Neurocomputing},
  title        = {Silicone mask face anti-spoofing detection based on visual saliency and facial motion},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-horizon robust formation-containment control of
multi-agent networks with unknown dynamics. <em>NEUCOM</em>,
<em>458</em>, 403–415. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the paper, data-driven finite-horizon robust formation-containment control scheme is developed based on integral reinforcement learning and zero-sum game for perturbed multi-agent networks with completely unknown nonlinear dynamics. At first, distributed finite-time sliding mode estimators are designed to obtain the desired states of leaders and followers, respectively. Then finite-horizon robust leader formation control and follower containment control are achieved based on proposed model-free integral reinforcement learning algorithms implemented by critic-actor-disturbance structure, in the framework of multi-player zero-sum game where the non-quadratic performance index for each agent considers the influence of saturated inputs and disturbances of local neighbors thoroughly. Furthermore, it is proved that the whole network has bounded L 2 L2 gain robust stability and Nash equilibrium of zero-sum game exists. Simulation results are provided to demonstrate the effectiveness of the proposed scheme.},
  archive      = {J_NEUCOM},
  author       = {Di Yu and Shuzhi Sam Ge and Dongyu Li and Peng Wang},
  doi          = {10.1016/j.neucom.2021.01.063},
  journal      = {Neurocomputing},
  pages        = {403-415},
  shortjournal = {Neurocomputing},
  title        = {Finite-horizon robust formation-containment control of multi-agent networks with unknown dynamics},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered synchronization for semi-markov jump complex
dynamic networks with time-varying delay. <em>NEUCOM</em>, <em>458</em>,
390–402. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the event-triggered synchronization of complex dynamic networks (CDNs) with semi-Markov switching and time-varying delay. First, by proposing auxiliary vectors with a few nonorthogonal polynomials, two slack-matrix-based integral inequalities are formulated, which encompass some existing ones as special cases. Second, a triple-integral-based delay-product-type (TIDPT) Lyapunov-Krasovskii functional (LKF) is formulated, which fully utilizes the information of time delay . After designing a controller via the event- triggered scheme, some sufficient conditions are proposed to achieve the global stochastic synchronization by utilizing the reciprocally convex matrix inequality (RCMI) and the founded inequalities to evaluate the derivative of the established LKF. A numerical example is employed to show the effectiveness and practicability of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Cheng-De Zheng and Shengzhou Liu and Haorui Meng},
  doi          = {10.1016/j.neucom.2021.06.022},
  journal      = {Neurocomputing},
  pages        = {390-402},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered synchronization for semi-markov jump complex dynamic networks with time-varying delay},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamical pattern recognition for sampling sequences based
on deterministic learning and structural stability. <em>NEUCOM</em>,
<em>458</em>, 376–389. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the recognition problem of dynamical patterns consisting of sampling sequences. Specifically, based on the concept of structural stability, a novel similarity measure for dynamical patterns is first given. Then, a specific realization is provided, which consists of: (1) an approximation scheme for computation of partial derivative information by utilizing the knowledge learned through deterministic learning; (2) a similarity comparison scheme using the recognition errors generated from the discrete-time dynamical estimators; and (3) performance analysis of the recognition scheme with general recognition conditions. Compared with the existing methods, in which misrecognition may occur when the differences of dynamics between adjacent training patterns are very small, the proposed method is more appealing in the sense that, the partial derivatives of dynamics are introduced to complement the similarity measures, such that the recognition performance is much improved. Simulation studies are conducted to verify the proposed method in a relatively large data set.},
  archive      = {J_NEUCOM},
  author       = {Weiming Wu and Fukai Zhang and Cong Wang and Chengzhi Yuan},
  doi          = {10.1016/j.neucom.2021.06.001},
  journal      = {Neurocomputing},
  pages        = {376-389},
  shortjournal = {Neurocomputing},
  title        = {Dynamical pattern recognition for sampling sequences based on deterministic learning and structural stability},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Prescribed finite-time adaptive neural trajectory tracking
control of quadrotor via output feedback. <em>NEUCOM</em>, <em>458</em>,
364–375. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel prescribed finite-time output feedback control scheme for quadrotor trajectory tracking control . The proposed control scheme considers the quadrotor modeling containing uncertain nonlinearities and strong coupling. The neural observer is set up to estimate the unknown state variables. The main difficulty caused by the time-vary coefficient matrix to design a state observer is overcame by the convex combination technique. To get a prescribed finite-time tracking performance, Barrier Lyapunov Function (BLF) approach is presented for control design. The constructed controllers guarantee that the tracking errors meet the prescribed accuracy in a pre-specified finite settling time. Finally, a simulation example verifies the effectiveness of the control scheme.},
  archive      = {J_NEUCOM},
  author       = {Mingyu Wang and Bing Chen and Chong Lin},
  doi          = {10.1016/j.neucom.2021.06.018},
  journal      = {Neurocomputing},
  pages        = {364-375},
  shortjournal = {Neurocomputing},
  title        = {Prescribed finite-time adaptive neural trajectory tracking control of quadrotor via output feedback},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-adversarial variational autoencoder with spectral
residual for time series anomaly detection. <em>NEUCOM</em>,
<em>458</em>, 349–363. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies accurately in time series data has been receiving considerable attention due to its enormous potential for a wide array of applications. Numerous unsupervised anomaly detection methods for time series have been developed because of the difficulty of obtaining accurate labels. However, most existing unsupervised approaches suffer from the problem of anomaly contamination, which results in models that are unable to learn the normal pattern well and further deteriorate the performance of detection methods. To this end, a novel unsupervised method , called Self-adversarial Variational Autoencoder with Spectral Residual (SaVAE-SR), is introduced for time series anomaly detection in this paper. The SaVAE-SR first produces labels for unlabeled training data using the spectral residual technique to identify the most critical anomalies. A VAE model with a modified loss that can leverage label information to remove the influence of anomalous points is then trained in a self-adversarial manner, enabling the model to self-evaluate the learning of complex data distribution and improve itself accordingly. Specifically, the encoder acts as an encoder to approximate the posterior of latent variables and as a discriminator to evaluate the generative ability of the generator and improve itself accordingly. The generator is trained to capture the underlying data distribution and attempts to produce real samples to deceive the discriminator . The encoder and generator of the model compete with each other just like the behavior of GANs but work together under the theoretical framework of VAEs. As a result, the SaVAE-SR model combines the respective strengths of the VAE and adversarial training but does not require an additional discriminator, which makes the whole model very compact. Extensive experiments on five datasets demonstrate the superiority of the proposed method over the existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yunxiao Liu and Youfang Lin and QinFeng Xiao and Ganghui Hu and Jing Wang},
  doi          = {10.1016/j.neucom.2021.06.030},
  journal      = {Neurocomputing},
  pages        = {349-363},
  shortjournal = {Neurocomputing},
  title        = {Self-adversarial variational autoencoder with spectral residual for time series anomaly detection},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Particle swarm optimization assisted b-spline neural network
based predistorter design to enable transmit precoding for nonlinear
MIMO downlink. <em>NEUCOM</em>, <em>458</em>, 336–348. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the multiple-input multiple-output (MIMO) downlink employing high-order quadrature amplitude modulation signaling and with nonlinear high power amplifiers (HPAs) at base station transmitter, the existing precoding designs relying on the linear MIMO channel can no longer work. We propose an efficient and accurate predistorter design to enable transmit precoding for nonlinear MIMO downlink. Specifically, we obtain the closed-form least squares estimates of the nonlinear HPA’s amplitude and phase response using two B-spline neural networks during training. The estimated HPA’s phase response automatically yields the estimate of the predistorter’s phase response. Based on the B-spline neural network estimate of the HPA’s amplitude response, we construct a B-spline neural network model for the predistorter amplitude response, and we adopt a particle swarm optimization (PSO) algorithm to solve this highly nonlinear optimization problem . Using our accurate predistorter estimate to pre-compensate for the nonlinear distortions of the transmit HPAs, a standard full-digital transmit precoding design can readily be adopted to combat the MIMO channel interference . A simulation study is conducted to demonstrate the effectiveness of our proposed PSO assisted predistorter design.},
  archive      = {J_NEUCOM},
  author       = {Sheng Chen and Soon Xin Ng and Emad Khalaf and Ali Morfeq and Naif Alotaibi},
  doi          = {10.1016/j.neucom.2021.06.010},
  journal      = {Neurocomputing},
  pages        = {336-348},
  shortjournal = {Neurocomputing},
  title        = {Particle swarm optimization assisted B-spline neural network based predistorter design to enable transmit precoding for nonlinear MIMO downlink},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variance aware reward smoothing for deep reinforcement
learning. <em>NEUCOM</em>, <em>458</em>, 327–335. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Reinforcement Learning (RL) agent interacts with the environment to learn a policy with high accumulated rewards through attempts and failures. However, RL suffers from its own trial-and-error learning nature, which results in an unstable learning process. In this paper, we investigate a common phenomenon called rewards drop at the late-stage RL training session, where the rewards trajectory oscillates dramatically. In order to solve such a problem, we propose a novel rewards shaping technique named Variance Aware Rewards Smoothing (VAR). We show that the proposed method reduces the variance of rewards and mitigates the rewards drop problem without changing the formulation of the value function. Furthermore, the theoretical analysis of convergence of VAR is provided, which is derived from the γ γ -contraction operator and the fixed point attribute of the value function. Finally, the theoretical results are illustrated by extensive results on various benchmarks and advanced algorithms across different random seeds to demonstrate the effectiveness and the compatibility of VAR.},
  archive      = {J_NEUCOM},
  author       = {Yunlong Dong and Shengjun Zhang and Xing Liu and Yu Zhang and Tan Shen},
  doi          = {10.1016/j.neucom.2021.06.014},
  journal      = {Neurocomputing},
  pages        = {327-335},
  shortjournal = {Neurocomputing},
  title        = {Variance aware reward smoothing for deep reinforcement learning},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Nonlinear process monitoring using a mixture of
probabilistic PCA with clusterings. <em>NEUCOM</em>, <em>458</em>,
319–326. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motivated by mixture of probabilistic principal component analysis (PCA), which is time-consuming due to expectation maximization, this paper investigates a novel mixture of probabilistic PCA with clusterings for process monitoring. The significant features are extracted by singular vector decomposition (SVD) or kernel PCA, and k -means is subsequently utilized as a clustering algorithm . Then, parameters of local PCA models are determined under each clustering model. Compared with PCA clustering, SVD based clustering only utilizes the nature basis for the components of the data instead of principal components of the data. Three clustering approaches are adopted and the effectiveness of the proposed approach is demonstrated by a practical coal pulverizing system.},
  archive      = {J_NEUCOM},
  author       = {Jingxin Zhang and Maoyin Chen and Xia Hong},
  doi          = {10.1016/j.neucom.2021.06.039},
  journal      = {Neurocomputing},
  pages        = {319-326},
  shortjournal = {Neurocomputing},
  title        = {Nonlinear process monitoring using a mixture of probabilistic PCA with clusterings},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An autonomous learning mobile robot using biological reward
modulate STDP. <em>NEUCOM</em>, <em>458</em>, 308–318. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have shown that biologically inspired Spiking Neural Networks (SNNs) has potentials for the mobile robot controls. Based on SNNs, an autonomous learning paradigm for controlling mobile robots is proposed in this work, which can learn specific tasks autonomously. A reward modulated spike-timing-dependent plasticity (R-STDP) learning algorithm is designed to aid implementing the autonomous learning paradigm. It can train the SNN under different environmental states and conditions. The obstacle avoidance in the synthetic and real environments is used as a robotic task example to verify the effectiveness of the proposed paradigm. Results show that the mobile robot can learn autonomously under different environmental conditions and is able to avoid obstacles after learning processes complete.},
  archive      = {J_NEUCOM},
  author       = {Hao Lu and Junxiu Liu and Yuling Luo and Yifan Hua and Senhui Qiu and Yongchuang Huang},
  doi          = {10.1016/j.neucom.2021.06.027},
  journal      = {Neurocomputing},
  pages        = {308-318},
  shortjournal = {Neurocomputing},
  title        = {An autonomous learning mobile robot using biological reward modulate STDP},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards reading beyond faces for sparsity-aware 3D/4D affect
recognition. <em>NEUCOM</em>, <em>458</em>, 297–307. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a sparsity-aware deep network for automatic 3D/4D facial expression recognition (FER). We first propose a novel augmentation method to combat the data limitation problem for deep learning , specifically given 3D/4D face meshes. This is achieved by projecting the input data into RGB and depth map images and then iteratively performing randomized channel concatenation. Encoded in the given 3D landmarks, we also introduce an effective way to capture the facial muscle movements from three orthogonal plans (TOP), the TOP-landmarks over multi-views. Importantly, we then present a sparsity-aware deep network to compute the sparse representations of convolutional features over multi-views. This is not only effective for a higher recognition accuracy but also computationally convenient. For training, the TOP-landmarks and sparse representations are used to train a long short-term memory (LSTM) network for 4D data, and a pre-trained network for 3D data. The refined predictions are achieved when the learned features collaborate over multi-views. Extensive experimental results achieved on the Bosphorus, BU-3DFE, BU-4DFE and BP4D-Spontaneous datasets show the significance of our method over the state-of-the-art methods and demonstrate its effectiveness by reaching a promising accuracy of 99.69\% on BU-4DFE for 4D FER.},
  archive      = {J_NEUCOM},
  author       = {Muzammil Behzad and Nhat Vo and Xiaobai Li and Guoying Zhao},
  doi          = {10.1016/j.neucom.2021.06.023},
  journal      = {Neurocomputing},
  pages        = {297-307},
  shortjournal = {Neurocomputing},
  title        = {Towards reading beyond faces for sparsity-aware 3D/4D affect recognition},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State consensus cooperative control for a class of nonlinear
multi-agent systems with output constraints via ADP approach.
<em>NEUCOM</em>, <em>458</em>, 284–296. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A state consensus cooperative adaptive dynamic programming (ADP) control strategy is proposed for a nonlinear multi-agent system (MAS) with output constraints. On the basis of the transformation function, state models of leader and followers are transformed into affine ones. By using a monotonically increasing mapping function, the state-consensus cooperative control problem for an MAS with output constraints is equivalently transformed into a cooperative approximately optimal control one for an affine MAS. Then, a neural network observer is constructed for estimation of inner states, and, by graph theory and ADP method, the state consensus cooperative ADP control strategy is developed. The proposed strategy guarantees the performance index of the transformed system is approximately optimal. Furthermore, the stability analysis of whole closed-loop system is presented. Through the Lyapunov Theorem, we prove that the states of the MAS achieve consensus and the output signals of the followers satisfy the constraints. Also, all signals of the closed-loop MAS are bounded, and the trajectory of the leader node is cooperative bounded. The theoretical analysis and effectiveness of the strategy are verified by both a physical and a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Yang Yang and Xin Fan and Chuang Xu and Jinran Wu and Baohua Sun},
  doi          = {10.1016/j.neucom.2021.05.046},
  journal      = {Neurocomputing},
  pages        = {284-296},
  shortjournal = {Neurocomputing},
  title        = {State consensus cooperative control for a class of nonlinear multi-agent systems with output constraints via ADP approach},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Accelerated convergent zeroing neurodynamics models for
solving multi-linear systems with m-tensors. <em>NEUCOM</em>,
<em>458</em>, 271–283. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a special type of neurodynamic methodology dedicated to finding zeros of equations, zeroing neurodynamics has shown a powerful ability in solving challenging online time-varying problems. Multi-linear systems, on the other hand, are a type of tensor equations with a wide range of applications. In this paper, a zeroing neurodynamics approach for solving multi-linear systems with M M -tensors is proposed along with three specific accelerated finite-time convergent zeroing neurodynamics models, which breaks the limitations of a recently presented neural network approach termed continuous time neural network . Activation functions available in constructing zeroing neurodynamics models for solving multi-linear systems with M M -tensors are also investigated in the rest of the paper. Theoretical analyses prove that the proposed zeroing neurodynamics approach is stable in the sense of Lyapunov stability theory and the proposed models converge to the theoretical solution in finite time. Finally, computer simulations are provided to substantiate the efficacy and superiority of the proposed zeroing neurodynamics models for solving multi-linear systems with M M -tensors.},
  archive      = {J_NEUCOM},
  author       = {Shuqiao Wang and Long Jin and Xiujuan Du and Predrag S. Stanimirovi},
  doi          = {10.1016/j.neucom.2021.06.005},
  journal      = {Neurocomputing},
  pages        = {271-283},
  shortjournal = {Neurocomputing},
  title        = {Accelerated convergent zeroing neurodynamics models for solving multi-linear systems with M-tensors},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical-aware relation rotational knowledge graph
embedding for link prediction. <em>NEUCOM</em>, <em>458</em>, 259–270.
(<a href="https://doi.org/10.1016/j.neucom.2021.05.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding, as the upstream task of link prediction which aims to predict new links between entities under the premise of known relations, its reliability greatly affects the performance of link prediction. However, previous distance-based models focus on modeling complicated relation patterns while ignoring the semantic hierarchy of knowledge graph, from TransE to RotatE. In this setting, all entities are regarded as the same type, and the fact that different entities belong to different levels is neglected. Therefore, we propose the general form of RotatE, the hierarchical-aware relation rotational knowledge graph embedding (HA-RotatE), to model the hierarchical-aware knowledge graph. HA-RotatE represents entities and relations as complex vectors and uses different moduli of entity embeddings to indicate the different hierarchical levels they belong to. The transformation of modulus and rotation from head entity to tail entity depends on different relations. Some relations are used to link entities of the same level, and others are used to link entities of different levels. We adopt the shared modulus transformation parameter method for avoiding overfitting. As the general form of RotatE, HA-RotatE also has the ability to model and infer various relation modes, i.e., symmetry/antisymmetric, inversion and composition. On benchmark datasets WN18RR and FB15k-237, the experiments on link prediction tasks show that: (1) HA-RotatE can effectively model the semantic hierarchy of the knowledge graph; (2) Compared with competitive benchmarks, our model substantially outperforms them in most metrics.},
  archive      = {J_NEUCOM},
  author       = {Shensi Wang and Kun Fu and Xian Sun and Zequn Zhang and Shuchao Li and Li Jin},
  doi          = {10.1016/j.neucom.2021.05.093},
  journal      = {Neurocomputing},
  pages        = {259-270},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical-aware relation rotational knowledge graph embedding for link prediction},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Affect-salient event sequence modelling for continuous
speech emotion recognition. <em>NEUCOM</em>, <em>458</em>, 246–258. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continuous speech emotion recognition , which faces the problems of delay caused by annotators’ reaction time and noise caused by non-emotional segments, is a challenging subject in the field of affective computing . To solve these problems, we propose a new affect-salient event sequence modelling (ASESM) method based on connectionist temporal classification (CTC). This method treats a sentence’s label as a chain of affect-salient event (ASE) and non-affect-salient event Null states rather than continuous emotional value. With this representation, a CTC-based convolutional neural network (CNN) is built to automatically label the sentence’s emotional segments with ASE and non-emotional segments with Null, so as to reduce the impact of noise caused by non-emotional segments. Furthermore, we propose an event probability vector decoding (EPVD) algorithm to search the optimal ASE sequence from the CTC loss matrix and mark the occurrence time of each event within this sequence. Then, the arousal and valence ground-truth annotations of each ASE are used to represent the continuous emotional value of a segment which is predicted as the ASE. Since the ground-truth annotations of each ASE have contained different time-delays, taking events as the target can avoid the additional reaction delay compensation. We test our method on the RECOLA and AVEC 2014 benchmark databases. The experimental results demonstrate that the proposed event-based method can improve the performance of continuous emotion recognition and the improvement is more obvious when the selected ASE has high annotation consistency.},
  archive      = {J_NEUCOM},
  author       = {Yizhuo Dong and Xinyu Yang},
  doi          = {10.1016/j.neucom.2021.06.036},
  journal      = {Neurocomputing},
  pages        = {246-258},
  shortjournal = {Neurocomputing},
  title        = {Affect-salient event sequence modelling for continuous speech emotion recognition},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep supervised learning using self-adaptive auxiliary loss
for COVID-19 diagnosis from imbalanced CT images. <em>NEUCOM</em>,
<em>458</em>, 232–245. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The outbreak and rapid spread of coronavirus disease 2019 (COVID-19) has had a huge impact on the lives and safety of people around the world. Chest CT is considered an effective tool for the diagnosis and follow-up of COVID-19. For faster examination, automatic COVID-19 diagnostic techniques using deep learning on CT images have received increasing attention. However, the number and category of existing datasets for COVID-19 diagnosis that can be used for training are limited, and the number of initial COVID-19 samples is much smaller than the normal’s, which leads to the problem of class imbalance. It makes the classification algorithms difficult to learn the discriminative boundaries since the data of some classes are rich while others are scarce. Therefore, training robust deep neural networks with imbalanced data is a fundamental challenging but important task in the diagnosis of COVID-19. In this paper, we create a challenging clinical dataset (named COVID19-Diag) with category diversity and propose a novel imbalanced data classification method using deep supervised learning with a self-adaptive auxiliary loss (DSN-SAAL) for COVID-19 diagnosis. The loss function considers both the effects of data overlap between CT slices and possible noisy labels in clinical datasets on a multi-scale, deep supervised network framework by integrating the effective number of samples and a weighting regularization item. The learning process jointly and automatically optimizes all parameters over the deep supervised network, making our model generally applicable to a wide range of datasets. Extensive experiments are conducted on COVID19-Diag and three public COVID-19 diagnosis datasets. The results show that our DSN-SAAL outperforms the state-of-the-art methods and is effective for the diagnosis of COVID-19 in varying degrees of data imbalance.},
  archive      = {J_NEUCOM},
  author       = {Kai Hu and Yingjie Huang and Wei Huang and Hui Tan and Zhineng Chen and Zheng Zhong and Xuanya Li and Yuan Zhang and Xieping Gao},
  doi          = {10.1016/j.neucom.2021.06.012},
  journal      = {Neurocomputing},
  pages        = {232-245},
  shortjournal = {Neurocomputing},
  title        = {Deep supervised learning using self-adaptive auxiliary loss for COVID-19 diagnosis from imbalanced CT images},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online event-based adaptive critic design with experience
replay to solve partially unknown multi-player nonzero-sum games.
<em>NEUCOM</em>, <em>458</em>, 219–231. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper designs a novel online event-based near-optimal control scheme for multi-player nonzero-sum (NZS) games with partially unknown system dynamics. With the introduction of event-triggered mechanism (ETM), the repetitive computing burdens and communication loads of the signals are largely alleviated. Under the event-triggered mechanism, the framework of identifier-critic is structured to solve the coupled Hamilton–Jacobi equations (CHJEs) for NZS games. A feedforward neural network (FNN) is employed to construct an identifier to learn the unknown dynamics of the nonlinear system . The critic network for each player utilizes a modified tuning law, which is composed of three terms, to seek for the approximated optimal control schemes. Besides the conventional term derived from the gradient descent method , the second term derived from the experience replay (ER) technique utilizes the historical state data to update the critic network weight vector so as to remove the persistence of excitation (PE) condition. In addition, a novel term is added to stabilize the closed-loop systems. Owing to the stabilizing term, there is no need for the initial stabilizing control. In theory, the uniform ultimate boundedness (UUB) properties of the system states and the critic network weight errors are proved by utilizing Lyapunov theorem. Furthermore, the minimal intersample time is proved to be lower bounded with a positive constant which means that the Zeno behavior is excluded during the learning phases. Finally, we show the validity of the designed algorithm via simulating two examples.},
  archive      = {J_NEUCOM},
  author       = {Pengda Liu and Huaguang Zhang and Hanguang Su and He Ren},
  doi          = {10.1016/j.neucom.2021.05.087},
  journal      = {Neurocomputing},
  pages        = {219-231},
  shortjournal = {Neurocomputing},
  title        = {Online event-based adaptive critic design with experience replay to solve partially unknown multi-player nonzero-sum games},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unifying tensor factorization and tensor nuclear norm
approaches for low-rank tensor completion. <em>NEUCOM</em>,
<em>458</em>, 204–218. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank tensor completion (LRTC) has gained significant attention due to its powerful capability of recovering missing entries. However, it has to repeatedly calculate the time-consuming singular value decomposition (SVD). To address this drawback, we, based on the tensor-tensor product (t-product), propose a new LRTC method-the unified tensor factorization (UTF)-for 3-way tensor completion. We first integrate the tensor factorization (TF) and the tensor nuclear norm (TNN) regularization into a framework that inherits the benefits of both TF and TNN: fast calculation and convex optimization . The conditions under which TF and TNN are equivalent are analyzed. Then, UTF for tensor completion is presented and an efficient iterative updated algorithm based on the alternate direction method of multipliers (ADMM) is used for our UTF optimization, and the solution of the proposed alternate minimization algorithm is also proven to be able to converge to a Karush–Kuhn–Tucker (KKT) point. Finally, numerical experiments on synthetic data completion and image/video inpainting tasks demonstrate the effectiveness of our method over other state-of-the-art tensor completion methods.},
  archive      = {J_NEUCOM},
  author       = {Shiqiang Du and Qingjiang Xiao and Yuqing Shi and Rita Cucchiara and Yide Ma},
  doi          = {10.1016/j.neucom.2021.06.020},
  journal      = {Neurocomputing},
  pages        = {204-218},
  shortjournal = {Neurocomputing},
  title        = {Unifying tensor factorization and tensor nuclear norm approaches for low-rank tensor completion},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FG-RS: Capture user fine-grained preferences through
attribute information for recommender systems. <em>NEUCOM</em>,
<em>458</em>, 195–203. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender system uses user-item historical interactions to portray user preferences. Due to the problem of data sparseness, auxiliary information is introduced to describe user preferences, such as user/item attribute information. However, some of these methods only consider user(item) attributes when modeling user preferences. Although another part of the methods interact with user attributes and item attributes, this interaction doesn’t consider the potential preference of a certain attribute of the user to a certain attribute of the item. This makes the model unable to capture fine-grained user preferences. In fact, capturing fine-grained user preferences in terms of attributes is very effective in improving the recommendation effect. Therefore, in this paper we propose a recommendation method to capture user fine-grained preferences through attribute information. Specifically, there are two elaborately designed modules, interactive preference module and attribute fine-grained preference module. The former uses user-item historical interactions to model user’s interaction preferences. In order to obtain the user’s fine-grained preferences, the latter interacts with each attribute of the user and all the attributes of the item and uses the attention mechanism to mine the user’s more fine-grained preferences on attributes. Extensive experiments on three publicly available datasets demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hai Chen and Fulan Qian and Jie Chen and Shu Zhao and Yanping Zhang},
  doi          = {10.1016/j.neucom.2021.05.068},
  journal      = {Neurocomputing},
  pages        = {195-203},
  shortjournal = {Neurocomputing},
  title        = {FG-RS: Capture user fine-grained preferences through attribute information for recommender systems},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A gain-adjustment neural network based time-varying
underdetermined linear equation solving method. <em>NEUCOM</em>,
<em>458</em>, 184–194. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To solve the time-varying underdetermined linear equation (TVULE), a gain-adjustment neural network (GANN) is proposed, designed and analyzed. First, based on the exploited error monitoring function and neural dynamic method, a GANN based linear equation solving method with gain-adjustment parameter is obtained. Second, the global convergence theorem is proved and shows that the state output of the GANN will converge to the solution of TVULE super-exponentially. Furthermore, the strong robustness of the GANN can be ensured theoretically. Third, compared with some traditional neural networks like the gradient neural network and the zeroing neural network, the computer simulations illustrate that the GANN has the fastest speed, the best accuracy and the best anti-noise capability when considering external disturbances. Meanwhile, a practical application to solve a motion planning scheme of redundant robot manipulators further verifies the flexibility and superiority of the GANN.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Zhang and Lunan Zheng and Tairu Qiu},
  doi          = {10.1016/j.neucom.2021.05.096},
  journal      = {Neurocomputing},
  pages        = {184-194},
  shortjournal = {Neurocomputing},
  title        = {A gain-adjustment neural network based time-varying underdetermined linear equation solving method},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive gaussian mixture method for nonlinear
uncertainty propagation in neural networks. <em>NEUCOM</em>,
<em>458</em>, 170–183. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Using neural networks to address data-driven problems often entails dealing with uncertainties. However, the propagation of uncertainty through a network’s nonlinear layers is usually a bottleneck, since the existing techniques designed to transmit Gaussian distributions via moment estimation are not capable of predicting non-Gaussian distributions. In this study, a Gaussian-mixture-based uncertainty propagation scheme is proposed for neural networks. Given that any input uncertainty can be characterized as a Gaussian mixture with a finite number of components, the developed scheme actively examines each mixture component and adaptively split those whose fidelity in representing uncertainty is deteriorated by the network’s nonlinear activation layers. A Kullback–Leibler criterion that directly measures the nonlinearity-induced non-Gaussianity in post-activation distributions is derived to trigger splitting and a set of high-precision Gaussian splitting libraries is established. Four uncertainty propagation examples on dynamic systems and data-driven applications are demonstrated, in all of which the developed scheme exhibited exemplary fidelity and efficiency in predicting the evolution of non-Gaussian distributions through both recurrent and multi-layer neural networks.},
  archive      = {J_NEUCOM},
  author       = {Bin Zhang and Yung C. Shin},
  doi          = {10.1016/j.neucom.2021.06.007},
  journal      = {Neurocomputing},
  pages        = {170-183},
  shortjournal = {Neurocomputing},
  title        = {An adaptive gaussian mixture method for nonlinear uncertainty propagation in neural networks},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-aware self-attention networks for natural language
processing. <em>NEUCOM</em>, <em>458</em>, 157–169. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Self-Attention Networks (SANs) have shown its flexibility in parallel computation and effectiveness of modeling both short- and long-term dependencies. However, SANs face two problems: 1) the weighted averaging inhibits relations among neighboring words (i.e., local context ); and 2) it calculates dependencies between representations without considering contextual information (i.e., global context ). Both local and global contexts have proven useful for modeling dependencies among neural representations in a variety of natural language processing tasks. Accordingly, we augment SANs with the ability of capturing usefully local and global context, and meanwhile maintain their simplicity and flexibility. Firstly, we cast local context modeling as a learnable Gaussian bias, which indicates the central and scope of the local region to be paid more attention. The bias is then incorporated into the original attention distribution to form a revised version. Secondly, we leverage the internal representations that embed sentence-level information as the global context. Specifically, we propose to contextualize the transformations of query and key layers, which are used to calculate the relevance between elements. Since the two approaches are potentially complementary to each other, we propose to combine them to further improve the performance. Empirical results on machine translation and linguistics probing tasks demonstrate the effectiveness and universality of the proposed approaches. Further analyses confirm that our approaches successfully capture contextual information as expected.},
  archive      = {J_NEUCOM},
  author       = {Baosong Yang and Longyue Wang and Derek F. Wong and Shuming Shi and Zhaopeng Tu},
  doi          = {10.1016/j.neucom.2021.06.009},
  journal      = {Neurocomputing},
  pages        = {157-169},
  shortjournal = {Neurocomputing},
  title        = {Context-aware self-attention networks for natural language processing},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explaining clinical decision support systems in medical
imaging using cycle-consistent activation maximization. <em>NEUCOM</em>,
<em>458</em>, 141–156. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clinical decision support using deep neural networks has become a topic of steadily growing interest. While recent work has repeatedly demonstrated that deep learning offers major advantages for medical image classification over traditional methods, clinicians are often hesitant to adopt the technology because its underlying decision-making process is considered to be intransparent and difficult to comprehend. In recent years, this has been addressed by a variety of approaches that have successfully contributed to providing deeper insight. Most notably, additive feature attribution methods are able to propagate decisions back into the input space by creating a saliency map which allows the practitioner to “see what the network sees.” However, the quality of the generated maps can become poor and the images noisy if only limited data is available—a typical scenario in clinical contexts. We propose a novel decision explanation scheme based on CycleGAN activation maximization which generates high-quality visualizations of classifier decisions even in smaller data sets. We conducted a user study in which we evaluated our method on the LIDC dataset for lung lesion malignancy classification, the BreastMNIST dataset for ultrasound image breast cancer detection, as well as two subsets of the CIFAR-10 dataset for RBG image object recognition. Within this user study, our method clearly outperformed existing approaches on the medical imaging datasets and ranked second in the natural image setting. With our approach we make a significant contribution towards a better understanding of clinical decision support systems based on deep neural networks and thus aim to foster overall clinical acceptance.},
  archive      = {J_NEUCOM},
  author       = {Alexander Katzmann and Oliver Taubmann and Stephen Ahmad and Alexander Mühlberg and Michael Sühling and Horst-Michael Groß},
  doi          = {10.1016/j.neucom.2021.05.081},
  journal      = {Neurocomputing},
  pages        = {141-156},
  shortjournal = {Neurocomputing},
  title        = {Explaining clinical decision support systems in medical imaging using cycle-consistent activation maximization},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Density saliency for clustered building detection and
population capacity estimation. <em>NEUCOM</em>, <em>458</em>, 127–140.
(<a href="https://doi.org/10.1016/j.neucom.2021.06.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Building detection is a critically important task in the field of remote sensing and it is conducive to urban construction planning, disaster survey, shantytown modification, and emergency landing, it etc. However, few studies have focused on the task of the clustered building detection which is inescapable and challenging for some relatively low space resolution images. The appearance structures of those buildings are not clear enough for the single-building detection. Whereas, it has been found that the distributions of clustered buildings are mostly dense and cellular, while the backgrounds are not. This clue will be beneficial to the clustered building detection. Motivated by the fact above and other similar density estimation applications, this work mainly focuses on the information mining mechanism of dense and cellular structure. Firstly, we propose a concept of Clustered Building Detection (CBD), which contributes to develop clustered building detection techniques of remote sensing images . Secondly, a saliency estimation algorithm is proposed to mine the prior information for the clustered buildings. Thirdly and most notably, combining with the CBD and the density saliency map, a Population Capacity Estimation (PCE) method is presented. The PCE can be easily used to estimate the population carrying capacity of certain areas and future applied for national land resource management. Moreover, a Clustered Building Detection Dataset (CBDD) from Gaofen-2 satellite is annotated and contributed for the public research. The experimental results by the representative detection algorithms manifest the effectiveness for the clustered building detection.},
  archive      = {J_NEUCOM},
  author       = {Kang Liu and Ju Huang and Mingliang Xu and Matjaž Perc and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.06.002},
  journal      = {Neurocomputing},
  pages        = {127-140},
  shortjournal = {Neurocomputing},
  title        = {Density saliency for clustered building detection and population capacity estimation},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Manifold constrained joint sparse learning via non-convex
regularization. <em>NEUCOM</em>, <em>458</em>, 112–126. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional robust principal component analysis (RPCA) via decomposition into low-rank plus sparse matrices offers a powerful framework for a large variety of applications in computer vision. However, the reconstructed image experiences serious interference by Gaussian noise , resulting in the degradation of image quality during the denoising process. Thus, a novel manifold constrained joint sparse learning (MCJSL) via non-convex regularization approach is proposed in this paper. Morelly, the manifold constraint is adopted to preserve the local geometric structures and the non-convex joint sparsity is introduced to capture the global row-wise sparse structures. To solve MCJSL, an efficient optimization algorithm using the manifold alternating direction method of multipliers (MADMM) is designed with closed-form solutions and it achieves a fast and convergent procedure. Moreover, the convergence is analyzed mathematically and numerically. Comparisons among the proposed MCJSL and some state-of-the-art solvers, on several accessible datasets, are presented to demonstrate its superiority in image denoising and background subtraction . The results indicate the importance to incorporate the manifold learning and non-convex joint sparse regularization into a general RPCA framework.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Liu and Xianchao Xiu and Xin Jiang and Wanquan Liu and Xiaoyang Zeng and Mingyu Wang and Hui Chen},
  doi          = {10.1016/j.neucom.2021.06.008},
  journal      = {Neurocomputing},
  pages        = {112-126},
  shortjournal = {Neurocomputing},
  title        = {Manifold constrained joint sparse learning via non-convex regularization},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural network-based adaptive hybrid impedance control for
electrically driven flexible-joint robotic manipulators with input
saturation. <em>NEUCOM</em>, <em>458</em>, 99–111. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a neural network (NN)-based adaptive hybrid impedance control (AHIC) scheme is proposed for the electrically driven flexible-joint robotic manipulators (EDFJRM) with input saturation, where the hybrid impedance is designed to obtain the reference trajectory by combining the position/force control with the impedance control . The proposed scheme integrates hybrid impedance control into backstepping technique, where a smooth saturation function is employed to facilitate input saturation. Moreover, the reference input trajectory of the robot is obtained by different target dynamics in the free space and the constrained space, and NNs are employed to approximate the saturation errors term, uncertain parts and external disturbances. In this way, the control objective of the position and force tracking can be realized in both free space and constrained space. Lyapunov stability analysis shows that all the signals in closed-loop system are guaranteed to be uniformly ultimately bounded, and the steady-state tracking errors of the position in the free space and the force in the constrained space are converged to zero. Finally, simulation results of two-rigid-link EDFJRM demonstrate the effectiveness of the proposed NN-based AHIC scheme.},
  archive      = {J_NEUCOM},
  author       = {Shuai Ding and Jinzhu Peng and Hui Zhang and Yaonan Wang},
  doi          = {10.1016/j.neucom.2021.05.095},
  journal      = {Neurocomputing},
  pages        = {99-111},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based adaptive hybrid impedance control for electrically driven flexible-joint robotic manipulators with input saturation},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differentially private average consensus with general
directed graphs. <em>NEUCOM</em>, <em>458</em>, 87–98. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy , a strict privacy notion, prevents the presence or absence of a single data from being identified. This paper proposes a novel average consensus algorithm to achieve differentially private average consensus on multi-agent systems (MASs) with general directed graphs . For MASs under the proposed algorithm, necessary and sufficient conditions are established on achieving average consensus and preserving differential privacy of the states of the agents at any time instant. Finally, numerical examples are provided to illustrate these results.},
  archive      = {J_NEUCOM},
  author       = {Yamin Wang and James Lam and Hong Lin},
  doi          = {10.1016/j.neucom.2021.06.016},
  journal      = {Neurocomputing},
  pages        = {87-98},
  shortjournal = {Neurocomputing},
  title        = {Differentially private average consensus with general directed graphs},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive neural backstepping control for flexible-joint
robot manipulator with bounded torque inputs. <em>NEUCOM</em>,
<em>458</em>, 70–86. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at tracking control with bounded torque inputs of the flexible-joint robot manipulators, we propose a generalized saturated adaptive controller based on backstepping control, singular perturbation decoupling and neural networks . First, by using the singular perturbation theory, the full-order rigid-flexible dynamics of the robot manipulator is decoupled into a slow subsystem and a fast subsystem. Second, saturated sub-controller by backstepping method is proposed for the slow subsystem, where the projection-type parameter adaptation and a class of saturation functions are applied to make the torque inputs bounded, and a saturated neural network approximator is involved to simplify the control law and to compensate for the uncertain nonlinearity. Third, for fast subsystem, a new filtered tracking error of the elastic torque is used in the fast control law to make the boundary layer subside quickly. In addition, explicit but strict stability analysis is given for the system. Finally, comparisons indicate that the proposed controller results in a more satisfactory tracking performance with keeping the control inputs bounded within the given range all the time and superior anti-disturbance capability.},
  archive      = {J_NEUCOM},
  author       = {Xin Cheng and Yajun Zhang and Huashan Liu and Dirk Wollherr and Martin Buss},
  doi          = {10.1016/j.neucom.2021.06.013},
  journal      = {Neurocomputing},
  pages        = {70-86},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural backstepping control for flexible-joint robot manipulator with bounded torque inputs},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint structured pruning and dense knowledge distillation
for efficient transformer model compression. <em>NEUCOM</em>,
<em>458</em>, 56–69. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we develop a novel Joint Model Compression (referred to as JMC) method by combining structured pruning and dense knowledge distillation techniques to significantly compress original large language model into a deep compressed shallow network. In particular, a new Direct Importance-aware Structured Pruning (referred as DISP) approach is proposed to structurally prune the redundant structures in the Transformer networks directly based on the corresponding parameter matrices in the model. Besides, a Dense Knowledge Distillation (referred to as DKD) method is developed with a many-to-one layer mapping strategy to leverage more comprehensive layer-wise linguistic knowledge for the distillation. Further, the proposed structured pruning and dense knowledge distillation are integrated together to perform the joint compression, which enables us to achieve a significant compression without sacrificing model accuracy. The extensive experimental results across four NLP tasks on seven datasets demonstrate its effectiveness and superiority to the baselines, while maintaining similar performance to original large model with further remarkable benefits for inference-time speedup and memory efficiency.},
  archive      = {J_NEUCOM},
  author       = {Baiyun Cui and Yingming Li and Zhongfei Zhang},
  doi          = {10.1016/j.neucom.2021.05.084},
  journal      = {Neurocomputing},
  pages        = {56-69},
  shortjournal = {Neurocomputing},
  title        = {Joint structured pruning and dense knowledge distillation for efficient transformer model compression},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Robust multi-view fuzzy clustering via softmin.
<em>NEUCOM</em>, <em>458</em>, 47–55. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering, which utilizes the ample information provided by multiple sources to obtain better performance, has attracted much attention. However, existing clustering algorithms either have no ability to offer confidence for each assignment or suffer from the disturbance of outliers. To address these problems, in this paper, we propose a novel multi-view fuzzy clustering method via transferring softmin to fuzzy models. To obtain fuzzy assignments, we utilize the softmin with temperature and further develop an efficient algorithm to solve the non-convex problem approximately. We also show another explanation for the algorithm from the aspect of the prior distribution of various views. Besides, we design a scalable robust loss function, which interpolates between ℓ 2 -norm and the squared ℓ 2 -norm, to enhance the robustness to outliers. Extensive experiments show the superiority of our model under different clustering metrics .},
  archive      = {J_NEUCOM},
  author       = {Hongyuan Zhang and Rui Zhang and Xuelong Li and Yueshen Xu},
  doi          = {10.1016/j.neucom.2021.06.011},
  journal      = {Neurocomputing},
  pages        = {47-55},
  shortjournal = {Neurocomputing},
  title        = {Robust multi-view fuzzy clustering via softmin},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-based saliency detection using a learning joint
affinity matrix. <em>NEUCOM</em>, <em>458</em>, 33–46. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph model is a reliable propagation mechanism in saliency detection , saliency value propagation diffusion results between any two nodes are determined merely by defining an effect affinity matrix . Most existing methods generally calculamatrix using mean values of single or multiple feature vectors, not fully exploit the diversity and consistency of multi-view features, may produce poor foreground uniformity and completeness in the complex scene. Multi-views should share an affinity matrix as well as complement each other. In this paper, we propose a graph-based saliency detection with a learning joint affinity matrix. First, we capture multiple appearance features from the image and generate a learning joint affinity matrix based on low-rank representation. Then, for computing an effect affinity matrix, we linearly integrate the traditional affinity matrix and learning joint affinity matrix, helping to construct an affinity graph for diffusion-based compactness. Finally, to effectively optimize the initial saliency map, we diffuse the learning joint affinity matrix and traditional impact factor matrix via cross-view diffusion processing, which begets an approving advantage for single-layer cellular automata . Results on three benchmark datasets demonstrate that our proposed method shows the best performance against nine state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Fan Wang and Guohua Peng},
  doi          = {10.1016/j.neucom.2021.03.131},
  journal      = {Neurocomputing},
  pages        = {33-46},
  shortjournal = {Neurocomputing},
  title        = {Graph-based saliency detection using a learning joint affinity matrix},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks-based adaptive tracking control of
multi-agent systems with output-constrained and unknown hysteresis.
<em>NEUCOM</em>, <em>458</em>, 24–32. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of adaptive tracking control for multi-agent systems subject to output constraint and unknown hysteresis. Different from most existing results that use the barrier Lyapunov function and integral barrier Lyapunov function to solve the output constraint problem, the transformation technique is introduced in this paper, which can convert the original system to a constrained or completely unconstrained system. The difficulty caused by unknown Bouc-Wen hysteresis is solved via the Nussbaum gain technique. The continuous unknown function is estimated by using the radial basis function neural networks . The tracking differentiator is utilized to overcome the difficulty of “explosion of complexity”. By using the Lyapunov stability theory , it is indicated that all signals of the closed-loop system are semi-globally uniformly ultimately bounded, and the tracking error converges to a small neighborhood of the origin. Eventually, the feasibility of the designed approach is demonstrated by some simulation results.},
  archive      = {J_NEUCOM},
  author       = {Zhihua Guo and Hong Xue and Yingnan Pan},
  doi          = {10.1016/j.neucom.2021.05.079},
  journal      = {Neurocomputing},
  pages        = {24-32},
  shortjournal = {Neurocomputing},
  title        = {Neural networks-based adaptive tracking control of multi-agent systems with output-constrained and unknown hysteresis},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving human action recognition by jointly exploiting
video and WiFi clues. <em>NEUCOM</em>, <em>458</em>, 14–23. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years have witnessed the increasing attentions on human action recognition(HAR). Traditional methods are prone to explore the optimum spatiotemporal feature representation of human actions in video clips so as to achieve high recognition performance. However, the optical limitations, such as inappropriate view, dim illumination and object occlusion, usually degrade video quality and affect the recognition performance a lot. Considering that wireless signals are robust against optical limitations, we thus incorporate WiFi signals with video streams for HAR. Specifically, we use WiFi Channel State Information as a compensator for video streams. A great challenge is how to effectively fuse the video and WiFi information to achieve better prediction performance. To this end, we employ convolution neural networks and statistic analysis algorithms to extract video and WiFi features respectively, and propose a novel multi-modal learning approach for video and WiFi feature fusion , where the video and WiFi features are projected to a common space by supervised learning. The experimental results indicate that the recognition precision of human actions in videos improved obviously with the aid of WiFi signals and the proposed multi-modal learning approach rivals the state of art methods.},
  archive      = {J_NEUCOM},
  author       = {Jun Guo and Mei Shi and Xingwu Zhu and Wei Huang and Yi He and Weiwei Zhang and Zhanyong Tang},
  doi          = {10.1016/j.neucom.2020.11.074},
  journal      = {Neurocomputing},
  pages        = {14-23},
  shortjournal = {Neurocomputing},
  title        = {Improving human action recognition by jointly exploiting video and WiFi clues},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intent-enhanced attentive bert capsule network for zero-shot
intention detection. <em>NEUCOM</em>, <em>458</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spoken language understanding (SLU) plays an indispensable role in the dialogue system . The traditional intention detection task is regarded as a classification problem where utterances are associated with pre-defined intents. However, the various expressions of user&#39;s intents and constantly emerging novel intents make the annotating time-consuming and labor-intensive, building massive obstacles for extending the model to new tasks. Identifying unexpected user intention and achieving the user&#39;s desire goal is a challenging task. Therefore, we conduct zero-shot intention detection based on a transformation-based learning manner. In this paper, we propose an intent-enhanced attentive capsule network (IE-BertCapsNet) further guides the aggregation process of the capsule network and generalizable useful features that can be adapted to emerging intentions. Coupling with the large margin cosine loss function, the proposed model can identify discriminative features by forcing the whole network to minimize inter-class distance and minimize intra-class distance. Finally, we leverage the IE-BertCapsNet’s feature extraction ability and knowledge transferring capability to conduct zero-shot intent detection and generalized zero-shot intent detection. Extensive experiments on five benchmark task-oriented datasets in four languages demonstrate that the proposed model can achieve competitive performance that can better discriminate known intents and detect unknown intents.},
  archive      = {J_NEUCOM},
  author       = {Siyuan Xue and Fuji Ren},
  doi          = {10.1016/j.neucom.2021.05.085},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Intent-enhanced attentive bert capsule network for zero-shot intention detection},
  volume       = {458},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A contour-aware feature-merged network for liver
segmentation based on shape prior knowledge. <em>NEUCOM</em>,
<em>457</em>, 389–399. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One primary challenge in liver segmentation is the fuzzy edge contour. Recently, fully convolutional neural networks (FCNs) have been widely used in liver segmentation because of their adequate feature extraction. Nevertheless, the context among liver slices is still ignored by FCN. To address this issue, we first propose a bidirectional convolutional long short-term memory (BiConvLSTM) to explore contextual information. Meanwhile, the attention gate (AG) is utilized to fuse high-dimensional information from BiConvLSTM to remove irrelevant features. Besides, Shape-Net network is proposed to extend the liver shape pattern by latent space information, which will contribute to reduce the interference of fuzzy boundaries. Finally, the improved active contour loss function with L2 norm acts as a feature constraint. Experimental results on public benchmark datasets show that the proposed method slightly outperforms other newly published methods and achieves good performance for liver segmentation.},
  archive      = {J_NEUCOM},
  author       = {Lifang Zhou and Xueyuan Deng and Weisheng Li and Shenhai Zheng and Bangjun Lei},
  doi          = {10.1016/j.neucom.2021.04.079},
  journal      = {Neurocomputing},
  pages        = {389-399},
  shortjournal = {Neurocomputing},
  title        = {A contour-aware feature-merged network for liver segmentation based on shape prior knowledge},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel context-aware multimodal framework for persian
sentiment analysis. <em>NEUCOM</em>, <em>457</em>, 377–388. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recent works on sentiment analysis have exploited the text modality. However, millions of hours of video recordings posted on social media platforms everyday hold vital unstructured information that can be exploited to more effectively gauge public perception. Multimodal sentiment analysis offers an innovative solution to computationally understand and harvest sentiments from videos by contextually exploiting audio, visual and textual cues. In this paper, we, firstly, present a first of its kind Persian multimodal dataset comprising more than 800 utterances, as a benchmark resource for researchers to evaluate multimodal sentiment analysis approaches in Persian language. Secondly, we present a novel context-aware multimodal sentiment analysis framework, that simultaneously exploits acoustic, visual and textual cues to more accurately determine the expressed sentiment. We employ both decision-level (late) and feature-level (early) fusion methods to integrate affective cross-modal information. Experimental results demonstrate that the contextual integration of multimodal features such as textual, acoustic and visual features deliver better performance (91.39\%) compared to unimodal features (89.24\%).},
  archive      = {J_NEUCOM},
  author       = {Kia Dashtipour and Mandar Gogate and Erik Cambria and Amir Hussain},
  doi          = {10.1016/j.neucom.2021.02.020},
  journal      = {Neurocomputing},
  pages        = {377-388},
  shortjournal = {Neurocomputing},
  title        = {A novel context-aware multimodal framework for persian sentiment analysis},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial imitation learning with mixed demonstrations
from multiple demonstrators. <em>NEUCOM</em>, <em>457</em>, 365–376. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of generative adversarial imitation learning (GAIL) is to allow an agent to learn an optimal policy from demonstrations via an adversarial training process. However, previous works have not considered a realistic setting for complex continuous control tasks such as robot manipulation, in which the available demonstrations are imperfect and possibly originate from different policies. Such a setting poses significant challenges for the application of the GAIL-related methods. This paper proposes a novel imitation learning (IL) algorithm, MD2-GAIL, to enable an agent to learn effectively from imperfect demonstrations by multiple demonstrators. Instead of training the policy from scratch, unsupervised pretraining is used to speed up the adversarial learning process. Confidence scores representing the quality of the demonstrations are utilized to reconstruct the objective function for off-policy adversarial training , making the policy match the optimal occupancy measure. Based on the Soft Actor Critic (SAC) algorithm, MD2-GAIL incorporates the idea of maximum entropy into the process of optimizing the objective function. Meanwhile, a reshaped reward function is adopted to update the agent policy to avoid falling into local optima.Experiments were conducted based on robotic simulation tasks, and the results show that our method can efficiently learn from the available demonstrations and achieves better performance than other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Guoyu Zuo and Qishen Zhao and Shuai Huang and Jiangeng Li and Daoxiong Gong},
  doi          = {10.1016/j.neucom.2021.06.053},
  journal      = {Neurocomputing},
  pages        = {365-376},
  shortjournal = {Neurocomputing},
  title        = {Adversarial imitation learning with mixed demonstrations from multiple demonstrators},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic binary neural networks with time-variant parameters
and switching of desired periodic orbits. <em>NEUCOM</em>, <em>457</em>,
357–364. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies 3-layer dynamic binary neural networks characterized by binary connection parameters and the signum activation function . The connection parameters and the number of hidden neurons are time-variant. The dynamics is described by a non-autonomous difference equation of binary state variables and the network can generate various periodic orbits of binary vectors. First, we present a simple synthesis method that guarantees storage of desired multiple periodic orbits and switching of the periodic orbits through desired entrances. Second, as a basic step to engineering applications, we present an FPGA based hardware prototype. The hardware can realize switching of various periodic orbits experimentally and typical examples are demonstrated. The switching of periodic orbits is applicable to switching of walking patterns in robotics and variable output of switching power converters.},
  archive      = {J_NEUCOM},
  author       = {Shota Anzai and Takumi Suzuki and Toshimichi Saito},
  doi          = {10.1016/j.neucom.2021.06.054},
  journal      = {Neurocomputing},
  pages        = {357-364},
  shortjournal = {Neurocomputing},
  title        = {Dynamic binary neural networks with time-variant parameters and switching of desired periodic orbits},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extreme theory of functional connections: A fast
physics-informed neural network method for solving ordinary and partial
differential equations. <em>NEUCOM</em>, <em>457</em>, 334–356. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present a novel, accurate, fast, and robust physics-informed neural network method for solving problems involving differential equations (DEs), called Extreme Theory of Functional Connections , or X-TFC. The proposed method is a synergy of two recently developed frameworks for solving problems involving DEs: the Theory of Functional Connections TFC, and the Physics-Informed Neural Networks PINN. Here, the latent solution of the DEs is approximated by a TFC constrained expression that employs a Neural Network (NN) as the free-function. The TFC approximated solution form always analytically satisfies the constraints of the DE, while maintaining a NN with unconstrained parameters. X-TFC uses a single-layer NN trained via the Extreme Learning Machine (ELM) algorithm. This choice is based on the approximating properties of the ELM algorithm that reduces the training of the network to a simple least-squares, because the only trainable parameters are the output weights. The proposed methodology was tested over a wide range of problems including the approximation of solutions to linear and nonlinear ordinary DEs (ODEs), systems of ODEs, and partial DEs (PDEs). The results show that, for most of the problems considered, X-TFC achieves high accuracy with low computational time, even for large scale PDEs, without suffering the curse of dimensionality.},
  archive      = {J_NEUCOM},
  author       = {Enrico Schiassi and Roberto Furfaro and Carl Leake and Mario De Florio and Hunter Johnston and Daniele Mortari},
  doi          = {10.1016/j.neucom.2021.06.015},
  journal      = {Neurocomputing},
  pages        = {334-356},
  shortjournal = {Neurocomputing},
  title        = {Extreme theory of functional connections: A fast physics-informed neural network method for solving ordinary and partial differential equations},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unnoticeable synthetic face replacement for image privacy
protection. <em>NEUCOM</em>, <em>457</em>, 322–333. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A rapidly growing amount of personal sensitive information is being released to the public due to unprotected sharing of face images and videos on social networks. Although some pioneering face de-identification techniques, such as face blurring, have been proposed, there is still a long way towards providing full protection of one’s facial privacy. In this paper, we propose a novel end-to-end privacy protection approach to seamlessly replace a face in an image with a synthesized face that looks as natural as normal photos yet pertaining very different look from the original face. The synthesized face images will prevent potential attackers from de-identifying the users. Specifically, our approach relies on generative adversarial network and considers both the foreground and background constrains with respect to the input face image to achieve the following two goals: Firstly, to make synthesized images perceptually unaltered, we design a new generative model to effectively fuse a synthesized face with the original background. Secondly, to ensure a synthesized face to be much different from the original face, we define multiple losses to distinguish the synthesized face from the original face. The experimental results on public datasets have validated the effectiveness of our approach compared with the-state-of-the-art.},
  archive      = {J_NEUCOM},
  author       = {Zhenzhong Kuang and Zhiqiang Guo and Jinglong Fang and Jun Yu and Noboru Babaguchi and Jianping Fan},
  doi          = {10.1016/j.neucom.2021.06.061},
  journal      = {Neurocomputing},
  pages        = {322-333},
  shortjournal = {Neurocomputing},
  title        = {Unnoticeable synthetic face replacement for image privacy protection},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Single-image de-raining using joint filter and multi-scale
deep alternate-connection dense network. <em>NEUCOM</em>, <em>457</em>,
306–321. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims at developing an effective approach to remove rain layer from an individual image. The proposed is a two-stage method named JF-MADN consisting of a Joint Filter (JF) extracting high frequency details from rainy image and a Multi-scale deep Alternate-connection Dense Network (MADN) separating rain streaks in a coarse-to-fine manner. In the first stage, rainy image is enhanced first through a high frequency emphasis filter. Next, a gradient operator is deduced based on trigonometric function and Laplacian operator to generate rain gradient prior. By combining it with rain dark channel prior, a rain-prior weighted statistic order filter could be constructed to separate high and low frequency components of rainy image. Then, the result image through a guided filter followed by would be subtracted by the original low frequency component to obtain residuals for final operation with high frequency component to generate high quality initial rain layer. In the second stage, by adopting multi-scale mechanism, this study develops two new alternate-connected fully convolutional DenseNets in different scale, WNet-129 and NNet-96, to implement de-raining. By combining element-wise addition in our alternate-connection structure with original concatenation in fully convolutional DenseNet , features could be constantly connected in our network. Experimental results demonstrate that the proposed framework outperforms existing single-image de-raining algorithms on testing rainy images. Code available at: http://www.imagetech-polynomials.com/derain.html.},
  archive      = {J_NEUCOM},
  author       = {Pengyu Wang and Hongqing Zhu},
  doi          = {10.1016/j.neucom.2021.06.052},
  journal      = {Neurocomputing},
  pages        = {306-321},
  shortjournal = {Neurocomputing},
  title        = {Single-image de-raining using joint filter and multi-scale deep alternate-connection dense network},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive neural design of fixed-time controllers for MIMO
systems with nonlinear static and dynamic interactions. <em>NEUCOM</em>,
<em>457</em>, 293–305. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing fixed-time adaptive neural controllers for uncertain multi-input/multi-output (MIMO) systems with unknown nonlinear interactions only ensure practical fixed-time stabilization or require extra assumptions on system nonlinear functions . To remove these limitations and improve the result to fixed-time stabilization, a dynamic switched Lyapunov function candidate is newly proposed, based on which a novel direct adaptive neural strategy is developed to design fixed-time stable controllers for MIMO systems. To overcome the difficulty in establishing fixed-time stability in the presence of unknown interactions, a two-step Lyapunov function analysis method is proposed to prove that the tracking errors asymptotically converge to preassigned values within a fixed time. Simulation studies substantiate the methods developed.},
  archive      = {J_NEUCOM},
  author       = {Kaixin Lu and Zhi Liu and C.L. Philip Chen and Yun Zhang},
  doi          = {10.1016/j.neucom.2021.06.060},
  journal      = {Neurocomputing},
  pages        = {293-305},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural design of fixed-time controllers for MIMO systems with nonlinear static and dynamic interactions},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A visual place recognition approach using learnable feature
map filtering and graph attention networks. <em>NEUCOM</em>,
<em>457</em>, 277–292. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual place recognition (VPR) in environments subject to extreme appearance variation due to changing weather, illumination or seasons is a challenging task. Recent works have shown that features learned from CNNs can achieve promising performance. However, most of the existing methods concentrate so much on the image itself that they neglect the architecture of the network, especially different filters that may carry more meaningful information. In this paper, we develop a learnable feature map filtering (FMF) module constrained by triplet loss to re-calibrate the weight of the individual feature map. In this way, specific feature maps that encode invariant characteristics of location are extracted. Moreover, to make full use of the rich global mutual information that resides in the sample set, we propose an influence-based graph attention network (IB-GAT) with a verification subnet to better incorporate the relations among samples during the training process. Different from conventional GAT approaches, IB-GAT enables feature nodes to attend over the influence of other nodes instead of the original feature. Thus refined features with more discriminative power could be generated. Extensive experiments have been conducted on six public VPR datasets with varying appearances. Ablation analysis verifies the potential efficacy of the FMF module and the IB-GAT components. The experimental results also demonstrate that the proposed methods can achieve better performance than the current state of the art.},
  archive      = {J_NEUCOM},
  author       = {Cao Qin and Yunzhou Zhang and Yingda Liu and Sonya Coleman and Huijie Du and Dermot Kerr},
  doi          = {10.1016/j.neucom.2021.06.038},
  journal      = {Neurocomputing},
  pages        = {277-292},
  shortjournal = {Neurocomputing},
  title        = {A visual place recognition approach using learnable feature map filtering and graph attention networks},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long short-term memory self-adapting online random forests
for evolving data stream regression. <em>NEUCOM</em>, <em>457</em>,
265–276. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolving data stream, especially with concept drift is generally accepted as a challenging data type for regression task , because it usually makes machine learning models trained on old data not adapting to new data, and leads to dramatic performance degradation as a result. Moreover, the behavior of a data stream may change in different modes and therefore introduces various concept drifts, e.g., abrupt, incremental, gradual, recurring, even more, complex concept drifts. Although there are some algorithms that can adapt to stationary data streams or a specific type of concept drift in non-stationary data streams, a wide range of practical applications call for machine learning regression models to handle multi-type of data streams. In this work, we propose an online learning strategy called adaptive long and short-term memories online Random Forests regression(ALSM-RFR), where an adaptive memory activation mechanism is designed to make the model switch adaptively between long-term and hybrid (long-term plus short-term) memory modes in the face of stationary data streams or non-stationary data streams with different types of concept drift. In particular, leaf and tree weights in random forests are used to learn information at different timescales, namely, long-term and short-term memories. Moreover, we devise an adaptive memory activation mechanism to formulate the switch decision of memory modes as a classification problem. Numerical experiments show remarkable improvements of the proposed method in the adaptability of stream types and predictive accuracy in data streams across several real datasets and synthetic datasets , compared to the state-of-the-art online approaches. Besides, the convergence and the influence of the parameters involved in our method are evaluated.},
  archive      = {J_NEUCOM},
  author       = {Yuan Zhong and Hongyu Yang and Yanci Zhang and Ping Li and Cheng Ren},
  doi          = {10.1016/j.neucom.2021.05.026},
  journal      = {Neurocomputing},
  pages        = {265-276},
  shortjournal = {Neurocomputing},
  title        = {Long short-term memory self-adapting online random forests for evolving data stream regression},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Topology identification of coupled neural networks with
multiple weights. <em>NEUCOM</em>, <em>457</em>, 254–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concentrates on the research of topology identification problem for coupled neural networks with multiple state couplings (CNNMSCs) or multiple delay state couplings (CNNMDSCs), in which single neural network may or may not include time delay . By constructing the response networks, designing suitable controllers and parameter adjustment schemes, utilizing several inequality techniques and significant lemmas, the topology of the original networks are identified based on synchronization between the original networks and the response networks. Finally, the validity of the proposed controllers and parameter adjustment strategies is demonstrated by two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Han-Yu Wu and Lu Wang and Lin-Hao Zhao and Jin-Liang Wang},
  doi          = {10.1016/j.neucom.2021.06.019},
  journal      = {Neurocomputing},
  pages        = {254-264},
  shortjournal = {Neurocomputing},
  title        = {Topology identification of coupled neural networks with multiple weights},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video quality assessment with dense features and ranking
pooling. <em>NEUCOM</em>, <em>457</em>, 242–253. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefiting with the rapid development of communication networks, effective video quality assessment (VQA) models which provide guidance for video transmission and compression technologies are highly demanded. This paper proposes a general-purpose full-reference VQA method combining DenseNet with spatial pyramid pooling and RankNet to not only extract high-level distortion representation and global spatial information of samples but also characterize the temporal correlation among frames. Firstly, the pretrained DenseNet is modified and finetuned to extract high-level features of distorBenefiting with the rapid development of communication networks, effective video quality assessment (VQA) models which provide guidance for video transmission and compression technologies are highly demanded. This paper proposes a general-purpose full-reference VQA method combining DenseNet with spatial pyramid pooling and RankNet to not only extract high-level distortion representation and global spatial information of samples but also characterize the temporal correlation among frames. Firstly, the pretrained DenseNet is modified and finetuned to extract high-level features of distorted videos. Then, spatial pyramid pooling is equipped in the DenseNet module to process flexible inputs with arbitrary spatial resolution. Thus, this kind of input which has the same spatial resolution as the original distorted video is processed by the well-trained DenseNet to generate frame-level quality, which considers the global spatial information of videos directly. Finally, learning to rank is introduced to explore the high-level temporal correlation of distorted videos by taking the RankNet as the temporal pooling function. The experimental results on two public VQA databases show that the proposed algorithm performs consistently with human visual perception.},
  archive      = {J_NEUCOM},
  author       = {Yu Zhang and Lihuo He and Wen Lu and Jie Li and Xinbo Gao},
  doi          = {10.1016/j.neucom.2021.06.026},
  journal      = {Neurocomputing},
  pages        = {242-253},
  shortjournal = {Neurocomputing},
  title        = {Video quality assessment with dense features and ranking pooling},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the representational power of graph autoencoder.
<em>NEUCOM</em>, <em>457</em>, 225–241. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While representation learning has yielded a great success on many graph learning tasks, there is little understanding behind the structures that are being captured by these embeddings. For example, we wonder if the topological features , such as the Triangle Count, the Degree of the node and other centrality measures are concretely encoded in the embeddings. Furthermore, we ask if the presence of these structures in the embeddings is necessary for a better performance on the downstream tasks, such as clustering and classification. To address these questions, we conduct an extensive empirical study over three classes of unsupervised graph embedding models and seven different variants of Graph Autoencoders .Our results show that five topological features : the Degree, the Local Clustering Score, the Betweenness Centrality , the Eigenvector Centrality , and Triangle Count are concretely preserved in the first layer of the graph autoencoder that employs the SUM aggregation rule, under the condition that the model preserves the second-order proximity. We supplement further evidence for the presence of these features by revealing a hierarchy in the distribution of the topological features in the embeddings of the aforementioned model. We also show that a model with such properties can outperform other models on certain downstream tasks, especially when the preserved features are relevant to the task at hand. Finally, we evaluate the suitability of our findings through a test case study related to social influence prediction.},
  archive      = {J_NEUCOM},
  author       = {Maroun Haddad and Mohamed Bouguessa},
  doi          = {10.1016/j.neucom.2021.06.034},
  journal      = {Neurocomputing},
  pages        = {225-241},
  shortjournal = {Neurocomputing},
  title        = {Exploring the representational power of graph autoencoder},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fine-grained question-answer sentiment classification with
hierarchical graph attention network. <em>NEUCOM</em>, <em>457</em>,
214–224. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {User-oriented Question-Answer (QA) text pair plays an increasingly important role in online e-commerce platforms, and expresses sentiment information with complicated semantic relations , causing great challenges for accurate sentiment analysis . To address this problem, we propose a novel hierarchical graph attention network (HGAT) to explore abundant relations. Firstly, we utilize the dependency parser to model relations of sentiment words with consideration of syntactic structures within sub-sentences. Then, to better extract hidden features of these sentiment words, we feed the dependency graph into an improved word-level graph attention network (GAT) that incorporates the learned attention weight with the prior graph edge weight. Besides, the sigmoid self-attention mechanism is applied to aggregate salient word representations. Finally, we establish a graph of all sub-sentences with a strong connection and capture inter-relations and intra-relations through the sentence-level GAT. Extensive experiments show that HGAT can achieve significant improvements in QA-style sentiment classification compared with several baselines.},
  archive      = {J_NEUCOM},
  author       = {Jiandian Zeng and Tianyi Liu and Weijia Jia and Jiantao Zhou},
  doi          = {10.1016/j.neucom.2021.06.040},
  journal      = {Neurocomputing},
  pages        = {214-224},
  shortjournal = {Neurocomputing},
  title        = {Fine-grained question-answer sentiment classification with hierarchical graph attention network},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Direct training of hardware-friendly weight binarized
spiking neural network with surrogate gradient learning towards
spatio-temporal event-based dynamic data recognition. <em>NEUCOM</em>,
<em>457</em>, 203–213. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The spiking neural network (SNN)-based neuromorphic hardware has been extensively studied in dynamic information processing . However, there is still a lack of training algorithms to drive or support the implementation of compact spatio-temporal neuromorphic hardware; and the existing neuromorphic hardware uses excessive on-chip memory to store parameters, which limits its neuron and synapse scale. Here, we introduce a hardware-friendly weight binarized spiking neural network (BSNN) to efficiently recognize the spatio-temporal event-based data. The neuron of the spike response model (SRM) is used in BSNN due to its rich spatio-temporal characteristics. In the training process, a surrogate gradient method is used to replace the derivative of the spike train, and the weights are binarized. Moreover, combined with the spiking characteristics of SNN (i.e., the input/output of SNN and the communications of neurons in SNN are binary spikes), it is possible to replace the hardware-expensive matrix–vector multiplication (MVM) with the hardware-friendly “Signed AND” operation during inference, which is favored for constructing compact neuromorphic hardware. The trained BSNN has competitive recognition accuracies of 99.52\% and 62.1\%, 97.57\%, and 90.35\% on the dynamic images dataset N-MNIST and DVS-CIFAR10, dynamic gestures dataset DvsGesture, and dynamic audio dataset N-TIDIGITS18, respectively, which are related to human vision or hearing . The proposed compact SNN training method paves the way for real-time dynamic information processing oriented hardware-saving and power-efficient neuromorphic hardware.},
  archive      = {J_NEUCOM},
  author       = {G.C. Qiao and N. Ning and Y. Zuo and S.G. Hu and Q. Yu and Y. Liu},
  doi          = {10.1016/j.neucom.2021.06.070},
  journal      = {Neurocomputing},
  pages        = {203-213},
  shortjournal = {Neurocomputing},
  title        = {Direct training of hardware-friendly weight binarized spiking neural network with surrogate gradient learning towards spatio-temporal event-based dynamic data recognition},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Molecular graph enhanced transformer for retrosynthesis
prediction. <em>NEUCOM</em>, <em>457</em>, 193–202. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With massive possible synthetic routes in chemistry, retrosynthesis prediction is still a challenge for researchers. Recently, retrosynthesis prediction is formulated as a Machine Translation (MT) task. Namely, since each molecule can be represented as a Simplified Molecular-Input Line-Entry System (SMILES) string, the process of retrosynthesis is analogized to a process of language translation from the product to reactants. However, the MT models that applied on SMILES data usually ignore the information of natural atomic connections and the topology of molecules. To make more chemically plausible constrains on the atom representation learning for better performance, in this paper, we propose a Graph Enhanced Transformer (GET) framework, which adopts both the sequential and graphical information of molecules. Four different GET designs are proposed, which fuse the SMILES representations with atom embeddings learned from our improved Graph Neural Network (GNN). Empirical results show that our model significantly outperforms the vanilla Transformer model in test accuracy.},
  archive      = {J_NEUCOM},
  author       = {Kelong Mao and Xi Xiao and Tingyang Xu and Yu Rong and Junzhou Huang and Peilin Zhao},
  doi          = {10.1016/j.neucom.2021.06.037},
  journal      = {Neurocomputing},
  pages        = {193-202},
  shortjournal = {Neurocomputing},
  title        = {Molecular graph enhanced transformer for retrosynthesis prediction},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble solution for multivariate time series
clustering. <em>NEUCOM</em>, <em>457</em>, 182–192. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technologies such as Big Data and IoT have shown the need for intelligent unsupervised processing of Multivariate Time Series (MTS), MTS clustering among them. The challenges in MTS clustering includes not only the selection of the algorithm but also the MTS representation and the similarity measurement among the instances. This study proposes an ensemble of MTS clustering methods that merges different MTS representations and distance functions, aggregating them to obtain a similarity measurement. Furthermore, a proposal for prior knowledge representation is propose to balance the aggregation of the distances. The final clustering is performed either using k-means or hierarchical clustering . The experimentation set up includes the implementation of the ensemble with either 4 or 5 different methods, including an MTS extension of k-Shape. The results show that the ensemble is biased towards the best methods, which helps the clustering practitioner in the selection of the most suitable prototypes. Moreover, the evaluation of the ensemble with the number of clusters set to the number of labels shows that metrics, such as the sensitivity and specificity, must drive the rule of the elbow; alternatively, this value represents the most interesting prior knowledge bit in MTS clustering. Further work includes the study of digital markers to compare MTS representations and distance functions and the use of external metrics to balance the aggregation of the methods.},
  archive      = {J_NEUCOM},
  author       = {Iago Vázquez and José R. Villar and Javier Sedano and Svetlana Simić and Enrique de la Cal},
  doi          = {10.1016/j.neucom.2020.09.093},
  journal      = {Neurocomputing},
  pages        = {182-192},
  shortjournal = {Neurocomputing},
  title        = {An ensemble solution for multivariate time series clustering},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring dropout discriminator for domain adaptation.
<em>NEUCOM</em>, <em>457</em>, 168–181. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptation of a classifier to new domains is one of the challenging problems in machine learning . This has been addressed using many deep and non-deep learning based methods. Among the methodologies used, that of adversarial learning is widely applied to solve many deep learning problems along with domain adaptation . These methods are based on a discriminator that ensures source and target distributions are close. However, here we suggest that rather than using a point estimate obtaining by a single discriminator , it would be useful if a distribution based on ensembles of discriminators could be used to bridge this gap. This could be achieved using multiple classifiers or using traditional ensemble methods . In contrast, we suggest that a Monte Carlo dropout based ensemble discriminator could suffice to obtain the distribution based discriminator. Specifically, we propose a curriculum based dropout discriminator that gradually increases the variance of the sample based distribution and the corresponding reverse gradients are used to align the source and target feature representations. An ensemble of discriminators helps the model to learn the data distribution efficiently. It also provides a better gradient estimates to train the feature extractor. The detailed results and thorough ablation analysis show that our model outperforms state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Vinod Kumar Kurmi and Venkatesh K. Subramanian and Vinay P. Namboodiri},
  doi          = {10.1016/j.neucom.2021.06.043},
  journal      = {Neurocomputing},
  pages        = {168-181},
  shortjournal = {Neurocomputing},
  title        = {Exploring dropout discriminator for domain adaptation},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Fully convolutional siamese networks based change detection
for optical aerial images with focal contrastive loss. <em>NEUCOM</em>,
<em>457</em>, 155–167. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a change detection algorithm based on Fully Convolutional Siamese Networks for optical aerial images, which is trained by using an improved Contrastive Loss-Focal Contrastive Loss (FCL). The proposed framework equipped with contrastive loss can extract features directly from image pairs and measure changes by using a distance metric. In other words, this method encourages reducing intra-class variance and enlarging inter-class difference, so that the binarized change map can be obtained by a simple threshold. In change detection task, a critical problem is how to overcome example imbalance (i.e. unchanged examples are much more than changed examples). To address this challenge, a novel focal contrastive loss is proposed to further improve the performance of the model. FCL can reduce the impact of example imbalance and make the model focus learning on hard examples. Extensive experiments demonstrate that the proposed approach is more abstract as well as robust. Compared with other baseline methods , the presented method achieves better results on SAZDA, TISZADOB, CDD, and WHU-CD data set. It achieves state-of-the-art performance in terms of the F1 measure.},
  archive      = {J_NEUCOM},
  author       = {Zhixue Wang and Chaoyong Peng and Yu Zhang and Nan Wang and Lin Luo},
  doi          = {10.1016/j.neucom.2021.06.059},
  journal      = {Neurocomputing},
  pages        = {155-167},
  shortjournal = {Neurocomputing},
  title        = {Fully convolutional siamese networks based change detection for optical aerial images with focal contrastive loss},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HSC: Leveraging horizontal shortcut connections for
improving accuracy and computational efficiency of lightweight CNN.
<em>NEUCOM</em>, <em>457</em>, 141–154. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past few years have witnessed the dramatic increase in layers of convolutional neural networks (CNN). Most studies focused on the CNN’s vertical structure design (e.g. residual structure, creating short paths architecture from early layers to later layers in vertical connections), but few people pay their attention to the process of feature generation and extraction in a single convolutional layer in CNN. In this paper, we find the non-feature suppression phenomenon in the process of extracting features. On the basis of this, we proposed an orthogonal approach named HSC (Horizontal Shortcut Connections) to improve feature representation fusion and computational efficiency for CNN. Especially, our HSC approach can effectively reduce interference overhead of non-feature areas and enhance the information fusion for depthwise convolution and group convolution which are the key blocks in lightweight neuron network. At HSC layer, the feature-maps of all preceding layer are properly connected with our strategy in horizon direction to constitute features and then produce a new representation which are used as input feature-maps passed on subsequent layers. Our HSC block can be plugged into convolution neural networks that include group convolution or depewise convolution, and can effectively improve accuracy of convolutional networks with slight additional computational cost. We evaluate our design on the popular lightweight neural networks and standard CNN structure. Compared with existing methods, we can achieve 1.63\% accuracy improvement for MobileNet v2 on CIFAR-10 dataset and up to 3.70\% accuracy improvement on CIFAR-100 dataset by adding HSC block after depthwise convolution, and 2.80\% accuracy improvement on ImageNet dataset. For Mobilenet v3-small, we can achieve 0.8\% accuracy improvement on ImageNet dataset. In order to prove the improvement effect of group convolution, the standard convolution is changed manually to group convolution and then the HSC block is added after group convolution, we can achieve 4X to 6X FLOPs improvement while maintaining the accuracy of neural networks. Notably, on ILSVRC- 2012, our method reduces more than 43\% FLOPs on ResNet-50 without accuracy declines and reduces 60.1\% FLOPs on ResNet-50 with 0.44\% accuracy declines.We also present primary hardware experiment results when HSC framework running on special hardware platform.},
  archive      = {J_NEUCOM},
  author       = {Anguo Zhu and Longjun Liu and Wenxuan Hou and Hongbin Sun and Nanning Zheng},
  doi          = {10.1016/j.neucom.2021.06.065},
  journal      = {Neurocomputing},
  pages        = {141-154},
  shortjournal = {Neurocomputing},
  title        = {HSC: Leveraging horizontal shortcut connections for improving accuracy and computational efficiency of lightweight CNN},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differential neural network approximation of positive
systems: An asymmetric barrier lyapunov functions approach for learning
laws design. <em>NEUCOM</em>, <em>457</em>, 128–140. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study is to design a non-parametric identifier based on Differential Neural Networks (DNNs) for a class of positive systems described by uncertain mathematical models. The inclusion of state constraints and the existence of equilibrium points outside the origin are considered in the design of the non-parametric identifier with the implementation of asymmetric barrier Lyapunov functions . The application of a stability analysis yields the design of learning laws for the weights adjustment. A class of hybrid learning laws depending on the relative difference of each state with respect to its corresponding component of the equilibrium point provides the ability of handling the positiveness of all the states, which is ensured considering he implementation of non-linear state dependent gains. A numerical example confirms the efficiency of the proposed state non-parametric identifier in the presence of bounded noises and perturbations affecting the dynamics of the evaluated positive systems. The example corresponds to a pharmaceutical compartmental system which reproduces the immunotherapy dynamics for the cancer treatment. The comparison of the proposed DDN approximated model with the classical non-barrier identifier confirms the ability of reproducing positive systems trajectories satisfying state constraints.},
  archive      = {J_NEUCOM},
  author       = {Olga Andrianova and Alexander Poznyak and Isaac Chairez},
  doi          = {10.1016/j.neucom.2021.06.056},
  journal      = {Neurocomputing},
  pages        = {128-140},
  shortjournal = {Neurocomputing},
  title        = {Differential neural network approximation of positive systems: An asymmetric barrier lyapunov functions approach for learning laws design},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Support vector machines with the ε-insensitive pinball loss
function for uncertain data classification. <em>NEUCOM</em>,
<em>457</em>, 117–127. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the use of the quantile function, support vector machines with the pinball loss (PinSVMs) have good properties such as noise insensitivity and stability of re-sampling. In this paper we propose a novel model with the ε ε -insensitive pinball loss function for uncertain data classification . The original model we propose involves the high-dimensional integral problem. In order to make the optimization model become tractable, we transform the original model into the simplified one by using some techniques. We theoretically analyze some properties of the proposed optimization model including noise insensitivity and scatter minimization. Based on the probability of uncertain samples in the halfspaces, we make a rule to classify uncertain samples. In the proposed model a probabilistic degree of the uncertain sample that belongs to the positive or negative class can be given. In addition, we use the kernel trick to extend the proposed model to deal with nonlinear problems. The experiments on artificial data and real-world data sets are carried out to confirm the effectiveness of the proposed model in handling uncertain data.},
  archive      = {J_NEUCOM},
  author       = {Zhizheng Liang and Lei Zhang},
  doi          = {10.1016/j.neucom.2021.06.044},
  journal      = {Neurocomputing},
  pages        = {117-127},
  shortjournal = {Neurocomputing},
  title        = {Support vector machines with the ε-insensitive pinball loss function for uncertain data classification},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Scalable and memory-efficient sparse learning for
classification with approximate bayesian regularization priors.
<em>NEUCOM</em>, <em>457</em>, 106–116. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse Bayesian learning (SBL) provides state-of-the-art performance in accuracy, sparsity and probabilistic prediction for classification. In SBL, the regularization priors are automatically determined that avoids an exhaustive hyperparameter selection by cross-validation. However, scalability to large problems is a drawback of SBL because of the inversion of a potentially enormous covariance matrix for updating the regularization priors in every iteration. This paper develops an approximate SBL algorithm called ARP-SBL, where the regularization priors are approximated without inverting the covariance matrix . Therefore, our approach can easily scale up to problems with large data size or feature dimension. It alleviates the long training time and high memory complexity in SBL. Based on ARP-SBL, two scalable nonlinear SBL models: scalable relevance vector machine (ARP-RVM) and scalable sparse Bayesian extreme learning machine (ARP-SBELM) are developed for problems of large data size and large feature size respectively. Experiments on a variety of benchmarks have shown that the proposed models are with competitive accuracy compared to existing methods while i) converging faster; ii) requiring thousands of times less memory; iii) without exhaustive regularized hyperparameter selection; and iv) easily scaling up to large data size and high dimensional features.},
  archive      = {J_NEUCOM},
  author       = {Jiahua Luo and Yanfen Gan and Chi-Man Vong and Chi-Man Wong and Chuangquan Chen},
  doi          = {10.1016/j.neucom.2021.06.025},
  journal      = {Neurocomputing},
  pages        = {106-116},
  shortjournal = {Neurocomputing},
  title        = {Scalable and memory-efficient sparse learning for classification with approximate bayesian regularization priors},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QRNN-MIDAS: A novel quantile regression neural network for
mixed sampling frequency data. <em>NEUCOM</em>, <em>457</em>, 84–105.
(<a href="https://doi.org/10.1016/j.neucom.2021.06.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text of abstract In the big data era, it is common to encounter data observed at different frequencies. This raises the problem of how to explore the heterogeneous nonlinear relationship between variables on mixed sampling frequency data. To this end, we develop a novel quantile regression neural network for mixed sampling frequency data called QRNN-MIDAS by introducing the Mixed Data Sampling (MIDAS) technique into the framework of quantile regression neural network (QRNN). The proposed QRNN-MIDAS model enables QRNN to handle raw mixed sampling frequency data directly. Specifically, we conduct frequency alignment on each high frequency input variable according to the given maximum lag order. Then, a convenient parametric weight function is imposed on the frequency alignment vector and a low frequency variable is obtained. This strategy allows the QRNN-MIDAS model to extract valuable information from raw mixed sampling frequency data, which is helpful to explore the heterogeneous nonlinear relationship between variables in real time. To illustrate the efficacy of QRNN-MIDAS, both Monte Carlo simulation studies and real-world data applications are considered. The numerical results show that the QRNN-MIDAS model outperforms several competing models in terms of goodness-of-fit and predictive ability. In addition, US quarterly GDP growth and China’s monthly inflation forecast results also illustrate the superiority of the QRNN-MIDAS model, and provide more timely, accurate and comprehensive forecasts for decision-making.},
  archive      = {J_NEUCOM},
  author       = {Qifa Xu and Shuting Liu and Cuixia Jiang and Xingxuan Zhuo},
  doi          = {10.1016/j.neucom.2021.06.006},
  journal      = {Neurocomputing},
  pages        = {84-105},
  shortjournal = {Neurocomputing},
  title        = {QRNN-MIDAS: A novel quantile regression neural network for mixed sampling frequency data},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient and effective deep convolutional kernel
pseudoinverse learner with multi-filter. <em>NEUCOM</em>, <em>457</em>,
74–83. (<a href="https://doi.org/10.1016/j.neucom.2021.06.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The convolutional neural network is the most widely used deep neural network . However, it still has some disadvantages. First, the back-propagation method is usually used in the training of convolutional neural networks, but it has several inherent defects, such as the vanishing gradient problem and exploding gradient problem. Moreover, the training of a convolutional neural network often needs substantial computational resources and time. To solve the above problems, based on pseudoinverse learning (PIL), kernel pseudoinverse learning (KPIL) is proposed, showing improved performance. The number of hidden layer neurons of KPIL is equal to the number of input data and does not need to be set. KPIL uses the kernel method to calculate the output of hidden layer, avoiding the uncertainty of random input weights. Based on KPIL, a deep convolutional kernel pseudoinverse learner with a multi-filter design is proposed, named kernel pseudoinverse learning convolutional neural network (KPIL-CNN), which uses multiple fixed convolutional kernels: kernel pseudoinverse learning filters (KPIL filter), Gabor filters, and random filters. The features obtained by this multi-filter approach are combined into feature maps by learning weights. The experimental results show that the proposed KPIL-CNN performs better than other network models with the same scale in the task of natural image classification . The training of KPIL-CNN is efficient and effective. Furthermore, KPIL-CNN outperforms the existing methods in the classification of the ISIC 2017 skin lesion dataset.},
  archive      = {J_NEUCOM},
  author       = {Xiaodan Deng and Mohammed A.B. Mahmoud and Qian Yin and Ping Guo},
  doi          = {10.1016/j.neucom.2021.06.041},
  journal      = {Neurocomputing},
  pages        = {74-83},
  shortjournal = {Neurocomputing},
  title        = {An efficient and effective deep convolutional kernel pseudoinverse learner with multi-filter},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). First SN p visual cryptographic circuit with astrocyte
control of structural plasticity for security applications.
<em>NEUCOM</em>, <em>457</em>, 67–73. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cryptographic algorithms have been widely used in all secure data transmissions due their capabilities to hide sensible information against eavesdroppers. Nevertheless, technological progress tends to develop new cryptographic methods based on non-classical computing paradigms . In this work, the first circuit of visual cryptography based on Spiking Neural P systems (VCSN P) is presented. The proposed circuit makes use of new biological behaviors in astrocytes, which are involved in processes of plasticity and pruning control in dendrites, that can be the beginning to new cryptographic algorithms based on SN P systems. To validate the SN P circuit, this was implemented on the Cyclone V field programmable gate array (FPGA) development kit. The results demonstrate that this new approach exploits the features of the SN P systems to improve the cryptographic algorithm.},
  archive      = {J_NEUCOM},
  author       = {L. Olvera-Martinez and T. Jimenez-Borgonio and T. Frias-Carmona and M. Abarca-Rodriguez and C. Diaz-Rodriguez and M. Cedillo-Hernandez and M. Nakano-Miyatake and H. Perez-Meana},
  doi          = {10.1016/j.neucom.2021.05.057},
  journal      = {Neurocomputing},
  pages        = {67-73},
  shortjournal = {Neurocomputing},
  title        = {First SN p visual cryptographic circuit with astrocyte control of structural plasticity for security applications},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fusion of intelligent learning for COVID-19: A
state-of-the-art review and analysis on real medical data.
<em>NEUCOM</em>, <em>457</em>, 40–66. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The unprecedented surge of a novel coronavirus in the month of December 2019, named as COVID-19 by the World Health organization has caused a serious impact on the health and socioeconomic activities of the public all over the world. Since its origin, the number of infected and deceased cases has been growing exponentially in almost all the affected countries of the world. The rapid spread of the novel coronavirus across the world results in the scarcity of medical resources and overburdened hospitals. As a result, the researchers and technocrats are continuously working across the world for the inculcation of efficient strategies which may assist the government and healthcare system in controlling and managing the spread of the COVID-19 pandemic. Therefore, this study provides an extensive review of the ongoing strategies such as diagnosis, prediction, drug and vaccine development and preventive measures used in combating the COVID-19 along with technologies used and limitations. Moreover, this review also provides a comparative analysis of the distinct type of data, emerging technologies, approaches used in diagnosis and prediction of COVID-19, statistics of contact tracing apps, vaccine production platforms used in the COVID-19 pandemic. Finally, the study highlights some challenges and pitfalls observed in the systematic review which may assist the researchers to develop more efficient strategies used in controlling and managing the spread of COVID-19.},
  archive      = {J_NEUCOM},
  author       = {Weiping Ding and Janmenjoy Nayak and H. Swapnarekha and Ajith Abraham and Bighnaraj Naik and Danilo Pelusi},
  doi          = {10.1016/j.neucom.2021.06.024},
  journal      = {Neurocomputing},
  pages        = {40-66},
  shortjournal = {Neurocomputing},
  title        = {Fusion of intelligent learning for COVID-19: A state-of-the-art review and analysis on real medical data},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A joint temporal-spatial ensemble model for short-term
traffic prediction. <em>NEUCOM</em>, <em>457</em>, 26–39. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of short-term traffic flow prediction since accurate prediction of short-term traffic flow facilitates timely traffic management and rapid response. We advocate deep machine learning approach and propose a novel ensemble model, named ALLSCP, that considers both temporal and spatial characteristics of traffic conditions. Specifically, we consider (1) short-, medium- and long-term temporal traffic evolution, (2) global and local spatial traffic patterns and (3) the correlation of temporal-spatial features in our predictions. We use real-world traffic data from two locations (i.e., Los Angeles and London) with frequent fluctuations (due to proneness to traffic accidents and/or congestion) to train and test our model. For each location, we consider road segments with and without junctions (i.e., linear vs intersection). We compare our model against well-known existing machine/deep learning prediction models. Our results indicate that our ALLSCP model consistently achieves the most accurate predictions ( ≈ 96\% ≈96\% accuracy both on linear and intersection roadways) when compared against existing models in the literature. In addition, we conducted ablation experiments to further gain insights into the contributions of individual constituent models of our ensemble ALLSCP model. Our results indicate that ALLSCP achieves the best results and is also robust against emergent traffic situations.},
  archive      = {J_NEUCOM},
  author       = {Ge Zheng and Wei Koong Chai and Vasilis Katos and Michael Walton},
  doi          = {10.1016/j.neucom.2021.06.028},
  journal      = {Neurocomputing},
  pages        = {26-39},
  shortjournal = {Neurocomputing},
  title        = {A joint temporal-spatial ensemble model for short-term traffic prediction},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context prior based semantic-spatial graph network for human
parsing. <em>NEUCOM</em>, <em>457</em>, 13–25. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many methods enlarged the kernel size or fused multi-scale features to capture contextual information for parsing the hard samples, such as heavy occlusions, limb absence, and complex poses. Nevertheless, those required higher computational and cannot explore the effective global context to achieve more precise parsing results. In this paper, we propose an end-to-end network for human parsing, named Context Prior based Semantic-Spatial Graph Network (CP-SSGNet), which achieves higher precision and consistency by encoding the context prior in the graph model. CP-SSGNet consists of three modules, Semantic Constraint Module (SCM), Spatial Perceiving Module (SPM), and Intra-class Attention Module (IAM). SCM captures richer global dependencies by encoding semantic structure context prior in a semantic graph, which can reduce semantic structure errors. SPM learns enhanced local features by encoding the spatial consistency context prior in the spatial graph, which can optimize boundaries and reduce the local consistency errors. IAM utilizes the spatial graph with strong–weak connections for intra-class features aggregation to distinguish the inter-class features clearly. Extensive experiments are conducted on two challenging datasets, PASCAL-Person-Part and LIP, effectively achieving state-of-the-arts performance.},
  archive      = {J_NEUCOM},
  author       = {Huaqing Hao and Weibin Liu and Weiwei Xing},
  doi          = {10.1016/j.neucom.2021.05.094},
  journal      = {Neurocomputing},
  pages        = {13-25},
  shortjournal = {Neurocomputing},
  title        = {Context prior based semantic-spatial graph network for human parsing},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RDRF-net: A pyramid architecture network with residual-based
dynamic receptive fields for unsupervised depth estimation.
<em>NEUCOM</em>, <em>457</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image depth estimation is a challenging problem in computer vision, especially considering both high accuracy and low run time. To save run time and maintain high accuracy, we present a new light-weight model in this paper, i.e., a Residual-based Dynamic Receptive Field Network (RDRF-Net). This model can automatically select the receptive fields suitable for different image scales to generate the depth maps with higher fitting degrees. Residual design and bottleneck layers are used to compress the network for reducing run time. Three groups of experiments are performed on the KITTI dataset to test the accuracy, computation time, and the impact of dynamic receptive fields. Experimental results show that RDRF-Net has comparable accuracy with Godard’s model and significantly outperforms it in terms of run time. In addition, it performs closely to Pyd-Net in terms of run time and beats Pyd-Net’s accuracy. Experiments also demonstrate the beneficial impact of dynamic receptive fields on improving depth estimation accuracy.},
  archive      = {J_NEUCOM},
  author       = {Zhen-yan Ji and Xiao-jun Song and Hou-bin Song and Hong Yang and Xiao-xuan Guo},
  doi          = {10.1016/j.neucom.2021.05.089},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {RDRF-net: A pyramid architecture network with residual-based dynamic receptive fields for unsupervised depth estimation},
  volume       = {457},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strong classification system for wear identification on
milling processes using computer vision and ensemble learning.
<em>NEUCOM</em>, <em>456</em>, 678–684. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metallic pieces are typically machined by continuous tool passes, which usually causes regular patterns in the form of straight edges in the surface of the pieces. An irregular pattern on the surface of the piece implies a decrease of the quality of the machined piece. In this paper, we propose an acquisition system and a machine-vision based method to describe the texture of the inner and outer surfaces of machined pieces with cylindrical holes. In order to capture images of the hole surface, we used a microscope camera connected to a rigid industrial boroscope. Considering the extracted texture descriptors , a significant correlation is shown. Consequently, the feature vector is reduced and then classified by several algorithms using an exhaustive grid search strategy with 10-fold cross validation. Best results are achieved with the Extremely Randomized Trees classifier with a mean test score on the hold out set of 92.98\%, what improves previous research and meets the requirements of the field.},
  archive      = {J_NEUCOM},
  author       = {Virginia Riego and Manuel Castejón-Limas and Lidia Sánchez-González and Laura Fernández-Robles and Hilde Perez and Javier Diez-Gonzalez and Ángel-Manuel Guerrero-Higueras},
  doi          = {10.1016/j.neucom.2020.07.131},
  journal      = {Neurocomputing},
  pages        = {678-684},
  shortjournal = {Neurocomputing},
  title        = {Strong classification system for wear identification on milling processes using computer vision and ensemble learning},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing CNN-LSTM neural networks with PSO for anomalous
query access control. <em>NEUCOM</em>, <em>456</em>, 666–677. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Database security focuses on protecting most organization’s virtual data storage unit and confidential information from malicious threats and external attacks. To keep out data secure, we need to use a role-based access control (RBAC) approach to accurately differentiate access permissions, but SQL queries written by an authorized user have very similar characteristics and are difficult to distinguish. In this paper, we propose a method of optimizing CNN-LSTM neural networks with particle swarm optimization (PSO) to classify the roles in RBAC system. Convolutional neural network (CNN) can extract parsed SQL queries into smaller details and features through an analysis mechanism. Long short-term memory (LSTM) is also suitable for modeling the temporal information of SQL queries to recognize the context of user authorities. PSO repeatedly searches and optimizes the complex hyperparameter space of the CNN-LSTM. Our PSO-based CNN-LSTM neural networks outperform other deep learning and machine learning models in the TPC-E benchmark SQL query statement. Finally, experiments and analysis show the usefulness of PSO and identify the important SQL query features that affect user role classification.},
  archive      = {J_NEUCOM},
  author       = {Tae-Young Kim and Sung-Bae Cho},
  doi          = {10.1016/j.neucom.2020.07.154},
  journal      = {Neurocomputing},
  pages        = {666-677},
  shortjournal = {Neurocomputing},
  title        = {Optimizing CNN-LSTM neural networks with PSO for anomalous query access control},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian networks for interpretable machine learning and
optimization. <em>NEUCOM</em>, <em>456</em>, 648–665. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As artificial intelligence is being increasingly used for high-stakes applications, it is becoming more and more important that the models used be interpretable. Bayesian networks offer a paradigm for interpretable artificial intelligence that is based on probability theory. They provide a semantics that enables a compact, declarative representation of a joint probability distribution over the variables of a domain by leveraging the conditional independencies among them. The representation consists of a directed acyclic graph that encodes the conditional independencies among the variables and a set of parameters that encodes conditional distributions. This representation has provided a basis for the development of algorithms for probabilistic reasoning (inference) and for learning probability distributions from data. Bayesian networks are used for a wide range of tasks in machine learning , including clustering, supervised classification , multi-dimensional supervised classification , anomaly detection , and temporal modeling . They also provide a basis for estimation of distribution algorithms , a class of evolutionary algorithms for heuristic optimization. We illustrate the use of Bayesian networks for interpretable machine learning and optimization by presenting applications in neuroscience , the industry, and bioinformatics, covering a wide range of machine learning and optimization tasks .},
  archive      = {J_NEUCOM},
  author       = {Bojan Mihaljević and Concha Bielza and Pedro Larrañaga},
  doi          = {10.1016/j.neucom.2021.01.138},
  journal      = {Neurocomputing},
  pages        = {648-665},
  shortjournal = {Neurocomputing},
  title        = {Bayesian networks for interpretable machine learning and optimization},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classification of educational videos by using a
semi-supervised learning method on transcripts and keywords.
<em>NEUCOM</em>, <em>456</em>, 637–647. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-learning is a rapidly growing field, which is giving rise to a massive amount of digital learning objects . Sorting these objects properly so that they are correctly indexed in searches and recommendation systems is a challenge. In this paper, we present a semi-supervised method of clustering and classifying learning objects in video format to extract their most relevant topics, specifically from lesson transcripts. These videos come from the educational video platform of the Universitat Politència de València . The proposed method also uses open content from Wikipedia to help build the labelled dataset.},
  archive      = {J_NEUCOM},
  author       = {Alexandru Stefan Stoica and Stella Heras and Javier Palanca and Vicente Julián and Marian Cristian Mihaescu},
  doi          = {10.1016/j.neucom.2020.11.075},
  journal      = {Neurocomputing},
  pages        = {637-647},
  shortjournal = {Neurocomputing},
  title        = {Classification of educational videos by using a semi-supervised learning method on transcripts and keywords},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detecting malicious android applications based on the
network packets generated. <em>NEUCOM</em>, <em>456</em>, 629–636. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Widespread communication by mobile devices today has promoted the use of huge amounts of information on them. Malware applications are undergoing exponential growth , directly attacking these smartphones to steal information. For this reason, we have created a methodology to analyze the network packets sent by any type of mobile applications in order to validate their behavior . In order to solve this problem, we have used supervised learning systems in an attempt to modelize the traffic communication with a set of previously labeled data. This will help to actively detect if applications installed in mobile devices could be tagged as malicious.},
  archive      = {J_NEUCOM},
  author       = {José Gaviria de la Puerta and Iker Pastor-López and Igone Porto and Borja Sanz and Pablo García Bringas},
  doi          = {10.1016/j.neucom.2020.08.095},
  journal      = {Neurocomputing},
  pages        = {629-636},
  shortjournal = {Neurocomputing},
  title        = {Detecting malicious android applications based on the network packets generated},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quality assessment methodology based on machine learning
with small datasets: Industrial castings defects. <em>NEUCOM</em>,
<em>456</em>, 622–628. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays there are numerous problems for which use of a multi-objective in image classification would be desirable although, unfortunately, the number of samples is too low. In these situations, higher level classifications could also work (for example, in surface defect detection, it is important to identify the defect, but it could also be useful to detect whether or not the object has a defect). To this end, we present a methodology called BoDoC which allows to improve this classification. To evaluate the methodology, we have created a new dataset, obtained from a foundry, to detect surface errors in casting pieces with 2 different defects: (i) inclusions, (ii) coldlaps and (iii) misruns. We also present a collection of techniques to select featu res from the images. We prove that our methodology improves the direct classification results in real world scenarios, with 91.305\% precision.},
  archive      = {J_NEUCOM},
  author       = {Iker Pastor-López and Borja Sanz and Alberto Tellaeche and Giuseppe Psaila and José Gaviria de la Puerta and Pablo G. Bringas},
  doi          = {10.1016/j.neucom.2020.08.094},
  journal      = {Neurocomputing},
  pages        = {622-628},
  shortjournal = {Neurocomputing},
  title        = {Quality assessment methodology based on machine learning with small datasets: Industrial castings defects},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent system for harmonic distortions detection in
wind generator power electronic devices. <em>NEUCOM</em>, <em>456</em>,
609–621. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high concern about climate change has boosted the promotion of renewable energy systems, being the wind power one of the key generation possibilities in this field. In this context, with the aim of ensuring the energy efficiency, the present work deals with the fault detection in the power electronic circuits of a wind generator system placed in a bioclimatic house. To do so, different outliers that emulate harmonic distortion appearance are tested. To implement a system capable of detecting this anomalous situations, six different one-class techniques are used, whose performance is thoroughly analyzed, offering interesting performance.},
  archive      = {J_NEUCOM},
  author       = {Esteban Jove and Jose Manuel González-Cava and José-Luis Casteleiro-Roca and Héctor Alaiz-Moretón and Bruno Baruque and Paulo Leitão and Juan Albino Méndez Pérez and José Luis Calvo-Rolle},
  doi          = {10.1016/j.neucom.2020.07.155},
  journal      = {Neurocomputing},
  pages        = {609-621},
  shortjournal = {Neurocomputing},
  title        = {An intelligent system for harmonic distortions detection in wind generator power electronic devices},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convex formulation for multi-task l1-, l2-, and LS-SVMs.
<em>NEUCOM</em>, <em>456</em>, 599–608. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quite often a machine learning problem lends itself to be split in several well-defined subproblems, or tasks. The goal of Multi-Task Learning (MTL) is to leverage the joint learning of the problem from two different perspectives: on the one hand, a single, overall model, and on the other hand task-specific models. In this way, the found solution by MTL may be better than those of either the common or the task-specific models. Starting with the work of Evgeniou et al., support vector machines (SVMs) have lent themselves naturally to this approach. This paper proposes a convex formulation of MTL for the L1-, L2- and LS-SVM models that results in dual problems quite similar to the single-task ones, but with multi-task kernels; in turn, this makes possible to train the convex MTL models using standard solvers. As an alternative approach, the direct optimal combination of the already trained common and task-specific models can also be considered. In this paper, a procedure to compute the optimal combining parameter with respect to four different error functions is derived. As shown experimentally, the proposed convex MTL approach performs generally better than the alternative optimal convex combination , and both of them are better than the straight use of either common or task-specific models.},
  archive      = {J_NEUCOM},
  author       = {Carlos Ruiz and Carlos M. Alaíz and José R. Dorronsoro},
  doi          = {10.1016/j.neucom.2021.01.137},
  journal      = {Neurocomputing},
  pages        = {599-608},
  shortjournal = {Neurocomputing},
  title        = {Convex formulation for multi-task l1-, l2-, and LS-SVMs},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recognition of JSL fingerspelling using deep convolutional
neural networks. <em>NEUCOM</em>, <em>456</em>, 586–598. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present approach for recognition of static fingerspelling in Japanese Sign Language on RGB images . Two 3D articulated hand models have been developed to generate synthetic fingerspellings and to extend a dataset consisting of real hand gestures.In the first approach, advanced graphics techniques were employed to rasterize photorealistic gestures using a skinned hand model. In the second approach, gestures rendered using simpler lighting techniques were post-processed by a modified Generative Adversarial Network . In order to avoid generation of unrealistic fingerspellings a hand segmentation term has been added to the loss function of the GAN. The segmentation of the hand in images with complex background was done by proposed ResNet34-based segmentation network . The finger-spelled signs were recognized by an ensemble with both fine-tuned and trained from scratch neural networks . Experimental results demonstrate that owing to sufficient amount of training data a high recognition rate can be attained on RGB images . The JSL dataset with pixel-level hand segmentations is available for download.},
  archive      = {J_NEUCOM},
  author       = {Bogdan Kwolek and Wojciech Baczynski and Shinji Sako},
  doi          = {10.1016/j.neucom.2021.03.133},
  journal      = {Neurocomputing},
  pages        = {586-598},
  shortjournal = {Neurocomputing},
  title        = {Recognition of JSL fingerspelling using deep convolutional neural networks},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep architectures for the segmentation of frontal sinuses
in x-ray images: Towards an automatic forensic identification system in
comparative radiography. <em>NEUCOM</em>, <em>456</em>, 575–585. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Comparative radiography (CR) is the forensic anthropology technique in which ante-mortem (AM) and post-mortem (PM) radiographic materials (e.g., X-ray images or CTs) are compared in order to determine the identity of a human being (either by providing a positive identification or by reducing the number of candidates). One of the most commonly used anatomical structures in CR are the frontal sinuses , which are used in forensic human identification tasks due to their singularity and high identification power. In order to automate the comparison of frontal sinuses in AM and PM materials, we need to perform their segmentation and registration. However, these tasks are time-consuming, subjective, and complex. This paper presents the first CR-based identification system for the comparison of frontal sinuses and supporting the forensic expert’s decision. The proposed system comprises two building blocks . First, a frontal sinus segmentation method in X-ray images using deep convolutional neural networks . Different convolutional architectures are compared in solving the segmentation problem, obtaining an average Dice Similarity Coefficient of the frontal sinuses of 0.823 on a dataset composed of 234 skull radiographs. Second, an evolutionary-based 2D-3D IR method, that searches for the best alignment of segmented AM and PM images using a real-coded evolutionary algorithm . The proposed system is evaluated on a real multiple-comparison identification scenario including 10 X-ray images and 10 CTs, where manual and automatic segmentation approaches are compared. The global results shows that the proposed system is able to filter 50\% of the sample. These preliminary results suggest that our system can reliably keep the true positive identity in the first half of the sample, allowing for a significant reduction of forensic experts’ workload and shortening identification times.},
  archive      = {J_NEUCOM},
  author       = {Óscar Gómez and Pablo Mesejo and Óscar Ibáñez and Óscar Cordón},
  doi          = {10.1016/j.neucom.2020.10.116},
  journal      = {Neurocomputing},
  pages        = {575-585},
  shortjournal = {Neurocomputing},
  title        = {Deep architectures for the segmentation of frontal sinuses in X-ray images: Towards an automatic forensic identification system in comparative radiography},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on hybrid artificial intelligence systems from
HAIS 2019 conference. <em>NEUCOM</em>, <em>456</em>, 573–574. (<a
href="https://doi.org/10.1016/j.neucom.2021.06.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Hilde Pérez and Lidia Sánchez-González and Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2021.06.042},
  journal      = {Neurocomputing},
  pages        = {573-574},
  shortjournal = {Neurocomputing},
  title        = {Special issue on hybrid artificial intelligence systems from HAIS 2019 conference},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HAL: Hybrid active learning for efficient labeling in
medical domain. <em>NEUCOM</em>, <em>456</em>, 563–572. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of the deep convolutional neural networks in computer vision tasks mainly relies on massive labeled training data. However, in the field of medical images, it is difficult to construct large labeled datasets since the labeling of medical images is time-consuming, labor-intensive, and medical expertise demanded. To meet the challenge, we propose a hybrid active learning framework HAL for efficient labeling in the medical domain, which integrates active learning into deep learning to reduce the cost of manual labeling and take the advantages of deep neural networks . The proposed HAL utilizes a hybrid sampling strategy considering both sample diversity and prediction loss simultaneously. The effectiveness and efficiency of proposed HAL are validated on three medical image datasets. The experimental results show that the proposed HAL outperforms several state-of-the-art active learning methods. On the Hyper-Kvasir Dataset, with only 10\% of the labels, the HAL achieves 95\% performance of the deep learning method trained on the entire dataset. The quantitative and qualitative analysis proves that HAL can greatly reduce the number of labels needed for training a deep neural network, which is robust to address efficient labeling problems even with imbalanced data distribution.},
  archive      = {J_NEUCOM},
  author       = {Xing Wu and Cheng Chen and Mingyu Zhong and Jianjia Wang},
  doi          = {10.1016/j.neucom.2020.10.115},
  journal      = {Neurocomputing},
  pages        = {563-572},
  shortjournal = {Neurocomputing},
  title        = {HAL: Hybrid active learning for efficient labeling in medical domain},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent fault diagnosis model based on deep neural
network for few-shot fault diagnosis. <em>NEUCOM</em>, <em>456</em>,
550–562. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The most existing deep neural networks (DNN)-based methods for fault diagnosis only focus on prediction accuracy without considering the limitation of labeled sample size. In practical applications of DNN-based methods, it is time-consuming and costly to collect massive labeled samples. In this paper a task named few-shot fault diagnosis is defined as training model given small labeled samples in source domain and testing given small samples in target domain. We develop a novel intelligent fault diagnosis model for few-shot fault diagnosis which is using similarities of sample pairs to classify samples, rather than end-to-end classification. The proposed model contains modules of feature learning and metric learning. The module of feature learning has twin neural networks aiming to extract features from the sample pair. The module of metric learning is to predict similarity of the sample pair. The similarities of sample pairs combined the test sample with each labelled sample are utilized to complete the classification task . Label smoothing is utilized to further improve performance of classification. The performance of the proposed model is verified by two fault diagnosis cases which are bearing fault diagnosis cross different working conditions and cross bearing locations. The comparison studies with other models demonstrate the superiority of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Cunjun Wang and Zili Xu},
  doi          = {10.1016/j.neucom.2020.11.070},
  journal      = {Neurocomputing},
  pages        = {550-562},
  shortjournal = {Neurocomputing},
  title        = {An intelligent fault diagnosis model based on deep neural network for few-shot fault diagnosis},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Few-shot palmprint recognition based on similarity metric
hashing network. <em>NEUCOM</em>, <em>456</em>, 540–549. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Palmprint recognition is one of the effective biometric technologies due to the advantages of convenience and safety. Recently, many deep learning-based methods are utilized in palmprint recognition and achieve satisfactory results. However, most of the existing learning methods are driven by the abundant labeled data. When the training data are insufficient, their performance drop sharply. In this work, we propose a novel and effective end-to-end algorithm for few-shot palmprint recognition, called Similarity Metric Hashing Network (SMHNet). SMHNet is designed to extract the features of palmprint images on both the structural and pixel levels. Specifically, an embedded structural similarity (SSIM) index block is constructed behind the last convolution layer to measure the structural similarity between query samples and support ones. A novel SSIM loss is designed with distance loss to train the entire model from scratch. Furthermore, a hashing block is added after the last fully connected (FC) layer to encode the features into hashing codes, which is convenient for large-scale feature storage and retrieval. Extensive experiments are conducted on three benchmark palmprint databases, and the results demonstrate that our model can achieve competitive accuracy compared with several state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Chengcheng Liu and Dexing Zhong and Huikai Shao},
  doi          = {10.1016/j.neucom.2020.07.153},
  journal      = {Neurocomputing},
  pages        = {540-549},
  shortjournal = {Neurocomputing},
  title        = {Few-shot palmprint recognition based on similarity metric hashing network},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sketch-specific data augmentation for freehand sketch
recognition. <em>NEUCOM</em>, <em>456</em>, 528–539. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sketch recognition remains a significant challenge due to the limited training data and the substantial intra-class variance of freehand sketches for the same object. Conventional methods for this task often rely on the availability of the temporal order of sketch strokes, additional cues acquired from different modalities and supervised augmentation of sketch datasets with real images, which also limit the applicability and feasibility of these methods in real scenarios. In this paper, we propose a novel sketch-specific data augmentation (SSDA) method that leverages the quantity and quality of the sketches automatically. From the aspect of quantity, we introduce a Bezier pivot based deformation (BPD) strategy to enrich the training data. Towards quality improvement, we present a mean stroke reconstruction (MSR) approach to generate a set of novel types of sketches with smaller intra-class variances. Both of these solutions are unrestricted from any multi-source data and temporal cues of sketches. Furthermore, we show that some recent deep convolutional neural network models that are trained on generic classes of real images can be better choices than most of the elaborate architectures that are designed explicitly for sketch recognition. As SSDA can be integrated with any convolutional neural networks, it has a distinct advantage over the existing methods. Our extensive experimental evaluations demonstrate that the proposed method achieves the state-of-the-art results (84.27\%) on the TU-Berlin dataset, outperforming the human performance by a remarkable 11.17\% increase. Finally, more experiments show the practical value of our approach for the task of sketch-based image retrieval .},
  archive      = {J_NEUCOM},
  author       = {Ying Zheng and Hongxun Yao and Xiaoshuai Sun and Shengping Zhang and Sicheng Zhao and Fatih Porikli},
  doi          = {10.1016/j.neucom.2020.05.124},
  journal      = {Neurocomputing},
  pages        = {528-539},
  shortjournal = {Neurocomputing},
  title        = {Sketch-specific data augmentation for freehand sketch recognition},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep video action clustering via spatio-temporal feature
learning. <em>NEUCOM</em>, <em>456</em>, 519–527. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent years have witnessed significant advances in deep video action recognition . However, the performances of deep learning-based video action recognition methods are limited in the case of relatively small samples or no labeled samples. Therefore, trying to use unlabeled video data to generate clustering label is essential for small sample learning and zero sample learning. In this paper, we propose a novel deep video action clustering network, which aims to learn the similarity relationship among the unlabeled video samples, and generate the clustering label for each video sample. Specifically, the proposed method simultaneously learns the spatio-temporal features and subspace representations under a jointly optimized framework. It consists of a 3D U-Net self-representation generator, a video-clip reconstruction discriminator , and a confidence-based feedback mechanism. The 3D U-Net self-representation generator learns the spatio-temporal features of the video clips and produces subspace representation matrix . Then, the similarity graph is constructed based on this subspace representation matrix , and the clustering result is obtained. In the learning procedure, a confidence-based feedback mechanism is designed to feed the high-confidence labels of partial samples back to further guide the subspace structure learning , so that the optimal result can be obtained. During training, the video-clip reconstruction discriminator is introduced to evaluate the reconstructed video clips, which is beneficial for capturing the discriminative spatio-temporal features. Experimental results on a video benchmark dataset demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Bo Peng and Jianjun Lei and Huazhu Fu and Yalong Jia and Zongqian Zhang and Yi Li},
  doi          = {10.1016/j.neucom.2020.05.123},
  journal      = {Neurocomputing},
  pages        = {519-527},
  shortjournal = {Neurocomputing},
  title        = {Deep video action clustering via spatio-temporal feature learning},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep time series models for scarce data. <em>NEUCOM</em>,
<em>456</em>, 504–518. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series data have grown at an explosive rate in numerous domains and have stimulated a surge of time series modeling research. A comprehensive comparison of different time series models , for a considered data analytics task, provides useful guidance on model selection for data analytics practitioners. Data scarcity is a universal issue that occurs in a vast range of data analytics problems, due to the high costs associated with collecting, generating, and labeling data as well as some data quality issues such as missing data. In this paper, we focus on the temporal classification/regression problem that attempts to build a mathematical mapping from multivariate time series inputs to a discrete class label or a real-valued response variable. For this specific problem, we identify two types of scarce data: scarce data with small samples and scarce data with sparsely and irregularly observed time series covariates. Observing that all existing works are incapable of utilizing the sparse time series inputs for proper modeling building, we propose a model called sparse functional multilayer perceptron (SFMLP) for handling the sparsity in the time series covariates. The effectiveness of the proposed SFMLP under each of the two types of data scarcity, in comparison with the conventional deep sequential learning models (e.g., Recurrent Neural Network , and Long Short-Term Memory), is investigated through mathematical arguments and numerical experiments.},
  archive      = {J_NEUCOM},
  author       = {Qiyao Wang and Ahmed Farahat and Chetan Gupta and Shuai Zheng},
  doi          = {10.1016/j.neucom.2020.12.132},
  journal      = {Neurocomputing},
  pages        = {504-518},
  shortjournal = {Neurocomputing},
  title        = {Deep time series models for scarce data},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep InterBoost networks for small-sample image
classification. <em>NEUCOM</em>, <em>456</em>, 492–503. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have recently shown excellent performance on numerous image classification tasks. These networks often need to estimate a large number of parameters and require much training data. When the amount of training data is small, however, a network with high flexibility quickly overfits the training data, resulting in a large model variance and poor generalization. To address this problem, we propose a new, simple yet effective ensemble method called InterBoost for small-sample image classification. In the training phase, InterBoost first randomly generates two sets of complementary weights for training data, which are used for separately training two base networks of the same structure, and then the two sets of complementary weights are updated for refining the training of the networks through interaction between the two base networks previously trained. This interactive training process continues iteratively until a stop criterion is met. In the testing phase, the outputs of the two networks are combined to obtain one final score for classification. Experimental results on four small-sample datasets, UIUC-Sports, LabelMe, 15Scenes and Caltech101, demonstrate that the proposed ensemble method outperforms existing ones. Moreover, results from the Wilcoxon signed-rank tests show that our method is statistically significantly better than the methods compared. Detailed analysis is also provided for an in-depth understanding of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xiaoxu Li and Dongliang Chang and Zhanyu Ma and Zheng-Hua Tan and Jing-Hao Xue and Jie Cao and Jun Guo},
  doi          = {10.1016/j.neucom.2020.06.135},
  journal      = {Neurocomputing},
  pages        = {492-503},
  shortjournal = {Neurocomputing},
  title        = {Deep InterBoost networks for small-sample image classification},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adding geodesic information and stochastic patch-wise image
prediction for small dataset learning. <em>NEUCOM</em>, <em>456</em>,
481–491. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most recent methods of image augmentation and prediction are building upon the deep learning paradigm. A careful preparation of the image dataset and the choice of a suitable network architecture are crucial steps to assess the desired image features and, thence, achieve accurate predictions. We first propose to help the learning process by adding structural information with specific distance transform to the input image data. To handle cases with limited number of training samples, we propose a patch-based procedure with a stratified sampling method at inference. We validate our approaches on two image datasets, corresponding to two different tasks. The ability of our method to segment and predict images is investigated through the ISBI 2012 segmentation challenge dataset and generated electric field masks, respectively. The obtained results are evaluated using appropriate metrics: VRand for image segmentation and SSIM, UIQ and PSNR for image prediction. The proposed techniques demonstrate that the established framework is a reliable estimation method that could be used for a wide range of applications.},
  archive      = {J_NEUCOM},
  author       = {Adam Hammoumi and Maxime Moreaud and Christophe Ducottet and Sylvain Desroziers},
  doi          = {10.1016/j.neucom.2021.01.108},
  journal      = {Neurocomputing},
  pages        = {481-491},
  shortjournal = {Neurocomputing},
  title        = {Adding geodesic information and stochastic patch-wise image prediction for small dataset learning},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain generalization via optimal transport with metric
similarity learning. <em>NEUCOM</em>, <em>456</em>, 469–480. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalizing knowledge to unseen domains, where data and labels are unavailable, is crucial for machine learning models. We tackle the domain generalization problem to learn from multiple source domains and generalize to a target domain with unknown statistics. The crucial idea is to extract the underlying invariant features across all the domains. Previous domain generalization approaches mainly focused on learning invariant features and stacking the learned features from each source domain to generalize to a new target domain while ignoring the label information, which will lead to indistinguishable features with an ambiguous classification boundary. One possible solution is to constrain the label-similarity when extracting the invariant features and take advantage of the label similarities for class-specific cohesion and separation of features across domains. Therefore we adopt optimal transport with Wasserstein distance, which could constrain the class label similarity, for adversarial training and also further deploy a metric learning objective to leverage the label information for achieving distinguishable classification boundary. Empirical results show that our proposed method could outperform most of the baselines. Furthermore, ablation studies also demonstrate the effectiveness of each component of our method.},
  archive      = {J_NEUCOM},
  author       = {Fan Zhou and Zhuqing Jiang and Changjian Shui and Boyu Wang and Brahim Chaib-draa},
  doi          = {10.1016/j.neucom.2020.09.091},
  journal      = {Neurocomputing},
  pages        = {469-480},
  shortjournal = {Neurocomputing},
  title        = {Domain generalization via optimal transport with metric similarity learning},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). A concise review of recent few-shot meta-learning methods.
<em>NEUCOM</em>, <em>456</em>, 463–468. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot meta-learning has been recently reviving with expectations to mimic humanity’s fast adaption to new concepts based on prior knowledge. In this short communication, we give a concise review on recent representative methods in few-shot meta-learning, which are categorized into four branches according to their technical characteristics. We conclude this review with some vital current challenges and future prospects in few-shot meta-learning.},
  archive      = {J_NEUCOM},
  author       = {Xiaoxu Li and Zhuo Sun and Jing-Hao Xue and Zhanyu Ma},
  doi          = {10.1016/j.neucom.2020.05.114},
  journal      = {Neurocomputing},
  pages        = {463-468},
  shortjournal = {Neurocomputing},
  title        = {A concise review of recent few-shot meta-learning methods},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Guest editorial: Special issue on deep learning with small
samples. <em>NEUCOM</em>, <em>456</em>, 461–462. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Jing-Hao Xue and Jufeng Yang and Xiaoxu Li and Yan Yan and Yujiu Yang and Zongqing Lu and Zhanyu Ma},
  doi          = {10.1016/j.neucom.2021.01.109},
  journal      = {Neurocomputing},
  pages        = {461-462},
  shortjournal = {Neurocomputing},
  title        = {Guest editorial: Special issue on deep learning with small samples},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-continuous energy-conservation neural network for
structural dynamics analysis. <em>NEUCOM</em>, <em>456</em>, 450–460.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fast and accurate structural dynamics analysis is important for structural design and damage assessment. Structural dynamics analysis leveraging machine learning techniques has become a popular research focus in recent years. Although the basic neural network provides an alternative approach for structural dynamics analysis, the lack of physics law inside the neural network limits the model accuracy and fidelity. In this paper, a new family of the energy-conservation neural network is introduced, which respects the physical laws. The neural network is explored from a fundamental single-degree-of-freedom system to a complicated multiple-degrees-of-freedom system. The damping force and external forces are also considered step by step. To improve the parallelization of the algorithm, the derivatives of the structural states are parameterized with the novel energy-conservation neural network instead of specifying the discrete sequence of structural states. The proposed model uses the system energy as the last layer of the neural network and leverages the underlying automatic differentiation graph to incorporate the system energy naturally, which ultimately improves the accuracy and long-term stability of structural dynamics response calculation under an earthquake impact. The trade-off between computation accuracy and speed is discussed. As a case study, a 3-story building earthquake simulation is conducted with realistic earthquake records.},
  archive      = {J_NEUCOM},
  author       = {Yuan Feng and Hexiang Wang and Han Yang and Fangbo Wang},
  doi          = {10.1016/j.neucom.2021.03.074},
  journal      = {Neurocomputing},
  pages        = {450-460},
  shortjournal = {Neurocomputing},
  title        = {Time-continuous energy-conservation neural network for structural dynamics analysis},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty quantification in extreme learning machine:
Analytical developments, variance estimates and confidence intervals.
<em>NEUCOM</em>, <em>456</em>, 436–449. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Uncertainty quantification is crucial to assess prediction quality of a machine learning model. In the case of Extreme Learning Machines (ELM), most methods proposed in the literature make strong assumptions on the data, ignore the randomness of input weights or neglect the bias contribution in confidence interval estimations. This paper presents novel estimations that overcome these constraints and improve the understanding of ELM variability. Analytical derivations are provided under general assumptions, supporting the identification and the interpretation of the contribution of different variability sources. Under both homoskedasticity and heteroskedasticity, several variance estimates are proposed, investigated, and numerically tested, showing their effectiveness in replicating the expected variance behaviours. Finally, the feasibility of confidence intervals estimation is discussed by adopting a critical approach, hence raising the awareness of ELM users concerning some of their pitfalls. The paper is accompanied with a scikit-learn compatible Python library enabling efficient computation of all estimates discussed herein.},
  archive      = {J_NEUCOM},
  author       = {Fabian Guignard and Federico Amato and Mikhail Kanevski},
  doi          = {10.1016/j.neucom.2021.04.027},
  journal      = {Neurocomputing},
  pages        = {436-449},
  shortjournal = {Neurocomputing},
  title        = {Uncertainty quantification in extreme learning machine: Analytical developments, variance estimates and confidence intervals},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generic FPGA-based hardware architecture for recursive
least mean p-power extreme learning machine. <em>NEUCOM</em>,
<em>456</em>, 421–435. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recursive least mean p-power extreme learning machine (RLMP-ELM) is a newly proposed online machine learning algorithm and is able to provide a robust online prediction of the datasets with noises of different statistics. To further explore the proposed RLMP-ELM to be used in real-world embedded systems, a generic serial FPGA-based hardware architecture of RLMP-ELM is presented in this paper. The entire hardware architecture of RLMP-ELM includes three serial processing modules, which are implemented parameterizably and can be adapted for different application requirements. The hardware framework is in a serial fashion, but parallelization efforts are focused on the processes with high computing complexity by analysis of potential inter-task dependency. To overcome the limitation of memory bandwidth , the block RAM and ping-pong on-chip buffer are applied to improve the computational throughput. The validation experiments are performed through five datasets with different p values. Accuracy results show that our implementation on FPGA could achieve similar accuracy compared to 64-bit floating-point software implementation. We also report and compare hardware performance of our proposed architecture with other existing implementations. The results show that our hardware architecture offers the excellent balance among accuracy, logic occupation and hardware performance .},
  archive      = {J_NEUCOM},
  author       = {Hui Huang and Jing Yang and Hai-Jun Rong and Shaoyi Du},
  doi          = {10.1016/j.neucom.2021.05.069},
  journal      = {Neurocomputing},
  pages        = {421-435},
  shortjournal = {Neurocomputing},
  title        = {A generic FPGA-based hardware architecture for recursive least mean p-power extreme learning machine},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Encoding-based memory for recurrent neural networks.
<em>NEUCOM</em>, <em>456</em>, 407–420. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to solve sequential tasks with recurrent models requires the ability to memorize long sequences and to extract task-relevant features from them. In this paper, we study memorization from the point of view of the design and training of recurrent neural networks . We study how to maximize the short-term memory of recurrent units, an objective difficult to achieve using backpropagation . We propose a new model, the Linear Memory Network, which features an encoding-based memorization component built with a linear autoencoder for sequences. Additionally, we provide a specialized training algorithm that initializes the memory to efficiently encode the hidden activations of the network. Experimental results on synthetic and real-world datasets show that the chosen encoding mechanism is superior to static encodings such as orthogonal models and the delay line. The method also outperforms RNN and LSTM units trained using stochastic gradient descent . Experiments on symbolic music modeling show that the training algorithm specialized for the memorization component improves the final performance compared to stochastic gradient descent .},
  archive      = {J_NEUCOM},
  author       = {Antonio Carta and Alessandro Sperduti and Davide Bacciu},
  doi          = {10.1016/j.neucom.2021.04.051},
  journal      = {Neurocomputing},
  pages        = {407-420},
  shortjournal = {Neurocomputing},
  title        = {Encoding-based memory for recurrent neural networks},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating explicit syntactic dependency for aspect level
sentiment classification. <em>NEUCOM</em>, <em>456</em>, 394–406. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect level sentiment classification aims to extract fine-grained sentiment expressed towards specific aspects from a sentence. The key to this task lies in connecting aspects and their respective sentiment contexts. Existing methods measure the dependency weights between aspects and context words via either the semantic similarity between words captured by attention mechanism or the structural proximity between words in syntactic structures. However, methods in both groups fail to fully exploit explicit syntactic dependency, which we argue should be critical to identify sentiment contexts. In this paper, we propose a novel syntactic-dependency-based attention network (SDATT) to incorporate explicit syntactic dependency for aspect level sentiment classification. SDATT first models the dependency path between each word and the aspect to characterize aspect-oriented syntactic representation of each word. The generated syntactic representations are later fed into the attention layer to help infer the dependency weights for sentiment prediction . Experimental results on five benchmark datasets show the superior performance of the proposed model over state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Wenjun Ke and Jinhua Gao and Huawei Shen and Xueqi Cheng},
  doi          = {10.1016/j.neucom.2021.05.078},
  journal      = {Neurocomputing},
  pages        = {394-406},
  shortjournal = {Neurocomputing},
  title        = {Incorporating explicit syntactic dependency for aspect level sentiment classification},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Cross-modality online distillation for multi-view action
recognition. <em>NEUCOM</em>, <em>456</em>, 384–393. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, some multi-modality features are introduced to the multi-view action recognition methods in order to obtain a more robust performance. However, it is intuitive that not all modalities are avail- able in real applications. For example, daily scenes lack depth modal data and capture RGB sequences only. Thus comes the challenge of learning critical features from multi-modality data at train time, while still getting robust performance based on RGB sequences at test time. To address this chal- lenge, our paper presents a novel two-stage teacher-student framework. The teacher network takes advantage of multi-view geometry-and-texture features during training, while the student network is given only RGB sequences at test time. Specifically, in the first stage, Cross-modality Aggregated Transfer (CAT) network is proposed to transfer multi-view cross-modality aggregated features from the teacher network to the student network. Moreover, we design a Viewpoint-Aware Attention (VAA) module which captures discriminative information across different views to combine multi-view fea- tures effectively. In the second stage, Multi-view Features Strengthen (MFS) network with the VAA module further strengthens the global view-invariance features of the student network. Besides, both of CAT and MFS learn in an online distillation manner, so that the teacher and the student network can be trained jointly. Extensive experiments on IXMAS and Northwestern-UCLA demonstrate the effectiveness of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Chao Xu and Xia Wu and Yachun Li and Yining Jin and Mengmeng Wang and Yong Liu},
  doi          = {10.1016/j.neucom.2021.05.077},
  journal      = {Neurocomputing},
  pages        = {384-393},
  shortjournal = {Neurocomputing},
  title        = {Cross-modality online distillation for multi-view action recognition},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving GAN with inverse cumulative distribution function
for tabular data synthesis. <em>NEUCOM</em>, <em>456</em>, 373–383. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designing a generative model to synthesize realistic tabular data is of great significance in data science. Existing tabular data generative models have difficulty in handling complicated and diverse marginal distribution types due to the gradient vanishing problem, and these models pay little attention to the correlation between attributes. We propose a method that improves the generative adversarial network (GAN) with inverse cumulative distribution function for tabular data synthesis. This method first transforms continuous columns into uniform distribution data by using the cumulative distribution function, which can alleviate the gradient vanishing problem in model training. Then the method trains GAN with the transformed data, where the discriminator with label reconstruction function is presented to model the correlation among attributes accurately by introducing an auxiliary supervised task to help the correlations extraction. After that, we train a neural network for each continuous column to perform the inverse transformation of generated data into the target distribution, thereby the synthetic data is obtained. Experiments on simulated and real-world datasets show that our method compares favorably against the state-of-the-art methods in modeling tabular data.},
  archive      = {J_NEUCOM},
  author       = {Ban Li and Senlin Luo and Xiaonan Qin and Limin Pan},
  doi          = {10.1016/j.neucom.2021.05.098},
  journal      = {Neurocomputing},
  pages        = {373-383},
  shortjournal = {Neurocomputing},
  title        = {Improving GAN with inverse cumulative distribution function for tabular data synthesis},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Neural dynamics for adaptive attitude tracking control of a
flapping wing micro aerial vehicle. <em>NEUCOM</em>, <em>456</em>,
364–372. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a class of neural dynamics models based on a neural dynamic approach to realize attitude tracking control of a flapping wing micro aerial vehicle (FWMAV), different from the existing conventional controllers . Firstly, from the perspective of FWMAV attitude tracking control , an attitude tracking model is presented. Further theoretical analyses reveal that there exist theoretical errors on such a controller when solving the attitude tracking control problem. To remedy its deficiency, we propose a class of adaptive neural dynamics models with activation functions . Different from the existing controller, the adaptive neural dynamics model adopts different activation functions to accelerate the convergence speed of attitude tracking errors and makes errors converge to zero in a short time. Finally, simulation results and theoretical analyses are provided, which verify that the proposed controllers possess the superiority and effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Mei Liu and Dexiu Ma and Shuai Li},
  doi          = {10.1016/j.neucom.2021.05.088},
  journal      = {Neurocomputing},
  pages        = {364-372},
  shortjournal = {Neurocomputing},
  title        = {Neural dynamics for adaptive attitude tracking control of a flapping wing micro aerial vehicle},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised moiré pattern removal for recaptured screen
images. <em>NEUCOM</em>, <em>456</em>, 352–363. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Moiré patterns, mainly due to the aliasing between the grids of display devices and camera sensors, often occur in recaptured screen images (videos). The spatial variety in densities and scales makes it difficult to remove moiré patterns with hand-crafted priors. Prevalent supervised-learning based methods require huge amount of paired images, which are difficult to capture and align. This paper proposes an unsupervised Generative Adversarial Network for Moiré Removal (MR-GAN), which is the first attempt at unsupervised learning based moiré removal. The recaptured images are corrected against vignetting artifacts to make MR-GAN focus on correcting brightness and contrast distortions while removing moiré patterns. We propose two complementary discriminator groups to effectively distinguish moiré patterns and image features at both large scales and small scales. A group of self-supervised loss functions, including cycle consistent loss, identity loss, cosine similarity loss, and content leakage loss, are designed to train effective generators. Experimental results demonstrate that our method outperforms state-of-the-art demoiréing methods on a large set of test images. Our code and dataset are released in the link: https://github.com/JerryLeolfl/pytorch-MRGAN-master .},
  archive      = {J_NEUCOM},
  author       = {Huanjing Yue and Yijia Cheng and Fanglong Liu and Jingyu Yang},
  doi          = {10.1016/j.neucom.2021.05.099},
  journal      = {Neurocomputing},
  pages        = {352-363},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised moiré pattern removal for recaptured screen images},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Reconstruction of natural images from evoked brain activity
with a dictionary-based invertible encoding procedure. <em>NEUCOM</em>,
<em>456</em>, 338–351. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Studies on visual encoding and reconstruction based on functional magnetic resonance imaging (fMRI) have inspired each other in recent years. However, as far as we know, there has not been any study that has achieved the reconstruction of natural stimuli by directly reversing an encoding model with strong interpretability ; in other words, the interpretability of current decoding methods is weak. To solve this problem, we first design a reversible feature extraction method using Gabor wavelets and build a nonnegative sparse mapping between the features and brain activity , thus achieving visual encoding . Then, based on the mapping, we estimate the features from measured brain activity and reverse the feature extraction method step-by-step. In this process, we use dictionary-learning technology to explore the natural statistical structure of the features from the image database, thereby greatly reducing the negative impact of information loss and fMRI noise. Finally, the stimuli can be reconstructed from the estimated features by back-propagation. Because the encoding procedure is highly transparent, the reconstruction procedure obtained by reversing the encoding model is also highly interpretable. The experiments show that our encoding method can build effective voxel-wise models for early visual areas, and also show that the proposed method is capable of reconstructing the basic outline of the stimuli with low structural complexity.},
  archive      = {J_NEUCOM},
  author       = {Chao Li and Baolin Liu and Jianguo Wei},
  doi          = {10.1016/j.neucom.2021.05.083},
  journal      = {Neurocomputing},
  pages        = {338-351},
  shortjournal = {Neurocomputing},
  title        = {Reconstruction of natural images from evoked brain activity with a dictionary-based invertible encoding procedure},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). A lightweight multi-scale channel attention network for
image super-resolution. <em>NEUCOM</em>, <em>456</em>, 327–337. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning techniques have significantly improved the performance of single image super-resolution (SISR). However, this improvement is often achieved at the cost of introducing a large amount of parameters, which limits the real-world applications for SISR. In this paper, we propose a lightweight SISR network called Multi-scale Channel Attention Network for Image Super-Resolution (MCSN). Our contributions are threefold. First of all, the multi-scale feature fusion block (MSFFB) can extract multi-scale features by filters with different receptive fields. Secondly, the channel shuffle attention mechanism (CSAM) encourages the flow of the information across feature channels and enhances the ability of feature selection. Thirdly, the global feature fusion connection (GFFC) can effectively improve feature utilization. Extensive experiments demonstrate that the parameter amount of our method is reduced by 3/4 compared with the current state-of-the-art MSRN method, while both the subjective visual effect and objective quality of the reconstructed high-resolution images are significantly better.},
  archive      = {J_NEUCOM},
  author       = {Wenbin Li and Juefei Li and Jinxin Li and Zhiyong Huang and Dengwen Zhou},
  doi          = {10.1016/j.neucom.2021.05.090},
  journal      = {Neurocomputing},
  pages        = {327-337},
  shortjournal = {Neurocomputing},
  title        = {A lightweight multi-scale channel attention network for image super-resolution},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive low-rank subspace alignment based on
semi-supervised joint domain adaption for personalized emotion
recognition. <em>NEUCOM</em>, <em>456</em>, 312–326. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, many scenarios, such as affective disorders treatment, have sparked rising needs for establishment of personalized emotion recognition (PER) models. Unfortunately, the data sparsity issue violates the basic i.i.d. assumption of supervised learning (i.e., training data and test data are independently and identically distributed). In this paper, we present a semi-supervised joint domain adaption (SSJDA) solution, aiming to inject the hidden domain knowledge from ample labeled data of multiple source individuals into the target subject’s customized model. Specifically, we put forward a novel Progressive Low-Rank Subspace Alignment (PLRSA) approach, which unifies a semi-supervised instance-transfer paradigm and an unsupervised mapping-transfer learning paradigm in a single optimization framework. We leverage the boosting-based TrAdaBoost algorithm and the Transfer Component Analysis (TCA) algorithm for the implementation of instance reweighting and feature matching, respectively. Then we introduce the ℓ 2 , 1 ℓ2,1 - norm to pass feedback and make the joint learning feasible. The central idea is to progressively minimize the cross-domain distribution discrepancies to finally construct the optimal domain-invariant features. We systematically compare the PLRSA method with five state-of-the-art techniques using two public EEG datasets (DEAP and SEED). Both many-to-one and one-to-one evaluations are performed. The experimental results have confirmed the efficacy of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Junhai Luo and Man Wu and Zhiyan Wang and Yanping Chen and Yang Yang},
  doi          = {10.1016/j.neucom.2021.05.064},
  journal      = {Neurocomputing},
  pages        = {312-326},
  shortjournal = {Neurocomputing},
  title        = {Progressive low-rank subspace alignment based on semi-supervised joint domain adaption for personalized emotion recognition},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Utilizing graph neural networks to improving dialogue-based
relation extraction. <em>NEUCOM</em>, <em>456</em>, 299–311. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Relation extraction has been an active research interest in the field of Natural Language Processing (NLP). The past works primarily focused on a corpus of formal text which is inherently non-dialogic. Recently, the dialogue-based relation extraction task, which detects relations among speaker-aware entities scattering in dialogues, has been gradually arousing people’s attention. Some sequence-based neural methods have been carried out to obtain the relevant information. However, identifying cross-sentence relations remains unsolved, especially in the context of a specific-domain dialogue system . In this paper, we propose a Relational Attention Enhanced Graph Convolutional Network (RAEGCN), which constructs the whole dialogue as a semantic interactive graph by emphasizing the speaker-related information and leveraging various inter-sentence dependencies. A dense connectivity mechanism is also introduced to empower the multi-hop relational reasoning across sentences, which can capture both local and non-local features simultaneously. Experiments show the significant superiority and robustness of our model on a real-world dataset DialogRE, as compared with previous approaches.},
  archive      = {J_NEUCOM},
  author       = {Lulu Zhao and Weiran Xu and Sheng Gao and Jun Guo},
  doi          = {10.1016/j.neucom.2021.05.082},
  journal      = {Neurocomputing},
  pages        = {299-311},
  shortjournal = {Neurocomputing},
  title        = {Utilizing graph neural networks to improving dialogue-based relation extraction},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). SDCRKL-GP: Scalable deep convolutional random kernel
learning in gaussian process for image recognition. <em>NEUCOM</em>,
<em>456</em>, 288–298. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks have shown great potential in image recognition tasks. However, the fact that the mechanism of deep learning is difficult to explain hinders its development. It involves a large amount of parameter learning, which results in high computational complexity . Moreover, deep convolutional neural networks are often limited by overfitting in regimes in which the number of training samples is limited. Conversely, kernel learning methods have a clear mathematical theory , fewer parameters, and can contend with small sample sizes; however, they are not able to handle high-dimensional data, e.g., images. It is important to achieve a performance and complexity trade-off in complicated tasks. In this paper, we propose a novel scalable deep convolutional random kernel learning in Gaussian process architecture called SDCRKL-GP, which is characterized by excellent performance and low complexity. First, we successfully incorporated the deep convolutional architecture into kernel learning by implementing the random Fourier feature transform for Gaussian processes, which can effectively capture hierarchical and local image-level features. This approach enabled the kernel method to effectively handle image processing problems. Second, we optimized the parameters of deep convolutional filters and Gaussian kernels by stochastic variational inference. Then, we derived the lower variational bound of the marginal likelihood. Finally, we explored the model architecture design space selection method to determine the appropriate network architecture for different datasets. The design space consists of the number of layers, the channels per layer, and so on. Different design space selections improved the scalability of the SDCRKL-GP architecture. We evaluated SDCRKL-GP on the MNIST, FMNIST, CIFAR10, and CALTECH4 benchmark datasets. Taking MNIST as an example, the error rate of classification is 0.60\%, and the number of parameters, number of computations and memory access cost of the architecture are 19.088k, 0.984M, and 1.057M, respectively. The experimental results verified that the proposed SDCRKL-GP method outperforms several state-of-the-art algorithms in both accuracy and speed in image recognition tasks. The code is available at https://github.com/w-tingting/deep-rff-pytorch.},
  archive      = {J_NEUCOM},
  author       = {Tingting Wang and Lei Xu and Junbao Li},
  doi          = {10.1016/j.neucom.2021.05.092},
  journal      = {Neurocomputing},
  pages        = {288-298},
  shortjournal = {Neurocomputing},
  title        = {SDCRKL-GP: Scalable deep convolutional random kernel learning in gaussian process for image recognition},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A self-organizing map and a normalizing multi-layer
perceptron approach to baselining in prognostics under dynamic regimes.
<em>NEUCOM</em>, <em>456</em>, 268–287. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the influence of changing operational and environmental conditions, such as temperature and external loading, is not factored out from sensor data it can be difficult to observe a clear deterioration path. This can significantly affect the task of engineering prognostics and other health management operations. To address this problem of dynamic operating regimes, it is necessary to baseline the data, typically by first finding the operating regimes and then normalizing the data within each regime. This paper describes a baselining solution based on neural networks. A self-organizing map is used to identify the regimes, and a multi-layer perceptron is used to normalize the sensor data according to the detected regimes. Tests are performed on public datasets from a turbofan simulator. The approach can produce similar results to classical methods without the need to specify in advance the number of regimes and the explicit computation of the statistical properties of a hold-out dataset. Importantly, the techniques can be integrated into a deep learning system to perform prognostics in a single pass.},
  archive      = {J_NEUCOM},
  author       = {Marcia Lourenco Baptista and Elsa M. P. Henriques and Kai Goebel},
  doi          = {10.1016/j.neucom.2021.05.031},
  journal      = {Neurocomputing},
  pages        = {268-287},
  shortjournal = {Neurocomputing},
  title        = {A self-organizing map and a normalizing multi-layer perceptron approach to baselining in prognostics under dynamic regimes},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential stability of hopfield neural networks with
conformable fractional derivative. <em>NEUCOM</em>, <em>456</em>,
263–267. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A class of Hopfield neural networks with conformable fractional derivative is studied. Sufficient conditions are derived for the existence and uniqueness of the equilibrium point of the network. Moreover, by using a Lyapunov function exponential stability result is proved.},
  archive      = {J_NEUCOM},
  author       = {Aysen Kütahyalıoglu and Fatma Karakoç},
  doi          = {10.1016/j.neucom.2021.05.076},
  journal      = {Neurocomputing},
  pages        = {263-267},
  shortjournal = {Neurocomputing},
  title        = {Exponential stability of hopfield neural networks with conformable fractional derivative},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Almost sure exponential synchronization of network systems
under a new intermittent noise-diffusion layer. <em>NEUCOM</em>,
<em>456</em>, 253–262. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel intermittent noise-diffusion layer is proposed to synchronize a network system. Different from most of the traditional noise-induced synchronization or noise stabilization (noise exists in nodes of the network), we give an intermittent noise-diffusion layer (the noise exists in the edges of the network) to study the almost sure exponential synchronization. The theoretical results show that the general network system can be synchronized in the almost sure sense as long as the topological structure of the network in the intermittent noise-diffusion layer is an undirected connected graph . Two examples are proposed to illustrate the theory obtained.},
  archive      = {J_NEUCOM},
  author       = {Ying Guo and Yifan Zhang and Yongbao Wu},
  doi          = {10.1016/j.neucom.2021.05.080},
  journal      = {Neurocomputing},
  pages        = {253-262},
  shortjournal = {Neurocomputing},
  title        = {Almost sure exponential synchronization of network systems under a new intermittent noise-diffusion layer},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale features based interpersonal relation
recognition using higher-order graph neural network. <em>NEUCOM</em>,
<em>456</em>, 243–252. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpersonal relation plays an essential role to gain understandings on how people interact with each other. In computer vision, interpersonal relations provide vital information to interpret people’s behaviors . However, the existing research has either omitted the interaction information between subjects or the structural information in the images. In this paper, we propose a new architecture to reason interpersonal relations based on higher-order graph networks and multi-scale features. First, we extract features of the whole images, the facial features , and the union region of face pairs. Apart from the pixel-wise features, we also consider the positional features of face-to-face pairs and the spatial scene cues. Higher-order Graph Neural Networks (GNNs) were employed to map out the interpersonal relations based on the feature extracted. Experimental results show that the proposed Higher-order Graph Neural Networks with multi-scale features can effectively recognize the social relations in images with over 5\% improvement in absolute balanced accuracy compared with the state-of-the-art work.},
  archive      = {J_NEUCOM},
  author       = {Jianjun Gao and Linbo Qing and Lindong Li and Yongqiang Cheng and Yonghong Peng},
  doi          = {10.1016/j.neucom.2021.05.097},
  journal      = {Neurocomputing},
  pages        = {243-252},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale features based interpersonal relation recognition using higher-order graph neural network},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A mixture varying-gain dynamic learning network for solving
nonlinear and nonconvex constrained optimization problems.
<em>NEUCOM</em>, <em>456</em>, 232–242. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear and nonconvex optimization problem (NNOP) is a challenging problem in control theory and applications. In this paper, a novel mixture varying-gain dynamic learning network (MVG-DLN) is proposed to solve NNOP with inequality constraints . To do so, first, this NNOP is transformed into some equations through Karush–Kuhn–Tucker (KKT) conditions and projection theorem, and the neuro-dynamics function can be obtained. Second, the time varying convergence parameter is utilized to obtain a faster convergence speed. Third, an integral term is used to strengthen the robustness. Theoretical analysis proves that the proposed MVG-DLN has global convergence and good robustness. Three numerical simulation comparisons between FT-FP-CDNN and MVG-DLN substantiate the faster convergence performance and greater robustness of the MVG-DLN in solving the nonlinear and nonconvex optimization problems.},
  archive      = {J_NEUCOM},
  author       = {Rongxiu Lu and Guanhua Qiu and Zhijun Zhang and Xianzhi Deng and Hui Yang and Zhenmin Zhu and Jianyong Zhu},
  doi          = {10.1016/j.neucom.2021.05.037},
  journal      = {Neurocomputing},
  pages        = {232-242},
  shortjournal = {Neurocomputing},
  title        = {A mixture varying-gain dynamic learning network for solving nonlinear and nonconvex constrained optimization problems},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive mimic learning: A new perspective to train
lightweight CNN models. <em>NEUCOM</em>, <em>456</em>, 220–231. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) builds a lightweight Student Model (SM) and trains it to approximate a large Teacher Model (TM) by exploring knowledge learned by the TM, which shows effectiveness to train lightweight CNN models. However, training a small SM to achieve better performance remains a challenging problem. Recent researches on human learning behaviors show that both the knowledge from teachers and the knowledge learning processes of teachers are significant for students. Inspired by this characteristic, in this paper, we propose a new perspective, called Progressive Mimic Learning (PML), to train lightweight CNN models by mimicking the learning trajectory of the TM. In order to obtain a more powerful SM, the useful hints in the learning process of the TM are explored. To start with, the TM learning process is divided into multiple stages, and the last state of the TM in each stage is recorded as a landmark. The learning trajectory of the TM is composed of these landmarks. Then, a landmark loss is defined to constrain the SM to progressively mimic the learning process of the TM, by employing landmarks in the learning trajectory as a training hint of the SM. Several experiments are conducted on four benchmark data sets, CIFAR-10, CIFAR-100, Fashion-MNIST, and ImageNet-10, to investigate the performance of the PML. The results show that the PML can make SMs generate more accurate predictions than SMs trained by its counterparts.},
  archive      = {J_NEUCOM},
  author       = {Hongbin Ma and Shuyuan Yang and Dongzhu Feng and Licheng Jiao and Luping Zhang},
  doi          = {10.1016/j.neucom.2021.04.086},
  journal      = {Neurocomputing},
  pages        = {220-231},
  shortjournal = {Neurocomputing},
  title        = {Progressive mimic learning: A new perspective to train lightweight CNN models},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A coarse-to-fine capsule network for fine-grained image
categorization. <em>NEUCOM</em>, <em>456</em>, 200–219. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image categorization is challenging due to the subordinate categories within an entry-level category can only be distinguished by subtle discriminations. This necessitates localizing key (most discriminative) regions and extract domain-specific features alternately. Existing methods predominantly realize fine-grained categorization independently, while ignoring that representation learning and foreground localization can reinforce each other iteratively. Sharing the state-of-the-art performance of capsule encoding for abstract semantic representation , we formalize our pipeline as a coarse-to-fine capsule network (CTF-CapsNet). It consists of customized expert CapsNets arranged in each perception scale and region proposal networks (RPNs) between two adjacent scales. Their mutually motivated self-optimization can achieve increasingly specialized cross-utilization of object-level and component-level descriptions. The RPN zooms the areas to turn the attention to the most distinctive regions by concerning preceding informations learned by expert CapsNet for references, whilst a finer-scale model takes as feed an amplified attended patch from last scale. Overall, CTF-CapsNet is driven by three focal margin losses between label prediction and ground truth, and three regeneration losses between original input images/feature maps and reconstructed images. Experiments demonstrate that without any prior knowledge or strongly-supervised supports (e.g., bounding-box/part annotations), CTF-CapsNet can deliver competitive categorization performance among state-of-the-arts, i.e., testing accuracy achieves 89.57\%, 88.63\%, 90.51\%, and 91.53\% on our hand-crafted rice growth image set and three public benchmarks, i.e., CUB Birds, Stanford Dogs, and Stanford Cars, respectively.},
  archive      = {J_NEUCOM},
  author       = {Zhongqi Lin and Jingdun Jia and Feng Huang and Wanlin Gao},
  doi          = {10.1016/j.neucom.2021.05.032},
  journal      = {Neurocomputing},
  pages        = {200-219},
  shortjournal = {Neurocomputing},
  title        = {A coarse-to-fine capsule network for fine-grained image categorization},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain MRI super-resolution using coupled-projection residual
network. <em>NEUCOM</em>, <em>456</em>, 190–199. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic Resonance Imaging (MRI) has been widely used in clinical application and pathology research to help doctors provide better diagnoses. However, accurate diagnosis by MRI remains a great challenge, as images obtained via current MRI techniques usually have low resolutions. Improving MRI image quality and resolution has thus become a critically important task. This paper presents an innovative Coupled-Projection Residual Network (CPRN) for MRI super-resolution. CPRN consists of two complementary sub-networks: a shallow network and a deep one, which maintain content consistency while learning high frequency differences between low-resolution and high-resolution images. The shallow sub-network employs coupled-projection to better retain the MR image details, where a novel feedback mechanism is introduced to guide the reconstruction of high-resolution images. The deep sub-network learns from the residuals of the high-frequency image information, where multiple residual blocks are cascaded to magnify the MR images at the last network layer. Finally, the features from the shallow and deep sub-networks are fused for the reconstruction of high-resolution MR images. For effective feature fusion between the deep and shallow sub-networks, a step-wise connection (CPRN_S) is designed, inspired by the human cognitive process (from simple to complex). Experiments over three public MRI datasets show that our proposed CPRN achieves superior MRI super-resolution performance compared with the state-of-the-art.},
  archive      = {J_NEUCOM},
  author       = {Chun-Mei Feng and Kai Wang and Shijian Lu and Yong Xu and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.01.130},
  journal      = {Neurocomputing},
  pages        = {190-199},
  shortjournal = {Neurocomputing},
  title        = {Brain MRI super-resolution using coupled-projection residual network},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). D-MmT: A concise decoder-only multi-modal transformer for
abstractive summarization in videos. <em>NEUCOM</em>, <em>456</em>,
179–189. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-modal abstractive summarization for videos is an emerging task, aiming to integrate multi-modal and multi-source inputs (video, audio transcript) into a compressed textual summary. Although recent multi-encoder-decoder models on this task have shown promising performance, they did not explicitly model interactions of multi-source inputs. While some strategies like co-attention are utilized for modeling this interaction, considering ultra-long sequences and additional decoder in this task, the coupling of multi-modal data from multi-encoders and decoder needs complicated structure and additional parameters. In this paper, we propose a concise D ecoder-only M ulti- m odal T ransformer (D-MmT) based on the above observations. Specifically, we cut the encoder structure, and introduce an in-out shared multi-modal decoder to make the multi-source and target fully interact and couple in the shared feature space, reducing the model parameter redundancy. Also, we design a concise cascaded cross-modal interaction (CXMI) module in the multi-modal decoder that generates joint fusion representations and spontaneously establishes a fine-grained intra- and inter- association between multi-modalities. In addition, to make full use of the ultra-long sequence information, we introduce a joint in-out loss to make the input transcript also participate in backpropagation to enhance the contextual feature representation. The experimental results on the How2 dataset show that the proposed model outperforms the current state-of-the-art approach with fewer model parameters. Further analysis and visualization show the effectiveness of our proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Nayu Liu and Xian Sun and Hongfeng Yu and Wenkai Zhang and Guangluan Xu},
  doi          = {10.1016/j.neucom.2021.04.072},
  journal      = {Neurocomputing},
  pages        = {179-189},
  shortjournal = {Neurocomputing},
  title        = {D-MmT: A concise decoder-only multi-modal transformer for abstractive summarization in videos},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pyramid fully residual network for single image de-raining.
<em>NEUCOM</em>, <em>456</em>, 168–178. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rain removal from a single image is a challenging and significant task of image pre-processing. In this paper, we learn the multi-scale streaks from rainy images using feature pyramid, and to improve the effectiveness of the learning, we focus on the feature propagation re-usage and propagation in the extremely deep de-raining network. Specifically, we design a de-raining2 unit and propose a novel deep de-raining network, respectively, called Pyramid Fully Residual Unit and Network (PFR-Unit and PFR-Net). The PFR-Unit employs fully residual learning in each level of feature pyramid and the PFR-Net connects PFR-Units by a compact dense architecture. The fully residual learning encourages the feature re-usage in PFR-Unit by performing identity mapping for all available shortcuts. The compact dense connection strengthens the feature propagation between the PFR-Units and ensures the unicity of the learning space for the PFR-Units. Along with negative SSIM loss, the PFR-Net presents a good performance in single image de-raining. Comprehensive experimental results show that the PFR-Net outperforms the state-of-the-art single de-raining methods with a big margin on Rain100H, Rain100L and Rain1200 datasets.},
  archive      = {J_NEUCOM},
  author       = {Guangle Yao and Cong Wang and Yutong Wu and Yang Wang},
  doi          = {10.1016/j.neucom.2021.05.086},
  journal      = {Neurocomputing},
  pages        = {168-178},
  shortjournal = {Neurocomputing},
  title        = {Pyramid fully residual network for single image de-raining},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Adaptive neural tracking control of high-order nonlinear
systems with quantized input. <em>NEUCOM</em>, <em>456</em>, 156–167.
(<a href="https://doi.org/10.1016/j.neucom.2021.05.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, adaptive neural tracking control problem is considered for non-strict-feedback high-order nonlinear systems with quantized input signal. Compared with the logarithmic quantizer, the quantizer introduced in this paper can avoid chattering problem. The dynamic surface control (DSC) technique is introduced to solve the problem of ‘explosion of complexity’, which is appeared in the classic adaptive backstepping control of high-order nonlinear systems. The structural properties of radial basis function neural networks (RBF NNs) are used to simplify the design difficulty from the functions of whole state variables. According to the classic adaptive backstepping technique and neural network algorithm, an output tracking controller is designed, which can guarantee that all the signals of the closed-loop system are semiglobally uniformly bounded and the output of the system can track the reference signal. Finally, a numerical example is presented to verify the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Huanqing Wang and Siwen Liu and Ding Wang and Ben Niu and Ming Chen},
  doi          = {10.1016/j.neucom.2021.05.054},
  journal      = {Neurocomputing},
  pages        = {156-167},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural tracking control of high-order nonlinear systems with quantized input},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised learning for community detection in attributed
networks based on graph convolutional network. <em>NEUCOM</em>,
<em>456</em>, 147–155. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community detection has emerged during the last decade as one of the most challenging problems in network science, which has been revisited with network representation learning recently and has attracted considerable attention. Many approaches have been proposed in recent years, including the latest methods based on graph convolutional network (GCN). Here, we propose a new network representation learning method based on GCN for community detection in attributed networks without prior label information. Inspired by the message pass mechanism of GCN and the local self-organizing property of community structure, we integrate a label sampling model and GCN into an unsupervised learning framework to uncover underlying community structures by fusing topology and attribute information. The label sampling model constructs a balanced training set by structural center location and neighbor node expansion to train the GCN. The experiments on various real-world networks give a comparison view to evaluate the proposed method. The experimental results demonstrate the proposed method performs more efficiently with a comparative performance over current state-of-the-art community detection algorithms.},
  archive      = {J_NEUCOM},
  author       = {Xiaofeng Wang and Jianhua Li and Li Yang and Hongmei Mi},
  doi          = {10.1016/j.neucom.2021.05.058},
  journal      = {Neurocomputing},
  pages        = {147-155},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised learning for community detection in attributed networks based on graph convolutional network},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning word representation by jointly using neighbor and
syntactic contexts. <em>NEUCOM</em>, <em>456</em>, 136–146. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Interpretability is a significant aspect of the distributed word representation learning model. Although the most advanced pretrained models have achieved the best results till date, the interpretability of a pretrained model is difficult to explain clearly. For this reason, based on the interpretability of distributed word embeddings , this paper presents a method of learning word representation using joint context. At present, the existing distributed word representation models for learning word representations usually focus on either neighbor or syntactic context. We argue that it is necessary to simultaneously model both contexts. In particular, the point mutual information obtained by combining the two types of contexts can efficiently express the correlation between the words. We propose two alternative distribution models for learning word representations by employing the neighbor and syntactic contexts via a simple and effective joint learning framework. Furthermore, the proposed models are trained on a public corpus, and the learned representations are evaluated in word analogy, word similarity, and sentence classification tasks . The experimental results demonstrate the potential of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Chuan Tian and Wenge Rong and Shijie Zhou and Jianfei Zhang and Yuanxin Ouyang and Zhang Xiong},
  doi          = {10.1016/j.neucom.2021.03.130},
  journal      = {Neurocomputing},
  pages        = {136-146},
  shortjournal = {Neurocomputing},
  title        = {Learning word representation by jointly using neighbor and syntactic contexts},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Forgetting memristors and memristor bridge synapses with
long- and short-term memories. <em>NEUCOM</em>, <em>456</em>, 126–135.
(<a href="https://doi.org/10.1016/j.neucom.2021.05.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an ideal current source forgetting memristor model is proposed. Based on the model, three kinds of synapses with long- and short-term memory are designed: the series forgetting memristor synapse, the forgetting memristor bridge synapse written independently and the forgetting memristor bridge synapse written in batches. Combined with the forgetting property, the long- and short-term weight of the forgetting synapse can be controlled by the long- and short-term resistance of memristors. Compared the three forgetting synapses, the series forgetting memristor synapse has the lowest requirement for memristors, the forgetting memristor bridge synapse written independently is the most flexible, and the forgetting memristor bridge synapse written in batches is the most convenient. Compared with traditional synapses, forgetting synapses with long- and short-term memory have multi-weight storage. When forgetting synapses are applied to associative memory , it can be found more patterns are stored in the neural network and different patterns are recalled at different time due to the forgetting effect.},
  archive      = {J_NEUCOM},
  author       = {Ling Chen and Wenhao Zhou and Chuandong Li and Junjian Huang},
  doi          = {10.1016/j.neucom.2021.05.062},
  journal      = {Neurocomputing},
  pages        = {126-135},
  shortjournal = {Neurocomputing},
  title        = {Forgetting memristors and memristor bridge synapses with long- and short-term memories},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FIN-GAN: Face illumination normalization via retinex-based
self-supervised learning and conditional generative adversarial network.
<em>NEUCOM</em>, <em>456</em>, 109–125. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illumination normalization is one of the most challenging issues for facial analysis. To be specific, the variation of environmental illumination influences the visual quality of an image and drastically degrades the performance of face recognition, detection, landmark and other related applications. Retinex theory provides an important concept for processing illumination variation , which supposes that a face image can be decomposed into [an invariant reflectance component and a variant illumination component. Enlighten by this theory, in this paper, we put forward a novel deep learning approach which combines self-supervised learning and adversarial training for face illumination normalization (FIN-GAN). The proposed FIN-GAN framework can be implemented by two steps. Firstly, self-supervised learning is employed to decompose the original face image into the illumination component and the illumination-invariant component with Retinex constraint. Then, we employ the conditional generative adversarial network for face image reconstruction. For network optimization, we design the combined loss to ensure visual quality and preserve identity information. Experiments are performed on Extended-YaleB, CAS-PEAL, CMU-PIE and Multi-PIE datasets. Through multiple quantitative criteria, we demonstrate that the proposed FIN-GAN obtains promising performance in face illumination normalization.},
  archive      = {J_NEUCOM},
  author       = {Yaocong Hu and Mingqi Lu and Chao Xie and Xiaobo Lu},
  doi          = {10.1016/j.neucom.2021.05.063},
  journal      = {Neurocomputing},
  pages        = {109-125},
  shortjournal = {Neurocomputing},
  title        = {FIN-GAN: Face illumination normalization via retinex-based self-supervised learning and conditional generative adversarial network},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep autoencoder with sparse and graph laplacian
regularization for characterizing dynamic functional connectivity during
brain development. <em>NEUCOM</em>, <em>456</em>, 97–108. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep-layer autoencoder (DAE) provides a powerful way for medical image analysis, while it remains a daunting challenge due to the limited samples but high dimension. In this paper, a DAE with sparse and graph Laplacian regularization , termed as GSDAE , is presented to identify significant differences of dynamic functional connectivity (dFC) between child and young adult groups. The proposed model incorporates prior knowledge into sparse learning, i.e., the intrinsic structural information defined by manifold in the data. In this way, the reconstruction ability of unsupervised DAE can be improved, which facilitates the extraction of most discriminative features of dFC changing with age. Results on the fMRI data from the Philadelphia Neurodevelopmental Cohort project reveal essential differences lying in the reoccurrence patterns of dFC and in the connectivity of resting state networks with increasing age, e.g., there exist different trajectories of connectivity patterns in brain functions: those associated with complex cognitive functions generally decreased, while those associated with basic visual or motor control functions usually enhanced. In addition, the brain circuitry moves from segregation to integration during brain development.},
  archive      = {J_NEUCOM},
  author       = {Chen Qiao and Xin-Yu Hu and Li Xiao and Vince D. Calhoun and Yu-Ping Wang},
  doi          = {10.1016/j.neucom.2021.05.003},
  journal      = {Neurocomputing},
  pages        = {97-108},
  shortjournal = {Neurocomputing},
  title        = {A deep autoencoder with sparse and graph laplacian regularization for characterizing dynamic functional connectivity during brain development},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised graph representation learning via
bootstrapping. <em>NEUCOM</em>, <em>456</em>, 88–96. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) apply deep learning techniques to graph-structured data and have achieved promising performance in graph representation learning. However, existing GNNs rely heavily on labeled data or well-designed negative samples. To address these issues, we propose a new self-supervised graph representation method: deep graph bootstrapping (DGB). DGB consists of two neural networks: online and target networks, and the input of them are different augmented views of the initial graph. The online network is trained to predict the target network while the target network is updated with a slow-moving average of the online network, which means the online and target networks can learn from each other. As a result, the proposed DGB can learn graph representation without negative examples in an unsupervised manner . In addition, we summarize three kinds of augmentation methods for graph-structured data and apply them to the DGB. Experiments on the benchmark datasets show the DGB performs better than the current state-of-the-art methods and how the augmentation methods affect the performances.},
  archive      = {J_NEUCOM},
  author       = {Feihu Che and Guohua Yang and Dawei Zhang and Jianhua Tao and Tong Liu},
  doi          = {10.1016/j.neucom.2021.03.123},
  journal      = {Neurocomputing},
  pages        = {88-96},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised graph representation learning via bootstrapping},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to restore light fields under low-light imaging.
<em>NEUCOM</em>, <em>456</em>, 76–87. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Light Field (LF) images have the unique advantage of recording scenes from multiple viewpoints, which provides many applications, such as refocusing and depth estimation. However, low-light conditions can severely influence these applications. In this paper, we propose a two-stage deep learning framework for the LF restoration under low-light imaging. First, there is a multi-to-one (MTO) network, which restores each view separately by utilizing multiple auxiliary views. All the views share the same feature extractor, with an efficient spatial-channel attention mechanism to extract more informative features. A channel-attention feature fusion (CAFF) module is designed to selectively fuse more useful complementary information from the auxiliary views, with a learnable global scalar to adjust the importance of the auxiliary features. Then, the outputs of the MTO network are further enhanced by an (all-to-all) ATA network, which uses spatial and angular residual blocks to process all the views synchronously for fully encoding the spatial-angular information. Extensive experiments have been conducted to demonstrate the superior performance and robustness of our method, i.e., it can restore the luminance, spatial details and angular geometries of the LF images under various light levels effectively.},
  archive      = {J_NEUCOM},
  author       = {Shansi Zhang and Edmund Y. Lam},
  doi          = {10.1016/j.neucom.2021.05.074},
  journal      = {Neurocomputing},
  pages        = {76-87},
  shortjournal = {Neurocomputing},
  title        = {Learning to restore light fields under low-light imaging},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel neural grey system model with bayesian
regularization and its applications. <em>NEUCOM</em>, <em>456</em>,
61–75. (<a href="https://doi.org/10.1016/j.neucom.2021.05.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most machine learning models are essentially “Black-box” models, of which the performance heavily relies on large scale data sets. In this work the idea of “Grey-box” modelling is adopted in order to take most advantage of known information represented by deterministic structure, and then the neural grey system model is developed. Levenberg-Marquardt algorithm is used to train the proposed model, and the Bayesian regularization is used to tune the regularized parameter automatically. Six real world case studies are presented to show the performance of the proposed model, comparing to 6 existing machine learning models and 17 grey system models. The results show that the proposed model can significantly overperform the other models and has very good generality, illustrating its high potential in a wide variety of real world applications and the efficiency of the proposed modelling method.},
  archive      = {J_NEUCOM},
  author       = {Xin Ma and Mei Xie and Johan A.K. Suykens},
  doi          = {10.1016/j.neucom.2021.05.048},
  journal      = {Neurocomputing},
  pages        = {61-75},
  shortjournal = {Neurocomputing},
  title        = {A novel neural grey system model with bayesian regularization and its applications},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On combining acoustic and modulation spectrograms in an
attention LSTM-based system for speech intelligibility level
classification. <em>NEUCOM</em>, <em>456</em>, 49–60. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech intelligibility can be affected by multiple factors, such as noisy environments, channel distortions or physiological issues. In this work, we deal with the problem of automatic prediction of the speech intelligibility level in this latter case. Starting from our previous work, a non-intrusive system based on LSTM networks with attention mechanism designed for this task, we present two main contributions. In the first one, it is proposed the use of per-frame modulation spectrograms as input features, instead of compact representations derived from them that discard important temporal information. In the second one, two different strategies for the combination of per-frame acoustic log-mel and modulation spectrograms into the LSTM framework are explored: at decision level or late fusion and at utterance level or Weighted-Pooling (WP) fusion. The proposed models are evaluated with the UA-Speech database that contains dysarthric speech with different degrees of severity. On the one hand, results show that attentional LSTM networks are able to adequately modeling the modulation spectrograms sequences producing similar classification rates as in the case of log-mel spectrograms. On the other hand, both combination strategies, late and WP fusion, outperform the single-feature systems, suggesting that per-frame log-mel and modulation spectrograms carry complementary information for the task of speech intelligibility prediction, than can be effectively exploited by the LSTM-based architectures, being the system with the WP fusion strategy and Attention-Pooling the one that achieves best results.},
  archive      = {J_NEUCOM},
  author       = {Ascensión Gallardo-Antolín and Juan M. Montero},
  doi          = {10.1016/j.neucom.2021.05.065},
  journal      = {Neurocomputing},
  pages        = {49-60},
  shortjournal = {Neurocomputing},
  title        = {On combining acoustic and modulation spectrograms in an attention LSTM-based system for speech intelligibility level classification},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised cross-iterative clustering for unlabeled
plant disease images. <em>NEUCOM</em>, <em>456</em>, 36–48. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current annotation for plant disease images depends on manual sorting and handcrafted features by agricultural experts, which is time-consuming and labour-intensive. In this paper, we propose a self-supervised clustering framework for grouping plant disease images based on the vulnerability of Kernel K-means. The main idea is to establish a cross iterative under-clustering algorithm based on Kernel K-means to produce the pseudo-labeled training set and a chaotic cluster to be further classified by a deep learning module. In order to verify the effectiveness of our proposed framework, we conduct extensive experiments on three different plant disease datatsets with five plants and 17 plant diseases. The experimental results show the high superiority of our method to do image-based plant disease classification over balanced and unbalanced datasets by comparing with five state-of-the-art existing works in terms of different metrics.},
  archive      = {J_NEUCOM},
  author       = {Uno Fang and Jianxin Li and Xuequan Lu and Longxiang Gao and Mumtaz Ali and Yong Xiang},
  doi          = {10.1016/j.neucom.2021.05.066},
  journal      = {Neurocomputing},
  pages        = {36-48},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised cross-iterative clustering for unlabeled plant disease images},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic analysis of disease progression in alzheimer’s
disease under the influence of hybrid synapse and spatially correlated
noise. <em>NEUCOM</em>, <em>456</em>, 23–35. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD), characterized by cognitive impairment , mainly affects middle-aged and elderly people. As the aging process of the world continues to intensify, AD harms people’s life, economy and society more and more seriously. Therefore, it has become an urgent problem to study the pathogenesis of AD and seek treatment on this basis. Hybrid synapse, autapse and spatial correlated noise in diverse neural activities have been investigated separately, however, theoretically understanding combination of them still has not been fully studied. Here in this paper, a neural network with multiple associative memory abilities is established from the perspective of the degeneration of associative memory ability in AD patients under the conditions of hybrid synapse, autapse and spatial correlated noise . In order to explore the pathogenesis, a synaptic loss and synaptic compensation model are established to analyze the associative memory ability of AD in different degrees of disease. The simulation results demonstrate the effectiveness of the proposed models and pave a way in the study of dynamic mechanism with higher bio-interpretability in neural networks.},
  archive      = {J_NEUCOM},
  author       = {Weiping Wang and Chang He and Zhen Wang and Jun Cheng and Xishuo Mo and Kuo Tian and Denggui Fan and Xiong Luo and Manman Yuan and Jürgen Kurths},
  doi          = {10.1016/j.neucom.2021.05.067},
  journal      = {Neurocomputing},
  pages        = {23-35},
  shortjournal = {Neurocomputing},
  title        = {Dynamic analysis of disease progression in alzheimer’s disease under the influence of hybrid synapse and spatially correlated noise},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relation-based multi-type aware knowledge graph embedding.
<em>NEUCOM</em>, <em>456</em>, 11–22. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph (KG) embedding projects the graph into a low-dimensional space and preserves the graph information . An essential part of a KG is the ontology, which always is organized as a taxonomy tree, depicting the type (or multiple types) of each entity and the hierarchical relationships among these types. The importance of considering the ontology during KG embedding lies in its ability to provide side-information, improving the downstream applications’ accuracy (e.g., link prediction, entity alignment or recommendation). However, the ontology has yet to receive adequate attention during the KG embedding, especially for instances where each entity may belong to multiple types. This ontology-enhanced KG embedding’s main challenges are twofold: determining how to discover the relationships among these types and how to integrate them with the entities’ relationship network. Although it is common to see attention-based models used in KG embedding, they cannot settle the issues raised simultaneously. Only a single type is assigned to each entity and the correlation among types are ignored in those models, leading to information loss and encumbered downstream tasks. To overcome these challenges, we propose a composite multi-type aware KG embedding model, whose main components are a multi-type layer and entity embedding layer. We model it as a natural language processing task at the multi-type layer to discover each entity’s multi-type feature and automatically capture their correlations. Additionally, a relation-based attention mechanism is conducted at the entity embedding layer, which aggregates neighborhoods’ information and integrates the multi-type layer’s information through common entities of these two layers. Through extensive experiments on two real KGs, we demonstrate that, compared to several state-of-the-art baselines, our Multi-Type aware Embedding (MTE) model achieves substantial gain in both Mean Rank and Hit@N for the link prediction task and accuracy for multi-type classification.},
  archive      = {J_NEUCOM},
  author       = {Yingying Xue and Jiahui Jin and Aibo Song and Yingxue Zhang and Yangyang Liu and Kaixuan Wang},
  doi          = {10.1016/j.neucom.2021.05.021},
  journal      = {Neurocomputing},
  pages        = {11-22},
  shortjournal = {Neurocomputing},
  title        = {Relation-based multi-type aware knowledge graph embedding},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Collaboration of multiple SCARA robots with guaranteed
safety using recurrent neural networks. <em>NEUCOM</em>, <em>456</em>,
1–10. (<a href="https://doi.org/10.1016/j.neucom.2021.05.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {SCARA robot is one of the most popularly used robots in industry. The obstacle avoidance feature of multiple SCARA robot collaboration is essential and prominent, which can be used to support multiple robots to accomplish not only more sophisticated tasks but also more efficient than individual robot. This paper mainly focuses on studying the problem of simultaneous multi-robot coordination and obstacle avoidance. A cooperative kinematic control problem of multiple robot manipulators, collision avoidance is taken into account to be the primary task as an inequality constraint and trajectory planning task is considered to be the secondary objective as to ensure the priority of safety, is described as a quadratic programming (QP) problem. Then, a recurrent neural network (RNN) based dynamic controller is designed to solve the formulated QP problem recursively. The convergence of the designed neural network is proved through Lyapunov analysis. With three SCARA planar robots, the effectiveness of the proposed controller is validated through numerical simulations. As observed in the results, when the minimal distance between robots is less than the setting safety distance, the collision avoidance strategy reacts to impel robots to avoid collision, which achieves the primary objective for obstacle avoidance; otherwise, the robot performs the desired trajectory tracking task.},
  archive      = {J_NEUCOM},
  author       = {Yuhong He and Xiaoxiao Li and Zhihao Xu and Xuefeng Zhou and Shuai Li},
  doi          = {10.1016/j.neucom.2021.05.049},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Collaboration of multiple SCARA robots with guaranteed safety using recurrent neural networks},
  volume       = {456},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Single-shot weakly-supervised object detection guided by
empirical saliency model. <em>NEUCOM</em>, <em>455</em>, 431–440. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Even though weakly-supervised object detection (WSOD) has become an effective method to relieve the heavy work of labeling, there are still difficult problems to be solved. WSOD method represented by a Multiple Instance Learning (MIL) have some common problems including running slowly and focusing on discriminative parts rather than the whole object, which will lead to false detection. To improve the efficiency and accuracy, we propose a single-shot weakly-supervised object detection model guided by empirical saliency model (SSWOD). As human vision always focuses on the most attracting parts of the image, saliency maps can usually guide our model to locate the most promising object areas. By this way, our model takes the saliency areas as pseudo ground-truths to realize the WSOD task with only class labels. Moreover, empirical saliency is designed to refine the pseudo ground-truth and improve the detection. Our new framework not only realizes a one-step detection without region proposals, but also reduces computational consumption. Experiments on PASCAL VOC 2007 &amp; 2012 benchmarks demonstrate that SSWOD is 8 times faster and 5 times smaller than previous approaches, surpassing the state-of-the-art WSOD methods by 6.1\% mean average precision (mAP).},
  archive      = {J_NEUCOM},
  author       = {Danpei Zhao and Zhichao Yuan and Zhenwei Shi and Fengying Xie},
  doi          = {10.1016/j.neucom.2021.03.047},
  journal      = {Neurocomputing},
  pages        = {431-440},
  shortjournal = {Neurocomputing},
  title        = {Single-shot weakly-supervised object detection guided by empirical saliency model},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DDQN-TS: A novel bi-objective intelligent scheduling
algorithm in the cloud environment. <em>NEUCOM</em>, <em>455</em>,
419–430. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Task scheduling has always been one of the crucial problem in cloud computing . With the transition of task types from static batch processing to dynamic stream processing, the dynamic online task scheduling problem has attracted widespread attention. At this stage, explore an effective task scheduling method to implement high quality of service (QoS) requests with limited resources is a considerable challenge. This paper proposes a novel scheduling algorithm called double deep Q-network task scheduling (DDQN-TS), which uses the adaptive learning ability of double deep Q-network (DDQN) to explore the optimal task scheduling strategy. Experiments conducted using the Random, Google, and Alibaba benchmarks to compare several classic algorithms show that the proposed DDQN-TS can guarantee a high task completion rate and efficiently reduce the task average response time.},
  archive      = {J_NEUCOM},
  author       = {Zhao Tong and Feng Ye and Bilan Liu and Jinhui Cai and Jing Mei},
  doi          = {10.1016/j.neucom.2021.05.070},
  journal      = {Neurocomputing},
  pages        = {419-430},
  shortjournal = {Neurocomputing},
  title        = {DDQN-TS: A novel bi-objective intelligent scheduling algorithm in the cloud environment},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast hierarchical clustering of local density peaks via an
association degree transfer method. <em>NEUCOM</em>, <em>455</em>,
401–418. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Density Peak clustering (DPC) as a novel algorithm can fast identify density peaks. But it comes along with two drawbacks: its allocation strategy may produce some non-adjacent associations that may lead to poor clustering results and even cause the malfunction of its cluster center selection method to mistakenly identify cluster centers; it may perform poorly with its high complex O ( n 2 ) O(n2) when comes to large-scale data. Herein, a fast hierarchical clustering of local density peaks via an association degree transfer method (FHC-LDP) is proposed. To avoid DPC’s drawbacks caused by non-adjacent associations, FHC-LDP only considers the association between neighbors and design an association degree transfer method to evaluate the association between points that are not neighbors. FHC-LDP can fast identify local density peaks as sub-cluster centers to generate sub-clusters automatically and evaluate the similarity between sub-clusters. Then, by analyzing the similarity of sub-cluster centers, a hierarchical structure of sub-clusters is built. FHC-LDP replaces DPC’s cluster center selection method with a bottom-up hierarchical approach to ensure sub-clusters in each cluster are most similar. In FHC-LDP, only neighbor information of data is required, so by using a fast KNN algorithm, FHC-LDP can run about O ( nlog ( n ) ) O(nlog(n)) . Experimental results demonstrate FHC-LDP is remarkably superior to traditional clustering algorithms and other variants of DPC in recognizing cluster structure and running speed.},
  archive      = {J_NEUCOM},
  author       = {Junyi Guan and Sheng Li and Xiongxiong He and Jinhui Zhu and Jiajia Chen},
  doi          = {10.1016/j.neucom.2021.05.071},
  journal      = {Neurocomputing},
  pages        = {401-418},
  shortjournal = {Neurocomputing},
  title        = {Fast hierarchical clustering of local density peaks via an association degree transfer method},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards improving classification power for one-shot object
detection. <em>NEUCOM</em>, <em>455</em>, 390–400. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection based on deep learning typically relies on a large number of training data, which may be very labor-consuming to prepare. In this paper, we attempt to tackle the problem by addressing the One-Shot Object Detection (OSOD) task. Given a novel image denoted as the query image whose category label is not included in the training data, OSOD aims to detect objects of the same class in a complex scene denoted as the target image. The performance of recent OSOD methods is much weaker than general object detection. We find that one of the reasons behind this limited performance is that more false positives (i.e., false detections) are generated. Therefore, we argue that it is important to reduce the number of false positives generated in OSOD task to improve performance. To this end, we present a Focus On Classification One-Shot Object Detection (FOC OSOD) network. Specifically, we design the network from two perspectives: (1) how to obtain the effective similarity feature between the query image and target image; (2) how to classify the similarity feature effectively. To solve the above two challenges, firstly, we propose a Classification Feature Deformation-and-Attention (CFDA) module to obtain the high-quality query feature and target feature, so we can further generate effective similarity feature between them. Secondly, we present a Split Iterative Head (SIH) to improve the ability to classify the similarity feature. Extensive experiments on two public datasets (i.e., PASCAL VOC and COCO) demonstrate that the proposed framework achieves superior performance which outperforms other state-of-the-art methods with a considerable margin.},
  archive      = {J_NEUCOM},
  author       = {Hanqing Yang and Yongliang Lin and Hong Zhang and Yu Zhang and Bin Xu},
  doi          = {10.1016/j.neucom.2021.04.116},
  journal      = {Neurocomputing},
  pages        = {390-400},
  shortjournal = {Neurocomputing},
  title        = {Towards improving classification power for one-shot object detection},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Passivity of fractional-order coupled neural networks with
multiple state/derivative couplings. <em>NEUCOM</em>, <em>455</em>,
379–389. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper respectively discusses the passivity of fractional-order coupled neural networks with multiple state couplings (FOCNNMSCs) or multiple derivative couplings (FOCNNMDCs). In light of fractional-order system theory, several sufficient conditions for ensuring the passivity of the FOCNNMSCs are established. Moreover, a synchronization criterion for the FOCNNMSCs is obtained under the condition that the FOCNNMSCs is output-strictly passive. Similarly, we also investigate the passivity of the FOCNNMDCs by resorting to the Lyapunov functional method, and the output-strict passivity is used to deal with the synchronization for the FOCNNMDCs. Finally, the effectiveness of the obtained criteria is verified by two numerical examples with simulations.},
  archive      = {J_NEUCOM},
  author       = {Chen-Guang Liu and Jin-Liang Wang},
  doi          = {10.1016/j.neucom.2021.05.050},
  journal      = {Neurocomputing},
  pages        = {379-389},
  shortjournal = {Neurocomputing},
  title        = {Passivity of fractional-order coupled neural networks with multiple state/derivative couplings},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural network learning of improved compressive sensing
sampling and receptive field structure. <em>NEUCOM</em>, <em>455</em>,
368–378. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While the theory of compressive sensing (CS) in modern signal processing typically indicates that uniformly random sampling facilitates the efficient recovery of sparse signals, such measurements are infeasible in many engineering applications and are not well reflected by the constraints of natural systems, including neuronal networks in the brain. Uniformly random sampling also does not leverage the underlying structure of many classes of signals, and may therefore be suboptimal in these cases. We address these issues by formulating a novel neural network framework for learning improved CS sampling based on the intrinsic structure present in classes of training signals. Beyond sparsity in an appropriate domain, this approach does not assume knowledge of any specific signal statistics and is purely data-driven. The learning methodology is biologically realistic in that it utilizes (1) asymmetric feedback and feedforward connections in the neural network and (2) only information from adjacent layers in training the CS measurement matrix . Observing a broad spectrum of learned sampling paradigms that improve CS signal reconstructions relative to uniformly random sampling, our learned sampling is widely applicable across logistical constraints. Motivated by the receptive field structure of sensory systems, we specifically analyze natural scene inputs and demonstrate improved CS reconstruction as a result of training across several choices of penalization schemes on the sampling weights. Considering this learning is effective even under sparse and spatially localized constraints, as commonly observed in the brain, we hypothesize that neuronal connectivity may have manifested with the aim of providing a compressive encoding of data by leveraging its sparse structure, thereby achieving efficient signal transmission.},
  archive      = {J_NEUCOM},
  author       = {Victor J. Barranca},
  doi          = {10.1016/j.neucom.2021.05.061},
  journal      = {Neurocomputing},
  pages        = {368-378},
  shortjournal = {Neurocomputing},
  title        = {Neural network learning of improved compressive sensing sampling and receptive field structure},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GSEN: An ensemble deep learning benchmark model for urban
hotspots spatiotemporal prediction. <em>NEUCOM</em>, <em>455</em>,
353–367. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Urban hotspots spatiotemporal prediction is a long-term but challenging task for urban management and smart city construction. Accurate urban hotspots spatiotemporal prediction can improve urban planning, scheduling and, security capability, reduce resource consumption. Existing deep spatiotemporal prediction methods mainly utilize geographic grid based image, some given network structure or some additional data to capture spatiotemporal dynamic. However, we observed that mining some latent self-semantics from raw data and fusing them with geospatial based grid images can also improve the performance of spatiotemporal predictions. In this paper, we propose Geographic-Semantic Ensemble Neural Network (GSEN), a novel deep learning approach to stack geographical prediction neural network and semantical prediction neutral network. GSEN model integrates the structures of Predictive Recurrent Neural Network (PredRNN), Graph Convolutional Predictive Recurrent Neural Network (GC-PredRNN), and Ensemble Layer to capture spatiotemporal dynamics from different views. And this model can also be correlated with some latent high-level dynamics in the real-world without any external data. We evaluate our proposed model on three different domains real-world datasets and the experimental studies demonstrate the generalization and effectiveness of GSEN in different urban hotspots spatiotemporal prediction tasks.},
  archive      = {J_NEUCOM},
  author       = {Guangyin Jin and Hengyu Sha and Yanghe Feng and Qing Cheng and Jincai Huang},
  doi          = {10.1016/j.neucom.2021.05.008},
  journal      = {Neurocomputing},
  pages        = {353-367},
  shortjournal = {Neurocomputing},
  title        = {GSEN: An ensemble deep learning benchmark model for urban hotspots spatiotemporal prediction},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperspectral image restoration via superpixel segmentation
of smooth band. <em>NEUCOM</em>, <em>455</em>, 340–352. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral images (HSIs) are inevitably degraded in the acquisition process by mixed noise including Gaussian noise, impulse noise, stripes, and so on. Recently, many low-rank regularization based HSI restoration methods have been proposed to powerfully remove the mixed noise. However, most of them use the square patch based denoising strategy, which destroyed the boundary information of the objects in the HSI. In this paper, we adopt superpixel segmentation to group the pixels of HSI with adjacent position, similar color, texture and luminance into a homogeneous region, whose shape is adaptive. Several homogeneous regions cover the full HSI. This is better than simply dividing the HSI into square patches. By taking advantage of both the low-rank property and the spectral smooth of the HSI, this approach can efficiently remove the mixed noise with few time. Several experiments verify the performance of the proposed approach for HSI restoration.},
  archive      = {J_NEUCOM},
  author       = {Ya-Ru Fan and Ting-Zhu Huang},
  doi          = {10.1016/j.neucom.2021.05.075},
  journal      = {Neurocomputing},
  pages        = {340-352},
  shortjournal = {Neurocomputing},
  title        = {Hyperspectral image restoration via superpixel segmentation of smooth band},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised video object segmentation using
integration-augmented attention. <em>NEUCOM</em>, <em>455</em>, 325–339.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While supervised learning approaches show great vitality and effectiveness in video object segmentation, most of them require large amounts of annotations which are expensive and time-consuming. Recently, self-supervised learning has attracted great attention by benefiting from unlabeled video sequences. However, current patch-based self-supervised video object segmentation methods only discriminate the patch from the entire image without distinguishing the object of interest from meaningless backgrounds or even occlusion. These disturbances deteriorate the extracted features and hinder the robustness of tracking when applied to real-world video sequences. In this paper, we propose a novel model named Tracker With Integration-Augmented Attention (TWIAA) to achieve both label-free and prominent performance. Specifically, we integrate both spatial and channel dimensions by introducing a feature spatial enhancement module and a two-stream channel module. With the combination of the two modules, the network can focus on exploring the discriminative object and suppressing the irrelevant part to improve the tracking robustness. Moreover, unlike other methods that calculate features separately on the search branch and template branch, the two designed modules coupled with the Siamese network compute the respective features of the search branch and the template branch jointly to augment the interdependence of the two branches. Such interdependence is injected into both spatial and channel dimensions. So that our approach establishes richer and more discriminative associations to identify the object more accurately. In addition, our method takes full advantage of cycle-consistency information in consecutive frames, which uses coherence as the learning signal to acquire object-oriented relationships. Extensive experiments and ablation studies are conducted on large VOS benchmarks, including DAVIS-2017, YouTube-VOS-2018, and YouTube-VOS-2019. The results verify that our proposed framework has both strong feature representation and competitive performance compared with supervised and self-supervised models.},
  archive      = {J_NEUCOM},
  author       = {Wenjun Zhu and Jun Meng and Li Xu},
  doi          = {10.1016/j.neucom.2021.04.090},
  journal      = {Neurocomputing},
  pages        = {325-339},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised video object segmentation using integration-augmented attention},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep cascading network architecture for robust automatic
modulation classification. <em>NEUCOM</em>, <em>455</em>, 308–324. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BACKGROUND : Automatic modulation classification (AMC) plays a crucial role in cognitive radio, such as industrial automation, transmitter identification, and spectrum resource allocation. Recently, deep learning (DL) as a new machine learning (ML) methodology has achieved considerable implementation in AMC missions. However, few studies have examined the robustness of DL models under varying signal-to-noise ratio (SNR) environments. OBJECTIVE : The primary objective of this paper is to design a robust DL-based AMC model to adapt to noise changes. METHODS : The AMC task is divided into two sub-problems: SNR environment perception and modulation classification in sub-environments. A deep cascading network architecture (DCNA) is proposed to solve these two problems. DCNA is composed of an SNR estimator network (SEN) and a modulation recognition cluster network (MRCN). SEN is designed to identify the SNR levels of samples, and MRCN is composed of several subnetworks for further modulation recognition under diverse SNR settings. In addition, a label-smoothing method is proposed to promote the integration between SEN and MRCN. An auxiliary data-segmenting method is also presented to deal with the contrasting data requirements of DCNA. Note that DCNA does not utilize a specific network structure and can be generalized to various deep learning models with advanced improvements. RESULTS : Experimental results on dataset RML2016.10b show that our proposed DCNA can enhance the recognition performance of different network structures on AMC tasks. In particular, a combination of DCNA and convolutional long short-term deep neural network (CLDNN) can achieve a classification accuracy of 91.0\%\% , outperforming the previous research. CONCLUSION : The performance of the cascading network demonstrates the significant performance advantage and application feasibility of DCNA.},
  archive      = {J_NEUCOM},
  author       = {Lintianran Weng and Yuan He and Jianhua Peng and Jianchao Zheng and Xinyu Li},
  doi          = {10.1016/j.neucom.2021.05.010},
  journal      = {Neurocomputing},
  pages        = {308-324},
  shortjournal = {Neurocomputing},
  title        = {Deep cascading network architecture for robust automatic modulation classification},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered h∞ state estimation for discrete-time
delayed switched stochastic neural networks with persistent dwell-time
switching regularities and sensor saturations. <em>NEUCOM</em>,
<em>455</em>, 297–307. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the H∞ state estimation problem is considered for a class of the discrete-time delayed switched stochastic neural networks with sensor saturations. In order to improve the resource utilization efficiency, an event-triggered H∞ state estimator is designed to regulate the transmission of the measurement outputs. The persistent dwell-time switching strategy is adopted in this paper which is more general and less conservative. By utilizing a proper Lyapunov–Krasovskii functional, some criteria are presented to ensure the exponential mean square stability of the estimation error system and the prespecified H∞ level of disturbance attenuation. Finally, a numerical example is given to illustrate the effectiveness of our results.},
  archive      = {J_NEUCOM},
  author       = {Jinghui Suo and Nan Li and Qi Li},
  doi          = {10.1016/j.neucom.2021.01.131},
  journal      = {Neurocomputing},
  pages        = {297-307},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered h∞ state estimation for discrete-time delayed switched stochastic neural networks with persistent dwell-time switching regularities and sensor saturations},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). CARM: Confidence-aware recommender model via review
representation learning and historical rating behavior in the online
platforms. <em>NEUCOM</em>, <em>455</em>, 283–296. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recommendation systems in the online platforms often suffer from the rating data sparseness and information overload issues. Previous studies on this topic often leverage review information to construct an accurate user/item latent factor. To address this issue, we propose a novel confidence-aware recommender model via review representation learning and historical rating behavior in this article. It is motived that ratings are consistent with reviews in terms of user preferences, and reviews often contain misleading comments (e.g., fake good reviews, fake bad reviews). To this end, the interaction latent factor of user and item in the framework is constructed by exploiting review information interactivity. Then, the confidence matrix, which measures the relationship between the rating outliers and misleading reviews, is employed to further improve the model accuracy and reduce the impact of misleading reviews on the model. Furthermore, the loss function is constructed by maximum a posteriori estimation theory. Finally, the mini-batch gradient descent algorithm is introduced to optimize the loss function. Experiments conducted on four real-world datasets empirically demonstrate that our proposed method outperforms the state-of-the-art methods. The proposed method also further promotes the application in learning resource adaptation. The source Python code will be available upon request.},
  archive      = {J_NEUCOM},
  author       = {Duantengchuan Li and Hai Liu and Zhaoli Zhang and Ke Lin and Shuai Fang and Zhifei Li and Neal N. Xiong},
  doi          = {10.1016/j.neucom.2021.03.122},
  journal      = {Neurocomputing},
  pages        = {283-296},
  shortjournal = {Neurocomputing},
  title        = {CARM: Confidence-aware recommender model via review representation learning and historical rating behavior in the online platforms},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep node clustering based on mutual information
maximization. <em>NEUCOM</em>, <em>455</em>, 274–282. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational Graph Autoencoders (VGAs) are generative models for unsupervised learning of node representations within graph data. While VGAs have been achieved state-of-the-art results for different predictive tasks on graph-structured data, they are susceptible to the over-pruning problem where only a small subset of the stochastic latent units are active. This can limit their modeling capacity and their ability to learn meaningful representations. In this paper, we present SOLI (Stacked auto-encoder for nOde cLusterIng), an information maximization approach for learning graph representations by leveraging maximal cliques . SOLI relies on aggregating useful representations by assigning clique-based weights to various edges in a neighborhood while maximizing mutual information. The learned representations are mindful of graph patches centered around each node, and can be used for a range of downstream tasks, and thus encouraging more active units. We demonstrate strong performance across three graph benchmark datasets.(Code is available at https://github.com/SoheilaMolaei/SOLI.)},
  archive      = {J_NEUCOM},
  author       = {Soheila Molaei and Nima Ghanbari Bousejin and Hadi Zare and Mahdi Jalili},
  doi          = {10.1016/j.neucom.2021.03.020},
  journal      = {Neurocomputing},
  pages        = {274-282},
  shortjournal = {Neurocomputing},
  title        = {Deep node clustering based on mutual information maximization},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bidirectional gated temporal convolution with attention for
text classification. <em>NEUCOM</em>, <em>455</em>, 265–273. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In text classification models based on deep learning , feature extraction and feature aggregation are two key steps. As one of the basic feature extraction methods, CNN has certain limitations due to its inability to effectively extract temporal features from text data. Using max-pooling can significantly reduce the amount of calculation while performing feature aggregation, but it will have an adverse effect on the classification results due to the loss of some text features. In this paper, in response to the above two issues, a Bidirectional Gated Temporal Convolutional Attention(BG-TCA) model is proposed. In the feature extraction stage, the BG-TCA model uses the bidirectional TCN to extract the bidirectional temporal features in text data, and a gating mechanism similar to the LSTM is added between the convolution layers . In the feature aggregation stage, the BG-TCA model uses the attention mechanism to replace the max-pooling method, which makes it possible to distinguish the importance of different features while retaining the text features to the maximum. Finally, experimental results on five benchmark datasets show that the classification accuracy of the BG-TCA model has been greatly improved compared to basic models, and is better than several other state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Jiansi Ren and Wei Wu and Gang Liu and Zhe Chen and Ruoxiang Wang},
  doi          = {10.1016/j.neucom.2021.05.072},
  journal      = {Neurocomputing},
  pages        = {265-273},
  shortjournal = {Neurocomputing},
  title        = {Bidirectional gated temporal convolution with attention for text classification},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Equidistant distribution loss for person re-identification.
<em>NEUCOM</em>, <em>455</em>, 255–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-id) is a technology that matches images of a certain pedestrian among non-overlapping cameras. Recently, many approaches based on deep learning have been studied comprehensively. Most of these methods try to learn discriminative pedestrian features via elaborated network architectures and one or multi loss functions to maximize inter-class separability and intra-class compactness. However, the class imbalance characteristics from the datasets are ignored, and the discriminative information cannot be completely exploited. In this paper, we propose a novel loss function termed as Equidistant Distribution Loss (EDL) to improve the imbalance problem that exists in re-id tasks. Specifically, we first normalize the learned features in the embedding layer and the weights in the last fully connected layer, so that both the features and the weights can be projected on a hypersphere space. After that, we directly impose an equidistance constraint among the weights to guide the learned features spread uniformly in the sphere space. The proposed EDL can effectively address the local squeeze or imbalance problem caused by imbalanced samples, making full use of feature space and profiting the performance. Extensive experiments on re-id datasets, including Market-1501, DukeMTMC-reID are conducted to demonstrate the preferable performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhao Yang and Jiehao Liu and Tie Liu and Yuanxin Zhu and Li Wang and Dapeng Tao},
  doi          = {10.1016/j.neucom.2021.04.070},
  journal      = {Neurocomputing},
  pages        = {255-264},
  shortjournal = {Neurocomputing},
  title        = {Equidistant distribution loss for person re-identification},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised brain tumor segmentation using a
symmetric-driven adversarial network. <em>NEUCOM</em>, <em>455</em>,
242–254. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The aim of this study was to computationally model, in an unsupervised manner , a manifold of symmetry variations in normal brains, such that the learned manifold can be used to segment brain tumors from magnetic resonance (MR) images that fail to exhibit symmetry. An unsupervised brain tumor segmentation method , named as symmetric driven generative adversarial network (SD-GAN), was proposed. SD-GAN model was trained to learn a non-linear mapping between the left and right brain images, and thus being able to present the variability of the (symmetry) normal brains. The trained SD-GAN was then used to reconstruct normal brains and to segment brain tumors based on higher reconstruction errors arising from their being unsymmetrical. SD-GAN was evaluated on two public benchmark datasets (Multi-modal Brain Tumor Image Segmentation (BRATS) 2012 and 2018). SD-GAN provided best performance with tumor segmentation accuracy superior to the state-of-the-art unsupervised segmentation methods and performed comparably (&lt;3\% lower in Dice score) to the supervised U-Net (the most widely used supervised method for medical images). This study demonstrated that symmetric features presenting variations (i.e., inherent anatomical variations) can be modelled using unannotated normal MR images and thus be used in segmenting tumors.},
  archive      = {J_NEUCOM},
  author       = {Xinheng Wu and Lei Bi and Michael Fulham and David Dagan Feng and Luping Zhou and Jinman Kim},
  doi          = {10.1016/j.neucom.2021.05.073},
  journal      = {Neurocomputing},
  pages        = {242-254},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised brain tumor segmentation using a symmetric-driven adversarial network},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A learning-based view extrapolation method for axial
super-resolution. <em>NEUCOM</em>, <em>455</em>, 229–241. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Axial light field resolution refers to the ability to distinguish features at different depths by refocusing. The axial refocusing precision corresponds to the minimum distance in the axial direction between two distinguishable refocusing planes. High refocusing precision can be essential for some light field applications like microscopy. In this paper, we propose a learning-based method to extrapolate novel views from axial volumes of sheared epipolar plane images (EPIs). As extended numerical aperture (NA) in classical imaging, the extrapolated light field gives re-focused images with a shallower depth of field (DOF), leading to more accurate refocusing results. Most importantly, the proposed approach does not need accurate depth estimation. Experimental results with both synthetic and real light fields show that the method not only works well for light fields with small baselines as those captured by plenoptic cameras (especially for the plenoptic 1.0 cameras), but also applies to light fields with larger baselines.},
  archive      = {J_NEUCOM},
  author       = {Zhaolin Xiao and Jinglei Shi and Xiaoran Jiang and Christine Guillemot},
  doi          = {10.1016/j.neucom.2021.05.056},
  journal      = {Neurocomputing},
  pages        = {229-241},
  shortjournal = {Neurocomputing},
  title        = {A learning-based view extrapolation method for axial super-resolution},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Atom-substituted tensor dictionary learning enhanced
convolutional neural network for hyperspectral image classification.
<em>NEUCOM</em>, <em>455</em>, 215–228. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel sparse tensor dictionary learning algorithm and a convolutional neural network (CNN) classification method based on this algorithm are proposed for hyperspectral image (HSI) in this paper. The HSI is intuitively represented as a three-dimensional (3-D) cube, and utilizing the joint spatial-spectral information can significantly improve the accuracy of HSI classification. Therefore, the proposed atom-substituted tensor dictionary learning (ASTDL) algorithm utilizes tensor techniques to extract 3-D joint spatial-spectral features from HSI cubes directly. Sparsity constraint is enforced on the coefficient tensors, which obeys the sparsity attribute of HSI. The proposed ASTDL enhanced CNN (ASTDL-CNN) classification method utilizes a two-dimensional (2-D) CNN to extract deep features from the feature tensors obtained by the ASTDL, and to perform the pixel-wise classification. The use of ASTDL, which extracts intrinsic tensor features before CNN, alleviates within-class spatial-spectral variation and reduces the requirement of CNN for the labeled data. Whereas, the CNN works as a 3-D classifier, and provides the final classification results . Besides, we perform the majority vote on the classification map obtained by CNN to refine the classification. The performance of the proposed method is evaluated on three real HSI data sets. The competitive results to the compared state-of-the-art methods demonstrate that the ASTDL-CNN can provide accurate and robust classification results .},
  archive      = {J_NEUCOM},
  author       = {Fengshuang Liu and Jiachen Ma and Qiang Wang},
  doi          = {10.1016/j.neucom.2021.05.051},
  journal      = {Neurocomputing},
  pages        = {215-228},
  shortjournal = {Neurocomputing},
  title        = {Atom-substituted tensor dictionary learning enhanced convolutional neural network for hyperspectral image classification},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast constrained state transition algorithm.
<em>NEUCOM</em>, <em>455</em>, 202–214. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When solving constrained optimization problems in real industrial processes, both optimality and computational efficiency need to be considered. However, most existing meta-heuristic algorithms are slow to find the global optimum. The first reason is that the way to generate and select candidate solutions is time-consuming. The low probability to generate and select potential solutions in assisting the computational efficiency is another reason. In this paper, a simplified state transition algorithm (STA) and a novel constraint-handling technique are proposed to address the above issues for small size constrained optimization problems. Firstly, three out of four operators in basic STA to produce candidate solutions are selected and two operators are modified with adaptive parameter tuning, which have a large probability to generate potential solutions, but consumes less time. Secondly, the constraint-handling technique considers not only the objective function value and the constraint violation but also the difference among candidate solutions. Thirdly, the sequential quadratic programming embedded into the simplified STA can further speed up the convergence. Experiments are conducted on 22 well-known test functions from IEEE CEC2006 and 4 engineering constrained optimization problems, in comparison with state-of-the-art algorithms. The experimental results show that the proposed method is competitive in finding the optimum faster.},
  archive      = {J_NEUCOM},
  author       = {Xiaojun Zhou and Jituo Tian and Jianpeng Long and Yaochu Jin and Guo Yu and Chunhua Yang},
  doi          = {10.1016/j.neucom.2021.05.053},
  journal      = {Neurocomputing},
  pages        = {202-214},
  shortjournal = {Neurocomputing},
  title        = {A fast constrained state transition algorithm},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Multistability of hopfield neural networks with a designed
discontinuous sawtooth-type activation function. <em>NEUCOM</em>,
<em>455</em>, 189–201. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a class of discontinuous sawtooth-type activation function is designed and the multistability of Hopfield neural networks (HNNs) with such kind of activation function is studied. By virtue of the Brouwer’s fixed point theorem and the property of strictly diagonally dominant matrix (SDDM), some sufficient conditions are presented to ensure that the n n -neuron HNN can have at least 7 n 7n equilibria, among which 4 n 4n equilibria are locally exponentially stable and the remaining 7 n - 4 n 7n-4n equilibria are unstable. Then, the obtained results are extended to a more general case. We continue to increase the number of the peaks of the sawtooth-type activation function and we find that the n n -neuron HNN can have ( 2 k + 3 ) n (2k+3)n equilibria, ( k + 2 ) n (k+2)n of them are locally exponentially stable and the remaining equilibria are unstable. Therein, k k denotes the total number of the peaks in the designed activation function. That is to say, there is a quantitative relationship between the number of the peaks and the number of the equilibria. It implies that one can improve the storage capacity of a HNN by increasing the number of the peaks of the activation function in theory and in practice. To some extent, this method is convenient and flexible. Compared with the existing results, HNN with the designed sawtooth-type activation function can have more total equilibria as well as more locally stable equilibria. Finally, two examples are presented to demonstrate the validity of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Yang Liu and Xia Huang and Yuxia Li and Hao Shen},
  doi          = {10.1016/j.neucom.2021.05.045},
  journal      = {Neurocomputing},
  pages        = {189-201},
  shortjournal = {Neurocomputing},
  title        = {Multistability of hopfield neural networks with a designed discontinuous sawtooth-type activation function},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). End-to-end aspect-based sentiment analysis with hierarchical
multi-task learning. <em>NEUCOM</em>, <em>455</em>, 178–188. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {End-to-end aspect-based sentiment analysis (E2E-ABSA) is a sequence labeling task which detects aspect terms and the corresponding sentiment simultaneously. Previous works ignore the useful task-specific knowledge and embed the vital aspect and sentiment attributes implicitly in the intermediate layers. In this paper, we propose a hierarchical multi-task learning framework, which explicitly leverages task-related knowledge via the supervision of intermediate layers. Specifically, aspect term extraction, sentiment lexicon detection, and aspect sentiment detection are designed to encode the aspect boundary and sentiment information. The tasks are in charge of different perspectives and levels of knowledge, which provide multi-fold regulation effects to optimize the main task. Unlike vanilla multi-task learning, all the tasks are integrated into a hierarchical structure to help the higher-level tasks make full use of the lower-level tasks’ information. Experimental results on three datasets demonstrate that the proposed method achieves state-of-the-art results. Further analysis shows that the proposed method achieves better performance than single-task and vanilla multi-task learning methods and yields a more discriminative feature representation.},
  archive      = {J_NEUCOM},
  author       = {Xinyi Wang and Guangluan Xu and Zequn Zhang and Li Jin and Xian Sun},
  doi          = {10.1016/j.neucom.2021.03.100},
  journal      = {Neurocomputing},
  pages        = {178-188},
  shortjournal = {Neurocomputing},
  title        = {End-to-end aspect-based sentiment analysis with hierarchical multi-task learning},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimation of the synchronization between intermittent
photic stimulation and brain response in hypertension disease by the
recurrence and synchrosqueezed wavelet transform. <em>NEUCOM</em>,
<em>455</em>, 163–177. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task is to identify differences in phase synchronization between the intermittent photic stimulation and a response of the brain of patients with arterial hypertension and manifestations of moderate cognitive impairment and without such manifestations. To solve the task we used the recurrence based phase synchronization index, the ratio of instantaneous frequencies , the duration and the phase synchronization index obtained after the synchrosqueezed wavelet transform of the EEG patterns and the light time series. We have shown that moderate cognitive impairment correlates with a greater degree of phase synchronization. This is manifested in an increase in the index and duration of phase synchronization between intermittent photostimulation and bioelectric activity of the brain, as well as with a shift in this activity to a lower frequency range compared to the excitation frequency . The results can be used for clinical assessment of the degree of moderate cognitive impairment of vascular origin.},
  archive      = {J_NEUCOM},
  author       = {O.E. Dick and A.L. Glazov},
  doi          = {10.1016/j.neucom.2021.05.038},
  journal      = {Neurocomputing},
  pages        = {163-177},
  shortjournal = {Neurocomputing},
  title        = {Estimation of the synchronization between intermittent photic stimulation and brain response in hypertension disease by the recurrence and synchrosqueezed wavelet transform},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive consensus tracking of multi-robotic systems via
using integral sliding mode control. <em>NEUCOM</em>, <em>455</em>,
154–162. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The finite-time consensus tracking of multi-robotic systems with disturbances is investigated via utilizing integral sliding mode control (ISMC) in this article. The main focus of this article is on designing consensus tracking protocols. Firstly, combined with Lyapunov stabilization theory, a continuous super-twisting (ST) consensus protocol is proposed to obtain the sufficient condition, which can guarantee the accuracy consensus of multi-robotic systems in the presence of disturbances in finite-time. Secondly, the adaptive mechanism and ISMC are integrated for multi-robotic systems without the prior knowledge of disturbances. It is easy to find that it can prevent the limited growth of the switching gain. In addition, the disturbance of multi-robotic systems can be estimated by designing a fascinating disturbance observer. The consensus tracking of multi-robotic systems can be assured in finite-time. Finally, the effectiveness of the presented adaptive ISMC strategy is demonstrated by two numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Shenghuang He and Yong Xu and Yuanqing Wu and Yanzhou Li and Wenjian Zhong},
  doi          = {10.1016/j.neucom.2021.03.069},
  journal      = {Neurocomputing},
  pages        = {154-162},
  shortjournal = {Neurocomputing},
  title        = {Adaptive consensus tracking of multi-robotic systems via using integral sliding mode control},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Global context-aware multi-scale features aggregative
network for salient object detection. <em>NEUCOM</em>, <em>455</em>,
139–153. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks have gained aggressive success in salient object detection. This paper uses the Multi-Scale Feature Extraction Module (MFEM) for each backbone level to get multi-scale contextual knowledge. We propose the Cross Feature Aggregation Modules(CFAM) to integrate the various features from adjacent levels, which comparatively propagate less noise due to small up-/down sampling rates. To further refine individual-level integrated features, we design Self Interactive Modules (SIRM) at each decoder stage. The SIRM utilizes the spatial- and channel-wise attention to suppress the non-salient regions while assigning more weights to the foreground salient object to visualize the submissive regions (i.e., some salient regions looking like non-salient regions) of the salient objects. Our network can enhance size-varying objects’ illustration proficiency by adopting the multi-scale feature extraction capability in each module. Besides, we develop the Global Context Flow Module (GCFM) to get the global context knowledge at different points in the decoder, which aims to acquire the association among different salient regions and mitigate the dilution of high-level features. Our proposed model (i.e., GCMANet) follows a supervised way to generate the saliency maps. The results produced over publicly available datasets verify that our model outperforms its counterparts in quantitative and qualitative measurements.},
  archive      = {J_NEUCOM},
  author       = {Inam Ullah and Muwei Jian and Sumaira Hussain and Li Lian and Zafar Ali and Imran Qureshi and Jie Guo and Yilong Yin},
  doi          = {10.1016/j.neucom.2021.05.001},
  journal      = {Neurocomputing},
  pages        = {139-153},
  shortjournal = {Neurocomputing},
  title        = {Global context-aware multi-scale features aggregative network for salient object detection},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An accurate and fair evaluation methodology for SNN-based
inferencing with full-stack hardware design space explorations.
<em>NEUCOM</em>, <em>455</em>, 125–138. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Neural Networks (ANNs) achieve high accuracy in various cognitive tasks (i.e., inferences), but often fail to meet power and latency budgets due to intensive computational overheads. To address the challenge, Spiking Neural Networks (SNNs) have emerged as high-performance and power-efficient alternatives thanks to their theoretically efficient spike-driven computations. The spike-based computations have a high potential of achieving cost-effective inferencing with their low-precision data representations, simple neuron operations, and new parallelization opportunities. To determine which network (i.e., ANN or SNN) is suitable for which purposes, it is essential to accurately evaluate the cost-effectiveness of an SNN and compare it to the corresponding ANN. However, existing studies overestimate or underestimate the cost-effectiveness of SNNs over ANNs as they consider only the limited design points and compare SNNs against naive ANN hardware baselines. In this study, we propose a full-stack SNN evaluation methodology to accurately evaluate the cost-effectiveness of SNNs. Quantifying the potential of SNNs is highly challenging as the evaluations require full-stack knowledge on SNNs’ unique computational features and how each affects the mechanisms of the underlying hardware. For this purpose, we identify five representative SNN-specific design points that affect hardware performance and demonstrate the impact of each design point with the quantified experimental results. Next, we modify the existing ANN accelerator to support the identified SNN-specific design points and implement a cycle-accurate simulator to evaluate how each point affects the overall cost-effectiveness. As a case study, we evaluate SNNs converted from pretrained ANNs and compare them against the ANN counterparts using our simulator. Our study is the first work to accurately evaluate the cost-effectiveness of SNNs and make fair comparisons against ANNs. In addition, our methodology provides important guidelines for the next-generation SNN accelerator designs.},
  archive      = {J_NEUCOM},
  author       = {Hunjun Lee and Chanmyeong Kim and Seungho Lee and Eunjin Baek and Jangwoo Kim},
  doi          = {10.1016/j.neucom.2021.05.020},
  journal      = {Neurocomputing},
  pages        = {125-138},
  shortjournal = {Neurocomputing},
  title        = {An accurate and fair evaluation methodology for SNN-based inferencing with full-stack hardware design space explorations},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hashing person re-ID with self-distilling smooth relaxation.
<em>NEUCOM</em>, <em>455</em>, 111–124. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-ID) has made substantial progress in recent years; however, it is still challenging to search for the target person in a short time. Re-ID with deep hashing is a shortcut for that but, limited by the expression of binary code, the performance of the hashing method is not satisfactory. Besides, to further speed up retrieval, researchers tend to reduce the number of feature bits, which will cause more performance degradation . In this paper, we design the attribute-based fast retrieval (AFR), which leverages the attribute prediction of the model trained in a binary classification manner tailor-made for hashing. The attribute information is also used to refine the global feature representation by an attribute-guided attention block (AAB). Then, to fully exploit deep feature to generate the hash codes, we propose a binary code learning method, named self-distilling smooth relaxation (SSR). In this method, a simple yet effective regularization is presented to distill the quantized knowledge in the model itself, thus mitigating the lack of semantic guidance in the traditional non-linear relaxations. We manually label attributes for each person in dataset CUHK03 and evaluate our method on four authoritative public benchmarks (Market-1501, Market-1501+500K, CUHK03, and DukeMTMC-reID). The experimental results indicate that with the SSR and AAB, we surpass all the state-of-the-art hashing methods. And compared with reducing the feature bits, the AFR strategy is more effective to save search time.},
  archive      = {J_NEUCOM},
  author       = {Hanyang Jin and Shenqi Lai and Guoshuai Zhao and Xueming Qian},
  doi          = {10.1016/j.neucom.2021.05.059},
  journal      = {Neurocomputing},
  pages        = {111-124},
  shortjournal = {Neurocomputing},
  title        = {Hashing person re-ID with self-distilling smooth relaxation},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LIFT-SLAM: A deep-learning feature-based monocular visual
SLAM method. <em>NEUCOM</em>, <em>455</em>, 97–110. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Simultaneous Localization and Mapping (SLAM) problem addresses the possibility of a robot to localize itself in an unknown environment and simultaneously build a consistent map of this environment. Recently, cameras have been successfully used to get the environment’s features to perform SLAM, which is referred to as visual SLAM (VSLAM). However, classical VSLAM algorithms can be easily induced to fail when either the motion of the robot or the environment is too challenging. Although new approaches based on Deep Neural Networks (DNNs) have achieved promising results in VSLAM, they still are unable to outperform traditional methods. To leverage the robustness of deep learning to enhance traditional VSLAM systems, we propose to combine the potential of deep learning-based feature descriptors with the traditional geometry-based VSLAM, building a new VSLAM system called LIFT-SLAM. Experiments conducted on KITTI and Euroc datasets show that deep learning can be used to improve the performance of traditional VSLAM systems, as the proposed approach was able to achieve results comparable to the state-of-the-art while being robust to sensorial noise. We enhance the proposed VSLAM pipeline by avoiding parameter tuning for specific datasets with an adaptive approach while evaluating how transfer learning can affect the quality of the features extracted.},
  archive      = {J_NEUCOM},
  author       = {Hudson Martins Silva Bruno and Esther Luna Colombini},
  doi          = {10.1016/j.neucom.2021.05.027},
  journal      = {Neurocomputing},
  pages        = {97-110},
  shortjournal = {Neurocomputing},
  title        = {LIFT-SLAM: A deep-learning feature-based monocular visual SLAM method},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TSRGAN: Real-world text image super-resolution based on
adversarial learning and triplet attention. <em>NEUCOM</em>,
<em>455</em>, 88–96. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The text in a low-resolution (LR) image is usually hard to read. Super-resolution (SR) is an intuitive solution to this issue. Existing single image super-resolution (SISR) models are mainly trained on synthetic datasets whose LR images are obtained by performing bicubic interpolation or gaussian blur on high-resolution (HR) images. However, these models can hardly generalize to practical scenarios because real-world LR images are more difficult to super-resolve. The newly proposed TextZoom dataset is the first dataset for real-world text image super-resolution. We propose a new model termed TSRGAN trained on this dataset. First, a discriminator is designed to prevent the SR network from generating over-smoothed images. Second, we introduce triplet attention into the SR network for better representational ability. Moreover, besides L 2 L2 loss and adversarial loss, wavelet loss is incorporated to help reconstruct sharper character edges. Since TextZoom provides text labels, the recognition accuracy of scene text recognition (STR) model can be used to evaluate the quality of SR images. It can reflect the performance of text image SR models better than traditional SR evaluation metrics such as PSNR and SSIM. Comprehensive experiments show the superiority of our TSRGAN. Compared with the state-of-the-art method, the proposed TSRGAN improves the average recognition accuracy of ASTER, MORAN and CRNN by 0.8\%, 1.5\% and 3.2\% on TextZoom respectively.},
  archive      = {J_NEUCOM},
  author       = {Chuantao Fang and Yu Zhu and Lei Liao and Xiaofeng Ling},
  doi          = {10.1016/j.neucom.2021.05.060},
  journal      = {Neurocomputing},
  pages        = {88-96},
  shortjournal = {Neurocomputing},
  title        = {TSRGAN: Real-world text image super-resolution based on adversarial learning and triplet attention},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Extended dissipativity state estimation for generalized
neural networks with time-varying delay via delay-product-type
functionals and integral inequality. <em>NEUCOM</em>, <em>455</em>,
78–87. (<a href="https://doi.org/10.1016/j.neucom.2021.05.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of extended dissipativity state estimation for delayed generalized neural networks (GNNs) is investigated. Firstly, in order to facilitate the use of more information of time-varying delay, a class of delay-product-type Lyapunov-Krasovskii functional (LKF) is proposed. Secondly, in order to accurately estimate the upper bound of the time-derivative of the constructed LKF, a delay-product-type integral inequality is proposed, then some sufficient conditions are obtained to guarantee the extended dissipativity state estimation for delayed GNNs. Moreover, the extended dissipativity state estimation can be used to tackle the problem of H ∞ H∞ performance state estimation, passivity performance state estimation, L 2 L2 - L ∞ L∞ performance state estimation, and ( Q , S , R ) (Q,S,R) - γ γ -dissipativity state estimation for delayed GNNs. Finally, simulations are provided to illustrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Guoqiang Tan and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2021.05.044},
  journal      = {Neurocomputing},
  pages        = {78-87},
  shortjournal = {Neurocomputing},
  title        = {Extended dissipativity state estimation for generalized neural networks with time-varying delay via delay-product-type functionals and integral inequality},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise covariance estimation for networked linear systems
under random access protocol scheduling. <em>NEUCOM</em>, <em>455</em>,
68–77. (<a href="https://doi.org/10.1016/j.neucom.2021.05.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the noise covariance estimation problem for the networked linear system under communication protocol. To reduce network burden and avoid data collisions, the data transmission from the sensor nodes to the filter is scheduled by the random access protocol (RAP), where only a sensor node is permitted to send data at each transmission instant. Within the framework, the correlations of the innovations data are utilized to construct a least-squares problem to estimate the noise covariances, where a novel estimation form of the auto-covariance from measurement data is given. Moreover, the two cases of the process noise correlated and uncorrelated with the measurement noise are both discussed. It can be proved that the estimated covariances are unbiased and asymptotically converge to the true values as the sample size increasing. Finally, the simulation results are given to demonstrate the effectiveness of the presented method.},
  archive      = {J_NEUCOM},
  author       = {Xiu-Xiu Ren and Guang-Hong Yang},
  doi          = {10.1016/j.neucom.2021.05.052},
  journal      = {Neurocomputing},
  pages        = {68-77},
  shortjournal = {Neurocomputing},
  title        = {Noise covariance estimation for networked linear systems under random access protocol scheduling},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Factored heterogeneous similarity model for recommendation
with implicit feedback. <em>NEUCOM</em>, <em>455</em>, 59–67. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation with implicit feedback such as “bought” in e-commerce sites and “like” in online-to-offline services is an important problem because of the abundance of users’ online behaviors. Previous works for modeling users’ implicit feedback mainly focus on designing some predefined similarity, learned similarity, or hybrid similarity between two users (or two items). However, these similarities either can not capture both the local and global relations among users (or items) simultaneously, or they are not easy to be tuned due to the tradeoff parameter in the linear hybridization. Moreover, information from one single group, either a user group or an item group, may not be sufficient for modeling users’ preferences well. To this end, in this paper, we first propose a heterogeneous similarity to capture rich correlations among users and items via a concise integration, and then design a novel recommendation algorithm, i.e., pointwise factored heterogeneous similarity model (Poi-FHSM), in which we fully exploit the proposed similarity in a flexible pointwise preference learning paradigm. Finally, we conduct extensive empirical studies on five real-world datasets, and find that our Poi-FHSM performs better than those based on the predefined, learned and hybrid similarity, as well as the state-of-the-art deep learning-based methods, showcasing the effectiveness of our heterogeneous similarity and recommendation algorithm.},
  archive      = {J_NEUCOM},
  author       = {Yongxin Ni and Xiancong Chen and Weike Pan and Zixiang Chen and Zhong Ming},
  doi          = {10.1016/j.neucom.2021.05.009},
  journal      = {Neurocomputing},
  pages        = {59-67},
  shortjournal = {Neurocomputing},
  title        = {Factored heterogeneous similarity model for recommendation with implicit feedback},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MASAD: A large-scale dataset for multimodal aspect-based
sentiment analysis. <em>NEUCOM</em>, <em>455</em>, 47–58. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis has obtained great success in recent years. Most of the existing work focuses on determining the sentiment polarity of the given aspect according to the given text, while little attention has been paid to the visual information as well as multimodality content for aspect-based sentiment analysis. Multimodal content is becoming increasingly popular in mainstream online social platforms and can help better extract user sentiments toward a given aspect. There are only few studies focusing on this new task: Multimodal Aspect-based Sentiment Analysis ( MASA ), which performs aspect-based sentiment analysis by integrating both texts and images. In this paper, we propose a mutimodal interaction model for MASA to learn the relationship among the text, image and aspect via interaction layers and adversarial training . Additionally, we build a new large-scale dataset for this task, named MASAD , which involves seven domains and 57 aspect categories with 38 k image-text pairs. Extensive experiments have been conducted on the proposed dataset to provide several baselines for this task. Though our models obtain significant improvement for this task, empirical results show that MASA is more challenging than textual aspect-based sentiment analysis, which indicates that MASA remains a challenging open problem and requires further efforts.},
  archive      = {J_NEUCOM},
  author       = {Jie Zhou and Jiabao Zhao and Jimmy Xiangji Huang and Qinmin Vivian Hu and Liang He},
  doi          = {10.1016/j.neucom.2021.05.040},
  journal      = {Neurocomputing},
  pages        = {47-58},
  shortjournal = {Neurocomputing},
  title        = {MASAD: A large-scale dataset for multimodal aspect-based sentiment analysis},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving resistance to adversarial deformations by
regularizing gradients. <em>NEUCOM</em>, <em>455</em>, 38–46. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Improving the resistance of deep neural networks against adversarial attacks is important for deploying models in realistic applications. Nowadays, most defense methods are designed to resist intensity perturbations, and location perturbations have not yet attracted enough attention. However, these two types should be equally important for deep model security. In this paper, we focus on adversarial deformations, a typical class of location perturbations, and propose a defense method named flow gradient regularization to improve the resistance of models against such attacks. By theoretical analysis, we prove that regularizing flow gradients is able to get a tighter bound than regularizing input gradients. Through verifying over multiple datasets, network architectures , and adversarial deformations, our empirical results indicate that training with flow gradients performs better than training with input gradients by a large margin, and also better than adversarial training. Moreover, the proposed method can be used to combine with adversarial deformation training to improve the resistance further. Our method is now available at https://github.com/xpf/Flow-Gradient-Regularization .},
  archive      = {J_NEUCOM},
  author       = {Pengfei Xia and Bin Li},
  doi          = {10.1016/j.neucom.2021.05.055},
  journal      = {Neurocomputing},
  pages        = {38-46},
  shortjournal = {Neurocomputing},
  title        = {Improving resistance to adversarial deformations by regularizing gradients},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GSCFN: A graph self-construction and fusion network for
semi-supervised brain tissue segmentation in MRI. <em>NEUCOM</em>,
<em>455</em>, 23–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a graph self-construction and fusion network (GSCFN) for semi-supervised brain tissue segmentation in Magnetic Resonance Imaging (MRI) by fusing multiple types of image features . Compared to the use of a single feature, various features bring complementary information and can contribute to a better graph representation with a great discriminative power increase. But to do so, two problems need to be solved. The first one consists in effectively inferring a graph from a Magnetic Resonance (MR) image so as to implicitly encode the segmentation information and the second in fully leveraging various features. To solve both problems, we propose an original brain MR image semi-supervised segmentation framework, called graph self-construction and fusion network. This one relies on two parts. In the first one, a graph self-construction network is utilized to obtain various graph representations of an MR image depending on different features. In the second, a multi-graph convolution network is proposed for the fusion of multiple graphs and features as well as for the classification of supervoxels which are treated as graph nodes. Experiments on the BrainWeb18 dataset and the Internet Brain Segmentation Repository 18 dataset validate the superiority of our scheme compared with approaches based on a single feature type, and some other state-of-the-art methods. The ablation experiment indicates that the proposed GSCFN can produce more accurate and reliable segmentation by seamlessly integrates multiple types of features.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Yifei Li and Youyong Kong and Jiasong Wu and Jian Yang and Huazhong Shu and Gouenou Coatrieux},
  doi          = {10.1016/j.neucom.2021.05.047},
  journal      = {Neurocomputing},
  pages        = {23-37},
  shortjournal = {Neurocomputing},
  title        = {GSCFN: A graph self-construction and fusion network for semi-supervised brain tissue segmentation in MRI},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Robustness-aware 2-bit quantization with real-time
performance for neural network. <em>NEUCOM</em>, <em>455</em>, 12–22.
(<a href="https://doi.org/10.1016/j.neucom.2021.05.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quantized neural networks (NN) with reduced bit precision are practical solutions to minimize computational and memory resource requirements and play a vital role in machine learning . However, it is still challenging to avoid significant accuracy degradation due to numerical approximation and lower redundancy. In this paper, a novel robustness-aware 2-bit quantization scheme (RAQ) is proposed for NN, based on binary NN and generative adversarial networks (GAN), which improve performance by enriching binary NN information, extracting the structural information and considering the robustness of the quantized NN. Specifically, using a shift-add operation to replace the multiply-accumulate in the quantization process can speed the NN. A structural loss is proposed to represent the difference between the original NN and quantized NN, such that the structural information of data is preserved after quantization. The structural information learned from NN plays an important role in improving the performance and allows for further fine-tuning of the quantized NN by applying the Lipschitz constraint to the structural loss. For the first time, we consider the robustness of the quantized NN and propose a non-sensitive perturbation loss function by introducing an extraneous term of the spectral norm. The experiments were conducted on CIFAR-10, SVHN and ImageNet datasets with popular NN (such as MobileNetV2 , ResNet20, etc.). Extensive experiments show that our new 2-bit quantization scheme is more efficient than the state-of-the-art quantization methods. Our scheme effectively reduced the latency by 2 × and the accuracy decline by 1–4\%. Meanwhile, the experimental results also demonstrate that the RAQ is robust with adversarial attacks , we not only eliminate the robustness gap between full-precision and quantized models, but also improve the robustness over full-precision ones by 10\%.},
  archive      = {J_NEUCOM},
  author       = {Xiaobin Li and Hongxu Jiang and Runhua Zhang and Fangzheng Tian and Shuangxi Huang and Donghuan Xu},
  doi          = {10.1016/j.neucom.2021.05.006},
  journal      = {Neurocomputing},
  pages        = {12-22},
  shortjournal = {Neurocomputing},
  title        = {Robustness-aware 2-bit quantization with real-time performance for neural network},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recent advances of single-object tracking methods: A brief
survey. <em>NEUCOM</em>, <em>455</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-object tracking is regarded as a challenging task in computer vision, especially in complex spatio-temporal contexts. The changes in the environment and object deformation make it difficult to track. In the last 10 years, the application of correlation filters and deep learning enhances the performance of trackers to a large extent. This paper summarizes single-object tracking algorithms based on correlation filters and deep learning . Firstly, we explain the definition of single-object tracking and analyze the components of general object tracking algorithms. Secondly, the single-object tracking algorithms proposed in the past decade are summarized according to different categories. Finally, this paper summarizes the achievements and problems of existing algorithms by analyzing experimental results and discusses the development trends.},
  archive      = {J_NEUCOM},
  author       = {Yucheng Zhang and Tian Wang and Kexin Liu and Baochang Zhang and Lei Chen},
  doi          = {10.1016/j.neucom.2021.05.011},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Recent advances of single-object tracking methods: A brief survey},
  volume       = {455},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DECN: Dialogical emotion correction network for
conversational emotion recognition. <em>NEUCOM</em>, <em>454</em>,
483–495. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition in conversation (ERC) is an important research topic in artificial intelligence . Different from the emotion estimation in individual utterances, ERC requires proper handling of human interactions in conversations. Several approaches have been proposed for ERC and achieved promising results. In this paper, we propose a correction model for previous approaches, called “Dialogical Emotion Correction Network (DECN)”. This model aims to automatically correct some errors made by emotion recognition strategies and further improve the recognition performance. Specifically, DECN employs a graphical network to model human interactions in conversations. To further utilize the contextual information, DECN also employs the multi-head attention based bi-directional GRU component. Since DECN is a correction model for ERC, it can be easily integrated with any emotion recognition strategy. Experimental results on the IEMOCAP and MELD datasets verify the effectiveness of our proposed method. DECN can improve the performance of emotion recognition strategies with few parameters and low computational complexity .},
  archive      = {J_NEUCOM},
  author       = {Zheng Lian and Bin Liu and Jianhua Tao},
  doi          = {10.1016/j.neucom.2021.05.017},
  journal      = {Neurocomputing},
  pages        = {483-495},
  shortjournal = {Neurocomputing},
  title        = {DECN: Dialogical emotion correction network for conversational emotion recognition},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive attention augmentor for weakly supervised object
localization. <em>NEUCOM</em>, <em>454</em>, 474–482. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly Supervised Object Localization (WSOL) is a technique for obtaining the object location from attention maps of the classification network, without using bounding box annotations. Existing WSOL approaches lack the modeling of the correlations between different regions of the target object. Hence they can only locate some discriminative attentions, which are small and sparse. Besides, they introduce too many background attentions when mining more object parts. In this paper, we propose a novel Adaptive Attention Augmentor (A 3 ) to adaptively augment the target object attentions on class attention maps. It can supplement object attentions by discovering the semantic correspondence between different regions and dynamically suppress background attentions through the proposed Focal Dice loss. Extensive experiments demonstrate the effectiveness of our approach. On the ILSVRC dataset, A 3 achieves a new state-of-the-art localization performance. On the fine-grained datasets including CUB-200–2011 and Cars-196, it also achieves very competitive results.},
  archive      = {J_NEUCOM},
  author       = {Longhao Zhang and Huihua Yang},
  doi          = {10.1016/j.neucom.2021.05.024},
  journal      = {Neurocomputing},
  pages        = {474-482},
  shortjournal = {Neurocomputing},
  title        = {Adaptive attention augmentor for weakly supervised object localization},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting vector attention and context prior for ultrasound
image segmentation. <em>NEUCOM</em>, <em>454</em>, 461–473. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic ultrasound image segmentation is crucial for clinical diagnosis and treatment. However, ultrasound image segmentation is challenging because of the ambiguous structure, incomplete boundary and analogous appearance among different categories. To address above challenges, we propose a flexibly plug-and-play module called vector self-attention layer (VSAL) to conduct long-range spatial and channels reasoning simultaneously. Moreover, it also preserves translational equivariance and considers multi-scale information, by using geometric priors and multi-scale calibration. Besides, a novel context aggregation loss (CAL) is designed to consider the contextual dependences between inter-classes and intra-classes based on context prior. The proposed methods, VSAL and CAL, are flexible enough to be integrated in any CNN-based methods. We validate the effectiveness of the modules on two different ultrasound datasets, multi-target Fetal Apical Four-chamber dataset and one-target Fetal Head dataset. Experiment results reveal significant performance gain when using the proposed modules.},
  archive      = {J_NEUCOM},
  author       = {Lu Xu and Shengbo Gao and Lijuan Shi and Boxuan Wei and Xiaowei Liu and Jicong Zhang and Yihua He},
  doi          = {10.1016/j.neucom.2021.05.033},
  journal      = {Neurocomputing},
  pages        = {461-473},
  shortjournal = {Neurocomputing},
  title        = {Exploiting vector attention and context prior for ultrasound image segmentation},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OAA-SVM-MS: A fast and efficient multi-class classification
algorithm. <em>NEUCOM</em>, <em>454</em>, 448–460. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces the idea of learning uniformly ergodic Markov chain for one-against-all support vector machine (OAA-SVM) algorithm. We first obtain the generalization error of OAA-SVM with fast learning rate for uniformly ergodic Markov samples. We also propose a new OAA-SVM method with Markov sampling (OAA-SVM-MS). The experimental researches for benchmark repository confirm that the OAA-SVM-MS algorithm has significantly better performance in sampling and training total time, classification accuracy and the obtained classifier’s sparsity compared to the classical OAA-SVM algorithm and other multi-class SVM algorithms.},
  archive      = {J_NEUCOM},
  author       = {Yuze Duan and Bin Zou and Jie Xu and Fen Chen and Jiaolong Wei and Yuan Yan Tang},
  doi          = {10.1016/j.neucom.2021.04.115},
  journal      = {Neurocomputing},
  pages        = {448-460},
  shortjournal = {Neurocomputing},
  title        = {OAA-SVM-MS: A fast and efficient multi-class classification algorithm},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronization of nonidentical complex dynamical networks
with unknown disturbances via observer-based sliding mode control.
<em>NEUCOM</em>, <em>454</em>, 441–447. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies globally asymptotical synchronization of nonidentical complex dynamical networks in presence of time delays and unknown disturbances. Based on the idea of sliding mode control , we propose the observer-based sliding mode control scheme to deal with the synchronization of nonidentical complex dynamical networks, where the unknown disturbances are estimated by the disturbance observer. Moreover, the designed sliding mode controller not only guarantee the reachability of the integral sliding surface but also overcome the influence of the disturbances in the control channel. Then, some sufficient conditions of globally asymptotical synchronization are derived via constructing some suitable Lyapunov–Krasovskii functionals and using linear matrix inequality technique. Finally, an example is given to demonstrate the applicability and the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Yongshun Zhao and Xiaodi Li and Ruofeng Rao},
  doi          = {10.1016/j.neucom.2021.05.042},
  journal      = {Neurocomputing},
  pages        = {441-447},
  shortjournal = {Neurocomputing},
  title        = {Synchronization of nonidentical complex dynamical networks with unknown disturbances via observer-based sliding mode control},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A CRNN-based attention-seq2seq model with fusion feature for
automatic labanotation generation. <em>NEUCOM</em>, <em>454</em>,
430–440. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Labanotation is a widely-used notation system for dance recording. Numerous methods for automatic Labanotation generation from motion capture data have been proposed to save time and human labor. However, dance performance variations, data noises, and difficulties in recognizing long continuous motion sequences limit the performance of existed methods. In this paper, we propose a CRNN-based attention-seq2seq model with fusion features for a robust and effective Labanotation generation.First, we fuse bone feature and Lie group feature to extract not only the information of bones between adjacent joints but also the relative geometry relationships between connected bones. Then, in the proposed seq2seq model, we employ the Convolutional Recurrent Neural Networks (CRNN) to learn the spatial–temporal representation of motion capture data and the attention mechanism to learn good alignments between input motion feature sequences and output symbol sequences. Extensive experiments on real-world datasets show that the proposed method obtains considerable recognition accuracy (90.65\% on the LabanSeq16 dataset and 93.29\% on the LabanSeq48 dataset), which outperforms state-of-the-art approaches on the task of automatic Labanotation generation.},
  archive      = {J_NEUCOM},
  author       = {Min Li and Zhenjiang Miao and Wanru Xu},
  doi          = {10.1016/j.neucom.2021.05.036},
  journal      = {Neurocomputing},
  pages        = {430-440},
  shortjournal = {Neurocomputing},
  title        = {A CRNN-based attention-seq2seq model with fusion feature for automatic labanotation generation},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge graph enhanced neural collaborative filtering with
residual recurrent network. <em>NEUCOM</em>, <em>454</em>, 417–429. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph (KG), which commonly consists of fruitful connected facts about items, presents an unprecedented opportunity to alleviate the sparsity problem in recommender system . However, existing KG based recommendation methods mainly rely on handcrafted meta-path features or simple triple-level entity embedding, which cannot automatically capture entities’ long-term relational dependencies for the recommendation. Specially, entity embedding learning is not properly designed to combine user-item interaction information with KG context information. In this paper, a two-channel neural interaction method named K nowledge G raph enhanced N eural C ollaborative F iltering with R esidual R ecurrent N etwork ( KGNCF-RRN ) is proposed, which leverages both long-term relational dependencies KG context and user-item interaction for recommendation. (1) For the KG context interaction channel, we propose Residual Recurrent Network (RRN) to construct context-based path embedding, which incorporates residual learning into traditional recurrent neural networks (RNNs) to efficiently encode the long-term relational dependencies of KG. The self-attention network is then applied to the path embedding to capture the polysemy of various user interaction behaviours . (2) For the user-item interaction channel, the user and item embeddings are fed into a newly designed two-dimensional interaction map. (3) Finally, above the two-channel neural interaction matrix, we employ a convolutional neural network to learn complex correlations between user and item. Extensive experimental results on three benchmark datasets show that our proposed approach outperforms existing state-of-the-art approaches for knowledge graph based recommendation.},
  archive      = {J_NEUCOM},
  author       = {Lei Sang and Min Xu and Shengsheng Qian and Xindong Wu},
  doi          = {10.1016/j.neucom.2021.03.053},
  journal      = {Neurocomputing},
  pages        = {417-429},
  shortjournal = {Neurocomputing},
  title        = {Knowledge graph enhanced neural collaborative filtering with residual recurrent network},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Applications of information channels to physics-informed
neural networks for WiFi signal propagation simulation at the edge of
the industrial internet of things. <em>NEUCOM</em>, <em>454</em>,
405–416. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ubiquitous presence of data driven technologies that move information from the edge of the Industrial Internet of Things (IIoT) to the cloud for advanced computation and back to the edge for action are pushing wireless connections to the limit. Under these conditions optimizing WIFI Received Signal Strength Intensity (RSSI) can improve data management, computational workflows, and geolocation accuracy while reducing energy consumption in order to minimize charging and computational resource requirements at the edge. Ensuring connectivity for these mission critical processes will require detailed knowledge (either measured or simulated) of the state of the electromagnetic fields in advanced manufacturing scenarios. Simulation has the advantage of developing more scalable solutions to this characterization problem but comes at a very high computational cost that may not be possible on edge devices with limited computational resources. In order to reduce the time and resource cost of achieving real time simulations with low computing specification edge devices, we propose creating a novel method that exploits the notion of information channels to create efficient Convolutional Neural Networks (CNNs) capable of determining the RSSI given a completely new geometry (never used in training) where objects or obstacles (walls, machines, tables, etc.) and their respective location, size and reflectivity indices, along with the antenna location are completely random.},
  archive      = {J_NEUCOM},
  author       = {E. Olivares and H. Ye and A. Herrero and B. Ashrafi Nia and Y. Ren and R.P. Donovan and F. Flaviis de},
  doi          = {10.1016/j.neucom.2021.04.021},
  journal      = {Neurocomputing},
  pages        = {405-416},
  shortjournal = {Neurocomputing},
  title        = {Applications of information channels to physics-informed neural networks for WiFi signal propagation simulation at the edge of the industrial internet of things},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive neural tracking control for switched nonlinear
systems with state quantization. <em>NEUCOM</em>, <em>454</em>, 392–404.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, an adaptive neural tracking control problem for uncertain switched nonlinear systems with state quantization under arbitrary switching is investigated. A command-filtered backstepping control design strategy is implemented to overcome the difficulty that the time derivate of common virtual control signals cannot be well defined. By deriving the closed-loop system quantized errors bounded, quantized states can be used to the control design and unquantized states can be applied to the stability analysis. And then, an adaptive neural tracking control approach for switched nonlinear systems with state quantization via common Lyapunov function is proposed, which guarantees that all the signals in the closed-loop system remain semiglobal uniform ultimate boundedness and the genuine output of system can well track the reference trajectory. Finally, the proposed method is demonstrated by two simulation results.},
  archive      = {J_NEUCOM},
  author       = {Danping Zeng and Zhi Liu and C.L. Philip Chen and Yun Zhang},
  doi          = {10.1016/j.neucom.2021.02.083},
  journal      = {Neurocomputing},
  pages        = {392-404},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural tracking control for switched nonlinear systems with state quantization},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A reconfigurable bidirectional associative memory network
with memristor bridge. <em>NEUCOM</em>, <em>454</em>, 382–391. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bidirectional associative memories (BAMs) have been extensively applied in auto and heteroassociative learning. However, the research on the hardware implementation of BAM neural networks is relatively few. Memristor , a nanoscale synaptic-like element, provides a new perspective for the circuit implementation of neural networks. In this work, we improve a threshold memristor bridge circuit (T-MBC) and design a novel memristive bidirectional associative memory (MBAM) network circuit on this basis. T-MBC is capable to achieve positive, negative, and zero synaptic weights without any switches, inverters , transistors, and current–voltage conversion processes. The validity of T-MBC is illustrated by PSPICE. MBAM has a simpler structure and gains excellent effects in flexibility, and reconfigurability. Besides, it is shown that MBAM can be trained to recall both disturbed binary images and incomplete/noisy grey-scale images robustly. Meanwhile, a more complex application of emotion classification based on MBAM is also accomplished. Experimental results verify the effectiveness of the MBAM neural network and demonstrate that the MBAM neural network has high recognition accuracy and strong noise immunity.},
  archive      = {J_NEUCOM},
  author       = {Yingying Li and Junrui Li and Jie Li and Shukai Duan and Lidan Wang and Mingjian Guo},
  doi          = {10.1016/j.neucom.2021.04.077},
  journal      = {Neurocomputing},
  pages        = {382-391},
  shortjournal = {Neurocomputing},
  title        = {A reconfigurable bidirectional associative memory network with memristor bridge},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Efficient two-step networks for temporal action
segmentation. <em>NEUCOM</em>, <em>454</em>, 373–381. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to boundary ambiguity and over-segmentation issues, identifying all the frames in long untrimmed videos is still challenging. To address these problems, we present the Efficient Two-Step Network (ETSN) with two components. The first step of ETSN is Efficient Temporal Series Pyramid Networks (ETSPNet) that capture both local and global frame-level features and provide accurate predictions of segmentation boundaries. The second step is a novel unsupervised approach called Local Burr Suppression (LBS), which significantly reduces the over-segmentation errors. Our empirical evaluations on the benchmarks including 50Salads, GTEA and Breakfast dataset demonstrate that ETSN outperforms the current state-of-the-art methods by a large margin.},
  archive      = {J_NEUCOM},
  author       = {Yunheng Li and Zhuben Dong and Kaiyuan Liu and Lin Feng and Lianyu Hu and Jie Zhu and Li Xu and Yuhan wang and Shenglan Liu},
  doi          = {10.1016/j.neucom.2021.04.121},
  journal      = {Neurocomputing},
  pages        = {373-381},
  shortjournal = {Neurocomputing},
  title        = {Efficient two-step networks for temporal action segmentation},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A switched view of retinex: Deep self-regularized low-light
image enhancement. <em>NEUCOM</em>, <em>454</em>, 361–372. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-regularized low-light image enhancement does not require any normal-light image in training, thereby freeing from the chains of paired or unpaired training data that are time-consuming to obtain. However, existing methods suffer color deviation and fail to generalize to various lighting conditions. This paper presents a novel self-regularized method based on Retinex, which, inspired by HSV, preserves all colors (Hue, Saturation) and only integrates Retinex theory into brightness (Value). Besides, we design a novel random brightness disturbance approach to generate another abnormal brightness of the same scene. It is combined with the original form of brightness to estimate the same reflectance, which is achieved by a CNN . The reflectance, which is assumed irrelevant to any illumination according to the Retinex theory, is treated as the enhanced brightness. Our method is efficient as a low-light image is decoupled into two subspaces, i.e., color and brightness, for better preservation and enhancement. Extensive experiments demonstrate that our method outperforms multiple state-of-the-art algorithms qualitatively and quantitatively and adapts to more lighting conditions. Our code is available at https://github.com/Github-LHT/A-Switched-View-of-Retinex-Deep-Self-Regularized-Low-Light-Image-Enhancement .},
  archive      = {J_NEUCOM},
  author       = {Zhuqing Jiang and Haotian Li and Liangjie Liu and Aidong Men and Haiying Wang},
  doi          = {10.1016/j.neucom.2021.05.025},
  journal      = {Neurocomputing},
  pages        = {361-372},
  shortjournal = {Neurocomputing},
  title        = {A switched view of retinex: Deep self-regularized low-light image enhancement},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DAEANet: Dual auto-encoder attention network for depth map
super-resolution. <em>NEUCOM</em>, <em>454</em>, 350–360. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, depth map super-resolution (DSR) has obtained remarkable performance with the development of convolutional neural networks (CNNs). High-resolution (HR) depth map can be inferred from a low-resolution (LR) one with the guidance of its corresponding HR intensity image. However, most of the existing CNNs-based methods unilaterally transfer structures information of guidance image to the input depth map, which ignores the corresponding relations between the depth map and the intensity map. In this paper, we propose a novel dual auto-encoder attention network (DAEANet) for DSR. The proposed DAEANet includes two auto-encoder networks, where guidance auto-encoder network (GAENet) and target auto-encoder network (TAENet) aim to extract feature information from intensity image and depth map. Specifically, all auto-encoder networks are similar and trained simultaneously to ensure structural consistency. Furthermore, to preserve the structure information in the process of training, the attention mechanism is employed to our DAEANet. Extensive experiments on several popular benchmarks show that the proposed DAEANet outperforms existing state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Xiang Cao and Yihao Luo and Xianyi Zhu and Liangqi Zhang and Yan Xu and Haibo Shen and Tianjiang Wang and Qi Feng},
  doi          = {10.1016/j.neucom.2021.04.096},
  journal      = {Neurocomputing},
  pages        = {350-360},
  shortjournal = {Neurocomputing},
  title        = {DAEANet: Dual auto-encoder attention network for depth map super-resolution},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Inter-patient ECG arrhythmia heartbeat classification based
on unsupervised domain adaptation. <em>NEUCOM</em>, <em>454</em>,
339–349. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electrocardiography (ECG) arrhythmia heartbeat classification is essential for automatic cardiovascular diagnosis system. However, the enormous differences of ECG signals among individuals and high price of labeled data have brought huge challenges for current classification algorithms based on deep neural networks and prevented these models from achieving satisfactory performance on new data. In order to build a classification system with better adaptability, we propose a novel Domain-Adaptative ECG Arrhythmia Classification (DAEAC) model based on convolutional network and unsupervised domain adaptation (UDA). Based on observation of clustering characteristics of data, we present two original objective functions to enhance the inter-patient performance. A Cluster-Aligning loss is presented to align the distributions of training data and test data. Simultaneously, a Cluster-Maintaining loss is proposed to reinforce the discriminability and structural information of features. The proposed method requires no expert annotations but a short period of unsupervised data in new records to make deep models more adaptive. Extensive experimental results on three public databases demonstrate that our method achieves competitive performance with other state-of-the-arts on the detection of ventricular ectopic beats (V), supraventricular ectopic beats (S) and fusion beats (F). The cross-dataset experimental results also verify the great generalization capability.},
  archive      = {J_NEUCOM},
  author       = {Guijin Wang and Ming Chen and Zijian Ding and Jiawei Li and Huazhong Yang and Ping Zhang},
  doi          = {10.1016/j.neucom.2021.04.104},
  journal      = {Neurocomputing},
  pages        = {339-349},
  shortjournal = {Neurocomputing},
  title        = {Inter-patient ECG arrhythmia heartbeat classification based on unsupervised domain adaptation},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implicit supervision for fault detection and segmentation of
emerging fault types with deep variational autoencoders.
<em>NEUCOM</em>, <em>454</em>, 324–338. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data-driven fault diagnostics of safety–critical systems often faces the challenge of a complete lack of labeled data from faulty system conditions at training time. Since faults of unknown types can arise during deployment, fault diagnostics in this scenario is an open-set learning problem. Without labels and samples from the possible fault types, the open-set diagnostics problem is typically reformulated as fault detection and fault segmentation tasks . Traditional approaches to these tasks, such as one-class classification and unsupervised clustering, do not typically leverage all the available labeled and unlabeled data in the learning algorithm. As a result, their performance is sub-optimal. In this work, we propose an adapted version of the variational autoencoder (VAE), which leverages all available data at training time and has two new design features: 1) implicit supervision on the latent representation of the healthy conditions and 2) implicit bias in the sampling process. The proposed method induces a compact and informative latent representation, thus enabling good detection and segmentation of previously unseen fault types. In an extensive comparison using two turbofan engine datasets, we demonstrate that the proposed method outperforms other learning strategies and deep learning algorithms , yielding significant performance improvements in fault detection and fault segmentation .},
  archive      = {J_NEUCOM},
  author       = {Manuel Arias Chao and Bryan T. Adey and Olga Fink},
  doi          = {10.1016/j.neucom.2021.04.122},
  journal      = {Neurocomputing},
  pages        = {324-338},
  shortjournal = {Neurocomputing},
  title        = {Implicit supervision for fault detection and segmentation of emerging fault types with deep variational autoencoders},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Semantic adaptation network for unsupervised domain
adaptation. <em>NEUCOM</em>, <em>454</em>, 313–323. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation methods aim at learning transferable model for the unlabeled target domain. Recently, extensive domain adaptation models are proposed to align representations by minimizing distribution distance between different domains or adversarial training manner. However, most existing methods only adapt the different features in feature space and ignore the semantic features that generated by the classifier, which can lead to misclassification of target samples near the source decision boundaries. In this paper, we propose a Semantic Adaptation Network (SAN) for unsupervised domain adaptation . SAN aligns the domain representations at both feature-level and semantic-level. SAN utilizes adversarial training to align different domain representations in the feature space. In the semantic space, SAN obtains the pseudo labels of target samples by nearest source semantic representation centroid, then forces the pseudo labeled target semantic representations close to corresponding source semantic representation centroids. Experiments on ImageCLEF-DA, Office-Home and VisDA datasets validate the effectiveness and superiority of our model.},
  archive      = {J_NEUCOM},
  author       = {Qiang Zhou and Wen’an Zhou and Shirui Wang},
  doi          = {10.1016/j.neucom.2021.05.041},
  journal      = {Neurocomputing},
  pages        = {313-323},
  shortjournal = {Neurocomputing},
  title        = {Semantic adaptation network for unsupervised domain adaptation},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-copying mechanism and dynamic emotion dictionary for
generating emotional responses. <em>NEUCOM</em>, <em>454</em>, 303–312.
(<a href="https://doi.org/10.1016/j.neucom.2021.05.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generating emotional responses plays an important role in human–computer conversational system. Adopting emotional information to the generation process improves user’s satisfaction and makes the generated responses more human-like. Furthermore using fixed and unrelated emotion dictionary limits the overall performance of recent models. In order to generate and utilize the emotional words related to our datasets and sensitive to semantic importance, we propose a dynamic emotion dictionary module to generate a proper emotional expression. Considering the response sometimes focuses on the certain words of the input text, we also introduce dual-copying mechanism for taking advantages of not only emotion dictionary but also words appearing in the input text. Experimental results demonstrate that our model outperforms strong alternatives in several metrics, e.g. BLEU, embedding similarity, Rouge-L and the quality of human evaluation.},
  archive      = {J_NEUCOM},
  author       = {Qiji Zhou and Donghong Ji and Yafeng Ren and Hao Tang},
  doi          = {10.1016/j.neucom.2021.05.035},
  journal      = {Neurocomputing},
  pages        = {303-312},
  shortjournal = {Neurocomputing},
  title        = {Dual-copying mechanism and dynamic emotion dictionary for generating emotional responses},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dependency syntactic knowledge augmented interactive
architecture for end-to-end aspect-based sentiment analysis.
<em>NEUCOM</em>, <em>454</em>, 291–302. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The end-to-end aspect-based sentiment analysis (ABSA) task remains to be a long-standing challenge, which aims to extract the aspect term and then identify its sentiment orientation . In previous approaches, the explicit syntactic structure of a sentence, which reflects the syntax properties of natural language and hence is intuitively crucial for aspect term extraction and sentiment recognition, is insufficiently modeled. In this paper, we thus propose a novel dependency syntactic knowledge augmented interactive architecture with multi-task learning for end-to-end ABSA. This model is capable of fully exploiting the syntactic knowledge (dependency relations and types) by leveraging a well-designed Dependency Relation Embedded Graph Convolutional Network . Additionally, we design a simple yet effective message-passing mechanism to ensure that our model learns from multiple related tasks in a multi-task learning framework. Extensive experimental results on three benchmark datasets demonstrate the effectiveness of our approach, which significantly outperforms the existing state-of-the-art method. Besides, we achieve further improvements by using BERT as an additional feature extractor.},
  archive      = {J_NEUCOM},
  author       = {Yunlong Liang and Fandong Meng and Jinchao Zhang and Yufeng Chen and Jinan Xu and Jie Zhou},
  doi          = {10.1016/j.neucom.2021.05.028},
  journal      = {Neurocomputing},
  pages        = {291-302},
  shortjournal = {Neurocomputing},
  title        = {A dependency syntactic knowledge augmented interactive architecture for end-to-end aspect-based sentiment analysis},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SRGCN: Graph-based multi-hop reasoning on knowledge graphs.
<em>NEUCOM</em>, <em>454</em>, 280–290. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to infer missing links is one of the fundamental tasks in the knowledge graph. Instead of reasoning based on separate paths in the existing methods, in this paper, we propose a new model, Sequential Relational Graph Convolutional Network (SRGCN), which treats the multiple paths between an entity pair as a sequence of subgraphs. Specifically, to reason the relationship between two entities, we first construct a graph for the entities based on the knowledge graph and serialize the graph to a sequence. For each hop in the sequence, Relational Graph Convolutional Network (R-GCN) is then applied to update the embeddings of the entities. The updated embedding of the tail entity contains information of the entire graph, hence the relationship between two entities can be inferred from it. Compared to the existing approaches that deal with paths separately, SRGCN treats the graph as a whole, which can encode structural information and interactions between paths better. Experiments show that SRGCN outperforms path-based baselines on both link and fact prediction tasks. We also show that SRGCN is highly efficient in the sense that only one epoch of training is enough to achieve high accuracy, and even partial datasets can lead to competitive performance.},
  archive      = {J_NEUCOM},
  author       = {Zikang Wang and Linjing Li and Daniel Zeng},
  doi          = {10.1016/j.neucom.2021.05.016},
  journal      = {Neurocomputing},
  pages        = {280-290},
  shortjournal = {Neurocomputing},
  title        = {SRGCN: Graph-based multi-hop reasoning on knowledge graphs},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metric-learning-assisted domain adaptation. <em>NEUCOM</em>,
<em>454</em>, 268–279. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain alignment (DA) has been widely used in unsupervised domain adaptation . Many existing DA methods assume that a low source risk, together with the alignment of distributions of source and target, means a low target risk. In this paper, we show that this does not always hold. We thus propose a novel metric-learning-assisted domain adaptation (MLA-DA) method, which employs a novel triplet loss for helping better feature alignment. We explore the relationship between the second largest probability of a target sample’s prediction and its distance to the decision boundary. Based on the relationship, we propose a novel mechanism to adaptively adjust the margin in the triplet loss according to target predictions. Experimental results show that the use of proposed triplet loss can achieve clearly better results. We also demonstrate the performance improvement of MLA-DA on all four standard benchmarks compared with the state-of-the-art unsupervised domain adaptation methods. Furthermore, MLA-DA shows stable performance in robust experiments.},
  archive      = {J_NEUCOM},
  author       = {Yueming Yin and Zhen Yang and Haifeng Hu and Xiaofu Wu},
  doi          = {10.1016/j.neucom.2021.05.023},
  journal      = {Neurocomputing},
  pages        = {268-279},
  shortjournal = {Neurocomputing},
  title        = {Metric-learning-assisted domain adaptation},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Planar object tracking benchmark in the wild.
<em>NEUCOM</em>, <em>454</em>, 254–267. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planar object tracking is an important problem in vision-based robotic systems. Several benchmarks have been constructed to evaluate the tracking algorithms. However, these benchmarks are built in constrained laboratory environments and there is a lack of video sequences captured in the wild to investigate the effectiveness of trackers in practical applications. In this paper, we present a carefully designed planar object tracking benchmark containing 280 videos of 40 planar objects sampled in the natural environment. In particular, for each object, we shoot seven videos involving various challenging factors, namely scale change , rotation , perspective distortion , motion blur , occlusion , out-of-view , and unconstrained . In addition, we design a semi-manual approach to annotate the ground truth with high quality. Moreover, 22 representative algorithms are evaluated on the benchmark using two evaluation metrics . Detailed analysis of the evaluation results is also presented to provide guidance on designing algorithms working in real-world scenarios. We expect that the proposed benchmark would benefit future studies on planar object tracking.},
  archive      = {J_NEUCOM},
  author       = {Pengpeng Liang and Haoxuanye Ji and Yifan Wu and Yumei Chai and Liming Wang and Chunyuan Liao and Haibin Ling},
  doi          = {10.1016/j.neucom.2021.05.030},
  journal      = {Neurocomputing},
  pages        = {254-267},
  shortjournal = {Neurocomputing},
  title        = {Planar object tracking benchmark in the wild},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gradient-based fly immune visual recurrent neural network
solving large-scale global optimization. <em>NEUCOM</em>, <em>454</em>,
238–253. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent achievements claimed that the fly visual neural system could serve a type of artificial computation model for revealing the properties of fly’s learning, memory and decision-making. It, however, still keeps open how to borrow the properties to develop artificial visual neural network optimization models. Hereby, inspired by gradient descent , fly’s visual information-processing and innate immunity mechanisms, this work probes into a fly immune visual recurrent neural network to solve large-scale global optimization (LSGO). As a two-step recurrent network , the neural network updates the output state matrix with the same size as that in the input layer through the gradient descent approach, where the learning rate of state transition is dynamically adjusted by a forward feedback fly immune visual neural network. Also, it is integrated with the conventional convolutional neural network to optimize the ultra-high dimensional weight and threshold parameters in order to acquire a prediction model of visual scene recognition. The theoretical results indicate that the recurrent neural network can converge to an equilibrium point under certain assumptions while the computational complexity is determined by the size of state matrix and the dimension of LSGO. The comparative experiments have confirmed that the neural network is an alternative and potential optimizer for LSGO problems , and in particular the acquired prediction model is a competitive tool for visual scene recognition.},
  archive      = {J_NEUCOM},
  author       = {Zhuhong Zhang and Lun Li and Jiaxuan Lu},
  doi          = {10.1016/j.neucom.2021.05.002},
  journal      = {Neurocomputing},
  pages        = {238-253},
  shortjournal = {Neurocomputing},
  title        = {Gradient-based fly immune visual recurrent neural network solving large-scale global optimization},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aligned variational autoencoder for matching danmaku and
video storylines. <em>NEUCOM</em>, <em>454</em>, 228–237. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study a task of aligning time-sync video comments (danmaku) to narrative video storylines, which is helpful for finding semantic segmentation of videos and conducting fine-grained user feedback analyses. Due to the mismatch of text styles and the shift of topics, it is hard to apply previous semantic matching models directly for the alignment. To tackle the problem, we propose to utilize variational auto-encoders to map both user comments and storylines into latent spaces. By posing a matching loss on their latent codes, we reduce their mismatches in the latent space and make the alignment easier to learn. To handle constraints in the alignment, we also apply dynamic programming for finding global optimal outputs. According to experiments on a TV series dataset (consisting of about 10 K pairs of storylines and danmaku sent by users), the proposed model can achieve competitive performances.},
  archive      = {J_NEUCOM},
  author       = {Qingchun Bai and Yuanbin Wu and Jie Zhou and Liang He},
  doi          = {10.1016/j.neucom.2021.04.118},
  journal      = {Neurocomputing},
  pages        = {228-237},
  shortjournal = {Neurocomputing},
  title        = {Aligned variational autoencoder for matching danmaku and video storylines},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple o(t-q) stability and instability of time-varying
delayed fractional-order cohen-grossberg neural networks with gaussian
activation functions. <em>NEUCOM</em>, <em>454</em>, 212–227. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper formulates new theoretical results concerning the multiple O ( t - q ) O(t-q) stability and instability for a class of time-varying delayed fractional-order Cohen-Grossberg neural networks (FoCGNNs) with Gaussian activation functions . With the aid of geometrical configurations obtained from the FoCGNNs model and Gaussian functions, the state space are partitioned into 3 k 3k subspaces, where k is a nonnegative constant determined by the parameters of FoCGNNs model. By means of the Brouwer’s fixed point theorem as well as the contraction mapping , it is guaranteed that there exists a unique equilibrium point in each subspace. Sufficient conditions are achieved that 2 k 2k equilibrium points are locally O ( t - q ) O(t-q) stable and 3 k - 2 k 3k-2k equilibrium points are unstable. Several examples are rendered to demonstrate the feasible analysis of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Liguang Wan and Zhenxing Liu},
  doi          = {10.1016/j.neucom.2021.05.018},
  journal      = {Neurocomputing},
  pages        = {212-227},
  shortjournal = {Neurocomputing},
  title        = {Multiple o(t-q) stability and instability of time-varying delayed fractional-order cohen-grossberg neural networks with gaussian activation functions},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). DeepSDM: Boundary-aware pneumothorax segmentation in chest
x-ray images. <em>NEUCOM</em>, <em>454</em>, 201–211. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of the pneumothorax from chest X-ray images is of considerable significance for the diagnosis in the emergency department. Recently, deep learning methods have achieved impressive progress in many medical image segmentation tasks. However, the blurred boundary of pneumothorax in chest X-ray images makes it difficult for these algorithms to perform well in pneumothorax segmentation. In this paper, we aim to solve the problem in current learning-based segmentation methods that they often ignore the information of the target boundary and thus fail to generate the result with the correct shape. The proposed new learning framework, DeepSDM, employs the rich information in Signed Distance Map (SDM). The binary segmentation mask and SDM are learned in parallel via the multi-task strategy. Moreover, a boundary-based weighting scheme is adopted in the SDM regression task, forcing the model to focus more on pneumothorax and its contour. The proposed DeepSDM is validated by extensive experiments on the Kaggle SIIM-ACR Pneumothorax Segmentation dataset and our PTX-498 dataset. The results demonstrate that DeepSDM effectively perceives the boundary of pneumothorax and outperforms other state-of-the-art methods. To provoke the research interest in the community, the PTX-498 dataset, codes, and trained models are publicly available at Zenodo and GitHub.},
  archive      = {J_NEUCOM},
  author       = {Yunpeng Wang and Kang Wang and Xueqing Peng and Lili Shi and Jing Sun and Shibao Zheng and Fei Shan and Weiya Shi and Lei Liu},
  doi          = {10.1016/j.neucom.2021.05.029},
  journal      = {Neurocomputing},
  pages        = {201-211},
  shortjournal = {Neurocomputing},
  title        = {DeepSDM: Boundary-aware pneumothorax segmentation in chest X-ray images},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active dropblock: Method to enhance deep model accuracy and
robustness. <em>NEUCOM</em>, <em>454</em>, 189–200. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we investigated a means to improve the robustness of deep network training on visual recognition tasks without sacrificing accuracy. The contribution of this work can reduce the dependence on model decay to gain a strong defense against malicious attacks , especially from adversarial samples. There are two major challenges in this study. First, the model defense capability should be strong and improved over the training stage. The other is that the degrading of the model performance must be minimized to ensure visual recognition performance. To tackle these challenges, we propose active dropblock (ActDB) by incorporating active learning into a dropblock. Dropblock effectively perturbs the feature maps, thus enhancing the invulnerability of gradient-based adversarial attacks . In addition, it selects an optimal perturbation solution to minimize the objective loss function, thereby reducing the model degradation . The proposed organic integration successfully solved the model robustness and accuracy simultaneously. We validated our approach using extensive experiments on various datasets. The results showed significant gains compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jie Yao and Weiwei Xing and Dongdong Wang and Jintao Xing and Liqiang Wang},
  doi          = {10.1016/j.neucom.2021.04.101},
  journal      = {Neurocomputing},
  pages        = {189-200},
  shortjournal = {Neurocomputing},
  title        = {Active dropblock: Method to enhance deep model accuracy and robustness},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep 3D caricature face generation with identity and
structure consistency. <em>NEUCOM</em>, <em>454</em>, 178–188. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposed a novel approach to generate face caricatures automatically from a single portrait image. We decompose the process of 3D face caricatures generation into two independent subtasks: appearance transfer of texture and the geometry transfer of mesh. For the appearance transfer, we design a GAN-based network named CariFaceGAN to learn the style mapping from portrait to caricature, in which facial features are leveraged to preserve identity consistency. For geometry transfer, we first learn the transformation of the landmarks between portraits and caricatures in an embedded space obtained with Locally Linear Embedding method, and then Kriging interpolation is used to manipulate the portrait mesh constructed from a single image. The experimental results show that our proposed CariFaceGAN outperforms the state-of-the-art methods in terms of maintaining identity consistency and providing satisfactory visual effects.},
  archive      = {J_NEUCOM},
  author       = {Song Li and Songzhi Su and Juncong Lin and Guorong Cai and Li Sun},
  doi          = {10.1016/j.neucom.2021.05.014},
  journal      = {Neurocomputing},
  pages        = {178-188},
  shortjournal = {Neurocomputing},
  title        = {Deep 3D caricature face generation with identity and structure consistency},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021h). A cross-modal edge-guided salient object detection for
RGB-d image. <em>NEUCOM</em>, <em>454</em>, 168–177. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection simulates the attention mechanism of human behavior to grasp the most attractive objects in the images. Recently edge information has been introduced to enhance the sharp contour in RGB image saliency detection . Inspired by it, we probe into the edge-guided RGB-D image saliency detection. There are two key problems need to be solved. One is how to extract edge information from cross-modal color and depth information, the other is how to fuse the edge feature into double-stream saliency detection network. To solve these two issues, a cross-modal edge-guided salient object detection for RGB-D image is proposed. Based on double-stream U-Net framework, edge information is extracted from the deep and shallow block of both modalities. The feature in deep layer contains sematic information implying where are the object boundaries, so the features of both modalities are directly fused. The feature in shallow layer provides more detailed spatial information, so a gated fusion layer is utilized to fuse the features of both modalities to filter out the depth image noise. Extracted edge feature is fed into decoder combining with color and depth feature to achieve edge-guided cross-modal decoding process. Experimental results show our model outperforms SOTA models based on the edge guidance and gated fusion strategies in cross-modal double-stream network.},
  archive      = {J_NEUCOM},
  author       = {Zhengyi Liu and Kaixun Wang and Hao Dong and Yuan Wang},
  doi          = {10.1016/j.neucom.2021.05.013},
  journal      = {Neurocomputing},
  pages        = {168-177},
  shortjournal = {Neurocomputing},
  title        = {A cross-modal edge-guided salient object detection for RGB-D image},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain adaptation with geometrical preservation and
distribution alignment. <em>NEUCOM</em>, <em>454</em>, 152–167. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation aims to learn a robust classifier for the target domain by leveraging knowledge from a different source domain. Existing methods realize the alignment of cross-domain distributions in manifold subspace to reduce the distribution divergence between the two domains. However, there exists a conspicuous deficiency in them, i.e., the exploration of preserving statistical and geometrical properties simultaneously is still under insufficient, which, to some extent, would cause the under adaptation effect. The statistical and geometrical properties play an important role in minimizing the domain discrepancy underlying the joint probability distributions. For better and adequately exploiting the statistical and geometrical properties, we propose a novel feature adaptation method in this paper, called domain adaptation with geometrical preservation and distribution alignment (GPDA). Specifically, GPDA performs graph dual regularization in the nonnegative matrix factorization framework with label constraints, to learn the discriminative and domain-invariant features while preserving both the statistical properties and geometrical structures of the original data, such that the cross-domain difference can be effectively and positively narrowed. Meanwhile, GPDA simultaneously aligns the marginal and conditional probability distributions in the nonnegative matrix factorization framework during the learning of domain-invariant features, to further minimize the domain gap between the source and target domains, which can adequately transfer knowledge from the source domain to the target domain. Extensive experiments on seven benchmark datasets demonstrate the effectiveness of the proposed GPDA algorithm in cross-domain image classification .},
  archive      = {J_NEUCOM},
  author       = {Jing Sun and Zhihui Wang and Wei Wang and Haojie Li and Fuming Sun},
  doi          = {10.1016/j.neucom.2021.04.098},
  journal      = {Neurocomputing},
  pages        = {152-167},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptation with geometrical preservation and distribution alignment},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GCCNet: Grouped channel composition network for scene text
detection. <em>NEUCOM</em>, <em>454</em>, 135–151. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anchor mechanism is widely applied in scene text detection methods and demonstrates promising performance. However, existing anchor mechanisms have two major limitations, namely handcrafted anchor design and hard-wired anchor assignment. We propose a novel Grouped Channels Composition(GCC) block to achieve the data-driven anchor design and adaptive anchor assignment. To be more specific, our GCC block uses optimizable anchor functions rather than handcrafted ones to achieve data-drive anchor design. In our GCC block, an adaptive anchor assignment is achieved with the attention mechanism instead of empirically assigning anchor according to the Intersection Over Union (IoU) between ground truth and targets. We then build a corresponding network named GCCNet with our GCC blocks. We also propose a Unified Loss Weighting module to alleviate the inconsistency between classification score and localization accuracy. Experiments conducted on publicly available datasets demonstrate the state-of-the-art performance of our methods.},
  archive      = {J_NEUCOM},
  author       = {Chang Liu and Chun Yang and Jie-Bo Hou and Long-Huang Wu and Xiao-Bin Zhu and Lei Xiao and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2021.04.095},
  journal      = {Neurocomputing},
  pages        = {135-151},
  shortjournal = {Neurocomputing},
  title        = {GCCNet: Grouped channel composition network for scene text detection},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Intensity enhancement via GAN for multimodal face
expression recognition. <em>NEUCOM</em>, <em>454</em>, 124–134. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face expression recognition (FER) on low expression intensity is not well studied in the literature. This paper investigates this problem and presents a novel Generative Adversarial Network (GAN) based multimodal approach to it. The method models the tasks of intensity enhancement and expression recognition jointly, ensuring that the synthesize faces not only present expression of high intensity, but also truly promote the performance of FER. The proposed model is flexible enough that faces can be expressed in various formats, such as RGB image , depth maps, 3D point-clouds, etc., so that complementarity of texture and geometry clues can be further exploited. Extensive experiments are conducted on the BU-3DFE, BU-4DFE, Oulu-CASIA and CK+ datasets. State-of-the-art FER performance is achieved for not only the circumstance of low expression intensities, but also the general FER scenarios, clearly validating the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hongyu Yang and Kangkang Zhu and Di Huang and Hebeizi Li and Yunhong Wang and Liming Chen},
  doi          = {10.1016/j.neucom.2021.05.022},
  journal      = {Neurocomputing},
  pages        = {124-134},
  shortjournal = {Neurocomputing},
  title        = {Intensity enhancement via GAN for multimodal face expression recognition},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New delay and order-dependent passivity criteria for
impulsive fractional-order neural networks with switching parameters and
proportional delays. <em>NEUCOM</em>, <em>454</em>, 113–123. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work deals with the problem of passivity analysis of fractional-order neural networks (FONNs) with impulse, proportional delays and state-dependent switching parameters. The novelty of the work lies in addressing the crucial issue of developing a delay-dependent LMI condition for analysing the behaviour of delayed FONNs. In this paper, a new lemma on Caputo fractional derivatives is developed to construct a new Lyapunov functional to derive delay dependent LMI condition for the passivity analysis of FONNs. Besides that, under modification, another sufficient condition is derived to give an impulse gain-dependent LMI condition. Moreover, for the first time in the literature, delay-dependent and order-dependent passivity criteria for fractional-order systems with proportional delays are presented in this paper. Finally, the results obtained are verified with suitable numerical parameter values and the simulation results are demonstrated to show the effectiveness of the proposed method and superiority of FONNs.},
  archive      = {J_NEUCOM},
  author       = {N. Padmaja and P. Balasubramaniam},
  doi          = {10.1016/j.neucom.2021.04.099},
  journal      = {Neurocomputing},
  pages        = {113-123},
  shortjournal = {Neurocomputing},
  title        = {New delay and order-dependent passivity criteria for impulsive fractional-order neural networks with switching parameters and proportional delays},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Training and inference for integer-based semantic
segmentation network. <em>NEUCOM</em>, <em>454</em>, 101–112. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation has been a major topic in research and industry in recent years. However, due to the computation complexity of pixel-wise prediction and backpropagation algorithm , semantic segmentation has been demanding in computation resources, resulting in slow training and inference speed and large storage space to store models. Existing schemes that speed up segmentation network change the network structure and come with noticeable accuracy degradation. However, neural network quantization can be used to reduce computation load while maintaining comparable accuracy and original network structure. Semantic segmentation networks are different from traditional deep convolutional neural networks (DCNNs) in many ways, and this topic has not been thoroughly explored in existing works. In this paper, we propose a new quantization framework for training and inference of segmentation networks, where parameters and operations are constrained to 8-bit integer-based values for the first time. Full quantization of the data flow and the removal of square and root operations in batch normalization give our framework the ability to perform inference on fixed-point devices. Our proposed framework is evaluated on mainstream semantic segmentation networks like FCN-VGG16 and DeepLabv3-ResNet50, achieving comparable accuracy against floating-point framework on ADE20K dataset and PASCAL VOC 2012 dataset.},
  archive      = {J_NEUCOM},
  author       = {Jiayi Yang and Lei Deng and Yukuan Yang and Yuan Xie and Guoqi Li},
  doi          = {10.1016/j.neucom.2021.04.119},
  journal      = {Neurocomputing},
  pages        = {101-112},
  shortjournal = {Neurocomputing},
  title        = {Training and inference for integer-based semantic segmentation network},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Quantum maximum mean discrepancy GAN. <em>NEUCOM</em>,
<em>454</em>, 88–100. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial network (GAN) has shown profound power in machine learning . It inspires many researchers from other fields to create powerful tools for various tasks, including quantum state preparation, quantum circuit translation, and so on. It is known as classical techniques cannot efficiently simulate the quantum system, and the existing works haven’t investigated the quantum version of maximum mean discrepancy as the metric in learning models and applied it to quantum data. In this paper, we propose a metric named quantum maximum mean discrepancy (qMMD), which can be used to measure the distance between quantum data in Hilbert space . Based on the qMMD, we then design a quantum generative adversarial model , named qMMD-GAN, under the hybrid quantum–classical methods. We also provide the construction of qMMD-GAN that can be easily implemented on a quantum device . We demonstrate the power of our qMMD-GAN by applying it to a crucial real-world application that is generating an unknown quantum state. Our numerical experiments show that qMMD-GAN has a competitive performance compared to existing results. We believe that the hybrid-based models will not only be applied to physics research but provide a new direction for improving classical data processing tasks.},
  archive      = {J_NEUCOM},
  author       = {Yiming Huang and Hang Lei and Xiaoyu Li and Guowu Yang},
  doi          = {10.1016/j.neucom.2021.04.091},
  journal      = {Neurocomputing},
  pages        = {88-100},
  shortjournal = {Neurocomputing},
  title        = {Quantum maximum mean discrepancy GAN},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gait recognition in the presence of co-variate conditions.
<em>NEUCOM</em>, <em>454</em>, 76–87. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition is a biometric technology used to identify people from their walking patterns. Most traditional Computer Vision-based gait recognition approaches have been tested to work satisfactorily given similar training and test conditions. However, there may be situations where the two conditions differ due to the presence of co-variate conditions like bag, coat, and/or others. The presence of co-variate conditions alters the silhouette shape of an individual which affects the performance of the gait recognition algorithms. In this work, we develop an automated approach to perform gait recognition satisfactorily even in the presence of co-variate conditions. First, we determine a set of generic unique poses in a gait cycle, following which we compute gait features corresponding to these poses, which we term as the Dynamic Gait Energy Image ( DGEI ). Next, a Generative Adversarial Network (GAN) model is employed to predict the corresponding DGEI images without the co-variates. These final gait features are readily comparable with the gallery sequences and, hence, the final recognition is performed using the GAN-generated DGEI images. Extensive experimental studies using the publicly available CASIA B, TUM-GAID, and OU-ISIR TreadMill B data sets verify the effectiveness of the proposed approach and its superiority over the state-of-the-art techniques.},
  archive      = {J_NEUCOM},
  author       = {Sanjay Kumar Gupta and Pratik Chattopadhyay},
  doi          = {10.1016/j.neucom.2021.04.113},
  journal      = {Neurocomputing},
  pages        = {76-87},
  shortjournal = {Neurocomputing},
  title        = {Gait recognition in the presence of co-variate conditions},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-domain activity recognition via substructural optimal
transport. <em>NEUCOM</em>, <em>454</em>, 65–75. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is expensive and time-consuming to collect sufficient labeled data for human activity recognition (HAR). Domain adaptation is a promising approach for cross-domain activity recognition. Existing methods mainly focus on adapting cross-domain representations via domain-level, class-level, or sample-level distribution matching. However, they might fail to capture the fine-grained locality information in activity data. The domain- and class-level matching are too coarse that may result in under-adaptation, while sample-level matching may be affected by the noise seriously and eventually cause over-adaptation. In this paper, we propose substructure-level matching for domain adaptation (SSDA) to better utilize the locality information of activity data for accurate and efficient knowledge transfer. Based on SSDA, we propose an optimal transport-based implementation, Substructural Optimal Transport (SOT), for cross-domain HAR. We obtain the substructures of activities via clustering methods and seeks the coupling of the weighted substructures between different domains. We conduct comprehensive experiments on four public activity recognition datasets (i.e. UCI-DSADS, UCI-HAR, USC–HAD, PAMAP2), which demonstrates that SOT significantly outperforms other state-of-the-art methods w.r.t classification accuracy ( 9\%+ improvement). In addition, SOT is 5 × faster than traditional OT-based DA methods with the same hyper-parameters.},
  archive      = {J_NEUCOM},
  author       = {Wang Lu and Yiqiang Chen and Jindong Wang and Xin Qin},
  doi          = {10.1016/j.neucom.2021.04.124},
  journal      = {Neurocomputing},
  pages        = {65-75},
  shortjournal = {Neurocomputing},
  title        = {Cross-domain activity recognition via substructural optimal transport},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential convergence of a proximal projection neural
network for mixed variational inequalities and applications.
<em>NEUCOM</em>, <em>454</em>, 54–64. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel proximal projection neural network (PPNN) to deal with mixed variational inequalities. It is shown that the PPNN has a unique continuous solution under the condition of Lipschitz continuity and that the trajectories of the PPNN converge to the unique equilibrium solution exponentially under some mild conditions. In addition, we study the influence of different parameters on the convergence rate. Furthermore, the proposed PPNN is applied in solving nonlinear complementarity problems, min–max problems, sparse recovery problems and classification and feature selection problems. Finally, numerical and experimental examples are presented to validate the effectiveness of the proposed neurodynamic network.},
  archive      = {J_NEUCOM},
  author       = {Xingxing Ju and Hangjun Che and Chuandong Li and Xing He and Gang Feng},
  doi          = {10.1016/j.neucom.2021.04.059},
  journal      = {Neurocomputing},
  pages        = {54-64},
  shortjournal = {Neurocomputing},
  title        = {Exponential convergence of a proximal projection neural network for mixed variational inequalities and applications},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rethinking the ST-GCNs for 3D skeleton-based human action
recognition. <em>NEUCOM</em>, <em>454</em>, 45–53. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The skeletal data has been an alternative for the human action recognition task as it provides more compact and distinct information compared to the traditional RGB input. However, unlike the RGB input, the skeleton data lies in a non-Euclidean space that traditional deep learning methods are not able to use their fullest potential. Fortunately, with the emerging trend of Geometric deep learning, the spatial-temporal graph convolutional network (ST-GCN) has been proposed to deal with the action recognition problem from skeleton data. ST-GCN and its variants fit well with skeleton-based action recognition and are becoming the mainstream frameworks for this task. However, the efficiency and the performance of the task are hindered by either fixing the skeleton joint correlations or providing a computational expensive strategy to construct a dynamic topology for the skeleton. We argue that many of these operations are either unnecessary or even harmful for the task. By theoretically and experimentally analysing the state-of-the-art ST-GCNs, we provide a simple but efficient strategy to capture the global graph correlations and thus efficiently model the representation of the input graph sequences. Moreover, the global graph strategy also reduces the graph sequence into the Euclidean space, thus a multi-scale temporal filter is introduced to efficiently capture the dynamic information. With the method, we are not only able to better extract the graph correlations with much fewer parameters (only 12.6\% of the current best), but we also achieve a superior performance. Extensive experiments on current largest 3D datasets, NTU-RGB+D and NTU-RGB+D 120, demonstrate the ability of our network to perform efficient and lightweight priority on this task.},
  archive      = {J_NEUCOM},
  author       = {Wei Peng and Jingang Shi and Tuomas Varanka and Guoying Zhao},
  doi          = {10.1016/j.neucom.2021.05.004},
  journal      = {Neurocomputing},
  pages        = {45-53},
  shortjournal = {Neurocomputing},
  title        = {Rethinking the ST-GCNs for 3D skeleton-based human action recognition},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite automata approach to reconstructibility of switched
boolean control networks. <em>NEUCOM</em>, <em>454</em>, 34–44. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the reconstructibility of switched Boolean control networks (SBCNs). Several new types of definition about reconstructibility are proposed where the existence and arbitrariness of the switching signal and the input sequence are inconsistent. A weighted pair graph describing all pairs of states which are indistinguished is defined. A deterministic finite automata method is applied into the reconstructibility analysis. Accordingly, several algorithms are designed to determine these types of reconstructibility. Moreover, for a given reconstructible SBCN, an algorithm for determining the current state is provided. Finally, an example is provided to demonstrate the effectiveness of the proposed algorithms and results.},
  archive      = {J_NEUCOM},
  author       = {Zhe Gao and Biao Wang and Jun-e Feng and Tiantian Li},
  doi          = {10.1016/j.neucom.2021.05.019},
  journal      = {Neurocomputing},
  pages        = {34-44},
  shortjournal = {Neurocomputing},
  title        = {Finite automata approach to reconstructibility of switched boolean control networks},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Preparing lessons: Improve knowledge distillation with
better supervision. <em>NEUCOM</em>, <em>454</em>, 25–33. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) is widely applied in the training of efficient neural network. A compact model, which is trained to mimic the representation of a cumbersome model for the same task, generally obtains a better performance compared with being trained with the ground truth label. Previous KD-based works mainly focus on two aspects: (1) designing various feature representation for knowledge transfer; (2) introducing different training mechanism such as progressive learning or adversarial learning. In this paper, we revisit the standard KD and observe that training with teacher’s logits might suffer from incorrect and uncertain supervision. To tackle these problems, we propose two novel approaches to deal with incorrect logits and uncertain logits respectively, which are called Logits Adjustment (LA) and Dynamic Temperature Distillation (DTD). To be specific, LA rectifies the incorrect logits according to ground truth label and certain rules. While DTD treats the temperature of KD as a dynamic sample wise parameter rather than a static and global hyper-parameter, which actually notes the uncertainty for each sample’s logits. With iteratively updating the sample wise temperature, the student model could pay more attention on the samples that confuse the teacher model. Experiments on CIFAR-10/100, CINIC-10 and Tiny ImageNet verify that the proposed methods yield encouraging improvement compared with the standard KD. Furthermore, considering the simple implementations, LA and DTD can be easily attached to many KD-based frameworks and bring improvements without extra cost of training time and computing resources.},
  archive      = {J_NEUCOM},
  author       = {Tiancheng Wen and Shenqi Lai and Xueming Qian},
  doi          = {10.1016/j.neucom.2021.04.102},
  journal      = {Neurocomputing},
  pages        = {25-33},
  shortjournal = {Neurocomputing},
  title        = {Preparing lessons: Improve knowledge distillation with better supervision},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). On the diversity of multi-head attention. <em>NEUCOM</em>,
<em>454</em>, 14–24. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-head attention is appealing for the ability to jointly attend to information from different representation subspaces at different positions. In this work, we propose two approaches to better exploit such diversity for multi-head attention, which are complementary to each other. First, we introduce a disagreement regularization to explicitly encourage the diversity among multiple attention heads. Specifically, we propose three types of disagreement regularization , which respectively encourage the subspace, the attended positions, and the output representation associated with each attention head to be different from other heads. Second, we propose to better capture the diverse information distributed in the extracted partial-representations with the routing-by-agreement algorithm. The routing algorithm iteratively updates the proportion of how much a part (i.e. the distinct information learned from a specific subspace) should be assigned to a whole (i.e. the final output representation), based on the agreement between parts and wholes. Experimental results on the machine translation, sentence encoding and logical inference tasks demonstrate the effectiveness and universality of the proposed approaches, which indicate the necessity of better exploiting the diversity for multi-head attention. While the two strategies individually boost performance, combining them together can further improve the model performance.},
  archive      = {J_NEUCOM},
  author       = {Jian Li and Xing Wang and Zhaopeng Tu and Michael R. Lyu},
  doi          = {10.1016/j.neucom.2021.04.038},
  journal      = {Neurocomputing},
  pages        = {14-24},
  shortjournal = {Neurocomputing},
  title        = {On the diversity of multi-head attention},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The generative adversarial network improved by channel
relationship learning mechanisms. <em>NEUCOM</em>, <em>454</em>, 1–13.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although recent deep generative models are able to generate high-resolution, diverse natural samples from complex datasets, the generated samples still exist some problems in terms of images structure and detailed texture. In this paper, we propose a novel network architecture–SEDA-GAN that can learn the potential relationship in the dimension of the channel to enhance the generation performance of GAN . The proposed architecture applies Squeeze-and-Excitation(SE) block for feature recalibration to model channel-interdependencies within the GAN feature, and it also incorporates a dual-attention(DA) model with a channel attention mechanism in the GAN framework that can obtain global dependencies between channels. After conducting some comparative experiments on CIFAR and ImageNet datasets by using model BIGGAN as a baseline, our model performance has a certain improvement when evaluating on Fr e ́ é chet Inception Distance(FID) and Inception Score(IS) respectively.},
  archive      = {J_NEUCOM},
  author       = {Danyang Yue and Jianxu Luo and Hongyi Li},
  doi          = {10.1016/j.neucom.2021.04.123},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {The generative adversarial network improved by channel relationship learning mechanisms},
  volume       = {454},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention based convolutional recurrent neural network for
environmental sound classification. <em>NEUCOM</em>, <em>453</em>,
896–903. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Environmental sound classification (ESC) is a challenging problem due to the complexity of sounds. The classification performance is heavily dependent on the effectiveness of representative features extracted from the environmental sounds. However, ESC often suffers from the semantically irrelevant frames and silent frames. In order to deal with this, we employ a frame-level attention model to focus on the semantically relevant frames and salient frames. Specifically, we first propose a convolutional recurrent neural network to learn spectro-temporal features and temporal correlations. Then, we extend our convolutional RNN model with a frame-level attention mechanism to learn discriminative feature representations for ESC. We investigated the classification performance when using different attention scaling function and applying different layers. Experiments were conducted on ESC-50 and ESC-10 datasets. Experimental results demonstrated the effectiveness of the proposed method and our method achieved the state-of-the-art or competitive classification accuracy with lower computational complexity. We also visualized our attention results and observed that the proposed attention mechanism was able to lead the network tofocus on the semantically relevant parts of environmental sounds.},
  archive      = {J_NEUCOM},
  author       = {Zhichao Zhang and Shugong Xu and Shunqing Zhang and Tianhao Qiao and Shan Cao},
  doi          = {10.1016/j.neucom.2020.08.069},
  journal      = {Neurocomputing},
  pages        = {896-903},
  shortjournal = {Neurocomputing},
  title        = {Attention based convolutional recurrent neural network for environmental sound classification},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). CSENet: Cascade semantic erasing network for
weakly-supervised semantic segmentation. <em>NEUCOM</em>, <em>453</em>,
885–895. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly-supervised semantic segmentation based on image-level annotations has difficulty exploring pixel-level information. Most approaches adopt Class Activation Maps (CAM) to localize initial object regions, called seeds. To cover more potential object parts, seeds-expansion methods raise concern for artificial mask generation. Due to the seeds simply focus on discriminative regions, it is a challenge to spread seeds to the integral object. To tackle this problem, we propose a Cascade Semantic Erasing Network (CSENet) to expand seeds effectively and reasonably. In particular, CSENet sequentially stacks the semantic erasing stage to erase discriminative areas progressively. It forces the network to exploit relevant feature response for non-discriminative object districts. Moreover, CSENet directly suppresses seeds on the Class Activation Maps (CAM), which have stronger semantics , rather than on the Intermediate Feature Maps (IFM). Under semantic guidance, proposed erasing strategy correctly spreads seeds regions to the intra-class regions and meanwhile, prohibits from extending to the unexpected inter-class areas. Extensive experiments demonstrate the effectiveness of proposed CSENet. More specifically, our approach achieves 62.3\% and 63.4\% mIoU on PASCAL VOC 2012 validation and test set, respectively.},
  archive      = {J_NEUCOM},
  author       = {Jiahui Liu and Changqian Yu and Beibei Yang and Changxin Gao and Nong Sang},
  doi          = {10.1016/j.neucom.2020.05.107},
  journal      = {Neurocomputing},
  pages        = {885-895},
  shortjournal = {Neurocomputing},
  title        = {CSENet: Cascade semantic erasing network for weakly-supervised semantic segmentation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Single image super-resolution with attention-based densely
connected module. <em>NEUCOM</em>, <em>453</em>, 876–884. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefited from the abundant features provided by the dense connection block, the densely connected-based super-resolution network has achieved superior performance in the single image super-resolution (SISR) task. However, the abundant features also introduce redundant and conflicting information, resulting in longer training time and unsatisfied image reconstruction results. To solve this problem, we propose an attention-based densely connected module (DAM). DAM consists of two parts: channel attention module (CAM) and dense connection block (DB). CAM is placed at the front of each DB and gives different weights of each channel from received features for suppressing redundant responses. Based on DAM, we propose an Attention-based Densely Connected Network (ADSRNet) for SISR, and explore the effectiveness of DAM on other densely connected-based super-resolution networks. Extensive experiments are performed on commonly-used super-resolution benchmarks. Qualitative and quantitative results demonstrate the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Zijian Wang and Yao Lu and Weiqi Li and Shunzhou Wang and Xuebo Wang and Xiaozhen Chen},
  doi          = {10.1016/j.neucom.2020.08.070},
  journal      = {Neurocomputing},
  pages        = {876-884},
  shortjournal = {Neurocomputing},
  title        = {Single image super-resolution with attention-based densely connected module},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-based interpolation network for video deblurring.
<em>NEUCOM</em>, <em>453</em>, 865–875. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video deblurring is a challenging low-level vision task due to variant blur artifacts caused by factors such as depth variations, high-speed movements and camera shakes. Although significant efforts have been devoted to addressing this task, two challenges of capturing temporal patterns and spatial topologies still remain. In this paper, an attention-based interframe compensation scheme is proposed to address the first challenge. The proposed scheme replaces frames in blurry sequences with newly restored frames, and estimates temporal patterns among the replaced sequence to restore the whole sequence. After each replacement, an attention block is employed to exploit dependencies among restored and blurry frames to capture stable temporal patterns. To tackle the second challenge, we propose an adaptive residual block that dynamically fuses multi-level features via learning location-specific weights. Comprehensive experimental results demonstrate that the proposed method achieves state-of-the-art performance in terms of accuracy, visual effect and model size.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqin Zhang and Runhua Jiang and Tao Wang and Pengcheng Huang and Li Zhao},
  doi          = {10.1016/j.neucom.2020.04.147},
  journal      = {Neurocomputing},
  pages        = {865-875},
  shortjournal = {Neurocomputing},
  title        = {Attention-based interpolation network for video deblurring},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive deformable convolutional network. <em>NEUCOM</em>,
<em>453</em>, 853–864. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deformable Convolutional Networks (DCNs) are proposed to solve the inherent limited geometric transformation in CNNs, showing outstanding performance on sophisticated computer vision tasks . Though they can rule out irrelevant image content and focus on region of interest to some degree, the adaptive learning of the deformation is still limited. In this paper, we delve it from the aspects of deformable modules and deformable organizations to extend the scope of deformation ability. Concretely, on the one hand, we reformulate the deformable convolution and RoIpooling by reconsidering spatial-wise attention, channel-wise attention and spatial-channel interdependency , to improve the single convolution’s ability to focus on pertinent image contents. On the other hand, an empirical study is conducted on various and general arrangements of deformable convolutions (e.g., connection type) in DCNs. Especially on semantic segmentation , the study yields significant findings for a proper combination of deformable convolutions. To verify the effectiveness and superiority of our proposed deformable modules, we also provide extensive ablation study for them and compare them with other previous versions. With the proposed contribution, our refined Deformable ConvNets achieve state-of-the-art performance on two semantic segmentation benchmarks (PASCAL VOC 2012 and Cityscapes) and an object detection benchmark (MS COCO).},
  archive      = {J_NEUCOM},
  author       = {Feng Chen and Fei Wu and Jing Xu and Guangwei Gao and Qi Ge and Xiao-Yuan Jing},
  doi          = {10.1016/j.neucom.2020.06.128},
  journal      = {Neurocomputing},
  pages        = {853-864},
  shortjournal = {Neurocomputing},
  title        = {Adaptive deformable convolutional network},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning spatial-channel regularization jointly with
correlation filter for visual tracking. <em>NEUCOM</em>, <em>453</em>,
839–852. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boundary effect of correlation filters is one key issue to limit the performance of visual tracking. Most existing methods focus on using regularization to constrain filters in the spatial domain, but less attention is paid to the channel information that is also important to enhance the discriminative ability of the filter. In this paper, we propose to learn the spatial-channel regularization jointly with the filter for visual tracking. Specifically, the channel regularization is integrated into the spatial regularization, which is exploited to make the filter more compact in spatial and channel domains. It benefits to improve the discriminative ability to identify the target from the background, even distractors. Additionally, the temporal coherence of the target is developed to enable the filter to be robust. The temporal regularization can suppress the sudden change of the spatial-channel regularization on the time axis, which can indirectly control the filter to pay attention to the target’s robust features. The regularization and filter can be jointly optimized by the alternating direction method of multipliers (ADMM) algorithm. We evaluate our method on a standard database. The results show that compared with traditional methods, our tracker has improved significantly in performance and can achieve real-time tracking.},
  archive      = {J_NEUCOM},
  author       = {Yufei Zha and Zhuling Qiu and Jingxian Sun and Peng Zhang and Wei Huang},
  doi          = {10.1016/j.neucom.2020.04.146},
  journal      = {Neurocomputing},
  pages        = {839-852},
  shortjournal = {Neurocomputing},
  title        = {Learning spatial-channel regularization jointly with correlation filter for visual tracking},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Bas-relief modelling from enriched detail and geometry with
deep normal transfer. <em>NEUCOM</em>, <em>453</em>, 825–838. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detail-and-geometry richness is essential to bas-relief modelling. However, existing image-based and model-based bas-relief modelling techniques commonly suffer from detail monotony or geometry loss. In this paper, we introduce a new bas-relief modelling framework for detail abundance with visual attention based mask generation and geometry preservation, which benefits from our two key contributions. For detail richness, we propose a novel semantic neural network of normal transfer to enrich the texture styles on bas-reliefs. For geometry preservation, we introduce a normal decomposition scheme based on Domain Transfer Recursive Filter (DTRF). Experimental results demonstrate that our approach is advantageous on producing bas-relief modellings with both fine details and geometry preservation.},
  archive      = {J_NEUCOM},
  author       = {Meili Wang and Li Wang and Tao Jiang and Nan Xiang and Juncong Lin and Mingqiang Wei and Xiaosong Yang and Taku Komura and Jianjun Zhang},
  doi          = {10.1016/j.neucom.2020.06.130},
  journal      = {Neurocomputing},
  pages        = {825-838},
  shortjournal = {Neurocomputing},
  title        = {Bas-relief modelling from enriched detail and geometry with deep normal transfer},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep eyes: Joint depth inference using monocular and
binocular cues. <em>NEUCOM</em>, <em>453</em>, 812–824. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human visual system relies on both monocular focusness cues and binocular stereo cues to gain effective 3D perception. Correspondingly, depth from focus/defocus (DfF/DfD) and stereo matching are two most studied passive depth sensing schemes, which are traditionally solved in separate tracks. However, the two techniques are essentially complementary: the monocular cue from DfF/DfD can robustly handle repetitive textures and occlusion that are problematic for stereo matching whereas the binocular cue from stereo matching is insensitive to defocus blurs and can resolve large depth range. In this paper, we emulate human perception and present unified learning-based techniques to conduct hybrid DfF/DfD and stereo matching. We first construct a comprehensive focal stack dataset synthesized by depth-guided light field rendering . Next, we propose different network architectures to suit various inputs, including focal stack, stereo image pair, binocular focal stack, a focus-defocus image pair and defocus-stereo image triplet. We also exploit different connection methods between the separate networks for integrating them into an optimized solution to produce high fidelity disparity maps. For experiment, we further explore different hardware setup to capture both monocular and binocular depth cues. Results show that our new learning-based hybrid techniques can significantly improve accuracy and robustness in depth estimation.},
  archive      = {J_NEUCOM},
  author       = {Zhang Chen and Xinqing Guo and Siyuan Li and Yang Yang and Jingyi Yu},
  doi          = {10.1016/j.neucom.2020.06.132},
  journal      = {Neurocomputing},
  pages        = {812-824},
  shortjournal = {Neurocomputing},
  title        = {Deep eyes: Joint depth inference using monocular and binocular cues},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). JWSAA: Joint weak saliency and attention aware for person
re-identification. <em>NEUCOM</em>, <em>453</em>, 801–811. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention mechanisms can extract salient features in images, which has been proven to be effective for person re-identification. However, focusing on the saliency of an image is not enough. On the one hand, the salient features extracted from the model are not necessarily the features needed, e.g., a similar background may also be mistaken as salient features; on the other hand, various salient features are often more conducive to improving the performance of the model. Based on this, in this paper, a model that has joint weak saliency and attention aware is proposed, which can obtain more complete global features by weakening saliency features. The model then obtains diversified saliency features via attention diversity to improve the performance of the model. Experiments on commonly used datasets prove the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Xin Ning and Ke Gong and Weijun Li and Liping Zhang},
  doi          = {10.1016/j.neucom.2020.05.106},
  journal      = {Neurocomputing},
  pages        = {801-811},
  shortjournal = {Neurocomputing},
  title        = {JWSAA: Joint weak saliency and attention aware for person re-identification},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Geometry-attentive relational reasoning for robust facial
landmark detection. <em>NEUCOM</em>, <em>453</em>, 790–800. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a geometry-attentive relational reasoning approach to investigate the problem of robust facial landmark detection, especially when faces were captured in wild conditions. Unlike existing methods which usually cannot explicitly exploit the geometric relationship among different landmarks, our approach aims to reason about the intrinsic geometry-aware relations among landmarks for feature enhancement. To achieve this, we carefully develop an interpretable and plug-and-play module to reinforce the discriminativeness and uniqueness of feature maps, which typically operates on all possible pairs on the immediate inter-landmark heat maps . Among these pairing maps, our model learns to infer the meaningful relational clues in the transformed feature space on condition of holistic facial shape prior. For permutation order invariance, we pool these features as a single aggregated relational feature. To further improve the performance, we simply equip the proposed module inside the backbone hourglass networks. The experimental results on the standard benchmarking datasets indicate the effectiveness of our proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Zongyong Deng and Hao Liu},
  doi          = {10.1016/j.neucom.2020.06.126},
  journal      = {Neurocomputing},
  pages        = {790-800},
  shortjournal = {Neurocomputing},
  title        = {Geometry-attentive relational reasoning for robust facial landmark detection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video person re-identification with global statistic pooling
and self-attention distillation. <em>NEUCOM</em>, <em>453</em>, 777–789.
(<a href="https://doi.org/10.1016/j.neucom.2020.05.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most existing methods for video person re-identification apply spatial-temporal global average or attention pooling to aggregate frame-level feature and get video-level feature. The obtained video-level feature models only the first-order statistics of the appearance feature from holistic video, resulting in limited representation capability of the feature network. In this paper, we propose a novel Global Statistic Pooling network (GSPnet) which takes full advantage of the second-order information for enhancing modeling capability. Firstly, a novel global statistic pooling module is proposed to summarize both the first- and second-order statistics across frame-level feature, and then transfer them into a compact and robust video-level feature embedding. Secondly, a statistic-based attention block is incorporated into multiple stages of convolutional networks to fully explore the second-order representations from low- to high-level features. To enhance the representation learning ability and further boost re-identification (re-ID) performance, we also propose a multi-level self-attention distillation training scheme, which squeezes the knowledge learned in the deeper portion of the networks into the shallow ones. Extensive experimental results have demonstrated the effectiveness and superiority of our approach on four popular video person re-ID datasets.},
  archive      = {J_NEUCOM},
  author       = {Gaojie Lin and Sanyuan Zhao and Jianbing Shen},
  doi          = {10.1016/j.neucom.2020.05.111},
  journal      = {Neurocomputing},
  pages        = {777-789},
  shortjournal = {Neurocomputing},
  title        = {Video person re-identification with global statistic pooling and self-attention distillation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Harmonious attention network for person re-identification
via complementarity between groups and individuals. <em>NEUCOM</em>,
<em>453</em>, 766–776. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) is of important capability for artificial intelligence and human–computer interaction. The main challenge of person Re-ID lies in limited data to precisely capture a wide range of appearance variations over multiple viewpoints. Furthermore, compared to the Re-ID between the single person, the person groups contain information about the relationship between pedestrians that can potentially help identify certain identities. The Re-ID combining groups and individuals remain to be a promising task under rare study. In this paper, we propose a harmonious attention network for person re-identification, in which we jointly consider the complementarity between person groups and individuals. Concretely, first we propose a two-stream attentive network (TSAN) to respectively learn the information from the person groups and individuals. TSAN consists of a spatial–temporal fusion network for the group Re-ID, as well as a deep network for the traditionally individual person Re-ID. To jointly consider the contributions of the groups and individuals, then we propose a novel re-ranking algorithm (GIRK) based on the learned features to associate the group and individual information. We also propose a new group Re-ID dataset DukeGroupVid to evaluate the performance of our approach. Comprehensive experimental results on the proposed dataset and other Re-ID datasets demonstrate the effectiveness of our model.},
  archive      = {J_NEUCOM},
  author       = {Lin Chen and Hua Yang and Qiling Xu and Zhiyong Gao},
  doi          = {10.1016/j.neucom.2020.07.118},
  journal      = {Neurocomputing},
  pages        = {766-776},
  shortjournal = {Neurocomputing},
  title        = {Harmonious attention network for person re-identification via complementarity between groups and individuals},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly supervised video object segmentation initialized with
referring expression. <em>NEUCOM</em>, <em>453</em>, 754–765. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the aid of one manually annotated frame, One-Shot Video Object Segmentation (OSVOS) uses a CNN architecture to tackle the problem of semi-supervised video object segmentation (VOS). However, annotating a pixel-level segmentation mask is expensive and time-consuming. To alleviate the problem, we explore a language interactive way of initializing semi-supervised VOS and run the semi-supervised methods into a weakly supervised mode. Our contributions are two folds: (i) we propose a variant of OSVOS initialized with referring expressions (REVOS), which locates a target object by maximizing the matching score between all the candidates and the referring expression; (ii) segmentation performance of semi-supervised VOS methods varies dramatically when selecting different frames for annotation. We present a strategy of the best annotation frame selection by using image similarity measurement. Meanwhile, we first to propose a multiple frame annotation selection strategy for initialization of semi-supervised VOS with more than one annotated frames. Finally we evaluate our method on DAVIS-2016 dataset, and experimental results show that REVOS achieves similar performance (79.94\% measured by average IoU) compared with OSVOS (80.1\%). Although current REVOS implementation is specific to the method of one-shot video object segmentation, it can be more widely applicable to other semi-supervised VOS methods.},
  archive      = {J_NEUCOM},
  author       = {XiaoQing Bu and YuKuan Sun and JianMing Wang and KunLiang Liu and JiaYu Liang and GuangHao Jin and Tae-Sun Chung},
  doi          = {10.1016/j.neucom.2020.06.129},
  journal      = {Neurocomputing},
  pages        = {754-765},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised video object segmentation initialized with referring expression},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local and correlation attention learning for subtle facial
expression recognition. <em>NEUCOM</em>, <em>453</em>, 742–753. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subtle facial expression recognition (SFER) aims to classify facial expressions with very low intensity into corresponding human emotions. Subtle facial expression can be regarded as a special kind of facial expression, whose facial muscle movements are more difficult to capture. In the last decade, various methods have been developed for common facial expression recognition (FER). However, most of them failed to automatically find the most discriminative parts of facial expression and the correlation of muscle movements when human makes facial expression, which makes them unsuitable for SFER. To better solve SFER problem, an attention mechanism based model focusing on salient local regions and their correlations is proposed in this paper. The proposed method: 1) utilizes multiple attention blocks to attend to distinct discriminative regions and extract corresponding local features automatically, 2) a correlation attention module is integrated in the model to extract global correlation feature over the salient regions , and finally 3) fuses the correlation feature and local features in an efficient way for the final facial expression classification. By this way, the useful but subtle local information can be utilized in more detail, and the correlation of different local regions is also extracted. Extensive experiment on the LSEMSW and CK+ datasets shows that the method proposed in this paper achieves superior results, which demonstrates its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Shaocong Wang and Yuan Yuan and Xiangtao Zheng and Xiaoqiang Lu},
  doi          = {10.1016/j.neucom.2020.07.120},
  journal      = {Neurocomputing},
  pages        = {742-753},
  shortjournal = {Neurocomputing},
  title        = {Local and correlation attention learning for subtle facial expression recognition},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Attention-based label consistency for semi-supervised deep
learning based image classification. <em>NEUCOM</em>, <em>453</em>,
731–741. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised deep learning , which aims to effectively use the available unlabeled data to aid the model in learning from labeled data, is a hot topic recently. To effectively employ the abundant unlabeled data and handle the imbalance in labeled data, we propose a novel attention-based label consistency (ALC) model for semi-supervised deep learning . The relationships between different samples are well exploited by the proposed scheme of channel and sample attention; meanwhile, the class estimations are required to be smooth for nearby unlabeled data. The proposed ALC is further extended to the imbalanced case by developing a label-imbalance ALC model. We have implemented the proposed ALC model in the semi-supervised frameworks of Π Π model and MeanTeacher, and the experimental results on four benchmark datasets, (e.g., Fashion-MNIST, CIFAR-10, SVHN, and ImageNet) clearly show the advantages of our proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jiaming Chen and Meng Yang and Jie Ling},
  doi          = {10.1016/j.neucom.2020.06.133},
  journal      = {Neurocomputing},
  pages        = {731-741},
  shortjournal = {Neurocomputing},
  title        = {Attention-based label consistency for semi-supervised deep learning based image classification},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unpaired salient object translation via spatial attention
prior. <em>NEUCOM</em>, <em>453</em>, 718–730. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With only set-level constraints, unpaired image translation is challenging in discovering the correct semantic-level correspondences between two domains. This limitation often results in false positives such as significantly changing color and appearance of the background during image translation. To address this limitation, we propose the Spatial Attention-Aware Generative Adversarial Network (SAAGAN), a novel approach to jointly learn salient object discovery and translation. Specifically, our generator consists of (1) spatial attention prediction branch and (2) image translation branch. For attention branch, we extract spatial attention prior from a pre-trained classification network to provide weak supervision for object discovery. The proposed attention loss can largely stabilize the training process of attention-guided generator. For translation branch, we revise classical adversarial loss for salient object translation. Such a discriminator only distinguish the distribution of the object between two domains. What is more, we propose a fake sample augmentation strategy to provide extra spatial information for discriminator . Our approach allows simultaneously locating the attention areas in each image and translating the related areas between two domains. Extensive experiments and evaluations show that our model can achieve more realistic mappings compared to state-of-the-art unpaired image translation methods.},
  archive      = {J_NEUCOM},
  author       = {Xianfang Zeng and Yusu Pan and Hao Zhang and Mengmeng Wang and Guanzhong Tian and Yong Liu},
  doi          = {10.1016/j.neucom.2020.05.105},
  journal      = {Neurocomputing},
  pages        = {718-730},
  shortjournal = {Neurocomputing},
  title        = {Unpaired salient object translation via spatial attention prior},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Human scanpath estimation based on semantic segmentation
guided by common eye fixation behaviors. <em>NEUCOM</em>, <em>453</em>,
705–717. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To explore the dynamic process of complex human eye movement behavior , we proposed a new model to simulate human scanpath when subjects observed natural images freely. Previous methods almost focused on finding effective and advanced technology, such as machine learning or deep learning , for estimating human scanpath. In contrast, our proposed method devoted to find a new way that could use the intrinsic property of eye-tracking data between different races to guide the design of a deep network. Inspired by that, the model of human scanpath estimation was established, which based on a semantic segmentation module guided by common eye fixation behaviors between people with different cultures. The semantic segmentation module could deal with locating fixations positions and the fixations ranking problem in parallel and generate human scanpath combined with the output of common attention portions (CAP) generator. The common attention portions (CAP) generator was designed to optimize the performance of semantic segmentation module and extract the common eye fixation behaviors between people with different cultures. We evaluated the performance of our model on three public eye-tracking datasets by comparing the result generated from our model with the ground truth of scanpath produced by a new method in this work. The proposed model also achieved the encouraging performance compared with some classic and fashionable models.},
  archive      = {J_NEUCOM},
  author       = {Yiyuan Han and Bing Han and Xinbo Gao},
  doi          = {10.1016/j.neucom.2020.07.121},
  journal      = {Neurocomputing},
  pages        = {705-717},
  shortjournal = {Neurocomputing},
  title        = {Human scanpath estimation based on semantic segmentation guided by common eye fixation behaviors},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep saliency models: The quest for the loss function.
<em>NEUCOM</em>, <em>453</em>, 693–704. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques are widely used to model human visual saliency, to such a point that state-of-the-art performances are now only attained by deep neural networks . However, one key part of a typical deep learning model is often neglected when it comes to modeling visual saliency: the choice of the loss function. In this work, we explore some of the most popular loss functions that are used in deep saliency models. We demonstrate that on a fixed network architecture , modifying the loss function can significantly improve (or depreciate) the results, hence emphasizing the importance of the choice of the loss function when designing a model. We also evaluate the relevance of new loss functions for saliency prediction inspired by metrics used in style-transfer tasks. Finally, we show that a linear combination of several well-chosen loss functions leads to significant improvements in performance on different datasets as well as on a different network architecture , thus demonstrating the robustness of a combined metric.},
  archive      = {J_NEUCOM},
  author       = {Alexandre Bruckert and Hamed R. Tavakoli and Zhi Liu and Marc Christie and Olivier Le Meur},
  doi          = {10.1016/j.neucom.2020.06.131},
  journal      = {Neurocomputing},
  pages        = {693-704},
  shortjournal = {Neurocomputing},
  title        = {Deep saliency models: The quest for the loss function},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Salient object segmentation for image composition: A case
study of group dinner photo. <em>NEUCOM</em>, <em>453</em>, 681–692. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rocketing number of photos shared on social media leads to the increasing demand for photo editing. We here focus on a specific scenario - group dinner photo and tackle two user-demanding problems - to add a person or replace the tabletop. The target objects are determined according to the saliency detection results. We developed a novel application to solve these problems. With our system, non-professional users can accomplish semantic editing within a few seconds, including inserting human and tidying up tabletops. Our system contributes to the state-of-the-art by (1) efficiently selecting the saliency area by its semantic meaning, (2) accurately compositing the salient content with the target image, based on the contextual knowledge. The context refers to the key factors, including occlusion and artifacts during the composition. The feedback from users shows that the authenticity of inserting human is satisfying. A comparative study shows that our system can more efficiently produce pictures with comparable quality as those edited by professional editing software in the tidying up tabletops work.},
  archive      = {J_NEUCOM},
  author       = {Tianxiang Ren and Lianhui Lin and Shihui Guo and Juncong Lin and Minghong Liao and Shujie Deng and Panpan Xu and Yinyu Nie},
  doi          = {10.1016/j.neucom.2020.06.127},
  journal      = {Neurocomputing},
  pages        = {681-692},
  shortjournal = {Neurocomputing},
  title        = {Salient object segmentation for image composition: A case study of group dinner photo},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting visual perceivability of scene objects through
spatio-temporal modeling of retinal receptive fields. <em>NEUCOM</em>,
<em>453</em>, 667–680. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal processing of a visual scene is an essential step of human visual perception. Although foveal vision is linked to the visual attention, perception is by not means limited to this region. Rather, the retinal field of view ranges from 60 ° 60° nasal to 107 ° 107° temporal, and from 70 ° 70° superior to 80 ° 80° inferior. Whether a scene object is visually perceived depends on both its visual appearance as well as its retinal location. We present a framework to evaluate the visual stimulus of a scene object with regard to different types of retinal receptive fields. Driven by gaze location provided by an eye tracker, the estimated retinal response considers the visual appearance of the object, its eccentricity in the users field of view, and the capabilities at the local retinal region. A desktop experiment shows that, in additional to foveal processing, the estimated retinal response leads to a significant increase in classification accuracy in terms of whether an object is reported as perceived by the user.},
  archive      = {J_NEUCOM},
  author       = {David Geisler and Andrew T. Duchowski and Enkelejda Kasneci},
  doi          = {10.1016/j.neucom.2020.07.119},
  journal      = {Neurocomputing},
  pages        = {667-680},
  shortjournal = {Neurocomputing},
  title        = {Predicting visual perceivability of scene objects through spatio-temporal modeling of retinal receptive fields},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Salient object detection via light-weight multi-path
cascaded networks. <em>NEUCOM</em>, <em>453</em>, 656–666. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning-based saliency detection has achieved fantastic performance over conventional works. However, repeated subsampling operations like pooling or convolution striding in deep CNNs lead to a significant decrease in the initial image resolution. It is difficult for a network to learn saliency at the boundaries of salient regions . In this paper, a Light-Weight Multi-Path Cascaded Network (LMCN) is proposed for image saliency detection – an encoder-decoder architecture that explicitly exploits all the information available along the down-sampling process to enable full-resolution prediction using long-range residual connections. The Res2Net is adopted as a backbone network to better extract multi-level and multi-scale feature maps by constructing hierarchical residual-like connections within one single residual block. Also, the network is lightweighted by the bottleneck structure and depth-wise convolution, which ultimately reduces the number of parameters by more than 50\% while maintaining the same performance. Comprehensive experiments are carried out and new state-of-the-art results are set in eight public datasets. Experiment results show that the proposed approach substantially improves previous state-of-the-art performances.},
  archive      = {J_NEUCOM},
  author       = {Qirong Bu and Kang Ma and Rui Wang and Tuo Zhang and Jun Feng},
  doi          = {10.1016/j.neucom.2020.06.123},
  journal      = {Neurocomputing},
  pages        = {656-666},
  shortjournal = {Neurocomputing},
  title        = {Salient object detection via light-weight multi-path cascaded networks},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep spatio-frequency saliency detection. <em>NEUCOM</em>,
<em>453</em>, 645–655. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the wide success in many vision tasks, it is still challenging for Convolutional Neural Networks (CNNs) to perform saliency detection due to their limited receptive fields and lack of enough discriminative contexts until very late layers. In this paper, beyond spatial convolution, we propose a Spatio-Frequency Network (SFNet) that exploits spatio-frequency clues to effectively enlarge the receptive fields of CNN layers and more importantly, strengthen their spatial discrimination for better saliency detection . In particular, the proposed SFNet contains a carefully designed Frequency Residual Module (FRM) that captures the holistic representation of the whole image within the frequency domain. The FRM leverages discrete and inverse discrete wavelet transformation to alternatively transfer global spatial features into frequency domains, to assist fast and accurate salient object detection. Besides, SFNet also includes an Aggregation of Frequency and Spatial Feature (AFSF) module to jointly integrate the two domain features guided by saliency results in a top-down manner. In this way, the aggregation features per layer contain rich holistic contexts, and the network can eventually explore more complete salient object parts and details by progressively integrating saliency predictions. Extensive experiments on six widely-used saliency detection datasets clearly demonstrate the advantages of our proposed model compared with state-of-the-arts.},
  archive      = {J_NEUCOM},
  author       = {Zun Li and Congyan Lang and Tao Wang and Yidong Li and Jiashi Feng},
  doi          = {10.1016/j.neucom.2020.05.109},
  journal      = {Neurocomputing},
  pages        = {645-655},
  shortjournal = {Neurocomputing},
  title        = {Deep spatio-frequency saliency detection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Deeply supervised group recursive saliency prediction.
<em>NEUCOM</em>, <em>453</em>, 636–644. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fully convolutional neural networks (FCNs) have shown great effects in the saliency detection task. In this paper, we present an FCN based model to aggregate multi-level convolutional features for salient object detection. The main contribution of this work is to make full use of the information extracted by the network while preserving the characteristics of each level. We first propose a novel Intra-stage Feature Aggregating (IFA) module to enhance the detailed information by integrating feature maps from different layers within the same stage of the ResNet-50. We then design an Inter-stage Feature Fusion (IFF) module which exploits contextual information by combining the features from neighboring stages to make each feature map more discriminative. Finally, we propose a Deeply Supervised Group Recursive Prediction (DGR) module to refine the details of the predicted saliency maps and generate the final saliency map. Our approach performs favorably against state-of-the-art methods on five popular datasets and achieves a real-time speed of 30 fps.},
  archive      = {J_NEUCOM},
  author       = {Zhenyu Wu and Lingwei Kong and Lu Zhang and Huchuan Lu},
  doi          = {10.1016/j.neucom.2020.06.124},
  journal      = {Neurocomputing},
  pages        = {636-644},
  shortjournal = {Neurocomputing},
  title        = {Deeply supervised group recursive saliency prediction},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RGB-d salient object detection via cross-modal joint feature
extraction and low-bound fusion loss. <em>NEUCOM</em>, <em>453</em>,
623–635. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection aims at identifying attractive objects in a scene by combining the color image and depth map. However, due to the differences between RGB-D image pairs, it is a key issue to utilize cross-modal data effectively. In this paper, we propose a novel RGB-D salient object detection method via cross-modal joint feature extraction and low-bound fusion loss. A two-stream framework is designed to generate the saliency maps for the RGB image and depth map. During the feature extraction, a cross-modal joint feature extraction module (CFM) is proposed to capture valuable joint features from the two streams. The CFM explores complementary information from the feature extraction and feeds the joint features to the aggregation stage of the network. Then, the fusion block (FB) is utilized to aggregate the multi-scale features of each stream and the joint features to generate the updated features. In addition, a low-bound fusion loss is designed to constrain the predictions of the two streams, to improve the lower bound of saliency values and generate a distinct saliency map. Experimental results on five datasets demonstrate that the proposed method achieves superior performances.},
  archive      = {J_NEUCOM},
  author       = {Xinxin Zhu and Yi Li and Huazhu Fu and Xiaoting Fan and Yanan Shi and Jianjun Lei},
  doi          = {10.1016/j.neucom.2020.05.110},
  journal      = {Neurocomputing},
  pages        = {623-635},
  shortjournal = {Neurocomputing},
  title        = {RGB-D salient object detection via cross-modal joint feature extraction and low-bound fusion loss},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting atypical visual saliency for autism spectrum
disorder via scale-adaptive inception module and discriminative region
enhancement loss. <em>NEUCOM</em>, <em>453</em>, 610–622. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autism spectrum disorder (ASD) is a prevalent lifelong neurodevelopmental disorder . Individuals with ASD perform atypical attention toward the visual stimulus. Despite that the number and performance of visual attention models are ongoing, the atypical attention prediction stagnates. To better understand abnormal visual behaviors of individuals with ASD, this paper models the atypical visual saliency via a deep neural network . First, the multi-level side-out feature maps are extracted from images. Second, the representation of features is enhanced by a scale-adaptive coarse-and-fine inception module that is specialized in integrating multi-scale features. Consequently, the enhanced features are transmitted from deep layers to shallow layers, boosting the precision of saliency maps. Furthermore, to facilitate our model transferring from typical saliency prediction to atypical saliency prediction, a loss function, namely discriminative region enhancement loss, is designed to intensify the discrepancy between the atypical saliency and typical saliency, driving the model to fit the atypical pattern of visual attention. Qualitative and quantitative experiments demonstrate that the proposed model achieves state-of-the-art performance in terms of various metrics.},
  archive      = {J_NEUCOM},
  author       = {Weijie Wei and Zhi Liu and Lijin Huang and Alexis Nebout and Olivier Le Meur and Tianhong Zhang and Jijun Wang and Lihua Xu},
  doi          = {10.1016/j.neucom.2020.06.125},
  journal      = {Neurocomputing},
  pages        = {610-622},
  shortjournal = {Neurocomputing},
  title        = {Predicting atypical visual saliency for autism spectrum disorder via scale-adaptive inception module and discriminative region enhancement loss},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gradient-based neural networks for online solutions of
coupled lyapunov matrix equations. <em>NEUCOM</em>, <em>453</em>,
599–609. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates gradient-based neural networks (GNNs) for solving coupled Lyapunov matrix equations arising in the stability analysis of continuous-time Markovian jump linear systems. First, based on the gradient descent principle, a general framework of GNNs is presented to solve the considered equations by following the ideas in some existing results, which are used to solve the standard Lyapunov matrix equation. Subsequently, a new GNN solver is developed for finding the online solution of the coupled Lyapunov equations. Compared with the general GNN solver, a main advantage of the proposed GNN solver is that its convergence can be directly proven through theoretical analysis. To be specific, according to Lyapunov theory , it is shown that the state of the presented GNN solver with appropriately activation functions can globally converge to the unique positive definite solution of the coupled Lyapunov equations. In addition, to accelerate its convergence rate, an improved version of the proposed GNN is established. Simulation results are given to substantiate the effectiveness of the theoretical results and the superior of the developed GNN solvers compared with the originally obtained general GNN solvers.},
  archive      = {J_NEUCOM},
  author       = {Hui-Jie Sun and Ai-Guo Wu and Wanquan Liu},
  doi          = {10.1016/j.neucom.2020.08.061},
  journal      = {Neurocomputing},
  pages        = {599-609},
  shortjournal = {Neurocomputing},
  title        = {Gradient-based neural networks for online solutions of coupled lyapunov matrix equations},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time stability of coupled impulsive neural networks
with time-varying delays and saturating actuators. <em>NEUCOM</em>,
<em>453</em>, 590–598. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper considers the stability of coupled impulsive neural networks with time-varying delays and saturating actuators in finite time. Based on a delayed state feedback controller , the stability of coupled impulsive neural networks with time-varying delays and saturating actuators can be achieved in finite time. Combined with Lyapunov-based finite-time stability theory, some sufficient conditions are obtained to ensure the stability of coupled impulsive neural networks with time-varying delays and saturating actuators in finite time by using polytopic representation approach and sector nonlinearity model approach, respectively. Moreover, the setting time of coupled impulsive neural networks with saturating actuators is given, and it is found to be related to both the initial state and impulse effect. Furthermore, as special cases, some finite-time stability results of coupled impulsive neural networks with saturating actuators are given under a memoryless controller. Finally, two simulation examples are used to test the effectiveness of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Deqiang Ouyang and Jie Shao and Haijun Jiang and Shiping Wen and Sing Kiong Nguang},
  doi          = {10.1016/j.neucom.2020.09.019},
  journal      = {Neurocomputing},
  pages        = {590-598},
  shortjournal = {Neurocomputing},
  title        = {Finite-time stability of coupled impulsive neural networks with time-varying delays and saturating actuators},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning allocentric representations of space for
navigation. <em>NEUCOM</em>, <em>453</em>, 579–589. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The hippocampus of the mammalian brain supports spatial navigation by building cognitive maps of the environments in which the animal explores. Currently, there is little neurocomputational work investigating the encoding and decoding mechanisms of hippocampal neural representations in large-scale environments. We propose a biologically-inspired hierarchical neural network architecture to learn the transformation of egocentric sensorimotor inputs into allocentric spatial representation for navigation. The hierarchical network is composed of two parallel subnetworks mimicking the lateral entorhinal cortex (LEC) and medial entorhinal cortex (MEC), and one convergent subnetwork mimicking the hippocampus . LEC relays time-related visual information and MEC supplies space-related information in the form of multi-resolution grid codes as resulted from integrating movement information. The convergent subnetwork integrates all information from the parallel subnetworks and predicts the position of the agent in the environment. Synaptic weights of the vision-to-place and grid-to-place connections are learned based on the stochastic gradient descent algorithm. Simulations in a large virtual maze demonstrate that hippocampal place units in the model form multiple and irregularly-spaced place fields, similar to those observed in neurobiological experiments. The model is able to accurately decode the positions of the agent from the learned spatial representations. Moreover, the model is capable of adaptation to degraded visual inputs, and therefore is robust against perturbations. When the motion inputs are deprived, the model meets with localization difficulty, suffering from less accuracy in position predictions.},
  archive      = {J_NEUCOM},
  author       = {Dongye Zhao and Bailu Si and Xiaoli Li},
  doi          = {10.1016/j.neucom.2020.10.013},
  journal      = {Neurocomputing},
  pages        = {579-589},
  shortjournal = {Neurocomputing},
  title        = {Learning allocentric representations of space for navigation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A compensation-based optimization strategy for top dense
layer training. <em>NEUCOM</em>, <em>453</em>, 563–578. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stochastic gradient descent (SGD) method plays a central role in training deep convolutional neural networks (DCNNs). The recent advances in the field of optimization methods for DCNNs follow the direction of gradients. The innovations mainly lie in adopting different techniques to manage the history of gradients or automatically adapt the step size. In contrast, in this paper we propose a novel optimization approach for training the top dense layer of DCNN. It primarily utilizes the orientation directly pointing to the optimal values of parameters instead of the direction of gradients to navigate the parameters updates. The Moore–Penrose inverse method has been adopted to determine the difference between the current parameters and the optimal parameters, and the parameter updates are driven along this direction to compensate such a difference. Subsequently, the parameters have been fine-tuned along the direction of the classical gradient. Experiments have been conducted on extensively selected benchmark datasets. The results indicate that the proposed approach obtains a higher convergence rate and lower minimum loss compared to other state-of-the-art optimization methods. Furthermore, with the same DCNN architectures, the performance improvement margin between the proposed optimization method and other state-of-the-art optimization approaches is highly significant.},
  archive      = {J_NEUCOM},
  author       = {Xiexing Feng and Q.M. Jonathan Wu and Yimin Yang and Libo Cao},
  doi          = {10.1016/j.neucom.2020.07.127},
  journal      = {Neurocomputing},
  pages        = {563-578},
  shortjournal = {Neurocomputing},
  title        = {A compensation-based optimization strategy for top dense layer training},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction intervals estimation of solar generation based on
gated recurrent unit and kernel density estimation. <em>NEUCOM</em>,
<em>453</em>, 552–562. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing attention to the energy crisis and global warming, solar generation has become an important way to use clean solar energy and is playing an increasingly important role. Due to the highly-variable patterns of solar generation, the estimation of prediction intervals is receiving more attention, which is conducive to the safe and stable operation of the power system. In order to further improve the performance of prediction intervals of solar generation, this paper proposes a prediction intervals estimation method for solar generation based on gated recurrent unit (GRU) neural networks and kernel density estimation (KDE). GRU, a commonly used recurrent neural networks , is utilized to obtain the deterministic forecast of solar generation. In addition, according to the characteristics of solar generation, attention mechanism is designed on the GRU prediction model to further improve the prediction performance. Then, the KDE method is used to fit the prediction errors of solar generation obtained by the deterministic forecasting method. In order to verify the effectiveness of the proposed method, we have carried out a large number of experiments on freely available datasets. The experimental results show that the proposed method outperforms competing methods and can generate high-quality prediction intervals.},
  archive      = {J_NEUCOM},
  author       = {Cheng Pan and Jie Tan and Dandan Feng},
  doi          = {10.1016/j.neucom.2020.10.027},
  journal      = {Neurocomputing},
  pages        = {552-562},
  shortjournal = {Neurocomputing},
  title        = {Prediction intervals estimation of solar generation based on gated recurrent unit and kernel density estimation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). IPMGAN: Integrating physical model and generative
adversarial network for underwater image enhancement. <em>NEUCOM</em>,
<em>453</em>, 538–551. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous underwater vehicles (AUVs) highly depend on the quality of captured underwater images to perform a variety of tasks. However, compared with everyday images taken in air, underwater images are hazy, with color shift, and in relatively low quality, posing significant challenges to available mature vision algorithms to achieve expected performance. There are, currently, two major lines of approaches to tackle these challenges: the physical image formation model-based and the neural-network-based approaches. In this paper, we propose an integrated approach, where the revised underwater image formation model, i.e., the Akkaynak-Treibitz model, is embedded into the network design for the benefit of combining the advantages of these two approaches. The embedded physical model guides for network learning, and the generative adversarial network (GAN) is adopted for coefficients estimation. We conduct extensive experiments and compare with state-of-the-art approaches quantitatively and qualitatively on nearly all the available underwater datasets, and our method achieves significant improvements.},
  archive      = {J_NEUCOM},
  author       = {Xiaodong Liu and Zhi Gao and Ben M. Chen},
  doi          = {10.1016/j.neucom.2020.07.130},
  journal      = {Neurocomputing},
  pages        = {538-551},
  shortjournal = {Neurocomputing},
  title        = {IPMGAN: Integrating physical model and generative adversarial network for underwater image enhancement},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). M-GWNN: Multi-granularity graph wavelet neural networks for
semi-supervised node classification. <em>NEUCOM</em>, <em>453</em>,
524–537. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional neural networks (GCNs) based on spectral-domain have achieved impressive performance for semi-supervised node classification task. Recently, graph wavelet neural network (GWNN) has made a significant improvement for this task. However, GWNN is usually shallow based on a one- or two-hop neighborhood structure, making it unable to obtain sufficient global information to make it better. But, if GWNN merely stacks too many convolutional layers , it produces the phenomenon of the wavelet convolutional filters over-smoothing. To stack this challenge, we propose Multi-granularity Graph Wavelet Neural Networks (M-GWNN), a novel spectral GCNs architecture that leverages the proposed Louvain-variant algorithm and the jump connection to improve the ability of node representations for semi-supervised node classification . We first repeatedly apply the proposed Louvain-variant algorithm to aggregate nodes into supernodes to build a hierarchy of successively coarser graph, further refine the coarsened graph symmetrically back to the original by utilizing the jump connection. Moreover, during this process, multiple layers of GWNN are applied to propagate information across entire networks. The proposed M-GWNN efficiently captures node features and graph topological structures of varying granularity to obtain global information. Furthermore, M-GWNN effectively employs the jump connection to connect receptive fields of varying granularity to alleviate the speed of over-smoothing. Experiments on four benchmark datasets demonstrate the effectiveness of the proposed M-GWNN. Particularly, when only a few labeled nodes are provided on the NELL dataset, M-GWNN achieves up to an average 5.7\% performance improvement compared with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Wenjie Zheng and Fulan Qian and Shu Zhao and Yanping Zhang},
  doi          = {10.1016/j.neucom.2020.10.033},
  journal      = {Neurocomputing},
  pages        = {524-537},
  shortjournal = {Neurocomputing},
  title        = {M-GWNN: Multi-granularity graph wavelet neural networks for semi-supervised node classification},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks optimized learning control of state
constraints systems. <em>NEUCOM</em>, <em>453</em>, 512–523. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive neural networks (NN) backstepping optimized tracking learning control approach is presented for nonlinear strict-feedback systems with state constraints. In the control design, neural networks are used to learn the unknown nonlinear dynamics, and a NN state identifier is proposed. By constructing Barrier Lyapunov functions and optimal Barrier type cost functions for identifier error dynamic systems and the subsystems of the identifier systems , and under the actor-critic architecture, the virtual and actual optimal controllers are constructed by the backstepping recursive control design algorithm . The proposed adaptive NN optimal control scheme can guarantee that the closed-loop system is uniformly ultimately bounded (UUB) and the states of the controlled system are ensured not to transgress their constrained sets. Moreover, the proposed optimized controller can guarantee that the system output can track the given reference signal. The effectiveness of the proposed control method is verified by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Xiaomei Li and Yongming Li},
  doi          = {10.1016/j.neucom.2020.10.034},
  journal      = {Neurocomputing},
  pages        = {512-523},
  shortjournal = {Neurocomputing},
  title        = {Neural networks optimized learning control of state constraints systems},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised cycle-consistent person pose transfer.
<em>NEUCOM</em>, <em>453</em>, 502–511. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person pose transfer, i.e., transferring the pose of a given person to a target pose, is a challenging task due to the complex interplay of appearance, pose, and background. Most of the previous works adopted the supervised framework and required paired person images with the same identity and different poses, which largely limits their applications. Besides, the background of the generated image may be altered from the original one due to some over-fitting issues, which is unfavorable for the pose transfer task. To tackle the above problems, we propose an unsupervised cycle-consistent person pose transfer approach. It is trained with unpaired cross-identity person images and can well preserve the background information. Compared with previous methods, our proposed approach achieves better results in the cross-identity person pose transfer task and similar results in self-identity one. Moreover, our method can serve as an effective data augmentation scheme for person recognition tasks, which is validated by extensive experiments on pedestrian re-identification and detection.},
  archive      = {J_NEUCOM},
  author       = {Songyan Liu and Haiyun Guo and Kuan Zhu and Jinqiao Wang and Ming Tang},
  doi          = {10.1016/j.neucom.2020.10.059},
  journal      = {Neurocomputing},
  pages        = {502-511},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised cycle-consistent person pose transfer},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State estimation of markov jump neural networks with random
delays by redundant channels. <em>NEUCOM</em>, <em>453</em>, 493–501.
(<a href="https://doi.org/10.1016/j.neucom.2020.09.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of state estimation for Markov jump neural networks with random delays through redundant channels. First, a redundant channel is provided to increase the probability of successfully transmitting the measurements over the shared communication network, and two mutually independent Bernoulli sequences are used to reflect the data dropouts phenomena in the main channel and the redundant channel. In addition, the time-varying random delay is both mode-dependent and distribution-dependent, and its probabilistic characteristic obeys Bernoulli distribution . Then, by constructing a suitable Lyapunov-Krasovskii functional, the sufficient condition is obtained to guarantee the augmented estimation error system is mean-square stable with a prescribed H ∞ H∞ disturbance attenuation performance. Meanwhile, a mode-dependent estimator is designed by convex optimization method. Finally, the effectiveness of the proposed method is demonstrated by a simulation example.},
  archive      = {J_NEUCOM},
  author       = {Yun Chen and Jing Ren and Xiaodong Zhao and Anke Xue},
  doi          = {10.1016/j.neucom.2020.09.081},
  journal      = {Neurocomputing},
  pages        = {493-501},
  shortjournal = {Neurocomputing},
  title        = {State estimation of markov jump neural networks with random delays by redundant channels},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective detection of mobile malware behavior based on
explainable deep neural network. <em>NEUCOM</em>, <em>453</em>, 482–492.
(<a href="https://doi.org/10.1016/j.neucom.2020.09.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid growth of the number of new mobile malware variants has posed a severe threat to user’s property and privacy. Recent studies show that deep neural networks can detect malicious traffic with high accuracy. However, a deep neural network works like a black box in the sense that its structure doesn’t give any insight on how it works. To overcome this drawback, we propose a method to extract rules from a deep neural network and then use the extracted rules to detect malicious network traffic. Specifically, for a trained deep neural network, we first construct one input-hidden tree per each hidden layer to represent the rules extracted between the input of the neural network and the output of that hidden layer. Then we construct one hidden-output tree to represent the rules extracted between the outputs of all hidden layers and the output of the neural network. Finally, these trees are merged to form one rule tree using the outputs of the hidden layers as a bridge. We have performed extensive experiments to verify the effectiveness of our method in terms of accuracy, precision, recall and F-Measure metrics by comparing it with other state-of-the-art methods. Experimental results show that our method achieves high accuracy using the packet size of only the first nine packets as a feature, which also gives good interpretability on how the deep neural network performs to detect malicious traffic. Besides, we design an online detection system based on FPGA to provide online detection in a high-speed network environment using rule tree, which reduces the difficulty of embedding a deep neural network into FPGA.},
  archive      = {J_NEUCOM},
  author       = {Anli Yan and Zhenxiang Chen and Haibo Zhang and Lizhi Peng and Qiben Yan and Muhammad Umair Hassan and Chuan Zhao and Bo Yang},
  doi          = {10.1016/j.neucom.2020.09.082},
  journal      = {Neurocomputing},
  pages        = {482-492},
  shortjournal = {Neurocomputing},
  title        = {Effective detection of mobile malware behavior based on explainable deep neural network},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RFRN: A recurrent feature refinement network for accurate
and efficient scene text detection. <em>NEUCOM</em>, <em>453</em>,
465–481. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene text detection plays a vital role for scene text understanding, but arbitrary-shaped text detection remains a significant challenge. To extract discriminative features , most recent state-of-the-art methods adopt heavy networks, resulting in parameter redundancy and inference inefficiency. For accurate and efficient scene text detection, in this paper we propose a novel recurrent feature refinement network (RFRN). RFRN, as a recurrent segmentation framework, contains a recurrent path augmentation that refines the previous feature maps as inner states, which not only helps improve the segmentation quality, but also fully facilitates the reuse of parameters and low computational cost. During testing, RFRN discards redundant prediction procedures for efficient inference, and achieves a good balance between speed and accuracy of inference. We conduct experiments on four challenging scene text benchmarks, CTW1500, Total-Text, ICDAR2015 and ICDAR2017-MLT, which include curved texts and multi-oriented texts with complex background. The results show that the proposed RFRN achieves competitive performance on detection accuracy while maintaining computational efficiency.},
  archive      = {J_NEUCOM},
  author       = {Guanyu Deng and Yue Ming and Jing-Hao Xue},
  doi          = {10.1016/j.neucom.2020.10.099},
  journal      = {Neurocomputing},
  pages        = {465-481},
  shortjournal = {Neurocomputing},
  title        = {RFRN: A recurrent feature refinement network for accurate and efficient scene text detection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incorporating sentimental trend into gated mechanism based
transformer network for story ending generation. <em>NEUCOM</em>,
<em>453</em>, 453–464. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Story ending generation is a challenging and under-explored task, which aims at generating a coherent, reasonable, and logical story ending given a context. Previous studies mainly focus on utilizing the contextual information and commonsense knowledge to generate story endings. However, there are still some issues must be addressed in the story endings generation processing, such as sentimental consistency and interference from secondary information. In this paper, we propose a Gated Mechanism based Transformer Network (GMTF). The GMTF model utilizes the sentimental trend to make story ending generation more sentimentally consistent with the context. For a given story context, we utilize a sentiment analysis tool VADER to obtain the sentimental trend. Then, the sentimental information and contextual information are input jointly into the transformer network to capture the key clues. Furthermore, the gated mechanism is applied to filter irrelative information and the weights of attention layers for encoder and decoder are shared to make the most of the contextual clues. The experimental results on ROCStories dataset demonstrate that the proposed method achieves 27.03\% on BLEU-1, 7.62\% on BLEU-2, 1.71 on Grammar, and 1.31 on Logicality, respectively. Specifically, our model outperforms the state-of-the-art model IE+MSA by 0.23\%, 0.22\%, 1.78\%, 5.64\%, respectively and the Transformer model by 3.06\%, 1.05\%, 5.55\%, 48.86\%, respectively. Both automatic and manual evaluations show that our model can generate more reasonable and appropriate story endings compared with the related well-established approaches.},
  archive      = {J_NEUCOM},
  author       = {Linzhang Mo and Jielong Wei and Qingbao Huang and Yi Cai and Qingguang Liu and Xingmao Zhang and Qing Li},
  doi          = {10.1016/j.neucom.2021.01.040},
  journal      = {Neurocomputing},
  pages        = {453-464},
  shortjournal = {Neurocomputing},
  title        = {Incorporating sentimental trend into gated mechanism based transformer network for story ending generation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive segmentation model for liver CT images based on
neural network and level set method. <em>NEUCOM</em>, <em>453</em>,
438–452. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation is difficult for liver computed tomography (CT) images, since the liver CT images do not always have obvious and smooth boundaries. The location of the tumor is not specified and the image intensity is similar to that of the liver. Although manual and automatic segmentation methods, traditional and deep learning models currently exist, none can be specifically and effectively applied to segment liver CT images. In this paper, we propose a new model based on a level set framework for liver CT images in which the energy functional contains three terms including the data fitting term, the length term and the bound term. Then we apply the split Bregman method to minimize the energy functional that leads the energy functional to converge faster. The proposed model is robust to initial contours and can segment liver CT images with intensity inhomogeneity and unclear boundaries. In the bound term, we use the U-Net to get constraint information which has a considerable influence on effective and accurate segmentation. We improve a multi-phase level set of our model to get contours of tumor and liver at the same time. Finally, a parallel algorithm is proposed to improve segmentation efficiency. Results and comparisons of experiments are shown to demonstrate the merits of the proposed model including robustness, accuracy, efficiency and intelligence.},
  archive      = {J_NEUCOM},
  author       = {Xiu Shu and Yunyun Yang and Boying Wu},
  doi          = {10.1016/j.neucom.2021.01.081},
  journal      = {Neurocomputing},
  pages        = {438-452},
  shortjournal = {Neurocomputing},
  title        = {Adaptive segmentation model for liver CT images based on neural network and level set method},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian neural networks with maximum mean discrepancy
regularization. <em>NEUCOM</em>, <em>453</em>, 428–437. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian Neural Networks (BNNs) are trained to optimize an entire distribution over their weights instead of a single set, having significant advantages in terms of, e.g., interpretability , multi-task learning, and calibration. Because of the intractability of the resulting optimization problem , most BNNs are either sampled through Monte Carlo methods , or trained by minimizing a suitable Evidence Lower BOund (ELBO) on a variational approximation . In this paper, we propose an optimized version of the latter, wherein we replace the Kullback–Leibler divergence in the ELBO term with a Maximum Mean Discrepancy (MMD) estimator, inspired by recent work in variational inference. After motivating our proposal based on the properties of the MMD term, we proceed to show a number of empirical advantages of the proposed formulation over the state-of-the-art. In particular, our BNNs achieve higher accuracy on multiple benchmarks, including several image classification tasks. In addition, they are more robust to the selection of a prior over the weights, and they are better calibrated. As a second contribution, we provide a new formulation for estimating the uncertainty on a given prediction, showing it performs in a more robust fashion against adversarial attacks and the injection of noise over their inputs, compared to more classical criteria such as the differential entropy .},
  archive      = {J_NEUCOM},
  author       = {Jary Pomponi and Simone Scardapane and Aurelio Uncini},
  doi          = {10.1016/j.neucom.2021.01.090},
  journal      = {Neurocomputing},
  pages        = {428-437},
  shortjournal = {Neurocomputing},
  title        = {Bayesian neural networks with maximum mean discrepancy regularization},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Least auxiliary loss-functions with impact growth adaptation
(laliga) for convolutional neural networks. <em>NEUCOM</em>,
<em>453</em>, 413–427. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model selection is a challenge, and a popular Convolutional Neural Networks (CNN) usually takes extra-need parameters. It causes overfitting in real applications. Besides, the extracted hidden features would be lost when the number of convolution layers increases. We use the least auxiliary loss-functions to solve both of these problems. To this end, an optimization problem is stated to select a set of layers with the highest contributions in the training process. Also, an impact growth adaptation procedure adjusts the weights of losses. The constructed Least Auxiliary Loss-functions with Impact Growth Adaptation (Laliga) is a professional forum to select the best settings of auxiliary loss functions for CNNs training. Laliga memorizes the hidden features carefully and better represents the space by using non-redundant and more relevant features. Also, it uses singular value decomposition to regularize the weights. The theoretical results show that Laliga decreases overfitting substantially. Although this algorithm is useful for all CNN models, its results are auspicious for Visual Geometry Group (VGG) networks. The testing accuracies of Laliga for different VGG models on MNIST, CIFAR-10, and CIFAR-100 datasets are 99.7\% 99.7\% , 92.3\% 92.3\% , and 73.4\% 73.4\% , indicating Laliga overcomes many regularization methods in the dropout family. Besides, on more complicated datasets Caltech-101 and Caltech-256, its accuracies raise than 66.1\% 66.1\% and 33.2\% 33.2\% , which are better than dropout and close to Adaptive Spectral Regularization (ASR) results, although Laliga converges rapidly than ASR. Finally, we analyze the results of Laliga in a transportation case study.},
  archive      = {J_NEUCOM},
  author       = {Mohammad Mahdi Bejani and Mehdi Ghatee},
  doi          = {10.1016/j.neucom.2021.01.106},
  journal      = {Neurocomputing},
  pages        = {413-427},
  shortjournal = {Neurocomputing},
  title        = {Least auxiliary loss-functions with impact growth adaptation (Laliga) for convolutional neural networks},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level dictionary learning for fine-grained images
categorization with attention model. <em>NEUCOM</em>, <em>453</em>,
403–412. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fine-grained image categorization is a challenging task due to the difficulty of localizing the discriminative regions for different sub-categories. Previous works mainly focus on using the manual annotations or the attention algorithm to localize these regions, which is demanding and complex in practical applications. This paper proposes a method of using a multi-level attention model (MLA-CNN) which has been trained on the full-size image train set of current tasks to localize the most discriminative regions. Intuitively, three typical receptive field sizes are selected for the multi-level attention maps. Then, multi-level dictionary learning is introduced to extract discriminative features from these localized regions. Our method explores a new thought about how to use the neural activations to generate multi-scale regions which are helpful for the fine-grained categorization. The method can be achieved in two steps. The first step is to select the neurons that have the max activation in the selected three feature maps. These feature maps are the outputs of the pre-trained CNN model by feeding the full-size images into the model. Then, we generate the discriminative regions according to the receptive field size of the selected neurons. The second step is to train the subtle networks with these multi-scale regions. One scaled discriminative region can be regarded as one typical dictionary feature. Then these results are integrated for final prediction. We evaluate our method on three challenging fine-grained image datasets, CUB-200-2011, Stanford Dogs, and Stanford Cars. The experimental results demonstrate that our method outperforms many state-of-the-art methods, using extra object/parts annotations and attention-based methods.},
  archive      = {J_NEUCOM},
  author       = {Jinsheng Ji and Yiyou Guo and Zhen Yang and Tao Zhang and Xiankai Lu},
  doi          = {10.1016/j.neucom.2020.07.147},
  journal      = {Neurocomputing},
  pages        = {403-412},
  shortjournal = {Neurocomputing},
  title        = {Multi-level dictionary learning for fine-grained images categorization with attention model},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pairwise attention network for cross-domain image
recognition. <em>NEUCOM</em>, <em>453</em>, 393–402. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the domain adaption has received wide attention from machine learning communities because of differences in data distribution or the lack of training data in a practical machine learning task. In this work, we propose a P airwise A ttention N etwork ( PAN for short) for addressing cross-domain image recognition task. In this model, different local features and the global-feature are concatenated to obtain different attention estimators, and then they are combined to get the attention map. In this way, we can focus on the important parts of an image, and ignore the irrelative regions. Moreover, attention consistency is also embedded in PAN to make sure consistent interest regions in the same class. Besides, to improve the feature discrimination, an embedding discriminative subspace is learned where it maps positive sample pairs aligned in a hypersphere and negative sample pairs separated. Extensive experimental results on the MNIST-USPS, office, and Visda-2017 datasets demonstrate that PAN can outperform state-of-the-art methods in terms of average accuracy.},
  archive      = {J_NEUCOM},
  author       = {Zan Gao and Yanbo Liu and Guangpin Xu and Xianbin Wen},
  doi          = {10.1016/j.neucom.2020.06.147},
  journal      = {Neurocomputing},
  pages        = {393-402},
  shortjournal = {Neurocomputing},
  title        = {Pairwise attention network for cross-domain image recognition},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Streamer action recognition in live video with
spatial-temporal attention and deep dictionary learning.
<em>NEUCOM</em>, <em>453</em>, 383–392. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Live video hosted by streamer is being sought after by more and more Internet users. A few streamers show inappropriate action in normal live video content for profit and popularity, who bring great harm to the network environment. In order to effectively regulate the streamer behavior in live video, a streamer action recognition method in live video with spatial-temporal attention and deep dictionary learning is proposed in this paper. First, deep features with spatial context are extracted by a spatial attention network to focus on action region of streamer after sampling video frames from live video. Then, deep features of video are fused by assigning weights with a temporal attention network to learn the frame attention from an action. Finally, deep dictionary learning is used to sparsely represent the deep features to further recognize streamer actions. Four experiments are conducted on a real-world dataset, and the competitive results demonstrate that our method can improve the accuracy and speed of streamer action recognition in live video.},
  archive      = {J_NEUCOM},
  author       = {Chenhao Li and Jing Zhang and Jiacheng Yao},
  doi          = {10.1016/j.neucom.2020.07.148},
  journal      = {Neurocomputing},
  pages        = {383-392},
  shortjournal = {Neurocomputing},
  title        = {Streamer action recognition in live video with spatial-temporal attention and deep dictionary learning},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward blind joint demosaicing and denoising of raw color
filter array data. <em>NEUCOM</em>, <em>453</em>, 369–382. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Raw color-filter-array (CFA) data collected in the real world are often noisy and signal-dependent, which makes it difficult to recover the full-resolution noise-free color image. Denoising and demosaicing are two popular tools developed for noisy CFA data in modern color imaging pipeline. However, most existing works on joint demosaicing and denoising (JDD) are based on ad hoc assumptions about image degradation process ; while in practice little is known about noise statistics (e.g., noise level) and processing pipeline (e.g., gamma correction). We advocate a blind formulation of joint demosaicing and denoising (bJDD) problem in this paper and present a novel divide-and-conquer approach toward blind reconstruction from noisy raw CFA data. Instead of making over-simplified assumptions about noise statistics, we propose to develop a more realistic Poisson-Gaussian noise model for simulating noisy raw CFA data in the real world. We also introduce a sub-network to adaptively estimate the noise level map from the noisy input, which will provide supplementary information to the deep model for non-blind JDD. Finally, we have adopted a generative adversarial network (GAN) based network for further perceptual optimization. Our extensive experimental results have shown convincingly improved performance over existing state-of-the-art methods in terms of both subjective and objective quality metrics.},
  archive      = {J_NEUCOM},
  author       = {Fangfang Wu and Tao Huang and Weisheng Dong and Guangming Shi and Zhonglong Zheng and Xin Li},
  doi          = {10.1016/j.neucom.2020.09.090},
  journal      = {Neurocomputing},
  pages        = {369-382},
  shortjournal = {Neurocomputing},
  title        = {Toward blind joint demosaicing and denoising of raw color filter array data},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cascaded SE-ResUnet for segmentation of thoracic organs at
risk. <em>NEUCOM</em>, <em>453</em>, 357–368. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computed Tomography (CT) has been widely used in the planning of radiation therapy , which is one of the most effective clinical lung cancer treatment options. Accurate segmentation of organs at risk (OARs) in thoracic CT images is a key step for radiotherapy planning to prevent healthy organs from getting over irradiation. However, known automatic image segmentation methods can hardly yield desired OAR delineation results, while manual delineation tends to take long time and tedious effort. In this paper, we propose a novel deep learning network, called cascaded SE-ResUnet, for automatic segmentation of thoracic organs including left lung, right lung, heart, esophagus, trachea, and spinal cord. Specifically, we first use a coarse segmentation network to identify the regions of interest (ROIs), and then a fine segmentation network is applied to achieve refined segmentation results, organ by organ. Finally, different configured models are ensembled to obtain the final segmentation results. In the StructSeg 2019 Challenge, we showed the capability of our new framework and won the 1st place at the test phase. Our code is available open-source at https://github.com/zjuybh/StructSeg2019.},
  archive      = {J_NEUCOM},
  author       = {Zheng Cao and Bohan Yu and Biwen Lei and Haochao Ying and Xiao Zhang and Danny Z. Chen and Jian Wu},
  doi          = {10.1016/j.neucom.2020.08.086},
  journal      = {Neurocomputing},
  pages        = {357-368},
  shortjournal = {Neurocomputing},
  title        = {Cascaded SE-ResUnet for segmentation of thoracic organs at risk},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A semi-supervised deep convolutional framework for signet
ring cell detection. <em>NEUCOM</em>, <em>453</em>, 347–356. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early detection of signet ring cell carcinoma (SRCC) can significantly improve patient survival rate. Pathological image analysis is applied as the golden standard for SRCC diagnosis. Automatic detection of pathological cells with deep learning methods can greatly reduce the burden of pathologists. Deep learning methods are commonly trained using large amounts of annotated data. However, due to the uneven distribution of medical resources and tedious manual examination procedure of high-resolution images, annotation data are usually insufficient and incomplete for deep learning model training. In this paper, we propose a new semi-supervised deep convolutional framework to address the data annotation problem for signet ring cell detection. Specifically, we propose a self-training strategy to generate pseudo bounding boxes based on Test Time Augmentation and modified Non-Maximum Suppression to re-train our detector. Our framework achieves 0.8774 in Valid Recall and 100.00 in FPs , winning the 1 st 1st place in the signet ring cell detection task of the Digestive-System Pathological Detection and Segmentation Challenge 2019. Code has been made publicly available at: https://github.com/ooooverflow/DigestPath2019.},
  archive      = {J_NEUCOM},
  author       = {Haochao Ying and Qingyu Song and Jintai Chen and Tingting Liang and Jingjing Gu and Fuzhen Zhuang and Danny Z. Chen and Jian Wu},
  doi          = {10.1016/j.neucom.2020.05.119},
  journal      = {Neurocomputing},
  pages        = {347-356},
  shortjournal = {Neurocomputing},
  title        = {A semi-supervised deep convolutional framework for signet ring cell detection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decoupled gradient harmonized detector for partial
annotation: Application to signet ring cell detection. <em>NEUCOM</em>,
<em>453</em>, 337–346. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early diagnosis of signet ring cell carcinoma dramatically improves the survival rate of patients. Due to lack of public dataset and expert-level annotations, automatic detection on signet ring cell (SRC) has not been thoroughly investigated. In MICCAI DigestPath2019 challenge, apart from foreground (SRC region)-background (normal tissue area) class imbalance, SRCs are partially annotated due to costly medical image annotation, which introduces extra label noise. To address the issues simultaneously, we propose Decoupled Gradient Harmonizing Mechanism (DGHM) and embed it into classification loss, denoted as DGHM-C loss. Specifically, besides positive (SRCs) and negative (normal tissues) examples, we further decouple noisy examples from clean examples and harmonize the corresponding gradient distributions in classification respectively. Without whistles and bells, we achieved the 2nd place in the challenge. Ablation studies and controlled label missing rate experiments demonstrate that DGHM-C loss can bring substantial improvement in partially annotated object detection.},
  archive      = {J_NEUCOM},
  author       = {Tiancheng Lin and Yuanfan Guo and Canqian Yang and Jiancheng Yang and Yi Xu},
  doi          = {10.1016/j.neucom.2020.03.128},
  journal      = {Neurocomputing},
  pages        = {337-346},
  shortjournal = {Neurocomputing},
  title        = {Decoupled gradient harmonized detector for partial annotation: Application to signet ring cell detection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Obtaining leaner deep neural networks for decoding brain
functional connectome in a single shot. <em>NEUCOM</em>, <em>453</em>,
326–336. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroscientific knowledge points to the presence of redundancy in the correlations of the brain’s functional activity. These redundancies can be removed to mitigate the problem of overfitting when deep neural network (DNN) models are used to classify neuroimaging datasets. We propose an algorithm that removes insignificant nodes of DNNs in a layerwise manner and then adds a subset of correlated features in a single shot. When performing experiments with functional MRI datasets for classifying patients from healthy controls, we were able to obtain simpler and more generalizable DNNs . The obtained DNNs maintained a similar performance as the full network with only around 2\% of the initial trainable parameters. Further, we used the trained network to identify salient brain regions and connections from functional connectome for multiple brain disorders. The identified biomarkers were found to closely correspond to previously known disease biomarkers. The proposed methods have cross-modal applications in obtaining leaner DNNs that seem to fit neuroimaging data better. The corresponding code is available at https://github.com/SCSE-Biomedical-Computing-Group/LEAN_CLIP.},
  archive      = {J_NEUCOM},
  author       = {Sukrit Gupta and Yi Hao Chan and Jagath C. Rajapakse and The Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.neucom.2020.04.152},
  journal      = {Neurocomputing},
  pages        = {326-336},
  shortjournal = {Neurocomputing},
  title        = {Obtaining leaner deep neural networks for decoding brain functional connectome in a single shot},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic whole slide pathology image diagnosis framework
via unit stochastic selection and attention fusion. <em>NEUCOM</em>,
<em>453</em>, 312–325. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.153">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pathology tissue slides are taken as the gold standard for the diagnosis of most cancer diseases. Automatic pathology slide diagnosis is still a challenging task for researchers because of the high-resolution, significant morphological variation, and ambiguity between malignant and benign regions in whole slide images (WSIs). In this study, we introduce a general framework to automatically diagnose different types of WSIs via unit stochastic selection and attention fusion. For example, a unit can denote a patch in a histopathology slide or a cell in a cytopathology slide. To be specific, we first train a unit-level convolutional neural network (CNN) to perform two tasks: constructing feature extractors for the units and for estimating a unit’s non-benign probability. Then we use our novel stochastic selection algorithm to choose a small subset of units that are most likely to be non-benign, referred to as the Units Of Interest (UOI), as determined by CNN. Next, we use the attention mechanism to fuse the representations of the UOI to form a fixed-length descriptor for the WSI’s diagnosis. We evaluate the proposed framework on three datasets: histological thyroid frozen sections, histological colonoscopy tissue slides, and cytological cervical pap smear slides. The framework achieves diagnosis accuracies higher than 0.8 and AUC values higher than 0.85 in all three applications. Experiments demonstrate the generality and effectiveness of the proposed framework and its potentiality for clinical applications.},
  archive      = {J_NEUCOM},
  author       = {Pingjun Chen and Yun Liang and Xiaoshuang Shi and Lin Yang and Paul Gader},
  doi          = {10.1016/j.neucom.2020.04.153},
  journal      = {Neurocomputing},
  pages        = {312-325},
  shortjournal = {Neurocomputing},
  title        = {Automatic whole slide pathology image diagnosis framework via unit stochastic selection and attention fusion},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view convolutional recurrent neural networks for lung
cancer nodule identification. <em>NEUCOM</em>, <em>453</em>, 299–311.
(<a href="https://doi.org/10.1016/j.neucom.2020.06.144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Screening via low-dose Computer Tomography (CT) has been shown to reduce lung cancer mortality rates by at least 20\%. However, the assessment of large numbers of CT scans by radiologists is cost intensive, and potentially produces varying and inconsistent results for differing radiologists (and also for temporally-separated assessments by the same radiologist). To overcome these challenges, computer aided diagnosis systems based on deep learning methods have proved effective in automatic detection and classification of lung cancer. Latterly, interest has focused on the full utilization of the 3D information in CT scans using 3D-CNNs and related approaches. However, such approaches do not intrinsically correlate size and shape information between slices. In this work, an innovative approach Multi-view Convolutional Recurrent Neural Network (MV-CRecNet) is proposed that exploits shape, size and cross-slice variations while learning to identify lung cancer nodules from CT scans. The multiple-views that are passed to the model ensure better generalization and the learning of robust features. We evaluate the proposed MV-CRecNet model on the reference Lung Image Database Consortium and Image Database Resource Initiative and Early Lung Cancer Action Program datasets; six evaluation metrics are applied to eleven comparison models for testing. Results demonstrate that proposed methodology outperforms all of the models against all of the evaluation metrics.},
  archive      = {J_NEUCOM},
  author       = {Mian Muhammad Naeem Abid and Tehseen Zia and Mubeen Ghafoor and David Windridge},
  doi          = {10.1016/j.neucom.2020.06.144},
  journal      = {Neurocomputing},
  pages        = {299-311},
  shortjournal = {Neurocomputing},
  title        = {Multi-view convolutional recurrent neural networks for lung cancer nodule identification},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mask-MCNet: Tooth instance segmentation in 3D point clouds
of intra-oral scans. <em>NEUCOM</em>, <em>453</em>, 286–298. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computational dentistry uses computerized methods and mathematical models for dental image analysis. One of the fundamental problems in computational dentistry is accurate tooth instance segmentation in high-resolution mesh data of intra-oral scans (IOS). This paper presents a new computational model based on deep neural networks , called Mask-MCNet , for end-to-end learning of tooth instance segmentation in 3D point cloud data of IOS. The proposed Mask-MCNet localizes each tooth instance by predicting its 3D bounding box and simultaneously segments the points that belong to each individual tooth instance. The proposed model processes the input raw 3D point cloud in its original spatial resolution without employing a voxelization or down-sampling technique. Such a characteristic preserves the finely detailed context in data like fine curvatures in the border between adjacent teeth and leads to a highly accurate segmentation as required for clinical practice (e.g. orthodontic planning). The experiments show that the Mask-MCNet outperforms state-of-the-art models by achieving 98\% Intersection over Union (IoU) score on tooth instance segmentation which is very close to human expert performance.},
  archive      = {J_NEUCOM},
  author       = {Farhad Ghazvinian Zanjani and Arash Pourtaherian and Svitlana Zinger and David Anssari Moin and Frank Claessen and Teo Cherici and Sarah Parinussa and Peter H.N. de With},
  doi          = {10.1016/j.neucom.2020.06.145},
  journal      = {Neurocomputing},
  pages        = {286-298},
  shortjournal = {Neurocomputing},
  title        = {Mask-MCNet: Tooth instance segmentation in 3D point clouds of intra-oral scans},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bio-inspired adaptive formation tracking control for swarm
systems with application to UAV swarm systems. <em>NEUCOM</em>,
<em>453</em>, 272–285. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive formation tracking problems for swarm systems with multiple leaders and switching topologies are studied in this paper. It is required that the followers form time-varying formations and track the positions of the leaders simultaneously, where the bio-inspired adaptive formation tracking control method is originated from the grey wolves with strict hierarchy and flexible communication structure. First, the grey wolf tracking strategy with four steps, including of level division, locating the prey, following the leaders, and encircling, is applied to swarm systems. Second, the adaptive formation tracking control protocol using neighboring relative state information is designed for swarm systems to achieve the adaptive formation tracking with switching topologies . Finally, the experiments of Unmanned Aerial Vehicle (UAV) swarm systems are performed using the visible simulation platform based on the Robot Operating System (ROS) and Gazebo to verify the adaptive formation tracking method. Inspired from the grey wolf tracking strategy, the adaptive formation tracking control method has been proposed, which improves the system stability and precision of the formation tracking.},
  archive      = {J_NEUCOM},
  author       = {Yuxin Xie and Liang Han and Xiwang Dong and Qingdong Li and Zhang Ren},
  doi          = {10.1016/j.neucom.2021.05.015},
  journal      = {Neurocomputing},
  pages        = {272-285},
  shortjournal = {Neurocomputing},
  title        = {Bio-inspired adaptive formation tracking control for swarm systems with application to UAV swarm systems},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain adaptation of object detector using scissor-like
networks. <em>NEUCOM</em>, <em>453</em>, 263–271. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When the training data and the test data do not obey the same distribution, the performances of many object detection methods always decrease greatly. Naturally, domain adaptation methods at feature level are proposed. The basic idea is to adapt the feature extraction network such that the feature distributions of the source and target domains match. We propose a new method that is built directly on the Faster R-CNN model, which not only aligns the source and target data features, but also forces their generated features closer together to further align the source and target domains. Moreover, compared with previous approaches, we construct a more powerful discriminator and a simple generator to solve the domain adaptation problem. The model works like a pair of scissors, so we call it Scissors Networks (SN). We conduct extensive experiments on popular datasets, including Cityscapes, Foggy Cityscapes, SIM10k and KITTI. The experimental results demonstrate that our algorithm is superior to the state-of-the-art deep learning based domain adaptation approaches.},
  archive      = {J_NEUCOM},
  author       = {Lin Xiong and Mao Ye and Dan Zhang and Yan Gan and Dongde Hou},
  doi          = {10.1016/j.neucom.2021.05.012},
  journal      = {Neurocomputing},
  pages        = {263-271},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptation of object detector using scissor-like networks},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identifying adverse drug reaction entities from social media
with adversarial transfer learning model. <em>NEUCOM</em>, <em>453</em>,
254–262. (<a
href="https://doi.org/10.1016/j.neucom.2021.05.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying adverse drug reaction (ADR) entities from texts is a crucial task for pharmacology, and it is the basis for the ADR relation extraction task. The publicly available resources on this task include PubMed abstracts, social media, and other resources. Among these resources, social media data can reflect the reactions of drug users after taking medicine in real-time and update quickly. However, a very small quantity of annotated social media data leads to less research on these data. Moreover, social media data have colloquialism and informal vocabulary expression problems, which pose a major challenge for ADR named entity recognition (NER). In this work, we present an adversarial transfer learning architecture for the ADR NER task. Our model improves the performance on Twitter data (target resource) by incorporating biomedical domain information from PubMed (source resource). Additionally, we set the scale parameter in the final loss function to address the problem of bias in model training caused by imbalanced amounts of data. Without adding any additional manually designed features, our approach achieves state-of-the-art performance with an F1 on Twitter ADR data of 68.58\%.},
  archive      = {J_NEUCOM},
  author       = {Tongxuan Zhang and Hongfei Lin and Yuqi Ren and Zhihao Yang and Jian Wang and Xiaodong Duan and Bo Xu},
  doi          = {10.1016/j.neucom.2021.05.007},
  journal      = {Neurocomputing},
  pages        = {254-262},
  shortjournal = {Neurocomputing},
  title        = {Identifying adverse drug reaction entities from social media with adversarial transfer learning model},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised feature selection via multi-step markov
probability relationship. <em>NEUCOM</em>, <em>453</em>, 241–253. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a widely used dimension reduction technique to select feature subsets because of its interpretability . Many methods have been proposed and achieved good results, in which the relationships between adjacent data points are mainly concerned. But the possible associations between data pairs that are not adjacent are always neglected. Different from previous methods, we propose a novel and very simple approach for unsupervised feature selection, named MMFS (Multi-step Markov Probability Relationship for Feature Selection). The idea is using multi-step Markov transition probability to describe the relation between any data pair. Two ways from the positive and negative viewpoints are employed respectively to keep the data structure after feature selection. From the positive viewpoint, the maximum transition probability that can be reached in a certain number of steps is used to describe the relation between two points. Then, the features which can keep the compact data structure are selected. From the viewpoint of negative, the minimum transition probability that can be reached in a certain number of steps is used to describe the relation between two points. On the contrary, the features that least maintain the loose data structure are selected. The two ways can also be combined. Thus three algorithms are proposed. Our main contributions are a novel feature section approach which uses multi-step transition probability to characterize the data structure, and three algorithms proposed from the positive and negative aspects for keeping data structure and select the features to preserve such structure. The performance of our approach is compared with the state-of-the-art methods on eight real-world data sets, and the experimental results show that the proposed MMFS is effective in unsupervised feature selection.},
  archive      = {J_NEUCOM},
  author       = {Yan Min and Mao Ye and Liang Tian and Yulin Jian and Ce Zhu and Shangming Yang},
  doi          = {10.1016/j.neucom.2021.04.073},
  journal      = {Neurocomputing},
  pages        = {241-253},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised feature selection via multi-step markov probability relationship},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Document image classification: Progress over two decades.
<em>NEUCOM</em>, <em>453</em>, 223–240. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Document image classification plays a vital role in the document image processing system. Thus it is of great importance to have a clear understanding of the state-of-the-art of the document image classification field, especially in this deep learning era, which will facilitate the development of effective document image processing systems. In this paper, we provide a comprehensive survey of the progress that has been made in the field of document image classification over the past two decades. We categorize the document images into non-mobile images and mobile images according to the way they are acquired. The existing document image classification methods for these two types of images are reviewed, which are classified as textual-based methods, structural-based methods, visual-based methods and hybrid methods. We further compare the performance of different classification methods on several public benchmark datasets. Finally, we highlight some open issues and recommend promising directions for future research.},
  archive      = {J_NEUCOM},
  author       = {Li Liu and Zhiyu Wang and Taorong Qiu and Qiu Chen and Yue Lu and Ching Y. Suen},
  doi          = {10.1016/j.neucom.2021.04.114},
  journal      = {Neurocomputing},
  pages        = {223-240},
  shortjournal = {Neurocomputing},
  title        = {Document image classification: Progress over two decades},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential synchronization of directed bipartite networks
with node delays and hybrid coupling via impulsive pinning control.
<em>NEUCOM</em>, <em>453</em>, 209–222. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bipartite networks, which comprise two classes of nonoverlapping nodes with links existing only between nodes in different classes, are natural models for many practical systems. Currently, most researches on network synchronization have been focusing on unipartite networks, and relatively few works have been done on bipartite networks. This paper aims to investigate the impulsive pinning control problem for synchronization of directed delayed bipartite networks with node delays and hybrid coupling. By using the methods of average impulsive interval and mathematical induction , some sufficient conditions ensuring global exponential synchronization of the addressed networks are derived. Here, a more flexible impulsive pinning scheme is proposed, which allows the set of pinned nodes as well as the corresponding number of pinned nodes to be different at distinct impulsive instants. Furthermore, an index called impulse pinned proportion is introduced, and the lower bound of impulse pinned proportions is determined, based on which a simple guide to picking what kind of nodes as pinned candidates is given. Some numerical simulations are finally presented to verify the correctness of the derived theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Yafei Shen and Jinyao Shi and Shuiming Cai},
  doi          = {10.1016/j.neucom.2021.04.097},
  journal      = {Neurocomputing},
  pages        = {209-222},
  shortjournal = {Neurocomputing},
  title        = {Exponential synchronization of directed bipartite networks with node delays and hybrid coupling via impulsive pinning control},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). WGLSM: An end-to-end line matching network based on graph
convolution. <em>NEUCOM</em>, <em>453</em>, 195–208. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Line matching plays an essential role in Structure from Motion (SFM) and Simultaneous Localization and Mapping (SLAM), especially in low-texture scenes, where feature points are hard to be detected. In this paper, we present a new method by combining Convolutional Neural Networks and Graph Convolutional Networks to match line segments in pairs of images. We design a graph-based method to predict the assignment matrix of two feature sets with solving a relaxed optimal transport problem. In contrast to handcrafted line matching algorithms , our approach learns the line segment features and performs matching simultaneously through end-to-end weakly supervised training. The experiment results show that our method outperforms the state-of-the-art techniques and is robust to various image transformations. Besides, the generalization experiment illustrates that our method has good generalization ability without fine-tuning. The code of our work is available at https://github.com/mameng1/GraphLineMatching .},
  archive      = {J_NEUCOM},
  author       = {Quanmeng Ma and Guang Jiang and Jiajie Wu and Changshuai Cai and Dianzhi Lai and Zixuan Bai and Hao Chen},
  doi          = {10.1016/j.neucom.2021.04.125},
  journal      = {Neurocomputing},
  pages        = {195-208},
  shortjournal = {Neurocomputing},
  title        = {WGLSM: An end-to-end line matching network based on graph convolution},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kernel alignment unsupervised discriminative dimensionality
reduction. <em>NEUCOM</em>, <em>453</em>, 181–194. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of most existing adaptive graph learning methods, which adjust data similarity matrix according to the data representation, depends on the hypotheses that the data representation is a good indicator of the underlying data structure . However, this hypothesis is not always applicable when dealing with high dimensional data . In this paper, we propose a novel kernel alignment unsupervised discriminative dimensionality reduction (KaUDDR) algorithm. By integrating adaptive graph learning and feature learning into a joint learning framework, graph construction and dimensionality reduction are conducted simultaneously to guarantee the optimality of graph for feature learning in the proposed algorithm. Data kernel and similarity indicator kernel are defined by learned graph and the projected data in a low-dimensional subspace, a compact and discriminative data representation in the projected subspace is obtained by means of kernel alignment to explore the consistency between the projected data kernel and similarity indicator kernel. Experimental results on dimensionality reduction as well as clustering show that our method consistently outperforms the related unsupervised dimensionality reduction algorithm .},
  archive      = {J_NEUCOM},
  author       = {Yunlong Gao and Sizhe Luo and Jinyan Pan and Zhihao Wang and Peng Gao},
  doi          = {10.1016/j.neucom.2021.03.127},
  journal      = {Neurocomputing},
  pages        = {181-194},
  shortjournal = {Neurocomputing},
  title        = {Kernel alignment unsupervised discriminative dimensionality reduction},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bayesian tensorized neural networks with automatic rank
selection. <em>NEUCOM</em>, <em>453</em>, 172–180. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor decomposition is an effective approach to compress over-parameterized neural networks and to enable their deployment on resource-constrained hardware platforms. However, directly applying tensor compression in the training process is a challenging task due to the difficulty of choosing a proper tensor rank. In order to address this challenge, this paper proposes a low-rank Bayesian tensorized neural network. Our Bayesian method performs automatic model compression via an adaptive tensor rank determination. We also present approaches for posterior density calculation and maximum a posteriori (MAP) estimation for the end-to-end training of our tensorized neural network. We provide experimental validation on a two-layer fully connected neural network, a 6-layer CNN and a 110-layer residual neural network where our work produces 7.4 × 7.4× to 137 × 137× more compact neural networks directly from the training while achieving high prediction accuracy.},
  archive      = {J_NEUCOM},
  author       = {Cole Hawkins and Zheng Zhang},
  doi          = {10.1016/j.neucom.2021.04.117},
  journal      = {Neurocomputing},
  pages        = {172-180},
  shortjournal = {Neurocomputing},
  title        = {Bayesian tensorized neural networks with automatic rank selection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Imputation of missing data with class imbalance using
conditional generative adversarial networks. <em>NEUCOM</em>,
<em>453</em>, 164–171. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Missing data is a common problem faced with real-world datasets. Imputation is a widely used technique to estimate the missing data. State-of-the-art imputation approaches model the distribution of observed data to approximate the missing values. Such an approach usually models a single distribution for the entire dataset, which overlooks the class-specific characteristics of the data. Class-specific characteristics are especially useful when there is a class imbalance. We propose a new method for imputing missing data based on its class-specific characteristics by adapting the popular Conditional Generative Adversarial Networks (CGAN). Our Conditional Generative Adversarial Imputation Network (CGAIN) imputes the missing data using class-specific distributions, which can produce the best estimates for the missing values. We tested our approach on baseline datasets and achieved superior performance compared with the state-of-the-art and popular imputation approaches.},
  archive      = {J_NEUCOM},
  author       = {Saqib Ejaz Awan and Mohammed Bennamoun and Ferdous Sohel and Frank Sanfilippo and Girish Dwivedi},
  doi          = {10.1016/j.neucom.2021.04.010},
  journal      = {Neurocomputing},
  pages        = {164-171},
  shortjournal = {Neurocomputing},
  title        = {Imputation of missing data with class imbalance using conditional generative adversarial networks},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Link prediction-based influence maximization in online
social networks. <em>NEUCOM</em>, <em>453</em>, 151–163. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Influence Maximization (IM) is the problem of finding a small set of highly influential users in the social networks. The influence spreads according to an explicit influence propagation model . IM is an essential component in many applications such as Network Monitoring and Viral Marketing. Most of the present IM solutions neglect the highly dynamic behavior of social networks. It can result in either deprived seed qualities or a prolonged processing time. In this paper, we study the IM problem in a social network that evolves with time and proposes a new Link Prediction based Influential Node Tracking (LPINT) framework. In the proposed model, we apply the conditional temporal Restricted Boltzmann Machine (ctRBM) to predict the upcoming snapshot of the graph by predicting the links that may appear in the network by considering the evolutionary network’s temporal and structural pattern. And then, we apply an efficient IM technique for finding the seed nodes in the predicted snapshot of the network. Finally, we evaluate the spread of influence in the latest snapshot of the graph using predicted seed nodes. Extensive experimentation on four real large-scale datasets confirms that our LPINT model attains better performance in terms of influence coverage and influence spread time for considered networks compared to the baseline techniques.},
  archive      = {J_NEUCOM},
  author       = {Ashwini Kumar Singh and Lakshmanan Kailasam},
  doi          = {10.1016/j.neucom.2021.04.084},
  journal      = {Neurocomputing},
  pages        = {151-163},
  shortjournal = {Neurocomputing},
  title        = {Link prediction-based influence maximization in online social networks},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HGEED: Hierarchical graph enhanced event detection.
<em>NEUCOM</em>, <em>453</em>, 141–150. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods that use document-level information for event detection ignore the dependencies between sentences and also have shortcomings in modeling the dependencies among words. In this paper, we propose a novel H ierarchical G raph E nhanced E vent D etection (HGEED) framework to make full use of syntax and document information for the task of event detection. First, a sentence graph is used to model word-to-word dependencies, enriching the local information of words by incorporating syntactic features. Then, a document graph is built to model sentence-to-sentence dependencies, obtaining global semantic representations for word-level prediction. The experiment results on the widely used ACE 2005 and TAC KBP 2015 corpora show that our model can capture local and global information with dependencies and achieve significant improvements as compared to all baselines.},
  archive      = {J_NEUCOM},
  author       = {Jianwei Lv and Zequn Zhang and Li Jin and Shuchao Li and Xiaoyu Li and Guangluan Xu and Xian Sun},
  doi          = {10.1016/j.neucom.2021.04.087},
  journal      = {Neurocomputing},
  pages        = {141-150},
  shortjournal = {Neurocomputing},
  title        = {HGEED: Hierarchical graph enhanced event detection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). VAE-based deep SVDD for anomaly detection. <em>NEUCOM</em>,
<em>453</em>, 131–140. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection is an essential task for different fields in the real world. The imbalanced data and lack of labels make the task challenging. Deep learning models based on autoencoder (AE) have been applied to address the above difficulties successfully. However, in these AE-based deep methods, the AE-based model’s optimization and the anomaly detector design are separated. Therefore, the latent representations in AE are less relevant for the anomaly detection task, which reduces the accuracy of anomaly detection. A deep support vector data description based on variational autoencoder (Deep SVDD-VAE) is proposed in this paper to solve this problem. In the proposed model, VAE is used to reconstruct the input instances, while a spherical discriminative boundary is learned with the latent representations simultaneously based on SVDD. Unlike existing AE-based methods, we seek the model parameters via the joint optimization of VAE and SVDD, which ensures the separability of the latent representations. Experimental results on MNIST, CIFAR-10, and GTSRB datasets show the effectiveness of Deep SVDD-VAE.},
  archive      = {J_NEUCOM},
  author       = {Yu Zhou and Xiaomin Liang and Wei Zhang and Linrang Zhang and Xing Song},
  doi          = {10.1016/j.neucom.2021.04.089},
  journal      = {Neurocomputing},
  pages        = {131-140},
  shortjournal = {Neurocomputing},
  title        = {VAE-based deep SVDD for anomaly detection},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-source propagation aware network clustering☆.
<em>NEUCOM</em>, <em>453</em>, 119–130. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network cluster analysis is of great importance as it is closely related to diverse applications, such as social community detection, biological module identification, and document segmentation. Aiming to effectively uncover clusters in the network data, a number of computational approaches, which utilize network topology , single vector of vertex features, or both the aforementioned, have been proposed. However, most prevalent approaches are incapable of dealing with those contemporary network data whose vertices are characterized by features collected from multiple sources. To address this challenge, in this paper, we propose a novel framework, dubbed Multi-Source Propagation Aware Network Clustering (MSPANC) for uncovering clusters in network data possessing multiple sources of vertex features. Different from most previous approaches, MSPANC is able to infer the cluster preference for each vertex utilizing both network topology and multi-source vertex features. To improve the practical significance of the discovered clusters, the learning of cluster membership is also involved into the modeling of the maximization of intra-cluster propagation regarding multi-source features. We propose a unified objective function for MSPANC to perform the clustering task and derive an alternative manner of learning algorithm for model optimization. Besides, we theoretically prove the convergence of the algorithm for optimizing MSPANC. The proposed model has been tested on five real-world datasets, including social, biological and document networks, and has been compared with several competitive baselines. The remarkable experimental results validate the effectiveness of MSPANC.},
  archive      = {J_NEUCOM},
  author       = {Tiantian He and Yew-Soon Ong and Pengwei Hu},
  doi          = {10.1016/j.neucom.2021.04.064},
  journal      = {Neurocomputing},
  pages        = {119-130},
  shortjournal = {Neurocomputing},
  title        = {Multi-source propagation aware network clustering☆},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BIOT: Explaining multidimensional nonlinear MDS embeddings
using the best interpretable orthogonal transformation. <em>NEUCOM</em>,
<em>453</em>, 109–118. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dimensionality reduction (DR) is a popular approach to data exploration in which instances in a given dataset are mapped to a lower-dimensional representation or “embedding.” For nonlinear dimensionality reduction (NLDR), the dimensions of the embedding may be difficult to understand. In such cases, it may be useful to learn how the different dimensions relate to a set of external features (i.e., relevant features that were not used for the DR). A variety of methods (e.g., PROFIT and BIR) use external features to explain embeddings generated by NLDR methods with rotation-invariant objective functions, such as multidimensional scaling (MDS). However, these methods are restricted to two-dimensional embeddings. In this paper, we propose BIOT , which makes it possible to explain an MDS embedding with any number of dimensions without requiring visualization.},
  archive      = {J_NEUCOM},
  author       = {Adrien Bibal and Rebecca Marion and Rainer von Sachs and Benoît Frénay},
  doi          = {10.1016/j.neucom.2021.04.088},
  journal      = {Neurocomputing},
  pages        = {109-118},
  shortjournal = {Neurocomputing},
  title        = {BIOT: Explaining multidimensional nonlinear MDS embeddings using the best interpretable orthogonal transformation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Erase then grow: Generating correct class activation maps
for weakly-supervised semantic segmentation. <em>NEUCOM</em>,
<em>453</em>, 97–108. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In spite of extremely challenging, the weakly-supervised semantic segmentation using image-level labels has made encouraging progress in the recent phase. The existing methods mainly adopt two-stage training procedures: a) optimizing class activation map (CAM) produced by the multi-label classification network to generate pseudo ground truth; b) training a conventional fully supervised semantic segmentation network through pseudo ground truth. When optimizing CAM, most advanced methods just consider the problem that CAM can only activate the sparse and discriminative regions for each class. However, since the loss function of the classification task is image-level supervision, classification network is weak in capturing intricate contextual information, which results in another problem that many misclassified regions are activated in CAM. Compared with classification networks, the loss function of semantic segmentation tasks is pixel-level supervision, which makes it better at capturing intricate contextual information. Thus, based on this ability of the segmentation network, we propose an erasing module to erase the misclassified regions in the CAM. Furthermore, to transform the sparse CAM into high-quality dense pseudo ground truth, we apply the proposed hierarchical deep seeded region growing (H-DSRG) on the erased CAM. Finally, we conduct extensive analysis to validate the proposed method. The proposed method achieves 66.8 of mIoU for Pascal voc 2012 val dataset and 67.6 of mIoU for Pascal voc 2012 test dataset, harvesting new state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Yanwen Chong and Xiaoshu Chen and Yulong Tao and Shaoming Pan},
  doi          = {10.1016/j.neucom.2021.04.103},
  journal      = {Neurocomputing},
  pages        = {97-108},
  shortjournal = {Neurocomputing},
  title        = {Erase then grow: Generating correct class activation maps for weakly-supervised semantic segmentation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Defect detection in CT scans of cast aluminum parts: A
machine vision perspective. <em>NEUCOM</em>, <em>453</em>, 85–96. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the many applications of X-ray computed tomography (CT) in industry is the detection of pores, cavities and other flaws in cast metal parts. Because of its improvement on part safety and saving of expenses, CT inspection is moving from a random sample inspection towards a full in-line inspection. With the increasing amount of produced data, however, comes the need for an automated processing. Due to tight time constraints the resulting CT scans are very artifact afflicted, which impedes automated inspection. In recent years, deep learning methods—convolutional neural networks in particular—have been used with great success to tackle even complex segmentation tasks in cluttered scenes. As we show, these methods are also applicable to the domain of industrial CT data: they are able to cope with noise, beam hardening, scatter and other artifacts which we encounter here. However, these methods need a vast amount of precisely labeled training data to work properly. Gathering the necessary data is not only cumbersome due to the need of annotating three-dimensional data but also expensive as it requires the knowledge of domain experts. Therefore, we present a new approach: We train our models on realistically simulated CT data only. Here, a precise per-voxel ground truth can simply be computed. In order to show that the simulated data is sufficient to train a segmentation network, we turn to its prediction performance on real CT data. We compare the prediction performance of traditional algorithms as well as the trained segmentation network on simulated and real validation data and demonstrate that they behave similarly. The ground truth for the real validation data is hand-labeled using high-quality CT scans, while the actual validation set consists of CT scans of lower quality of the exact same parts. For a comprehensive evaluation, we evaluate the probability of detection as well as the intersection over union. The first tells us how likely a flaw of given size can be found with a given confidence, which is of special interest to domain experts. The latter gives us a per-voxel information of how precise the overall segmentation is. Moreover, our synthetic data enables us to examine the influence of different artifact types on the detection rate. Besides these quantitative analyses we show some qualitative results of real-world applications. To the best of our knowledge, we describe the first approach for defect detection in three-dimensional CT data, which is solely trained with simulated data.},
  archive      = {J_NEUCOM},
  author       = {Patrick Fuchs and Thorben Kröger and Christoph S. Garbe},
  doi          = {10.1016/j.neucom.2021.04.094},
  journal      = {Neurocomputing},
  pages        = {85-96},
  shortjournal = {Neurocomputing},
  title        = {Defect detection in CT scans of cast aluminum parts: A machine vision perspective},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-objective search of robust neural architectures
against multiple types of adversarial attacks. <em>NEUCOM</em>,
<em>453</em>, 73–84. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many existing deep learning models are vulnerable to adversarial examples that are imperceptible to humans. To address this issue, various methods have been proposed to design network architectures that are robust to one particular type of adversarial attacks . It is practically impossible, however, to predict beforehand which type of attacks a machine learn model may suffer from. To address this challenge, we propose to search for deep neural architectures that are robust to five types of well-known adversarial attacks using a multi-objective evolutionary algorithm. To reduce the computational cost, a normalized error rate of a randomly chosen attack is calculated as the robustness for each newly generated neural architecture at each generation. All non-dominated network architectures obtained by the proposed method are then fully trained against randomly chosen adversarial attacks and tested on two widely used datasets. Our experimental results demonstrate the superiority of optimized neural architectures found by the proposed approach over state-of-the-art networks that are widely used in the literature in terms of the classification accuracy under different adversarial attacks.},
  archive      = {J_NEUCOM},
  author       = {Jia Liu and Yaochu Jin},
  doi          = {10.1016/j.neucom.2021.04.111},
  journal      = {Neurocomputing},
  pages        = {73-84},
  shortjournal = {Neurocomputing},
  title        = {Multi-objective search of robust neural architectures against multiple types of adversarial attacks},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). STN-enhanced message passing guided by adversarial learning
for human pose estimation. <em>NEUCOM</em>, <em>453</em>, 60–72. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an STN (Spatial Transformer Network)-enhanced message passing module guided by adversarial learning is proposed for human pose estimation. Transformations performed on the predicted heatmaps mean to modify the raw predictions and conduct the message passing among human joints in an elegant way. Firstly, we employ STN submodule to transform the predicted heatmap of one human joint to heatmap of its neighboring joint to remove ambiguity of its neighboring predictions. STN submodule automatically learns the geometric information between adjacent joints and thus builds related neighboring associations among them. Nevertheless, it seems difficult for STN submodule to learn inherent geometric information from a single RGB image alone. Secondly, limb guidance is introduced to assist STN in predicting corresponding correlations. Since quality of limb predictions poses great significance for the guidance, we propose to exploit adversarial learning to improve the quality of limb heatmaps which are easier to learn than precise keypoint location. Hence, the precision of STN transformation improves owing to more precise prior instructions. However, STN submodule might be confused when performing the transformation due to massive noises of the heatmaps. To circumvent this dilemma, at last, we propose to utilize Weighted Mean Square Error (WMSE) loss and convolutional random walk (CRW) which improve the performance further. Our method achieves competitive results on both MPII and LSP benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhou and Yingying Chen and Congqi Cao and Jinqiao Wang and Hanqing Lu},
  doi          = {10.1016/j.neucom.2021.04.110},
  journal      = {Neurocomputing},
  pages        = {60-72},
  shortjournal = {Neurocomputing},
  title        = {STN-enhanced message passing guided by adversarial learning for human pose estimation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Self-attention feature fusion network for semantic
segmentation. <em>NEUCOM</em>, <em>453</em>, 50–59. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capturing rich contextual information is very helpful for semantic segmentation . In addition, the effective use of low-level details and high-level semantics is crucial for semantic segmentation. In this paper, we start from these two aspects, and we propose a self-attention feature fusion network for semantic segmentation (SA-FFNet) to improve semantic segmentation performance. Specifically, we introduced the vertical and horizontal compression attention module (VH-CAM) and the unequal channel pyramid pooling module (UC-PPM). The previous position attention module, such as the position attention module (PAM) in DANet, calculates the similarity between each pixel and all other pixels. However, the amount of information contained in a single isolated pixel is too small, so the resulting position attention weight is not perfect. Our approach is to compress a feature map from both vertical and horizontal directions so that the information contained in each pixel will be richer, and the spatial feature map obtained from this will be better. Experiments show that the position attention weight generated by our vertical and horizontal compression attention module is better than PAM in DANet. Additionally, our UC-PPM on each decoder can provide high-level rich semantic information to guide the selection of low-level feature maps. The proposed model achieves a 76.42\% mean IoU on PASCAL VOC2012 and a 73.13\% mean IoU on Cityscapes.},
  archive      = {J_NEUCOM},
  author       = {Zhen Zhou and Yan Zhou and Dongli Wang and Jinzhen Mu and Haibin Zhou},
  doi          = {10.1016/j.neucom.2021.04.106},
  journal      = {Neurocomputing},
  pages        = {50-59},
  shortjournal = {Neurocomputing},
  title        = {Self-attention feature fusion network for semantic segmentation},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuromorphic extreme learning machines with bimodal
memristive synapses. <em>NEUCOM</em>, <em>453</em>, 38–49. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biology-inspired intelligent computing system for the neuromorphic hardware implementation is useful in high-speed parallel information processing . However, the traditional Von Neumann computer architecture and the unsatisfactory signal transmission approach have jointly limited the overall performance of the specific hardware implementation. In this paper, a compact extreme learning machine (ELM) architecture synthesized with the spintronic memristor-based synaptic circuit, the biasing circuit, and the activation function circuit is presented. Notably, due to the threshold characteristic of the memristive device, the synaptic circuit has a bimodal behavior . Namely, it is capable to provide the constant and adjustable network weights between the adjacent layers in the ELM. Furthermore, two major limitations (process variations and sneak path issue) are taken into account for the detailed robustness analysis of the whole network. Finally, the entire scheme is verified with case studies in single image super-resolution (SR) reconstruction.},
  archive      = {J_NEUCOM},
  author       = {Zhekang Dong and Chun Sing Lai and Zhaowei Zhang and Donglian Qi and Mingyu Gao and Shukai Duan},
  doi          = {10.1016/j.neucom.2021.04.049},
  journal      = {Neurocomputing},
  pages        = {38-49},
  shortjournal = {Neurocomputing},
  title        = {Neuromorphic extreme learning machines with bimodal memristive synapses},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hard decorrelated centralized loss for fine-grained image
retrieval. <em>NEUCOM</em>, <em>453</em>, 26–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although there is abundant of investigations on fine-grained image retrieval, it is still an extremely challenging task in the field of computer vision, due to the character of small diversity in inter-class but large diversity within intra-class. To handle this task, loss functions are critical to the performance of a deep convolutional neural network in extracting the discriminative feature of the fine-grained image for retrieval. Recent studies showed that the global structure loss functions help to extract more discriminative features. In this paper, we introduce a novel global structure loss function, named Hard Decorrelated Centralized Loss, for further improving the representation for fine-grained image retrieval. The proposed loss is available in extracting the discriminative feature for dividing the most similar categories. In our experiments, we employ the proposed loss to train the convolutional neural network, which shows state-of-the-art performances on six classical fine-grained image retrieval benchmarks, e.g. CUB-200-2011 and Stanford Cars.},
  archive      = {J_NEUCOM},
  author       = {Xianxian Zeng and Shun Liu and Xiaodong Wang and Yun Zhang and Kairui Chen and Dong Li},
  doi          = {10.1016/j.neucom.2021.04.030},
  journal      = {Neurocomputing},
  pages        = {26-37},
  shortjournal = {Neurocomputing},
  title        = {Hard decorrelated centralized loss for fine-grained image retrieval},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel view synthesis approach based on view space covering
for gait recognition. <em>NEUCOM</em>, <em>453</em>, 13–25. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gait recognition has proven to be effective for long-distance human recognition. View angle, one form of the gait variations, can change the human appearance greatly and reduce its performance. For most existing gait datasets, the angle interval between the two nearest views is large. This means that the angle does not cover the entire view space and prevent better view-invariant feature extraction for CNN. Additionally, the angles between cameras and people vary widely in typical camera deployments for monitoring people. In this paper, we, therefore, propose a novel view synthesis approach based on view space covering to deal with the challenge of large-angle interval. Specifically, a Dense-View GEIs Set (DV-GEIs) is introduced to expand this view approach, from 0 ° 0° to 180 ° 180° with 1 ° 1° interval. GEI is a popular feature representation for gait, which can be obtained by aligning human silhouettes and averaging them in a gait cycle. In order to synthesize DV-GEIs set, Dense-View GAN (DV-GAN) is proposed to model the gait attribute distribution and generate new GEIs with various views. DV-GAN consists of a generator, discriminator , and monitor, where the monitor is designed to preserve human identification and view information. Compared with our previous work DV-GAN-pre, we add a center for each object in the monitor to improve the discriminative capability of synthesized images during the modeling process. The proposed method is evaluated on the CASIA-B and OU-ISIR dataset. The experimental results show that view space covering is an effective way to light the burden of view-invariant feature extraction for CNN and make the feature more discriminative. We believe the idea of view space covering will further improve the development of gait recognition.},
  archive      = {J_NEUCOM},
  author       = {Rijun Liao and Weizhi An and Zhu Li and Shuvra S. Bhattacharyya},
  doi          = {10.1016/j.neucom.2021.04.081},
  journal      = {Neurocomputing},
  pages        = {13-25},
  shortjournal = {Neurocomputing},
  title        = {A novel view synthesis approach based on view space covering for gait recognition},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification of acoustic emission sources for structural
health monitoring applications based on convolutional neural networks
and deep transfer learning. <em>NEUCOM</em>, <em>453</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the present work, different types of acoustic emission (AE) sources are identified by means of computational intelligence. The goal is to characterize the type of AE source and to successfully differentiate between sources that are related to an internal damage, such as a fracture initiation, or an external load represented by an elastic impact. A Hsu-Nielsen source (pencil-lead break) and two steel ball impacts of different diameters are selected for the excitation of an aluminum plate equipped with four piezoelectric transducers to record the acoustic emissions. Furthermore, 25 different areas for the AE sources are defined to collect a large database. Three different machine learning architectures are considered, which can predict the type of the AE source. Time domain signals of the acoustic emissions are used for the training of an artificial neural network and a 1D convolutional neural network. Additionally, the wavelet transformation is performed on the captured signals to generate RGB images of the sensor responses and to train a 2D convolutional neural network in combination with deep transfer learning. An error evaluation of each machine learning model is performed to discuss the classification results. The proposed methodology demonstrates that computational intelligence can be applied to accurately identify the type of AE source based on the captured acoustic emission signals.},
  archive      = {J_NEUCOM},
  author       = {Daniel Frank Hesser and Shimaalsadat Mostafavi and Georg Karl Kocur and Bernd Markert},
  doi          = {10.1016/j.neucom.2021.04.108},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Identification of acoustic emission sources for structural health monitoring applications based on convolutional neural networks and deep transfer learning},
  volume       = {453},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability criteria for stochastic neural networks with
unstable subnetworks under mixed switchings. <em>NEUCOM</em>,
<em>452</em>, 827–833. (<a
href="https://doi.org/10.1016/j.neucom.2019.10.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, stability of a class of stochastic neural networks with switching signal is studied. Firstly, by means of the method of limiting average dwell time, we analyze the stability of switched systems which potentially contain unstable subsystems and stable subsystems simultaneously. Moreover, considering two types of switchings: stabilizing switchings and destabilizing switchings, we adopt time-dependent parameters to give a description of the relationship between two successive activated subsystems. Based on the obtained results for switched systems, some stability criteria for switched neural networks with stochastic disturbances are derived. At last, we present a numerical example to demonstrate the effectiveness of our results.},
  archive      = {J_NEUCOM},
  author       = {Yaqi Wang and Jungang Lou and Hongyan Yan and Jianquan Lu},
  doi          = {10.1016/j.neucom.2019.10.119},
  journal      = {Neurocomputing},
  pages        = {827-833},
  shortjournal = {Neurocomputing},
  title        = {Stability criteria for stochastic neural networks with unstable subnetworks under mixed switchings},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). Event-triggered control of second-order nonlinear
multi-agent systems with directed topology. <em>NEUCOM</em>,
<em>452</em>, 820–826. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the distributed event-triggered control problems of second-order nonlinear multi-agent systems (MASs) with directed graph . Firstly, an event-triggered consensus algorithm is developed for second-order nonlinear MASs. It is proved that MASs reach practical consensus and Zeno-behavior doesn&#39;t occur. Secondly, for leader–follower MASs, an event-triggered tracking algorithm is presented, which ensures that follower agents track leader agent even when leader agent has a nonzero input. Finally, a numerical simulation is given to show effectiveness of the proposed consensus algorithm .},
  archive      = {J_NEUCOM},
  author       = {Zhaodong Liu and Ancai Zhang and Jianlong Qiu and Zhenxing Li},
  doi          = {10.1016/j.neucom.2020.03.118},
  journal      = {Neurocomputing},
  pages        = {820-826},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered control of second-order nonlinear multi-agent systems with directed topology},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust stability analysis of stochastic switched neural
networks with parameter uncertainties via state-dependent switching law.
<em>NEUCOM</em>, <em>452</em>, 813–819. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of robust stability analysis for a class of stochastic switched neural networks ( SSNNs ) with time-varying parametric uncertainties is investigated in this paper. Some sufficient conditions are derived to guarantee the robust global asymptotical stability in mean square for the uncertain SSNNs by using state-dependent switching ( SDS ) method. It is shown that the robust stability of uncertain SSNNs composed of all unstable subnetworks can be achieved by using the designed SDS law. Moreover, the proposed sufficient conditions can be easily checked in terms of linear matrix inequalities (LMIs) for conveniently using Matlab toolbox. A numerical example is provided to demonstrate the effectiveness of the proposed SDS law.},
  archive      = {J_NEUCOM},
  author       = {Dan Yang and Xiaodi Li},
  doi          = {10.1016/j.neucom.2019.11.120},
  journal      = {Neurocomputing},
  pages        = {813-819},
  shortjournal = {Neurocomputing},
  title        = {Robust stability analysis of stochastic switched neural networks with parameter uncertainties via state-dependent switching law},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convergence and objective functions of noise-injected
multilayer perceptrons with hidden multipliers. <em>NEUCOM</em>,
<em>452</em>, 796–812. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial neural networks (ANNs) are known to be sensitive to the initial setting of parameters and the network architecture , such as the number of hidden nodes in multilayer perceptron (MLP). In this paper, we focus on a network structure which can help to find the proper number of hidden nodes in MLP. In this structure, so called Multilayer Perceptrons with Hidden Multipliers (MLPHM), each of the hidden nodes is associated with a tunable “gate” multiplier. With a specific regularization term , each gate tends to be opened or closed completely at the end of the training, and finally a pruned network is obtained. To study the fault tolerance and to improve the generalization of MLPHM, a noise-injected training scheme is proposed, with both multiplicative noise and additive noise taken into consideration. The objective functions and convergence theorems of the noise-injected training algorithms are obtained, and the latter have been verified by simulations. Applications to several UCI datasets have demonstrated that the proposed algorithms have efficient pruning ability and superior generalization ability .},
  archive      = {J_NEUCOM},
  author       = {Xiangyu Wang and Jian Wang and Kai Zhang and Feng Lin and Qin Chang},
  doi          = {10.1016/j.neucom.2020.03.119},
  journal      = {Neurocomputing},
  pages        = {796-812},
  shortjournal = {Neurocomputing},
  title        = {Convergence and objective functions of noise-injected multilayer perceptrons with hidden multipliers},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Distributed output tracking of nonlinear multi-agent
systems perturbed by second-order moment processes. <em>NEUCOM</em>,
<em>452</em>, 789–795. (<a
href="https://doi.org/10.1016/j.neucom.2019.10.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we study the distributed output tracking problem for nonlinear multi-agent systems (MASs) perturbed by second-order moment processes. This is in contrast with most of the existing results where only white noise model is considered. For the case where the graph topology is directed and the leader is the neighbor of only a small portion of followers, new distributed tracking control laws are designed via the distributed backstepping method. By using the stochastic analysis tools, it is shown that the output tracking errors between the followers and the leader can be tuned arbitrarily small while all the states of the closed-loop system remain bounded in probability. Finally, the effectiveness of the tracking controller is demonstrated by a simulation example.},
  archive      = {J_NEUCOM},
  author       = {Hui Wang and Wuquan Li and Meiqin Tang},
  doi          = {10.1016/j.neucom.2019.10.120},
  journal      = {Neurocomputing},
  pages        = {789-795},
  shortjournal = {Neurocomputing},
  title        = {Distributed output tracking of nonlinear multi-agent systems perturbed by second-order moment processes},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive finite-time synchronization of stochastic mixed
time-varying delayed memristor-based neural networks. <em>NEUCOM</em>,
<em>452</em>, 781–788. (<a
href="https://doi.org/10.1016/j.neucom.2019.09.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the finite-time synchronization of stochastic memristor-based neural networks with time-varying discrete and distributed delays and discontinuous nonlinear functions via the adaptive state-feedback controller. Based on the theories of set-valued mappings and stochastic differential inclusions, the finite-time synchronization of the drive neural network and response neural network is transformed into the finite-time stabilization problem of the corresponding error stochastic neural network. By choosing an appropriate Lyapunov function and employing the theory of stochastic finite-time stability, we present a method to design the control gain parameters. Finally, an example verifies the validity of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Tianliang Zhang and Feiqi Deng},
  doi          = {10.1016/j.neucom.2019.09.117},
  journal      = {Neurocomputing},
  pages        = {781-788},
  shortjournal = {Neurocomputing},
  title        = {Adaptive finite-time synchronization of stochastic mixed time-varying delayed memristor-based neural networks},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural-network-based optimization and analysis for nonlinear
stochastic systems. <em>NEUCOM</em>, <em>452</em>, 779–780. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Weihai Zhang and Xue-Jun Xie and Jinling Liang},
  doi          = {10.1016/j.neucom.2020.05.079},
  journal      = {Neurocomputing},
  pages        = {779-780},
  shortjournal = {Neurocomputing},
  title        = {Neural-network-based optimization and analysis for nonlinear stochastic systems},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards online myoelectric control based on muscle
synergies-to-force mapping for robotic applications. <em>NEUCOM</em>,
<em>452</em>, 768–778. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The development of a functional myoelectric control represents a big challenge within the researchers community, due to the complexity of mapping the user’s movement intention onto the control signals. It is continuously gaining attention since it could be useful for building natural, intuitive and tailored human–machine interfaces. In this context, muscle synergies-based approaches are playing an important role since they may be useful to exploit the modular organization of the musculoskeletal system. Muscle synergies-based myo-control schemes have shown promising results when they are trained and validated at the same limb pose. However, dealing with a muscle-to-force mapping variability across multiple limb poses remains an open challenge, thus keeping these techniques unusable in several real application scenarios, e.g. rehabilitation contexts. In this paper, the authors propose a method able to compute the synergies-to-force mapping of a new limb pose by interpolation, with the knowledge of the synergies-to-force mapping related to a limited set of limb poses. The proposed interpolation-based approach has been evaluated on three different kind of mappings: muscle-to-force, “Pose-Shared” synergies-to-force and “Pose-Related” synergies-to-force. The muscle-to-force mapping considers a direct map between muscles and hand force. Both synergies-to-force approaches consider a map between muscle synergies and hand force, but, the “Pose-Shared” mapping assumes that the muscle patterns can be factorized using data coming from different limb poses, whereas the “Pose-Related” one assumes that each pose has its own set of muscle primitives that can be clustered together. The generalization capability of the proposed approach has been evaluated by comparing performances obtained in untrained conditions with the ones obtained in trained upper limb poses. Results showed that synergies-based approach substantially reduce the performance loss when tested on untrained upper-limb’s poses, demonstrating that muscle synergies may be suitable to be shared across different working conditions. Moreover, the feasibility of the proposed approach has been preliminary tested in an online condition, demonstrating that the subject was able to accomplish the force task by controlling a virtual cursor with his muscular activations.},
  archive      = {J_NEUCOM},
  author       = {Cristian Camardella and Michele Barsotti and Domenico Buongiorno and Antonio Frisoli and Vitoantonio Bevilacqua},
  doi          = {10.1016/j.neucom.2020.08.081},
  journal      = {Neurocomputing},
  pages        = {768-778},
  shortjournal = {Neurocomputing},
  title        = {Towards online myoelectric control based on muscle synergies-to-force mapping for robotic applications},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relay selection and power allocation for secrecy sum rate
maximization in underlying cognitive radio with cooperative relaying
NOMA. <em>NEUCOM</em>, <em>452</em>, 756–767. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative communication that integrates cognitive radio and non-orthogonal multiple access is recognized as an emerging technology for fifth-generation and beyond wireless networks. However, security is still a critical issue because of the risk that confidential information will be overheard in wireless transmission environments. Thus, physical-layer security appears as a powerful alternative to complement, or even replace, the traditional use of encryption-based approaches. In this paper, we investigate a particle swarm optimization-based power allocation and relay-selection scheme to enhance physical-layer security by maximizing the secrecy sum-rate in a cooperative relaying cognitive radio-non-orthogonal multiple access system. First, we formulate the optimization problem subject to the constraints of minimum data rate at each secondary user and maximum transmission power at the secondary base station and the relay, provided that the interference induced by the base station and the relay on the primary users’ receivers is below an acceptable level. Afterward, we describe the cooperative relaying cognitive radio-orthogonal multiple access system to compare the secrecy sum-rate performance of the proposed system with that of the orthogonal multiple access baseline scheme. Satisfactorily, simulation results show that by applying the non-orthogonal multiple access transmission strategy, our proposed scheme reaches higher secrecy sum-rate than the baseline scheme.},
  archive      = {J_NEUCOM},
  author       = {Carla E. Garcia and Mario R. Camana and Insoo Koo},
  doi          = {10.1016/j.neucom.2020.08.082},
  journal      = {Neurocomputing},
  pages        = {756-767},
  shortjournal = {Neurocomputing},
  title        = {Relay selection and power allocation for secrecy sum rate maximization in underlying cognitive radio with cooperative relaying NOMA},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Bacterial colony algorithm with adaptive attribute learning
strategy for feature selection in classification of customers for
personalized recommendation. <em>NEUCOM</em>, <em>452</em>, 747–755. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a new bacterial colony-based feature selection algorithm to improve the classification accuracy of customers for personalized products recommendation. An attribute learning strategy is developed in this study to update the feature related population. Specifically, the features can be weighted according to their historic contributions to both the individual- and group-based subsets. Additionally, the frequency of appearance is also recorded for the feature candidates to improve the diversity of feature distribution and avoid the over-fitting. Based on the weight-based feature indexes and frequency of appearance records, the performance of feature subsets are enhanced by replacing the features being repeatedly appeared in a same vector. To explore the feasibility of the proposed method for the missing feature problems, the objective of the optimization is to minimize the classification error using the acceptable number of features. K-Nearest Neighbor is employed as the learning technique to cooperate with the proposed feature selection method. The effectiveness of the proposed feature selection method is demonstrated by performing test on the datasets from UCI machine learning repository and real-world data from Amazon customer reviews of products. Compared with other seven feature selections methods, the proposed feature selection algorithm outperforms the other algorithms by achieving higher classification accuracy rate using smaller features.},
  archive      = {J_NEUCOM},
  author       = {Hong Wang and Ben Niu and Lijing Tan},
  doi          = {10.1016/j.neucom.2020.07.142},
  journal      = {Neurocomputing},
  pages        = {747-755},
  shortjournal = {Neurocomputing},
  title        = {Bacterial colony algorithm with adaptive attribute learning strategy for feature selection in classification of customers for personalized recommendation},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey of bacterial foraging optimization.
<em>NEUCOM</em>, <em>452</em>, 728–746. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bacterial foraging optimization algorithm (BFO) is a biological-inspired swarm intelligence optimization algorithm that simulates the foraging behavior of bacteria to obtain maximal energy during the searching process. Since its inception, it has evoked wide attention from researchers. The number of articles about BFO and its variants has grown significantly over the past decades and continues to grow. Hence, there is a clear need for a scientific and comparative review of extant BFO literature based on a common framework that offers a quick glimpse of the development of BFO. In light of this, we develop a bibliometric review via using CiteSpace to construct a knowledge mapping, and then conduct a thorough literature review of BFO research. Based on the analytical results, we present the influential researchers, journals or proceedings, and articles, and discuss various key issues of BFO. Finally, we suggest serval research directions that require further attention. This survey is expected to exhibit a lucid outline and useful guidance for the researchers of BFO.},
  archive      = {J_NEUCOM},
  author       = {Chen Guo and Heng Tang and Ben Niu and Chang Boon Patrick Lee},
  doi          = {10.1016/j.neucom.2020.06.142},
  journal      = {Neurocomputing},
  pages        = {728-746},
  shortjournal = {Neurocomputing},
  title        = {A survey of bacterial foraging optimization},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-stage personalized recommendation based on
multi-objective teaching–learning-based optimization with decomposition.
<em>NEUCOM</em>, <em>452</em>, 716–727. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its successful application in information filtering and knowledge retrieval systems in the era of big data, personalized recommender system plays a significant role in meeting personalized demands of people from big data and has become a hot research hotspot. Traditional recommender systems only guarantee the recommendation accuracy and the recommendation diversity will be lost. In this paper, we propose a two-stage personalized recommendation (TSPR) algorithm based on an improved collaborative filtering (ICF) and multi-objective teaching–learning-based optimization (MOTLBO/D) with decomposition. Firstly, ICF made use of each user’ preference and social neighborhood information to obtain a candidate recommendation list for each target user. In the proposed ICF method , the jump relationship between users and their unrated items was mined to describe the characteristic behavior information of users more fully. Moreover, MOTLBO/D was adopted to simultaneously optimize accuracy and diversity of recommendation list of items for each target user. In the proposed MOTLBO/D algorithm, the learner representation strategy is designed based on attributes of the recommendation problem, and the learners are updated by an improved TLBO procedure. Finally, the simulation results on two Movielens datasets show that TSPR is effective and efficient in personalized recommender systems.},
  archive      = {J_NEUCOM},
  author       = {Feng Zou and Debao Chen and Qingzheng Xu and Ziqi Jiang and Jiahui Kang},
  doi          = {10.1016/j.neucom.2020.08.080},
  journal      = {Neurocomputing},
  pages        = {716-727},
  shortjournal = {Neurocomputing},
  title        = {A two-stage personalized recommendation based on multi-objective teaching–learning-based optimization with decomposition},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intrusion detection approach based on optimised artificial
neural network. <em>NEUCOM</em>, <em>452</em>, 705–715. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion Detection , the ability to detect malware and other attacks, is a crucial aspect to ensure cybersecurity. So is the ability to identify this myriad of attacks. Artificial Neural Networks (as well as other machine learning bio-inspired approaches) are an established and proven method of accurate classification. ANNs are extremely versatile – a wide range of setups can achieve significantly different classification results . The main objective and contribution of this paper is the evaluation of the way the hyperparameters can influence the final classification result. In this paper, a wide range of ANN setups is put to comparison. We have performed our experiments on two benchmark datasets, namely NSL-KDD and CICIDS2017. The most effective arrangement achieves the multi-class classification accuracy of 99.909\% on an established benchmark dataset.},
  archive      = {J_NEUCOM},
  author       = {Michał Choraś and Marek Pawlicki},
  doi          = {10.1016/j.neucom.2020.07.138},
  journal      = {Neurocomputing},
  pages        = {705-715},
  shortjournal = {Neurocomputing},
  title        = {Intrusion detection approach based on optimised artificial neural network},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Symmetrical feature extraction via novel mirror PCA.
<em>NEUCOM</em>, <em>452</em>, 690–704. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symmetry is an important property of human faces. Many researchers exploit symmetry to improve face recognition. In this paper, we explore the symmetry of faces under the framework of PCA (Principal Component Analysis). Unlike previous studies that manipulate facial symmetry by averaging the two halves, we argue that well-estimated symmetrical faces lie in a low-dimensional subspace. Inspired by this, a PCA-like model, referred to as Mirror PCA, is proposed to extract low-rank symmetrical features of faces, as well as their principal directions. Although the optimization problem is non-convex, a suboptimal solution could be found under existing optimization frameworks such as ADMM , PGD, etc. A number of experiments are conducted to verify the effectiveness and robustness of our method.},
  archive      = {J_NEUCOM},
  author       = {Jian-Xun Mi and Li-Jian Yang and Li-Fang Zhou and Yue-Ru Sun and Kong Heng},
  doi          = {10.1016/j.neucom.2020.06.141},
  journal      = {Neurocomputing},
  pages        = {690-704},
  shortjournal = {Neurocomputing},
  title        = {Symmetrical feature extraction via novel mirror PCA},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Recent developments of content-based image retrieval
(CBIR). <em>NEUCOM</em>, <em>452</em>, 675–689. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of Internet technology and the popularity of digital devices, Content-Based Image Retrieval (CBIR) has been quickly developed and applied in various fields related to computer vision and artificial intelligence . Currently, it is possible to retrieve related images effectively and efficiently from a large scale database with an input image. In the past ten years, great efforts have been made for new theories and models of CBIR and many effective CBIR algorithms have been established. In this paper, we present a survey on the fast developments and applications of CBIR theories and algorithms during the period from 2009 to 2019. We mainly review the technological developments from the viewpoint of image representation and database search. We further summarize the practical applications of CBIR in the fields of fashion image retrieval , person re-identification, e-commerce product retrieval, remote sensing image retrieval and trademark image retrieval. Finally, we discuss the future research directions of CBIR with the challenge of big data and the utilization of deep learning techniques .},
  archive      = {J_NEUCOM},
  author       = {Xiaoqing Li and Jiansheng Yang and Jinwen Ma},
  doi          = {10.1016/j.neucom.2020.07.139},
  journal      = {Neurocomputing},
  pages        = {675-689},
  shortjournal = {Neurocomputing},
  title        = {Recent developments of content-based image retrieval (CBIR)},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combing modified grabcut, k-means clustering and sparse
representation classification for weed recognition in wheat field.
<em>NEUCOM</em>, <em>452</em>, 665–674. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weeding is beneficial to the growth of the crops in field. At present, weeding in China mainly relies on chemical herbicide spraying on a large area, which leads to environmental pollution. Combined with digital image processing and pattern recognition technology, weed species identification in wheat seedling stage in field is of great significance to realize the variable spraying of herbicide, reduce the cost and protect the ecological environment. Weed species identification in field by machine vision is one of the challenging and hard topics because of the diversity and changeability of the weed in field. A weed species recognition approach is proposed combining modified Grabcut, adaptive fuzzy dynamic K-means algorithms and sparse representation classification (SRC). First, the original weed images are enhanced and noise is suppressed using filtering technique, and in the segmentation phase, each weed image is coarsely segmented by the modified GrabCut algorithm to remove most of background of the original image captured in the field, which can reduce the computing cost and recognition time. The original weed image is segmented by adaptive fuzzy dynamic K-means. Finally the weed species is recognized by SRC. Compared with the other weed recognition methods, the proposed method integrated the advantages of three approaches, (1) the improved Grabcut method does not require human interaction and can automatically segment the background, (2) the dynamic K-means algorithm introduces fitness function to evaluate clustering, which reduces the dependence of traditional K-means clustering algorithm on the initial value of clustering center to a certain extent, and avoids the problems such as dead zone center and center redundancy caused by local extremum, (3) SRC is utilized to classify the weed species. To test the proposed method, a lot of experiments are carried on the wheat weed image dataset. The results validate that the proposed method is effective for the weed species recognition, which can be used as a preliminary step for precision applying pesticide.},
  archive      = {J_NEUCOM},
  author       = {Shanwen Zhang and Wenzhun Huang and Zuliang Wang},
  doi          = {10.1016/j.neucom.2020.06.140},
  journal      = {Neurocomputing},
  pages        = {665-674},
  shortjournal = {Neurocomputing},
  title        = {Combing modified grabcut, K-means clustering and sparse representation classification for weed recognition in wheat field},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advanced variations of two-dimensional principal component
analysis for face recognition. <em>NEUCOM</em>, <em>452</em>, 653–664.
(<a href="https://doi.org/10.1016/j.neucom.2020.08.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The two-dimensional principal component analysis (2DPCA) has been one of the basic methods of developing artificial intelligent algorithms. To increase the feasibility, we propose a new general ridge regression model for 2DPCA and variations, with extracting low dimensional features under two projection subspaces . A new relaxed 2DPCA under the quaternion framework is proposed to utilize the label (if known) and color information to compute the essential features of generalization ability with optimization algorithms . The 2DPCA-based approaches for face recognition are also improved by weighting each principle component a scatter measure, which increases efficiently the rate of face recognition. In numerical experiments on well-known standard databases, the R2DPCA approach has high generalization ability and achieves a higher recognition rate than the state-of-the-art 2DPCA-like methods, and has better performance than the basic deep learning methods such as CNNs , DBNs, and DNNs in the small-sample case.},
  archive      = {J_NEUCOM},
  author       = {Meixiang Zhao and Zhigang Jia and Yunfeng Cai and Xiao Chen and Dunwei Gong},
  doi          = {10.1016/j.neucom.2020.08.083},
  journal      = {Neurocomputing},
  pages        = {653-664},
  shortjournal = {Neurocomputing},
  title        = {Advanced variations of two-dimensional principal component analysis for face recognition},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient similarity search on multidimensional space of
biometric databases. <em>NEUCOM</em>, <em>452</em>, 623–652. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of pursuing the data items of a large database whose distances to a query item are the least is known as Similarity Search (Nearest Neighbor Search) problem. There exist various algorithms to address this problem. Some of the well known algorithms are i) exact algorithms ii) approximation algorithms and iii) randomized algorithms . This paper has made study only on exact and approximation algorithms because randomized algorithm produces approximate results with some probability. Recently, there are several approximation algorithms are proposed by the researchers because this type of algorithms minimizes the problem of Curse of Dimensionality . This paper mainly has two major sections. In first section, various methods under exact and approximation algorithms are discussed with regard to storage, preprocessing and query time. In the second section, efficient algorithms for similarity search suitable for certain physiological characteristics based biometric systems are considered. Biometric system has five main steps viz acquisition of Image, pre-processing, extraction of features, matching and making final decision. In this paper, indexing algorithms for similarity search suitable for iris trait based on different features are discussed in detail. Since the nature of features are distinct and different in biometric traits , there does not exist a universal (one unique) solution which can apply to all traits of biometric systems. Various performance measures like Penetration Rate and Hit Rate are used to determine the correct recognition rate with top best match (rank-1 accuracy).},
  archive      = {J_NEUCOM},
  author       = {Umarani Jayaraman and Phalguni Gupta},
  doi          = {10.1016/j.neucom.2020.08.084},
  journal      = {Neurocomputing},
  pages        = {623-652},
  shortjournal = {Neurocomputing},
  title        = {Efficient similarity search on multidimensional space of biometric databases},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on regional level set image segmentation models
based on the energy functional similarity measure. <em>NEUCOM</em>,
<em>452</em>, 606–622. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image segmentation is an important field of computer vision and has attracted significant research attention in the recent years. In this paper, we provide a survey of regional level set image segmentation models based on the energy functional similarity measure. Our survey begins with an introduction to region-based level set image segmentation and an overview of its general steps. Then the different segmentation models are summarized. We define and survey six categories of regional level set image segmentation models based on energy functional similarity measures. For every category, we present the mainstream approaches from the literature as examples. Experimental analyses are conducted to compare the segmentation performance of various methods, which allow us to draw meaningful conclusions about their mutual advantages and disadvantages. Finally, we conclude this survey by highlighting several promising directions which need to be further explored by the research community in the future.},
  archive      = {J_NEUCOM},
  author       = {Le Zou and Liang-Tu Song and Thomas Weise and Xiao-Feng Wang and Qian-Jing Huang and Rui Deng and Zhi-Ze Wu},
  doi          = {10.1016/j.neucom.2020.07.141},
  journal      = {Neurocomputing},
  pages        = {606-622},
  shortjournal = {Neurocomputing},
  title        = {A survey on regional level set image segmentation models based on the energy functional similarity measure},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ResGNet-c: A graph convolutional neural network for
detection of COVID-19. <em>NEUCOM</em>, <em>452</em>, 592–605. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.144">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widely spreading COVID-19 has caused thousands of hundreds of mortalities over the world in the past few months. Early diagnosis of the virus is of great significance for both of infected patients and doctors providing treatments. Chest Computerized tomography (CT) screening is one of the most straightforward techniques to detect pneumonia which was caused by the virus and thus to make the diagnosis. To facilitate the process of diagnosing COVID-19, we therefore developed a graph convolutional neural network ResGNet-C under ResGNet framework to automatically classify lung CT images into normal and confirmed pneumonia caused by COVID-19. In ResGNet-C, two by-products named NNet-C, ResNet101-C that showed high performance on detection of COVID-19 are simultaneously generated as well. Our best model ResGNet-C achieved an averaged accuracy at 0.9662 with an averaged sensitivity at 0.9733 and an averaged specificity at 0.9591 using five cross-validations on the dataset, which is comprised of 296 CT images. To our best knowledge, this is the first attempt at integrating graph knowledge into the COVID-19 classification task. Graphs are constructed according to the Euclidean distance between features extracted by our proposed ResNet101-C and then are encoded with the features to give the prediction results of CT images. Besides the high-performance system, which surpassed all state-of-the-art methods, our proposed graph construction method is simple, transferrable yet quite helpful for improving the performance of classifiers, as can be justified by the experimental results.},
  archive      = {J_NEUCOM},
  author       = {Xiang Yu and Siyuan Lu and Lili Guo and Shui-Hua Wang and Yu-Dong Zhang},
  doi          = {10.1016/j.neucom.2020.07.144},
  journal      = {Neurocomputing},
  pages        = {592-605},
  shortjournal = {Neurocomputing},
  title        = {ResGNet-C: A graph convolutional neural network for detection of COVID-19},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). Automatic fluid segmentation in retinal optical coherence
tomography images using attention based deep learning. <em>NEUCOM</em>,
<em>452</em>, 576–591. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical coherence tomography (OCT) is one of the most commonly used ophthalmic diagnostic techniques. Macular Edema (ME) is the swelling of the macular region in the eye. Segmentation of the fluid region in the retinal layer is an important step in detecting lesions. However, manual segmentation is often a time consuming and subjective process. In this paper, an improved U-Net segmentation method is proposed. In this method, the attention mechanism is introduced to automatically locate the fluid region, which avoids the problem of excessive calculation in multi-stage methods. At the same time, the use of dense skip connections which combines high-level and low-level features makes the segmentation results more precise. The loss function is a joint loss, including weighted binary cross entropy loss, dice loss, and regression loss, where regression loss is used to avoid the problem of merging multiple fluid regions into one. The experimental results show that the proposed method can adapt to the OCT scans acquired by various imaging scanning devices, and this method is more effective than other start-of-the-art fluid segmentation methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaoming Liu and Shaocheng Wang and Ying Zhang and Dong Liu and Wei Hu},
  doi          = {10.1016/j.neucom.2020.07.143},
  journal      = {Neurocomputing},
  pages        = {576-591},
  shortjournal = {Neurocomputing},
  title        = {Automatic fluid segmentation in retinal optical coherence tomography images using attention based deep learning},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction of cardiovascular diseases using weight learning
based on density information. <em>NEUCOM</em>, <em>452</em>, 566–575.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uneven distribution of sample points is a common problem in medical datasets. How to improve the classification accuracy with these datasets remains to be solved. Based on the density-based spatial clustering of applications with noise (DBSCAN) algorithm, a weight learning approach is proposed to utilize the density information of datasets for the accurate prediction of cardiovascular diseases (CVDs). The approach selects important features by the random forest (RF) algorithm, divides the sample points into three types and weights them using different values by weight learning based on the density. Thus, the constructed machine learning models that combine the original features and weight feature can learn density information, more effectively identify decision boundaries, and achieve better performance. Compared with conventional machine learning models , the cross-validation approach showed that the performance of machine learning models with weight learning could achieve improved accuracy by 3 percentage points with the Stroke dataset and more than 10 percentage points with the University of California, Irvine (UCI) dataset.},
  archive      = {J_NEUCOM},
  author       = {Jiang Xie and Ruiying Wu and Haitao Wang and Haibing Chen and Xiaochun Xu and Yanyan Kong and Wu Zhang},
  doi          = {10.1016/j.neucom.2020.10.114},
  journal      = {Neurocomputing},
  pages        = {566-575},
  shortjournal = {Neurocomputing},
  title        = {Prediction of cardiovascular diseases using weight learning based on density information},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for processing electromyographic signals: A
taxonomy-based survey. <em>NEUCOM</em>, <em>452</em>, 549–565. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has been recently employed to build smart systems that perform incredibly well in a wide range of tasks, such as image recognition, machine translation, and self-driving cars. In several fields the considerable improvement in the computing hardware and the increasing need for big data analytics has boosted DL work. In recent years physiological signal processing has strongly benefited from deep learning. In general, there is an exponential increase in the number of studies concerning the processing of electromyographic (EMG) signals using DL methods. This phenomenon is mostly explained by the current limitation of myoelectric controlled prostheses as well as the recent release of large EMG recording datasets, e.g. Ninapro. Such a growing trend has inspired us to seek and review recent papers focusing on processing EMG signals using DL methods. Referring to the Scopus database, a systematic literature search of papers published between January 2014 and March 2019 was carried out, and sixty-five papers were chosen for review after a full text analysis. The bibliometric research revealed that the reviewed papers can be grouped in four main categories according to the final application of the EMG signal analysis: Hand Gesture Classification, Speech and Emotion Classification, Sleep Stage Classification and Other Applications. The review process also confirmed the increasing trend in terms of published papers, the number of papers published in 2018 is indeed four times the amount of papers published the year before. As expected, most of the analyzed papers ( ≈ ≈ 60\%) concern the identification of hand gestures, thus supporting our hypothesis. Finally, it is worth reporting that the convolutional neural network (CNN) is the most used topology among the several involved DL architectures, in fact, the sixty percent approximately of the reviewed articles consider a CNN.},
  archive      = {J_NEUCOM},
  author       = {Domenico Buongiorno and Giacomo Donato Cascarano and Irio De Feudis and Antonio Brunetti and Leonarda Carnimeo and Giovanni Dimauro and Vitoantonio Bevilacqua},
  doi          = {10.1016/j.neucom.2020.06.139},
  journal      = {Neurocomputing},
  pages        = {549-565},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for processing electromyographic signals: A taxonomy-based survey},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Study on anatomical and functional medical image
registration methods. <em>NEUCOM</em>, <em>452</em>, 534–548. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The purpose of this paper is to give an overview of various well known medical image registration techniques with a special focus on registration between anatomical and functional medical images. Examples of anatomical medical images (AMI) are Computer Tomography (CT), Magnetic Resonance Images (MRI), X-ray radiographs and ultrasound etc. whereas Positron Emission Tomography (PET), Single Photon Emission Tomography (SPECT) and fMRI are examples of functional medical images (FMI). Irrespective of such types (AMI or FMI), every case can be considered as a medical imaging modality. All these modalities are widely used by clinicians to study the structure/functionality of human body parts for diagnosis and treatment. It is frequently required to combine PET/SPECT with CT/MRI to simultaneous study the metabolic and molecular information received through PET/SPECT with fine anatomical details observed by CT/MRI. This concurrent study will help in the diagnosis and localization of many diseases like cancer, blockage in coronary arteries and brain-related diseases like Parkinson, Alzheimer etc. Further, in many cases, clinicians are required to co-register one or more anatomical images with functional images, for example, ultrasound-guided biopsy fused with PET and MRI. This registration can be done either at the hardware level or at the software level. The introduction of integrated PET-CT machine increases the acceptability of hardware-based registration systems as compared to software-based methods among the medics. One possible reason for this is the lack of validation of results achieved through software-based registration methods. On the other hand, software-based registration methods also have many advantages over the hardware-based registration systems like lesser exposure to radiation and no need for new investment on hardware etc. In this paper, both the methods with their merits and demerits are discussed in detail.},
  archive      = {J_NEUCOM},
  author       = {Sandesh Gupta and Phalguni Gupta and Vivek S. Verma},
  doi          = {10.1016/j.neucom.2020.08.085},
  journal      = {Neurocomputing},
  pages        = {534-548},
  shortjournal = {Neurocomputing},
  title        = {Study on anatomical and functional medical image registration methods},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new deep learning approach for the retinal hard exudates
detection based on superpixel multi-feature extraction and patch-based
CNN. <em>NEUCOM</em>, <em>452</em>, 521–533. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diabetic Retinopathy (DR) is a severe complication of chronic diabetes causing significant visual deterioration and may lead to blindness with delay of being treated. Exudative diabetic maculopathy , a form of macular edema where hard exudates (HE) develop, is a frequent cause of visual deterioration in DR. The detection of HE comprises a significant role in the DR diagnosis. In this paper, an automatic exudates detection method based on superpixel multi-feature extraction and patch-based deep convolutional neural network is proposed. Firstly, superpixels, regarded as candidates, are generated on each resized image using the superpixel segmentation algorithm called Simple Linear Iterative Clustering (SLIC). Then, 25 features extracted from resized images and patches are generated on each feature. Patches are subsequently used to train a deep convolutional neural network, which distinguishes the hard exudates from the background. Experiments conducted on three publicly available datasets (DiaretDB1, e-ophtha EX and IDRiD) demonstrate that our proposed methodology achieved superior HE detection when compared with current state-of-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Chenxi Huang and Yongshuo Zong and Yimin Ding and Xin Luo and Kathy Clawson and Yonghong Peng},
  doi          = {10.1016/j.neucom.2020.07.145},
  journal      = {Neurocomputing},
  pages        = {521-533},
  shortjournal = {Neurocomputing},
  title        = {A new deep learning approach for the retinal hard exudates detection based on superpixel multi-feature extraction and patch-based CNN},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Low-dose CT image denoising using residual convolutional
network with fractional TV loss. <em>NEUCOM</em>, <em>452</em>, 510–520.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a Fractional-order Residual Convolutional Neural Network (FRCNN) for Low-Dose CT (LDCT) denoising . As increasing the dose of radiation is harmful to the patient, how to trade off between reducing the radiation dose and improving the quality of the CT image has become a challenging problem. To this end, this paper proposes a new approach for LDCT image denoising using Convolutional Neural Network (CNN) with Fractional-order Total Variation (FTV) loss, as well as residual learning. Firstly, this paper introduced the FTV loss function for structural details enhancement. Secondly, skip connections were added to optimize the network. Thirdly, extensive experimental analysis was used to evaluate the capacity of this method in suppressing noise and preserving detailed information. The FTV loss can retain essential structural details while suppressing noise, generating high-quality CT images ready for interpretation by radiologists. Compared with state-of-the-art methods, our method obtained better results visually and numerically, especially in structural details preservation. These promising results will significantly improve the usability of LDCT images.},
  archive      = {J_NEUCOM},
  author       = {Miao Chen and Yi-Fei Pu and Yu-Cai Bai},
  doi          = {10.1016/j.neucom.2020.10.004},
  journal      = {Neurocomputing},
  pages        = {510-520},
  shortjournal = {Neurocomputing},
  title        = {Low-dose CT image denoising using residual convolutional network with fractional TV loss},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue: Advanced intelligent computing theory and
applications in big data era. <em>NEUCOM</em>, <em>452</em>, 508–509.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Qinhu Zhang ( Guest Editors ) and Vitoantonio Bevilacqua and De-Shuang Huang},
  doi          = {10.1016/j.neucom.2021.04.126},
  journal      = {Neurocomputing},
  pages        = {508-509},
  shortjournal = {Neurocomputing},
  title        = {Special issue: Advanced intelligent computing theory and applications in big data era},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid intelligent classifier for anomaly detection.
<em>NEUCOM</em>, <em>452</em>, 498–507. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present research is focused on the use of intelligent techniques to perform anomaly detection . This task represents a special concern in complex systems that operate in different regimes. Then, this work proposes a hybrid intelligent classifier based on one-class techniques, capable of detecting anomalies of the different operating ranges. The proposal is implemented over an industrial plant designed to control the water level in a tank, taking into consideration three different operating points. The hybrid classifier is validated by using real anomalies, obtaining successful results.},
  archive      = {J_NEUCOM},
  author       = {Esteban Jove and Roberto Casado-Vara and José-Luis Casteleiro-Roca and Juan Albino Méndez Pérez and Zita Vale and José Luis Calvo-Rolle},
  doi          = {10.1016/j.neucom.2019.12.138},
  journal      = {Neurocomputing},
  pages        = {498-507},
  shortjournal = {Neurocomputing},
  title        = {A hybrid intelligent classifier for anomaly detection},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A machine learning-based forecasting system of perishable
cargo flow in maritime transport. <em>NEUCOM</em>, <em>452</em>,
487–497. (<a
href="https://doi.org/10.1016/j.neucom.2019.10.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The uncertainty cargo flow problem establishes a limitation in ports management where decision-making processes need accurate information of the future values. This work aims at predicting the future values of Ro-Ro perishable cargo flow at the Port of Algeciras Bay using a machine learning-based forecasting system. Two datasets consisting of daily records of fresh fruits and vegetables between 2010 to 2017 were analyzed. Additionally, these two--time series were pre-processed applying an exponential moving average method to obtain a smoothed version of the original ones. Multiple Linear Regression, Support Vector Machines , Long Short-Term Memory networks and an ensemble approach have been used to build a forecasting system and obtain the future values of the perishable cargo. The results of the analysis showed how this machine learning-based system achieved 14.83\% better performance rate than a baseline persistence model in terms of root mean squared error in the fresh fruits dataset and 11.3\% better in the vegetables one. In general, models’ average performance rates are better using the smoothed version of the times series rather than the original ones.},
  archive      = {J_NEUCOM},
  author       = {José Antonio Moscoso-López and Daniel Urda and Juan Jesús Ruiz-Aguilar and Javier González-Enrique and Ignacio J. Turias},
  doi          = {10.1016/j.neucom.2019.10.121},
  journal      = {Neurocomputing},
  pages        = {487-497},
  shortjournal = {Neurocomputing},
  title        = {A machine learning-based forecasting system of perishable cargo flow in maritime transport},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixing user-centered and generalized models for fall
detection. <em>NEUCOM</em>, <em>452</em>, 473–486. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall Detection (FD) using wearable devices has been the focus of many research studies during the last years. Solutions are expected to work autonomously and securely; however, even the commercial products are still far from being reliable in elderly people autonomously everyday life. This research focuses on developing a FD method valid to be deployed on a wearable device with tri-axial accelerometer as sensing unit, and working autonomously without external services. Moreover, each fall type is considered independently and the solution adapts to its current user. The proposal includes three stages: a novel event detection stage followed by a one-class problem classification and a final classifier that labels the anomaly events as Fall or Normal. The process starts gathering data from the current user’s wearable provided the data does not include any fall; this data is used to tune the event detection and to train a one-class classifier. Two different methods are tested: a One-Class Support Vector Machine and a classifier based on the centroid of the normal activities’ instances. The detected anomaly events are then classified as Fall or Normal; this second classifier is previously obtained from data from other users’ past experiences. For this two-class model, two different options are tested as well: a Support Vector Machine and a feed-forward Neural Network. The experimentation stage includes two different published simulated falls data sets. The obtained results show that filtering the detected peaks corresponding to normal activities of the current user helps the two-class classifier for some types of fall events, suggesting to introduce specific one-class filtering per fall type. However, the number of false alarms is still high, and the two-class classifiers have a high variability in their performances according to the user, which still needs further research. The results suggest that it might be interesting to obtain a more accurate two-class classifier using data only from subjects with similar activity levels; the use of online learning might also improve the general performance in the classification stages.},
  archive      = {J_NEUCOM},
  author       = {Mirko Fáñez and José R. Villar and Enrique de la Cal and Víctor M. González and Javier Sedano and Samad B. Khojasteh},
  doi          = {10.1016/j.neucom.2020.02.133},
  journal      = {Neurocomputing},
  pages        = {473-486},
  shortjournal = {Neurocomputing},
  title        = {Mixing user-centered and generalized models for fall detection},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extreme learning machine ensemble model for time series
forecasting boosted by PSO: Application to an electric consumption
problem. <em>NEUCOM</em>, <em>452</em>, 465–472. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ensemble Model is a tool that has attracted attention due to its capability to improve the outcome performance of emerging techniques to solve the modelling and classifying problem. However, the feasibility of applying intelligent algorithms to build the Ensemble Model presents a challenge of its own. In this work, an Extreme Learning Machine ensemble is applied to the Time Series modelling problem. We develop a thorough study of the models that will be candidates to compose the ensemble, obtaining statistical results of optimal topologies to solve each Time Series problem. The proposed method for the ensemble is the weighted averaging method, where the parameters (weights) are tuned with the Particle Swarm Optimization algorithm . Lastly, the ensemble is tested first in the well known Santa Fe Time Series Competition benchmark. Given the obtained satisfactory results, the ensemble is secondly tested in a real problem of Spain’s electric consumption forecasting. It is demonstrated that the PSO is a suitable algorithm to optimize Extreme Learning Machine ensemble and that the proposed strategy can obtain good results in both Time Series problems.},
  archive      = {J_NEUCOM},
  author       = {Mikel Larrea and Alain Porto and Eloy Irigoyen and Antonio Javier Barragán and José Manuel Andújar},
  doi          = {10.1016/j.neucom.2019.12.140},
  journal      = {Neurocomputing},
  pages        = {465-472},
  shortjournal = {Neurocomputing},
  title        = {Extreme learning machine ensemble model for time series forecasting boosted by PSO: Application to an electric consumption problem},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Switched learning adaptive neuro-control strategy.
<em>NEUCOM</em>, <em>452</em>, 450–464. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The generalized learning algorithm can be efficiently used as control strategy, but it has some drawbacks such as: sensitivity to the training dataset, poor robustness against changes in the system, difficulty to generate the control signals without destabilising the plant, tuning of the controller, etc. To overcome some of these issues, in this work a new switched neural adaptive control strategy is proposed. It is based on the combination of an adaptive artificial neural network , a PID regulator, an estimated inverse model of the plant and two switches to route the signals properly in the control scheme. The technique is described using the hybrid automata formalism. In order to test the validity of this proposal, it is applied to the control of a quadrotor unmanned aerial vehicle (UAV), subjected to changes in its mass and wind disturbances. Simulation results show how the on-line learning increases the robustness of the controller, reducing the effects of the mass change and of the wind on the UAV stabilization, thus improving the UAV trajectory tracking.},
  archive      = {J_NEUCOM},
  author       = {J. Enrique Sierra-García and Matilde Santos},
  doi          = {10.1016/j.neucom.2019.12.139},
  journal      = {Neurocomputing},
  pages        = {450-464},
  shortjournal = {Neurocomputing},
  title        = {Switched learning adaptive neuro-control strategy},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining metaheuristic search and simulation to deal with
capacitated aisles in facility layout. <em>NEUCOM</em>, <em>452</em>,
443–449. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The layout of machines in a manufacturing system has a significant impact on production time and cost. The aim of a good layout is generally determining the machines’ position on the shop floor to minimize transportation time and cost. However, not only machines’ positions but also aisle affect transportation cost and time. The aisles are paths that transporters go through them to move the materials between machines. The capacity of the aisles is limited to a specific number of transporters and this may cause transporters to wait before being allowed to pass an aisle. Therefore, when optimizing the layout of machines, the aisles structure and their capacity must be considered. This article presents a hybrid approach for layout design in manufacturing systems taking into account capacitated aisles structure. The proposed approach combines a metaheuristic algorithm and simulation. First, the aisle structure is defined and then, the layout of the machines is determined. Each layout is evaluated through a simulation model. In this way, it is possible to avoid unrealistic assumptions and consider realistic conditions such as stochastic demand, random process time and random transportation time. Finally, a numerical example is included to illustrate the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Hani Pourvaziri and Henri Pierreval},
  doi          = {10.1016/j.neucom.2020.05.116},
  journal      = {Neurocomputing},
  pages        = {443-449},
  shortjournal = {Neurocomputing},
  title        = {Combining metaheuristic search and simulation to deal with capacitated aisles in facility layout},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuro-tabu search approach to scheduling in automotive
manufacturing. <em>NEUCOM</em>, <em>452</em>, 435–442. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The work concerns a new problem of minimizing production time of a set of tasks on machines while limiting the availability of machine operators. The problem is taken from practice, from a company producing subassemblies for the automotive industry. A mathematical model of the problem is formulated, and for its solution a neuro-tabu algorithm is proposed, which is a variation of the tabu search algorithm with a neural mechanism replacing the tabu list: short-term memory. The efficiency of the algorithm constructed in this way is verified on test examples based on real data from the production process.},
  archive      = {J_NEUCOM},
  author       = {Wojciech Bożejko and Anna Burduk and Kamil Musiał and Jarosław Pempera},
  doi          = {10.1016/j.neucom.2020.01.121},
  journal      = {Neurocomputing},
  pages        = {435-442},
  shortjournal = {Neurocomputing},
  title        = {Neuro-tabu search approach to scheduling in automotive manufacturing},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep residual transfer learning for automatic diagnosis and
grading of diabetic retinopathy. <em>NEUCOM</em>, <em>452</em>, 424–434.
(<a href="https://doi.org/10.1016/j.neucom.2020.04.148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation and diagnosis of retina pathology is usually made via the analysis of different image modalities that allow to explore its structure. The most popular retina image method is retinography, a technique that displays the fundus of the eye, including the retina and other structures. Retinography is the most common imaging method to diagnose retina diseases such as Diabetic Retinopathy (DB) or Macular Edema (ME). However, retinography evaluation to score the image according to the disease grade presents difficulties due to differences in contrast, brightness and the presence of artifacts. Therefore, it is mainly done via manual analysis; a time consuming task that requires a trained clinician to examine and evaluate the images. In this paper, we present a computer aided diagnosis tool that takes advantage of the performance provided by deep learning architectures for image analysis. Our proposal is based on a deep residual convolutional neural network for extracting discriminatory features with no prior complex image transformations to enhance the image quality or to highlight specific structures. Moreover, we used the transfer learning paradigm to reuse layers from deep neural networks previously trained on the ImageNet dataset, under the hypothesis that first layers capture abstract features than can be reused for different problems. Experiments using different convolutional architectures have been carried out and their performance has been evaluated on the MESSIDOR database using cross-validation. Best results were found using a ResNet50-based architecture, showing an AUC of 0.93 for grades 0 + 1, AUC of 0.81 for grade 2 and AUC of 0.92 for grade 3 labelling, as well as AUCs higher than 0.97 when considering a binary classification problem (grades 0 vs 3).},
  archive      = {J_NEUCOM},
  author       = {Francisco J. Martinez-Murcia and Andrés Ortiz and Javier Ramírez and Juan M. Górriz and Ricardo Cruz},
  doi          = {10.1016/j.neucom.2020.04.148},
  journal      = {Neurocomputing},
  pages        = {424-434},
  shortjournal = {Neurocomputing},
  title        = {Deep residual transfer learning for automatic diagnosis and grading of diabetic retinopathy},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Localization of charging stations for electric vehicles
using genetic algorithms. <em>NEUCOM</em>, <em>452</em>, 416–423. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The electric vehicle (EV) is gradually being introduced in cities. The impact of this introduction is less due, among other reasons, to the lack of charging infrastructure necessary to satisfy the demand. In today’s cities there is no adequate infrastructure and it is necessary to have action plans that allow an easy deployment of a network of EV charging points in current cities. These action plans should try to place the EV charging stations in the most appropriate places for optimizing their use. According to this, this paper presents an agent-oriented approach that analyses the different configurations of possible locations of charging stations for the electric vehicles in a specific city. The proposed multi-agent system takes into account data from a variety of sources such as social networks activity and mobility information in order to estimate the best configurations. The proposed approach employs a genetic algorithm (GA) that tries to optimize the possible configurations of the charging infrastructure. Additionally, a new crossover method for the GA is proposed considering this context.},
  archive      = {J_NEUCOM},
  author       = {Jaume Jordán and Javier Palanca and Elena del Val and Vicente Julian and Vicent Botti},
  doi          = {10.1016/j.neucom.2019.11.122},
  journal      = {Neurocomputing},
  pages        = {416-423},
  shortjournal = {Neurocomputing},
  title        = {Localization of charging stations for electric vehicles using genetic algorithms},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue SOCO-CISIS 2018: New trends in soft computing
and computational intelligence in security and its application in
industrial and environmental problems. <em>NEUCOM</em>, <em>452</em>,
414–415. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Manuel Graña and José Manuel López-Guede and José Antonio Sáez Muñoz and Álvaro Herrero Cosio and Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2020.09.058},
  journal      = {Neurocomputing},
  pages        = {414-415},
  shortjournal = {Neurocomputing},
  title        = {Special issue SOCO-CISIS 2018: New trends in soft computing and computational intelligence in security and its application in industrial and environmental problems},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous on-wrist acceleration-based fall detection
systems: Unsolved challenges. <em>NEUCOM</em>, <em>452</em>, 404–413.
(<a href="https://doi.org/10.1016/j.neucom.2019.12.147">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall detection (FD) has been the focus of many research studies during the last years. Developing reliable FD systems is relevant, for instance, to provide support to the elderly population in their everyday life. Besides, the generalization of the use of wearable devices (and more specifically, on-wrist devices) to measure the daily activity strongly suggests that in a short period of time, the elderly people will be making use of this type of devices. On-wrist devices can be used as the FD basic sensing unit; while the intelligent classification can be obtained either autonomously (on the device) or requested to a remote service (via the paired smartphone or via web services). This study tries to analyze the current challenges in autonomous on-wrist wearable devices for producing a reliable and robust FD system. To do so, we analyze the related work; one of the possible solutions is implemented with several alternatives and evaluated with publicly available simulated falls data sets. The most remarkable findings in this research are that i) real fall data sets are needed, at least, a valid merging method to produce real fall like Time Series, ii) generalized solutions might not be enough and research is needed in models that learns from the user, iii) the need of tuning and fitting to the current user performance, iv) the amount of fall types suggests that hybrid and ensemble approaches might be interesting.},
  archive      = {J_NEUCOM},
  author       = {José R. Villar and Camelia Chira and Enrique de la Cal and Víctor M. González and Javier Sedano and Samad B. Khojasteh},
  doi          = {10.1016/j.neucom.2019.12.147},
  journal      = {Neurocomputing},
  pages        = {404-413},
  shortjournal = {Neurocomputing},
  title        = {Autonomous on-wrist acceleration-based fall detection systems: Unsolved challenges},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep CNN transferred from VAE and GAN for classifying
irritating noise in automobile. <em>NEUCOM</em>, <em>452</em>, 395–403.
(<a href="https://doi.org/10.1016/j.neucom.2019.10.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Noise from automobiles, such as buzzing, squeaking, and rattling (BSR) noises, is a key factor in automobile quality assessment. It is necessary to classify these noises for appropriate handling and prevention. Although many researchers have conducted studies to classify noise, they suffer from several problems: difficulty in extracting appropriate features, insufficient data to train a classifier, and weak robustness to surrounding noise. This paper proposes a method called latent semantic controlling generative adversarial networks (LSC-GAN) to solve these problems. To capture the features of data, a variational autoencoder (VAE), an autoencoder with approximate inference in a latent Gaussian model , learns the data representation by projecting them into the latent space according to their features and reconstructing the projected data. Because the generator and the discriminator of the LSC-GAN are trained simultaneously, the capacity to extract the characteristics of the data is improved and a knowledge space of classifiable data is also expanded with insufficient data. While data are generated by the generator, the encoder projects them back to the latent space according to their characteristics to advance the ability to extract features. Finally, the encoder is trained to the classifier, which is trained to classify BSR noises. The proposed classifier outperforms other models and achieves an accuracy of 96.68\%. We confirm using a confusion matrix that the proposed model classifies the types of insufficient class better than other models. Our proposed model classifies data with accuracy of 94.68\%, even if the data contains surrounding noise, which means it is more robust to BSR with surrounding noise than other models.},
  archive      = {J_NEUCOM},
  author       = {Jin-Young Kim and Sung-Bae Cho},
  doi          = {10.1016/j.neucom.2019.10.123},
  journal      = {Neurocomputing},
  pages        = {395-403},
  shortjournal = {Neurocomputing},
  title        = {Deep CNN transferred from VAE and GAN for classifying irritating noise in automobile},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid algorithm for the classification of prostate cancer
patients of the MCC-spain study based on support vector machines and
genetic algorithms. <em>NEUCOM</em>, <em>452</em>, 386–394. (<a
href="https://doi.org/10.1016/j.neucom.2019.08.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this novel research a hybrid algorithm is presented, one capable of selecting a set of features that makes it possible to identify individuals who are healthy and those who suffer from prostate cancer. In this research the selection of features is carried out by means of evolutionary algorithms . In previous works, algorithms of this nature have proven their ability to find solutions for optimization problems in a wide range of fields. The present research proposes a novel hybrid algorithm based on genetic algorithms and support vector machines have been developed in order to find the best variables subset for classifying individuals. The results obtained show how well the method performs in comparison to other methodologies. Cases and controls belong to the study MCC-Spain.},
  archive      = {J_NEUCOM},
  author       = {Juan Enrique Sánchez Lasheras and Fernando Sánchez Lasheras and Carmen González Donquiles and Adonina Tardón and Gemma Castaño-Vinyals and Camilo Palazuelos and Dolores Salas and Vicente Martín Sánchez and Francisco Javier de Cos Juez},
  doi          = {10.1016/j.neucom.2019.08.113},
  journal      = {Neurocomputing},
  pages        = {386-394},
  shortjournal = {Neurocomputing},
  title        = {Hybrid algorithm for the classification of prostate cancer patients of the MCC-spain study based on support vector machines and genetic algorithms},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual agent organizations for user behaviour pattern
extraction in energy optimization processes: A new perspective.
<em>NEUCOM</em>, <em>452</em>, 374–385. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The optimization of energy use in family homes and public buildings is an ongoing topic of discussion. State-of-the-art research has almost always focused on reducing the consumption of heating systems, air-conditioning or lighting. Despite their importance, user-related variables, such as comfort, are normally not included in the optimization process. These aspects should be considered to be able to effectively minimize energy consumption. Thus, there is a need for a comprehensive energy optimization approach, one that will consider both climatological factors and user behaviour . Learning about user behaviour is key to effective optimization . In this work, the proposed architecture’s capacity to organize Virtual Agent Organizations (VAO) allows it to adapt to highly variable user behavior and preferences. This agent methodology has the ability to manage Wireless Sensor Networks (WSNs), Artificial Neural Networks (ANN) and Case-Based Reasoning (CBR) to obtain user preferences and predict their behaviour in the home or building. The proposed approach has been tested in two different buildings, a traditional-construction house and a modular home, obtaining savings of 30.16\% and 13.43\%, respectively. These results validate the proposed mixed approach of temperature adjustment algorithms together with the extraction of user behavior patterns for the establishment of a threshold based on preferences.},
  archive      = {J_NEUCOM},
  author       = {Alfonso González-Briones and Javier Prieto and Fernando De La Prieta and Yves Demazeau and Juan M. Corchado},
  doi          = {10.1016/j.neucom.2020.05.117},
  journal      = {Neurocomputing},
  pages        = {374-385},
  shortjournal = {Neurocomputing},
  title        = {Virtual agent organizations for user behaviour pattern extraction in energy optimization processes: A new perspective},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving time series forecasting using information fusion
in local agricultural markets. <em>NEUCOM</em>, <em>452</em>, 355–373.
(<a href="https://doi.org/10.1016/j.neucom.2019.11.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research explores the capacity of Information Fusion and Data Mining to extract knowledge about associations among agricultural products and achieve better predictions for future consumption in local markets in the Andean region of Ecuador. This commercial activity is performed using Alternative Marketing Circuits (CIALCO), seeking to establish a direct relationship between producer and consumer prices, and promote buying and selling among family groups. The time-series forecasting, presented as a machine learning formulation, is enhanced with multi-variate predictions based on association rules extracted from transactions data analysis. These transactional data are used to learn the best association rules between products sold in different local markets, knowledge that allows the system to gain a significant improvement in forecasting accuracy by including these variables in multi-variate forecasting models. In the results we see that, from establishing best association rules valid in the original dataset, we can achieve a considerable improvement in prediction accuracy, validated with independent test subsequences of agricultural products using non-linear regression techniques including neural networks with a varying number of hidden layers.},
  archive      = {J_NEUCOM},
  author       = {Washington R. Padilla and Jesús García and José M. Molina},
  doi          = {10.1016/j.neucom.2019.11.125},
  journal      = {Neurocomputing},
  pages        = {355-373},
  shortjournal = {Neurocomputing},
  title        = {Improving time series forecasting using information fusion in local agricultural markets},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Motivational engine and long-term memory coupling within a
cognitive architecture for lifelong open-ended learning.
<em>NEUCOM</em>, <em>452</em>, 341–354. (<a
href="https://doi.org/10.1016/j.neucom.2019.10.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a cognitive architecture that revolves around a network memory based Long-Term Memory and how it can lead to a working lifelong learning system that can deal with open-ended learning. It focuses on the mutual interaction between the Motivational Engine and the Long-Term Memory and, in particular, on autonomously producing high-level utility representations in order to allow for development. Thus, the main point is to study how this architecture allows to start from primitive policies and models operating over continuous and large state/action spaces and progressively move towards higher level structures defined over smaller and discrete state/action spaces. This progression is demonstrated in a series of experiments carried out on a real robotic setup that involves different contexts, both in terms of domains (worlds) and tasks (goals).},
  archive      = {J_NEUCOM},
  author       = {José Antonio Becerra and Alejandro Romero and Francisco Bellas and Richard J. Duro},
  doi          = {10.1016/j.neucom.2019.10.124},
  journal      = {Neurocomputing},
  pages        = {341-354},
  shortjournal = {Neurocomputing},
  title        = {Motivational engine and long-term memory coupling within a cognitive architecture for lifelong open-ended learning},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Use of image processing to monitor tool wear in micro
milling. <em>NEUCOM</em>, <em>452</em>, 333–340. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro milling is a versatile machining process owing to its capability to machine, by material removal, micro-sized components with complex geometrical features. However, micro milling tools wear quickly, being a key issue to determine tool wear condition in order to prevent excessive tool wear or a sudden tool breakage while machining, which would waste the workpiece. Due to the small size of micro milling tools, direct measurement of the worn tool is not possible. In order to overcome this drawback, this paper presents a new method based on digital image processing where image captures of the micro tool and subsequent analysis provides a valuable information to determine the progression of tool wear. Tool wear is measured in flank wear, crater wear and tool radius reduction. Different approaches are compared so as to determine the best option for every set of images. These methods are based on the use of morphological operations , k-means clustering and Otsu Multilevel algorithm. Results show a good performance with differences of 5\% between predicted and actual worn area, which satisfies the industrial requirements. This procedure can be transferred to industrial environments and implemented in collaborative robots, increasing the level of automation and facilitating the decision-making process.},
  archive      = {J_NEUCOM},
  author       = {Laura Fernández-Robles and Lidia Sánchez-González and Javier Díez-González and Manuel Castejón-Limas and Hilde Pérez},
  doi          = {10.1016/j.neucom.2019.12.146},
  journal      = {Neurocomputing},
  pages        = {333-340},
  shortjournal = {Neurocomputing},
  title        = {Use of image processing to monitor tool wear in micro milling},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative study of six model complexity metrics to
search for parsimonious models with GAparsimony r package.
<em>NEUCOM</em>, <em>452</em>, 317–332. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, interest is growing in automating KDD processes. Thanks to the increasing power and decreasing costs of computation devices, the search for the best features and model parameters can be conducted with different meta-heuristics. Thus, researchers can focus on other important tasks like data wrangling or feature engineering. This article details a comparative study of a GAparsimony R Package with six model complexity metrics. The objective was to identify an adequate model complexity measure for searching for accurate parsimonious solutions by combining feature selection, hyperparameter optimization, and parsimonious evaluation. This study also includes a regression code example to address some recommended precautions and considerations to find robust parsimonious models. This code can be easily adapted to other problems, databases, or algorithms.},
  archive      = {J_NEUCOM},
  author       = {F.J. Martinez-de-Pison and J. Ferreiro and E. Fraile and A. Pernia-Espinoza},
  doi          = {10.1016/j.neucom.2020.02.135},
  journal      = {Neurocomputing},
  pages        = {317-332},
  shortjournal = {Neurocomputing},
  title        = {A comparative study of six model complexity metrics to search for parsimonious models with GAparsimony r package},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The prior probability in the batch classification of
imbalanced data streams. <em>NEUCOM</em>, <em>452</em>, 309–316. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the diversity of contemporary decision-making tasks, where the data is no longer static and changes over time, data stream processing has become an important issue in the field of pattern recognition. In addition, most of the real problems are not balanced, representing their classes in various improportions. Following paper proposes the Prior Imbalance Compensation method, modifying on-the-fly predictions made by the base classifier , aiming at mapping prior probability in the statistics of assigned classes. It is intended to be a less computationally complex competition for popular algorithms such as smote , solving this problem by oversampling the training set. The proposed method has been tested using computer experiments on the example of a set of various data streams, leading to promising results, suggesting its usefulness in solving this type of problems.},
  archive      = {J_NEUCOM},
  author       = {Paweł Ksieniewicz},
  doi          = {10.1016/j.neucom.2019.11.126},
  journal      = {Neurocomputing},
  pages        = {309-316},
  shortjournal = {Neurocomputing},
  title        = {The prior probability in the batch classification of imbalanced data streams},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on hybrid artificial intelligence systems from
HAIS 2018 conference. <em>NEUCOM</em>, <em>452</em>, 307–308. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Héctor Quintián and Emilio Corchado},
  doi          = {10.1016/j.neucom.2020.09.057},
  journal      = {Neurocomputing},
  pages        = {307-308},
  shortjournal = {Neurocomputing},
  title        = {Special issue on hybrid artificial intelligence systems from HAIS 2018 conference},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning locomotion skills in evolvable robots.
<em>NEUCOM</em>, <em>452</em>, 294–306. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The challenge of robotic reproduction – making of new robots by recombining two existing ones – has been recently cracked and physically evolving robot systems have come within reach. Here we address the next big hurdle: producing an adequate brain for a newborn robot. In particular, we address the task of targeted locomotion which is arguably a fundamental skill in any practical implementation. We introduce a controller architecture and a generic learning method to allow a modular robot with an arbitrary shape to learn to walk towards a target and follow this target if it moves. Our approach is validated on three robots, a spider, a gecko, and their offspring, in three real-world scenarios.},
  archive      = {J_NEUCOM},
  author       = {Gongjin Lan and Maarten van Hooft and Matteo De Carlo and Jakub M. Tomczak and A.E. Eiben},
  doi          = {10.1016/j.neucom.2021.03.030},
  journal      = {Neurocomputing},
  pages        = {294-306},
  shortjournal = {Neurocomputing},
  title        = {Learning locomotion skills in evolvable robots},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A novel fixed-time stability strategy and its application
to fixed-time synchronization control of semi-markov jump delayed neural
networks. <em>NEUCOM</em>, <em>452</em>, 284–293. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper emphasizes on a novel fixed-time stability strategy and its application to fixed-time synchronization control for a class of semi-Markov jump delayed Cohen-Grossberg neural networks (SMJDCGNNs). First, a novel fixed-time stability strategy for a class of nonlinear delayed systems is proposed, which is a generalization of the existing stability strategies. Second, the addressed fixed-time stability strategy is applied to solving fixed-time synchronization control for a class of SMJDCGNNs, whose framework generalizes the existing Cohen-Grossberg neural networks (CGNNs). The application testifies that compared with the existing fixed-time stability strategies, the obtained fixed-time stability strategy can provide a tighter settling time which can more effectively and accurately estimate the convergence time of the studied delayed system. Finally, we give a comparative example to illustrate the validity of our results.},
  archive      = {J_NEUCOM},
  author       = {Xin Wang and Jinde Cao and Jiangtao Wang and Jinshan Qi},
  doi          = {10.1016/j.neucom.2021.04.107},
  journal      = {Neurocomputing},
  pages        = {284-293},
  shortjournal = {Neurocomputing},
  title        = {A novel fixed-time stability strategy and its application to fixed-time synchronization control of semi-markov jump delayed neural networks},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed control of nonlinear stochastic multi-agent
systems with external disturbance and time-delay via event-triggered
strategy. <em>NEUCOM</em>, <em>452</em>, 275–283. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the distributed event-triggered control (ETC) problems for nonlinear stochastic multi-agent systems (MASs) with external disturbance and time-delay are discussed. The leader-following input-to-state actual exponential mean-square consensus (EMSC) criteria are established in networks containing a directed spanning tree. By devising appropriate Lyapunov–Krasovskii function, sufficient conditions for the model to achieve leader-following input-to-state actual EMSC are obtained. The control gain matrix is designed to realize the controller. The lower bounds of interexecution times are given to show that the Zeno-behavior will not appear. Besides, the validity of theoretical analyses is verified by simulation.},
  archive      = {J_NEUCOM},
  author       = {Kailu Sun and Hui Yu and Xiaohua Xia},
  doi          = {10.1016/j.neucom.2021.04.100},
  journal      = {Neurocomputing},
  pages        = {275-283},
  shortjournal = {Neurocomputing},
  title        = {Distributed control of nonlinear stochastic multi-agent systems with external disturbance and time-delay via event-triggered strategy},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-based full slice brain CT image diagnosis with
explanations. <em>NEUCOM</em>, <em>452</em>, 263–274. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Diagnose brain diseases by brain CT images is one of the most common ways. But, it usually takes several ( &gt; 7 &amp;gt;7 ) years to train a professional doctor because it is very challenging to diagnose brain diseases correctly. The study on automated assistance of brain CT diagnosis is still limited. In this paper, we research the challenges of this task and propose a method by simulating human doctor diagnosis habits. Our method analyzes a full slice of brain CT images, instead of every single one, to take into account continuous changes of the whole brain structure, simulate the way the doctor diagnoses. To avoid redundancies in a thin slice scan, we propose a redundancy removal and data augmentation method that can both reduce computation complexity and improve performance without information loss. Doctors make a diagnosis by observing several key images and key points in them. Our method achieved this by two steps of attention mechanisms . It can highlight the images and key points that have significant impacts on the prediction and explain the results. We evaluated our method on two public datasets CQ500 and RSNA, which achieved 0.9262 and 0.8650 F1 score respectively. Moreover, an experienced doctor (with 29 years of experience) verified the promising clinical application value of the proposed method through manual experiments.},
  archive      = {J_NEUCOM},
  author       = {Guanghui Fu and Jianqiang Li and Ruiqian Wang and Yue Ma and Yueda Chen},
  doi          = {10.1016/j.neucom.2021.04.044},
  journal      = {Neurocomputing},
  pages        = {263-274},
  shortjournal = {Neurocomputing},
  title        = {Attention-based full slice brain CT image diagnosis with explanations},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mitigating backdoor attacks in LSTM-based text
classification systems by backdoor keyword identification.
<em>NEUCOM</em>, <em>452</em>, 253–262. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been proved that deep neural networks are facing a new threat called backdoor attacks, where the adversary can inject backdoors into the neural network model through poisoning the training dataset. When the input containing some special pattern called the backdoor trigger, the model with backdoor will carry out malicious task such as misclassification specified by adversaries. In text classification systems, backdoors inserted in the models can cause spam or malicious speech to escape detection. Previous work mainly focused on the defense of backdoor attacks in computer vision, little attention has been paid to defense method for RNN backdoor attacks regarding text classification . In this paper, through analyzing the changes in inner LSTM neurons, we proposed a defense method called Backdoor Keyword Identification (BKI) to mitigate backdoor attacks which the adversary performs against LSTM-based text classification by data poisoning. This method can identify and exclude poisoning samples crafted to insert backdoor into the model from training data without a verified and trusted dataset. We evaluate our method on four different text classification datset: IMDB, DBpedia ontology, 20 newsgroups and Reuters-21578 dataset. It all achieves good performance regardless of the trigger sentences.},
  archive      = {J_NEUCOM},
  author       = {Chuanshuai Chen and Jiazhu Dai},
  doi          = {10.1016/j.neucom.2021.04.105},
  journal      = {Neurocomputing},
  pages        = {253-262},
  shortjournal = {Neurocomputing},
  title        = {Mitigating backdoor attacks in LSTM-based text classification systems by backdoor keyword identification},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coupling adversarial graph embedding for transductive
zero-shot action recognition. <em>NEUCOM</em>, <em>452</em>, 239–252.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot action recognition (ZSAR) aims to recognize novel actions that have not been seen in the training stage. However, ZSAR always suffers from serious domain shift problem, which causes poor performance. This is because: 1) Videos contain complicated intrinsic structures, including cross-sample visual correlations and cross-category semantic relationships , which make it challenging to generalize domain shift over categories and transfer knowledge across videos. 2) Existing methods do not disentangle unique and shared information underlying unseen videos during embedding. They are always weakly adaptive to novel categories and easily shift unseen videos to irrelevant action prototypes. In this paper, we propose a novel Coupling Adversarial Graph Embedding (CAGE) method for ZSAR, which formulates an effective visual-to-semantic embedding to alleviate the domain shift problem. Our model implements in a transductive setting that assumes accessing to a full set of unseen videos. Firstly, a structured graph is built for expressing both seen and unseen videos, which integrally captures visual and semantic relationships between them. Then, an effective visual-to-semantic embedding is formulated based on graph convolutional network (GCN), which is generalized to disjoint action categories and optimized for label propagation. In addition, a couple of adversarial constraints are proposed to characterize unique information of unseen videos and purify shared information across categories, which further improve the adaptability and discriminability of our model. Experiments on Olympic sports, HMDB51 and UCF101 datasets show that our model achieves impressive performance on ZSAR task.},
  archive      = {J_NEUCOM},
  author       = {Yi Tian and Yaping Huang and Wanru Xu and Yu Kong},
  doi          = {10.1016/j.neucom.2021.04.031},
  journal      = {Neurocomputing},
  pages        = {239-252},
  shortjournal = {Neurocomputing},
  title        = {Coupling adversarial graph embedding for transductive zero-shot action recognition},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Mixture of robust gaussian processes and its hard-cut EM
algorithm with variational bounding approximation. <em>NEUCOM</em>,
<em>452</em>, 224–238. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Gaussian process is a powerful statistical learning model and has been applied widely in nonlinear regression and classification. However, it fails to model multi-modal data from a non-stationary source since a prior Gaussian process is generally stationary. Based on the idea of the mixture of experts, the mixture of Gaussian processes was established to increase the model flexibility. On the other hand, the Gaussian process is also sensitive to outliers and thus robust Gaussian processes have been suggested to own the heavy-tailed property. In practical applications, the datasets may be multi-modal and contain outliers at the same time. In order to overcome these two difficulties together, we propose a mixture of robust Gaussian processes (MRGP) model and establish a precise hard-cut EM algorithm for learning its parameters. Since the exact solving process is intractable due to the fact that non-Gaussian probability density functions of the noises are adopted into the likelihood of the proposed model on the dataset, we employ a variational bounding method to approximate the marginal likelihood functions so that the hard-cut EM algorithm can be implemented effectively. Moreover, we conduct various experiments on both synthetic and real-world datasets to evaluate and compare our proposed MRGP method with several competitive nonlinear regression methods . The experimental results demonstrate that our MRGP model with the hard-cut EM algorithm is much more effective and robust than the competitive nonlinear regression models .},
  archive      = {J_NEUCOM},
  author       = {Tao Li and Di Wu and Jinwen Ma},
  doi          = {10.1016/j.neucom.2021.04.085},
  journal      = {Neurocomputing},
  pages        = {224-238},
  shortjournal = {Neurocomputing},
  title        = {Mixture of robust gaussian processes and its hard-cut EM algorithm with variational bounding approximation},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability of internal states in recurrent neural networks
trained on regular languages. <em>NEUCOM</em>, <em>452</em>, 212–223.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We provide an empirical study of the stability of recurrent neural networks trained to recognize regular languages. Noise is used to force the recurrent neurons into saturation. In the saturated regime, analysis of the network activation reveals the formation of clusters that resemble discrete states in a finite state machine . We demonstrate that transitions between these activation clusters in response to input symbols are deterministic and stable. The networks display a stationary behavior for arbitrarily long strings and, when random perturbations are applied, they can recover, and their evolution converges to the original clusters. This observation reinforces the interpretation of the networks as finite automata , with neurons or groups of neurons coding specific and meaningful input patterns.},
  archive      = {J_NEUCOM},
  author       = {Christian Oliva and Luis F. Lago-Fernández},
  doi          = {10.1016/j.neucom.2021.04.058},
  journal      = {Neurocomputing},
  pages        = {212-223},
  shortjournal = {Neurocomputing},
  title        = {Stability of internal states in recurrent neural networks trained on regular languages},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level cross-modal interaction network for RGB-d
salient object detection. <em>NEUCOM</em>, <em>452</em>, 200–211. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth cues with affluent spatial information have been proven beneficial in boosting salient object detection (SOD), while the depth quality directly affects the subsequent SOD performance. However, it is inevitable to obtain some low-quality depth cues due to thelimitations of its acquisition devices, which can inhibit the SOD performance. Besides, existing methods tend to combine RGB images and depth cues in a direct fusion or a simple fusion module, making them not effectively exploit the complex correlations between the two sources. Moreover, few methods design an appropriate module to fully fuse multi-level features, resulting in cross-level feature interaction insufficient. To address these issues, we propose a novel Multi-level Cross-modal Interaction Network ( MCI-Net ) for RGB-D based SOD. Our MCI-Net includes two key components: 1) a cross-modal feature learning network, which is used to learn the high-level features for the RGB images and depth cues, effectively enabling the correlations between the two sources to be exploited; and 2) a multi-level interactive integration network, which integrates multi-level cross-modal features to boost the SOD performance. Extensive experiments on six benchmark datasets demonstrate the superiority of our MCI-Net over 14 state-of-the-art methods, and validate the effectiveness of different components in our MCI-Net . More important, our MCI-Net significantly improves the SOD performance as well as has a higher FPS.},
  archive      = {J_NEUCOM},
  author       = {Zhou Huang and Huai-Xin Chen and Tao Zhou and Yun-Zhi Yang and Bi-Yuan Liu},
  doi          = {10.1016/j.neucom.2021.04.053},
  journal      = {Neurocomputing},
  pages        = {200-211},
  shortjournal = {Neurocomputing},
  title        = {Multi-level cross-modal interaction network for RGB-D salient object detection},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized dilation convolutional neural networks for
remaining useful lifetime estimation. <em>NEUCOM</em>, <em>452</em>,
182–199. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a novel approach for multivariate time series data analysis with special emphasis on industrial sensor data sets. The approach applies deep convolutional neural networks as a base architecture, incorporating a generalization of the dilated convolution operation on the receptive fields. The dilation operation allows for the aggregation of distributed information in the input space compared to standard convolution operation . The proposed dilation methodology allows for a trainable selection and ignorance of individual sensor features, based on their relevance to the prediction task. Furthermore, arbitrary patterns in the input feature space, including in the temporal dimension of the multivariate time series data can be extracted. In contrast to the standard dilation methodology, the proposed generalized dilation technique is end-to-end differentiable and hence can be trained with off the shelf gradient descent optimizers. Two methodologies have been proposed for the resulting constrained optimization problem namely, the Barrier Function and Top-K sampling approach. We apply the dilated convolutional neural networks to remaining useful lifetime (RUL) estimation problems where degradation recognition over a longer time horizon is crucial for precise estimation. We test the approach on two challenging benchmark datasets, namely the PRONOSTIA Bearing Dataset and the C-MAPSS Aircraft Engine Dataset for RUL prediction. The experimental results obtained for RUL estimation show the superior prediction capability of the proposed generalized dilation methodologies and constitute a new state of the art compared to previous results in literature.},
  archive      = {J_NEUCOM},
  author       = {Gavneet Singh Chadha and Utkarsh Panara and Andreas Schwung and Steven X. Ding},
  doi          = {10.1016/j.neucom.2021.04.109},
  journal      = {Neurocomputing},
  pages        = {182-199},
  shortjournal = {Neurocomputing},
  title        = {Generalized dilation convolutional neural networks for remaining useful lifetime estimation},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Building partially understandable convolutional neural
networks by differentiating class-related neural nodes. <em>NEUCOM</em>,
<em>452</em>, 169–181. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, convolutional neural networks (CNNs) have been successfully applied in the field of image processing , and have been deployed to a variety of artificial intelligence systems. However, such neural models are still considered to be “black box” for most tasks. Two of fundamental issues underlying this problem are as follows: 1. What type of knowledge learned by a neural network in a task was not understandable and predictable? 2. The decision made by a neural model was generally not evaluable. Like neural coding in the brain, some neurons only participated in encoding a particular task. Inspired by this, in this paper, we propose a method to modify traditional CNN models into understandable CNNs, to clarify the information coding in high conv-layers of CNNs and further evaluate the decisions made by a neural model. In our understandable CNN models, each neural node (feature map) in a selected conv-layer was assigned to participate in encoding only one class in a classification task . Our models use the same training data as ordinary models without the need for additional annotations for supervision. We applied our method to the ResNet and DenseNet models. The experiments showed that new models can learn the information coding mode that we expected in an image-recognition task, and, using the pre-assigned coding mode, we can interpret why a neural model makes a right or wrong decision, which decisions are credible, and which are not.},
  archive      = {J_NEUCOM},
  author       = {Dawei Dai and Chengfu Tang and Guoyin Wang and Shuyin Xia},
  doi          = {10.1016/j.neucom.2021.04.003},
  journal      = {Neurocomputing},
  pages        = {169-181},
  shortjournal = {Neurocomputing},
  title        = {Building partially understandable convolutional neural networks by differentiating class-related neural nodes},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TSSN-net: Two-step sparse switchable normalization for
learning correspondences with heavy outliers. <em>NEUCOM</em>,
<em>452</em>, 159–168. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we solve the problem of feature matching by designing an end-to-end network (called TSSN-Net). Given putative correspondences of feature points in two views, existing deep learning based methods formulate the feature matching problem as a binary classification problem. In these methods, a normalizer plays an important role in the networks. However, they adopt the same normalizer in all normalization layers of the entire networks, which will result in suboptimal performance. To address this problem, we propose a Two-step Sparse Switchable Normalization Block, which involves the advantage of adaptive normalization for different convolution layers from Sparse Switchable Normalization and robust global context information from Context Normalization. Moreover, to capture local information of correspondences, we propose a Multi-Scale Correspondence Grouping algorithm, by defining a multi-scale neighborhood representation, to search for consistent neighbors of each correspondence. Finally, with a series of convolution layers , the end-to-end TSSN-Net is proposed to learn correspondences with heavy outliers for feature matching. Our experimental results have shown that our network achieves the state-of-the-art performance on benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhen Zhong and Guobao Xiao and Kun Zeng and Shiping Wang},
  doi          = {10.1016/j.neucom.2021.04.093},
  journal      = {Neurocomputing},
  pages        = {159-168},
  shortjournal = {Neurocomputing},
  title        = {TSSN-net: Two-step sparse switchable normalization for learning correspondences with heavy outliers},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial defense via self-orthogonal randomization
super-network. <em>NEUCOM</em>, <em>452</em>, 147–158. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks are demonstrated to be vulnerable to adversarial examples . In this paper, starting from the robustness analysis about the model ensemble, we propose a novel type of defense method named “Self-Orthogonal Randomization Super-network” ( SORS ). More specifically, we think the main robustness benefit from the model ensemble comes from two aspects: smaller adversarial subspace and gradient orthogonality. However, the naive model ensemble has two fundamental limitations: 1) Though ensembling more models will introduce more robustness, training too many models is infeasible and resource-consuming. 2) Since these models are usually trained independently, the gradient orthogonality among them is often partial and weak. Motivated by this, we propose to train one single super-network that consists of the exponential number of sub-networks, and explicitly constrain the gradient of different sub-networks with respect to the same input to be orthogonal. In the inference stage, at each forward pass, one sub-network will be randomly sampled. Through extensive experiments, we demonstrate that the proposed method can achieve significantly better robustness than the vanilla single model baseline and the naive model ensemble baseline. Moreover, this new type of defense strategy is also complementary to other types of defense methods and achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Huanyu Bian and Dongdong Chen and Kui Zhang and Hang Zhou and Xiaoyi Dong and Wenbo Zhou and Weiming Zhang and Nenghai Yu},
  doi          = {10.1016/j.neucom.2021.04.062},
  journal      = {Neurocomputing},
  pages        = {147-158},
  shortjournal = {Neurocomputing},
  title        = {Adversarial defense via self-orthogonal randomization super-network},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Global-local graph convolutional network for cross-modality
person re-identification. <em>NEUCOM</em>, <em>452</em>, 137–146. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-thermal person re-identification (VT-ReID) is an important task for retrieving pedestrian between visible and thermal modality. It makes up for the drawbacks of single modality person re-identification in night surveillance applications. Most of the existing methods extract the features of different images/parts independently which ignore the potential relationship between them. In this paper, we propose a novel Global-Local Graph Convolutional Network (GLGCN) to learn discriminative feature representation by modeling the relation through graph convolutional network. The local graph module builds the potential relation of different body parts within each modality to extract discriminative part-level features. The global module constructs the contextual relation of same identity across two modalities to reduce the modality discrepancy. By training the two modules jointly, the robustness of the model can be further improved. The experiment results on the SYSU-MM01 and RegDB datasets demonstrate that our model outperforms the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Zhang and Xiaohong Li and Cuiqun Chen and Meibin Qi and Jingjing Wu and Jianguo Jiang},
  doi          = {10.1016/j.neucom.2021.04.080},
  journal      = {Neurocomputing},
  pages        = {137-146},
  shortjournal = {Neurocomputing},
  title        = {Global-local graph convolutional network for cross-modality person re-identification},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interlayer synchronization of duplex time-delay network with
delayed pinning impulses. <em>NEUCOM</em>, <em>452</em>, 127–136. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly focuses on interlayer synchronization in a duplex network setting with the intralayer coupling delay and the interlayer transmission delay via pinning impulsive control. Firstly, based on Lyapunov stability theory, a general pinning impulsive strategy guaranteeing interlayer synchronization is obtained. Then, the minimum number of pinned nodes and the maximum impulse interval needed theoretically for interlayer synchronization are obtained. Moreover, when some parameters, including the impulse strengths, the ratio of pinned nodes and the impulse interval, are fixed certain values, their influences on the stable region are further discussed. It is found that the stable region becomes smaller as the ratio of pinned nodes decreases, and gets larger as the impulse strength with no delay is closer to −1 and that with delay is closer to 0. At the same time, the small intralayer coupling delay and interlayer transmission delay can enlarge the stable region. Finally, numerical simulations are provided to verify the effectiveness and correctness of our results.},
  archive      = {J_NEUCOM},
  author       = {Di Ning and Ziye Fan and Xiaoqun Wu and Xiuping Han},
  doi          = {10.1016/j.neucom.2021.04.041},
  journal      = {Neurocomputing},
  pages        = {127-136},
  shortjournal = {Neurocomputing},
  title        = {Interlayer synchronization of duplex time-delay network with delayed pinning impulses},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Resisting membership inference attacks through knowledge
distillation. <em>NEUCOM</em>, <em>452</em>, 114–126. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, membership inference attacks (MIAs) against machine learning models have been proposed. Using MIAs, adversaries can inference whether a data record is in the training set of the target model. Defense methods which use differential privacy mechanisms or adversarial training cannot handle the trade-off between privacy and utility well. Other methods based on knowledge transfer to improve model utility need public unlabeled data in the same distribution as private data, and this requirement may not be satisfied in some scenarios. To handle the trade-off between privacy and utility better, we propose two algorithms of deep learning , i.e., complementary knowledge distillation (CKD) and pseudo complementary knowledge distillation (PCKD). In CKD, the transfer data of knowledge distillation all come from the private training set, but their soft targets are generated from the teacher model which is trained using their complementary set. With similar idea, we propose PCKD which reduces the training set of each teacher model and uses model averaging to generate soft targets of transfer data. Because smaller training set leads to less utility, PCKD utilizes pre-training to improve the utility of teacher models. Experimental results on widely used datasets show that CKD and PCKD can both averagely decrease attack accuracy by nearly 25\% with negligible utility loss. The training time of PCKD is nearly 40\% lower than that of CKD. Compared with existing defense methods such as DMP, adversarial regularization , dropout, and DP-SGD, CKD and PCKD have great advantages on handling the trade-off between privacy and utility.},
  archive      = {J_NEUCOM},
  author       = {Junxiang Zheng and Yongzhi Cao and Hanpin Wang},
  doi          = {10.1016/j.neucom.2021.04.082},
  journal      = {Neurocomputing},
  pages        = {114-126},
  shortjournal = {Neurocomputing},
  title        = {Resisting membership inference attacks through knowledge distillation},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of HEVC double compression with non-aligned GOP
structures via inter-frame quality degradation analysis.
<em>NEUCOM</em>, <em>452</em>, 99–113. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detection of double compression is of great significance to reveal video compression history. However, efficient detection algorithm for High Efficiency Video Coding (HEVC) double compression with non-aligned Group of Pictures (GOP) structures is rarely reported. To address this issue, a novel algorithm based on inter-frame quality degradation process analysis is proposed in this paper. Firstly, a brief introduction to HEVC standard and double compression with non-aligned GOP structures is provided. Next, theoretical analysis of inter-frame quality degradation process is given. Then, from the perspective of filtering decision, the inter-frame In-Loop Filtering Decision Mode (ILFDM) feature is adopted for double compression detection. Finally, the detection framework is given, which includes feature extraction, feature combination and periodic analysis. Experiments are conducted under different coding scenarios, by comparing with existing algorithms, results demonstrate that the proposed algorithm has better performance not only in terms of double compression detection, but also in original GOP size estimation. Furthermore, the proposed scheme is proved to be satisfactory in relocated I-frame detection.},
  archive      = {J_NEUCOM},
  author       = {Qiang Xu and Xinghao Jiang and Tanfeng Sun and Alex C. Kot},
  doi          = {10.1016/j.neucom.2021.04.092},
  journal      = {Neurocomputing},
  pages        = {99-113},
  shortjournal = {Neurocomputing},
  title        = {Detection of HEVC double compression with non-aligned GOP structures via inter-frame quality degradation analysis},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variational quantum tensor networks classifiers.
<em>NEUCOM</em>, <em>452</em>, 89–98. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor networks (TN) are a method of decomposing high-rank tensors into tractable lower rank. In this paper, we present a classification algorithm for variational quantum tensor networks (VQTN), which has higher performance on near-term processors. Motivated by the hybrid quantum–classical architecture, the truncated quantum tensor networks (QTN) outputs are fed into a classical neural network. We then utilize kernel encoding, circuit models, multiple readouts, and stochastic gradient descent to achieve shallow quantum circuits. Finally, we deploy the QTN and VQTN algorithms on the TensorFlow Quantum processor by using the Iris and MNIST data sets. Our algorithm experimentally costs only half of the qubits with an average accuracy of 93.72\% 93.72\% . Compared with the QTN algorithm, the accuracy is improved by 7.71\% 7.71\% .},
  archive      = {J_NEUCOM},
  author       = {Rui Huang and Xiaoqing Tan and Qingshan Xu},
  doi          = {10.1016/j.neucom.2021.04.074},
  journal      = {Neurocomputing},
  pages        = {89-98},
  shortjournal = {Neurocomputing},
  title        = {Variational quantum tensor networks classifiers},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning with noisy labels method for unsupervised domain
adaptive person re-identification. <em>NEUCOM</em>, <em>452</em>, 78–88.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to adapt the model trained on a labeled source domain to an unlabeled target domain. For pseudo-label-based UDA methods, pseudo labels noise is the main problem for model degradation and the factors that cause noise are complex. In this paper, a novel learning with noisy labels (LNL) method for UDA person re-ID is proposed to address this problem by analyzing the noise data itself. LNL learns with noise data from two aspects, including noise correction and noise resistance. According to the idea of neighbor consistency, pseudo labels correction (PLC) based on sample similarity is designed to correct the noisy pseudo labels before training. In order to solve the problem of noise labels in deep learning , noise recognition based on similarity and confidence relationship (SACR) is designed. Then, an easy-to-hard model collaborative training (MCT) strategy is developed, which can resist noise during the training process and obtain a more robust training model. To further avoid overfitting of noisy samples, the re-weighting (RW) method is employed in MCT. The proposed LNL model achieves considerable results of 75.2\%/88.9\% and 62.5\%/77.4\% mAP/Rank-1 on DukeMTMC-reID-to-Market-1501 and Market-1501-to-DukeMTMC-reID UDA tasks.},
  archive      = {J_NEUCOM},
  author       = {Xiaodi Zhu and Yanfeng Li and Jia Sun and Houjin Chen and Jinlei Zhu},
  doi          = {10.1016/j.neucom.2021.04.120},
  journal      = {Neurocomputing},
  pages        = {78-88},
  shortjournal = {Neurocomputing},
  title        = {Learning with noisy labels method for unsupervised domain adaptive person re-identification},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge-preserving MRI image synthesis via adversarial network
with iterative multi-scale fusion. <em>NEUCOM</em>, <em>452</em>, 63–77.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Magnetic resonance imaging (MRI) is a major imaging technique for studying neuroanatomy . By applying different pulse sequences and parameters, different modalities can be generated regarding the same anatomical structure, which can provide complementary information for diagnosis. However, limited by the scanning time and related cost, multiple different modalities are often not available for the same patient in clinic. Recently, many methods have been proposed for cross-modality MRI synthesis, but most of them only consider pixel-level differences between the synthetic and ground-truth images, ignoring the edge information, which is critical to provide clinical information. In this paper, we propose a novel edge-preserving MRI image synthesis method with iterative multi-scale feature fusion based generative adversarial network (EP_IMF-GAN). Particularly, the generator consists of a shared encoder and two specific decoders to carry out different tasks: 1) a primary task aiming to generate the target modality and 2) an auxiliary task aiming to generate the corresponding edge image of target modality. We assume that infusing the auxiliary edge image generation task can help preserve edge information and learn better latent representation features through the shared encoder. Meanwhile, an iterative multi-scale fusion module is embedded in the primary decoder to fuse supplementary information of feature maps at different scales, thereby further improving quality of the synthesized target modality. Experiments on the BRATS dataset indicate that our proposed method is superior to the state-of-the-art image synthesis approaches in both qualitative and quantitative measures. Ablation study further validates the effectiveness of the proposed components.},
  archive      = {J_NEUCOM},
  author       = {Yanmei Luo and Dong Nie and Bo Zhan and Zhiang Li and Xi Wu and Jiliu Zhou and Yan Wang and Dinggang Shen},
  doi          = {10.1016/j.neucom.2021.04.060},
  journal      = {Neurocomputing},
  pages        = {63-77},
  shortjournal = {Neurocomputing},
  title        = {Edge-preserving MRI image synthesis via adversarial network with iterative multi-scale fusion},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review on the attention mechanism of deep learning.
<em>NEUCOM</em>, <em>452</em>, 48–62. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attention has arguably become one of the most important concepts in the deep learning field. It is inspired by the biological systems of humans that tend to focus on the distinctive parts when processing large amounts of information. With the development of deep neural networks , attention mechanism has been widely used in diverse application domains. This paper aims to give an overview of the state-of-the-art attention models proposed in recent years. Toward a better general understanding of attention mechanisms, we define a unified model that is suitable for most attention structures. Each step of the attention mechanism implemented in the model is described in detail. Furthermore, we classify existing attention models according to four criteria: the softness of attention, forms of input feature, input representation, and output representation. Besides, we summarize network architectures used in conjunction with the attention mechanism and describe some typical applications of attention mechanism. Finally, we discuss the interpretability that attention brings to deep learning and present its potential future trends.},
  archive      = {J_NEUCOM},
  author       = {Zhaoyang Niu and Guoqiang Zhong and Hui Yu},
  doi          = {10.1016/j.neucom.2021.03.091},
  journal      = {Neurocomputing},
  pages        = {48-62},
  shortjournal = {Neurocomputing},
  title        = {A review on the attention mechanism of deep learning},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning digital camera pipeline for extreme low-light
imaging. <em>NEUCOM</em>, <em>452</em>, 37–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In low-light conditions, a conventional camera imaging pipeline produces sub-optimal images that are usually dark and noisy due to a low photon count and low signal-to-noise ratio (SNR). We present a data-driven approach that learns the desired properties of well-exposed images and reflects them in images that are captured in extremely low ambient light environments, thereby significantly improving the visual quality of these low-light images. The recent works on this problem only consider a pixel-level loss metric that ignores perceptual quality and thus generate outputs susceptible to visual artifacts. To address this problem, we propose a new loss function that exploits the characteristics of both pixel-wise and perceptual metrics, enabling our deep neural network to learn the camera processing pipeline to transform the short-exposure, low-light RAW sensor data to well-exposed sRGB images. The results show that our method outperforms the state-of-the-art according to psychophysical tests as well as pixel-wise standard metrics and recent learning-based perceptual image quality measures. In essence, the proposed model can potentially replace the conventional digital camera pipeline for the specific case of extreme low-light imaging.},
  archive      = {J_NEUCOM},
  author       = {Syed Waqas Zamir and Aditya Arora and Salman Khan and Fahad Shahbaz Khan and Ling Shao},
  doi          = {10.1016/j.neucom.2021.04.076},
  journal      = {Neurocomputing},
  pages        = {37-47},
  shortjournal = {Neurocomputing},
  title        = {Learning digital camera pipeline for extreme low-light imaging},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial network for table-to-text generation.
<em>NEUCOM</em>, <em>452</em>, 28–36. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Table-to-Text generation aims to generate descriptions which can be viewed as a set of field-value records for factual tables. Despite the significant progress, the state-of-the-art models suffer from two major issues: Nonfluency and Divergence. Nonfluency means descriptions generated by models are not as fluent as those generated by humans, and thus can be distinguished easily. Divergence refers to the fact that the generated sentences contain information which can not be concluded from factual tables. This could be attributed to that most neural models are trained with the Maximum Likelihood Estimation (MLE) loss and use divergence-contained references as the ground truth, which forces the models to learn what cannot be inferred from the source to some extent. Motivated by the limitations of current models, we propose a novel GAN-based model with adversarial learning mechanism, which simultaneously trains a generative model G and a discriminative model D , to address Nonfluency and Divergence issues in Table-to-Text generation. Specifically, we build the generator G as an agent of reinforcement learning with a sequence-to-sequence architecture, which takes the raw data as input and predicts the generated sentences. Meanwhile, we build the discriminator D with a Convolutional Neural Network (CNN) to calculate rewards to measure the fluency of generations. To judge the fidelity of generations with regard to the original table more accurately, we also calculate the rewards from BLEU-Table. With the fusion rewards from CNN and BLEU-Table, our methods outperform the baselines by a large margin on the WikiBio and Wiki3C benchmarks evaluated with BLEU, ROURGE, and PARENT. Specifically, our models achieve 49.0 (BLEU-4), 37.8 (ROUGE-4) and 45.4 (PARENT) on WikiBio, as well as 12.9 (BLEU-4) and 6.9 (ROUGE-4) on Wiki3C. More importantly, we construct a new Wiki3C dataset that improves the insufficiency of datasets and promote the progress in Table-to-Text generation.},
  archive      = {J_NEUCOM},
  author       = {Jianyu Zhao and Zhiqiang Zhan and Tong Li and Rang Li and Changjian Hu and Siyun Wang and Yang Zhang},
  doi          = {10.1016/j.neucom.2021.04.036},
  journal      = {Neurocomputing},
  pages        = {28-36},
  shortjournal = {Neurocomputing},
  title        = {Generative adversarial network for table-to-text generation},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A transfer approach with attention reptile method and
long-term generation mechanism for few-shot traffic prediction.
<em>NEUCOM</em>, <em>452</em>, 15–27. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial–temporal prediction is a fundamental problem for intelligent transportation system (ITS), which is important for traffic management such as vehicle controls and travel plans. Deep learning has achieved success in spatial–temporal prediction with adequate data. However, many cities still suffer from data scarcity due to lack of essential infrastructure and services for data collection. Therefore, spatial–temporal prediction of cities with scarce data can be regarded as a few-shot learning problem. In this paper, we propose a novel transfer learning method to tackle spatial–temporal prediction tasks with only a small collection of data. Our proposed model aims to transfer the knowledge from multiple source cities to the target city by considering the different spatial–temporal distribution similarities between cities. Specifically, our model is designed as a spatial–temporal network based on a first-order meta-learning algorithm Reptile with an attention mechanism . Different from meta-learning algorithms that aim to learn a well-generalized initialization which can be adapted to any new task, our model achieves better performance on the specific target city by considering the different distribution similarities between multiple source cities and the target city. In addition, as it is difficult to learn the long-term spatial–temporal dependency with limited data in the target city, we propose a generation mechanism to learn and transfer long-term temporal features from source cities which have abundant long-period data to the target city. In the experiments, we compare our model with other state-of-the-art methods in real-world traffic prediction task. The experiments demonstrate the effectiveness of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Chujie Tian and Xinning Zhu and Zheng Hu and Jian Ma},
  doi          = {10.1016/j.neucom.2021.03.068},
  journal      = {Neurocomputing},
  pages        = {15-27},
  shortjournal = {Neurocomputing},
  title        = {A transfer approach with attention reptile method and long-term generation mechanism for few-shot traffic prediction},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group multi-scale attention pyramid network for traffic sign
detection. <em>NEUCOM</em>, <em>452</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sign detection has made great progress with the rise of deep learning in recent years. As a result of the complex and changeable traffic environment, detecting small traffic signs in a real-world scene is still a challenging problem. In this paper, a novel group multi-scale attention pyramid network is proposed to address the problem. Specifically, to aggregate the feature at different scales and suppress the messy information in the background, an effective multi-scale attention module is proposed. Furthermore, a feature fusion module, named adaptive pyramid convolution, is further designed, which can drive the network to learn the optimal feature fusion pattern and construct an informative feature pyramid for detecting traffic signs in different sizes. Extensive experimental results on the public traffic sign detection datasets demonstrate the effectiveness and superiority of the proposed method when compared with several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Lili Shen and Liang You and Bo Peng and Chuhe Zhang},
  doi          = {10.1016/j.neucom.2021.04.083},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Group multi-scale attention pyramid network for traffic sign detection},
  volume       = {452},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential synchronization for spatio-temporal directed
networks via intermittent pinning control. <em>NEUCOM</em>,
<em>451</em>, 337–349. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the exponential synchronization of directed spatio-temporal complex networks is concerned via intermittent pinning control, where the underlying topology is very generic and is not necessarily node balanced or strongly connected. Firstly, based on the decomposition of the topological graph into several maximal strongly connected subgraphs , two intermittent pinning controllers are developed. Subsequently, by adding the synchronized state as a virtual node to the original network, the exponential pinning synchronization of the underlying network is discussed, and several sufficient criteria are derived by utilizing M -matrix and LMI technique. Finally, the feasibility of theoretical results is substantiated by an illustrative example.},
  archive      = {J_NEUCOM},
  author       = {Tingting Shi and Cheng Hu and Juan Yu and Haijun Jiang},
  doi          = {10.1016/j.neucom.2021.04.057},
  journal      = {Neurocomputing},
  pages        = {337-349},
  shortjournal = {Neurocomputing},
  title        = {Exponential synchronization for spatio-temporal directed networks via intermittent pinning control},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey on generative adversarial network-based
text-to-image synthesis. <em>NEUCOM</em>, <em>451</em>, 316–336. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of text-to-image synthesis is a new challenge in the field of image synthesis . In the earlier research, the task of text-to-image synthesis is mainly to achieve the alignment of words and images by the way of retrieval based on the sentences or keywords. With the development of deep learning , especially the application of deep generative models in image synthesis , image synthesis achieves promising progress. The Generative adversarial networks (GANs) are one of the most significant generative models , and GANs have been successfully applied in computer vision, natural language processing and so on. In this paper, we review and summarize the recent research in GANs-based text-to-image synthesis, and provide a summary of the development of classic and advanced models. The input of the GANs-based text-to-image synthesis is not only the general text description as earlier studies, also includes scene layout and dialog text. The typical structure of each categories is elaborated. The general text-based image synthesis is the most commonly in the text-to-image synthesis, and it is subdivided into three groups based on the improvements of text information utilization, network structure and output control conditions. Through the survey, the detailed and logical overview of the evolution of GANs-based text-to-image synthesis is presented. Finally, the challenged problems and the future development of text-to-image synthesis are discussed.},
  archive      = {J_NEUCOM},
  author       = {Rui Zhou and Cong Jiang and Qingyang Xu},
  doi          = {10.1016/j.neucom.2021.04.069},
  journal      = {Neurocomputing},
  pages        = {316-336},
  shortjournal = {Neurocomputing},
  title        = {A survey on generative adversarial network-based text-to-image synthesis},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bias-reduced hindsight experience replay with virtual goal
prioritization. <em>NEUCOM</em>, <em>451</em>, 305–315. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hindsight Experience Replay (HER) is a multi-goal reinforcement learning algorithm for sparse reward functions. The algorithm treats every failure as a success for an alternative (virtual) goal that has been achieved in the episode. Virtual goals are randomly selected, irrespective of which are most instructive for the agent. In this paper, we present two improvements over the existing HER algorithm. First, we prioritize virtual goals from which the agent will learn more valuable information. We call this property the instructiveness of the virtual goal and define it by a heuristic measure, which expresses how well the agent will be able to generalize from that virtual goal to actual goals. Secondly, we reduce existing bias in HER by the removal of misleading samples. To test our algorithms, we built three challenging environments with sparse reward functions. Our empirical results in both environments show vast improvement in the final success rate and sample efficiency when compared to the original HER algorithm. A video showing experimental results is available at https://youtu.be/xjAiwJiSeLc.},
  archive      = {J_NEUCOM},
  author       = {B Manela and A Biess},
  doi          = {10.1016/j.neucom.2021.02.090},
  journal      = {Neurocomputing},
  pages        = {305-315},
  shortjournal = {Neurocomputing},
  title        = {Bias-reduced hindsight experience replay with virtual goal prioritization},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Features injected recurrent neural networks for short-term
traffic speed prediction. <em>NEUCOM</em>, <em>451</em>, 290–304. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic speed forecasting is critical in advanced transportation management and traveler route planing. Considering the important influences of spatial–temporal factors and excellent performance of recurrent neural networks (RNNs) in the field of time series analyzing, in this paper, the features injected recurrent neural networks (FI-RNNs) were proposed, which combines sequential time data with contextual factors to mine the potential relationship between traffic state and its context. In this model, a stacked RNN was used to learn the sequence features of traffic data. Meanwhile, a sparse Autoencoder was trained to expand the contextual features, which are high-level coding and abstract representations of contextual factors. Then an merging mechanism which injects contextual features into sequence features was explored to generate fusion features. Finally, the new fused features were fed to the predictor to learn the traffic patterns and predict future speed. Case studies based on two real-world data sets show that the injection of contextual features can greatly improve the accuracy of time series prediction. Comparison with ten frequently used models, including k k -nearest neighbor ( k k -NN), support vector machine (SVM), decision tree (DT), gradient booting decision tree (GBDT), random forest (RF), stacked autoencoder (SAE), and four classic RNNs, also shows the proposed models outperform these state-of-the-art traffic prediction methods in terms of accuracy and stability.},
  archive      = {J_NEUCOM},
  author       = {Licheng Qu and Jiao Lyu and Wei Li and Dongfang Ma and Haiwei Fan},
  doi          = {10.1016/j.neucom.2021.03.054},
  journal      = {Neurocomputing},
  pages        = {290-304},
  shortjournal = {Neurocomputing},
  title        = {Features injected recurrent neural networks for short-term traffic speed prediction},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast and robust multiplane single-molecule localization
microscopy using a deep neural network. <em>NEUCOM</em>, <em>451</em>,
279–289. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single-molecule localization microscopy is a widely used technique in biological research for measuring the nanostructures of samples smaller than the diffraction limit. This study uses multifocal plane microscopy and addresses the three-dimensional (3D) single-molecule localization problem , where lateral and axial locations of molecules are estimated. However, when multifocal plane microscopy is used, the estimation accuracy of 3D localization is easily deteriorated by the small lateral drifts of camera positions. A 3D molecule localization problem was presented along with the lateral drift estimation as a compressed sensing problem. A deep neural network (DNN) was applied to solve this problem accurately and efficiently. The results show that the proposed method is robust to lateral drift and achieves an accuracy of 20 nm laterally and 50 nm axially without an explicit drift correction.},
  archive      = {J_NEUCOM},
  author       = {Toshimitsu Aritake and Hideitsu Hino and Shigeyuki Namiki and Daisuke Asanuma and Kenzo Hirose and Noboru Murata},
  doi          = {10.1016/j.neucom.2021.04.050},
  journal      = {Neurocomputing},
  pages        = {279-289},
  shortjournal = {Neurocomputing},
  title        = {Fast and robust multiplane single-molecule localization microscopy using a deep neural network},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial–temporal pooling for action recognition in videos.
<em>NEUCOM</em>, <em>451</em>, 265–278. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep convolutional neural networks have demonstrated great effectiveness in action recognition with both RGB and optical flow in the past decade. However, existing studies generally treat all frames and pixels equally, potentially leading to poor robustness of models. In this paper, we propose a novel parameter-free spatial–temporal pooling block (referred to as STP ) for action recognition in videos to address this challenge. STP is proposed to learn spatial and temporal weights, which are further used to guide information compression. Different from other temporal pooling layers, STP is more efficient as it discards the non-informative frames in a certain clip. In addition, STP applies a novel loss function that forces the model to learn information from sparse and discriminative frames. Moreover, we introduce a dataset for ferry action classification , named Ferryboat-4 , which includes four categories: Inshore , Offshore , Traffic , and Negative . This designed dataset can be used for the identification of ferries with abnormal behaviors, providing the essential information to support the supervision, management, and monitoring of ships. All the videos are acquired via real-world cameras. We perform extensive experiments on publicly available datasets as well as Ferryboat-4 and find that the proposed method outperforms several state-of-the-art methods in action classification. Source code and datasets are available at https://github.com/jiaming-wang/STP .},
  archive      = {J_NEUCOM},
  author       = {Jiaming Wang and Zhenfeng Shao and Xiao Huang and Tao Lu and Ruiqian Zhang and Xianwei Lv},
  doi          = {10.1016/j.neucom.2021.04.071},
  journal      = {Neurocomputing},
  pages        = {265-278},
  shortjournal = {Neurocomputing},
  title        = {Spatial–temporal pooling for action recognition in videos},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards accurate estimation for visual object tracking with
multi-hierarchy feature aggregation. <em>NEUCOM</em>, <em>451</em>,
252–264. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many methods achieve the visual object tracking task with deep learning technologies. As the deep features of different levels contain various semantic information and functions, this paper presents a multi-hierarchy feature aggregation approach to tackle the specific issues in the tracking task, which consists of two aspects. On one hand, this paper integrates the features captured by the offline and online classifiers at the score level, which constructs complementary roles of these classifiers to enhance the stability of classification. Besides, the proposed offline classifier is continuously optimized with different levels of features to reinforce classification constraints. On the other hand, we design a butterfly attention module to promote the capacity of multi-hierarchy feature aggregation in the regression network, which aims to fuse and strengthen the multi-scale features by attending to their spatial information. It can capture more spatial contexts by utilizing the self-attention mechanism during the fusion procedure, and preserve the hierarchy of the features during the strengthening process. Extensive experiments on four public datasets, i.e., VOT2018, OTB100, NFS and LaSOT datasets, demonstrate the effectiveness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Wu and Jianguo Jiang and Meibin Qi and Xiaohong Li},
  doi          = {10.1016/j.neucom.2021.04.075},
  journal      = {Neurocomputing},
  pages        = {252-264},
  shortjournal = {Neurocomputing},
  title        = {Towards accurate estimation for visual object tracking with multi-hierarchy feature aggregation},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evolving neuro-fuzzy system based on uni-nullneurons with
advanced interpretability capabilities. <em>NEUCOM</em>, <em>451</em>,
231–251. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a hybrid architecture based on neural networks , fuzzy systems, and n-uninorms for solving pattern classification problems, termed as ENFS-Uni0 (short for evolving neuro-fuzzy system based on uni-nullneurons). The model can produce knowledge in an on-line (single-pass) and evolving learning context in a particular form of neuro-fuzzy rules representing the dependencies among input features through IF-THEN type relations. The rules antecedents are thereby realized through uni-nullneurons, which are constructed from n-uninorms, leading to the possibility to express both, AND- and OR-connections (and a mixture of these) among the single antecedent parts of a rule (and thus achieving an advanced interpretability aspect of the rules). The neurons’ evolution is done through an extended version of an autonomous data partition method (ADPA). On-line interpretation of the timely evolution of rules is addressed by (i) a concept for tracking the degree of changes of the rules over data stream samples, which may indicate experts/operators how much dynamics is in the process and may be used as a structural active learning component to request operator’s feedback in the case of significant changes and (ii) a concept for updating feature weights incrementally. These weights express the (possibly changing) impact degrees of features on the classification problem: features with low weights can be seen as unimportant and masked out when showing rules to an expert ( → → rule length reduction). The rules’ consequents are represented by certainty vectors and are recursively updated by an indicator-based recursive weighted least squares (I-RWLS) approach (one RWLS estimator per class) where the weights are given through the neuron activation levels in order to gain stable local learning. The model proposed in this paper was successfully compared to related hybrid and evolving approaches in the literature for classifying binary and multi-class patterns. The results obtained by the proposed model show an outperformance of the related works in terms of higher accuracy trend lines over time, while offering a high degree of interpretability through coherent neuro-fuzzy rules to solve the classification problems.},
  archive      = {J_NEUCOM},
  author       = {Paulo Vitor de Campos Souza and Edwin Lughofer},
  doi          = {10.1016/j.neucom.2021.04.065},
  journal      = {Neurocomputing},
  pages        = {231-251},
  shortjournal = {Neurocomputing},
  title        = {An evolving neuro-fuzzy system based on uni-nullneurons with advanced interpretability capabilities},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PDANet: Pyramid density-aware attention based network for
accurate crowd counting. <em>NEUCOM</em>, <em>451</em>, 215–230. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting, i.e. , estimating the number of people in crowded areas, has attracted much interest in the research community. Although many attempts have been reported, crowd counting remains an open real-world problem due to the vast density variations and severe occlusion within the interested crowd area. In this paper, we propose a novel Pyramid Density-Aware Attention based network, abbreviated as PDANet, which leverages the attention, pyramid scale feature, and two branch decoder modules for density-aware crowd counting. The PDANet utilizes these modules to extract features of different scales while focusing on the relevant information and suppressing the misleading information. We also address the variation of crowdedness levels among different images with a Density-Aware Decoder (DAD) modules. For this purpose, a classifier is constructed to evaluate the density level of the input features and then passes them to the corresponding high and low density DAD modules. Finally, we generate an overall density map by considering the summation of low and high crowdedness density maps. Meanwhile, we employ different losses aiming to achieve a precise density map for the input scene. Extensive evaluations conducted on the challenging benchmark datasets well demonstrate the superior performance of the proposed PDANet in terms of the accuracy of counting and generated density maps over the well-known state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Saeed Amirgholipour and Wenjing Jia and Lei Liu and Xiaochen Fan and Dadong Wang and Xiangjian He},
  doi          = {10.1016/j.neucom.2021.04.037},
  journal      = {Neurocomputing},
  pages        = {215-230},
  shortjournal = {Neurocomputing},
  title        = {PDANet: Pyramid density-aware attention based network for accurate crowd counting},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot learning system based on dynamic movement primitives
and neural network. <em>NEUCOM</em>, <em>451</em>, 205–214. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the process of Human-robot skill transfer, we require the robot to reproduce the trajectory of teacher and expect that the robot can generalize the learned trajectory. For the trajectory after generalization, we expect that the robot arm can accurately track. However, because the model of the robot can not be accurately obtained, some researchers have proposed using a neural network to approximate the unknown term. The parameters of the traditional RBF neural network are usually selected through the empirical and trial-and-error method, which maybe biased and inefficient. In addition, due to the end-effector of the mechanical arm trajectory will be constantly changing according to the needs of the task, when the neural network of compact set cannot contain the whole input vector, the neural network cannot achieve the ideal approximation effect. In this paper, the broad neural network is used to approximate the unknown terms of the robot. This method can reuse the motion controller that has been learned and complete other motions in the robot operating space without relearning its weight parameters. In this paper, the effectiveness of the proposed method is proved by the ultrasound scanning task.},
  archive      = {J_NEUCOM},
  author       = {Ying Zhang and Miao Li and Chenguang Yang},
  doi          = {10.1016/j.neucom.2021.04.034},
  journal      = {Neurocomputing},
  pages        = {205-214},
  shortjournal = {Neurocomputing},
  title        = {Robot learning system based on dynamic movement primitives and neural network},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Single-scale siamese network based RGB-d object tracking
with adaptive bounding boxes. <em>NEUCOM</em>, <em>451</em>, 192–204.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the excellent methods for visual object tracking are based on RGB videos. With the popularity of depth cameras, the research on RGB-D(RGB+depth) tracking has gradually gained extensive attention. The depth map provides more available information for dealing with intractable tracking problems. How to make full use of depth maps to construct a better tracker is the foremost problem to be settled. The fully-convolutional siamese network shows excellent performance in 2D tracking, but still cannot achieve satisfying tracking performance in complex scenarios. Therefore, we have proposed the RGB-D tracker integrated with the single-scale siamese network as well as the adaptive bounding boxes, which achieves stable tracking performance under the challenges such as occlusion, scale variation and background clutter. Our proposed adaptive strategy enables the bounding box to adjust automatically when the target appearance changes during the tracking, instead of multi-scale input in the siamese network. We design an effective algorithm to quickly obtain the target depth and construct the 3D local visual field to eliminate the interference from background and similar objects. In addition, the total occlusion handling approach combined with RGB and depth information has achieved more reliable occlusion detection and target recovery. Our presented object tracker, including the strategies of 3D local visual field, adaptive bounding boxes and occlusion handling, has been evaluated on two widely utilized RGB-D tracking benchmarks and achieves suprior performance especially for the situations of occlusion and pedestrian detection.},
  archive      = {J_NEUCOM},
  author       = {Feng Xiao and Qiuxia Wu and Han Huang},
  doi          = {10.1016/j.neucom.2021.04.016},
  journal      = {Neurocomputing},
  pages        = {192-204},
  shortjournal = {Neurocomputing},
  title        = {Single-scale siamese network based RGB-D object tracking with adaptive bounding boxes},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memristive DeepLab: A hardware friendly deep CNN for
semantic segmentation. <em>NEUCOM</em>, <em>451</em>, 181–191. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {DeepLab—one of the most critical deep neural network models for image segmentation—has achieved the most advanced performance in the field of image semantic understanding. However, the rich parameters and calculation of deep convolutional neural networks (DCNNs) demand further research on neuro-inspired computing chips specifically designed for hardware acceleration and AI applications. This motivates memristive solutions—the memristor integrates a range of merits, such as fast speed and nanoscale device, to provide an ideal implementation for building low-power neural computing chips and ultra-high-density non-volatile memory. Here, this paper proposes a memristive DeepLab (MDeepLab) system with software-hardware co-design, in which atrous convolution is used to enlarge the receptive field of neurons, the measure to avoid the gridding effect is adopted. Also, the weights are stored by leveraging the unit of a single crossbar array and the constant-term circuit, which significantly reduces the number of memristor devices, doubles the density, and nearly halves the power consumption conventional crossbar array. Finally, the effectiveness of the proposed scheme is verified by a series of experimental simulations and result analysis, showing the superiority of MDeepLab. This study is expected to provide a new solution for low-power consumption and real-time image processing of edge devices.},
  archive      = {J_NEUCOM},
  author       = {Lin Zhang and Xiaofang Hu and Yue Zhou and Guangdong Zhou and Shukai Duan},
  doi          = {10.1016/j.neucom.2021.04.061},
  journal      = {Neurocomputing},
  pages        = {181-191},
  shortjournal = {Neurocomputing},
  title        = {Memristive DeepLab: A hardware friendly deep CNN for semantic segmentation},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention-aware conditional generative adversarial networks
for facial age synthesis. <em>NEUCOM</em>, <em>451</em>, 167–180. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) have recently achieved impressive results in facial age synthesis. However, these methods usually select an autoencoder-style generator. And the bottleneck layer in the encoder-decoder generally gives rise to blurry and low-quality generation. To address this limitation, we propose a novel attention-aware conditional generative adversarial network (ACGAN). First, we utilize two different attention mechanisms to improve generation quality. On one hand, we integrate channel attention modules into the generator to enhance the discriminative representation power. On the other hand, we introduce a position attention mask to well-process images captured with various backgrounds and illuminations. Second, we deploy a local discriminator to enhance the central face region with informative details. Third, we adopt three types of losses to achieve accurate age generation and preserve personalized features: 1) The adversarial loss aims to synthesize photo-realistic faces with expected aging effects; 2) The identity loss intends to keep identity information unchanged; 3) The attention loss tries to improve the accuracy of attention mask regression. To assess the effectiveness of the proposed method, we conduct extensive experiments on several public aging databases. Experimental results on MORPH, CACD, and FG-NET show the effectiveness of the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Xiahui Chen and Yunlian Sun and Xiangbo Shu and Qi Li},
  doi          = {10.1016/j.neucom.2021.04.068},
  journal      = {Neurocomputing},
  pages        = {167-180},
  shortjournal = {Neurocomputing},
  title        = {Attention-aware conditional generative adversarial networks for facial age synthesis},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BPFINet: Boundary-aware progressive feature integration
network for salient object detection. <em>NEUCOM</em>, <em>451</em>,
152–166. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks have improved the results of salient object detection by a significant margin. Most existing methods focus on aggregating multi-level features but pay little attention to the differences between their spatial resolution. Besides, the widely used binary cross entropy loss treats all pixels equally and neglects the fact that pixels near the salient boundaries are prone to being misclassified. To solve these problems, we propose a novel network named BPFINet to aggregate low-level detail features, high-level semantic information, and global information progressively by using the U-shape Feature Integration Modules (UFIMs). Moreover, a U-shape Self-Refinement Module (USRM) is proposed to generate multi-scale representation from the intra-layer features and fuse them progressively to generate features robust to scale variation of salient objects. Besides, a Channel Compression Module (CCM) is designed to reduce the channel number of certain features and enhance the features by leveraging channel-wise attention. Furthermore, an integrated loss is introduced to highlight pixels near the salient boundaries and solve the problem caused by the imbalance of foreground and background regions. Experimental results on six benchmark datasets prove that our BPFINet is competitive compared with 16 other state-of-the-art methods. The source code will be publicly available at https://github.com/clelouch/BPFINet .},
  archive      = {J_NEUCOM},
  author       = {Tianyou Chen and Xiaoguang Hu and Jin Xiao and Guofeng Zhang},
  doi          = {10.1016/j.neucom.2021.04.078},
  journal      = {Neurocomputing},
  pages        = {152-166},
  shortjournal = {Neurocomputing},
  title        = {BPFINet: Boundary-aware progressive feature integration network for salient object detection},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Multi-scale and multi-pooling sparse filtering: A simple
and effective representation learning method for intelligent fault
diagnosis. <em>NEUCOM</em>, <em>451</em>, 138–151. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Representation learning (RL) has gained increasingly considerable attention in intelligent fault diagnosis due to its great capability of automatically learning useful features. Most existing studies focus on developing various variants about RL through modifying loss function of original versions, whereas it is a challenging task. Using the promising sparse filtering as the basic module, this paper presents a simple and effective RL method called multi-scale and multi-pooling sparse filtering (MSMPSF). Instead of modifying loss function of sparse filtering, we simply introduce two fusion mechanisms into sparse filtering, i.e., multi-scale fusion and multi-pooling fusion. In detail, the former aims to learn different local features from the collected signals under multiple scales. The latter tries to fuse various local features using multiple poolings. With these two mechanisms, MSMPSF is capable of capturing complementary fault information hidden in raw signals of several scales and obtaining richly informative feature representations, hence it can perform better. The proposed method is evaluated through experiments on three datasets about gear and bearing. Extensive comparison results confirm that both of two mechanisms facilitate a significant improvement on diagnosis performance. Furthermore, our method receives very reliable and competitive results in terms of diagnosis accuracy and stability in comparison with existing related works.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Zhang and Qingyu Yang and Yanyang Zi},
  doi          = {10.1016/j.neucom.2021.04.066},
  journal      = {Neurocomputing},
  pages        = {138-151},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale and multi-pooling sparse filtering: A simple and effective representation learning method for intelligent fault diagnosis},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-time adaptive neural tracking control of output
constrained nonlinear pure-feedback system with input saturation.
<em>NEUCOM</em>, <em>451</em>, 125–137. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the fixed-time tracking control problem for system-constrained nonlinear pure-feedback systems involving input saturation and output constraints. A sequence of auxiliary virtual and actual input signals is designed to obtain an expression for the system tracking error and stabilize the system. A combination of the fixed-time stability theory, barrier Lyapunov function , and radial basis function neural network is employed to develop the proposed method for obtaining the expected performance from the considered system. Further, a theorem is proposed to ensure that the designed controller allows the system output to track the reference signal within a fixed time, ensuring that the tracking error is limited to a small neighborhood of origin within a fixed time and that all the signals in the system are bounded. The aforementioned problem can be solved using the proposed control method , and the simulation experiments indicate the effectiveness of the designed controller.},
  archive      = {J_NEUCOM},
  author       = {Cheng He and Jian Wu and Jiyang Dai and Zhe Zhang},
  doi          = {10.1016/j.neucom.2021.04.067},
  journal      = {Neurocomputing},
  pages        = {125-137},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time adaptive neural tracking control of output constrained nonlinear pure-feedback system with input saturation},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning bayesian networks using a* search with ancestral
constraints. <em>NEUCOM</em>, <em>451</em>, 107–124. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When using a Bayesian network to model a practical problem, weak prior knowledge projected as ancestral constraints is necessary. However, it is difficult to directly utilize these non-decomposable constraints using search strategies based on the decomposable score. In this study, we attempt to solve this problem by conducting an implicate path-space search graph and driving the A* algorithm, which is used to obtain the globally optimal solution satisfying the given constraints. We use a maximum covering principle to provide useful pruning rules based on these constraints in the new framework. Moreover, we improve the simple heuristic and the static k-cycle conflict heuristic to adapt to ancestral constraints. We theoretically prove that the new heuristic functions remain admissible and consistent. Our experiments demonstrate that the proposed framework with the new heuristic functions significantly reduces the space complexity of A* search compared with state-of-the-art frameworks, such as Bayesian network graphs and equivalent class trees, when integrating ancestral constraints.},
  archive      = {J_NEUCOM},
  author       = {Zidong Wang and Xiaoguang Gao and Xiangyuan Tan and Xiaohan Liu},
  doi          = {10.1016/j.neucom.2021.04.054},
  journal      = {Neurocomputing},
  pages        = {107-124},
  shortjournal = {Neurocomputing},
  title        = {Learning bayesian networks using a* search with ancestral constraints},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Circular complement network for RGB-d salient object
detection. <em>NEUCOM</em>, <em>451</em>, 95–106. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the supplement of texture and geometry cues in depth maps, some difficult scenes of salient object detection (SOD) in 2D images can be overcome. However, some distractors in the depth maps with relatively poor quality may interfere with SOD. Thus, how to suppress the interference of depth maps and extract valuable depth cues, is a critical issue to serve as effective complements to RGB cues. Aiming at addressing this issue, we propose a predict-refine scheme based Circular Complement Network (CCNet), which consists of a prediction subnetwork and a refinement subnetwork . On one hand, since RGB images generally contain more essential information for SOD, we propose a strategy which employs higher-level RGB feature maps to suppress the interference of depth feature maps. With this strategy, a novel Circular Feature Complement (CFC) module is specifically designed to enhance depth feature maps as well as to promote mutual complementarity between RGB feature maps and depth feature maps. The CFC modules are embedded into two subnetworks to achieve the cross-modal interactions at three levels. On the other hand, for the sake of the integration of two subnetworks, a Transmission Bridge (TB) module is proposed to effectively transfer the feature maps of the prediction subnetwork to the refinement subnetwork. The non-salient regions are thus further suppressed in the TB module. Comprehensive experiments on six benchmark datasets show that the proposed CCNet outperforms 13 state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Zhen Bai and Zhi Liu and Gongyang Li and Linwei Ye and Yang Wang},
  doi          = {10.1016/j.neucom.2021.04.052},
  journal      = {Neurocomputing},
  pages        = {95-106},
  shortjournal = {Neurocomputing},
  title        = {Circular complement network for RGB-D salient object detection},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GenExp: Multi-objective pruning for deep neural network
based on genetic algorithm. <em>NEUCOM</em>, <em>451</em>, 81–94. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unstructured deep neural network (DNN) pruning have been widely studied. However, previous schemes only focused upon compressing the model’s memory footprint , which had led to relatively low reduction ratio in computational workload. This study demonstrates that the main reason behind is the inconsistent distribution of memory footprint and workload of the DNN model among different layers. Based on this observation, we propose to map the network pruning flow as a multi-objective optimization problem and design an improved genetic algorithm , which can efficiently explore the whole pruning structure space with both pruning goals equally constrained, to find the suitable solution that strikes a judicious balance between the DNN’s model size and workload. Experiments show that the proposed scheme can achieve up to 34\% 34\% further reduction on the model’s computational workload compared to the state-of-the-art pruning scheme [11] , [33] for ResNet50 on the ILSVRC-2012 dataset. We have also deployed the pruned ResNet50 models on a dedicated DNN accelerator, and the measured data have shown a considerable 6 × 6× reduction in inference time compared to FPGA accelerator implementing dense CNN model quantized in INT8 format, and a 2.27 × 2.27× improvement in power efficiency over 2080Ti GPU-based implementations, respectively.},
  archive      = {J_NEUCOM},
  author       = {Ke Xu and Dezheng Zhang and Jianjing An and Li Liu and Lingzhi Liu and Dong Wang},
  doi          = {10.1016/j.neucom.2021.04.022},
  journal      = {Neurocomputing},
  pages        = {81-94},
  shortjournal = {Neurocomputing},
  title        = {GenExp: Multi-objective pruning for deep neural network based on genetic algorithm},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Adaptive multi-level feature fusion and attention-based
network for arbitrary-oriented object detection in remote sensing
imagery. <em>NEUCOM</em>, <em>451</em>, 67–80. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with the classic object detection problem, detecting objects in aerial images has some special challenges including huge orientation variations, complicated and large background, and wide multi-scale distribution. Considering these three challenges together, we propose a novel arbitrary-oriented object detection framework consisting of three main parts. Firstly, the Cascading Attention Network (CA-Net) composed of a patching self-attention module and a supervised spatial attention module is proposed for enhancing the feature representations from objects of interest and suppressing the background noises in Feature Pyramid Network (FPN) from coarse to fine. Then, the Adaptive Feature Concatenate Network (AFC-Net) is proposed to adaptively stack the feature maps pooled from all FPN levels as well as the global semantic features , for dealing with the multi-scale change of objects. Lastly, the OBB Multi-Definition and Selection Strategy (OBB-MDS-Strategy) is proposed to regress rotated bounding boxes more smoothly and detect oriented objects more accurately in the training process. Our experiments are conducted on two common and challenging aerial datasets, i.e., DOTA and HRSC2016. Experiments results show that the proposed method has superior performances in multi-orientated objects detection compared with the representative methods.},
  archive      = {J_NEUCOM},
  author       = {Luchang Chen and Chunsheng Liu and Faliang Chang and Shuang Li and Zhaoying Nie},
  doi          = {10.1016/j.neucom.2021.04.011},
  journal      = {Neurocomputing},
  pages        = {67-80},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multi-level feature fusion and attention-based network for arbitrary-oriented object detection in remote sensing imagery},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). QIRM: A quantum interactive retrieval model for session
search. <em>NEUCOM</em>, <em>451</em>, 57–66. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web search has become a popular way for people to obtain information. Due to the complexity of search task, one retrieval cannot serve all of user’s information needs. Multiple interactions with the search engine are required, and session search comes into being. Currently proposed session search methods still cannot take advantage of interactive information to capture the user’s implicit information needs. Recently, quantum theory has been successively applied into information retrieval task. We find the similarities between quantum measurements and session interactions. This paper thus develops a Quantum Interactive Retrieval Model (QIRM), which involves both quantum standard measurement (QSM) and quantum weak measurement (QWM) to re-characterize the user’s cognition shifts during a session interaction. Particularly, the user’s cognition states in strong interaction and weak interaction are quantified into quantum-like representations formalized by QSM and QWM, respectively. The representations are then viewed as the user’s information needs for computing ranking score of an evaluated document. We conduct experiments on TREC 2013 and 2014 Session Track datasets. The empirical evaluation demonstrates the effectiveness of our proposed methods, which obtains very comparable performance in terms of nDCG@10 and ERR@10.},
  archive      = {J_NEUCOM},
  author       = {Panpan Wang and Yuexian Hou and Zhao Li and Yazhou Zhang},
  doi          = {10.1016/j.neucom.2021.04.013},
  journal      = {Neurocomputing},
  pages        = {57-66},
  shortjournal = {Neurocomputing},
  title        = {QIRM: A quantum interactive retrieval model for session search},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Context-aware positional representation for self-attention
networks. <em>NEUCOM</em>, <em>451</em>, 46–56. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In self-attention networks (SANs), positional embeddings are used to model order dependencies between words in the input sentence and are added with word embeddings to gain an input representation, which enables the SAN-based neural model to perform (multi-head) and to stack (multi-layer) self-attentive functions in parallel to learn the representation of the input sentence. However, this input representation only involves static order dependencies based on discrete position indexes of words, that is, is independent of context information, which may be weak in modeling the input sentence. To address this issue, we proposed a novel positional representation method to model order dependencies based on n-gram context or sentence context in the input sentence, which allows SANs to learn a more effective sentence representation. To validate the effectiveness of the proposed method, it is applied to the neural machine translation model , which adopts a typical SAN-based neural model. Experimental results on two widely used translation tasks, i.e., WMT14 English-to-German and WMT17 Chinese-to-English, showed that the proposed approach can significantly improve the translation performance over the strong Transformer baseline.},
  archive      = {J_NEUCOM},
  author       = {Kehai Chen and Rui Wang and Masao Utiyama and Eiichiro Sumita},
  doi          = {10.1016/j.neucom.2021.04.055},
  journal      = {Neurocomputing},
  pages        = {46-56},
  shortjournal = {Neurocomputing},
  title        = {Context-aware positional representation for self-attention networks},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CCPrune: Collaborative channel pruning for learning compact
convolutional networks. <em>NEUCOM</em>, <em>451</em>, 35–45. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (CNNs) is difficult to deploy on resource-constrained devices due to its huge amount of computation. Channel pruning is an effective method to reduce the amount of computation and accelerate network inference. Most of channels pruning methods use statistics from a single structure (convolutional layer or batch normalization layer) of the sparse network to evaluate the importance of channels. The limitation of these methods is that it may often mistakenly delete the important channels. In view of this, we propose a novel method, namely Collaborative Channel Pruning (CCPrune), to evaluate the importance of channels, which combines the convolution layer weights and the BN layer scaling factors. The proposed method first introduces the regularization on the convolution layer weights and the BN layer scaling factors respectively. Then combine the weight of the convolutional layer and the scaling factor of the BN layer to evaluate the importance of the channel. Finally, it can delete the unimportant channels without reduces the performance of the model. The experimental results well demonstrate the effectiveness of our method. On CIFAR-10, it can reduce the FLOPs of VGG-19 by 85.50\% while only slightly reducing the accuracy of the model, and it can reduce the FLOPs of Resnet-50 by 78.31\% without reducing the accuracy of the model, respectively.},
  archive      = {J_NEUCOM},
  author       = {Yanming Chen and Xiang Wen and Yiwen Zhang and Weisong Shi},
  doi          = {10.1016/j.neucom.2021.04.063},
  journal      = {Neurocomputing},
  pages        = {35-45},
  shortjournal = {Neurocomputing},
  title        = {CCPrune: Collaborative channel pruning for learning compact convolutional networks},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Speech neuromuscular decoding based on spectrogram images
using conformal predictors with bi-LSTM. <em>NEUCOM</em>, <em>451</em>,
25–34. (<a href="https://doi.org/10.1016/j.neucom.2021.03.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationships between muscle movements and neural signals make it possible to decode silent speech based on neuromuscular activities . The decoding can be formulated as a supervised classification task . The electromyography (EMG) captured from surface articulatory muscles contains useful information that can help assist in decoding of speech. Spectrograms obtained from EMG have a wealth of information relating to the decoding, but have not yet been fully explored. In addition, the decoding results are often uncertain. Therefore, it is important to quantify the prediction confidence. This paper aims to improve the decoding performance by representing time series signals as spectrograms and utilising Inductive Conformal Prediction (ICP) to provide predictions with confidence. All EMG data are recorded on six dedicated facial muscles while participants recite the displayed words subvocally. Three pre-trained convolutional models of MobileNet-V1, ResNet18 and Xception are used to extract features from spectrograms for classification. Both bidirectional Long-Short Time Memory (Bi-LSTM) and Gate Recurrent Unit (GRU) classifiers are used for prediction. Furthermore, an ICP decoder based on Bi-LSTM is built to provide guaranteed predictions for each example at a specified confidence level. The proposed method of combining feature extraction based on Xception and classification using Bi-LSTM gives a higher accuracy of 0.87 than other methods. ICP outputs confidence measurements for each example that can help users to evaluate the reliability of new predictions. Experimental results demonstrate the practical usefulness in decoding articulatory neuromuscular activity and the advantages in applying ICP.},
  archive      = {J_NEUCOM},
  author       = {You Wang and Ming Zhang and Rumeng Wu and Hengyang Wang and Zhiyuan Luo and Guang Li},
  doi          = {10.1016/j.neucom.2021.03.025},
  journal      = {Neurocomputing},
  pages        = {25-34},
  shortjournal = {Neurocomputing},
  title        = {Speech neuromuscular decoding based on spectrogram images using conformal predictors with bi-LSTM},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Crowd counting based on attention-guided multi-scale fusion
networks. <em>NEUCOM</em>, <em>451</em>, 12–24. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an attention-guided multi-scale fusion network (named as AMS-Net) for crowd counting in dense scenarios. The overall model is mainly comprised by the density and the attention networks. The density network is able to provide a coarse prediction of the crowd distribution (density map), while the attention network helps to distinguish crowded regions from backgrounds. The output of the attention network serves as a mask of the coarse density map. The number of persons in the scene is finally estimated by applying integration on the refined density map. In order to deal with persons of varied resolutions, we introduce a multi-scale fusion strategy which is built upon dilated convolution. Experiments are carried out on the standard benchmark datasets, covering varied over-crowded scenarios. Experimental results demonstrate the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Bo Zhang and Naiyao Wang and Zheng Zhao and Ajith Abraham and Hongbo Liu},
  doi          = {10.1016/j.neucom.2021.04.045},
  journal      = {Neurocomputing},
  pages        = {12-24},
  shortjournal = {Neurocomputing},
  title        = {Crowd counting based on attention-guided multi-scale fusion networks},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A dense connection encoding–decoding convolutional neural
network structure for semantic segmentation of thymoma. <em>NEUCOM</em>,
<em>451</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurately positioning and segmenting thymoma from computed tomography (CT) images is of great importance for an image-driven thymoma analysis. In clinical practice, the diagnosis and segmentation of thymomas for radiologists are time-consuming and inefficient tasks. Thus, it is necessary to develop a method to accurately and efficiently realize automatic segmentation of thymoma. Here, a dense skip connection encoding–decoding model (DSC-Net), which is a deep convolutional neural network , was proposed to perform automatic segmentation of thymoma with the ability to fuse feature maps under receptive fields of different scales. An image preprocessing method was also proposed to provide much more texture information and enhance the contrast between thymoma and its surrounding tissues. A total of 310 subjects who underwent contrast-enhanced CT scanning were included in this ethically-approved retrospective study. All of the CT slices were manually labeled by four experienced radiologists, and 80\% of images were included in the training set and the rest were included in the testing set. The performance of segmentation was evaluated by calculating the accuracy, intersection over union (IoU), and Boundary F1 contour matching score (BFScore) between the predicted segmentation and the manual labels. For segmentation of thymoma in the testing set, the accuracy, IoU and BFScore were 92.96\%, 87.86\% and 0.9087 respectively. Compared to the U-Net method, the DSC-Net model improved IoU by 3.94\%. In addition, the efficacy and robustness of DSC-Net in segmentation of different patients and different types of thymoma classified by the WHO histological classification criteria were verified. The proposed preprocessing method and DSC-Net demonstrated improved performance in segmentation of thymomas, suggesting the ability to provide consistent delineation and assist radiologists in their clinical applications.},
  archive      = {J_NEUCOM},
  author       = {Jingyuan Li and Wenfang Sun and Xiulong Feng and Gang Xing and Karen M. von Deneen and Wen Wang and Yi Zhang and Guangbin Cui},
  doi          = {10.1016/j.neucom.2021.04.023},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {A dense connection encoding–decoding convolutional neural network structure for semantic segmentation of thymoma},
  volume       = {451},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Improving robustness of deep neural networks via
large-difference transformation. <em>NEUCOM</em>, <em>450</em>, 411–419.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent research shows that previous model-agnostic methods that transform the input images before feeding them into the classifiers fail to defend against the adversarial examples . We assume that the small-difference transformations commonly used are the blame and therefore propose a new model-agnostic defense using a large-difference transformation. Specifically, we try to apply the novel primitive-based transformation that re-builds the input images by primitives of colorful triangles. In terms of the distortions required to completely break the defenses, our experiments on the ImageNet subset show that significantly large distortions (0.12) are needed to break the defense compared to other state-of-the-art model-agnostic defenses (0.05–0.06) under the strong attack method Backward Pass Differentiable Approximation (BPDA). This finding indicates that large difference transformation can improve the adversarial robustness, suggesting a promising new direction towards solving the challenge of adversarial robustness.},
  archive      = {J_NEUCOM},
  author       = {Longwei Wang and Chengfei Wang and Yupeng Li and Rui Wang},
  doi          = {10.1016/j.neucom.2021.03.112},
  journal      = {Neurocomputing},
  pages        = {411-419},
  shortjournal = {Neurocomputing},
  title        = {Improving robustness of deep neural networks via large-difference transformation},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust stability for a class of fractional-order
complex-valued projective neural networks with neutral-type delays and
uncertain parameters. <em>NEUCOM</em>, <em>450</em>, 399–410. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is devoted to researching the robust stability of fractional-order complex-valued projective neural networks (FOCVPNNs) with neutral-type delays and uncertain parameters. Without dividing the FOCVPNNs into two real-valued systems, based on Lyapunov method, matrix inequality technique and homeomorphism principle, several delay-independent and delay-dependent criteria are established to make sure that the equilibrium point of the addressed FOCVPNNs is existent, unique and globally robustly stable. Finally, three examples with simulations are given to verify the availability of the main results.},
  archive      = {J_NEUCOM},
  author       = {Weiqin Huang and Qiankun Song and Zhenjiang Zhao and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2021.04.046},
  journal      = {Neurocomputing},
  pages        = {399-410},
  shortjournal = {Neurocomputing},
  title        = {Robust stability for a class of fractional-order complex-valued projective neural networks with neutral-type delays and uncertain parameters},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual leader-follower synchronization controller design
for distributed parameter multi-agent systems with time-varying
disturbances. <em>NEUCOM</em>, <em>450</em>, 389–398. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the virtual leader-follower synchronization control problem for a class of distributed parameter multi-agent systems, and all agents are governed by the heat equations with structured time-varying perturbations and time-varying disturbances, communicating through an undirected and connected static topology. A stable heat equation is designed as the virtual leader, and all agents as followers need to track the leader, such that the multi-agent systems can achieve a consensus. The design of the controller is split into two parts: one is design infinite dimension observers to estimate the total disturbances online by using the estimation/cancellation strategy in active disturbance rejection control (ADRC), the other is that the adaptive proportional differential (PD) synchronous controller determined by the Lyapunov functional is proposed to ensure all agent’s states and the leader’s state reach a consensus. The linear local interaction protocol realizes the synchronization of multi-agent system, and the adaptive PD control accelerates the subsystem to follow the virtual leader. The well-posedness of the closed-loop system is analyzed and proved. Simulation results illustrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jiangtao Zheng and Xiju Zong and Hao Ge and Zeyang Zheng and Munashe Cane Makuwatsine},
  doi          = {10.1016/j.neucom.2021.04.025},
  journal      = {Neurocomputing},
  pages        = {389-398},
  shortjournal = {Neurocomputing},
  title        = {Virtual leader-follower synchronization controller design for distributed parameter multi-agent systems with time-varying disturbances},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autoencoder framework based on orthogonal projection
constraints improves anomalies detection. <em>NEUCOM</em>, <em>450</em>,
372–388. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this study, we propose a novel autoencoder framework based on orthogonal projection constraint (OPC) for anomaly detection (AD) on both complex image and vector datasets. Orthogonal projection is useful to capture the null subspace that consists of noisy information for AD, which is explicitly ignored in the existing approaches. The exploration of double subspaces, called normal space (NS) and abnormal space (AS) can improve the discriminative manifold information. Therefore, in this study, autoencoder framework based on the OPC learning method is proposed that combines the orthogonal subspace score and the reconstruction error score in the target tasks for AD. To the best of our knowledge, this is the first study that introduces an autoencoder-based model with two orthogonal subspaces for AD. Through the orthogonality, the anomaly-free data and abnormal ⧹ ⧹ ⧹ nosiy information are projected into the NS and the AS, respectively. Thus, it potentially addresses the problem of the distribution of generative model by combining the abilities of two subspaces that can appropriately learn the features and establish a strict boundaries around the normal data. For image datasets, we propose a convolutional autoencoder based on OPC. Additionally, the generalization and adaptability of the proposed method in AD was investigated using vector datasets by implementing a fully-connected layer-based OPC in the encoder-decoder structure. The effectiveness of the proposed framework for AD was evaluated through the comparison with state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Qien Yu and Muthusubash Kavitha and Takio Kurita},
  doi          = {10.1016/j.neucom.2021.04.033},
  journal      = {Neurocomputing},
  pages        = {372-388},
  shortjournal = {Neurocomputing},
  title        = {Autoencoder framework based on orthogonal projection constraints improves anomalies detection},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D-TDC: A 3D temporal dilation convolution framework for
video action recognition. <em>NEUCOM</em>, <em>450</em>, 362–371. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action recognition is a vital area of computer vision. By adding temporal dimension into convolution structure, 3D convolution neural network owns the capacity to extract spatio-temporal features from videos. However, due to computing constraints, it is hard to input the whole video into the convolution network at one time, resulting in a limited temporal receptive field of the network. To address this issue, we propose a novel 3D temporal dilation convolution (3D-TDC) framework, to extract spatio-temporal features of actions from videos. First, we deploy the 3D temporal dilation convolution as the shallow temporal compression layer, enabling an effective capture of spatio-temporal information in a larger time domain with the reduced computational load. Then, an action recognition framework is constructed by integrating two networks with different temporal receptive fields to balance the long-short time difference. We conduct extensive experiments on three widely-used public datasets (UCF-101, HMDB-51, and Kinetics-400) for performance evaluation, and the experimental results demonstrate the effectiveness of our proposed framework in video action recognition with low computational load.},
  archive      = {J_NEUCOM},
  author       = {Yue Ming and Fan Feng and Chao Li and Jing-Hao Xue},
  doi          = {10.1016/j.neucom.2021.03.120},
  journal      = {Neurocomputing},
  pages        = {362-371},
  shortjournal = {Neurocomputing},
  title        = {3D-TDC: A 3D temporal dilation convolution framework for video action recognition},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive sparse dropout: Learning the certainty and
uncertainty in deep neural networks. <em>NEUCOM</em>, <em>450</em>,
354–361. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dropout is an important training method for deep neural networks , because it can help avoid over-fitting. Traditional dropout methods and many extended dropout methods, omit some of the neurons’ activation values according to the probabilities. These methods calculate the activation probability of neurons using the designed formula, without providing a plausible explanation of the calculation method. This paper proposes an adaptive sparse dropout (AS-Dropout) method for neural network training. The algorithm maps the neurons’ activation values in a layer to a relative linear range of a sigmoid function , determines the ratio of active neurons by a probability calculation process, and drops most of neurons according to the probabilities. The probability calculation depends on the activation values of the neurons. The selection of active neurons is according to the probabilities. Therefore, AS-Dropout learns both the certainty and uncertainty in deep neural networks . Additionally, since only a small number of neurons are active, AS-Dropout increases the sparsity of the network. We applied AS-Dropout in different neural network structures. When evaluated on MNIST, COIL-100, and Caltech-101 datasets, the experimental results demonstrated that, overall, AS-Dropout substantially outperformed the traditional dropout and some improved dropout methods.},
  archive      = {J_NEUCOM},
  author       = {Yuanyuan Chen and Zhang Yi},
  doi          = {10.1016/j.neucom.2021.04.047},
  journal      = {Neurocomputing},
  pages        = {354-361},
  shortjournal = {Neurocomputing},
  title        = {Adaptive sparse dropout: Learning the certainty and uncertainty in deep neural networks},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Partially black-boxed collective interpretation and its
application to SOM-based convolutional neural networks. <em>NEUCOM</em>,
<em>450</em>, 336–353. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to extend collective interpretation to networks with complicated components. The collective interpretation is used to generate an internally interpretable model independently of specific inputs and learning conditions. The internally interpretable model is obtained by network compression where multi-layers are sequentially compressed, taking into account all possible routes from inputs to outputs. The network compression is easily applied to fully connected networks, but it cannot be applied to some networks with complicated components. Thus, to make the compression possible, we black-box partially and minimally these components to be replaced by the ordinary components. For demonstrating the effectiveness of this technique, we use here a new model based on the self-organizing map (SOM). Then, we introduce the convolutional neural networks (CNN) for dealing with SOM knowledge, usually represented in two-dimensional lattices. Because our network compression cannot deal with those convolutional components, we temporarily black-box the CNN components. Fixing the other connection weights, we re-train the partially black-boxed network to obtain the simplest prototype model for interpretation. The method was applied to two well-known data sets, and we demonstrated that the present method could compress the networks to get the simplest and interpretable ones. In addition, very stable compressed weights for interpretation could be obtained for easy interpretation. The results suggest that the main mechanism of multi-layered neural networks is based on linear relations between individual inputs and targets, to which peripheral non-linear ones are added.},
  archive      = {J_NEUCOM},
  author       = {Ryotaro Kamimura},
  doi          = {10.1016/j.neucom.2021.04.019},
  journal      = {Neurocomputing},
  pages        = {336-353},
  shortjournal = {Neurocomputing},
  title        = {Partially black-boxed collective interpretation and its application to SOM-based convolutional neural networks},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantic segmentation of breast ultrasound image with fuzzy
deep learning network and breast anatomy constraints. <em>NEUCOM</em>,
<em>450</em>, 319–335. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most serious disease affecting women’s health. Due to low cost, portable, no radiation, and high efficiency, breast ultrasound (BUS) imaging is the most popular approach for diagnosing early breast cancer. However, ultrasound images are low resolution and poor quality. Thus, developing accurate detection system is a challenging task. In this paper, we propose a fully automatic segmentation algorithm consisting of two parts: fuzzy fully convolutional network and accurately fine-tuning post-processing based on breast anatomy constraints. In the first part, the image is pre-processed by contrast enhancement, and wavelet features are employed for image augmentation. A fuzzy membership function transforms the augmented BUS images into the fuzzy domain. The features from convolutional layers are processed using fuzzy logic as well. The conditional random fields (CRFs) post-process the segmentation result. The location relation among the breast anatomy layers is utilized to improve the performance. The proposed method is applied to the dataset with 325 BUS images, and achieves state-of-the-art performance compared with that of existing methods with true positive rate 90.33\%, false positive rate 9.00\%, and intersection over union (IoU) 81.29\% on tumor category, and overall intersection over union (mIoU) 80.47\% over five categories: fat layer, mammary layer, muscle layer, background, and tumor.},
  archive      = {J_NEUCOM},
  author       = {Kuan Huang and Yingtao Zhang and H.D. Cheng and Ping Xing and Boyu Zhang},
  doi          = {10.1016/j.neucom.2021.04.012},
  journal      = {Neurocomputing},
  pages        = {319-335},
  shortjournal = {Neurocomputing},
  title        = {Semantic segmentation of breast ultrasound image with fuzzy deep learning network and breast anatomy constraints},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Global asymptotic stability of fractional-order
complex-valued neural networks with probabilistic time-varying delays.
<em>NEUCOM</em>, <em>450</em>, 311–318. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability of fractional-order complex-valued neural networks (FOCVNNs) with probabilistic time-varying delays is investigated in this paper. By constructing suitable Lyapunov–Krasovskii functional and utilizing inequality technique, a complex-valued linear matrix inequality (LMI) criterion guaranteeing the global asymptotic stability of the proposed FOCVNNs is deduced. A numerical example with simulations is provided to demonstrate the feasibility and availability of the obtained theoretical result.},
  archive      = {J_NEUCOM},
  author       = {Sihan Chen and Qiankun Song and Zhenjiang Zhao and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2021.04.043},
  journal      = {Neurocomputing},
  pages        = {311-318},
  shortjournal = {Neurocomputing},
  title        = {Global asymptotic stability of fractional-order complex-valued neural networks with probabilistic time-varying delays},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatiotemporal non-negative projected convolutional network
with bidirectional NMF and 3DCNN for remaining useful life estimation of
bearings. <em>NEUCOM</em>, <em>450</em>, 294–310. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life (RUL) estimation for bearings is crucial in guaranteeing the reliability of rotating machinery. With the rapid development of information science, deep-learning-based RUL estimation has become more appealing as it can automatically establish the mapping relationship between the monitored data and the degradation states through feature learning. Vibration analysis via time–frequency representation (TFR) has shown great advantages for the detection of bearing damage in deep-learning-based prognostics. However, the following two problems remain: 1) insufficient or ineffective utilization of the data feature information, and 2) the requirement for huge computational resources, which still present challenges for the accuracy and efficiency of TFR-based prognostics. A novel RUL estimation approach called spatiotemporal non-negative projected convolutional network (SNPCN) is hence proposed. The approach can fully learn the spatiotemporal degradation features of bearing TFRs with high computational efficiency. In detail, the continuous wavelet transform (CWT) was applied as a TFR analysis method to reveal the nonstationary properties of the bearing degradation signals. Then, a newly proposed bidirectional non-negative matrix factorization (BiNMF) method was used to obtain the low-rank eigenmatrices of the TFRs and greatly compress the calculations in TFR-based prognostics. A three-dimensional convolutional neural network (3DCNN) was next constructed to learn the spatiotemporal degradation features in adjacent BiNMF eigenmatrices and construct the mapping relationship between the bearing RUL and current monitored data. Experiments on the PRONOSTIA platform demonstrate the feasibility and superiority of the proposed SNPCN-based bearing RUL estimation approach.},
  archive      = {J_NEUCOM},
  author       = {Xu Wang and Tianyang Wang and Anbo Ming and Wei Zhang and Aihua Li and Fulei Chu},
  doi          = {10.1016/j.neucom.2021.04.048},
  journal      = {Neurocomputing},
  pages        = {294-310},
  shortjournal = {Neurocomputing},
  title        = {Spatiotemporal non-negative projected convolutional network with bidirectional NMF and 3DCNN for remaining useful life estimation of bearings},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An evidential classifier based on dempster-shafer theory and
deep learning. <em>NEUCOM</em>, <em>450</em>, 275–293. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a new classifier based on Dempster-Shafer (DS) theory and a convolutional neural network (CNN) architecture for set-valued classification. In this classifier, called the evidential deep-learning classifier, convolutional and pooling layers first extract high-dimensional features from input data. The features are then converted into mass functions and aggregated by Dempster’s rule in a DS layer. Finally, an expected utility layer performs set-valued classification based on mass functions. We propose an end-to-end learning strategy for jointly updating the network parameters. Additionally, an approach for selecting partial multi-class acts is proposed. Experiments on image recognition, signal processing, and semantic-relationship classification tasks demonstrate that the proposed combination of deep CNN, DS layer, and expected utility layer makes it possible to improve classification accuracy and to make cautious decisions by assigning confusing patterns to multi-class sets.},
  archive      = {J_NEUCOM},
  author       = {Zheng Tong and Philippe Xu and Thierry Denœux},
  doi          = {10.1016/j.neucom.2021.03.066},
  journal      = {Neurocomputing},
  pages        = {275-293},
  shortjournal = {Neurocomputing},
  title        = {An evidential classifier based on dempster-shafer theory and deep learning},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). U-RSNet: An unsupervised probabilistic model for joint
registration and segmentation. <em>NEUCOM</em>, <em>450</em>, 264–274.
(<a href="https://doi.org/10.1016/j.neucom.2021.04.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation and registration have vital roles in computer-assisted diagnosis procedures, challenging tasks suffering from various limitations and artifacts inside images. Recently, deep learning techniques accomplish these two tasks and achieve outstanding performances. However, most deep learning-based methods overlook the potential correlation between each other. In this paper, an unsupervised probabilistic model named U-RSNet is proposed to realize concurrent medical image registration and segmentation in one framework. Specifically, the unsupervised segmentation branch is derived from Bayesian inference. The prior warped atlas for segmentation can be obtained by deforming a known probabilistic atlas by the corresponding invertible deformation field with a well-behaved diffeomorphic guarantee, which can perfectly integrate these two tasks to form a complete intelligent prediction system. In this case, the segmentation performance could be largely improved based on the warped probabilistic atlas obtained from the registration branch. Experiments on human brain 3D magnetic resonance images have demonstrated the effectiveness of our approach. We trained and validated U-RSNet with 1000 images and tested its performances on four public datasets. We showed our method successfully realized concurrent segmentation and registration and yielded better segmentation results than a separately trained network.},
  archive      = {J_NEUCOM},
  author       = {Liang Qiu and Hongliang Ren},
  doi          = {10.1016/j.neucom.2021.04.042},
  journal      = {Neurocomputing},
  pages        = {264-274},
  shortjournal = {Neurocomputing},
  title        = {U-RSNet: An unsupervised probabilistic model for joint registration and segmentation},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient design of multicolumn RBF networks.
<em>NEUCOM</em>, <em>450</em>, 253–263. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To make radial basis function (RBF) networks efficient for large-scale learning tasks, the parallel technique provides a promising way for the construction of multicolumn RBF network (MCRN), where the task to be tackled is decomposed into several subtasks and RBF networks designed for these subtasks are integrated as a parallel structure to obtain the final model. This paper focuses on presenting an efficient design method for MCRN based on improved generalized hybrid constructive (GHC) learning algorithm such that desired performance and high efficiency are guaranteed. Specifically, a minimum difference scheme is firstly introduced to divide a large-scale dataset into several parts with similar distribution. For each subtask, a compact RBF network is designed by improved GHC learning algorithm. By fully considering the inherent properties of RBF networks, a K -nearest potential centers based criterion is established to calculate the output of testing sample. Experiments on some benchmark classification problems are conducted to verify the advantages of the proposed method. In terms of training and testing efficiencies and classification accuracy , it is shown that our model is superior over some existing ones.},
  archive      = {J_NEUCOM},
  author       = {Ziyang Han and Xusheng Qian and He Huang and Tingwen Huang},
  doi          = {10.1016/j.neucom.2021.04.040},
  journal      = {Neurocomputing},
  pages        = {253-263},
  shortjournal = {Neurocomputing},
  title        = {Efficient design of multicolumn RBF networks},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Molecular generative graph neural networks for drug
discovery. <em>NEUCOM</em>, <em>450</em>, 242–252. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drug Discovery is a fundamental and ever-evolving field of research. The design of new candidate molecules requires large amounts of time and money, and computational methods are being increasingly employed to cut these costs. Machine learning methods are ideal for the design of large amounts of potential new candidate molecules, which are naturally represented as graphs. Graph generation is being revolutionized by deep learning methods, and molecular generation is one of its most promising applications. In this paper, we introduce a sequential molecular graph generator based on a set of graph neural network modules, which we call MG 2 N 2 . At each step, a node or a group of nodes is added to the graph, along with its connections. The modular architecture simplifies the training procedure, also allowing an independent retraining of a single module. Sequentiality and modularity make the generation process interpretable. The use of Graph Neural Networks maximizes the information in input at each generative step, which consists of the subgraph produced during the previous steps. Experiments of unconditional generation on the QM9 and Zinc datasets show that our model is capable of generalizing molecular patterns seen during the training phase, without overfitting. The results indicate that our method is competitive, and outperforms challenging baselines for unconditional generation.},
  archive      = {J_NEUCOM},
  author       = {Pietro Bongini and Monica Bianchini and Franco Scarselli},
  doi          = {10.1016/j.neucom.2021.04.039},
  journal      = {Neurocomputing},
  pages        = {242-252},
  shortjournal = {Neurocomputing},
  title        = {Molecular generative graph neural networks for drug discovery},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A local search algorithm for k-means with outliers.
<em>NEUCOM</em>, <em>450</em>, 230–241. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {k -Means is a well-studied clustering problem that finds applications in many fields related to unsupervised learning . It is known that k -means clustering is highly sensitive to the isolated points (called outliers). Such outliers can significantly influence the final cluster configuration and should be removed to obtain quality solutions. In this paper, we study the k -means with outliers problem. Given a set of data points, the problem is to remove a set of outliers such that the k -means clustering cost of the remaining points is minimized. Designing efficient algorithms for this problem remains an active area of research due to its important role in dealing with noisy data. We consider a relaxed objective function and propose a local search algorithm for k -means with outliers. It is shown that the algorithm has better performance guarantees than previously implemented methods. In particular, it yields a constant-factor bi-criteria approximation solution to the problem. Moreover, we show experimentally that the algorithm performs much better than its provable guarantee and dominates other state-of-the-art methods for the problem.},
  archive      = {J_NEUCOM},
  author       = {Zhen Zhang and Qilong Feng and Junyu Huang and Yutian Guo and Jinhui Xu and Jianxin Wang},
  doi          = {10.1016/j.neucom.2021.04.028},
  journal      = {Neurocomputing},
  pages        = {230-241},
  shortjournal = {Neurocomputing},
  title        = {A local search algorithm for k-means with outliers},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image stitching via deep homography estimation.
<em>NEUCOM</em>, <em>450</em>, 219–229. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image stitching is a well-studied problem and has many applications in a variety of fields. Traditional feature based methods rely heavily on accurate localization or even distribution of hand-crafted features, and may fail for some difficult cases. Although there are robust deep learning based homography estimation or semantic alignment methods, their accuracies are not high enough for image stitching problem. In this paper, we present a deep neural network that estimates homography accurately enough for image stitching of images with small parallax. The key components of our network are feature maps with progressively increased resolution and matching cost volumes constructed in hybrid manner. Both of these designs are illustrated to be helpful for performance improvement. We also propose a new stitching oriented loss function that takes image contents into consideration. To train our network, we prepare a synthesized training dataset, the image pairs in which are more nature and similar to those of real world image stitching problem. Experimental results demonstrate that our method outperforms existing deep learning based methods and traditional feature based method in term of quantitative evaluation , visual stitching result and robustness.},
  archive      = {J_NEUCOM},
  author       = {Qiang Zhao and Yike Ma and Chen Zhu and Chunfeng Yao and Bailan Feng and Feng Dai},
  doi          = {10.1016/j.neucom.2021.03.099},
  journal      = {Neurocomputing},
  pages        = {219-229},
  shortjournal = {Neurocomputing},
  title        = {Image stitching via deep homography estimation},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A time-frequency channel attention and vectorization network
for automatic depression level prediction. <em>NEUCOM</em>,
<em>450</em>, 208–218. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physiological studies have illustrated that speech can be used as a biomarker to analyze the severity of depression and different frequency bands of the speech spectrum contribute unequally for depression detection. To this end, we propose a Time-Frequency Attention (TFA) component and combine it with the Squeeze-and-Excitation (SE) component to form our Time-Frequency Channel Attention (TFCA) block for emphasizing those discriminative timestamps, frequency bands and channels. In addition, considering the time-frequency attributes of the data, a Time-Frequency Channel Vectorization (TFCV) block is proposed to vectorize the tensor. Furthermore, we merge the proposed blocks (i.e., TFCA and TFCV blocks) and the two blocks (i.e., Dense block and Transition Layer) of the DenseNet into a unified architecture to form our Time-Frequency Channel Attention and Vectorization (TFCAV) network. In this way, to predict the depression level of an individual, we firstly introduce the sphere embedding normalization method to preprocess the long-term logarithmic amplitude spectrum for maintaining the time-frequency attributes and divide it into segments. Then, these segments are input into the TFCAV network to obtain the depression scores. Finally, the average of scores is taken as the result corresponding to the long-term spectrum. Our method is validated on two challenging databases, i.e., AVEC2013 and AVEC2014 depression databases. The experimental performance illustrates the superiority of the proposed network over some previous methods.},
  archive      = {J_NEUCOM},
  author       = {Mingyue Niu and Bin Liu and Jianhua Tao and Qifei Li},
  doi          = {10.1016/j.neucom.2021.04.056},
  journal      = {Neurocomputing},
  pages        = {208-218},
  shortjournal = {Neurocomputing},
  title        = {A time-frequency channel attention and vectorization network for automatic depression level prediction},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronization of fractional-order spatiotemporal complex
networks with boundary communication. <em>NEUCOM</em>, <em>450</em>,
197–207. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is dedicated to the synchronization problem of fractional-order spatiotemporal networks with boundary coupling. Above all, instead of the traditional coupling form at the whole space, a type of boundary communication mechanism is proposed for fractional-order spatiotemporal networks, where nodes interact each other only at the spatial boundary. Subsequently, based on fractional-order inequalities and various analytical skills, some synchronization criteria are derived for the addressed networks with boundary constant weights or time-varying weights. Particularly, an adaptive scheme and its pinning form are designed to update time-varying coupling weights only based on the states information at the boundary position, which are more effective and convenient compared to the existing adaptive strategies dependent of states information in whole space. In addition, a rigorous theoretical analysis is developed for fractional-order adaptive strategy, which provides a new analytic method for adaptive control of fractional-order models. Lastly, the theoretical analysis is confirmed by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Yapeng Yang and Cheng Hu and Juan Yu and Haijun Jiang and Shiping Wen},
  doi          = {10.1016/j.neucom.2021.04.008},
  journal      = {Neurocomputing},
  pages        = {197-207},
  shortjournal = {Neurocomputing},
  title        = {Synchronization of fractional-order spatiotemporal complex networks with boundary communication},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Zero-sum game-based neuro-optimal control of modular robot
manipulators with uncertain disturbance using critic only policy
iteration. <em>NEUCOM</em>, <em>450</em>, 183–196. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a zero-sum differential game strategy-based neuro-optimal control method is presented via critic only policy iteration-adaptive dynamic programming (COPI-ADP) approach to address optimal trajectory tracking control problem of modular robot manipulators (MRMs) with uncertain disturbance. The dynamic model of modular robot manipulator systems is formulated as an integration of joint subsystems and unknown robotic model uncertainties are identified by the developed linear extension state observer. Then, the optimal control issue of the modular robot manipulator systems with uncertain disturbance is transformed into a two-player zero-sum differential game one. Based on adaptive dynamic programming and policy iteration algorithms, the Hamilton-Jacobi-Issacs (HJI) equation is approximately solved using only critic neural network and thus facilitating the feasible derivation of the approximated optimal control policy. The trajectory of tracking errors of modular robot manipulator system is guaranteed to be uniform ultimate bounded by using the Lyapunov theory. Finally, experiments are provided to demonstrate the advantage and effectiveness of the developed control method.},
  archive      = {J_NEUCOM},
  author       = {Bo Dong and Tianjiao An and Xinye Zhu and Yuanchun Li and Keping Liu},
  doi          = {10.1016/j.neucom.2021.04.032},
  journal      = {Neurocomputing},
  pages        = {183-196},
  shortjournal = {Neurocomputing},
  title        = {Zero-sum game-based neuro-optimal control of modular robot manipulators with uncertain disturbance using critic only policy iteration},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leader-following consensus of delayed neural networks under
multi-layer signed graphs. <em>NEUCOM</em>, <em>450</em>, 168–182. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the leader-following consensus problem for delayed neural networks with multi-layer signed digraph topologies. Both structurally balanced and unbalanced topologies are considered. By using the structural balance theory and the pinning control strategy, some sufficient conditions are given to guarantee that the bipartite leader-following consensus can be reached in structurally balanced multi-layer signed neural networks , which depend on the node dynamics and the topology of the multi-layer signed network. In addition, a scheme is designed for selecting the pinning nodes and gains of each layer to achieve bipartite leader-following consensus. When the multi-layer signed network is structurally unbalanced, the asymptotic stability of the neural network is investigated by decomposing the structurally unbalanced network into a structurally balanced subgraph and some special edges. The conditions proposed in this paper are also suitable for addressing the consensus problem of traditional single layer signed neural networks. Numerical examples are given to illustrate the correctness and effectiveness of the proposed theorems and algorithms.},
  archive      = {J_NEUCOM},
  author       = {Jie Ren and Qiang Song and Yanbo Gao and Min Zhao and Guoping Lu},
  doi          = {10.1016/j.neucom.2021.03.009},
  journal      = {Neurocomputing},
  pages        = {168-182},
  shortjournal = {Neurocomputing},
  title        = {Leader-following consensus of delayed neural networks under multi-layer signed graphs},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural synchronization of optimal structure-based group of
neural networks. <em>NEUCOM</em>, <em>450</em>, 156–167. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a neural synchronization of the optimal structure-based group of neural networks is proposed. Asymmetric cryptography is widely used to generate a key amongst two parties and to exchange the key through an insecure channel. However, since the methods that used this strategy, like RSA, have been compromised, new methods for producing a key that can offer security must be discovered. A new group of cryptography known as neural cryptography was created to solve this issue. The primary aim of neural cryptography is to produce a secret key over an unreliable medium. The optimal neural network architecture for creating and defining a secret key between the two authorized individuals is examined in this article. Furthermore, studies into the coordination of a group of neural networks are uncommon. For the design of the public key exchange protocol , synchronization of a cluster of neural networks with Three Layer Tree Parity Machine (TLTPM) is proposed. To calculate the synchronization time, steps taken, and the number of times the attacking neural network could replicate the actions of the two accepted networks, more than 15 million simulations were run. Various parametric experiments have been conducted on the proposed methodology. Simulations of the approach show that it is correct, according to the results of the paper.},
  archive      = {J_NEUCOM},
  author       = {Arindam Sarkar},
  doi          = {10.1016/j.neucom.2021.04.024},
  journal      = {Neurocomputing},
  pages        = {156-167},
  shortjournal = {Neurocomputing},
  title        = {Neural synchronization of optimal structure-based group of neural networks},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-attention guided representation learning for image-text
matching. <em>NEUCOM</em>, <em>450</em>, 143–155. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-text matching plays an important role in bridging vision and language. Most existing research works embed both images and sentences into a joint latent space to measure their similarities. However, these methods failed to either exploit the interactions between sentences and images, or distinguish the importance of different elements within each modality. In this paper, we propose a self-attention guided representation (SGR) learning model, which incorporates the guidance of self-attention mechanism into cross-attention representation learning module for image-text matching. Specifically, we introduce a self-attention mechanism to discriminate the importance of different words within a sentence, as well as that of different regions within an image. The representations associated with each modality are then fed into a cross-attention module to discover distinct alignments between words and regions. Moreover, we employ Term Frequency - Inverse Document Frequency (TF-IDF) to highlight the words that function prominently in textual descriptions, paving the way to accurate image-text matching results. Extensive experiments on datasets MSCOCO and Flickr30K demonstrate the effectiveness and superiority of our framework.},
  archive      = {J_NEUCOM},
  author       = {Xuefei Qi and Ying Zhang and Jinqing Qi and Huchuan Lu},
  doi          = {10.1016/j.neucom.2021.03.129},
  journal      = {Neurocomputing},
  pages        = {143-155},
  shortjournal = {Neurocomputing},
  title        = {Self-attention guided representation learning for image-text matching},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pyramid convolutional network for colorization in
monochrome-color multi-lens camera system. <em>NEUCOM</em>,
<em>450</em>, 129–142. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of colorization in the monochrome-color multi-lens camera system. The recent convolutional network (CNN) based method learns a 3-D weight volume to solve this problem and gets very high accuracy. But the model size is very big due to the large-displacement problem, i.e. there are large displacements between some pixels in the input gray image and the pixels in the reference image that could provide correct colors. To overcome the limitations, we improve the recent CNN based method and propose to combine pyramid processing with CNNs for colorization. At each level of the pyramid, our method warps the reference image using the estimated warping information map from the previous level so that we can learn a much more compact 3-D weight volume for colorization. We also compute an update to the warping information map by a Markov Random Field method at each level. With the pyramid CNN structure, our model has much smaller model size, and experimental results show that our method outperforms all of the state-of-the-art methods in accuracy as well.},
  archive      = {J_NEUCOM},
  author       = {Xuan Dong and Weixin Li and Xiaojie Wang},
  doi          = {10.1016/j.neucom.2021.04.014},
  journal      = {Neurocomputing},
  pages        = {129-142},
  shortjournal = {Neurocomputing},
  title        = {Pyramid convolutional network for colorization in monochrome-color multi-lens camera system},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Delay-aware model-based reinforcement learning for
continuous control. <em>NEUCOM</em>, <em>450</em>, 119–128. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action delays degrade the performance of reinforcement learning in many real-world systems. This paper proposes a formal definition of delay-aware Markov Decision Process and proves it can be transformed into standard MDP with augmented states using the Markov reward process. We develop a delay-aware model-based reinforcement learning framework that can incorporate the multi-step delay into the learned system models without learning effort. Experiments with the Gym and MuJoCo platforms show that the proposed delay-aware model-based algorithm is more efficient in training and transferable between systems with various durations of delay compared with state-of-the-art model-free reinforcement learning methods.},
  archive      = {J_NEUCOM},
  author       = {Baiming Chen and Mengdi Xu and Liang Li and Ding Zhao},
  doi          = {10.1016/j.neucom.2021.04.015},
  journal      = {Neurocomputing},
  pages        = {119-128},
  shortjournal = {Neurocomputing},
  title        = {Delay-aware model-based reinforcement learning for continuous control},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint feature embedding learning and correlation filters for
aircraft tracking with infrared imagery. <em>NEUCOM</em>, <em>450</em>,
104–118. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared object tracking is a key technology for infrared imaging guidance. Blurred imaging, strong ego-motion and frequent occlusion make it difficult to maintain robust tracking. We observe that the features trained on ImageNet are not suitable for aircraft tracking with infrared imagery. In addition, for deep feature-based tracking, the main computational burden comes from the feedforward pass through the pretrained deep network. To this end, we present an airborne infrared target tracking algorithm that employs feature embedding learning and correlation filters to obtain improved performance. We develop a shallow network and a contrastive center loss function to learn the prototypical representation of the aircraft in the embedding space. The feature embedding module is lightweight and integrated into the efficient convolution operator framework for aircraft tracking. Finally, to demonstrate the effectiveness of our tracking algorithm, we conduct extensive experiments on airborne infrared imagery and benchmark trackers.},
  archive      = {J_NEUCOM},
  author       = {Sijie Wu and Kai Zhang and Shaoyi Li and Jie Yan},
  doi          = {10.1016/j.neucom.2021.04.018},
  journal      = {Neurocomputing},
  pages        = {104-118},
  shortjournal = {Neurocomputing},
  title        = {Joint feature embedding learning and correlation filters for aircraft tracking with infrared imagery},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A unified position-aware convolutional neural network for
aspect based sentiment analysis. <em>NEUCOM</em>, <em>450</em>, 91–103.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect based sentiment analysis (ABSA) can be divided into aspect category sentiment analysis (ACSA) and aspect term sentiment analysis (ATSA). To detect the sentiment polarity in a context given an aspect, both ACSA and ATSA highly rely on aspect-centroid sentiment information. However, aspect terms in ATSA appear in the context, but aspect categories in ACSA may not. This make it difficult to use important aspect position information and further design effective aspect injection strategy when modeling ACSA and ATSA in a unified framework. To address this problem, we propose a novel U nified P osition-aware C onvolutional N eural N etwork (UP-CNN). There are two major modifications in UP-CNN. Firstly, to handle the absence of aspect position in ACSA, we propose an aspect detection network with prior knowledge. Thus ABSA can be solved in a unified view with the important aspect position. Secondly, to fit CNN in ABSA, an aspect mask is proposed to construct aspect-aware context representation. Experimental results on seven datasets demonstrate that our model performs effectively and efficiently on both ACSA and ATSA tasks.},
  archive      = {J_NEUCOM},
  author       = {Xinyi Wang and Feng Li and Zequn Zhang and Guangluan Xu and Jingyuan Zhang and Xian Sun},
  doi          = {10.1016/j.neucom.2021.03.092},
  journal      = {Neurocomputing},
  pages        = {91-103},
  shortjournal = {Neurocomputing},
  title        = {A unified position-aware convolutional neural network for aspect based sentiment analysis},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Bringing order to episodes: Mining timeline in social
media. <em>NEUCOM</em>, <em>450</em>, 80–90. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media is growing at an explosive rate and it becomes increasingly difficult for users to locate useful information from massive and high-velocity social media data . Recently a few social media sites have employed timelines to organize historical data of entities, which greatly improve user experiences in rediscovering important timeline episodes and understanding their order and trends. However, timelines of entities are not explicitly available in most social media sites. In other words, a gap exists between the importance of timelines and their availability in social media. In this paper, we investigate the problem of mining timelines of entities in social media. We delineate its challenges and opportunities, and propose a principled framework Timeliner, which can automatically generate timelines for entities by exploiting their historical social media data . We conduct experiments on real-world datasets, and the experimental results demonstrate that Timeliner can accurately mine timelines of entities in social media.},
  archive      = {J_NEUCOM},
  author       = {Shang Wang and Zhiwei Yang and Yi Chang},
  doi          = {10.1016/j.neucom.2021.04.020},
  journal      = {Neurocomputing},
  pages        = {80-90},
  shortjournal = {Neurocomputing},
  title        = {Bringing order to episodes: Mining timeline in social media},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint feature extraction for multi-source data using similar
double-concentrated network. <em>NEUCOM</em>, <em>450</em>, 70–79. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Joint classification of multi-source data is often better than single-source data in application scenes, but it is difficult to ensure effective feature extraction of multi-source information. In this paper, a similar double-concentrate network, denoted as SDCN, is proposed for extracting features effectively and classifying more accurately based on hyperspectral imagery (HSI) and Light Detection and Ranging (LiDAR) data. Specifically, the dual-concentrate network is first developed to capture spectral and spatial features from HSI, and then expanding the connection of LiDAR information based on the trained HSI branch. Each branch of the designed network is similar, which includes two convolutional layers , one maximum pooling layer, one batch normalization layer and two activation layers. After the network of HSI is fully trained, similar network is deployed to distinguish spatial features and ‘band’ difference of LiDAR data, and different features are also combined with multi-source associations. The absolute symmetry network structure and specific multi-source connection can ensure the orderly and balance of features extracted in this model, and adjust the direction of feature extraction constantly. Experimental results on several real data demonstrate that the proposed SDCN outperforms other relevant state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yixuan Zhu and Wei Li and Mengmeng Zhang and Yong Pang and Ran Tao and Qian Du},
  doi          = {10.1016/j.neucom.2021.03.088},
  journal      = {Neurocomputing},
  pages        = {70-79},
  shortjournal = {Neurocomputing},
  title        = {Joint feature extraction for multi-source data using similar double-concentrated network},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperspectral image shadow compensation via cycle-consistent
adversarial networks. <em>NEUCOM</em>, <em>450</em>, 61–69. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Illumination variance and shadows are challenging problems in remote sensing and hyperspectral imaging applications. Shadow compensation can effectively enhance the accuracy of object detection and material classification. Most shadow compensation methods either require preprocessing to detect the shadow region, or extra knowledge collected from additional sensors. Supervised deep learning based methods require paired samples to train the network. To overcome these restrictions, this work proposes an effective cycle-consistent adversarial network for shadow compensation (SC-CycleGAN). This unsupervised method is able to automatically transfer spectra in shadow region to their nonshadow counterparts, without requiring paired training samples and the step of shadow detection. The superiority of the proposed scheme is confirmed with both laboratory-created labeled data and real airborne data.},
  archive      = {J_NEUCOM},
  author       = {Min Zhao and Longbin Yan and Jie Chen},
  doi          = {10.1016/j.neucom.2021.04.017},
  journal      = {Neurocomputing},
  pages        = {61-69},
  shortjournal = {Neurocomputing},
  title        = {Hyperspectral image shadow compensation via cycle-consistent adversarial networks},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A progressive sampling framework for clustering.
<em>NEUCOM</em>, <em>450</em>, 48–60. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering algorithms become more and more sophisticated to cope with large data sets of increasing complexity. Sampling selection methods are likely to provide an interesting alternative as they can reduce memory requirements, and reduce execution time. Many sampling algorithms for clustering are efficient but they each have their own limitations with large data sets. In this paper, we introduce a sampling framework for clustering algorithms that inherits from both progressive sampling and stratification concepts. Driven by two parameters, the iterative process consists in managing representatives of independent strata that carry similar statistical information regarding the clustering objective. At each iteration, the candidate representatives of the incoming stratum are examined. The interesting feature of the framework stems from the idea of selecting new representatives of the incoming stratum only if they improve the representation quality of the already selected set of samples. The algorithm stops when new representatives are no longer needed, which is likely to happen without examining the whole data set. The tests conducted on synthetic and real world datasets proved that the progressive sampling framework yielded similar results to the sampling algorithm applied to the whole set in a low computational time. In comparison with progressive sampling techniques, using the proposed framework enables smaller sampling sets to be used without loss of accuracy.},
  archive      = {J_NEUCOM},
  author       = {Frédéric Ros and Serge Guillaume},
  doi          = {10.1016/j.neucom.2021.04.029},
  journal      = {Neurocomputing},
  pages        = {48-60},
  shortjournal = {Neurocomputing},
  title        = {A progressive sampling framework for clustering},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identity-and-pose-guided generative adversarial network for
face rotation. <em>NEUCOM</em>, <em>450</em>, 33–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face rotation has been a challenging task due to the variation of head poses, illumination, and occlusions, etc. This work provides a novel Identity-and-Pose-Guided Generative Adversarial Network (IPG-GAN) to generate faces with arbitrary head poses. Besides the proposed architecture, an adversarial head pose estimation loss is newly introduced to make IPG-GAN learn the precise head pose representation, and further improve the face synthesis with the employed adversarial identity classification loss. A dual training strategy is adopted to learn the mutual transformation of identity and head pose representation between two source images in one iteration. Under the supervision of such training, the pose-robust identity representation is learned, and the domain knowledge of the learned representation of identity and head pose is properly distinguished. Additionally, based on the two synthesis approaches, IPG-GAN proposes two strategies of frontalizing the profile probe faces and rotating the faces to profile views for both recognition and verification, which differs from most previous face rotation methods. Quantitative and qualitative experiments on Multi-PIE, LFW, and CFP databases for face synthesis, recognition, and verification show that the proposed method achieves state-of-the-art performance and yields substantial improvements.},
  archive      = {J_NEUCOM},
  author       = {Yi Zhang and Keren Fu and Cong Han and Peng Cheng},
  doi          = {10.1016/j.neucom.2021.04.007},
  journal      = {Neurocomputing},
  pages        = {33-47},
  shortjournal = {Neurocomputing},
  title        = {Identity-and-pose-guided generative adversarial network for face rotation},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). People counting using visible and infrared images.
<em>NEUCOM</em>, <em>450</em>, 25–32. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose the use of convolutional neural networks (CNN) for counting and positioning people given aerial shots of visible and infrared images. Our data set is entirely made of semi-artificial images created from real photographs taken from a drone using a dual FLIR camera. We compare the performance between the CNNs using 3 (RGB) and 4 (RGB + IR) channels, both under different lighting conditions. The 4-channel network responds better in all situations, particularly in cases of poor visible illumination that can be found in night scenarios. The proposed methodology could be applied to real situations when an extensive data bank of 4-channel images is available.},
  archive      = {J_NEUCOM},
  author       = {Joaquín Filipic and Martín Biagini and Ignacio Mas and Claudio D. Pose and Juan I. Giribet and Daniel R. Parisi},
  doi          = {10.1016/j.neucom.2021.03.089},
  journal      = {Neurocomputing},
  pages        = {25-32},
  shortjournal = {Neurocomputing},
  title        = {People counting using visible and infrared images},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial scale-adaptive neural network for crowd
counting. <em>NEUCOM</em>, <em>450</em>, 14–24. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting aims to count the number of pedestrians in an image or a video. Currently, scale variations in crowd counting are inevitable and challenging in practice. Besides, for the crowd counting task, there is only a small amount of annotated data available. It can be seen from previous methods of crowd counting and object detection that the two tasks have similar attention areas. However, existing methods in crowd counting generally ignore the similarities and specialties between the crowd counting task and the object detection task. In this paper, in order to solve the above challenges, we propose an adversarial scale-adaptive neural network (ASANet), consisting of three branches. First, a private branch for the crowd counting task concentrates on generating high-quality density maps. Second, another private branch for the object detection task aims to correctly detect and recognize objects. Third, we design a common branch to learn the similar attention area of the two tasks and assist crowd counting. Experimental results demonstrate an outstanding performance of the ASANet over state-of-the-art methods on three public datasets (ShanghaiTech, UCF_CC_50, and UCF_QNRF).},
  archive      = {J_NEUCOM},
  author       = {Xinyue Chen and Hua Yan and Tong Li and Jialang Xu and Fushun Zhu},
  doi          = {10.1016/j.neucom.2021.03.128},
  journal      = {Neurocomputing},
  pages        = {14-24},
  shortjournal = {Neurocomputing},
  title        = {Adversarial scale-adaptive neural network for crowd counting},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recurrent dictionary learning for state-space models with an
application in stock forecasting. <em>NEUCOM</em>, <em>450</em>, 1–13.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we introduce a new modeling and inferential tool for dynamical processing of time series. The approach is called recurrent dictionary learning (RDL). The proposed model reads as a linear Gaussian Markovian state-space model involving two linear operators, the state evolution and the observation matrices , that we assumed to be unknown. These two unknown operators (that can be seen interpreted as dictionaries) and the sequence of hidden states are jointly learnt via an expectation–maximization algorithm. The RDL model gathers several advantages, namely online processing, probabilistic inference, and a high model expressiveness which is usually typical of neural networks. RDL is particularly well suited for stock forecasting. Its performance is illustrated on two problems: next day forecasting (regression problem) and next day trading (classification problem), given past stock market observations. Experimental results show that our proposed method excels over state-of-the-art stock analysis models such as CNN-TA, MFNN, and LSTM.},
  archive      = {J_NEUCOM},
  author       = {Shalini Sharma and Víctor Elvira and Emilie Chouzenoux and Angshul Majumdar},
  doi          = {10.1016/j.neucom.2021.03.111},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Recurrent dictionary learning for state-space models with an application in stock forecasting},
  volume       = {450},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to predict more accurate text instances for scene
text detection. <em>NEUCOM</em>, <em>449</em>, 455–463. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, multi-oriented text detection methods based on deep neural network have achieved promising performances on various benchmarks. Nevertheless, there are still some difficulties for arbitrary shape text detection, especially for a simple and proper representation of arbitrary shape text instances. In this paper, a pixel-based text detector is proposed to facilitate the representation and prediction of text instances with arbitrary shapes in a simple manner. Firstly, to alleviate the influence of the target vertex sorting and achieve the direct regression of arbitrary shape text instances, the starting-point-independent coordinates regression loss is proposed. Furthermore, to predict more accurate text instances, the text instance accuracy loss is proposed as an assistant task to refine the predicted coordinates under the guidance of IoU. To evaluate the effectiveness of our detector, extensive experiments have been carried on public benchmarks which contain arbitrary shape text instances and multi-oriented text instances. We obtain 84.8\% of F-measure on Total-Text benchmark. The results show that our method can reach state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqian Li and Jie Liu and Guixuan Zhang and Ying Huang and Yang Zheng and Shuwu Zhang},
  doi          = {10.1016/j.neucom.2021.04.035},
  journal      = {Neurocomputing},
  pages        = {455-463},
  shortjournal = {Neurocomputing},
  title        = {Learning to predict more accurate text instances for scene text detection},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel domain activation mapping-guided network (DA-GNT)
for visual tracking. <em>NEUCOM</em>, <em>449</em>, 443–454. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional convolution neural network (CNN)-based visual trackers are easily influenced by too much background information in candidate samples. Further, extreme imbalance of foreground and background samples has a negative impact on training the classifier, whereas features learned from limited data are insufficient to train the classifier. To address these problems, we propose a novel deep neural network for visual tracking, termed the domain activation mapping guided network (DA-GNT). First, we introduce the class activation mapping with weakly supervised localization in multi-domain to identify the most discriminative regions in the bounding box and suppress the background in the positive sample. Next, to further increase the discriminability of deep feature representation, we utilize an ensemble network to achieve a kind of multi-view feature representation and a channel attention mechanism for adaptive feature selection. Finally, we propose a simple but effective data augmentation method to further increase the positive samples for our network training. Extensive experiments on two widely used benchmark datasets demonstrate the effectiveness of the proposed tracking method against many state-of-the-art trackers. The novel DA-GNT is thus posited as a potential benchmark resource for the computer vision and machine learning research community.},
  archive      = {J_NEUCOM},
  author       = {Zhengzheng Tu and Ajian Zhou and Chuang Gan and Bo Jiang and Amir Hussain and Bin Luo},
  doi          = {10.1016/j.neucom.2021.03.056},
  journal      = {Neurocomputing},
  pages        = {443-454},
  shortjournal = {Neurocomputing},
  title        = {A novel domain activation mapping-guided network (DA-GNT) for visual tracking},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time adaptive NN control for permanent magnet
synchronous motors with full-state constraints. <em>NEUCOM</em>,
<em>449</em>, 435–442. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a finite-time adaptive neural network (NN) position tracking control method for the permanent magnet synchronous motor (PM SM) servo system with full-state constraints. NNs are utilized to compensate the parameter uncertainties and load torque disturbances of the PMSM servo system. Multiple barrier Lyapunov functions are introduced in the backstepping based control design, such that the rotor position, the rotor angular velocity and the currents of the d-q axis are constrained in given compact sets. In addition, the finite-time control technique is adopted to the control design, which can accelerate the convergence speed and improve the robustness of the PMSM servo system. Under the proposed control algorithm, the position tracking control is realized in finite time, and the tracking error can converge to a small neighborhood of the origin. Finally, simulation results are presented to show the effectiveness of the developed control approach, and some comparisons are given to show the rapid and accurate position tracking control performance.},
  archive      = {J_NEUCOM},
  author       = {Lusong Ding and Wei Wang and Yang Yu},
  doi          = {10.1016/j.neucom.2021.02.012},
  journal      = {Neurocomputing},
  pages        = {435-442},
  shortjournal = {Neurocomputing},
  title        = {Finite-time adaptive NN control for permanent magnet synchronous motors with full-state constraints},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time detection of bursts in neuronal cultures using a
neuromorphic auditory sensor and spiking neural networks.
<em>NEUCOM</em>, <em>449</em>, 422–434. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The correct identification of burst events is crucial in many scenarios, ranging from basic neuroscience to biomedical applications. However, none of the burst detection methods that can be found in the literature have been widely adopted for this task. As an alternative to conventional techniques, a novel neuromorphic approach for real-time burst detection is proposed and tested on acquisitions from in vitro cultures. The system consists of a Neuromorphic Auditory Sensor, which converts the input signal obtained from electrophysiological recordings into spikes and decomposes them into different frequency bands. The output of the sensor is sent to a trained Spiking Neural Network implemented on a SpiNNaker board that discerns between bursting and non-bursting activity. This data-driven approach was compared with different conventional spike-based and raw-based burst detection methods, addressing some of their drawbacks, such as being able to detect both high and low frequency events and working in an online manner. Similar results in terms of number of detected events, mean burst duration and correlation as current state-of-the-art approaches were obtained with the proposed system, also benefiting from its lower power consumption and computational latency. Therefore, our neuromorphic-based burst detection paves the road to future implementations for real-time neuroprosthetic applications.},
  archive      = {J_NEUCOM},
  author       = {Juan P. Dominguez-Morales and Stefano Buccelli and Daniel Gutierrez-Galan and Ilaria Colombi and Angel Jimenez-Fernandez and Michela Chiappalone},
  doi          = {10.1016/j.neucom.2021.03.109},
  journal      = {Neurocomputing},
  pages        = {422-434},
  shortjournal = {Neurocomputing},
  title        = {Real-time detection of bursts in neuronal cultures using a neuromorphic auditory sensor and spiking neural networks},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive knowledge distillation for image classification.
<em>NEUCOM</em>, <em>449</em>, 411–421. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) is a standard teacher-student learning framework to train a light-weight student network under the guidance of a well-trained, large teacher network. As an effective teaching strategy, interactive teaching has been widely employed at school to motivate students, in which teachers not only provide knowledge, but also give constructive feedback to students upon their responses, to improving their learning performance. In this work, we propose Interactive Knowledge Distillation (IAKD) to leverage the interactive teaching strategy for efficient knowledge distillation. In the distillation process, the interaction between the teacher network and the student one is implemented by swapping-in operations: randomly replacing the blocks in the student network with the corresponding blocks in the teacher network. In this way, we directly involve the teacher’s powerful feature transformation ability for largely boosting the performance of the student network. Experiments with typical settings of teacher-student networks demonstrate that the student networks trained by our IAKD achieve better performance than those trained by conventional knowledge distillation methods on diverse image classification datasets.},
  archive      = {J_NEUCOM},
  author       = {Shipeng Fu and Zhen Li and Zitao Liu and Xiaomin Yang},
  doi          = {10.1016/j.neucom.2021.04.026},
  journal      = {Neurocomputing},
  pages        = {411-421},
  shortjournal = {Neurocomputing},
  title        = {Interactive knowledge distillation for image classification},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous excitation-and-squeeze network for visual
dialog. <em>NEUCOM</em>, <em>449</em>, 399–410. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual dialog is a challenging vision-language task, which requires an agent to answer a series of questions about an image. To answer correctly, the agent should explore question-relevant clues from heterogeneous information, such as resolve visual coreference using dialog history , or locate the referred object in the image. Previous methods usually capture question-relevant factors from heterogeneous information in a sequential manner, that is, first enrich the question context with relevant dialog history , and then use the enriched question to perform visual grounding. However, this sequential way may bring unexpected information mix, leading to wrong answers. In this paper, we propose Heterogeneous Excitation-and-Squeeze Network (HESNet), which can handle with heterogeneous information in a parallel and adaptive way. HESNet contains two key modules: Heterogeneous Excitation Module (HE-Module) and Heterogeneous Squeeze Module (HS-Module). HE-Module excavates question-related clues in heterogeneous information, namely image, dialog history, and candidate answer parallelly by conducting bi-directional excitation operations. Then, the HS-Module squeezes the enriched question representation and multiple enhanced heterogeneous representations adaptively for final answer prediction. Experimental results on VisDial v0.9 and v1.0 datasets show the superiority of the proposed approach over the state-of-the-art methods. The visualization analysis further shows that the proposed HESNet alleviates the information mix by collecting the heterogeneous clues parallelly and adaptively.},
  archive      = {J_NEUCOM},
  author       = {Bingqian Lin and Yi Zhu and Xiaodan Liang},
  doi          = {10.1016/j.neucom.2021.03.104},
  journal      = {Neurocomputing},
  pages        = {399-410},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous excitation-and-squeeze network for visual dialog},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised deep convolutional generative adversarial
networks. <em>NEUCOM</em>, <em>449</em>, 389–398. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GANs) are one of the most important generative network models. Using real samples, the GAN generates fake samples from the noise given as input to the network. This popular network model, which has recently emerged and consists of several variants, has different applications in many areas. Some of the studies have been implemented by applying GANs to real-world problems. Another part is aimed at improving the performance of GANs or eliminating the disadvantages observed over time. One of these studies is DCGAN. The importance of DCGAN is that it contributes significantly to balancing GAN training with its convolutional architecture. GAN and naturally DCGAN have an unsupervised network structure. While the network is informed that the samples given as input are real or fake, the category label information is not given to the network. In the present study, a method is proposed, which enables creating a supervised network structure when using multi-categories data set with DCGAN structure. The proposed method ensures that noise can be given a category label and this generated category label information can be used in the output layer. This method, which is easily applicable and effective, is named as Supervised DCGAN (SDCGAN).},
  archive      = {J_NEUCOM},
  author       = {Abdurrahman Öcal and Lale Özbakır},
  doi          = {10.1016/j.neucom.2021.03.125},
  journal      = {Neurocomputing},
  pages        = {389-398},
  shortjournal = {Neurocomputing},
  title        = {Supervised deep convolutional generative adversarial networks},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view clustering with interactive mechanism.
<em>NEUCOM</em>, <em>449</em>, 378–388. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing multi-view clustering methods either seek to directly learn a consistent spectral embedding, or to learn a consistent graph. This work presents a novel model, called Multi-view Clustering with Interactive Mechanism (MCIM). Using the interactive mechanism, the uniform graph and spectral embedding can be learned alternatively and promote to each other. Furthermore, we perform spectral embedding learning on Grassmann manifold via an implicitly weighted-learning scheme and reveal the clustering result via graph learning. To solve the proposed model, we propose an efficient optimization method and provide the corresponding convergence analysis . The experimental results on real image datasets demonstrate the superiorities of MCIM compared to several SOTA methods.},
  archive      = {J_NEUCOM},
  author       = {Danyang Wu and Zhanxuan Hu and Feiping Nie and Rong Wang and Hui Yang and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.03.065},
  journal      = {Neurocomputing},
  pages        = {378-388},
  shortjournal = {Neurocomputing},
  title        = {Multi-view clustering with interactive mechanism},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi goals and multi scenes visual mapless navigation in
indoor using meta-learning and scene priors. <em>NEUCOM</em>,
<em>449</em>, 368–377. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of visual mapless navigation is to navigate from a random starting point in a scene to a specified target in an unknown environment. A fundamental challenge in visual mapless navigation is generalizing to a novel environment, where the layout of the scenes and appearance of targets are unfamiliar. Furthermore, traditional navigation models are frozen during inference resulting in poor adaptability. To address these issues, we propose a multi goals and multi scenes visual mapless navigation model, which integrates meta learning with spatial relationships between different object categories. In this way, our method not only improves the generalization on multi goals in multi scenes but also encourages effective navigation. Experimental results on AI2-THOR dataset show that our approach significantly outperforms the state-of-the-art model SAVN by &gt; &amp;gt; 27.05\%\% for the average success rate and by &gt; &amp;gt; 31.7\%\% for the average SPL. Our source code and data of this paper are available at: https://github.com/zhiyu-tech/WHU-VMN.},
  archive      = {J_NEUCOM},
  author       = {Fei Li and Chi Guo and Binhan Luo and Huyin Zhang},
  doi          = {10.1016/j.neucom.2021.03.084},
  journal      = {Neurocomputing},
  pages        = {368-377},
  shortjournal = {Neurocomputing},
  title        = {Multi goals and multi scenes visual mapless navigation in indoor using meta-learning and scene priors},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive face super-resolution with cascaded recurrent
convolutional network. <em>NEUCOM</em>, <em>449</em>, 357–367. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Progressive upsampling is beneficial for deep learning based large factor (e.g., 8 × 8× ) super-resolution (SR) to improve network performance and reduce the difficulties of network training. The feedback mechanism is helpful in strengthening the representation power of deep networks since it can efficiently enlarge the receptive field. In this paper, we propose a progressive cascaded recurrent convolutional network , dubbed PCRCN, for large factor face SR (FSR). Specifically, a novel multi-stage cascaded convolutional neural network is developed to progressively obtain high magnification face images, where the first stage of network achieves an initial 2 × 2× magnification image, and the following other stages, adopting the recurrent structure , sequentially generate the corresponding 4 × , 8 × 4×,8× and possibly larger factor SR images through multiple independent iterative modules. The deep features and parsing priors of face are extracted in parallel in each stage of network, and integrated to improve the deep representation ability of network. The training of the whole network is supervised in an end-to-end way by the weighted sum of multiple losses. Compared with other state-of-the-art methods, the experimental results show that the proposed method can achieve superior results in terms of both subjective and objective evaluations.},
  archive      = {J_NEUCOM},
  author       = {Shuang Liu and Chengyi Xiong and Xiaodi Shi and Zhirong Gao},
  doi          = {10.1016/j.neucom.2021.03.124},
  journal      = {Neurocomputing},
  pages        = {357-367},
  shortjournal = {Neurocomputing},
  title        = {Progressive face super-resolution with cascaded recurrent convolutional network},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Passivity-based distributed tracking control of uncertain
agents via a neural network combined with UDE. <em>NEUCOM</em>,
<em>449</em>, 342–356. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the distributed tracking problem of networked agents in the presence of model uncertainties and external disturbances. A novel two-component distributed control scheme is proposed. One component is a passivity-based nominal consensus tracking controller. The passivity technique injects extra damping into the system to enhance the transient performance. The update laws for the feedforward control are designed based on the Lyapunov function terms to ensure the effectiveness. The other component is called NN-UDE, which is a combination of neural network (NN) and uncertainty and disturbance estimator (UDE). NN-UDE is featured with low computational complexity and structural simplicity, and it has less stringent requirements on the structure and performance of the actuator. The comparative simulation studies verify the effectiveness of the proposed control scheme. According to the results, (1) the control input based on NN-UDE exhibits no chattering phenomenon; (2) the computation time of NN-UDE is around half of that in NN .},
  archive      = {J_NEUCOM},
  author       = {Weihao Li and Kaiyu Qin and Bowen Chen and Boxian Lin and Mengji Shi},
  doi          = {10.1016/j.neucom.2021.03.008},
  journal      = {Neurocomputing},
  pages        = {342-356},
  shortjournal = {Neurocomputing},
  title        = {Passivity-based distributed tracking control of uncertain agents via a neural network combined with UDE},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PCCM-GAN: Photographic text-to-image generation with pyramid
contrastive consistency model. <em>NEUCOM</em>, <em>449</em>, 330–341.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synthesizing photographic images from given text descriptions is a challenging problem. Although previous many studies have made significant progress on the visual quality of the generated images by using the multi-stage and attentional network, they ignore the interrelationships between the images generated by the generator in each stage and simply leverage the attention mechanism . In this paper, the Photographic Text-to-Image Generation with Pyramid Contrastive Consistency Model (PCCM-GAN) is proposed to generate photographic images. PCCM-GAN introduces two modules: a Pyramid Contrastive Consistency Model ( PCCM ) and a stack attention model ( Stack-Attn ). Based on generated images from the different stages, PCCM is proposed to compute a contrastive loss for training the generator. Stack-Attn concentrates on generating images with more details and better semantic consistency by stacking the global–local attention mechanism . And visual inspection of the inner product of PCCM and Stack-Attn is also performed to validate their effectiveness. Extensive experiments and ablation studies on the CUB and MS-COCO datasets prove the superiority of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Zhongjian Qi and Jun Sun and Jinzhao Qian and Jiajia Xu and Shu Zhan},
  doi          = {10.1016/j.neucom.2021.03.059},
  journal      = {Neurocomputing},
  pages        = {330-341},
  shortjournal = {Neurocomputing},
  title        = {PCCM-GAN: Photographic text-to-image generation with pyramid contrastive consistency model},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image compressive sensing recovery via group residual based
nonlocal low-rank regularization. <em>NEUCOM</em>, <em>449</em>,
315–329. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To address the ill-posed nature of image compressive sensing (CS) recovery, it is of great importance to properly exploit image priors. In this paper, we propose a novel group residual based nonlocal low-rank regularization for image CS recovery, namely GRNLR-CS, which performs nonlocal low-rank modeling based on the residual of patch group rather than on the patch group itself as conventional methods. In our GRNLR-CS, the weighted Schatten p-norm is adopted as a non-convex surrogate function to estimate the rank of the group residual. To make our GRNLR-CS method tractable and robust, the split Bregman iteration technique is employed to develop an efficient algorithm to solve the optimization problem of GRNLR-CS. Extensive experimental results demonstrate that our GRNLR-CS method outperforms some state-of-the-art optimization based or deep learning based methods for image CS recovery.},
  archive      = {J_NEUCOM},
  author       = {Jin Xu and Zhizhong Fu and Xiaodong Zhu},
  doi          = {10.1016/j.neucom.2021.03.101},
  journal      = {Neurocomputing},
  pages        = {315-329},
  shortjournal = {Neurocomputing},
  title        = {Image compressive sensing recovery via group residual based nonlocal low-rank regularization},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring the auxiliary learning for long-tailed visual
recognition. <em>NEUCOM</em>, <em>449</em>, 303–314. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world visual data often exhibits a long-tailed distribution, where some “head” classes have a large number of samples, yet only a few samples are available for “tail” classes. The fundamental problem of learning with the imbalanced data is that insufficient training samples easily lead to the over-fitting of feature extractor and classifier for tail classes, which can be boiled down into a dilemma: on the one hand, we prefer to increase the exposure of tail class samples to avoid the excessive dominance of head classes in the classifier training. On the other hand, oversampling tail classes makes the network prone to over-fitting, since head class samples are often consequently under-represented. To resolve this dilemma, in this paper, we propose an effective auxiliary learning approach. The key idea is to split a network into a classifier part and a feature extractor part, and then employ different training strategies for each part in an auxiliary learning manner. Specifically, to promote the awareness of tail-classes, a class-balanced sampling scheme is utilised for training both the classifier and the feature extractor as the primary task. For the feature extractor, we also introduce an auxiliary training task, which is to train a classifier under the regular random sampling scheme. In this way, the feature extractor is jointly trained from both sampling strategies and thus can take advantage of all training data and avoid the over-fitting issue. Apart from this basic auxiliary task, we further explore the benefits of different types of auxiliary tasks for improving the generality of learned features, including self-supervised learning and class-wise re-weighting. Without using any bells and whistles, our model compares favourably over state-of-the-art solutions.},
  archive      = {J_NEUCOM},
  author       = {Junjie Zhang and Lingqiao Liu and Peng Wang and Jian Zhang},
  doi          = {10.1016/j.neucom.2021.03.096},
  journal      = {Neurocomputing},
  pages        = {303-314},
  shortjournal = {Neurocomputing},
  title        = {Exploring the auxiliary learning for long-tailed visual recognition},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A parallel multi-module deep reinforcement learning
algorithm for stock trading. <em>NEUCOM</em>, <em>449</em>, 290–302. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep reinforcement learning (DRL) algorithm has been widely used in algorithmic trading. Many fully automated trading systems or strategies have been built using DRL agents, which integrate price prediction and trading signal generation in one system. However, the previous agents extract the current state from the market data without considering the long-term market historical trend when making decisions. Besides, plenty of related and useful information has not been considered. To address these two problems, we propose a novel model named Parallel Multi-Module Deep Reinforcement Learning (PMMRL) algorithm. Here, two parallel modules are used to extract and encode the feature: one module employing Fully Connected (FC) layers is used to learn the current state from the market data of the traded stock and the fundamental data of the issuing company; another module using Long Short-Term Memory (LSTM) layers aims to detect the long-term historical trend of the market. The proposed model can extract features from the whole environment by the above two modules simultaneously, taking the advantages of both LSTM and FC layers. Extensive experiments on China stock market illustrate that the proposed PMMRL algorithm achieves a higher profit and a lower drawdown than several state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Cong Ma and Jiangshe Zhang and Junmin Liu and Lizhen Ji and Fei Gao},
  doi          = {10.1016/j.neucom.2021.04.005},
  journal      = {Neurocomputing},
  pages        = {290-302},
  shortjournal = {Neurocomputing},
  title        = {A parallel multi-module deep reinforcement learning algorithm for stock trading},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). V-SOINN: A topology preserving visualization method for
multidimensional data. <em>NEUCOM</em>, <em>449</em>, 280–289. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data visualization plays an important role in data analysis by displaying data to observers in an interpretable way. Visualizing multidimensional data requires projecting the data into a low-dimensional space that is visible to humans. In this paper, we propose a neural network model that can generate such projections while preserving the topology relationships within data points, which is named Visible Self Organizing Incremental Neural Network (V-SOINN). V-SOINN is able to construct a topology preserving visible network automatically and classify visible nodes to different classes in the low-dimensional space. The thought of topology preserving visualization stems from Self-Organizing Map (SOM). Compared to SOM, the main advantage of V-SOINN is that it does not need prior decision of network structure, including the number of nodes and grid in the output layer. V-SOINN can show the density distribution of datasets by using the activation counts of datasets. V-SOINN is able to depict the number of classes in the low-dimensional space as well. We perform experiments on artificial and real-world datasets, and V-SOINN outperforms PCA , MDS, t-SNE, Neural Gas and SOM on the datasets. Experiments show that V-SOINN can preserve the topology and V-SOINN can produce the correct classification result when the number of samples is small.},
  archive      = {J_NEUCOM},
  author       = {Hui Dou and Baile Xu and Furao Shen and Jian Zhao},
  doi          = {10.1016/j.neucom.2021.03.113},
  journal      = {Neurocomputing},
  pages        = {280-289},
  shortjournal = {Neurocomputing},
  title        = {V-SOINN: A topology preserving visualization method for multidimensional data},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MS-ranker: Accumulating evidence from potentially correct
candidates via reinforcement learning for answer selection.
<em>NEUCOM</em>, <em>449</em>, 270–279. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Answer selection (AS) aims to select correct answers for a question from an answer candidate set. Conventional AS methods generally address this task by independently matching the question and each candidate. However, since the matching information between the question and a single candidate is usually limited, it is not enough to use the question as the only evidence to estimate the correctness of each candidate. To address this problem, we propose a novel reinforcement learning (RL) based multi-step ranking model, named MS-Ranker, which accumulates candidate. In specific, we explicitly consider the potential correctness of candidates when accumulating information and update the evidence with a gating mechanism. Moreover, as we use a listwise ranking reward, our model learns to pay more attention to the overall performance. Experiments on three benchmarks, namely WikiQA, SemEval-2016 CQA and SelQA, show that our model significantly outperforms existing methods that do not rely on external resources.},
  archive      = {J_NEUCOM},
  author       = {Yingxue Zhang and Fandong Meng and Peng Li and Ping Jian and Jie Zhou},
  doi          = {10.1016/j.neucom.2021.03.083},
  journal      = {Neurocomputing},
  pages        = {270-279},
  shortjournal = {Neurocomputing},
  title        = {MS-ranker: Accumulating evidence from potentially correct candidates via reinforcement learning for answer selection},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A power reformulation continuous-time algorithm for
nonconvex distributed constrained optimization over multi-agent systems.
<em>NEUCOM</em>, <em>449</em>, 258–269. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonconvex distributed constrained optimization over multi-agent systems plays an increasingly important role in control community. However, the duality gap for a nonconvex distributed constrained optimization problem is not always zero. This brings some difficulties for the algorithm design and convergence analysis about such problems. In this paper, to eliminate the duality gap, the original distributed optimization problem is converted to an equivalent distributed one by using a partial power reformulation. Next, for solving this equivalence problem, a continuous-time algorithm is proposed over the multi-agent system where each agent exchanges local information with other agents under an undirected communication graph . It is proved that the proposed continuous-time algorithm locally converges to a strict local optimal solution of the considered original nonconvex distributed optimization problem. Numerical examples show the validness of the presented algorithm. Finally, the algorithm is applied for optimal placement.},
  archive      = {J_NEUCOM},
  author       = {Na Liu and Shijie Zhao and Sitian Qin},
  doi          = {10.1016/j.neucom.2021.03.082},
  journal      = {Neurocomputing},
  pages        = {258-269},
  shortjournal = {Neurocomputing},
  title        = {A power reformulation continuous-time algorithm for nonconvex distributed constrained optimization over multi-agent systems},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modal space neural network compensation control for
gough-stewart robot with uncertain load. <em>NEUCOM</em>, <em>449</em>,
245–257. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the motion control of a Stewart parallel robot with uncertain load. The external disturbances caused by load can trigger dynamic coupling among six degree-of-freedoms and have a significant impact on control precision. In practice, the dynamic parameters of load is difficult to be precedent identified and the robot with load is a multi-input multi-output(MIMO) system in physical space, which makes the dynamic coupling problem difficult to solve effectively and the high-performance control is hard to achieve. In this paper, the dynamic effect of the load is first analyzed. Then a novel motion control method , modal space neural network compensation control, is designed with the aim of reducing the effect of the load disturbances. This controller implements the neural network to compensate for the load disturbances. In addition, the modal space control theory is introduced to realize the independent control of each control channel. The feasibility of the proposed controller is evaluated in numerical simulations. Results reveal that the proposed control method gives exceptional tracking performance and dynamic coupling suppression capability.},
  archive      = {J_NEUCOM},
  author       = {Xiaolin Dai and Shijie Song and Wenbo Xu and Zhangchao Huang and Dawei Gong},
  doi          = {10.1016/j.neucom.2021.03.119},
  journal      = {Neurocomputing},
  pages        = {245-257},
  shortjournal = {Neurocomputing},
  title        = {Modal space neural network compensation control for gough-stewart robot with uncertain load},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing object detection for autonomous driving by
optimizing anchor generation and addressing class imbalance.
<em>NEUCOM</em>, <em>449</em>, 229–244. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection has been one of the most active topics in computer vision for the past years. Recent works have mainly focused on pushing the state-of-the-art in the general-purpose COCO benchmark. However, the use of such detection frameworks in specific applications such as autonomous driving is yet an area to be addressed. This study presents an enhanced 2D object detector based on Faster R-CNN that is better suited for the context of autonomous vehicles. Two main aspects are improved: the anchor generation procedure and the performance drop in minority classes. The default uniform anchor configuration is not suitable in this scenario due to the perspective projection of the vehicle cameras. Therefore, we propose a perspective-aware methodology that divides the image into key regions via clustering and uses evolutionary algorithms to optimize the base anchors for each of them. Furthermore, we add a module that enhances the precision of the second-stage header network by including the spatial information of the candidate regions proposed in the first stage. We also explore different re-weighting strategies to address the foreground-foreground class imbalance, showing that the use of a reduced version of focal loss can significantly improve the detection of difficult and underrepresented objects in two-stage detectors. Finally, we design an ensemble model to combine the strengths of the different learning strategies. Our proposal is evaluated with the Waymo Open Dataset, which is the most extensive and diverse up to date. The results demonstrate an average accuracy improvement of 6.13\% mAP when using the best single model, and of 9.69\% mAP with the ensemble. The proposed modifications over the Faster R-CNN do not increase computational cost and can easily be extended to optimize other anchor-based detection frameworks.},
  archive      = {J_NEUCOM},
  author       = {Manuel Carranza-García and Pedro Lara-Benítez and Jorge García-Gutiérrez and José C. Riquelme},
  doi          = {10.1016/j.neucom.2021.04.001},
  journal      = {Neurocomputing},
  pages        = {229-244},
  shortjournal = {Neurocomputing},
  title        = {Enhancing object detection for autonomous driving by optimizing anchor generation and addressing class imbalance},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability for multi-links stochastic delayed complex
networks with semi-markov jump under hybrid multi-delay impulsive
control. <em>NEUCOM</em>, <em>449</em>, 214–228. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the problem of p th moment exponential stability for multi-links stochastic delayed complex networks with semi-Markov jump under hybrid multi-delay impulsive control. Different from the previous literature on multi-links systems, we take semi-Markov jump into account. The hybrid multi-delay impulses we addressed are composed of unstable delay-free impulses, stable delay-free impulses, unstable multi-delay impulses and stable multi-delay impulses. Average multi-delay impulsive gain is proposed to quantify the strength of the impulses. Serving as an extension of Halanay inequality, a novel multi-delay impulsive differential inequality is constructed. Combining the multi-delay impulsive differential inequality with Lyapunov method and graph theory, the sufficient criteria for p th moment exponential stability of the considered systems are given, which are closely related to average multi-delay impulsive gain, topological structure , stochastic disturbance strength and semi-Markov jump. Furthermore, the obtained theoretical results are applied to a class of stochastic delayed coupled oscillator systems. Finally, a corresponding numerical simulation is provided to demonstrate the effectiveness of the proposed theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Ning Zhang and Huiyu Chen and Wenxue Li},
  doi          = {10.1016/j.neucom.2021.03.116},
  journal      = {Neurocomputing},
  pages        = {214-228},
  shortjournal = {Neurocomputing},
  title        = {Stability for multi-links stochastic delayed complex networks with semi-markov jump under hybrid multi-delay impulsive control},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-play reinforcement learning with comprehensive critic
in computer games. <em>NEUCOM</em>, <em>449</em>, 207–213. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-play reinforcement learning , where agents learn by playing with themselves, has been successfully applied in many game scenarios. However, the training procedure for self-play reinforcement learning is unstable and more sample-inefficient than (general) reinforcement learning, especially in imperfect information games. To improve the self-play training process, we incorporate a comprehensive critic into the policy gradient method to form a self-play actor-critic (SPAC) method for training agents to play computer games. We evaluate our method in four different environments in both competitive and cooperative tasks. The results show that the agent trained with our SPAC method outperforms those trained with deep deterministic policy gradient (DDPG) and proximal policy optimization (PPO) algorithms in many different evaluation approaches, which vindicate the effect of our comprehensive critic in the self-play training procedure.},
  archive      = {J_NEUCOM},
  author       = {Shanqi Liu and Junjie Cao and Yujie Wang and Wenzhou Chen and Yong Liu},
  doi          = {10.1016/j.neucom.2021.04.006},
  journal      = {Neurocomputing},
  pages        = {207-213},
  shortjournal = {Neurocomputing},
  title        = {Self-play reinforcement learning with comprehensive critic in computer games},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). V-LPDR: Towards a unified framework for license plate
detection, tracking, and recognition in real-world traffic videos.
<em>NEUCOM</em>, <em>449</em>, 189–206. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {License plate detection and recognition (LPDR) has attracted considerable attention in recent years, and many algorithms have presented the competitive performance on several datasets. However, there are still three significant issues to be addressed in this field. Firstly, most methods have poor detection performance in unconstrained scenarios with moving vehicles and highly distracting background objects. Secondly, existing systems generally focus on single image-based algorithms, yet traffic video sequences provide more effective information than individual frames for LPDR tasks. Thirdly, images and videos captured in complex environments may be adversely affected by distortions and low resolution, causing sensitive recognition performance and reduced robustness. To remedy these issues, we propose to automatically perform license plate detection, tracking, and recognition in real-world traffic videos and integrate them into a unified end-to-end framework via deep learning . The contributions of this paper are threefold: 1) A deep flow-guided spatiotemporal license plate detector is proposed to model the video contextual information by introducing optical flow and a novel spatiotemporal attention mechanism ; 2) An online license plate tracker is developed to bridge video-based detection and recognition which utilizes both motion and deep appearance information, and innovatively, it can be end-to-end trained with the detector via multi-task learning; 3) The efficient quality-guided license plate recommender and recognizer are proposed to jointly perform stream recognition. The former recommends high-quality frames from video streams while the latter generates recognition results. We evaluate the proposed method on three traffic video-based license plate datasets, and ablation studies have been presented to verify the effectiveness of each component mentioned above. Moreover, extensive experiments are conducted for comparison with other approaches in different scenarios, and the results have demonstrated that our method achieves state-of-the-art performance on all datasets.},
  archive      = {J_NEUCOM},
  author       = {Cong Zhang and Qi Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.03.103},
  journal      = {Neurocomputing},
  pages        = {189-206},
  shortjournal = {Neurocomputing},
  title        = {V-LPDR: Towards a unified framework for license plate detection, tracking, and recognition in real-world traffic videos},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Macro-micro mutual learning inside compositional model for
human pose estimation. <em>NEUCOM</em>, <em>449</em>, 176–188. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose to perform mutual learning inside the compositional model for human pose estimation. We conduct inference of the human pose in a compositional model which is composed of parts and subparts networks to better capture intrinsic prior knowledge. A macro–micro mutual learning mechanism is put forward to promote the information interaction between human limbs (parts) and joints (subparts). At first, a macro mutual learning module is proposed to conduct the information interaction macroscopically. Features representing the whole human body are leveraged in this case. Secondly, a micro mutual learning module is proposed to promote the information interaction within each limb triplet group to refine corresponding features microcosmically. Combining the macro and micro mutual learning modules promotes the information interaction across different levels. Besides, a novel Balanced Masked Mean Square Error (BMMSE) loss is put forward to solve the positive–negative samples imbalance problem which is more apparent in compositional model. Effectiveness of the method is evaluated on MPII, LSP and COCO benchmarks. Our algorithm achieves leading positions on the leader board of these three datasets.},
  archive      = {J_NEUCOM},
  author       = {Lu Zhou and Yingying Chen and Congqi Cao and Yakui Chu and Jinqiao Wang and Hanqing Lu},
  doi          = {10.1016/j.neucom.2021.03.061},
  journal      = {Neurocomputing},
  pages        = {176-188},
  shortjournal = {Neurocomputing},
  title        = {Macro-micro mutual learning inside compositional model for human pose estimation},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PyNAVIS: An open-source cross-platform software for
spike-based neuromorphic audio information processing. <em>NEUCOM</em>,
<em>449</em>, 172–175. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visualizing the output from event-based sensors and analyzing the information within it is crucial when developing new neuromorphic systems. A novel open-source, cross-platform Python package called pyNAVIS is proposed, which provides a set of functionalities to analyze and process spiking information obtained from neuromorphic cochleas, along with other tools to generate files and datasets for machine learning tasks. This modular package can be integrated in complex and higher-level projects, which could be useful for researchers working in neuromorphic audio processing tasks.},
  archive      = {J_NEUCOM},
  author       = {Juan P. Dominguez-Morales and D. Gutierrez-Galan and A. Rios-Navarro and L. Duran-Lopez and M. Dominguez-Morales and A. Jimenez-Fernandez},
  doi          = {10.1016/j.neucom.2021.03.121},
  journal      = {Neurocomputing},
  pages        = {172-175},
  shortjournal = {Neurocomputing},
  title        = {PyNAVIS: An open-source cross-platform software for spike-based neuromorphic audio information processing},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative study on movement feature in different
directions for micro-expression recognition. <em>NEUCOM</em>,
<em>449</em>, 159–171. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expression can reflect people’s real emotions. Recognizing micro-expressions is difficult because they are small motions and have a short duration. As the research is deepening into micro-expression recognition, many effective features and methods have been proposed. To determine which direction of movement feature is easier for distinguishing micro-expressions, this paper selects 18 directions (including three types of horizontal, vertical and oblique movements) and proposes a new low-dimensional feature called the Histogram of Single Direction Gradient (HSDG) to study this topic. In this paper, HSDG in every direction is concatenated with LBP-TOP to obtain the LBP with Single Direction Gradient (LBP-SDG) and analyze which direction of movement feature is more discriminative for micro-expression recognition. As with some existing work, Euler Video Magnification (EVM) is employed as a preprocessing step . The experiments on the CASME II and SMIC-HS databases summarize the effective and optimal directions and demonstrate that HSDG in an optimal direction is discriminative, and the corresponding LBP-SDG achieves state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Jinsheng Wei and Guanming Lu and Jingjie Yan},
  doi          = {10.1016/j.neucom.2021.03.063},
  journal      = {Neurocomputing},
  pages        = {159-171},
  shortjournal = {Neurocomputing},
  title        = {A comparative study on movement feature in different directions for micro-expression recognition},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive multiscale feature for object detection.
<em>NEUCOM</em>, <em>449</em>, 146–158. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In object detection, multiscale features are necessary to deal with objects with different size. Using Feature Pyramid Network (FPN) as the backbone network is a very popular paradigm in existing object detectors, we call this paradigm FPN+. However, feature fusion of FPN is insufficient to express object of similar size but different appearance due to the unidirectional feature fusion . We motivate and present Adaptive Multiscale Feature (AMF), a new multiscale feature fusion method with bidirectional feature fusion, using to solve the one-direction fusion of FPN. AMF module fuses multiscale features from two aspects: (1) shattering features by the way of CLSM; (2) fusing features by the way of channel-wise attention. The proposed AMF improves the expression ability of multiscale features of the backbone network , and effectively improves the performance of the object detector. The proposed feature fusion method can be added to all object detector, such as the one-stage detector, the two-stage detector, anchor-based detector and anchor-free based detector. Experimental results on the COCO 2014 dataset show that the proposed AMF module performs the popular FPN based detector. Whether anchored-free based detectors or anchored based detectors, performance of detector can be improved through AMF. And the resulting best model can achieve a very competitive mAP on COCO 2014 dataset.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyong Yu and Siyuan Wu and Xiaoqiang Lu and Guilong Gao},
  doi          = {10.1016/j.neucom.2021.04.002},
  journal      = {Neurocomputing},
  pages        = {146-158},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multiscale feature for object detection},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Subject sensitive EEG discrimination with fast
reconstructable CNN driven by reinforcement learning: A case study of
ASD evaluation. <em>NEUCOM</em>, <em>449</em>, 136–145. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent Electroencephalogram (EEG) analysis in connection with brain disorders has been tremendously benefiting from the (Deep) Neural Network technology in neuroscience research and neuro-engineering practices. However, the performance of existing hand-crafted models, such as the stability, has largely been refrained. This is the case especially in the paradigms that sensitive to the individuality of subjects and the non-stationarity of cognitive dynamics, such as Autism Spectrum Disorder (ASD) evaluation. Aiming at this problem, this study develops a Q-Learning method to enable fast reconstruction of Convolutional Neural Network (CNN) thus to support EEG discrimination adapting to the individuality of subjects under examination. The proposed method first generates a CNN model with the structure and hyper-parameters determined (i.e., Neural Architecture Search) by the customized Q-Learning algorithm, where the CNN model is treated as a discrete system to be optimized. With the sharp shift of subjects, the Q-Learning algorithm reconstructs the CNN model to reach optimization reusing the tacit knowledge learned from the previous trials. A case study has been performed to check the proposed method versus state-of-the-art counterparts based on resting-state EEG collected from 175 ASD-suspicious children with a diverse geological distribution. The observations in the case study indicate that: 1) the method outperforms the counterparts with an individual/sample accuracy of 92.63\% 92.63\% / 83.23\% 83.23\% achieved; 2) the method can quickly reconstruct the CNN model with the group of subjects shifting from one region to another to maintain an encouraging performance while the counterparts without reconstruction may drop by about 12\% 12\% .},
  archive      = {J_NEUCOM},
  author       = {Heyou Dong and Dan Chen and Lei Zhang and Hengjin Ke and Xiaoli Li},
  doi          = {10.1016/j.neucom.2021.04.009},
  journal      = {Neurocomputing},
  pages        = {136-145},
  shortjournal = {Neurocomputing},
  title        = {Subject sensitive EEG discrimination with fast reconstructable CNN driven by reinforcement learning: A case study of ASD evaluation},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). Rethinking semantic-visual alignment in zero-shot object
detection via a softplus margin focal loss. <em>NEUCOM</em>,
<em>449</em>, 117–135. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot object detection (ZSD) aims to locate and recognize novel objects without additional training samples. Most existing methods usually map visual features to semantic space, resulting in a hubness problem, and learning an effective feature mapping between the two modalities remains a considerable challenge. In this work, we propose a novel end-to-end framework, Semantic-Visual Auto-Encoder (SVAE) network, to tackle the above issues. Distinct from previous works that utilize fully-connected layers to learn the feature mapping, we implement a 1-dimensional convolution with various shared filters to construct the auto-encoder, which maps semantic features to visual space to alleviate the hubness problem. Specifically, we design a novel loss function, Softplus Margin Focal Loss (SMFL), for object classification channel to align the projected semantic features in visual space and address the class imbalance problem . The SMFL improves the discrimination of projections on positive and negative categories and maintains the property of focal loss. Besides, to promote the localization performance for novel objects, we also provide semantic information for object localization channel and utilize a trainable matrix to align the semantic-visual mapping, considering noises in semantic representations . We conduct extensive experiments on four challenging benchmarks. The experimental results show the competitive performances compared with state-of-the-art approaches. Especially, we achieve 8.39\%/6.58\% mean average precision (mAP) improvements for ZSD/general-ZSD on Microsoft COCO benchmark.},
  archive      = {J_NEUCOM},
  author       = {Qianzhong Li and Yujia Zhang and Shiying Sun and Xiaoguang Zhao and Kang Li and Min Tan},
  doi          = {10.1016/j.neucom.2021.03.073},
  journal      = {Neurocomputing},
  pages        = {117-135},
  shortjournal = {Neurocomputing},
  title        = {Rethinking semantic-visual alignment in zero-shot object detection via a softplus margin focal loss},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Robust bayesian matrix decomposition with mixture of
gaussian noise. <em>NEUCOM</em>, <em>449</em>, 108–116. (<a
href="https://doi.org/10.1016/j.neucom.2021.04.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix decomposition is a popular and fundamental approach in machine learning . The classical matrix decomposition methods with Frobenius norm loss is only optimal for Gaussian noise and thus suffer from the sensitivity to outliers and non-Gaussian noise. To address these limitations, the proposed methods can be divided into two categories. One type of approach is to replace the Frobenius norm loss with robust loss functions. The other type of approach is to impose the Bayesian priors to reduce the risk of overfitting. This paper combines these two approaches. Specifically, we model the noise by a mixture of Gaussian distribution, enabling the model to approximate a wide range of noise distributions. Meanwhile, we put a Laplace prior on the basis matrix to enforce the sparsity and a Dirichlet prior on the coefficient matrix to improve the interpretability . Extensive experiments in synthetic data and real-world data demonstrate that this method outperforms several competing ones. Ablation studies show that this method benefits from both the Bayesian priors and the Mixture of Gaussian noise loss, which confirms the necessity of combining the two schemes.},
  archive      = {J_NEUCOM},
  author       = {Haohui Wang and Chihao Zhang and Shihua Zhang},
  doi          = {10.1016/j.neucom.2021.04.004},
  journal      = {Neurocomputing},
  pages        = {108-116},
  shortjournal = {Neurocomputing},
  title        = {Robust bayesian matrix decomposition with mixture of gaussian noise},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust distributed adaptive consensus for discrete-time
multiagent systems with uncertain topologies. <em>NEUCOM</em>,
<em>449</em>, 100–107. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the stochastic consensus problem of high-order linear discrete-time multiagent systems (MASs) with uncertain topologies and external disturbances. The randomly switching interaction signed topologies are governed by a time-homogenous Markov chain with incomplete knowledge of the transition probabilities. Based on Lyapunov function theory and adaptive control strategies, we employ a homogeneous parameter-dependent Lyapunov function to propose sufficient conditions under a set of linear matrix inequality (LMI) constraints. A free-weighting matrix method is introduced to give the proposed LMIs extra freedom to search feasible solutions. Furthermore, the adaptive controllers applied in this paper are independent of topologies and fully distributed; i.e., the system achieves robust consensus without continuously updating the controller and dealing with global data. Additionally, we extend the theoretical framework to analyze the disturbance rejection performance of MASs under the stochastic process. Two numerical examples are provided to show the effectiveness of the algorithms.},
  archive      = {J_NEUCOM},
  author       = {Chengrong Lin and Bo Hu and Wenchao Huang and Tao Niu},
  doi          = {10.1016/j.neucom.2021.03.126},
  journal      = {Neurocomputing},
  pages        = {100-107},
  shortjournal = {Neurocomputing},
  title        = {Robust distributed adaptive consensus for discrete-time multiagent systems with uncertain topologies},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convolutional neural networks based on fractional-order
momentum for parameter training. <em>NEUCOM</em>, <em>449</em>, 85–99.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a parameter training method via the fractional-order momentum for convolutional neural networks (CNNs). To update the parameters of CNNs more smoothly, the parameter training method via the fractional-order momentum is proposed based on the Grünwald-Letnikov (G-L) difference operation. The stochastic classical momentum (SCM) algorithm and adaptive moment (Adam) estimation algorithm are improved by replacing the integer-order difference with the fractional-order difference. Meanwhile, the linear and the nonlinear methods are discussed to adjust the fractional-order. Therefore, the proposed methods can improve the flexibility and the adaptive ability of CNN parameters. We analyze the validity of the methods by using MNIST dataset and CIFAR-10 dataset, and the experimental results show that the proposed methods can improve the recognition accuracy and the learning convergence speed of CNNs compared with the traditional SCM and Adam methods.},
  archive      = {J_NEUCOM},
  author       = {Tao Kan and Zhe Gao and Chuang Yang and Jing Jian},
  doi          = {10.1016/j.neucom.2021.03.075},
  journal      = {Neurocomputing},
  pages        = {85-99},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural networks based on fractional-order momentum for parameter training},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing social recommendation via two-level graph
attentional networks. <em>NEUCOM</em>, <em>449</em>, 71–84. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective deep representation learning technique for graph data, graph convolutional network (GCN) has recently been widely applied to obtain better embedding of vertex. The existing studies have successfully explored user-item interaction via GCN for recommendation task and proved its effectiveness. We argue that a significant limitation of these methods is that social relation, which has been proven to impose positive effects for recommendation in many loss optimization models, has received relatively little scrutiny in GCN. Thus, the resultant embeddings are insufficient to model the potential social propagation effect. In our work, we propose to obtain embeddings by using the neighborhood propagation mechanism on two coupled graphs, i.e. user-item interaction graph and social relation graph , which is capable of capturing the interplay between the user’s item taste and user’s friend relationship to integrate social effect into the embeddings. In particular, to address the challenge that different factors on neighborhood propagation process make different contributions for the embedding, we develop Attentional Social Recommendation system (ASR), a new social recommendation framework with hierarchical attention(i.e., neighbor-level and graph-level attention). This allows much flexibility for adaptively acquiring relative importance for different factors. Extensive experiment on three real-world datasets not only show the superior performance of our proposed model over the baselines, but also demonstrate the effectiveness of simultaneous neighborhood propagation on two graphs.},
  archive      = {J_NEUCOM},
  author       = {Yanbin Jiang and Huifang Ma and Yuhang Liu and Zhixin Li and Liang Chang},
  doi          = {10.1016/j.neucom.2021.03.076},
  journal      = {Neurocomputing},
  pages        = {71-84},
  shortjournal = {Neurocomputing},
  title        = {Enhancing social recommendation via two-level graph attentional networks},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Crowd density estimation via a multichannel dense grouping
network. <em>NEUCOM</em>, <em>449</em>, 61–70. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has made substantial progress in crowd density estimation, but in practical application, due to the interference factors such as uneven distribution of crowd and changes in illumination, the existing methods still have large errors in counting. To solve the above problems, a crowd density estimation method based on multichannel dense grouping network is proposed. To solve the problem that it is difficult to extract the multiscale information of the crowd due to the uneven distribution of the crowd, multichannel dense grouping module (McDGM) is designed. In the module, Improved grouping convolution block (IGCB) is dense connected with other layers to obtain different levels of crowd characteristics, so as to avoid the loss of multi-scale information. In addition, the parameters of IGCB are reduced by group convolution. Then, to overcome the change of illumination, a crowd image enhancement algorithm is designed, which makes the image clear by the average pixel value and adjusting the contrast. Finally, to enhance the sensitivity of the network to crowd counting, a new loss function is proposed, which adds counting loss to the previous pixel space loss to improve the accuracy of crowd counting. The algorithm in this paper has been tested on ShanghaiTech and UCF_CC_50 datasets. The test results show that the algorithm in this paper has better statistical accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yan-Bo Liu and Rui-Sheng Jia and Jin-Tao Yu and Ruo-Nan Yin and Hong-Mei Sun},
  doi          = {10.1016/j.neucom.2021.03.078},
  journal      = {Neurocomputing},
  pages        = {61-70},
  shortjournal = {Neurocomputing},
  title        = {Crowd density estimation via a multichannel dense grouping network},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AEVRNet: Adaptive exploration network with variance reduced
optimization for visual tracking. <em>NEUCOM</em>, <em>449</em>, 48–60.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For visual tracking methods based on reinforcement learning , action space determines the ability of exploration, which is crucial to model robustness. However, most trackers adopted simple strategies with action space, which will suffer local optima problem. To address this issue, a novel reinforcement learning based tracker called AEVRNet is proposed with non-convex optimization and effective action space exploration. Firstly, inspired by combinatorial upper confidence bound , we design an adaptive exploration strategy leveraging temporal and spatial knowledge to enhance effective action exploration and jump out of local optima. Secondly, we define the tracking problem as a non-convex problem and incorporate non-convex optimization in stochastic variance reduced gradient as backward propagation of our model, which can converge faster with lower loss. Thirdly, different from existing reinforcement learning based trackers using classification method to train model, we define a regression based action-reward loss function, which is more sensitive to aspects of the target states, e.g., the width and height of the target to further improve robustness. Extensive experiments on six benchmark datasets demonstrate that our proposed AEVRNet achieves favorable performance against the state-of-the-art reinforcement learning based methods .},
  archive      = {J_NEUCOM},
  author       = {Yuxiang Yang and Weiwei Xing and Dongdong Wang and Shunli Zhang and Qi Yu and Liqiang Wang},
  doi          = {10.1016/j.neucom.2021.03.118},
  journal      = {Neurocomputing},
  pages        = {48-60},
  shortjournal = {Neurocomputing},
  title        = {AEVRNet: Adaptive exploration network with variance reduced optimization for visual tracking},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial self-supervised clustering with
cluster-specificity distribution. <em>NEUCOM</em>, <em>449</em>, 38–47.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As we embark on the big data era, numerous unlabeled data has generated increasingly, and thus deep clustering analysis has become prevalent in artificial intelligence . Yet, most existing deep clustering methods still have the following demerits: 1) They fail to take cluster-specificity distribution into account, resulting in suboptimal latent representation. 2) They suffer from the scale issue of the distributions between the given sample and cluster centers, resulting in unstable clustering performance. 3) They fail to utilize the obtained clustering labels, resulting in suboptimal clustering performances. To fill these gaps, we propose a new deep clustering solution, namely A dversarial S elf-supervised C lustering With C luster-specificity D istribution (ASC2D). Specifically, by imposing the cluster-specificity constraint, which is measured by the ℓ 1 , 2 ℓ1,2 -norm, the learned latent representation well encodes the cluster structure. Meanwhile, by introducing the thought of adversarial learning, ASC2D well eliminates the gaps between distributions. Moreover, ASC2D utilize the clustering label to supervise the learning of representation, where the latter is used in turn to conduct the subsequent clustering. By this way, clustering and representation learning are seamlessly connected, with the aim to achieve better clustering performance. Extensive experimental results show that ASC2D is superior to 14 state-of-the-art baselines on six image datasets in terms of three evaluation metrics , especially on Fashion-MNIST datasets, ASC2D brings about 4.1\% 4.1\% and 7.1\% 7.1\% improvement over the best baseline in terms of ACC and NMI metrics.},
  archive      = {J_NEUCOM},
  author       = {Wei Xia and Xiangdong Zhang and Quanxue Gao and Xinbo Gao},
  doi          = {10.1016/j.neucom.2021.03.108},
  journal      = {Neurocomputing},
  pages        = {38-47},
  shortjournal = {Neurocomputing},
  title        = {Adversarial self-supervised clustering with cluster-specificity distribution},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). LF3Net: Leader-follower feature fusing network for fast
saliency detection. <em>NEUCOM</em>, <em>449</em>, 24–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, convolutional neural networks (CNNs) have been widely used for saliency detection . Most of existing saliency detection methods produce saliency maps from the complementary multi-level convolutional features. However, it is still a challenging task to accurately integrate multi-level features for saliency detection. In this paper, we explore the intrinsic relationships between multi-level features and introduce the Stackelberg game theory as a new strategy to fuse multi-level features for saliency detection. Based on the theory, we propose a leader-follower feature fusing network (LF 3 Net) to obtain saliency maps. We first apply a multi-scale context-aware leader-follower attention module (MCLAM) to select multi-scale spatial and semantic information. Then, we propose a leader-follower feature fusing module (LF 3 M) to integrate the multi-level features. Extensive experiments on five datasets show that the proposed method outperforms the state-of-the-art approaches under different evaluation metrics . In addition, our network can run fast at the real-time speed of 75 FPS.},
  archive      = {J_NEUCOM},
  author       = {Huiyuan Luo and Guangliang Han and Xiaotian Wu and Peixun Liu and Hang Yang and Xin Zhang},
  doi          = {10.1016/j.neucom.2021.03.080},
  journal      = {Neurocomputing},
  pages        = {24-37},
  shortjournal = {Neurocomputing},
  title        = {LF3Net: Leader-follower feature fusing network for fast saliency detection},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view subspace clustering networks with local and
global graph information. <em>NEUCOM</em>, <em>449</em>, 15–23. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the problem of multi-view subspace clustering, the goal of which is to explore the underlying grouping structure of data collected from different fields or measurements. Since data do not always comply with the linear subspace models in many real-world applications, most existing multi-view subspace clustering methods based on the shallow linear subspace models may fail in practice. Furthermore, the underlying graph information of multi-view data is usually ignored in most existing multi-view subspace clustering methods . To address the aforementioned limitations, we proposed the novel multi-view subspace clustering networks with local and global graph information , termed MSCNLG, in this paper. Specifically, autoencoder networks are employed on multiple views to achieve latent smooth representations that are suitable for the linear assumption. Simultaneously, by integrating fused multi-view graph information into self-expressive layers, the proposed MSCNLG obtains the common shared multi-view subspace representation, which can be used to get clustering results by employing the standard spectral clustering algorithm . As an end-to-end trainable framework, the proposed method fully investigates the valuable information of multiple views. Comprehensive experiments on six benchmark datasets validate the effectiveness and superiority of the proposed MSCNLG.},
  archive      = {J_NEUCOM},
  author       = {Qinghai Zheng and Jihua Zhu and Yuanyuan Ma and Zhongyu Li and Zhiqiang Tian},
  doi          = {10.1016/j.neucom.2021.03.115},
  journal      = {Neurocomputing},
  pages        = {15-23},
  shortjournal = {Neurocomputing},
  title        = {Multi-view subspace clustering networks with local and global graph information},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). MSEC: Multi-scale erasure and confusion for fine-grained
image classification. <em>NEUCOM</em>, <em>449</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning , the performance of fine-grained image classification has experienced unprecedented improvement. However, for fine-grained image classification , quickly and effectively focusing on subtle discriminative details that make the sub-classes different from each other has always been challenging. In this paper, we propose a novel Multi-Scale Erasure and Confusion (MSEC) method to tackle the challenge of fine-grained image classification. Firstly, the input image is divided into several sub-regions, and the confidence scores of those sub-regions are calculated by the confidence function. The sub-regions with lower confidence scores are then erased by the Region Erasure Module (REM) and the erased image is confused once by the Multi-scale Region Confusion Module (Multi-scale RCM). Secondly, the sub-regions with higher confidence scores are divided and confused again by the Multi-scale RCM, and then generate an image with multi-scale information. Finally, features in the erased image and the “destructed” image are extracted by the backbone network , and the whole network is optimized by the multi-loss function to realize classification tasks . Extensive experiments on three standard fine-grained benchmark datasets, including Stanford Dogs, CUB-200-2011 and FGVC-Aircraft, show that MSEC can improve the accuracy of fine-grained image classification.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhang and Yongsheng Sun and Nian Wang and Zijian Gao and Feng Chen and Chenfei Wang and Jun Tang},
  doi          = {10.1016/j.neucom.2021.03.114},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {MSEC: Multi-scale erasure and confusion for fine-grained image classification},
  volume       = {449},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DGSAN: Discrete generative self-adversarial network.
<em>NEUCOM</em>, <em>448</em>, 364–379. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although GAN-based methods have received many achievements in the last few years, they have not been entirely successful in generating discrete data. The most crucial challenge of these methods is the difficulty of passing the gradient from the discriminator to the generator when the generator outputs are discrete. Despite the fact that several attempts have been made to alleviate this problem, none of the existing GAN-based methods have improved the performance of text generation compared with the maximum likelihood approach in terms of both the quality and the diversity. In this paper, we proposed a new framework for generating discrete data by an adversarial approach in which there is no need to pass the gradient to the generator. The proposed method has an iterative manner in which each new generator is defined based on the last discriminator . It leverages the discreteness of data and the last discriminator to model the real data distribution implicitly. Moreover, the method is supported with theoretical guarantees, and experimental results generally show the superiority of the proposed DGSAN method compared to the other popular or recent methods in generating discrete sequential data.},
  archive      = {J_NEUCOM},
  author       = {Ehsan Montahaei and Danial Alihosseini and Mahdieh Soleymani Baghshah},
  doi          = {10.1016/j.neucom.2021.03.097},
  journal      = {Neurocomputing},
  pages        = {364-379},
  shortjournal = {Neurocomputing},
  title        = {DGSAN: Discrete generative self-adversarial network},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Online h∞ control for continuous-time nonlinear large-scale
systems via single echo state network. <em>NEUCOM</em>, <em>448</em>,
353–363. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the H ∞ H∞ optimal control for nonlinear large-scale interconnected systems is designed using novel adaptive/approximate dynamic programming (ADP) method and single echo state network (ESN). All subsystems of the large-scale systems are combined into an augmented system. Subsequently, the H ∞ H∞ problem is transformed into a zero-sum game problem, where a nonlinear partial differential Hamilton-Jacobi-Isaacs (HJI) equation is required to be solved. However, the HJI equation has no analytically solution, so this paper develops a novel online ADP algorithm to approximatively obtain the index function and control policy simultaneously employing single ESN without requiring the initial admissible control. The stability of the closed-loop augmented system and the ESN output weights is analyzed using the Lyapunov theorem and guaranteed to be uniformly ultimate boundedness (UUB). A large-scale system example including three subsystems is simulated to show the feasibility of the suggested control scheme.},
  archive      = {J_NEUCOM},
  author       = {Chong Liu and Huaguang Zhang and Shaoxin Sun and He Ren},
  doi          = {10.1016/j.neucom.2021.03.017},
  journal      = {Neurocomputing},
  pages        = {353-363},
  shortjournal = {Neurocomputing},
  title        = {Online h∞ control for continuous-time nonlinear large-scale systems via single echo state network},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered h∞ filtering for nonlinear networked control
systems via t-s fuzzy model approach. <em>NEUCOM</em>, <em>448</em>,
344–352. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the event-triggering filtering problem for a class of nonlinear networked control systems subject to the prescribed disturbance attenuation level. To alleviate the data transmission burden of communication channels, an event-triggering mechanism is adopted, where the data can be transmitted only if certain condition is fulfilled. The T-S fuzzy model approach is utilized to approximate the nonlinear dynamics. It is the purpose of this paper to design a filter for the addressed nonlinear system ensuring that the filtering error system is asymptotically stable whereas the prespecified H ∞ H∞ criterion is guaranteed. By using Lyapunov approach in combination with matrix analysis method, the sufficient conditions are established for the existence of desired filtering parameters in terms of the solvability of certain linear matrix inequalities. Finally, a numerical simulation example is put forward to demonstrate the validity and effectiveness of the developed theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Xiaojian Yi and Guangjie Li and Yajuan Liu and Fang Fang},
  doi          = {10.1016/j.neucom.2021.03.081},
  journal      = {Neurocomputing},
  pages        = {344-352},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered h∞ filtering for nonlinear networked control systems via T-S fuzzy model approach},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dissipative sampled-data synchronization for spatiotemporal
complex dynamical networks with semi-markovian switching topologies.
<em>NEUCOM</em>, <em>448</em>, 333–343. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study concerns the sampled-data synchronization problem for spatiotemporal complex dynamical networks with switching topological structure , and the topologies switching is modeled by a semi-Markov process, where the transition rates between different modes are related to the sojourn-time. By constructing a suitable Lyapunov–Krasovskii functional including an improved looped-functional and utilizing the Bessel–Legendre inequality, two sufficient synchronization conditions with less conservatism are established. A sample-data controller which can ensure the error system stochastically stable with a prescribed dissipative performance is developed. Finally, three examples, which including normal numerical examples, comparative examples and an application example, are presented to demonstrate the validity and superiority of the developed methods.},
  archive      = {J_NEUCOM},
  author       = {Renzhi Zhang and Xiaona Song and Yijun Zhang and Shuai Song},
  doi          = {10.1016/j.neucom.2021.03.086},
  journal      = {Neurocomputing},
  pages        = {333-343},
  shortjournal = {Neurocomputing},
  title        = {Dissipative sampled-data synchronization for spatiotemporal complex dynamical networks with semi-markovian switching topologies},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regression-based clustering network via combining prior
information. <em>NEUCOM</em>, <em>448</em>, 324–332. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the promising performance, existing regression-based clustering methods still have the following limitations. (1) They only extract the shallow discriminant features, resulting in unstable clustering performance on data with complex underlying subspaces. (2) It is difficult to optimize the objective due to the discretization of the elements in the cluster indicator matrix , resulting in suboptimal solution. (3) They fail to employ the structure prior information embedded in the clustering label matrix, resulting in suboptimal clustering performance. Targeting at above problems, we propose a novel R egression-based C lustering network via C ombining P rior I nformation (RC2PI), which consists of a convolutional auto-encoder, a priori information encoder, and a discriminator . Specifically, the auto-encoder is used to generate the ideal distribution to relax discrete cluster indicator matrix , which can help obtain optimal solution. The prior information encoder is employed to exploit the structure prior knowledge embedded in clustering label matrix, thereby boosting clustering via a self-supervised manner. The discriminator , as a connector of the above two sub-networks, is used for verifying the embedding process of prior information that will guide the auto-encoder to generate a more reliable actual distribution. Extensive experiments demonstrate the effectiveness of RC2PI over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Wei Xia and Quanxue Gao and Qianqian Wang and Xinbo Gao},
  doi          = {10.1016/j.neucom.2021.03.031},
  journal      = {Neurocomputing},
  pages        = {324-332},
  shortjournal = {Neurocomputing},
  title        = {Regression-based clustering network via combining prior information},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequence feature generation with temporal unrolling network
for zero-shot action recognition. <em>NEUCOM</em>, <em>448</em>,
313–323. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-Shot Action Recognition (ZSAR) aims to recognize unseen action classes not included in the training dataset. Existing generative methods for ZSAR synthesize a feature of unseen action from a class embedding to overcome the absence of training data. Specifically, previous methods synthesize a feature which is averaged along a time axis, even though a video is extracted as a sequence of feature vectors. They suffer from the ambiguity of temporal information, which leads to confusion among actions sharing similar subactions. To tackle the problem, we first propose to synthesize not an averaged feature but a sequence consisting of feature vectors along the time axis. Hence, we design Sequence Feature Generative Adversarial Network (SFGAN) with Temporal Unrolling NEtwork (TUNE), which unrolls a class embedding into a set of condition vectors for generating sequences of features. Also, we employ a sequence discriminator as the second teacher. Through extensive experiments on the three benchmarks, HMDB51, UCF101, and Olympic, we validate the efficacy of sequence generation for ZSAR, and our method achieves the state-of-the-art generalized zero-shot learning performances.},
  archive      = {J_NEUCOM},
  author       = {Jewook Lee and Hoseong Kim and Hyeran Byun},
  doi          = {10.1016/j.neucom.2021.03.070},
  journal      = {Neurocomputing},
  pages        = {313-323},
  shortjournal = {Neurocomputing},
  title        = {Sequence feature generation with temporal unrolling network for zero-shot action recognition},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple asymptotic stability of fractional-order
quaternion-valued neural networks with time-varying delays.
<em>NEUCOM</em>, <em>448</em>, 301–312. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the multiple asymptotic stability is investigated for fractional-order quaternion-valued neural networks (FQVNNs) with time-varying delays. The activation function is a nonmonotonic piecewise nonlinear activation function . By applying the Hamilton rules, the FQVNNs are transformed into real-valued systems. Then, according to the Brouwer’s fixed point theorem , three new conditions are proposed to ensure that there exist 3 4 n 34n equilibrium points. Moreover, by virtue of fractional-order Razumikhin theorem and Lyapunov function , a new condition is derived to guarantee the FQVNNs have 2 4 n 24n locally asymptotic stable equilibrium points. For the first time, the multiple asymptotic stability of delayed FQVNNs is investigated. Contrast to multistability analysis of integer-order quaternion-valued neural networks , this paper present different conclusions. Finally, two numerical simulations demonstrate the validity of the results.},
  archive      = {J_NEUCOM},
  author       = {Zhongwen Wu},
  doi          = {10.1016/j.neucom.2021.03.079},
  journal      = {Neurocomputing},
  pages        = {301-312},
  shortjournal = {Neurocomputing},
  title        = {Multiple asymptotic stability of fractional-order quaternion-valued neural networks with time-varying delays},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large-scale gastric cancer screening and localization using
multi-task deep neural network. <em>NEUCOM</em>, <em>448</em>, 290–300.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gastric cancer is one of the most common cancers, which ranks third among the leading causes of cancer death. Biopsy of gastric mucosa is a standard procedure in gastric cancer screening test. However, manual pathological inspection is labor-intensive and time-consuming. Besides, it is challenging for an automated algorithm to locate the small lesion regions in the gigapixel whole-slide image and make the decision correctly. To tackle these issues, we collected large-scale whole-slide image dataset with detailed lesion region annotation and designed a whole-slide image analyzing framework consisting of 3 networks which could not only determine the screening result but also present the suspicious areas to the pathologist for reference. Experiments demonstrated that our proposed framework achieves sensitivity of 97.05\% 97.05\% and specificity of 92.72\% 92.72\% in screening task and Dice coefficient of 0.8331 0.8331 in segmentation task . Furthermore, we tested our best model in real-world scenario on 10 , 315 10,315 whole-slide images collected from 4 medical centers.},
  archive      = {J_NEUCOM},
  author       = {Hong Yu and Xiaofan Zhang and Lingjun Song and Liren Jiang and Xiaodi Huang and Wen Chen and Chenbin Zhang and Jiahui Li and Jiji Yang and Zhiqiang Hu and Qi Duan and Wanyuan Chen and Xianglei He and Jinshuang Fan and Weihai Jiang and Li Zhang and Chengmin Qiu and Minmin Gu and Weiwei Sun and Yangqiong Zhang},
  doi          = {10.1016/j.neucom.2021.03.006},
  journal      = {Neurocomputing},
  pages        = {290-300},
  shortjournal = {Neurocomputing},
  title        = {Large-scale gastric cancer screening and localization using multi-task deep neural network},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-stage 3D CNN based learning method for spontaneous
micro-expression recognition. <em>NEUCOM</em>, <em>448</em>, 276–289.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions (MEs) are spontaneous and involuntary facial subtle reactions which often reveal the genuine emotions within human beings. Recognizing MEs automatically is becoming increasingly crucial for many areas such as diagnosis and security. However, the short time duration and low spatial intensity of MEs pose great challenges for accurately recognizing them. Additionally, the lack of sufficient and balanced spontaneous MEs data also makes this problem even harder to solve, and some adaptive modeling strategies have been quite urgent recently. To this end, this paper draws inspirations from few-shot learning to propose a novel two-stage learning (i.e., prior learning and target learning ) method based on a siamese 3D convolutional neural network for MEs recognition (MERSiamC3D). Specifically, in the prior learning stage, the proposed MERSiamC3D is used to extract the generic features of MEs. In the target learning stage, the structure and parameters of the MERSiamC3D will be carefully adjusted and the Focal Loss is adopted for high-level features learning . Afterwards, in order to effectively retain the spatiotemporal information of the original MEs video, an adaptive construction method based on adaptive convolutional neural network is proposed to construct the key-frames sequence to summarize the original MEs video, which is able to help drop the redundant frames and relatively highlight the movement of the apex frame. Then, the new key-frames are taken as the input of the two-stage learning method. Finally, through extensive evaluations and experiments on three publically available MEs datasets, the proposed method in this work could outperform traditional methods and other deep learning baselines, which provides a novel insight on how to leverage scarce data for MEs recognition.},
  archive      = {J_NEUCOM},
  author       = {Sirui Zhao and Hanqing Tao and Yangsong Zhang and Tong Xu and Kun Zhang and Zhongkai Hao and Enhong Chen},
  doi          = {10.1016/j.neucom.2021.03.058},
  journal      = {Neurocomputing},
  pages        = {276-289},
  shortjournal = {Neurocomputing},
  title        = {A two-stage 3D CNN based learning method for spontaneous micro-expression recognition},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural-network-based adaptive secure control for
nonstrict-feedback nonlinear interconnected systems under DoS attacks.
<em>NEUCOM</em>, <em>448</em>, 263–275. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problems of decentralized adaptive neural network (NN) secure control for a class of nonstrict-feedback nonlinear interconnected large-scale systems (NILSs) under denial-of-service (DoS) attacks. The considered systems contain not only unknown interconnected terms but also general nonlinear functions that are not required to be globally Lipschitz, in contrast to most of the existing results in the area. When the system subject to the DoS attack, the sampled data can neither be sent by the sensors nor received by the actuators due to the appearance of DoS in the sensor-to-controller (S-C) and the controller-to-actuator (C-A) communication channels. The data packets sent from the sensors are blocked and the traditional backstepping technology cannot be adopted. In order to solve this difficulty, a novel dynamic gain observer is constructed, which can obtain the desired states from the NILSs under DoS attacks. Considering the energy limitation of attackers, two reasonable Assumptions of DoS attack intensity are given. The stability is proven based on the Lyapunov stability theory (LST) and the improved average dwell time (ADT) method. The proposed controller guarantees that all signals in closed-loop systems are bounded, while the tracking error signals converge to a small residual set. Finally, two simulation examples are provided to illustrate the effectiveness of the proposed control method .},
  archive      = {J_NEUCOM},
  author       = {Xinfeng Shao and Dan Ye},
  doi          = {10.1016/j.neucom.2021.03.087},
  journal      = {Neurocomputing},
  pages        = {263-275},
  shortjournal = {Neurocomputing},
  title        = {Neural-network-based adaptive secure control for nonstrict-feedback nonlinear interconnected systems under DoS attacks},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed quantile regression for massive heterogeneous
data. <em>NEUCOM</em>, <em>448</em>, 249–262. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Massive data sets pose great challenges to data analysis because of their heterogeneous data structure and limited computer memory. Jordan et al. (2019, Journal of American Statistical Association ) has proposed a communication-efficient surrogate likelihood (CSL) method to solve distributed learning problems. However, their method cannot be directly applied to quantile regression because the loss function in quantile regression does not meet the smoothness requirement in CSL method. In this paper, we extend CSL method so that it is applicable to quantile regression problems . The key idea is to construct a surrogate loss function which relates to the local data only through subgradients of the loss function. The alternating direction method of multipliers (ADMM) algorithm is used to address computational issues caused by the non-smooth loss function. Our theoretical analysis establishes the consistency and asymptotic normality for the proposed method. Simulation studies and applications to real data show that our method works well.},
  archive      = {J_NEUCOM},
  author       = {Aijun Hu and Yuling Jiao and Yanyan Liu and Yueyong Shi and Yuanshan Wu},
  doi          = {10.1016/j.neucom.2021.03.041},
  journal      = {Neurocomputing},
  pages        = {249-262},
  shortjournal = {Neurocomputing},
  title        = {Distributed quantile regression for massive heterogeneous data},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Spatiotemporal and frequential cascaded attention networks
for speech emotion recognition. <em>NEUCOM</em>, <em>448</em>, 238–248.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Speech emotion recognition is an important but difficult task in human–computer interaction systems. One of the main challenges in speech emotion recognition is how to extract effective emotion features from a long utterance. To address this issue, we propose a novel spatiotemporal and frequential cascaded attention network with large-margin learning in this paper. Spatiotemporal attention selectively locates the targeted emotional regions from a long speech spectrogram. In these targeted regions, frequential attention captures the emotional features by frequency distribution. The cascaded attention assists the neural network to gradually extract effective emotion features from the long spectrogram. During training, large-margin learning is applied to improve intra-class compactness and enlarge inter-class distances. Experiments on four public datasets demonstrate that our proposed model achieves a promising performance in speech emotion recognition.},
  archive      = {J_NEUCOM},
  author       = {Shuzhen Li and Xiaofen Xing and Weiquan Fan and Bolun Cai and Perry Fordson and Xiangmin Xu},
  doi          = {10.1016/j.neucom.2021.02.094},
  journal      = {Neurocomputing},
  pages        = {238-248},
  shortjournal = {Neurocomputing},
  title        = {Spatiotemporal and frequential cascaded attention networks for speech emotion recognition},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving abstractive summarization based on dynamic
residual network with reinforce dependency. <em>NEUCOM</em>,
<em>448</em>, 228–237. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Seq2Seq abstract summarization model based on long short-term memory (LSTM) is very effective for short text summarization. However, LSTM is limited by long-term dependencies, which can potentially result in salient information loss when long text is processed by the Seq2Seq model based on LSTM. To overcome the long-term dependence limitation, an encoder-decoder model based on the dynamic residual network is proposed in this work. The model can dynamically select an optimal state from the state history to establish a connection with the current state to improve the LSTM long sequence dependencies according to the current decoding environment. Because the dynamic residual connections will result in long-term connection-dependent words, a new method based on reinforcement learning is proposed to simulate the dependence between words, which is then implemented into the training process of the model. This model is verified using the CNN/Daily Mail and New York Times datasets, and the experimental results show that the proposed model achieves significant improvements in capturing long-term dependencies compared with the traditional LSTM-based Seq2Seq abstractive summarization model.},
  archive      = {J_NEUCOM},
  author       = {Weizhi Liao and Yaheng Ma and Yanchao Yin and Guanglei Ye and Dongzhou Zuo},
  doi          = {10.1016/j.neucom.2021.02.028},
  journal      = {Neurocomputing},
  pages        = {228-237},
  shortjournal = {Neurocomputing},
  title        = {Improving abstractive summarization based on dynamic residual network with reinforce dependency},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021g). Real-domain QR decomposition models employing zeroing
neural network and time-discretization formulas for time-varying
matrices. <em>NEUCOM</em>, <em>448</em>, 217–227. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigated the problem of QR decomposition for time-varying matrices. We transform the original QR decomposition problem into an equation system using its constraints. Then, we propose a continuous-time QR decomposition (CTQRD) model by applying zeroing neural network method, equivalent transformations, Kronecker product , and vectorization techniques. Subsequently, a high-precision ten-instant Zhang et al. discretization (ZeaD) formula is proposed. A ten-instant discrete-time QR decomposition model is also proposed by using the ten-instant ZeaD formula to discretize the CTQRD model. Moreover, three discrete-time QR decomposition models are proposed by applying three other ZeaD formulas, and three examples of QR decomposition are presented. The experimental results confirm the effectiveness and correctness of the proposed models for the QR decomposition of time-varying matrices.},
  archive      = {J_NEUCOM},
  author       = {Zhenyu Li and Yunong Zhang and Liangjie Ming and Jinjin Guo and Vasilios N. Katsikis},
  doi          = {10.1016/j.neucom.2021.03.014},
  journal      = {Neurocomputing},
  pages        = {217-227},
  shortjournal = {Neurocomputing},
  title        = {Real-domain QR decomposition models employing zeroing neural network and time-discretization formulas for time-varying matrices},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep learning framework for autonomous flame detection.
<em>NEUCOM</em>, <em>448</em>, 205–216. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel framework of flame region-based convolutional neural network for autonomous flame detection. The task of flame detection is especially challenging since flames have greater diversity in colour, texture, and shape than regular rigid objects. To cope with these difficulties due to the various appearances and unclear edges of flames, a proposal generation approach is developed to effectively select candidate flame regions based on two crucial properties of flames, i.e., their dynamics and colours. The candidate flame regions together with a convolutional feature map are further processed by additional layers to output detected flames. The diversity in flame colours is well represented by approximating the distribution using a Dirichlet Process Gaussian mixture model with variational inference. The proposed framework is evaluated on publicly available videos and achieves an average frame-wise accuracy higher than 88\%, which outperforms the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zhenglin Li and Lyudmila Mihaylova and Le Yang},
  doi          = {10.1016/j.neucom.2021.03.019},
  journal      = {Neurocomputing},
  pages        = {205-216},
  shortjournal = {Neurocomputing},
  title        = {A deep learning framework for autonomous flame detection},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A survey: Deep learning for hyperspectral image
classification with few labeled samples. <em>NEUCOM</em>, <em>448</em>,
179–204. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning technology and improvement in computing capability, deep learning has been widely used in the field of hyperspectral image (HSI) classification. In general, deep learning models often contain many trainable parameters and require a massive number of labeled samples to achieve optimal performance. However, in regard to HSI classification, a large number of labeled samples is generally difficult to acquire due to the difficulty and time-consuming nature of manual labeling. Therefore, many research works focus on building a deep learning model for HSI classification with few labeled samples. In this article, we concentrate on this topic and provide a systematic review of the relevant literature. Specifically, the contributions of this paper are twofold. First, the research progress of related methods is categorized according to the learning paradigm, including transfer learning , active learning and few-shot learning. Second, a number of experiments with various state-of-the-art approaches has been carried out, and the results are summarized to reveal the potential research directions. More importantly, it is notable that although there is a vast gap between deep learning models (that usually need sufficient labeled samples) and the HSI scenario with few labeled samples, the issues of small-sample sets can be well characterized by fusion of deep learning methods and related techniques, such as transfer learning and a lightweight model. For reproducibility, the source codes of the methods assessed in the paper can be found at https://github.com/ShuGuoJ/HSI-Classification.git.},
  archive      = {J_NEUCOM},
  author       = {Sen Jia and Shuguo Jiang and Zhijie Lin and Nanying Li and Meng Xu and Shiqi Yu},
  doi          = {10.1016/j.neucom.2021.03.035},
  journal      = {Neurocomputing},
  pages        = {179-204},
  shortjournal = {Neurocomputing},
  title        = {A survey: Deep learning for hyperspectral image classification with few labeled samples},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A hybrid deep segmentation network for fundus vessels via
deep-learning framework. <em>NEUCOM</em>, <em>448</em>, 168–178. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-precision segmentation of fundus vessels is a fundamental step in the diagnosis and treatment of fundus diseases, in which both thick and thin vessels are important features for symptom detection. With the rapid development of artificial intelligence , the deep convolutional neural network (DCNN) has been widely applied into image analysis of fundus vessels. Nevertheless, due to the imbalanced ratio between thick and thin vessels, the existing segmentation methods are weak in the task of microvessel extraction from fundus images. To address this problem, this paper proposes a new hybrid deep image segmentation method for fundus vessels that consists of a multitask segmentation network and a fusion network. For the proposed method, a multitask segmentation network is developed to precisely segment both thick vessels and thin vessels from fundus images separately. In addition, an effective loss function is designed to adapt to the two different vessel segmentation tasks and ultimately solve the imbalanced ratio between these two vessels. Furthermore, an improved U-net network model is proposed to serve as the basic segmentation network to ensure the segmentation performance of the multitask segmentation network. Together with these networks, a fusion network is also proposed to fuse these two kinds of blood vessels to obtain the fusion images as the final segmentation results of fundus vessels. The proposed segmentation method is validated on many different public data sets of fundus images, such as DRIVE, STARE and CHASE_DB1. Experimental results show that the proposed method obtains a better segmentation performance on fundus images and acquires a higher recall, F_1 value, and accuracy than other advanced segmentation methods .},
  archive      = {J_NEUCOM},
  author       = {Lei Yang and Huaixin Wang and Qingshan Zeng and Yanhong Liu and Guibin Bian},
  doi          = {10.1016/j.neucom.2021.03.085},
  journal      = {Neurocomputing},
  pages        = {168-178},
  shortjournal = {Neurocomputing},
  title        = {A hybrid deep segmentation network for fundus vessels via deep-learning framework},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). ERBANet: Enhancing region and boundary awareness for
salient object detection. <em>NEUCOM</em>, <em>448</em>, 152–167. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing methods based on convolutional neural networks (CNNs) have progressed significantly in the salient object detection task. However, in some cases, the accurate detection of intact objects and maintenance of their original detailed structures, such as boundaries, was not possible. In this paper, we propose an Enhancing Region and Boundary Awareness Network (ERBANet), equipped with attentional feature enhancement (AFE) modules to improve the detection performance. The AFE modules act on high-level and low-level features to generate corresponding attentional features. High-level attentional features are used to highlight entire salient objects, while low-level attentional features help retain their boundaries. The proposed ERBANet aims to effectively aggregate high-level and low-level attentional features, fully utilizing their respective advantages. Furthermore, we propose a novel boundary maintenance loss (BML) for learning to preserve the original boundaries of salient objects. Meanwhile, dice loss is combined for learning to enhance the integrity of salient regions . The experimental results on five benchmark datasets demonstrate that our proposed method outperforms recent state-of-the-art methods and achieves better performance.},
  archive      = {J_NEUCOM},
  author       = {Zhaojian Yao and Luping Wang},
  doi          = {10.1016/j.neucom.2021.03.094},
  journal      = {Neurocomputing},
  pages        = {152-167},
  shortjournal = {Neurocomputing},
  title        = {ERBANet: Enhancing region and boundary awareness for salient object detection},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differences first in asymmetric brain: A bi-hemisphere
discrepancy convolutional neural network for EEG emotion recognition.
<em>NEUCOM</em>, <em>448</em>, 140–151. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroscience research studies have shown that the left and right hemispheres of the human brain response differently to the same or different emotions. Exploiting this difference in the human brain response is important to emotion recognition. In this study, we propose a bi-hemisphere discrepancy convolutional neural network model (BiDCNN) for electroencephalograph (EEG) emotion recognition, which can effectively learn the different response patterns between the left and right hemispheres, and is designed as a three-input and single-output network structure with three convolutional neural network layers. Specifically, to capture and amplify different electrical responses of the left and right brain to emotional stimuli, three different EEG feature matrices are constructed based on the International 10–20 System. Subsequently, by using three convolutional neural network layers, the spatial and temporal features are extracted to mine the inter-channel correlation among the physically adjacent EEG electrodes. We evaluate our proposed BiDCNN model on the classical dataset called DEAP to verify its effectiveness. Our results of the subject-dependent experiment show that BiDCNN achieves state-of-the-art performance with a mean accuracy of 94.38\% in valence and 94.72\% in arousal, where the data for training and testing come from one subject. Furthermore, our subject-independent experimental results, in which different subjects are used to train and test the model, show that BiDCNN also obtains superior results on the valence and arousal recognition tasks, respectively achieving an accuracy of 68.14\% and 63.94\%.},
  archive      = {J_NEUCOM},
  author       = {Dongmin Huang and Sentao Chen and Cheng Liu and Lin Zheng and Zhihang Tian and Dazhi Jiang},
  doi          = {10.1016/j.neucom.2021.03.105},
  journal      = {Neurocomputing},
  pages        = {140-151},
  shortjournal = {Neurocomputing},
  title        = {Differences first in asymmetric brain: A bi-hemisphere discrepancy convolutional neural network for EEG emotion recognition},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A joint model for IT operation series prediction and anomaly
detection. <em>NEUCOM</em>, <em>448</em>, 130–139. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Status prediction and anomaly detection are two fundamental tasks in automatic IT systems monitoring. In this paper, a joint model Predictor &amp; Anomaly Detector (PAD) is proposed to address these two issues under one framework. In our design, the variational auto-encoder (VAE) and long short-term memory (LSTM) are joined together. The prediction block (LSTM) takes clean input from the reconstructed time series by VAE, which makes it robust to the anomalies and noise for prediction task. In the meantime, the LSTM block maintains the long-term sequential patterns, which are out of the sight of a VAE encoding window. This leads to the better performance of VAE in anomaly detection than it is trained alone. In the whole processing pipeline, the spectral residual analysis is integrated with VAE and LSTM to boost the performance of both. The superior performance on two tasks is confirmed with the experiments on two challenging evaluation benchmarks .},
  archive      = {J_NEUCOM},
  author       = {Run-Qing Chen and Guang-Hui Shi and Wan-Lei Zhao and Chang-Hui Liang},
  doi          = {10.1016/j.neucom.2021.03.062},
  journal      = {Neurocomputing},
  pages        = {130-139},
  shortjournal = {Neurocomputing},
  title        = {A joint model for IT operation series prediction and anomaly detection},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep multi-view learning methods: A review. <em>NEUCOM</em>,
<em>448</em>, 106–129. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view learning (MVL) has attracted increasing attention and achieved great practical success by exploiting complementary information of multiple features or modalities. Recently, due to the remarkable performance of deep models, deep MVL has been adopted in many domains, such as machine learning , artificial intelligence and computer vision. This paper presents a comprehensive review on deep MVL from the following two perspectives: MVL methods in deep learning scope and deep MVL extensions of traditional methods. Specifically, we first review the representative MVL methods in the scope of deep learning , such as multi-view auto-encoder, conventional neural networks and deep brief networks. Then, we investigate the advancements of the MVL mechanism when traditional learning methods meet deep learning models , such as deep multi-view canonical correlation analysis, matrix factorization and information bottleneck. Moreover, we also summarize the main applications, widely-used datasets and performance comparison in the domain of deep MVL. Finally, we attempt to identify some open challenges to inform future research directions.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqiang Yan and Shizhe Hu and Yiqiao Mao and Yangdong Ye and Hui Yu},
  doi          = {10.1016/j.neucom.2021.03.090},
  journal      = {Neurocomputing},
  pages        = {106-129},
  shortjournal = {Neurocomputing},
  title        = {Deep multi-view learning methods: A review},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cosine metric supervised deep hashing with balanced
similarity. <em>NEUCOM</em>, <em>448</em>, 94–105. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep supervised hashing takes prominent advantages of low storage cost, high computational efficiency and good retrieval performance , which draws attention in the field of large-scale image retrieval . However, similarity-preserving, quantization errors and imbalanced data are still great challenges in deep supervised hashing. This paper proposes a pairwise similarity-preserving deep hashing scheme to handle the aforementioned problems in a unified framework, termed as Cosine Metric Supervised Deep Hashing with Balanced Similarity (BCMDH). BCMDH integrates contrastive cosine similarity and Cosine distance entropy quantization to preserve the original semantic distribution and reduce the quantization errors simultaneously. Furthermore, a weighted similarity measure with cosine metric entropy is designed to reduce the impact of imbalanced data , which adaptively assigns weights according to sample attributes (pos/neg and easy/hard) in the embedding process of similarity-preserving. The experimental results on four widely-used datasets demonstrate that the proposed method is capable of generating hash codes of high quality and improve large-scale image retrieval performance .},
  archive      = {J_NEUCOM},
  author       = {Wenjin Hu and Lifang Wu and Meng Jian and Yukun Chen and Hui Yu},
  doi          = {10.1016/j.neucom.2021.03.093},
  journal      = {Neurocomputing},
  pages        = {94-105},
  shortjournal = {Neurocomputing},
  title        = {Cosine metric supervised deep hashing with balanced similarity},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature learning for stacked ELM via low-rank matrix
factorization. <em>NEUCOM</em>, <em>448</em>, 82–93. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme-learning-machine based auto-encoder (ELM-AE) is regarded as a useful architecture with fast learning speed and general approximation ability, and stacked ELM is used to develop efficient and effective deep learning networks. However, considering features learned from conventional ELM-AEs have issues of weak nonlinear representation ability and random factors in feature projection, this paper proposes an improved ELM-AE architecture which utilize low-rank matrix factorization to learn optimal low-dimensional features. Two superiorities can be obtained compared to conventional ELM-AEs. One is the dimensionality of the hidden layer in ELM-AE could be set arbitrarily, e.g. a higher-dimension hidden layer could lower the random effect in feature learning and enhance features representation ability. The other is enhancing features nonlinear ability, since features are learned directly from the nonlinear outputs of hidden layer. Finally, comparison experiments on numerical and image datasets are implemented in this paper to verify the superior performance of the proposed ELM-AE in this paper.},
  archive      = {J_NEUCOM},
  author       = {Tinghui Ouyang},
  doi          = {10.1016/j.neucom.2021.03.110},
  journal      = {Neurocomputing},
  pages        = {82-93},
  shortjournal = {Neurocomputing},
  title        = {Feature learning for stacked ELM via low-rank matrix factorization},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Stability analysis for quaternion-valued inertial
memristor-based neural networks with time delays. <em>NEUCOM</em>,
<em>448</em>, 67–81. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quaternion-valued inertial memristor-based neural networks with time-varying delays are found to be effective in demonstrating complex dynamic behaviors . Considering the stability of the periodic solution for a novel neural network, we construct a class quaternion-valued inertial memristor-based neural network model by combining with the cellular neural networks and the inertial item with time-varying delay. Based on the continuation theorem of Mawhin’s coincidence degree theory, differential inclusion theory, and inequality techniques, some sufficient criteria for the existence of periodic solutions are obtained. Meanwhile, through constructing a novel Lyapunov functional method, several sufficient conditions have been derived to ensure the global exponential stability of periodic solutions. At last, an example is provided to illustrate the obtained theoretical results of the quaternion-valued inertial memristor-based neural networks model.},
  archive      = {J_NEUCOM},
  author       = {Weide Liu and Jianliang Huang and Qinghe Yao},
  doi          = {10.1016/j.neucom.2021.03.106},
  journal      = {Neurocomputing},
  pages        = {67-81},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis for quaternion-valued inertial memristor-based neural networks with time delays},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asymptotical state synchronization for the controlled
directed complex dynamic network via links dynamics. <em>NEUCOM</em>,
<em>448</em>, 60–66. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the perspective of large-scale system, a directed complex dynamic network (DCDN) may be considered as a coupling system of the node subsystem (NS) and the link subsystem (LS). In this paper, by using the outgoing link vector and incoming link vector for DCDN, the dynamics of LS is described by employing the vector differential equation instead of the matrix differential equation. Since the outgoing and incoming link vectors have the stronger geometric intuition, the results in this paper show that this kind model of links can not only reflect the direction of links but also find the dynamic tracking goal of links more easily when the state synchronization of NS emerges. Furthermore, by employing the simple mathematical conditions, the nonlinear controller of NS and the coupling term of LS are proposed to ensure achieving the asymptotical state synchronization for DCDN. Finally, the numerical simulations are given to demonstrate the validity of the results in this paper.},
  archive      = {J_NEUCOM},
  author       = {Peitao Gao and Yinhe Wang and Lizhi Liu and LiLi Zhang and Xiao Tang},
  doi          = {10.1016/j.neucom.2021.03.095},
  journal      = {Neurocomputing},
  pages        = {60-66},
  shortjournal = {Neurocomputing},
  title        = {Asymptotical state synchronization for the controlled directed complex dynamic network via links dynamics},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning the structure of bayesian networks via the
bootstrap. <em>NEUCOM</em>, <em>448</em>, 48–59. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning the structure of dependencies among multiple random variables is a problem of considerable theoretical and practical interest. Within the context of Bayesian Networks , a practical and surprisingly successful solution to this learning problem is achieved by adopting score-functions optimisation schema, augmented with multiple restarts to avoid local optima. Yet, the conditions under which such strategies work well are poorly understood, and there are also some intrinsic limitations to learning the directionality of the interaction among the variables. Following an early intuition of Friedman and Koller, we propose to decouple the learning problem into two steps: first, we identify a partial ordering among input variables which constrains the structural learning problem, and then propose an effective bootstrap-based algorithm to simulate augmented data sets, and select the most important dependencies among the variables. By using several synthetic data sets, we show that our algorithm yields better recovery performance than the state of the art, increasing the chances of identifying a globally-optimal solution to the learning problem, and solving also well-known identifiability issues that affect the standard approach. We use our new algorithm to infer statistical dependencies between cancer driver somatic mutations detected by high-throughput genome sequencing data of multiple colorectal cancer patients . In this way, we also show how the proposed methods can shade new insights about cancer initiation, and progression. Code: https://github.com/caravagn/Bootstrap-based-Learning},
  archive      = {J_NEUCOM},
  author       = {Giulio Caravagna and Daniele Ramazzotti},
  doi          = {10.1016/j.neucom.2021.03.071},
  journal      = {Neurocomputing},
  pages        = {48-59},
  shortjournal = {Neurocomputing},
  title        = {Learning the structure of bayesian networks via the bootstrap},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MultiFace: A generic training mechanism for boosting face
recognition performance. <em>NEUCOM</em>, <em>448</em>, 40–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Convolutional Neural Networks (DCNNs) and their variants have been widely used in large scale face recognition(FR) recently. Existing methods have achieved good performance on many FR benchmarks. However, most of them suffer from two major problems. First, these methods converge quite slowly since they optimize the loss functions in a high-dimensional and sparse Gaussian Sphere. Second, the high dimensionality of features, despite the powerful descriptive ability, brings difficulty to the optimization, which may lead to a sub-optimal local optimum. To address these problems, we propose a simple yet efficient training mechanism called MultiFace, where we approximate the original high-dimensional features by the ensemble of low-dimensional features. The proposed mechanism is also generic and can be easily applied to many advanced FR models. Moreover, it brings the benefits of good interpretability to FR models via the clustering effect. In detail, the ensemble of these low-dimensional features can capture complementary yet discriminative information, which can increase the intra-class compactness and inter-class separability. Experimental results show that the proposed mechanism can accelerate 2–3 times with the softmax loss and 1.2–1.5 times with Arcface or Cosface, while achieving state-of-the-art performances in several benchmark datasets. Especially, the significant improvements on large-scale datasets(e.g., IJB and MageFace) demonstrate the flexibility of our new training mechanism.},
  archive      = {J_NEUCOM},
  author       = {Jing Xu and Tszhang Guo and Yong Xu and Zenglin Xu and Kun Bai},
  doi          = {10.1016/j.neucom.2021.03.043},
  journal      = {Neurocomputing},
  pages        = {40-47},
  shortjournal = {Neurocomputing},
  title        = {MultiFace: A generic training mechanism for boosting face recognition performance},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective method for detecting malicious PowerShell scripts
based on hybrid features☆. <em>NEUCOM</em>, <em>448</em>, 30–39. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, network attacks are rampant in the Internet world, and the attack methods of hackers are changing steadily. PowerShell is a programming language based on the command line and.NET framework, with powerful functions and good compatibility. Therefore, hackers often use PowerShell malicious scripts to attack the victims in APT attacks. When these malicious PowerShell scripts are executed, hackers can control the victim’s computer or leave a backdoor on their computers. In this paper, a detection model of malicious PowerShell scripts based on hybrid features is proposed, we analyzed the differences between malicious and benign samples in text characters, functions, tokens and the nodes of the abstract syntax tree. Firstly, the script of PowerShell is embedded by FastText. Then the textual features, token features and the nodes features of PowerShell code extracted from the abstract syntax tree are added. Finally, the hybrid features of scrips will be classified by a Random Forest classifier. In the experiment, the malicious scripts are inserted into the benign scripts to weaken the features of the malicious samples in the level of abstract syntax tree nodes and tokens, which makes the scripts more complex. Even in such a complex data set, the proposed model which is based on hybrid features still achieves an accuracy of 97.76\% in fivefold cross-validation. Moreover, the accuracy of this proposed model on the original scripts is 98.93\%, which means that the proposed model has the ability to classify complex scripts.},
  archive      = {J_NEUCOM},
  author       = {Yong Fang and Xiangyu Zhou and Cheng Huang},
  doi          = {10.1016/j.neucom.2021.03.117},
  journal      = {Neurocomputing},
  pages        = {30-39},
  shortjournal = {Neurocomputing},
  title        = {Effective method for detecting malicious PowerShell scripts based on hybrid features☆},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Learning noise-decoupled affine models for extreme
low-light image enhancement. <em>NEUCOM</em>, <em>448</em>, 21–29. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {How to handle the noise effectively is an important yet challenging problem for low-light image enhancement especially in real-world extreme low-light conditions. Furthermore, contrast enhancement and noise removal are coupled problems, it’s hard to trade off well between noise suppression and preservation of details. To this end, this paper proposes an end-to-end network for low-light image enhancement with a particular focus on handling this coupling relationship. The basic idea is to convert low-light image enhancement to local affine color transformations. Instead of image smooth denoising , a special noise processing mechanism is proposed to learn noise-decoupled affine models. Alternatively, to achieve efficient learning, the whole network is trained in bilateral space. Extensive experiments on several benchmark datasets have shown that the proposed method is very competitive to state-of-the-art methods. Especially when processing images captured in extreme low-light conditions, it has a significant advantage over other algorithms in reducing noise while retaining image details.},
  archive      = {J_NEUCOM},
  author       = {Maomei Liu and Lei Tang and Sheng Zhong and Hangzai Luo and Jinye Peng},
  doi          = {10.1016/j.neucom.2021.03.107},
  journal      = {Neurocomputing},
  pages        = {21-29},
  shortjournal = {Neurocomputing},
  title        = {Learning noise-decoupled affine models for extreme low-light image enhancement},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SCENT: A new precipitation nowcasting method based on sparse
correspondence and deep neural network. <em>NEUCOM</em>, <em>448</em>,
10–20. (<a href="https://doi.org/10.1016/j.neucom.2021.02.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precipitation nowcasting is an important research topic in meteorology, which relates to many aspects of people’s life and social development. Under the combined influence of resolution and corresponding timestamp, a certain nonlinear relationship is satisfied between the echo intensity and precipitation. Therefore, the short-term precipitation prediction scheme based on radar echo extrapolation has become the main research method. By analyzing the spatiotemporal characteristics of the radar echo images, we found that precipitation results are related not only to currently observed radar echo images but also to some non-image features such as wind speed and shape of cloud clusters. Inspired by optical flow method, combined with the characteristics of radar reflectivity, we propose a new method SCENT to achieve precipitation prediction. Firstly, the sparse correspondence method based on Fast feature detection and SIFT matching is used to radar echo extrapolate and complete the extraction of non-image influence features. Afterwards, an improved neural network is utilized for regression calculation to obtain the total precipitation. By comparing with existing prediction models based on deep neural network , our new method can make precipitation nowcasting more accurate.},
  archive      = {J_NEUCOM},
  author       = {Wei Fang and Feihong Zhang and Victor S. Sheng and Yewen Ding},
  doi          = {10.1016/j.neucom.2021.02.072},
  journal      = {Neurocomputing},
  pages        = {10-20},
  shortjournal = {Neurocomputing},
  title        = {SCENT: A new precipitation nowcasting method based on sparse correspondence and deep neural network},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise-modulated neural networks for selectively
functionalizing sub-networks by exploiting stochastic resonance.
<em>NEUCOM</em>, <em>448</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the phenomenon of stochastic resonance , adding a certain level of nonzero noise to a nonlinear system reduces information loss. A previous study proposed a neural network consisting of thresholding functions that exploit stochastic resonance at run time and during training, with the aim of smooth mapping and backpropagation . Such a neural network can be rephrased as one that operates only when noise is added, i.e., one that is unable to smoothly map and train when noise is absent. Focusing on both explanations simultaneously, a neural network for which only a sub-network is activated selectively by adding noise locally on that sub-network is proposed in this paper. To this end, a new activation function is introduced. It exploits stochastic resonance and presents null output and derivative when no noise is added. Simple simulations confirm that the proposed neural network with the new activation function allows the sub-network to be functionalized selectively, and interpolations are investigated by imposing varying noise intensity on various regions of the network after sub-networks are trained separately.},
  archive      = {J_NEUCOM},
  author       = {Shuhei Ikemoto},
  doi          = {10.1016/j.neucom.2020.05.125},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Noise-modulated neural networks for selectively functionalizing sub-networks by exploiting stochastic resonance},
  volume       = {448},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multistability and robustness of complex-valued neural
networks with delays and input perturbation. <em>NEUCOM</em>,
<em>447</em>, 319–328. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concentrates on the multistability and robustness of complex-valued neural networks (CVNNs) with delays and input perturbation. Firstly, several criteria on the multiple ψ ψ -type stability of CVNNs with time-varying delays are obtained by virtue of ψ ψ -type function and the analytical method. Secondly, several sufficient conditions of robustness have been derived to guarantee the ψ ψ -type stability and boundedness of delayed CVNNs with input perturbation. These obtained results improve and extend the previous results. Finally, one numerical example is provided to show the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Fanghai Zhang and Tingwen Huang and Dan Feng and Zhigang Zeng},
  doi          = {10.1016/j.neucom.2021.03.045},
  journal      = {Neurocomputing},
  pages        = {319-328},
  shortjournal = {Neurocomputing},
  title        = {Multistability and robustness of complex-valued neural networks with delays and input perturbation},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Skip-connected network with gram matrix for product image
retrieval. <em>NEUCOM</em>, <em>447</em>, 307–318. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Designers usually retrieve and review existing relevant product images to draw inspiration when designing a new proposal. Obtaining reasonable retrieval results of a given target is a challenging task due to the large-scale, low-correlation searching process in the product image field. In this paper, an end-to-end skip-connected network is introduced to improve the accuracy of retrieval by directly addressing the above problems. In more detail, skip-connections are employed to combine the multi-resolution feature maps produced by a pre-trained backbone network , which provides important improvements to address the presence of large scale variance problem. And the second-order information of the multi-resolution feature maps is obtained by using gram matrix operation , which allows the network to exploit more representative features and their correlations. Experimental results indicate that the proposed method achieves better retrieval performance when compared to current state-of-the-art techniques on there normal benchmark datasets as well as the product image data.},
  archive      = {J_NEUCOM},
  author       = {Yong Dai and Yi Li and Bin Sun and Li-Jun Liu},
  doi          = {10.1016/j.neucom.2021.03.067},
  journal      = {Neurocomputing},
  pages        = {307-318},
  shortjournal = {Neurocomputing},
  title        = {Skip-connected network with gram matrix for product image retrieval},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhanced beetle antennae search with zeroing neural network
for online solution of constrained optimization. <em>NEUCOM</em>,
<em>447</em>, 294–306. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a continuous-time enhanced variant of Beetle Antennae Search (BAS), a metaheuristic algorithm that mimics the food searching nature of beetles. Beetles register the smell of the food on their two antennae, and based on the intensity of smell, they move left or right. Likewise, discrete-time BAS computes the value of objective function three times and moves toward the optimal solution. However, the computation of objective function three times in each iteration known as a “virtual particle,” makes it computationally expensive, inefficient, and time-consuming, especially while dealing with complex systems, e.g., redundant manipulators. Our proposed, Enhanced Beetle Antennae Search with Zeroing Neural Network (BASZNN) algorithm overcomes this problem by introducing a delay factor in objective function and input. This delay allows BASZNN to compute objective function value once, making it computationally robust and efficient. BASZNN includes the flexible random searching nature of BAS and the parallel processing nature of ZNN, making it computationally fast and less time-consuming, especially for complex problems. As a testbed , we employed BASZNN on two types of problems: Unconstrained (unimodal, multimodal) and Constrained (real-world) and compared the results with state-of-the-art metaheuristic algorithms.},
  archive      = {J_NEUCOM},
  author       = {Ameer Tamoor Khan and Xinwei Cao and Zhan Li and Shuai Li},
  doi          = {10.1016/j.neucom.2021.03.027},
  journal      = {Neurocomputing},
  pages        = {294-306},
  shortjournal = {Neurocomputing},
  title        = {Enhanced beetle antennae search with zeroing neural network for online solution of constrained optimization},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PNL: Efficient long-range dependencies extraction with
pyramid non-local module for action recognition. <em>NEUCOM</em>,
<em>447</em>, 282–293. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Long-range spatiotemporal dependencies capturing plays an essential role in improving video features for action recognition. The previously introduced non-local block, inspired by the non-local means, is designed to address this challenge and have shown excellent performance. However, the non-local block brings significant increase in computation cost to the original network. It also lacks the ability to model regional correlations in videos. To address the above limitations, we propose the Pyramid Non-Local (PNL) module, which extends the original non-local block by incorporating regional correlations at multiple scales through a pyramid structured module. This extension upscales the effectiveness of the original non-local block by attending to the interaction between different regions. Empirical results prove the effectiveness and efficiency of our PNL module, which achieves state-of-the-art performance of 83.09\% 83.09\% on the Mini-Kinetics dataset, with decreased computational cost compared to the non-local block.},
  archive      = {J_NEUCOM},
  author       = {Yuecong Xu and Haozhi Cao and Jianfei Yang and Kezhi Mao and Jianxiong Yin and Simon See},
  doi          = {10.1016/j.neucom.2021.03.064},
  journal      = {Neurocomputing},
  pages        = {282-293},
  shortjournal = {Neurocomputing},
  title        = {PNL: Efficient long-range dependencies extraction with pyramid non-local module for action recognition},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Finite-time synchronization of reaction-diffusion neural
networks with time-varying parameters and discontinuous activations.
<em>NEUCOM</em>, <em>447</em>, 272–281. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of finite-time synchronization (FTS) of discontinuous reaction-diffusion neural networks (DRDNNs) with time-varying coefficients is investigated here. First, the effects caused by discontinuous activations are handled by differential inclusion theory. Secondly, a relaxed Lyapunov function (RLF) method is introduced to design novel control algorithms, including state-feedback control and adaptive control, to achieve FTS of DRDNNs, and the upper-bound of the settling time is explicitly estimated. In this RLF method, the LF is allowed to be nonsmooth and possess an indefinite derivative.Moreover, the FTS results via generalized pinning state-feedback and generalized pinning adaptive control are presented as two corollaries. Finally, two numerical simulations are presented to substantiate the merits of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Zengyun Wang and Jinde Cao and Zuowei Cai and Xuegang Tan and Rensi Chen},
  doi          = {10.1016/j.neucom.2021.02.065},
  journal      = {Neurocomputing},
  pages        = {272-281},
  shortjournal = {Neurocomputing},
  title        = {Finite-time synchronization of reaction-diffusion neural networks with time-varying parameters and discontinuous activations},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly supervised object-aware convolutional neural networks
for semantic feature matching. <em>NEUCOM</em>, <em>447</em>, 257–271.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the task of establishing visual correspondences between two images depicting main objects of the same semantic category. This task encounters various challenges such as background clutter, intra-class variation, and viewpoint variations. Existing works are dominated by end-to-end training methods that rely on redundant calculation or large amounts of manual annotations, and cannot generalize to unseen object categories. In this paper, we propose to construct a weakly supervised object-aware convolutional neural network architecture for semantic feature matching, while being trainable end-to-end without the requirement for manual annotations. The main component of this architecture is a similarity filter module containing a trainable neural nearest neighbors network. Since training data for semantic feature matching is rather limited, we introduce a simple and effective foreground selection strategy to produce the foreground masks. Using these masks as a form of weak supervision signal for correspondence task and tackle the background clutter. Extensive experiments illustrate that the proposed approach outperforms the state-of-the-art methods for semantic feature matching on multiple public standard benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Wei Lyu and Lang Chen and Zhong Zhou and Wei Wu},
  doi          = {10.1016/j.neucom.2021.03.052},
  journal      = {Neurocomputing},
  pages        = {257-271},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised object-aware convolutional neural networks for semantic feature matching},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling implicit feedback based on bandit learning for
recommendation. <em>NEUCOM</em>, <em>447</em>, 244–256. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Implicit feedback such as clicks and favorites has been widely studied and applied to recommender systems due to its low collection cost and rich hidden information. In this paper, the recommendation based on implicit feedback of multiple behaviors is formalized into a multi-armed bandit (MAB) problem, and an online recommendation model based on MAB is proposed. In the model, we use item categories as arms, rather than using items as arms in existing related models, so that the number of arms can be fixed and the scale can be controlled, thereby avoiding computational complexity . Such a design can also increase the diversity of recommendations. In addition, we divide the implicit feedback into strong interaction, weak interaction, and non-interaction to calculate user preferences more accurately. Almost all recommendation models face two important challenges, namely the cold start problem and the exploration &amp; exploitation (EE) problem. In our model, a differentiated recommendation strategy is put forward to alleviate the cold start problem and a bandit learning algorithm based on Thompson sampling is proposed to balance the EE problem by making the expected reward of each arm subject to an independent beta distribution and using multi-behavior implicit feedback to update the posterior distribution . We verified the effectiveness of the proposed model on three public datasets, and discussed the factors that affect the model, as well as its robustness in the cold start environment.},
  archive      = {J_NEUCOM},
  author       = {Cairong Yan and Junli Xian and Yongquan Wan and Pengwei Wang},
  doi          = {10.1016/j.neucom.2021.03.072},
  journal      = {Neurocomputing},
  pages        = {244-256},
  shortjournal = {Neurocomputing},
  title        = {Modeling implicit feedback based on bandit learning for recommendation},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete-time super-twisting controller using neural
networks. <em>NEUCOM</em>, <em>447</em>, 235–243. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a neural super-twisting controller for a class of discrete-time nonlinear systems . A general plot of the control problem consists in considering a discrete-time nonlinear system with a block controllable structure, and assuming that the equations of the nonlinear system have virtual controls, a discrete-time super-twisting algorithm is applied such that each equation follows a desired trajectory until the real control is achieved. On the other hand, taking into account the capacity of neural networks to learn the behaviour of complex systems, it is proposed a neural network with a block controllable structure for identifying and controlling a discrete-time nonlinear system. Neural network weights are trained with the cubature Kalman filter algorithm. To show the effectiveness of the proposed neural super-twisting controller, a numerical simulation is performed on a Quanser 2-DOF helicopter.},
  archive      = {J_NEUCOM},
  author       = {M. Hernandez-Gonzalez and E.A. Hernandez-Vargas},
  doi          = {10.1016/j.neucom.2021.03.060},
  journal      = {Neurocomputing},
  pages        = {235-243},
  shortjournal = {Neurocomputing},
  title        = {Discrete-time super-twisting controller using neural networks},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel rumor detection algorithm based on entity
recognition, sentence reconfiguration, and ordinary differential
equation network. <em>NEUCOM</em>, <em>447</em>, 224–234. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social media has recently become one of the most used media in the world. This has resulted in a great hotbed for the growth of rumors, as anyone can spread knowledge and opinions without confirmation. Previous works on rumor detection focused on hand-extracted features and spent less effort on text representation. In this research, a novel method for rumor detection on social media is proposed, which integrates entity recognition, sentence reconfiguration and ordinary differential equation network under a unified framework called ESODE. An entity recognition method to enhance the semantic understanding of rumor texts is used. Then, a sentence reconfiguration to improve the frequency of important words is designed. The complete feature map is established by further collecting statistical features from three aspects: linguistic features on the content of rumors, characteristics of users involved in rumor propagating, and propagation network structures. Finally, the ordinary differential equation network (ODEnet) is applied to detect rumors. Experimental results on datasets from Twitter and Weibo show that the proposed method achieves better performance than previous ones.},
  archive      = {J_NEUCOM},
  author       = {Tinghuai Ma and Honghao Zhou and Yuan Tian and Najla Al-Nabhan},
  doi          = {10.1016/j.neucom.2021.03.055},
  journal      = {Neurocomputing},
  pages        = {224-234},
  shortjournal = {Neurocomputing},
  title        = {A novel rumor detection algorithm based on entity recognition, sentence reconfiguration, and ordinary differential equation network},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive bias RBF neural network control for a robotic
manipulator. <em>NEUCOM</em>, <em>447</em>, 213–223. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Considering the bias of the dynamics which is a global trend of the dynamical equation of a robot manipulator because of the gravity or the constant payloads, two kinds of adaptive bias radial basis function neural network (RBFNN) control schemes, which are the local bias scheme and the global bias scheme, are proposed to remedy the negative influence of the bias of the dynamics. Such slight modifications lead to the following two attractive features: 1) both of two schemes can improve the approximation accuracy of the RBFNN for the dynamics with significant bias, and then enhance the control performance correspondingly; 2) when the inputs deviate from the approximation domain of the RBFNN because of the large payloads, the controller with the local bias or global bias degrades to the PID controller to push the states back. It improves the robustness of the adaptive RBFNN controller further. We also propose a simpler controller structure that reduces the dimension of the input vectors from 4 n 4n to 3 n 3n , where n n is the degree of freedom of the manipulator. It exponentially decreases the computation cost of the RBFNNs. Uniform ultimate boundedness of the closed-loop system is proved by the Lyapunov stability theory. Finally, simulation results demonstrate the effectiveness of the proposed two schemes.},
  archive      = {J_NEUCOM},
  author       = {Qiong Liu and Dongyu Li and Shuzhi Sam Ge and Ruihang Ji and Zhong Ouyang and Keng Peng Tee},
  doi          = {10.1016/j.neucom.2021.03.033},
  journal      = {Neurocomputing},
  pages        = {213-223},
  shortjournal = {Neurocomputing},
  title        = {Adaptive bias RBF neural network control for a robotic manipulator},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative adaptive emotional neuro-control for a class of
higher-ordered heterogeneous uncertain nonlinear multi-agent systems.
<em>NEUCOM</em>, <em>447</em>, 196–212. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion is nature’s most exquisite survival mechanism to speedily and reasonably handle the uncertainties and complexities of life. It is hence reasonable to expect emotion-based artificial agencies to better handle their complex and uncertain environments and their interactions with other known or unknown agencies. Accordingly, an emotional neural network is proposed here for multi-agent systems (MAS). This computational paradigm has the universal approximation property of its well-established predecessor, the multilayer perceptron , but also promises the characteristics of the emotional mind such as fast response and learning. Specifically, we extend our previously established radial basis emotional neural network (RBENN) to approximate the uncertain dynamics in a cooperative adaptive radial basis emotional neuro-controller (CARENC) for a class of higher-ordered uncertain nonlinear MAS. Artificial potential functions are used to describe the interactions among heterogeneous agents. Also, the approximation error is compensated using an adaptive component. Suitable update laws are derived for the weights of RBENN that are consistent with the basic emotional models. In following Lyapunov stability theory , the overall system stability is also guaranteed. Application to two nonlinear multi-agent control problems shows a lower steady-state tracking and lesser control energy consumption when compared with a competing multi-agent neuro controller.},
  archive      = {J_NEUCOM},
  author       = {F. Baghbani and M.-R. Akbarzadeh-T and M.-B. Naghibi Sistani},
  doi          = {10.1016/j.neucom.2021.03.057},
  journal      = {Neurocomputing},
  pages        = {196-212},
  shortjournal = {Neurocomputing},
  title        = {Cooperative adaptive emotional neuro-control for a class of higher-ordered heterogeneous uncertain nonlinear multi-agent systems},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generalized elastic net optimal scoring problem for feature
selection. <em>NEUCOM</em>, <em>447</em>, 183–195. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear discriminant analysis (LDA) is a well-known tool for classification and dimensionality reduction. As an equivalent form of LDA, optimal scoring is presented to solve the classification problem by regression. In this paper, we propose a generalized elastic net optimal scoring problem (GenOS) to find sparse discriminant vectors, where the generalized elastic et is the combination of the ℓ 2 ℓ2 -norm and ℓ q ℓq -norm ( 0 0&amp;lt;q⩽1 ). In GenOS, ℓ q ℓq -norm is imposed to confer sparsity to discriminant vectors and ℓ 2 ℓ2 -norm is added to enhance the performance of the classifier. Then, a new efficient algorithm based on block coordinate descent (BCD) method is developed to solve GenOS approximately and the convergence is also established. Simulated data and real-world data are used to empirically illustrate the effectiveness of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Guoquan Li and Xuxiang Duan and Zhiyou Wu and Changzhi Wu},
  doi          = {10.1016/j.neucom.2021.03.018},
  journal      = {Neurocomputing},
  pages        = {183-195},
  shortjournal = {Neurocomputing},
  title        = {Generalized elastic net optimal scoring problem for feature selection},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Improving biomedical word representation with locally
linear embedding. <em>NEUCOM</em>, <em>447</em>, 172–182. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distributed word representation, usually obtained through calculation from large corpora, has been widely used in biomedical text because of its effectiveness in representing word semantic information. High-quality and meaningful biomedical words enable doctors to obtain the gist of information and knowledge in a short time to make clinical decisions quickly. Currently, the distributed word representation ignores the influence of the word embedding geometric structure obtained through calculation on the word semantic information and cannot accurately represent the word information, thus affecting the representation effect of biomedical text. To solve the above problems, we propose a biomedical word embedding framework based on manifold learning. Our work provides new perspectives for representing biomedical word embedding, which is the key concept in biomedical natural language processing tasks. First, the distributed word representation model is used to obtain the pretrained word embedding, and then the manifold learning is used to re-embed the pretrained word embedding. To verify the validity of the proposed framework in the biomedical domain, we evaluate the algorithm by using biomedical texts. Experimental results show that the proposed method can effectively improve the results of electronic health record classification and semantic similarity.},
  archive      = {J_NEUCOM},
  author       = {Di Zhao and Jian Wang and Yonghe Chu and Yijia Zhang and Zhihao Yang and Hongfei Lin},
  doi          = {10.1016/j.neucom.2021.02.071},
  journal      = {Neurocomputing},
  pages        = {172-182},
  shortjournal = {Neurocomputing},
  title        = {Improving biomedical word representation with locally linear embedding},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised stereoscopic image retargeting via view
synthesis and stereo cycle consistency losses. <em>NEUCOM</em>,
<em>447</em>, 161–171. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stereoscopic image retargeting aims to manipulate the stereoscopic images to fit various devices with different resolutions and prescribed aspect ratios. With the development of various types of three-dimensional (3D) displays, stereoscopic image retargeting becomes increasingly popular in the field of computer graphics . In this paper, we propose an unsupervised stereoscopic image retargeting network (USIR-Net) to address the problem of stereoscopic image retargeting without label information. By exploring the inter-view correlation and disparity relationship of stereoscopic images, two unsupervised losses are developed to guide the learning of stereoscopic image retargeting model. First, in view of the inter-view correlation, a view synthesis loss is proposed to guarantee the generation of high-quality stereoscopic images with accurate inter-view relationship. Second, by exploiting the consistency of stereoscopic images before and after the retargeting, a stereo cycle consistency loss, which consists of a content consistency term and a disparity consistency term, is developed to preserve the structure information and prevent binocular disparity inconsistency. Quantitative and qualitative experimental results demonstrate that the proposed method achieves superior performance compared with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaoting Fan and Jianjun Lei and Jie Liang and Yuming Fang and Xiaochun Cao and Nam Ling},
  doi          = {10.1016/j.neucom.2021.02.079},
  journal      = {Neurocomputing},
  pages        = {161-171},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised stereoscopic image retargeting via view synthesis and stereo cycle consistency losses},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Benchmarking the performance of neuromorphic and spiking
neural network simulators. <em>NEUCOM</em>, <em>447</em>, 145–160. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software simulators play a critical role in the development of new algorithms and system architectures in any field of engineering. Neuromorphic computing, which has shown potential in building brain-inspired energy-efficient hardware, suffers a slow-down in the development cycle due to a lack of flexible and easy-to-use simulators of either neuromorphic hardware itself or of spiking neural networks (SNNs), the type of neural network computation executed on most neuromorphic systems. While there are several openly available neuromorphic or SNN simulation packages developed by a variety of research groups, they have mostly targeted computational neuroscience simulations, and only a few have targeted small-scale machine learning tasks with SNNs. Evaluations or comparisons of these simulators have often targeted computational neuroscience-style workloads. In this work, we seek to evaluate the performance of several publicly available SNN simulators with respect to non-computational neuroscience workloads, in terms of speed, flexibility, and scalability. We evaluate the performance of the NEST, Brian2, Brian2GeNN, BindsNET and Nengo packages under a common front-end neuromorphic framework. Our evaluation tasks include a variety of different network architectures and workload types to mimic the computation common in different algorithms, including feed-forward network inference, genetic algorithms, and reservoir computing . We also study the scalability of each of these simulators when running on different computing hardware, from single core CPU workstations to multi-node supercomputers . Our results show that the BindsNET simulator has the best speed and scalability for most of the SNN workloads (sparse, dense, and layered SNN architectures) on a single core CPU. However, when comparing the simulators leveraging the GPU capabilities, Brian2GeNN outperforms the others for these workloads in terms of scalability. NEST performs the best for small sparse networks and is also the most flexible simulator in terms of reconfiguration capability NEST shows a speedup of at least 2 × 2× compared to the other packages when running evolutionary algorithms for SNNs. The multi-node and multi-thread capabilities of NEST show at least 2 × 2× speedup compared to the rest of the simulators (single core CPU or GPU based simulators) for large and sparse networks. We conclude our work by providing a set of recommendations on the suitability of employing these simulators for different tasks and scales of operations. We also present the characteristics for a future generic ideal SNN simulator for different neuromorphic computing workloads.},
  archive      = {J_NEUCOM},
  author       = {Shruti R. Kulkarni and Maryam Parsa and J. Parker Mitchell and Catherine D. Schuman},
  doi          = {10.1016/j.neucom.2021.03.028},
  journal      = {Neurocomputing},
  pages        = {145-160},
  shortjournal = {Neurocomputing},
  title        = {Benchmarking the performance of neuromorphic and spiking neural network simulators},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). HDNet: Hybrid distance network for semantic segmentation.
<em>NEUCOM</em>, <em>447</em>, 129–144. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is currently solved as a pixel-wise labeling task, which predicts the label of each pixel based on its features. However, current methods isolate the relations of points in a feature map and cause the discontinuous segmentation results. In order to solve this problem, we propose a Hybrid Distance Network to measure the distance from two aspects. First, the Hybrid Distance Relation is proposed to model the relations between a point and its context regions to capture contexts in a feature map by an elegant combination of positional distance and high-dimension feature distance. Then, a Location Aware Attention module is proposed to efficiently sample the contexts by the positional distance and produces sparse Hybrid Distance Relations. It synthesizes the different contexts of each point and generates position-wise attention value to compact object-level representation. During the training step, High-dimension Feature Distance loss is also presented as an auxiliary loss to compact category-level representation in feature space. Experiments show that the proposed HDNet achieves state-of-the-art performance with interpretability and efficiency on three challenging semantic segmentation benchmarks: Pascal Context, ADE20K, and COCO Stuff 10 K.},
  archive      = {J_NEUCOM},
  author       = {Chunpeng Li and Xuejing Kang and Lei Zhu and Lizhu Ye and Panhe Feng and Anlong Ming},
  doi          = {10.1016/j.neucom.2021.03.044},
  journal      = {Neurocomputing},
  pages        = {129-144},
  shortjournal = {Neurocomputing},
  title        = {HDNet: Hybrid distance network for semantic segmentation},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Large margin metric learning for multi-view vehicle
re-identification. <em>NEUCOM</em>, <em>447</em>, 118–128. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper we propose a novel large margin metric learning scheme for vehicle re-identification (re-ID), which aims to maximize the distance margins among different vehicles in the embedding feature space. Inspired by the fact that in the embedding feature space vehicles with the same identity are usually scattered sparsely due to vehicles’ multi-view appearance, our method is designed to make samples with the same identities more compact and meanwhile project instances with different categories to separate regions in the embedding space. To make training process more efficient, in the first stage, only the Softmax Loss is adopted, and in the second stage, by computing classification hyperplanes between different vehicle identities, a large margin loss is defined to maximize the distances between training samples and their corresponding hyperplanes . Besides, a new sampling method is adopted to find the hardest samples which are close to their hyperplanes and a kernelized re-ranking method is applied to further boost the performance. Compared with state-of-the-art approaches, our method achieves superior results with efficient training and inference process and only the identity as supervision signal. Experimental results on three most popular datasets show that our system produce promising results, and notably on the VeRi-776 dataset, our method can reach the best record with Rank1 96.81\% and mAP 80.95\%.},
  archive      = {J_NEUCOM},
  author       = {Shilin Zhang and Cong Lin and Siming Ma},
  doi          = {10.1016/j.neucom.2021.02.095},
  journal      = {Neurocomputing},
  pages        = {118-128},
  shortjournal = {Neurocomputing},
  title        = {Large margin metric learning for multi-view vehicle re-identification},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ESA☆: A generic framework for semi-supervised inductive
learning. <em>NEUCOM</em>, <em>447</em>, 102–117. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised learning is crucial in many applications where accessing class labels is unaffordable or costly. The most promising approaches are graph-based but they are transductive and they do not provide a generalized model working on inductive scenarios. To address this problem, we propose a generic framework, ESA ☆ , for inductive semi-supervised learning based on three components: an ensemble of semi-supervised autoencoders providing a new data representation that leverages the knowledge supplied by the reduced amount of available labels; a graph-based step that helps augmenting the training set with pseudo-labeled instances and, finally, a classifier trained with labeled and pseudo-labeled instances. Additionally, we also introduce two variants of our framework adopting different graph-based pseudo-labeling strategies: the first, ESA LP , is based on a confidence-aware label propagation algorithm, while the second, ESA GAT , on a graph convolutional attention network. The experimental results show that our framework outperforms state-of-the-art inductive semi-supervised methods.},
  archive      = {J_NEUCOM},
  author       = {Shuyi Yang and Dino Ienco and Roberto Esposito and Ruggero G. Pensa},
  doi          = {10.1016/j.neucom.2021.03.051},
  journal      = {Neurocomputing},
  pages        = {102-117},
  shortjournal = {Neurocomputing},
  title        = {ESA☆: A generic framework for semi-supervised inductive learning},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel transferability attention neural network model for
EEG emotion recognition. <em>NEUCOM</em>, <em>447</em>, 92–101. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The existed methods for electroencephalograph (EEG) emotion recognition always train the models based on all the EEG samples indistinguishably. However, some of the source (training) samples may lead to a negative influence because they are significant dissimilar with the target (test) samples. So it is necessary to give more attention to the EEG samples with strong transferability rather than forcefully training a classification model by all the samples. Furthermore, for an EEG sample, from the aspect of neuroscience , not all the brain regions of an EEG sample contain emotional information that can transferred to the test data effectively. Even some brain region data will make strong negative effect for learning the emotional classification model . Considering these two issues, in this paper, we propose a transferable attention neural network (TANN) for EEG emotion recognition, which learns the emotional discriminative information by highlighting the transferable EEG brain regions data and samples adaptively through local and global attention mechanism . This can be implemented by measuring the outputs of multiple brain-region-level discriminators and one single sample-level discriminator. Extensive experiments on EEG emotion recognition demonstrate that the proposed TANN is superior to those state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yang Li and Boxun Fu and Fu Li and Guangming Shi and Wenming Zheng},
  doi          = {10.1016/j.neucom.2021.02.048},
  journal      = {Neurocomputing},
  pages        = {92-101},
  shortjournal = {Neurocomputing},
  title        = {A novel transferability attention neural network model for EEG emotion recognition},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-object tracking with hard-soft attention network and
group-based cost minimization. <em>NEUCOM</em>, <em>447</em>, 80–91. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-object tracking (MOT) has received constant attention from researchers with the development of deep learning and person re-identification (ReID). However, the occlusion caused tracking failure is still far from solved. In this paper, we propose a Hard-Soft Attention Network (HSAN) to improve the ReID performance and get robust appearance features of different targets. The pose information and attention mechanism are combined to distinguish between challenging targets. Besides, the unary and binary costs are constructed to ensure consistency and long-term tracking, which consider not only the appearance-motion affinity of single tracks, but also the interactions between neighboring tracks. For that we cluster the tracks into different groups and choose reliable tracks as anchors to establish the two types of costs. Our HSAN appearance model is evaluated on the Market-1501, DUKE and CUHK03 ReID datasets and the MOT tracking method is conducted on MOTChallenge 15, 16 and 17. The experimental results demonstrate that our method can improve tracking accuracy and reduce fragments.},
  archive      = {J_NEUCOM},
  author       = {Yating Liu and Xuesong Li and Tianxiang Bai and Kunfeng Wang and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2021.02.084},
  journal      = {Neurocomputing},
  pages        = {80-91},
  shortjournal = {Neurocomputing},
  title        = {Multi-object tracking with hard-soft attention network and group-based cost minimization},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Particle swarm optimization with state-based adaptive
velocity limit strategy. <em>NEUCOM</em>, <em>447</em>, 64–79. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Velocity limit (VL) has been widely adopted in many variants of particle swarm optimization (PSO) to prevent particles from searching outside the solution space. Several adaptive VL strategies have been introduced with which the performance of PSO can be improved. However, the existing adaptive VL strategies simply adjust their VL based on iterations, leading to unsatisfactory optimization results because of the incompatibility between VL and the current searching state of particles. To deal with this problem, a novel PSO variant with state-based adaptive velocity limit strategy (PSO-SAVL) is proposed. In the proposed PSO-SAVL, VL is adaptively adjusted based on the evolutionary state estimation (ESE) in which a high value of VL is set for global searching state and a low value of VL is set for local searching state. Besides that, limit handling strategies have been modified and adopted to improve the capability of avoiding local optima. The good performance of PSO-SAVL has been experimentally validated on a wide range of benchmark functions with 50 dimensions. The satisfactory scalability of PSO-SAVL in high-dimension and large-scale problems is also verified. Besides, the merits of the strategies in PSO-SAVL are verified in experiments. Sensitivity analysis for the relevant hyper-parameters in state-based adaptive VL strategy is conducted, and insights in how to select these hyper-parameters are also discussed.},
  archive      = {J_NEUCOM},
  author       = {Xinze Li and Kezhi Mao and Fanfan Lin and Xin Zhang},
  doi          = {10.1016/j.neucom.2021.03.077},
  journal      = {Neurocomputing},
  pages        = {64-79},
  shortjournal = {Neurocomputing},
  title        = {Particle swarm optimization with state-based adaptive velocity limit strategy},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Single image haze removal via attention-based transmission
estimation and classification fusion network. <em>NEUCOM</em>,
<em>447</em>, 48–63. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of deep learning theory, many excellent convolutional neural network (CNN) based dehazing methods have been proposed for single image dehazing. However, the slow training convergence rate and haze residual are still two serious flaws of these existing dehazing networks. To tackle these issues, we propose a novel end-to-end CNN-based dehazing framework called attention-based transmission estimation and classification fusion network (ATECFN). The ATECFN framework consists of three submodules: attention-based transmission-airlight estimation network (ATAEN), multi-scale Auto-Encoders (MAE), and patch-based classification fusion network (PCFN). First, the transmission similarity, that is the similarity of neighboring pixels in transmission map, is introduced to significantly increase the capability of CNN to fit transmission map. Second, the ATAEN is exploited to estimate airlight map and transmission map and then they are used to obtain a rough dehazed result according to the atmospheric scattering model. Third, we present the MAE to further refine the rough result, where the multi-scale structure can effectively capture local details over a wide range of scales. Finally, PCFN, a new fusion strategy, is employed to integrate the two results generated by ATAEN and MAE, in which a probability map is derived from a binary classification network and viewed as the fusion coefficient map. Extensive experiments demonstrate that the proposed algorithm outperforms the state-of-the-art methods on both synthetic and real-world images, which can not only improve the training convergence rate but also remove the residual haze effectively.},
  archive      = {J_NEUCOM},
  author       = {Shan Wang and Libao Zhang and Xiaohan Wang},
  doi          = {10.1016/j.neucom.2021.03.102},
  journal      = {Neurocomputing},
  pages        = {48-63},
  shortjournal = {Neurocomputing},
  title        = {Single image haze removal via attention-based transmission estimation and classification fusion network},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Review-based hierarchical attention cooperative neural
networks for recommendation. <em>NEUCOM</em>, <em>447</em>, 38–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In e-commerce platform, users conduct purchase behavior and write reviews for the purchased items. These reviews usually contain a lot of valuable information for recommendation, which can reflect the purchase preference of the user and the characteristic of the item. We propose the Hierarchical Attention Cooperative Neural Networks (HACN) model for recommendation. Hierarchical attention mechanism is adopted to enrich user’s and item’s feature representation from review texts. Two parallel networks based on review texts are used to model users and items respectively, which makes the generated features more purposeful. Further, the target ID embedding is introduced to capture the global entity relationship in the dataset. The experiments are performed on five real-world datasets of different domains from Amazon, and our proposed HACN model has achieved better results than the existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yongping Du and Lulin Wang and Zhi Peng and Wenyang Guo},
  doi          = {10.1016/j.neucom.2021.03.098},
  journal      = {Neurocomputing},
  pages        = {38-47},
  shortjournal = {Neurocomputing},
  title        = {Review-based hierarchical attention cooperative neural networks for recommendation},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AKRNet: A novel convolutional neural network with attentive
kernel residual learning for feature learning of gearbox vibration
signals. <em>NEUCOM</em>, <em>447</em>, 23–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vibration signals have been widely used for machine health monitoring and fault diagnosis. However, due to the complex working conditions, vibration signals collected from gearbox are generally nonlinear and non-stationary, which may contain multiple time scales and much noise. Considering these physical characteristics of vibration signals, in this paper, a novel deep neural network (DNN), attentive kernel residual network (AKRNet), is proposed for multi-scale feature learning from vibration signals. Firstly, multiple branches with different kernel widths are used to extract multi-scale features from vibration signals. Secondly, an attentive kernel selection is proposed to fuse the multiple branches features, where dynamic selection is developed to adaptively highlight the informative feature maps, while suppress the useless feature maps. Thirdly, an attentive residual block is developed to improve the feature learning performance, which not only can alleviate gradient vanishing, but also further enhances the impulsive features in feature maps. Finally, the effectiveness of AKRNet for feature learning of vibration signals is verified on two gearbox test rigs. The experimental results show that AKRNet has good capacity of feature learning on vibration signals. It performs better on gearbox fault diagnosis than other typical DNNs, e.g., stacked auto-encoders (SAE), one-dimensional CNN (1-D CNN) and residual network (ResNet).},
  archive      = {J_NEUCOM},
  author       = {Zhuang Ye and Jianbo Yu},
  doi          = {10.1016/j.neucom.2021.02.055},
  journal      = {Neurocomputing},
  pages        = {23-37},
  shortjournal = {Neurocomputing},
  title        = {AKRNet: A novel convolutional neural network with attentive kernel residual learning for feature learning of gearbox vibration signals},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TSingNet: Scale-aware and context-rich feature learning for
traffic sign detection and recognition in the wild. <em>NEUCOM</em>,
<em>447</em>, 10–22. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sign detection and recognition in the wild is a challenging task. Existing techniques are often incapable of detecting small or occluded traffic signs because of the scale variation and context loss, which causes semantic gaps between multiple scales. We propose a new traffic sign detection network (TSingNet), which learns scale-aware and context-rich features to effectively detect and recognize small and occluded traffic signs in the wild. Specifically, TSingNet first constructs an attention-driven bilateral feature pyramid network, which draws on both bottom-up and top-down subnets to dually circulate low-, mid-, and high-level foreground semantics in scale self-attention learning. This is to learn scale-aware foreground features and thus narrow down the semantic gaps between multiple scales. An adaptive receptive field fusion block with variable dilation rates is then introduced to exploit context-rich representation and suppress the influence of occlusion at each scale. TSingNet is end-to-end trainable by joint minimization of the scale-aware loss and multi-branch fusion losses, this adds a few parameters but significantly improves the detection performance. In extensive experiments with three challenging traffic sign datasets (TT100K, STSD and DFG), TSingNet outperformed state-of-the-art methods for traffic sign detection and recognition in the wild.},
  archive      = {J_NEUCOM},
  author       = {Yuanyuan Liu and Jiyao Peng and Jing-Hao Xue and Yongquan Chen and Zhang-Hua Fu},
  doi          = {10.1016/j.neucom.2021.03.049},
  journal      = {Neurocomputing},
  pages        = {10-22},
  shortjournal = {Neurocomputing},
  title        = {TSingNet: Scale-aware and context-rich feature learning for traffic sign detection and recognition in the wild},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly supervised segmentation via instance-aware
propagation. <em>NEUCOM</em>, <em>447</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peak Response Map (PRM) highlighting the discriminative regions can be extracted from a pre-trained classification network. We can accurately localize instances of each class with the help of these response maps. However, these maps cannot provide reliable information for segmentation even with off-the-shelf object proposals. This is because neither PRM nor the proposals know which regions can be regarded as a complete instance. In this paper, we tackle this problem by proposing an Instance-aware Cue-propagation Network (ICN) with a new proposal-matching strategy. In particular, the ICN aims to filter out background distractions and cover the complete instance, while our proposed proposal-matching strategy adds a re-balancing constraint on the contributions of multi-scale object proposals. Extensive experiments conducted on the PASCAL VOC 2012 dataset show the superior performance of our method over weakly-supervised state-of-the-arts for both semantic and instance segmentation .},
  archive      = {J_NEUCOM},
  author       = {Xin Huang and Qianshu Zhu and Yongtuo Liu and Shengfeng He},
  doi          = {10.1016/j.neucom.2021.02.093},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Weakly supervised segmentation via instance-aware propagation},
  volume       = {447},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LSVP: A visual based deep neural direction learning model
for point-of-interest recommendation on sparse check-in data.
<em>NEUCOM</em>, <em>446</em>, 204–210. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently accumulated massive amounts of geo-tagged photos provide an excellent opportunity to understand human behaviors and can be used for personalized POI recommendation. However, no existing work has considered both the visual contents in these photos and the sequential patterns of users’ check-ins for POI recommendation. To this end, in this paper, we propose an attentional network named LSVP for POI recommendation, which adaptively considers the joint effects of users’ long-term, short-term and visual preferences. Specifically, we first extract visual preferences from photos, then extract long-term and short-term preferences from check-in sequences. At last, an adaptive attention mechanism is used to balance all the extracted users’ preferences. Experimental results on two real-world datasets collected show that LSPV provides significantly superior performances compared to other state-of-the-art POI recommendation models in terms of accuracy.},
  archive      = {J_NEUCOM},
  author       = {Yu Sang and Huimin Sun and Chao Li and Lihua Yin},
  doi          = {10.1016/j.neucom.2020.09.087},
  journal      = {Neurocomputing},
  pages        = {204-210},
  shortjournal = {Neurocomputing},
  title        = {LSVP: A visual based deep neural direction learning model for point-of-interest recommendation on sparse check-in data},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual selection of standard wells for large scale logging
data via discrete choice model. <em>NEUCOM</em>, <em>446</em>, 192–203.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is a time-consuming and laborious task to conduct accurate geological interpretation based on large-scale logging data. A subset of drilling wells are always selected undergoing detailed stratigraphic correlation, aiming to enhance the efficiency of geological interpretation and retain the matching accuracy of stratigraphic structures. However, standard wells are selected by hand in the course of traditional standard well selection, which will easily bring many uncertainties for subsequent interpretation of geological structures. In this paper, we propose a visual analytics system to support supervised standard well selection via a discrete choice model . Firstly, an adaptive blue noise sampling model is applied to determine spatial distribution of standard wells, and a stratigraphic correlation model is designed to measure the similarity between drilling wells from different attribute perspectives. Then, we utilize a discrete choice model to select standard wells with the spatial distribution and multiple attributes taken into consideration. Furthermore, several meaningful visualizations are designed allowing users to get deeper insights into the selection of standard wells, and a rich set of interactions are also provided enabling users to further optimize the discrete choice model. At last, a visualization framework is implemented to integrate the models and visual designs, by means of which the geological interpreters are able to visually select, evaluate and optimize the standard wells. The effectiveness of our work and its application values for geological interpretation are further demonstrated through case studies based on real-world datasets and interviews with domain experts.},
  archive      = {J_NEUCOM},
  author       = {Chen Shi and Zhiguang Zhou and Miaoxin Hu and Yuhua Liu},
  doi          = {10.1016/j.neucom.2021.01.105},
  journal      = {Neurocomputing},
  pages        = {192-203},
  shortjournal = {Neurocomputing},
  title        = {Visual selection of standard wells for large scale logging data via discrete choice model},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Empirical analysis of performance bottlenecks in graph
neural network training and inference with GPUs. <em>NEUCOM</em>,
<em>446</em>, 165–191. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The graph neural network (GNN) has become a popular research area for its state-of-the-art performance in many graph analysis tasks. Recently, various graph neural network libraries have emerged. They make developing GNNs convenient, but the performance bottlenecks of GNNs on large datasets are not well studied. In this work, we analyze the performance bottlenecks in GNN training and inference with GPUs empirically. A GNN layer can be decomposed into two parts: the vertex and the edge calculation parts. We select four representative GNNs (GCN, GGNN, GAT, GaAN) for evaluation according to their computational complexity. We decompose their running time and memory usage, evaluate the effects of hyper-parameters and assess the efficiency of the sampling techniques. The experimental evaluation with PyTorch Geometric indicates that the edge-related calculation is the performance bottleneck for most GNNs, dominating the training/inference time and memory usage. The sampling techniques are essential for GNN training and inference on big graphs with GPUs, but their current implementation still has non-trivial overheads in sampling and data transferring.},
  archive      = {J_NEUCOM},
  author       = {Zhaokang Wang and Yunpan Wang and Chunfeng Yuan and Rong Gu and Yihua Huang},
  doi          = {10.1016/j.neucom.2021.03.015},
  journal      = {Neurocomputing},
  pages        = {165-191},
  shortjournal = {Neurocomputing},
  title        = {Empirical analysis of performance bottlenecks in graph neural network training and inference with GPUs},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Practical fixed-time adaptive consensus control for a class
of multi-agent systems with full state constraints and input delay.
<em>NEUCOM</em>, <em>446</em>, 156–164. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper concentrates on a fixed-time consensus issue for nonstrict nonlinear uncertain multi-agent systems (MASs) with state constraints and input delay. In comparison with previous works, the topic of full state constraints and input delay is first embodied in nonstrict MASs in a fixed time. A semi-global practical fixed-time stability (SPFTS) is employed to handle the consensus problem in this note. The radial basis function neural networks (RBFNNs) are developed to counteract unknown items in each agent. Pade approximation approach is introduced to cope with input delay. By using the backstepping technique, adaptive virtual controllers, adaption laws and the actual consensus controller are devised. And the rest followers can converge to a specified trajectory built by the leader in fixed time. Finally, a practical example is employed to test the correctness for the proposed control protocol.},
  archive      = {J_NEUCOM},
  author       = {Dajie Yao and Chunxia Dou and Nan Zhao and Tingjun Zhang},
  doi          = {10.1016/j.neucom.2021.03.032},
  journal      = {Neurocomputing},
  pages        = {156-164},
  shortjournal = {Neurocomputing},
  title        = {Practical fixed-time adaptive consensus control for a class of multi-agent systems with full state constraints and input delay},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vision-assisted recognition of stereotype behaviors for
early diagnosis of autism spectrum disorders. <em>NEUCOM</em>,
<em>446</em>, 145–155. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical diagnosis supported by computer-assisted technologies is getting more popularity and acceptance among medical society. In this paper, we propose a non-intrusive vision-assisted method based on human action recognition to facilitate the diagnosis of Autism Spectrum Disorder (ASD). We collected a novel and comprehensive video dataset f the most distinctive Stereotype actions of this disorder with the assistance of professional clinicians. Several frameworks as a function of different input modalities were developed and used to produce extensive baseline results. Various local descriptors , which are commonly used within the Bag-of-Visual-Words approach, were tested with Multi-layer Perceptron (MLP), Gaussian Naive Bayes (GNB), and Support Vector Machines (SVM) classifiers for recognizing ASD associated behaviors. Additionally, we developed a framework that first receives articulated pose-based skeleton sequences as input and follows an LSTM network to learn the temporal evolution of the poses. Finally, obtained results were compared with two fine-tuned deep neural networks: ConvLSTM and 3DCNN. The results revealed that the Histogram of Optical Flow (HOF) descriptor achieves the best results when used with MLP classifier. The promising baseline results also confirmed that an action-recognition-based system can be potentially used to assist clinicians to provide a reliable, accurate, and timely diagnosis of ASD disorder.},
  archive      = {J_NEUCOM},
  author       = {Farhood Negin and Baris Ozyer and Saeid Agahian and Sibel Kacdioglu and Gulsah Tumuklu Ozyer},
  doi          = {10.1016/j.neucom.2021.03.004},
  journal      = {Neurocomputing},
  pages        = {145-155},
  shortjournal = {Neurocomputing},
  title        = {Vision-assisted recognition of stereotype behaviors for early diagnosis of autism spectrum disorders},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive nonlinear filter for integrated navigation
systems using deep neural networks. <em>NEUCOM</em>, <em>446</em>,
130–144. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel nonlinear adaptive sensor fusion method for integrated navigation systems with varying noise parameters. The innovation is utilizing deep neural networks to mine the noise-related patterns of specific sensors and combining it with conventional nonlinear filters. This hybrid approach improves the feasibility and robustness of adaptive filtering by achieving an effective estimation of the originally weakly observable noise parameters. The specific sensors are defined as α α -type sensors whose errors are entirely generated by themselves. The mathematical model for analyzing α α -type sensors output sequence and the deep neural network for mining the patterns of interest are established. All adaptive filtering systems using α α -type sensors can benefit from this paper. Specifically, it is applied to inertial and satellite integrated navigation system. The numerical experiments indicate that the proposed filter achieves promising accuracy and robustness improvement as compared to conventional nonlinear filters. And the comparisons between different nonlinear approximation algorithms indicate that the first-order approximation is accurate enough for our application.},
  archive      = {J_NEUCOM},
  author       = {Fei Yan and Sheng Li and Enze Zhang and Jian Guo and Qingwei Chen},
  doi          = {10.1016/j.neucom.2021.03.046},
  journal      = {Neurocomputing},
  pages        = {130-144},
  shortjournal = {Neurocomputing},
  title        = {An adaptive nonlinear filter for integrated navigation systems using deep neural networks},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decoding the torque of lower limb joints from EEG recordings
of pre-gait movements using a machine learning scheme. <em>NEUCOM</em>,
<em>446</em>, 118–129. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-machine interfaces (BMIs) are useful tools for controlling assistive devices . One current approach in this field is continuous trajectory reconstruction (CTR), which decodes variables from electroencephalographic (EEG) signals. In this study, the CTR approach was applied to estimate kinetic variables from lower limb joints during pre-gait movements. The methodology consisted of a multi-layer perceptron capable of detecting patterns that represent the relation between EEG and torque signals acquired during motion tasks. The study also searched for an optimal subset of EEG channels based on the resulting patterns. A group of volunteers was recruited to execute pre-gait movements with both lower limbs to test the methodology. Results show that decodings of extracted patterns were successful in terms of the selected performance metrics; that is, the coefficient of determination, correlation coefficient, and signal-to-noise ratio. These metrics suggest that decodings for the right lower limb are better than for the left one, and that the most frequent electrodes in the optimal subsets for each task and joint show a tendency to lateralize. The results obtained suggest that this machine learning scheme could be used for future studies of the CTR of kinetic variables.},
  archive      = {J_NEUCOM},
  author       = {Luis Mercado and Lucero Alvarado and Griselda Quiroz-Compean and Rebeca Romo-Vazquez and Hugo Vélez-Pérez and M.A. Platas-Garza and Andrés A. González-Garrido and J.E. Gómez-Correa and J. Alejandro Morales and Angel Rodriguez-Liñan and Luis Torres-Treviño and José M. Azorín},
  doi          = {10.1016/j.neucom.2021.03.038},
  journal      = {Neurocomputing},
  pages        = {118-129},
  shortjournal = {Neurocomputing},
  title        = {Decoding the torque of lower limb joints from EEG recordings of pre-gait movements using a machine learning scheme},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quality-driven deep active learning method for 3D brain MRI
segmentation. <em>NEUCOM</em>, <em>446</em>, 106–117. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic segmentation of the brain Magnetic Resonance Imaging (MRI) plays a crucial role in many brain MRI processing algorithms, which is effective for the prevention, detection, monitoring, and treatment planning of brain disease. Currently, deep learning algorithms have shown outstanding performance in brain segmentation. Most algorithms train models with fully annotated brain MRI datasets. However, full annotation of 3D brain MRI is laborious and time-consuming. Using sparsely annotated datasets to train models may be one appropriate solution to reduce annotation cost. However, the approach of 3D dense segmentation with sparse annotation has not been fully studied. In this paper, we develop a segmentation framework combined with the quality-driven active learning (QDAL) module for suggestive annotation. In the proposed Active Learning module, attention mechanism and deep supervision mode are used to improve the segmentation accuracy and feedback segmentation quality information. Meanwhile, we observe a high correlation coefficient between the proposed two surrogate metrics and the real segmentation accuracy of per slice in one scan. We validate our framework on two public brain MRI datasets for brain region extraction and brain tissue segmentation. The comparative experiments demonstrate that the QDAL method outperforms the other four popular sampling strategies. The segmentation network with the guidance of the QDAL method only needs 15–20\% annotated slices in brain extraction task, and 30–40\% annotated slices in tissue segmentation task to achieve competitive results compared with training with full supervision.},
  archive      = {J_NEUCOM},
  author       = {Zhenxi Zhang and Jie Li and Chunna Tian and Zhusi Zhong and Zhicheng Jiao and Xinbo Gao},
  doi          = {10.1016/j.neucom.2021.03.050},
  journal      = {Neurocomputing},
  pages        = {106-117},
  shortjournal = {Neurocomputing},
  title        = {Quality-driven deep active learning method for 3D brain MRI segmentation},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Fine-grained predicting urban crowd flows with adaptive
spatio-temporal graph convolutional network. <em>NEUCOM</em>,
<em>446</em>, 95–105. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting crowd flows is important for traffic management and public safety, which is very challenging as it is affected by many complex factors. In this paper, we propose a novel fine-grained predicting urban crowd flows approach with an adaptive spatio-temporal graph convolutional network, called ASTGCN. This approach can simultaneously predict the inflow, outflow, and flow direction. We first design a method for modeling crowd flow in irregular urban regions based on urban bus line data. Then, we design an end-to-end structure of the adaptive spatio-temporal graph convolutional network with unique properties of spatio-temporal data. Finally, extensive experiments on GAIA open dataset are constructed to evaluate the performance of ASTGCN. Results show that our approach outperforms four well-known methods, the average absolute error is reduced by 28.7\%, and the root mean square error is reduced by 37.9\%.},
  archive      = {J_NEUCOM},
  author       = {Xu Yang and Qiang Zhu and Peihao Li and Pengpeng Chen and Qiang Niu},
  doi          = {10.1016/j.neucom.2021.02.089},
  journal      = {Neurocomputing},
  pages        = {95-105},
  shortjournal = {Neurocomputing},
  title        = {Fine-grained predicting urban crowd flows with adaptive spatio-temporal graph convolutional network},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State estimator design for genetic regulatory networks with
leakage and discrete heterogeneous delays: A nonlinear model
transformation approach. <em>NEUCOM</em>, <em>446</em>, 86–94. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We address the state estimation problem for a class of genetic regulatory networks (GRNs) with leakage and discrete heterogeneous delays in this paper. In order to simplify the complexity of designing the state estimator for nonlinear delayed model of GRNs, a state estimate algorithm based on a model transformation method is presented, which goal is to get the entire system state. First, in light of the Lagrange’s mean-value theorem, the nonlinear model transformation method is applied to describe the nonlinear error system as a linear time-varying model. Second, by constructing the Lyapunov–Krasovskii functional dependent on the composite function variables of state estimate errors, a new technique lemma is provided and applied to the stability analysis. Third, the sufficient condition of state estimator design is obtained in term linear matrix inequalities, under which, the certification of the uniform asymptotic stability for state estimate error system is derived. Finally, a simulation example illustrates the rationality and effectiveness of the proposed theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Shasha Xiao and Xin Wang and Xian Zhang and Jun-Wei Zhu and Xin Yang},
  doi          = {10.1016/j.neucom.2021.03.022},
  journal      = {Neurocomputing},
  pages        = {86-94},
  shortjournal = {Neurocomputing},
  title        = {State estimator design for genetic regulatory networks with leakage and discrete heterogeneous delays: A nonlinear model transformation approach},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Game theory based multi-task scheduling of decentralized 3D
printing services in cloud manufacturing. <em>NEUCOM</em>, <em>446</em>,
74–85. (<a href="https://doi.org/10.1016/j.neucom.2021.03.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the multi-task scheduling competitivenesss of the distributed three-dimensional (3D) printing services with different types in cloud manufacturing, a non-cooperative game model of 3D printing services is proposed to reduce completion time, cost and to improve service quality. Moreover, the non-cooperative game consists of two kinds of sub-game to work together. Some service attributes, such as moving speed of nozzle, model dimension, 3D printing precision, 3D printing material, and pricing mode, are considered in the model. In order to obtain the expected solution, a two-layer nested method based on genetic algorithm is developed to improve scheduling efficiency. An industrial case is given to verify the feasibility and effectiveness of the proposed method. The results show that it has a better performance than traditional scheduling methods.},
  archive      = {J_NEUCOM},
  author       = {Sicheng Liu and Lin Zhang and Weiling Zhang and Weiming Shen},
  doi          = {10.1016/j.neucom.2021.03.029},
  journal      = {Neurocomputing},
  pages        = {74-85},
  shortjournal = {Neurocomputing},
  title        = {Game theory based multi-task scheduling of decentralized 3D printing services in cloud manufacturing},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Zero-shot policy generation in lifelong reinforcement
learning. <em>NEUCOM</em>, <em>446</em>, 65–73. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong reinforcement learning (LRL) is an important approach to achieve continual lifelong learning of multiple reinforcement learning tasks. The two major methods used in LRL are task decomposition and policy knowledge extraction. Policy knowledge extraction method in LRL can share knowledge for tasks in different task domains and for tasks in the same task domain with different system environmental coefficients. However, the generalization ability of policy knowledge extraction method is limited on learned tasks rather than learned task domains. In this paper, we propose a cross-domain lifelong reinforcement learning algorithm with zero-shot policy generation ability (CDLRL-ZPG) to improve generalization ability of policy knowledge extraction method from learned tasks to learned task domains. In experiments, we evaluated CDLRL-ZPG performance on four task domains. And our results show that the proposed algorithm can directly generate satisfactory results without needing a trial and error learning process to achieve zero-shot learning in general.},
  archive      = {J_NEUCOM},
  author       = {Yi-Ming Qian and Fang-Zhou Xiong and Zhi-Yong Liu},
  doi          = {10.1016/j.neucom.2021.02.058},
  journal      = {Neurocomputing},
  pages        = {65-73},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot policy generation in lifelong reinforcement learning},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Global asymptotic consensus of multi-agent internet
congestion control system. <em>NEUCOM</em>, <em>446</em>, 50–64. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the Internet congestion control and consensus problems of a multi-agent system composed of a congested node, some aggregation nodes and their following nodes. First, a novel multi-agent Internet congestion control system with both discrete and distributed delays is proposed. Second, the stability and Hopf bifurcation of the congested node are discussed. Subsequently, a simple error controller designed for aggregation nodes , some necessary and sufficient conditions have been established to solve the bifurcation consensus problem between aggregating nodes and the congested node. Bifurcation consensus of aggregation nodes and their following nodes are also obtained through consensus protocols which based on a novel predictive controller. So far, the bifurcation asymptotically consensus of multi-agent Internet congestion control system is achieved. It is worth noting that conditions for global stability of system can be obtained by selecting appropriate control parameters, and conclusions of global asymptotic stability consensus is given to draw conditions for avoiding network congestion in the whole system. Finally, numerical examples illustrated the correctness and validity of the main results.},
  archive      = {J_NEUCOM},
  author       = {Yu Wang and Jinde Cao and Bin Lu and Zunshui Cheng},
  doi          = {10.1016/j.neucom.2021.02.067},
  journal      = {Neurocomputing},
  pages        = {50-64},
  shortjournal = {Neurocomputing},
  title        = {Global asymptotic consensus of multi-agent internet congestion control system.},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). ASKs: Convolution with any-shape kernels for efficient
neural networks. <em>NEUCOM</em>, <em>446</em>, 32–49. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the outstanding performance, deep convolutional neural networks (CNNs) are computationally expensive and contain a large number of redundant parameters, hindering their deployment on resource constrained platforms. To address this issue, many model compression methods have been proposed. However, these methods mainly focus on pruning redundant parameters or designing efficient architectures, the redundancy in convolution kernels has rarely been investigated. In this paper, we find that the contributions of parameters at different locations in the traditional 3 × 3 3×3 kernels are not the same, and this distribution varies considerably in different layers. Motivated by this, we propose to use irregular kernels and present a novel approach to implementing convolution with any-shape kernels (ASKs) efficiently. The proposed ASKs are plug-and-play and can be readily embedded into existing CNNs, providing efficient modules for building compact CNNs. Experiments on benchmarks demonstrate the effectiveness of the proposed method. We improve the accuracy of VGG-16 on CIFAR-10 dataset from 93.45\% to 94.04\% simply by replacing the regular 3 × 3 3×3 kernel with cross-shaped kernel, which takes up only about 5 / 9 5/9 of the original storage and computing resources. Compared to state-of-the-art model compression methods, our ASKs achieve a better trade-off between accuracy and compression ratio.},
  archive      = {J_NEUCOM},
  author       = {Guangzhe Liu and Ke Zhang and Meibo Lv},
  doi          = {10.1016/j.neucom.2021.03.039},
  journal      = {Neurocomputing},
  pages        = {32-49},
  shortjournal = {Neurocomputing},
  title        = {ASKs: Convolution with any-shape kernels for efficient neural networks},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Disturbance-observer-based adaptive NN control for a class
of MIMO discrete-time nonlinear strict-feedback systems with dead zone.
<em>NEUCOM</em>, <em>446</em>, 23–31. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, based on a disturbance observer (DO), an adaptive neural network (ANN) tracking control scheme is proposed for the multi-input and multi-output (MIMO) strict-feedback discrete-time system (SFDTS). The unknown nonlinear functions , dead-zone input and external disturbance are all considered in the studied SFDTS. Before starting to design the controller, the MIMO SFDTS is transformed into a maximum N -step ahead predictor to solve the noncausal problem. Then, the backstepping method is successfully used to design the control scheme for the new system. The unknown nonlinear functions are approximated by radial basis function neural networks. The external disturbance is estimated based on the DO, and the ANN controller is designed on the basis of the outputs of the DO. By applying the Lyapunov stability theory , all the signals in the whole closed-loop system are ensured bounded. Finally, a numerical simulation is provided to verify the validity of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Bei Wu and Mou Chen and Shuyi Shao and Luo Zhang},
  doi          = {10.1016/j.neucom.2021.02.077},
  journal      = {Neurocomputing},
  pages        = {23-31},
  shortjournal = {Neurocomputing},
  title        = {Disturbance-observer-based adaptive NN control for a class of MIMO discrete-time nonlinear strict-feedback systems with dead zone},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Edge and identity preserving network for face
super-resolution. <em>NEUCOM</em>, <em>446</em>, 11–22. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face super-resolution (SR) has become an indispensable function in security solutions such as video surveillance and identification system, but the distortion in facial components is a great challenge in it. Most state-of-the-art methods have utilized facial priors with deep neural networks. These methods require extra labels, longer training time, and larger computation memory. In this paper, we propose a novel Edge and Identity Preserving Network for Face SR Network, named as EIPNet, to minimize the distortion by utilizing a lightweight edge block and identity information. We present an edge block to extract perceptual edge information, and concatenate it to the original feature maps in multiple scales. This structure progressively provides edge information in reconstruction to aggregate local and global structural information. Moreover, we define an identity loss function to preserve identification of SR images. The identity loss function compares feature distributions between SR images and their ground truth to recover identities in SR images. In addition, we provide a luminance-chrominance error (LCE) to separately infer brightness and color information in SR images. The LCE method not only reduces the dependency of color information by dividing brightness and color components but also enables our network to reflect differences between SR images and their ground truth in two color spaces of RGB and YUV. The proposed method facilitates the proposed SR network to elaborately restore facial components and generate high quality 8 × 8× scaled SR images with a lightweight network structure. Furthermore, our network is able to reconstruct an 128 × 128 128×128 SR image with 215 fps on a GTX 1080Ti GPU. Extensive experiments demonstrate that our network qualitatively and quantitatively outperforms state-of-the-art methods on two challenging datasets: CelebA and VGGFace2.},
  archive      = {J_NEUCOM},
  author       = {Jonghyun Kim and Gen Li and Inyong Yun and Cheolkon Jung and Joongkyu Kim},
  doi          = {10.1016/j.neucom.2021.03.048},
  journal      = {Neurocomputing},
  pages        = {11-22},
  shortjournal = {Neurocomputing},
  title        = {Edge and identity preserving network for face super-resolution},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). End-to-end trainable network for degraded license plate
detection via vehicle-plate relation mining. <em>NEUCOM</em>,
<em>446</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {License plate detection is the first and essential step of the license plate recognition system and is still challenging in real applications, such as on-road scenarios. In particular, small-sized and multi-oriented license plates, mainly caused by the remote and mobile camera, are challenging to detect. We propose a novel and applicable method for degraded license plate detection via vehicle-plate relation mining in this work. The proposed method can detect the license plate in a coarse-to-fine scheme. First, we propose to estimate the plate by using the relationships between the vehicle and the license plate, which can significantly reduce the search area and precisely detect small-sized license plates. Second, we present to robustly detect the multi-oriented license plate by regressing the four corners of the license plate in the local region. The whole network is constructed in an end-to-end manner, and codes are available at https://github.com/chensonglu/LPD-end-to-end.},
  archive      = {J_NEUCOM},
  author       = {Song-Lu Chen and Shu Tian and Jia-Wei Ma and Qi Liu and Chun Yang and Feng Chen and Xu-Cheng Yin},
  doi          = {10.1016/j.neucom.2021.03.040},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {End-to-end trainable network for degraded license plate detection via vehicle-plate relation mining},
  volume       = {446},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solving the time-varying tensor square root equation by
varying-parameters finite-time zhang neural network. <em>NEUCOM</em>,
<em>445</em>, 309–325. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the time-varying (TV) tensor square root problem, which could be regarded as a generalization of both the time-invariant (TI) tensor square root and the TV/TI matrix square root problems. The existence and uniqueness of the solution to the TV tensor square root problem are discussed. A new general varying-parameters finite-time convergent Zhang neural network model (VPsFTZNN) is proposed. We use the original ZNN and the new VPsFTZNN model as software solutions to the TV tensor square root problem. The convergence results of ZNN and VPsFTZNN dynamical systems are given. We prove that the VPsFTZNN model converges in a finite-time which is shorter than the finite time convergence of existing finite-time ZNN models. Also, we show that a superior convergence can be achieved if we use the power-sigmoid or smooth power-sigmoid activation functions instead of linear activation function under certain conditions. For comparison, some other models are also introduced and used to compute the square root of TV tensors. Numerical examples for TI and TV tensor/matrix square root problems are elaborated to confirm the theoretical results and comparison results with various model further illustrate the reliability and superiority of the proposed VPsFTZNN dynamics. Representative example on the application of this model for solving TV linear equations is also given.},
  archive      = {J_NEUCOM},
  author       = {Changxin Mo and Dimitrios Gerontitis and Predrag S. Stanimirović},
  doi          = {10.1016/j.neucom.2021.03.011},
  journal      = {Neurocomputing},
  pages        = {309-325},
  shortjournal = {Neurocomputing},
  title        = {Solving the time-varying tensor square root equation by varying-parameters finite-time zhang neural network},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AST-GNN: An attention-based spatio-temporal graph neural
network for interaction-aware pedestrian trajectory prediction.
<em>NEUCOM</em>, <em>445</em>, 298–308. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting pedestrian trajectories in the future is a basic research topic in many real applications, such as video surveillance, self-driving cars, and robotic systems. There are two major challenges in this task, the complex interaction modeling among pedestrians and the unique motion pattern extraction for each pedestrian. Regarding the two challenges, an attention-based interaction-aware spatio-temporal graph neural network is proposed for predicting pedestrian trajectories. There are two components in the proposed method: spatial graph neural network for interaction modeling, and temporal graph neural network for motion feature extraction. Spatial graph neural network uses an attention mechanism to capture the spatial interactions among all the pedestrians at each time step. Meanwhile, temporal graph neural network uses an attention mechanism to capture the temporal motion pattern of each pedestrian. Finally, a time-extrapolator convolutional neural network is used in the temporal dimension of the aggregated graph features to predict the future trajectories. Experimental results on two benchmark pedestrian trajectory prediction datasets demonstrate the competitive performances of the proposed method in terms of both the final displace error and the average displacement error metrics as compared with state-of-the-art trajectory prediction methods.},
  archive      = {J_NEUCOM},
  author       = {Hao Zhou and Dongchun Ren and Huaxia Xia and Mingyu Fan and Xu Yang and Hai Huang},
  doi          = {10.1016/j.neucom.2021.03.024},
  journal      = {Neurocomputing},
  pages        = {298-308},
  shortjournal = {Neurocomputing},
  title        = {AST-GNN: An attention-based spatio-temporal graph neural network for interaction-aware pedestrian trajectory prediction},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving speech recognition models with small samples for
air traffic control systems. <em>NEUCOM</em>, <em>445</em>, 287–297. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of air traffic control (ATC) systems, efforts to train a practical automatic speech recognition (ASR) model always faces the problem of small training samples since the collection and annotation of speech samples are expert- and domain-dependent task. In this work, a novel training approach based on pretraining and transfer learning is proposed to address this issue, and an improved end-to-end deep learning model is developed to address the specific challenges of ASR in the ATC domain. An unsupervised pretraining strategy is first proposed to learn speech representations from unlabeled samples for a certain dataset. Specifically, a masking strategy is applied to improve the diversity of the sample without losing their general patterns. Subsequently, transfer learning is applied to fine-tune a pretrained or other optimized baseline models to finally achieves the supervised ASR task. By virtue of the common terminology used in the ATC domain, the transfer learning task can be regarded as a sub-domain adaption task, in which the transferred model is optimized using a joint corpus consisting of baseline samples and new transcribed samples from the target dataset. This joint corpus construction strategy enriches the size and diversity of the training samples, which is important for addressing the issue of the small transcribed corpus. In addition, speed perturbation is applied to augment the new transcribed samples to further improve the quality of the speech corpus . Three real ATC datasets are used to validate the proposed ASR model and training strategies. The experimental results demonstrate that the ASR performance is significantly improved on all three datasets, with an absolute character error rate only one-third of that achieved through the supervised training. The applicability of the proposed strategies to other ASR approaches is also validated.},
  archive      = {J_NEUCOM},
  author       = {Yi Lin and Qin Li and Bo Yang and Zhen Yan and Huachun Tan and Zhengmao Chen},
  doi          = {10.1016/j.neucom.2020.08.092},
  journal      = {Neurocomputing},
  pages        = {287-297},
  shortjournal = {Neurocomputing},
  title        = {Improving speech recognition models with small samples for air traffic control systems},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quantum probability-inspired graph neural network for
document representation and classification. <em>NEUCOM</em>,
<em>445</em>, 276–286. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have found that text can be represented in Hilbert space through a neural network driven by quantum probability, which provides a unified representation of texts with different granularities without losing the performance of downstream tasks. However, these quantum probability-inspired methods only focus on intra-document semantics and lack modeling global structural information. In this paper, we explore the potential of combining quantum probability with graph neural network , and propose a quantum probability-inspired graph neural network model to capture global structural information of interaction between documents for document representation and classification. We build a document interaction graph for a given corpus based on document word relation and frequency information, then learn a graph neural network driven by quantum probability on the defined graph. First, the proposed model represents each document node in the graph as a superposition state in a Hilbert space . Then the proposed model further computes density matrix representations for nodes to encode document interaction as mixed states. Finally, the model computes classification probability by performing quantum measurement on the mixed states. Experiments on four document classification benchmarks show that the proposed model outperforms a variety of classical neural network models and the previous quantum probability-inspired model with much smaller parameter size. Extended analyses also demonstrate the robustness of the proposed model with limited training data and its ability to learn semantically distinguishable document representation.},
  archive      = {J_NEUCOM},
  author       = {Peng Yan and Linjing Li and Miaotianzi Jin and Daniel Zeng},
  doi          = {10.1016/j.neucom.2021.02.060},
  journal      = {Neurocomputing},
  pages        = {276-286},
  shortjournal = {Neurocomputing},
  title        = {Quantum probability-inspired graph neural network for document representation and classification},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). From context-aware to knowledge-aware: Boosting OOV tokens
recognition in slot tagging with background knowledge. <em>NEUCOM</em>,
<em>445</em>, 267–275. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural-based context-aware models for slot tagging tasks in language understanding have achieved state-of-the-art performance, especially deep contextualized models, such as ELMo, BERT . However, the presence of out-of-vocab (OOV) words significantly degrades the performance of neural-based models, especially in a few-shot scenario. In this paper, we propose a novel knowledge-aware slot tagging model to integrate contextual representation of input text and the large-scale lexical background knowledge. Besides, we use multi-level graph attention to explicitly reason via lexical relations. We aim to leverage both linguistic regularities covered by deep language models (LM) and high-quality background knowledge derived from curated knowledge bases (KB). Consequently, our model could infer rare and unseen words in the test dataset by incorporating contextual semantics learned from the training dataset and lexical relations from ontology. The experiments show that our proposed knowledge integration mechanism achieves consistent improvements across settings with different sizes of training data on two public benchmark datasets. We also show through detailed analysis that incorporating background knowledge effectively alleviates issues of data scarcity.},
  archive      = {J_NEUCOM},
  author       = {Keqing He and Yuanmeng Yan and Weiran Xu},
  doi          = {10.1016/j.neucom.2021.01.134},
  journal      = {Neurocomputing},
  pages        = {267-275},
  shortjournal = {Neurocomputing},
  title        = {From context-aware to knowledge-aware: Boosting OOV tokens recognition in slot tagging with background knowledge},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Personalized image observation behavior learning in fixation
based personalized salient object segmentation. <em>NEUCOM</em>,
<em>445</em>, 255–266. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fixation as representation of one viewer’s attention are very intuitive to reflect the viewer’s observation procedure. The viewer’s observation behavior can be further revealed by analyzing fixations features. In this paper, we propose a fixation based personalized salient object segmentation method involving personal observation behavior learning. Concretely, we design three neural networks and deploy a meta-learning method. The first network is a base segmentation network that can be converted into a meta-segmentation network by meta-learning. The meta- segmentation network can learn one viewer’s observation behavior from only one sample and then generates the viewer’s segmentation network to segment the other samples. Moreover, a fusion network plays an important role in alleviating an unsuitable transmission problem and generating a final segmentation result. The experimental results demonstrate the reasonability of our observation behavior learning and the effectiveness of the three proposed neural networks .},
  archive      = {J_NEUCOM},
  author       = {Ran Shi and Gongyang Li and Weijie Wei and Xiaofei Zhou and Zhi Liu},
  doi          = {10.1016/j.neucom.2021.03.042},
  journal      = {Neurocomputing},
  pages        = {255-266},
  shortjournal = {Neurocomputing},
  title        = {Personalized image observation behavior learning in fixation based personalized salient object segmentation},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contrastive and consistent feature learning for weakly
supervised object localization and semantic segmentation.
<em>NEUCOM</em>, <em>445</em>, 244–254. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised learning attempts to construct predictive models by learning with weak supervision. In this paper, we concentrate on weakly supervised object localization and semantic segmentation tasks. Existing methods are limited to focusing on narrow discriminative parts or overextending the activations to less discriminative regions even on backgrounds. To mitigate these problems, we regard the background as an important cue that guides the feature activation to cover the entire object to the right extent, and propose two novel objective functions: 1) contrastive attention loss and 2) foreground consistency loss. Contrastive attention loss draws the foreground feature and its dropped version close together and pushes the dropped foreground feature away from the background feature. Foreground consistency loss favors agreement between layers and provides early layers with a sense of objectness. Using both losses leads to balanced improvements over localization and segmentation accuracy by boosting activations on less discriminative regions but restraining the activation in the target object extent. For better optimizing the above losses, we use the non-local attention blocks to replace channel-pooled attention leading to enhanced attention maps considering the spatial similarity. Finally, our method achieves state-of-the-art localization performance on CUB-200-2011, ImageNet, and OpenImages benchmarks regarding top-1 localization accuracy , MaxBoxAccV2 , and PxAP . We also demonstrate the effectiveness of our method in improving segmentation performance measured by mIoU on the PASCAL VOC dataset.},
  archive      = {J_NEUCOM},
  author       = {Minsong Ki and Youngjung Uh and Wonyoung Lee and Hyeran Byun},
  doi          = {10.1016/j.neucom.2021.03.023},
  journal      = {Neurocomputing},
  pages        = {244-254},
  shortjournal = {Neurocomputing},
  title        = {Contrastive and consistent feature learning for weakly supervised object localization and semantic segmentation},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast hierarchical tucker decomposition with single-mode
preservation and tensor subspace analysis for feature extraction from
augmented multimodal data. <em>NEUCOM</em>, <em>445</em>, 231–243. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tensor decomposition is a valuable and robust method for multilinear feature extraction and the dimensionality reduction of multiway data with a wide range of applications. Various tensor network (TN) models have been developed to extract features, and to relax the dimensionality and storage complexity of highly dimensional data. In this study, we extend the family of TNs and propose the hierarchical Tucker decomposition model with single-mode preservation (HTDMP). Various tensor augmentation strategies are suggested to enrich existing data information. These strategies are applied in combination with the HTDMP and multimodal tensor subspace analysis for image classification . The numerical experiments conducted confirm that the proposed method can outperform well-known tensor decomposition algorithms.},
  archive      = {J_NEUCOM},
  author       = {Krzysztof Fonał and Rafał Zdunek},
  doi          = {10.1016/j.neucom.2021.02.087},
  journal      = {Neurocomputing},
  pages        = {231-243},
  shortjournal = {Neurocomputing},
  title        = {Fast hierarchical tucker decomposition with single-mode preservation and tensor subspace analysis for feature extraction from augmented multimodal data},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential stabilization for fractional intermittent
controlled multi-group models with dispersal. <em>NEUCOM</em>,
<em>445</em>, 220–230. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-group models have attracted considerable attention due to their promising potential applications in various fields. In this paper, aperiodically intermittent control is designed to study the exponential stability of fractional-order multi-group models with dispersal. By applying Lyapunov method and graph theory, some sufficient conditions about exponential stability are established. From the theoretical results, we observe that the convergence speed depends on the control gain and the order of fractional derivative. Moreover, to show the practicality of theoretical results, we provide an application of modified fractional-order competitive neural networks . A stability criterion is also given to guarantee the exponential stability of modified fractional-order competitive neural networks . Finally, a numerical example is provided to show the effectiveness of the stated results. Some simulation comparisons are also carried out to illustrate the relationship between the convergence speed and the control gain with the order of fractional derivative.},
  archive      = {J_NEUCOM},
  author       = {Yao Xu and Teng Lin and Jiqiang Feng},
  doi          = {10.1016/j.neucom.2021.02.063},
  journal      = {Neurocomputing},
  pages        = {220-230},
  shortjournal = {Neurocomputing},
  title        = {Exponential stabilization for fractional intermittent controlled multi-group models with dispersal},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A joint learning model for click-through prediction in
display advertising. <em>NEUCOM</em>, <em>445</em>, 206–219. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Click-through rate (CTR) prediction is essential for targeted advertising and recommendation. At present, machine learning models are widely used to build CTR estimators, including logistic regression (LR), factorization machine (FM), and deep neural network (DNN). Unfortunately, these models adopt the single structure that only considers either low-order feature interactions (such as LR and FM) or high-order feature interactions (such as DNN), not sufficient for CTR prediction. Therefore, the joint learning models are proposed, such as Wide &amp; Deep and DeepFM, which can exploit both high- and low-order feature interactions to predict CTR by combining two different models. In this paper, we first analyze the typical CTR prediction models’ structures and performance, and then summarize the general form and design rules of CTR estimators. Based on the general form, we further design a new joint learning model that combines two different residual networks to explore the feature interactions automatically. Compared with the widely adopted feed-forward neural network , the residual network is more capable of exploring complex feature interactions at different layers. Additionally, we introduce a neural attention network to learn the importance of each second-order interaction of features from various fields. Finally, we evaluate the prediction performance of the proposed model based on two real-world datasets (i.e., Criteo and Avazu) in terms of LogLoss and AUC metrics. The extensive experimental results demonstrate our model performs the best compared to the state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Mengjuan Liu and Shijia Cai and Zhi Lai and Lizhou Qiu and Zhengning Hu and Yi Ding},
  doi          = {10.1016/j.neucom.2021.02.036},
  journal      = {Neurocomputing},
  pages        = {206-219},
  shortjournal = {Neurocomputing},
  title        = {A joint learning model for click-through prediction in display advertising},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Crowd emotion evaluation based on fuzzy inference of
arousal and valence. <em>NEUCOM</em>, <em>445</em>, 194–205. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd behavior analysis is an important research topic in the field of video surveillance and public safety management. Crowd emotion has a strong relation with the crowd behavior. However, it is very challenging to predict crowd emotion using conventional emotion clues of humans from the video surveillance data, e.g. facial expression or body gesture. To tackle this challenge, this paper presents a crowd emotion evaluation method using fuzzy inference according to the arousal-valence model of the crowd movement. Specifically, the enthalpy, magnitude variance, confusion index and crowd density are extracted to describe crowd emotion. The enthalpy value and magnitude variance are taken as the input of the fuzzy inference system of arousal. And the confusion index and crowd density are used as the input of the fuzzy system of valence. The arousal value and valence value are the output respectively. Through establishing the relationship between arousal, valence and crowd features, the fuzzy rules are constructed to infer the emotion in the crowd scene. Experimental results show that the proposed method can effectively evaluate the arousal and valence in crowd emotion.},
  archive      = {J_NEUCOM},
  author       = {Xuguang Zhang and Xiuxin Yang and Weiguang Zhang and Gongfa Li and Hui Yu},
  doi          = {10.1016/j.neucom.2021.02.047},
  journal      = {Neurocomputing},
  pages        = {194-205},
  shortjournal = {Neurocomputing},
  title        = {Crowd emotion evaluation based on fuzzy inference of arousal and valence},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Asymptotical synchronization analysis of fractional-order
complex neural networks with non-delayed and delayed couplings.
<em>NEUCOM</em>, <em>445</em>, 180–193. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the asymptotical synchronization of fractional-order complex neural networks with non-delayed and delayed couplings is investigated. By employing the Kronecker product technique and weighted norm, two Lyapunov functions are constructed. Based on the fractional-order Lyapunov direct method and Kronecker product method, together with the Laplace transform and the comparison principle, several novel sufficient conditions on synchronization of fractional-order complex neural networks with non-delayed and delayed couplings, respectively, are proposed. Finally, three numerical examples are given to show the effectiveness of our proposed theoretical results and the difference between our main result and some existing results in the literature.},
  archive      = {J_NEUCOM},
  author       = {Li Li and Xinge Liu and Meilan Tang and Shuailei Zhang and Xian-Ming Zhang},
  doi          = {10.1016/j.neucom.2021.03.001},
  journal      = {Neurocomputing},
  pages        = {180-193},
  shortjournal = {Neurocomputing},
  title        = {Asymptotical synchronization analysis of fractional-order complex neural networks with non-delayed and delayed couplings},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Match matrix aggregation enhanced transition-based neural
network for SQL parsing. <em>NEUCOM</em>, <em>445</em>, 167–179. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays many neural networks have been widely employed for semantic parsing problems especially for Structured Query Language (SQL) parsing , which aims at transforming natural language sentences into SQL representations. Selecting proper table headers in SQL tasks is extremely important, and the main cause of performance drop is that attention mechanism in neural models sometimes obtains wrong word-level distribution over headers. In order to obtain better header selection, we propose a match matrix aggregation enhanced SQL parser to consider the outer character-level ROUGE-L match information between the question and headers, then dynamically combine it with the inner generated attention matrix. We also introduce customized BERT and extra semantic information of the question and headers to further improve the performance. The results on two SQL datasets demonstrate that our method achieves an inspiring performance and highly outperforms other state-of-the-art alternatives.},
  archive      = {J_NEUCOM},
  author       = {Dongdong Xie and Donghong Ji and Hao Tang and Qiji Zhou},
  doi          = {10.1016/j.neucom.2021.03.005},
  journal      = {Neurocomputing},
  pages        = {167-179},
  shortjournal = {Neurocomputing},
  title        = {Match matrix aggregation enhanced transition-based neural network for SQL parsing},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A case study on computer-aided diagnosis of nonerosive
reflux disease using deep learning techniques. <em>NEUCOM</em>,
<em>445</em>, 149–166. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to develop deep-learning-based algorithms to automatically diagnose the nonerosive reflux disease (NERD) using the near focus narrow band imaging (NF-NBI) images, which are collected by clinicians of King’s College Hospital. To diagnose this disease, we propose a deep learning classification system to distinguish the NF-NBI images captured in the esophagus of healthy people and the NERD patients, which is a binary classification of two classes: non-NERD and NERD. To achieve an effective and accurate classification, we first propose an algorithm to automatically extract the region of interest (ROI) from the NF-NBI images and then generate image patches through a patch-generating algorithm. After that, we train six representative state-of-the-art deep convolutional neural network (CNN) models (ResNet18, ResNet50 , ResNet101, DenseNet201, InceptionV3, and Inception-ResNetV2) to extract robust hierarchical features from these patches and classify them based on the hierarchical features. Finally, to determine the classification results of each subject, majority voting is employed to the corresponding generated NF-NBI image patches. We verify our classification system by ten-fold cross-validation using the clinical dataset. We perform subject-dependent and subject-independent experiments. In both experiments, we compare the classification performance of the ROI-based CNN models (the CNN models with our proposed ROI-based algorithms) with the CNN models. Meanwhile, we compare the classification performance of the ROI-based CNN models with the local binary pattern (LBP)-based support vector machine (SVM) classifier, the histograms of oriented gradients (HOG)-based SVM classifier, and the scale-invariant feature transform (SIFT)-based SVM classifier. The results show that the ROI-based CNN models are able to obtain higher average mean of ten-fold test accuracy on image level than the CNN models in the subject-dependent experiment (29.0\% improvement) and the subject-independent experiment (10.5\% improvement), which demonstrate the effectiveness of our proposed ROI-based algorithms. Meanwhile, the ROI-based CNN models are able to obtain higher average mean of ten-fold test accuracy on image level than the SVM classifiers in the subject-dependent experiment (20.5\% improvement) and the subject-independent experiment (14.0\% improvement), which demonstrate the ROI-based CNN models have better classification performance than the SVM classifiers. Among the ROI-based CNN models, the ROI-based InceptionV3 model achieves the best classification performance in the subject-dependent experiment, while the ROI-based Inception-ResNetV2 model achieves the best classification performance in the subject-independent experiment, which suggests the ROI-based Inception-ResNetV2 model has better generalization ability than the ROI-based InceptionV3 model. Moreover, the highest mean of ten-fold test accuracy (77.8\%) on subject level obtained by using the ROI-based InceptionV3 model or the ROI-based Inception-ResNetV2 model demonstrates the practicality of our proposed classification system for assisting clinical diagnosis of the NERD.},
  archive      = {J_NEUCOM},
  author       = {Junkai Liao and Hak-Keung Lam and Guangyu Jia and Shraddha Gulati and Julius Bernth and Dmytro Poliyivets and Yujia Xu and Hongbin Liu and Bu Hayee},
  doi          = {10.1016/j.neucom.2021.02.049},
  journal      = {Neurocomputing},
  pages        = {149-166},
  shortjournal = {Neurocomputing},
  title        = {A case study on computer-aided diagnosis of nonerosive reflux disease using deep learning techniques},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reservoir computing dissection and visualization based on
directed network embedding. <em>NEUCOM</em>, <em>445</em>, 134–148. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The reservoir computing (RC) has recently gained considerable attention in practice and many methods have been developed to study its internal mechanism. However, the specific role played by the reservoir nodes of RC in time series prediction is still to be defined. An interpretable RC model wherein its reservoir network is designated as the directed acyclic network (DAN) is proposed with focus on time series prediction in this paper. In virtue of asymmetric transitivity and hierarchical structure of DAN, we present a directed network embedding method to identify the latent memory property of each node in the DAN. Such memory property is utilized to characterize the roles played by the reservoir nodes on the prediction performance of the RC. Meanwhile, it can also be leveraged to identify the corresponding memory community of DAN. As a result, we demonstrate how the reservoir network structure takes effect on the prediction performance from the perspective of memory community. In addition, two novel hyperparameters with the deterministic meaning are introduced to quantify the influence of the model initialization on the reservoir input so as to facilitate further dissection of the interpretable RC. The experimental results indicate that tuning these hyperparameters, which is explicable in terms of the Taylor expansion of the activation function , serves as an essential step in achieving superior prediction performance. Finally, comparative experiments with some other RC models on various time series benchmarks are also conducted.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Han and Yi Zhao},
  doi          = {10.1016/j.neucom.2021.02.029},
  journal      = {Neurocomputing},
  pages        = {134-148},
  shortjournal = {Neurocomputing},
  title        = {Reservoir computing dissection and visualization based on directed network embedding},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A comparative study of language transformers for video
question answering. <em>NEUCOM</em>, <em>445</em>, 121–133. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the goal of correctly answering questions about images or videos, visual question answering (VQA) has quickly developed in recent years. However, current VQA systems mainly focus on answering questions about a single image and face many challenges in answering video-based questions. VQA in video not only has to understand the evolution between video frames but also requires a certain understanding of corresponding subtitles. In this paper, we propose a language Transformer-based video question answering model to encode the complex semantics from video clips. Different from previous models which represent visual features by recurrent neural networks , our model encodes visual concept sequences with a pre-trained language Transformer. We investigate the performance of our model using four language Transformers over two different datasets. The results demonstrate outstanding improvements compared to previous work.},
  archive      = {J_NEUCOM},
  author       = {Zekun Yang and Noa Garcia and Chenhui Chu and Mayu Otani and Yuta Nakashima and Haruo Takemura},
  doi          = {10.1016/j.neucom.2021.02.092},
  journal      = {Neurocomputing},
  pages        = {121-133},
  shortjournal = {Neurocomputing},
  title        = {A comparative study of language transformers for video question answering},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability analysis of nontrivial stationary solution and
constant equilibrium point of reaction–diffusion neural networks with
time delays under dirichlet zero boundary value. <em>NEUCOM</em>,
<em>445</em>, 105–120. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, Lyapunov-Razumikhin technique, design of state-dependent switching laws, a fixed point theorem and variational methods are employed to derive the existence and the unique existence results of globally exponentially stable (positive) stationary solution of delayed reaction–diffusion cell neural networks under Dirichlet zero boundary value, including the global stability criteria in the classical meaning . Next, sufficient conditions are proposed to guarantee the global stability invariance of ordinary differential systems under the influence of diffusions. New theorems show that the diffusion is a double-edged sword in judging the stability of diffusion systems. Besides, an example is constructed to illuminate that any non-zero constant equilibrium point must be not in the phase plane of dynamic system under Dirichlet zero boundary value, or it must lead to a contradiction. Next, under Lipschitz assumptions on active function, another example is designed to prove that the small diffusion effect will cause the essential change of the phase plane structure of the dynamic behavior of the delayed neural networks via a Saddle point theorem. Finally, a numerical example illustrates the feasibility of the proposed methods. It is worth mentioning that some interesting mathematical problems are originally put forward in the last chapter.},
  archive      = {J_NEUCOM},
  author       = {Ruofeng Rao and Jialin Huang and Xiaodi Li},
  doi          = {10.1016/j.neucom.2021.02.064},
  journal      = {Neurocomputing},
  pages        = {105-120},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of nontrivial stationary solution and constant equilibrium point of reaction–diffusion neural networks with time delays under dirichlet zero boundary value},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AttM-CNN: Attention and metric learning based CNN for
pornography, age and child sexual abuse (CSA) detection in images.
<em>NEUCOM</em>, <em>445</em>, 81–104. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, the growing number of cases of possession and distribution of Child Sexual Abuse (CSA) material pose a significant challenge for Law Enforcement Agencies (LEAs). In this paper, we decompose the automatic CSA detection problem into two simpler ones for which it is feasible to create massive labeled datasets, especially to train deep neural networks: (i) pornographic content detection and (ii) age-group classification of a person as a minor or an adult. We propose a deep CNN architecture with a novel attention mechanism and metric learning, denoted as AttM-CNN, for these tasks. Furthermore, the pornography detection and the age-group classification networks are combined for CSA detection using two different strategies: decision level fusion for binary CSA classification and score level fusion for the re-arrangement of the suspicious images. We also introduce two new datasets: (i) Pornographic-2M, which contains two million pornographic images, and (ii) Juvenile-80k, including 80k manually labeled images with apparent facial age. The experiments conducted for age-group and pornographic classification demonstrate that our approach obtained similar or superior results compared to the state-of-the-art systems on various benchmark datasets for both tasks, respectively. For the evaluation of CSA detection, we created a test dataset comprising one million adult porn, one million non-porn images, and 5 , 000 5,000 real CSA images provided to us by Police Forces. For binary CSA classification, our method obtained an accuracy of 92.72\% 92.72\% , which increases the recognition rate by more than 21\% 21\% compared to a well-known forensic tool, i.e. NuDetective. Furthermore, re-arrangement of the CSA test dataset images showed that 80\% 80\% of CSA images can be found in the top 8.5\% 8.5\% of images in the ranked list created using our approach.},
  archive      = {J_NEUCOM},
  author       = {Abhishek Gangwar and Víctor González-Castro and Enrique Alegre and Eduardo Fidalgo},
  doi          = {10.1016/j.neucom.2021.02.056},
  journal      = {Neurocomputing},
  pages        = {81-104},
  shortjournal = {Neurocomputing},
  title        = {AttM-CNN: Attention and metric learning based CNN for pornography, age and child sexual abuse (CSA) detection in images},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerated masked transformer for dense video captioning.
<em>NEUCOM</em>, <em>445</em>, 72–80. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dense video captioning aims to generate dense descriptions for all possible events in an untrimmed video. The task is challenging that it requires accurately localizing events in the video and simultaneously describe each event with a sentence. Current approaches usually decompose this task into two independent stages—the proposal localization stage and the caption generation stage, resulting in a suboptimal solution. Masked Transformer (MT) model [30] has been proposed to integrate the two stages and optimize them in an end-to-end philosophy. Despite the superior performance that the MT has achieved, its runtime efficiency is unsatisfactory which severely limits its applicability in real-world scenarios. In this paper, we devise an improved Accelerated Masked Transformer (AMT) model that enjoys the dual-benefit of effectiveness and efficiency. Taking MT as our reference model, we respectively introduce accelerating strategies to the two stages: 1) in the proposal localization stage, we introduce a lightweight anchor-free proposal in company with a local attention mechanism ; and 2) in the caption generation stage, we introduce the single-shot feature masking strategy along with an average attention mechanism . Extensive experiments on two benchmark datasets ActivityNet-Caption and YouCookII demonstrate that AMT achieves competitive performance on both datasets with significant speed improvement. On the ActivityNet-Caption dataset, AMT reduces up to 2 × × running time with comparable performance when compared to the reference MT model.},
  archive      = {J_NEUCOM},
  author       = {Zhou Yu and Nanjia Han},
  doi          = {10.1016/j.neucom.2021.03.026},
  journal      = {Neurocomputing},
  pages        = {72-80},
  shortjournal = {Neurocomputing},
  title        = {Accelerated masked transformer for dense video captioning},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Binary thresholding defense against adversarial attacks.
<em>NEUCOM</em>, <em>445</em>, 61–71. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks are always vulnerable to adversarial attacks . In recent research, Projected Gradient Descent (PGD) has been recognized as the most effective attack method, and adversarial training on adversarial examples generated by PGD attack is the most reliable defense method. However, adversarial training requires a large amount of computation time. In this paper, we propose a fast, simple and strong defense method that achieves the best speed-accuracy trade-off. We first compare the feature maps of naturally trained model with adversarially trained model in same architecture, then we find the key of adversarially trained model lies on the binary thresholding the convolutional layers perform. Inspired by this, we perform binary thresholding to preprocess the input image and defend against PGD attack. On MNIST, our defense achieves 99.0\% accuracy on clean images and 91.2\% on white-box adversarial images. This performance is slightly better than adversarial training, and our method largely saves the computation time for retraining. On Fashion-MNIST and CIFAR-10, we train a new model on binarized images and use this model to defend against attack. Though its performance is not as good as adversarial training, it gains the best speed-accuracy trade-off.},
  archive      = {J_NEUCOM},
  author       = {Yutong Wang and Wenwen Zhang and Tianyu Shen and Hui Yu and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2021.03.036},
  journal      = {Neurocomputing},
  pages        = {61-71},
  shortjournal = {Neurocomputing},
  title        = {Binary thresholding defense against adversarial attacks},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Second-order encoding networks for semantic segmentation.
<em>NEUCOM</em>, <em>445</em>, 50–60. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently most of the state-of-the-art semantic segmentation methods have focused on context modeling for more accurate prediction. As real-world images often contain multiple objects and stuff, image features may have complex and multi-modal distributions. However, existing methods do not fully consider sch complex distributions, having limited capability for context modeling. Towards addressing this problem, this paper proposes a second-order encoding network (SoENet) trainable end-to-end for harvesting complex contextual knowledge. At the core of SoENet is an encoding module which can capture second-order statistics in individual feature subspaces. Specifically, we divide the entire feature space into a set of subspaces (clusters) represented by codewords, in each of which a covariance matrix is computed for second-order statistical modeling. The covariance matrices of all subspaces are concatenated to form a 3D tensor, which is then subject to convolutions and nonlinear activations and finally used for scaling of input features. In this way, we can encode the context which involves the complex distribution into learning process in an end-to-end manner. The proposed SoENet is evaluated on four commonly used challenging benchmarks, i.e., PASCAL Context, PASCAL VOC 2012, ADE20K and Cityscapes. The experiments show that our network significantly outperforms its counterparts and is competitive compared to state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Qiule Sun and Zhimin Zhang and Peihua Li},
  doi          = {10.1016/j.neucom.2021.03.003},
  journal      = {Neurocomputing},
  pages        = {50-60},
  shortjournal = {Neurocomputing},
  title        = {Second-order encoding networks for semantic segmentation},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep saliency detection via spatial-wise dilated
convolutional attention. <em>NEUCOM</em>, <em>445</em>, 35–49. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saliency detection aims to highlight the area which significantly attracts human attention and stands out in an image. In recent years, deep learning-based saliency detection has achieved fantastic performance over conventional works while still facing huge challenges in multi-features fusion and the enlargement of the receptive field. Current top-performing saliency detectors on the basis of FCNs benefit from their powerful feature representations but suffer from high computational costs due to the integration of multi-scale features without distinction. So in this paper, we propose a novel and simple network, the DCAM, based on attention mechanism with dilated convolutions (DAM), incorporating multi-scale features with enlarged receptive field. Specifically, we apply DAM to guide each side output respectively which selectively emphasizes the significant regions, thus efficiently enhancing the representation ability of each layer. Our spatial attention module helps us looking for areas in the image that have a greater impact and give them a higher weight.Besides, we adopt FPN to integrate features adjacent to each other layer and a CRF scheme for refining saliency results. Experiments on five benchmark datasets demonstrate that the proposed approach performs favorably against five state-of-the-art methods with a fast speed (56 FPS on a single GPU).},
  archive      = {J_NEUCOM},
  author       = {Wenzhao Cui and Qing Zhang and Baochuan Zuo},
  doi          = {10.1016/j.neucom.2021.02.061},
  journal      = {Neurocomputing},
  pages        = {35-49},
  shortjournal = {Neurocomputing},
  title        = {Deep saliency detection via spatial-wise dilated convolutional attention},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimized adaptive PReLU-DBN for rolling element bearing
fault diagnosis. <em>NEUCOM</em>, <em>445</em>, 26–34. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rolling element bearings are critical components in industrial rotating machines. Faults and failures of bearings can cause degradation of machine performance or even a catastrophe. Therefore, it is significant to perform bearing fault diagnosis accurately and effectively. Deep Learning based approaches are promising for bearing diagnosis. They can extract fault information efficiently and conduct accurate diagnosis. However, the structure of deep learning networks is often determined by trial and error, which is time consuming and lacks theoretical guidance. Besides, the traditional deep learning approaches have low diagnosis accuracy and learning efficiency. To address these problems, this paper proposes a rolling element bearing fault diagnosis approach based on principal component analysis and adaptive deep belief network with Parametric Rectified Linear Unit activation layers. In the proposed approach, particle swarm optimization is integrated to obtain an optimal DBN structure with high accuracy and convergence rate. Experiments on tapered roller bearings and comparison studies with state-of-the-art methods are conducted to demonstrate the effectiveness and accuracy of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Guangxing Niu and Xuan Wang and Michael Golda and Stephen Mastro and Bin Zhang},
  doi          = {10.1016/j.neucom.2021.02.078},
  journal      = {Neurocomputing},
  pages        = {26-34},
  shortjournal = {Neurocomputing},
  title        = {An optimized adaptive PReLU-DBN for rolling element bearing fault diagnosis},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-view spectral graph convolution with consistent edge
attention for molecular modeling. <em>NEUCOM</em>, <em>445</em>, 12–25.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although graph convolutional networks (GCNs) that extend the convolution operation from images to graphs have led to competitive performance, the existing GCNs are still difficult to handle a variety of applications, especially cheminformatics problems. Recently multiple GCNs are applied to chemical compound structures which are represented by the hydrogen-depleted molecular graphs of different size. GCNs built for a binary adjacency matrix that reflects the connectivity among nodes in a graph do not account for the edge consistency in multiple molecular graphs, that is, chemical bonds (edges) in different molecular graphs can be similar due to the similar enthalpy and interatomic distance. In this paper, we propose a variant of GCN where a molecular graph is first decomposed into multiple views of the graph, each comprising a specific type of edges. In each view, an edge consistency constraint is enforced so that similar edges in different graphs can receive similar attention weights when passing information. Similarly to prior work, we prove that in each layer, our method corresponds to a spectral filter derived by the first order Chebyshev approximation of graph Laplacian. Extensive experiments demonstrate the substantial advantages of the proposed technique in quantitative structure-activity relationship prediction.},
  archive      = {J_NEUCOM},
  author       = {Chao Shang and Qinqing Liu and Qianqian Tong and Jiangwen Sun and Minghu Song and Jinbo Bi},
  doi          = {10.1016/j.neucom.2021.02.025},
  journal      = {Neurocomputing},
  pages        = {12-25},
  shortjournal = {Neurocomputing},
  title        = {Multi-view spectral graph convolution with consistent edge attention for molecular modeling},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online optimal learning algorithm for stackelberg games with
partially unknown dynamics and constrained inputs. <em>NEUCOM</em>,
<em>445</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an online integral reinforcement learning (IRL) algorithm to solve the Stackelberg games with partially unknown dynamics and input constraints. A general function form of penalizing the control with considering the saturating bounds is introduced into the cost function. Hence, difficulty to deal with the input constraints is handled effectively. The core of solving the Stackelberg games is that one needs to find the two-level optimal control problem that the leader optimizes their cost function subject to the followers decision as estimated by the leader. The problem is converted into the coupled Hamilton–Jacobi (HJ) equations with the constraints of the follower’s costate equation. A novel IRL algorithm is designed to learn the solution to the coupled HJ equation with unknown internal dynamical information. A single critic NN structure for each player is utilized to implement the proposed algorithm by using the method of least-squares. The convergence proof of the algorithm based on NN is also proved. Lastly, simulation results verify the effectiveness of the online learning algorithm.},
  archive      = {J_NEUCOM},
  author       = {Xiaohong Cui and Binrui Wang and Lina Wang and Jiayu Chen},
  doi          = {10.1016/j.neucom.2021.03.021},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Online optimal learning algorithm for stackelberg games with partially unknown dynamics and constrained inputs},
  volume       = {445},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Deep-learning-based reading eye-movement analysis for
aiding biometric recognition. <em>NEUCOM</em>, <em>444</em>, 390–398.
(<a href="https://doi.org/10.1016/j.neucom.2020.06.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Eye-movement recognition is a new type of biometric recognition technology. Without considering the characteristics of the stimuli, the existing eye-movement recognition technology is based on eye-movement trajectory similarity measurements and uses more eye-movement features. Related studies on reading psychology have shown that when reading text, human eye-movements are different between individuals yet stable for a given individual. This paper proposes a type of technology for aiding biometric recognition based on reading eye-movement. By introducing a deep-learning framework, a computational model for reading eye-movement recognition (REMR) was constructed. The model takes the text, fixation, and text-based linguistic feature sequences as inputs and identifies a human subject by measuring the similarity distance between the predicted fixation sequence and the actual one (to be identified). The experimental results show that the fixation sequence similarity recognition algorithm obtained an equal error rate of 19.4\% on the test set, and the model obtained an 86.5\% Rank-1 recognition rate on the test set.},
  archive      = {J_NEUCOM},
  author       = {Xiaoming Wang and Xinbo Zhao and Yanning Zhang},
  doi          = {10.1016/j.neucom.2020.06.137},
  journal      = {Neurocomputing},
  pages        = {390-398},
  shortjournal = {Neurocomputing},
  title        = {Deep-learning-based reading eye-movement analysis for aiding biometric recognition},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-attention based deep neural network with hybrid
features for dynamic sequential facial expression recognition.
<em>NEUCOM</em>, <em>444</em>, 378–389. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In interpersonal communication, the expression is an import way to express one’s emotions. In order to make computers understand facial expressions like human beings, a large number of researchers have put a lot of time and energy into it. But for now, most of the work of dynamic sequence facial expression recognition fails to make full use of the combined advantages of shallow features (prior knowledge) and depth features (high-level semantic). Therefore, this paper implements a dynamic sequence facial expression recognition system that integrates shallow features and deep features with the attention mechanism . In order to extract the shallow features, an Attention Shallow Model (ASModel) is proposed by using the relative position of facial landmarks and the texture characteristics of the local area of the face to describe the Action Units of the Facial Action Coding System . And with the advantage of the deep convolutional neural network in expressing high-level features, a Attention Deep Model (ADModel) is also designed to extract deep features on sequence facial images . Finally, the ASModel and the ADModel are integrated to a Multi-attention Shallow and Deep Model (MSDModel) to complete the dynamic sequence facial expression recognition. There are three kinds of attention mechanism introduced, such as Self-Attention (SA), Weight-Attention (WA), and Convolution-Attention (CA). We verify our dynamic expression recognition system on three publicly available databases include CK+, MMI, and Oulu-CASIA and get superior performance than other state-of-art results.},
  archive      = {J_NEUCOM},
  author       = {Xiao Sun and Pingping Xia and Fuji Ren},
  doi          = {10.1016/j.neucom.2019.11.127},
  journal      = {Neurocomputing},
  pages        = {378-389},
  shortjournal = {Neurocomputing},
  title        = {Multi-attention based deep neural network with hybrid features for dynamic sequential facial expression recognition},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). GID-net: Detecting human-object interaction with global and
instance dependency. <em>NEUCOM</em>, <em>444</em>, 366–377. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since detecting and recognizing individual human or object are not adequate to understand the visual world, learning how humans interact with surrounding objects becomes a core technology. However, convolution operations are weak in depicting visual interactions between the instances since they only build blocks that process one local neighborhood at a time. To address this problem, we learn from human perception in observing HOIs to introduce a two-stage trainable reasoning mechanism, referred to as GID block. GID block breaks through the local neighborhoods and captures long-range dependency of pixels both in global-level and instance-level from the scene to help detecting interactions between instances. Furthermore, we conduct a multi-stream network called GID-Net, which is a human-object interaction detection framework consisting of a human branch, an object branch and an interaction branch. Semantic information in global-level and local-level are efficiently reasoned and aggregated in each of the branches. We have compared our proposed GID-Net with existing state-of-the-art methods on two public benchmarks, including V-COCO and HICO-DET. The results have showed that GID-Net outperforms the existing best-performing methods on both the above two benchmarks, validating its efficacy in detecting human-object interactions.},
  archive      = {J_NEUCOM},
  author       = {Dongming Yang and YueXian Zou and Jian Zhang and Ge Li},
  doi          = {10.1016/j.neucom.2020.02.136},
  journal      = {Neurocomputing},
  pages        = {366-377},
  shortjournal = {Neurocomputing},
  title        = {GID-net: Detecting human-object interaction with global and instance dependency},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deformation representation based convolutional mesh
autoencoder for 3D hand generation. <em>NEUCOM</em>, <em>444</em>,
356–365. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its flexible joints and self-occlusion, representation and reconstruction of 3D human hand is a very challenging problem. Although some parametric models have been proposed to alleviate this problem, these representation models have limited representation ability, like not being able to represent complex gestures. In this paper, we presented a new 3D hand model with powerful representation ability and applied it to high accuracy monocular RGB-D/RGB 3D hand reconstruction. To achieve this, we firstly build a large scale high-quality hand mesh data set based on MANO with a novel mesh deformation method. We train a VAE based on this data set, and get the low-dimensional representation of hand meshes. By using our HandVAE model, we can recover a 3D human hand by giving a code within this latent space. We also build a framework to recover 3D hand mesh from RGB-D/RGB data. Experimental results have demonstrated the powerfulness of our hand model in terms of the reconstruction accuracy and the application for RGB-D/RGB reconstruction. We believe that our 3D hand representation could be further used in other related human hand applications.},
  archive      = {J_NEUCOM},
  author       = {Xinqian Zheng and Boyi Jiang and Juyong Zhang},
  doi          = {10.1016/j.neucom.2020.01.122},
  journal      = {Neurocomputing},
  pages        = {356-365},
  shortjournal = {Neurocomputing},
  title        = {Deformation representation based convolutional mesh autoencoder for 3D hand generation},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SUNNet: A novel framework for simultaneous human parsing and
pose estimation. <em>NEUCOM</em>, <em>444</em>, 349–355. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel Separation-and-UnioN Network (SUNNet) for simultaneous human parsing and pose estimation. Our SUNNet consists of two stages: a feature separation stage and a feature union stage. In feature separation stage, we leverage a common feature extractor to implicitly encode the correlation between human parsing and pose estimation, meanwhile, two task-specific feature extractors are designed to extract the features for both tasks. By combining the task-specific features and common features with a feature consolidation module in a coarse-to-fine manner, we can get an initial prediction for parsing and pose estimation; In feature union stage, we refine the initial prediction by explicitly leveraging the features from parallel task to predict the kernels’ receptive fields in a convolutional neural network . We further propose to leverage a 3D human body reconstructed from the image to facilitate these tasks, and a novel Gated Feature Fusion (GFF) block is designed to automatically decide whether to use or skip the priors from the reconstructed 3D human body. Extensive experiments demonstrate the effectiveness of our SUNNet model for human body configuration analysis.},
  archive      = {J_NEUCOM},
  author       = {Yanyu Xu and Zhixin Piao and Ziheng Zhang and Wen Liu and Shenghua Gao},
  doi          = {10.1016/j.neucom.2020.01.123},
  journal      = {Neurocomputing},
  pages        = {349-355},
  shortjournal = {Neurocomputing},
  title        = {SUNNet: A novel framework for simultaneous human parsing and pose estimation},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge embedded GCN for skeleton-based two-person
interaction recognition. <em>NEUCOM</em>, <em>444</em>, 338–348. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-person interaction recognition with skeleton data has attracted much attention in computer vision. Recently, graph convolutional network (GCN) based methods, which model the skeleton data in the form of graph, have achieved remarkable performance. However, the topology of graph in existing methods, denoted as naturally connected graph , is predefined based on the natural connection of each person. It ignores the correlations between two persons and cannot be suitable for different actions. In this paper, we design two graphs by exploiting the knowledge for two-person interaction recognition. A knowledge-given graph is constructed to build the direct connection between two persons. Meanwhile, a knowledge-learned graph is proposed to build the adaptive correlations, which is unique for each input sample. Moreover, we further propose the knowledge embedded graph convolution network (K-GCN) to exploit the complementarity among knowledge-given, knowledge-learned and naturally connected graphs for two-person interaction recognition. In addition, multi-level scheme is proposed to model the joint-level and part-level information simultaneously, which further enhances the performance. To verify the effectiveness of the proposed method, consecutive ablation studies are performed on two prevalence datasets, SBU and NTU Interaction. Experimental results show that our method achieves the state-of-the-art performance for two-person interaction recognition on both of them.},
  archive      = {J_NEUCOM},
  author       = {Jianan Li and Xuemei Xie and Yuhan Cao and Qingzhe Pan and Zhifu Zhao and Guangming Shi},
  doi          = {10.1016/j.neucom.2019.12.149},
  journal      = {Neurocomputing},
  pages        = {338-348},
  shortjournal = {Neurocomputing},
  title        = {Knowledge embedded GCN for skeleton-based two-person interaction recognition},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Normal graph: Spatial temporal graph convolutional networks
based prediction network for skeleton based video anomaly detection.
<em>NEUCOM</em>, <em>444</em>, 332–337. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focus on analyzing graph connection of human joints for skeleton based video anomaly detection , which is more effective and efficient than those image-level reconstruction based or prediction based methods that may be affected by complex background. Specifically, we propose a spatial temporal graph convolutional networks based prediction network for skeleton based video anomaly detection . In other words, we build a normal graph describing graph connection of joints in normal data, where joints of abnormal events will be outliers of this graph. To our knowledge, this is the first work to apply graph convolutional networks on skeleton-based video anomaly detection. Experiments show that our proposed normal graph achieves the-state-of-art performance, compared to those image-level reconstruction-based or prediction-based methods, as well as RNN based methods upon joints.},
  archive      = {J_NEUCOM},
  author       = {Weixin Luo and Wen Liu and Shenghua Gao},
  doi          = {10.1016/j.neucom.2019.12.148},
  journal      = {Neurocomputing},
  pages        = {332-337},
  shortjournal = {Neurocomputing},
  title        = {Normal graph: Spatial temporal graph convolutional networks based prediction network for skeleton based video anomaly detection},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DB-LSTM: Densely-connected bi-directional LSTM for human
action recognition. <em>NEUCOM</em>, <em>444</em>, 319–331. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning has achieved promising progress recently, action recognition remains a challenging task, due to cluttered backgrounds, diverse scenes, occlusions, viewpoint variations and camera motions. In this paper, we propose a novel deep learning model to capture the spatial and temporal patterns of human actions from videos. Sample representation learner is proposed to extract the video-level temporal feature, which combines the sparse temporal sampling and long-range temporal learning to form an efficient and effective training strategy. To boost the effectiveness and robustness of modeling long-range action recognition, a Densely-connected Bi-directional LSTM (DB-LSTM) network is novelly proposed to model the visual and temporal associations in both forward and backward directions. They are stacked and integrated with the dense skip-connections to improve the capability of temporal pattern modeling. Two modalities from appearance and motion are integrated with a fusion module to further improve the performance. Experiments conducted on two benchmark datasets, UCF101 and HMDB51, demonstrate that the proposed DB-LSTM model achieves promising performance, which outperforms the state-of-the-art approaches for action recognition.},
  archive      = {J_NEUCOM},
  author       = {Jun-Yan He and Xiao Wu and Zhi-Qi Cheng and Zhaoquan Yuan and Yu-Gang Jiang},
  doi          = {10.1016/j.neucom.2020.05.118},
  journal      = {Neurocomputing},
  pages        = {319-331},
  shortjournal = {Neurocomputing},
  title        = {DB-LSTM: Densely-connected bi-directional LSTM for human action recognition},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Action anticipation for collaborative environments: The
impact of contextual information and uncertainty-based prediction.
<em>NEUCOM</em>, <em>444</em>, 301–318. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To interact with humans in collaborative environments, machines need to be able to predict (i.e., anticipate) future events, and execute actions in a timely manner. However, the observation of the human limb movements may not be sufficient to anticipate their actions unambiguously. In this work, we consider two additional sources of information (i.e., context) over time, gaze, movement and object information, and study how these additional contextual cues improve the action anticipation performance. We address action anticipation as a classification task , where the model takes the available information as the input and predicts the most likely action. We propose to use the uncertainty about each prediction as an online decision-making criterion for action anticipation. Uncertainty is modeled as a stochastic process applied to a time-based neural network architecture, which improves the conventional class-likelihood (i.e., deterministic) criterion. The main contributions of this paper are fourfold: ( i ) We propose a novel and effective decision-making criterion that can be used to anticipate actions even in situations of high ambiguity; ( ii ) we propose a deep architecture that outperforms previous results in the action anticipation task when using the Acticipate collaborative dataset; ( iii ) we show that contextual information is important to disambiguate the interpretation of similar actions; and ( iv ) we also provide a formal description of three existing performance metrics that can be easily used to evaluate action anticipation models. Our results on the Acticipate dataset showed the importance of contextual information and the uncertainty criterion for action anticipation. We achieve an average accuracy of 98.75\% 98.75\% in the anticipation task using only an average of 25\% 25\% of observations. Also, considering that a good anticipation model should perform well in the action recognition task, we achieve an average accuracy of 100\% 100\% in action recognition on the Acticipate dataset, when the entire observation set is used.},
  archive      = {J_NEUCOM},
  author       = {Clebeson Canuto and Plinio Moreno and Jorge Samatelo and Raquel Vassallo and José Santos-Victor},
  doi          = {10.1016/j.neucom.2020.07.135},
  journal      = {Neurocomputing},
  pages        = {301-318},
  shortjournal = {Neurocomputing},
  title        = {Action anticipation for collaborative environments: The impact of contextual information and uncertainty-based prediction},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive multi-view graph convolutional networks for
skeleton-based action recognition. <em>NEUCOM</em>, <em>444</em>,
288–300. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Skeleton based human action recognition has attracted more and more attentions recently thanks to the accessibility of depth sensors and the development of pose estimation techniques. Conventional approaches such as convolutional neural networks usually model skeletons with grid-shaped representations, which cannot explicitly explore the dependency between two correlated joints. In this paper, we treat the skeleton as a single graph with joints as nodes and bones as edges. Based on the skeleton graph, the improved graph convolutional network called adaptive multi-view graph convolutional networks(AMV-GCNs) is proposed to deal with skeleton based action recognition. We firstly construct a novel skeleton graph and two kinds of graph nodes are defined to model the spatial configuration and temporal dynamics respectively. Then the generated graphs along with feature vectors on graph nodes are fed into AMV-GCNs. In AMV-GCNs, an adaptive view transformation module is designed to reduce the impact of view diversity. Proposed module can automatically determine suitable viewpoints and transform skeletons to new representations under those viewpoints for better recognition. Further, we employ multiple GCNs based streams to utilize and learn action information from different viewpoints. Finally, the classification scores from multiple streams are fused to provide the recognition result. Extensive experimental evaluations on four challenging datasets, NTU RGB+D 60, NTU RGB+D 120, Northwestern-UCLA and UTD-MHAD, demonstrate the superiority of our proposed network.},
  archive      = {J_NEUCOM},
  author       = {Xing Liu and Yanshan Li and Rongjie Xia},
  doi          = {10.1016/j.neucom.2020.03.126},
  journal      = {Neurocomputing},
  pages        = {288-300},
  shortjournal = {Neurocomputing},
  title        = {Adaptive multi-view graph convolutional networks for skeleton-based action recognition},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-frequency and multi-domain human activity recognition
based on SFCW radar using deep learning. <em>NEUCOM</em>, <em>444</em>,
274–287. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning and radar make it feasible to automatically recognize human activities in various lighting conditions, even occlusion case, which significantly promotes the application of activity recognition in the fields of security surveillance, health care, and so on. In this paper, an approach for human activity recognition (HAR) using deep learning is proposed based on stepped frequency continues wave (SFCW) radar. Specifically, SFCW radar is utilized to generate two types of characteristic representation domains, namely multiple frequencies of spectrograms in time–frequency domain and range maps in range domain. On the one hand, spectrograms and range maps provide different types of features. On the other hand, multi-frequency spectrograms furnish same type of features while with different scattering properties and frequency resolutions. Then a specific deep learning network including multiple parallel deep convolutional neural networks (DCNNs) and a sparse autoencoder is designed to extract and fuse these features associated with human activities from the multi-frequency spectrograms and rang map. In particular, each DCNN is aimed at extracting the detailed micro-Doppler features from a spectrogram, while sparse autoencoder learns prime range distribution features by compressing each range map to reduce complexity and improve robustness. Experimental results verify that the proposed deep learning scheme achieves 96.42\% recognition accuracy about six types of activities by incorporating three frequencies of spectrograms and range map, and surpasses two existed methods depending on single-frequency spectrogram and combination of single-frequency spectrogram and range map.},
  archive      = {J_NEUCOM},
  author       = {Yong Jia and Yong Guo and Gang Wang and Ruiyuan Song and Guolong Cui and Xiaoling Zhong},
  doi          = {10.1016/j.neucom.2020.07.136},
  journal      = {Neurocomputing},
  pages        = {274-287},
  shortjournal = {Neurocomputing},
  title        = {Multi-frequency and multi-domain human activity recognition based on SFCW radar using deep learning},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Towards CSI-based diversity activity recognition via
LSTM-CNN encoder-decoder neural network. <em>NEUCOM</em>, <em>444</em>,
260–273. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition using WiFi signals is widespread for smart-environment sensing domain in recent years. Existing researches use learning-based methods to obtain several features of activity data and then recognize human activities. As we know, propagation characteristics of WiFi signals are different for individuals under different place conditions even in the same environment. In this paper, we focus on how to weaken the accuracy differences among individuals on activity recognition and improve the robustness in one indoor environment. Based on this, we design a novel deep learning model called LCED which consists of one LSTM-based Encoder, features image presentation, and one CNN-based Decoder to weaken the accuracy differences among individuals on activity recognition. We first use a low-pass filter to remove high-frequency noise data in time-sequence signal data and design variance-based window method to determine the start and the end of time-sequence signal data corresponding to an activity. After that, we utilize the proposed LCED model to learn informative features space of activity data and improve the accuracy of sixteen activities. Experimental results show that the average accuracy of sixteen activities is high 95\% 95\% and the accuracy differences among individuals on activity recognition averagely decreases by 3\% 3\% .},
  archive      = {J_NEUCOM},
  author       = {Linlin Guo and Hang Zhang and Chao Wang and Weiyu Guo and Guangqiang Diao and Bingxian Lu and Chuang Lin and Lei Wang},
  doi          = {10.1016/j.neucom.2020.02.137},
  journal      = {Neurocomputing},
  pages        = {260-273},
  shortjournal = {Neurocomputing},
  title        = {Towards CSI-based diversity activity recognition via LSTM-CNN encoder-decoder neural network},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain models for data sources integration in HAR.
<em>NEUCOM</em>, <em>444</em>, 244–259. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ever-increasing quantities of data generated by internet of things applications bring diverse and rich perspectives about monitored phenomena. This is the case, for example, of applications monitoring continuously human activities from wearable sensor deployments for diverse purposes like eHealth. While the profusion of modalities in these deployments could offer many benefits, current learning processes need to be further guided to relate these multisensory information more effectively. Additional knowledge about, e.g. the structure of the sensors deployments, the dynamics of human activities, physical models of the body movements, etc., in short, domain models, have the potential to bring efficiency and robustness to the process of data sources integration. In this contribution, we propose to leverage domain models in order to integrate information sources efficiently. Precisely, (1) a model of the influence of data sources w.r.t. particular human activities, (2) a model of the interactions between data sources, and (3) a model of the transitions between human activities are composed in order to sample, from the data sources, information to fuse. The proposed approach is able to perform intelligent data sampling from information sources by taking into consideration the infrastructure of the sensor deployments and their evolution. Empirical evaluations show that the proposed approach ensures an efficient trade-off between the quantities of sampled data and recognition performances. Noticeably, we get an improvement of 17.84\% over the baseline setting, which exploits all available data, while reducing the number of required data sources by one-half.},
  archive      = {J_NEUCOM},
  author       = {Massinissa Hamidi and Aomar Osmani},
  doi          = {10.1016/j.neucom.2020.06.138},
  journal      = {Neurocomputing},
  pages        = {244-259},
  shortjournal = {Neurocomputing},
  title        = {Domain models for data sources integration in HAR},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human activity recognition based on smartphone and wearable
sensors using multiscale DCNN ensemble. <em>NEUCOM</em>, <em>444</em>,
226–243. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensor-based Human Activity Recognition (sensor-based HAR) has been used in many real-world applications providing valuable knowledge to many areas, such as human-object interaction, medical, military and security. Recently, wearable devices have progressively gained momentum due to their relevant data provided by their sensors, which could be employed in sensor-based HAR. In addition, the large number of sensors present in these devices provides complementary data since each sensor provides distinct information. However, there are two main issues: data heterogeneity between multiple sensors and the temporal nature of the sensor data. To cope with the former issue, we process each sensor separately, learning their features and performing the classification before fusing with the other sensors. To exploit the latter issue, we use an approach to extract patterns in multiple temporal scales of the data, using an ensemble of Deep Convolution Neural Networks (DCNN). This is convenient since the data are already a temporal sequence and the multiple scales extracted provide meaningful information regarding the activities performed by the users. Consequently, our approach is able to extract both simple movement patterns, such as a wrist twist when picking up a spoon and complex movements, such as the human gait. This multimodal and multi-temporal approach outperforms previous state-of-the-art works in seven important datasets using two different protocols. Finally, we demonstrate that our proposed set of kernels improves sensor-based HAR in another multi-kernel approach, the widely employed inception network.},
  archive      = {J_NEUCOM},
  author       = {Jessica Sena and Jesimon Barreto and Carlos Caetano and Guilherme Cramer and William Robson Schwartz},
  doi          = {10.1016/j.neucom.2020.04.151},
  journal      = {Neurocomputing},
  pages        = {226-243},
  shortjournal = {Neurocomputing},
  title        = {Human activity recognition based on smartphone and wearable sensors using multiscale DCNN ensemble},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human activity recognition by manifold regularization based
dynamic graph convolutional networks. <em>NEUCOM</em>, <em>444</em>,
217–225. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has shown superiority to extract more representative features from multimedia data in recent years. Recently, the most typical graph convolutional networks (GCN) has achieved excellent performance in the semi-supervised framework-based data representation learning tasks. GCN successfully generalizes traditional convolutional neural networks to encode arbitrary graphs by exploiting the graph Laplacian-based sample structure information. However, GCN only fuses the static structure information. It is difficult to guarantee that its structure information is optimal during the training process and applicable for all practical applications. To tackle the above problem, in this paper, we propose a manifold regularized dynamic graph convolutional network (MRDGCN). The proposed MRDGCN automatically updates the structure information by manifold regularization until model fitting. In particular, we build an optimization convolution layer formulation to acquire the optimal structure information. Thus, MRDGCN can automatically learn high-level sample features to improve the performance of data representation learning . To demonstrate the effectiveness of our proposed model, we apply MRDGCN on the semi-supervised classification tasks. The extensive experiment results on human activity datasets and citation network datasets validate the performance of MRDGCN compared with GCN and other semi-supervised learning methods.},
  archive      = {J_NEUCOM},
  author       = {Weifeng Liu and Sichao Fu and Yicong Zhou and Zheng-Jun Zha and Liqiang Nie},
  doi          = {10.1016/j.neucom.2019.12.150},
  journal      = {Neurocomputing},
  pages        = {217-225},
  shortjournal = {Neurocomputing},
  title        = {Human activity recognition by manifold regularization based dynamic graph convolutional networks},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for human activity recognition.
<em>NEUCOM</em>, <em>444</em>, 214–216. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Xiaoli Li and Peilin Zhao and Min Wu and Zhenghua Chen and Le Zhang},
  doi          = {10.1016/j.neucom.2020.11.020},
  journal      = {Neurocomputing},
  pages        = {214-216},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for human activity recognition},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information diffusion across cyber-physical-social systems
in smart city: A survey. <em>NEUCOM</em>, <em>444</em>, 203–213. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The smart city makes use of information technology to integrate city systems and functions to optimize city management and services. In this paper, we treat the smart city as a Cyber-Physical-Social System (CPSS), which is a kind of heterogeneous complex network system. Since information diffusion is fundamental to complex network analysis, we would like to summarize information diffusion in CPSS, including features of information diffusion, its application in the field of smart city, and critical technologies of information diffusion modeling and analysis. Finally, we point out open research issues, challenges, and put forward the possible future direction for research of information diffusion in smart city CPSS.},
  archive      = {J_NEUCOM},
  author       = {Xiaokang Zhou and Shaohua Li and Zheng Li and Weimin Li},
  doi          = {10.1016/j.neucom.2020.08.089},
  journal      = {Neurocomputing},
  pages        = {203-213},
  shortjournal = {Neurocomputing},
  title        = {Information diffusion across cyber-physical-social systems in smart city: A survey},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A human-centered artificial intelligence approach for
privacy protection of elderly app users in smart cities.
<em>NEUCOM</em>, <em>444</em>, 189–202. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial Intelligence and Machine Learning based Ambient Assisted Living systems play an important role in smart cities by improving the quality of life of the elderly population. Many Ambient Assisted Living systems are coupled with Android Apps for command-and-control purposes. Consequently, the privacy and security of Ambient Assisted Living systems depend on the privacy and security of the corresponding Android Apps, which follow a privacy self-management model. Unfortunately, the privacy self-management model ignores the decision-making abilities of the elderly and increases their cognitive loads, which put their privacy protection and wellbeing at stake. In this paper, we follow a Human-Centered Artificial Intelligence inspired approach for addressing these issues. This approach uses privacy as a shared responsibility model instead of the privacy self-management model. We have proposed two algorithms, the participatory privacy protection algorithm-I, and participatory privacy protection algorithm-II, for determining optimal privacy settings of an Ambient Assisted Living App and handling its runtime Permission requests, respectively. We demonstrated the working of these algorithms using a case study. We have also compared the proposed approach with state-of-the-art privacy management schemes for Android Apps. The proposed algorithms can improve the privacy protection of Ambient Assisted Living App users in smart cities and relieve them through cognitive offloading.},
  archive      = {J_NEUCOM},
  author       = {Haroon Elahi and Aniello Castiglione and Guojun Wang and Oana Geman},
  doi          = {10.1016/j.neucom.2020.06.149},
  journal      = {Neurocomputing},
  pages        = {189-202},
  shortjournal = {Neurocomputing},
  title        = {A human-centered artificial intelligence approach for privacy protection of elderly app users in smart cities},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy distribution in EV energy network under energy
shortage. <em>NEUCOM</em>, <em>444</em>, 179–188. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smart grids can use energy stored in electric vehicles (EVs) through vehicle-to-grid (V2G) technology. When the mobility of electric vehicles is combined with V2G technology, electric vehicles can form an energy transmission network called the EV energy network. The EV energy network relies heavily on renewable energy, but due to the unstable nature of renewable energy, sometimes the energy supply is insufficient. If no adjustment is made for energy shortage, the EV energy network will soon collapse. This paper studies how to make the EV energy network operate normally as long as possible when the energy shortage comes. In order to ensure the survivability of the system in the event of energy shortage, a global optimization algorithm is proposed. New terms and criteria are defined for this scenario to evaluate algorithms’ performance. The global optimization algorithm is simulated on real bus line data from Manhattan and the Pioneer Valley Transportation Authority (PVTA). Simulation results show that the algorithm is effective.},
  archive      = {J_NEUCOM},
  author       = {Baixi Lai and Ping Yi and Yu Sui and Qingquan Zhang},
  doi          = {10.1016/j.neucom.2020.08.090},
  journal      = {Neurocomputing},
  pages        = {179-188},
  shortjournal = {Neurocomputing},
  title        = {Energy distribution in EV energy network under energy shortage},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bridge health anomaly detection using deep support vector
data description. <em>NEUCOM</em>, <em>444</em>, 170–178. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extremely important part of traffic arteries, bridge structure plays an essential role in national economic construction, social development and smart city. Thus the monitoring of the bridge structure health are increasingly concerned by the bridge industry scholars and engineering people at home and aboard. In this paper, we propose a deep learning framework to evaluate the safety of the bridge structural state. More specifically, the proposed system generates a learnable transformation which attempts to map most of the data network representations into a hypersphere characterized of minimum volume. During inference, mappings of normal examples fall within the learned hypersphere, whereas mappings of anomalies fall outside the hypersphere. The whole system is end-to-end trainable and outperforms other advanced methods in real-world dataset.},
  archive      = {J_NEUCOM},
  author       = {JianXi Yang and Fei Yang and Likai Zhang and Ren Li and Shixin Jiang and Guiping Wang and Le Zhang and Zeng Zeng},
  doi          = {10.1016/j.neucom.2020.08.087},
  journal      = {Neurocomputing},
  pages        = {170-178},
  shortjournal = {Neurocomputing},
  title        = {Bridge health anomaly detection using deep support vector data description},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facial age estimation with bilateral relationships
exploitation. <em>NEUCOM</em>, <em>444</em>, 158–169. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the environment of smart cities, human facial age estimation has become an important research topic due to its wide applications. Although a variety of methods are proposed to depict facial biologic attributes, the underlying relationships between facial appearance and its biological aging process have not been fully explored. Although relationship learning methods have been constructed in terms of modeling either the facial representations or the facial attributes, none of them model the relationships simultaneously. In this paper, we propose a unified model to explore these relationships simultaneously, coined as JREAE. In JREAE, two covariance matrices are symmetrically constructed to capture the underlying correlations from both aspects of input facial features and output age labels. In this way, the potential relationships of both feature and label are not only modeled definitely, but also explored adaptively from the training data, which is significantly different from those methods that define the relationships manually. Then, we extend the JREAE model with deep convolutional architecture (deep-JREAE) for more powerful discrimination. In addition, we present optimization algorithms to solve the proposed models with theoretical convergence and complexity proof. Finally, through extensive experiments, we not only validate the effectiveness and superior of the proposed methods in performance, but also visualize and analyze the resulting relationships.},
  archive      = {J_NEUCOM},
  author       = {Qing Tian and Meng Cao and Heyang Sun and Lianyong Qi and Junxiang Mao and Yue Cao and Jun Tang},
  doi          = {10.1016/j.neucom.2020.07.149},
  journal      = {Neurocomputing},
  pages        = {158-169},
  shortjournal = {Neurocomputing},
  title        = {Facial age estimation with bilateral relationships exploitation},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PrePCT: Traffic congestion prediction in smart cities with
relative position congestion tensor. <em>NEUCOM</em>, <em>444</em>,
147–157. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic congestion prediction is a vital part of Intelligent Transportation Systems in smart cities. Effective methods for traffic congestion prediction can help people make travel plans reasonably with Advanced Traveler Information Systems. Most of the existing methods for traffic congestion prediction was designed for a specific location. The parameters need to be modified when applying these methods to different locations. Other studies on the traffic network require sophisticated data pre-processing such as map matching. In this paper, we build a model named Relative Position Congestion Tensor and propose a Predictor for Position Congestion Tensor for traffic congestion prediction. First, we design a novel approach to construct congestion matrix on region traffic networks using the concept of relative locations for road nodes and convert matrices into three-dimensional spatio-temporal tensors. Then, we propose a method based on convolutional long-short term memory network to predict congestion at all locations of the road network in the near future. The experiments show that in all locations where congestion often occurs, the proposed method significantly outperforms baseline models including Linear Regression, Autoregressive Integrated Moving Average, Support Vector Regression , Random Forest , Gradient Boosting Regression, Long-Short Term Memory and generally outperforms the Convolution-based deep Neural Network modeling Periodic traffic data. Furthermore, we study the internal structure of the Predictor for Position Congestion Tensor model to analyze the interpretability of the model for congestion prediction. The results show that the proposed model can accurately capture the temporal and spatial characteristics of traffic.},
  archive      = {J_NEUCOM},
  author       = {Mengting Bai and Yangxin Lin and Meng Ma and Ping Wang and Lihua Duan},
  doi          = {10.1016/j.neucom.2020.08.075},
  journal      = {Neurocomputing},
  pages        = {147-157},
  shortjournal = {Neurocomputing},
  title        = {PrePCT: Traffic congestion prediction in smart cities with relative position congestion tensor},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Citywide road-network traffic monitoring using large-scale
mobile signaling data. <em>NEUCOM</em>, <em>444</em>, 136–146. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road-network traffic monitoring on city-scale is critical for a wide range of applications, such as traffic forecasting, congestion identification, traffic safety, and urban planning, etc. Despite the fruitful research outcomes, however, most traffic monitoring models suffered from limited coverage, data sparsity, and data deviation, which leads to a biased and inaccurate result. With the widespread usage of mobile phones, mobile signaling data is of great value for various fields, especially for monitoring urban traffic. Thousands cell towers are distributed in the urban area, which can serve as ubiquitous sensors. Specifically, a mobile phone will passively generate a mobile signaling record that contains users’ spatiotemporal information. When mobile phone users move with their phones, their phones will interact with cell towers and these towers can obtain their mobile signaling records. And these signaling records contain sufficient information for traffic monitoring. However, there also exists excessive noise in signaling records, which makes most monitoring models abandon these data. In this paper, we present the Urban-STM scheme, which utilizes large-scale anonymous and coarse-grained mobile signaling data to infer road-network traffic conditions. We apply our scheme to a real-world signaling dataset in Changchun city and present an extensive validation study based on 2000 taxicabs’ GPS trajectories. Experiment results show that our scheme improves traffic monitoring performance in terms of coverage and accuracy.},
  archive      = {J_NEUCOM},
  author       = {Qiuyang Huang and Yongjian Yang and Yuanbo Xu and Funing Yang and Zhilu Yuan and Yongxiong Sun},
  doi          = {10.1016/j.neucom.2020.07.150},
  journal      = {Neurocomputing},
  pages        = {136-146},
  shortjournal = {Neurocomputing},
  title        = {Citywide road-network traffic monitoring using large-scale mobile signaling data},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IMatching: An interactive map-matching system.
<em>NEUCOM</em>, <em>444</em>, 126–135. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Map-matching is a process that aligns location points on a digital map and it is an essential step in location-based services. However, regular map-matching methods cannot archive very high accuracy due to the errors in raw location data and the complexity of road networks. Hence, the final resort for map matching is often through manual annotation, which is human labour intensive. Therefore, we propose iMatching , an interactive system for map-matching which greatly reduces annotation cost and achieves a high accuracy through an active learning approach. Specifically, we model the mapping of a sequence of location points to a road network as a hidden Markov model and automatically generate an initial result. Then, we select error-prone points on the trajectory and guide the annotator to review, and possibly correct, the results. Our evaluation on both real-world and synthetic data demonstrates that iMatching has a better performance comparing with the existing methods.},
  archive      = {J_NEUCOM},
  author       = {Ye Ding and Xibo Zhou and Qing Liao and Haoyu Tan and Qiong Luo and Lionel M. Ni},
  doi          = {10.1016/j.neucom.2020.04.155},
  journal      = {Neurocomputing},
  pages        = {126-135},
  shortjournal = {Neurocomputing},
  title        = {IMatching: An interactive map-matching system},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effective influential community search on attributed graph.
<em>NEUCOM</em>, <em>444</em>, 111–125. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Community search in node-attributed network returns a subgraph that contains the query vertices, and can be used in a wide range of applications domain in real world. However, most existing works ignore the influence among nodes. This leads to inaccuracy in many scenarios which require communities with high expansibility. So a few recent studies have tried to consider the influence in community search. But they ignore the attributes cohesiveness of community. Therefore, this research proposes two influential community search algorithms by taking both the influence and node attributes into consideration. We propose a novel scoring function to check the cohesiveness of the community. Our method can find the attributed pkd-truss community by maximizing the attribute and influence relevance scoring function. In order to enable effective community search in large network, we develop a graph refining algorithm and pruning rule. So our methods can provide more personalized and effective subgraph searching for big data, which can enable many downstream applications such as recommendation of dating sites, setting up of social events and other e-commerce applications. The experimental work on four networks with ground-truth communities confirms that our methods can effectively find the personalized community and have better performance than existing approaches.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqin Xie and Mingjie Song and Chiming Liu and Jiaming Zhang and Jiahui Li},
  doi          = {10.1016/j.neucom.2020.08.088},
  journal      = {Neurocomputing},
  pages        = {111-125},
  shortjournal = {Neurocomputing},
  title        = {Effective influential community search on attributed graph},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convolutional neural networks for medical image analysis:
State-of-the-art, comparisons, improvement and perspectives.
<em>NEUCOM</em>, <em>444</em>, 92–110. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks , are one of the most representative deep learning models . CNNs were extensively used in many aspects of medical image analysis, allowing for great progress in computer-aided diagnosis in recent years. In this paper, we provide a survey on convolutional neural networks in medical image analysis. First, we review the commonly used CNNs in medical image processing , including AlexNet, GoogleNet, ResNet , R-CNN, and FCNN. Then, we present an overview of the use of CNNs, for image classification , segmentation, detection, and other tasks such as registration, content-based image retrieval, image generation and enhancement, in some typical medical diagnosis areas such as brain, breast, and abdominal. Finally, we discuss the remaining challenges of CNNs in medical image analysis, and accordingly we present some ideas for future research directions.},
  archive      = {J_NEUCOM},
  author       = {Hang Yu and Laurence T. Yang and Qingchen Zhang and David Armstrong and M. Jamal Deen},
  doi          = {10.1016/j.neucom.2020.04.157},
  journal      = {Neurocomputing},
  pages        = {92-110},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural networks for medical image analysis: State-of-the-art, comparisons, improvement and perspectives},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing random forest classification with NLP in DAMEH: A
system for DAta management in eHealth domain. <em>NEUCOM</em>,
<em>444</em>, 79–91. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The use of pervasive IoT devices in Smart Cities, have increased the Volume of data produced in many and many field. Interesting and very useful applications grow up in number in E-health domain, where smart devices are used in order to manage huge amount of data, in highly distributed environments, in order to provide smart services able to collect data to fill medical records of patients. The problem here is to gather data, to produce records and to analyze medical records depending on their contents. Since data gathering involve very different devices (not only wearable medical sensors, but also environmental smart devices, like weather, pollution and other sensors) it is very difficult to classify data depending their contents, in order to enable better management of patients. Data from smart devices couple with medical records written in natural language: we describe here an architecture that is able to determine best features for classification, depending on existent medical records. The architecture is based on pre-filtering phase based on Natural Language Processing, that is able to enhance Machine learning classification based on Random Forests . We carried on experiments on about 5000 medical records from real (anonymized) case studies from various health-care organizations in Italy. We show accuracy of the presented approach in terms of Accuracy-Rejection curves.},
  archive      = {J_NEUCOM},
  author       = {Flora Amato and Luigi Coppolino and Giovanni Cozzolino and Giovanni Mazzeo and Francesco Moscato and Roberto Nardone},
  doi          = {10.1016/j.neucom.2020.08.091},
  journal      = {Neurocomputing},
  pages        = {79-91},
  shortjournal = {Neurocomputing},
  title        = {Enhancing random forest classification with NLP in DAMEH: A system for DAta management in eHealth domain},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A robust ensemble technique in forecasting workload of local
healthcare departments. <em>NEUCOM</em>, <em>444</em>, 69–78. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the exponential growth of the Internet of Things and Cloud Computing , especially in recent years, the potentiality of Machine Learning (ML) has been demonstrated and amplified, together with data mining developments and the availability of large amounts of data. In order to design a ML system capable of producing effective and accurate predictions and results it is necessary to make sure that it is actually working on large data sets; clean, high quality and complete data really representing the information you are trying to analyze. More data are available, the more accurate are evidently predictions. Forecasting represents an important use of extracted knowledge from data. It is the process of predict future demand for an offered product or service, and it allows for optimizing company decisions, reducing risks, managing stocks, planning sales and making many other internal or in-market assessments. In this paper we present and discuss a novel ensemble technique in forecasting workload of local health department. The proposed approach relies on a real dataset composed by over than 20 M of administrative e-health records. Obtained results demonstrate that our ensemble approach outperforms the state-of-the-art.},
  archive      = {J_NEUCOM},
  author       = {Francesco Piccialli and Fabio Giampaolo and Alessandro Salvi and Salvatore Cuomo},
  doi          = {10.1016/j.neucom.2020.02.138},
  journal      = {Neurocomputing},
  pages        = {69-78},
  shortjournal = {Neurocomputing},
  title        = {A robust ensemble technique in forecasting workload of local healthcare departments},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Introduction to the special issue on advances of
neurocomputing for smart cities (NEUROCOM for smart cities).
<em>NEUCOM</em>, <em>444</em>, 67–68. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Kenli Li ( Guest Editors ) and Keqin Li and Cen Chen and Xiaokang Wang},
  doi          = {10.1016/j.neucom.2020.11.069},
  journal      = {Neurocomputing},
  pages        = {67-68},
  shortjournal = {Neurocomputing},
  title        = {Introduction to the special issue on advances of neurocomputing for smart cities (NEUROCOM for smart cities)},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Neural network for computing GSVD and RSVD.
<em>NEUCOM</em>, <em>444</em>, 59–66. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the neural dynamical network to compute the generalized and restricted singular value decompositions (GSVD/RSVD) in the regularization methods for ill-posed problems. The neural network model is defined by ordinary differential equations (ODE) which can be solved by many state-of-the-art techniques. The main purpose of the paper is to develop two neural network models for finding approximations of the GSVD and the RSVD. The globally asymptotic stability analyses are provided and numerical experiments illustrate our theory and methods. For small scale problems, the estimation can be as accurate as O ( 10 - 15 ) O(10-15) . For ill-posed problems, the truncation regularization method implementing the GSVD/RSVD algorithms also produces accurate results.},
  archive      = {J_NEUCOM},
  author       = {Liping Zhang and Yimin Wei and Eric King-wah Chu},
  doi          = {10.1016/j.neucom.2020.10.057},
  journal      = {Neurocomputing},
  pages        = {59-66},
  shortjournal = {Neurocomputing},
  title        = {Neural network for computing GSVD and RSVD},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A weighted feature enhanced hidden markov model for spam SMS
filtering. <em>NEUCOM</em>, <em>444</em>, 48–58. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short message service (SMS) is a most favored communication service people use in daily life. However, this service is being misused by spammers. Rule based systems (RBS) and content based filtering (CBF) techniques have been developed to filter out spam messages. New rules can be easily added into RBS, but the throughput usually reduces as the rules increase. The bag-of-words (BoW) assumption based CBF techniques ignore the word order, which use machine learning methods to extract features from SMS message body according to word frequency and distribution. Striving to improve performance, researchers developed hybrid models that made algorithms ever-more complex. In addition, frequently conducting the time consuming models training and deployment forces the anti-spam industry still rely mainly on rule-based systems with unsolved throughput issue. A discrete Hidden Markov Model (HMM) was proposed in our previous study to address these issues, and the HMM method achieved a comparable performance to the deep learning methods. To further improve the performance of HMM method, we propose a new approach to weight and label words in SMS for formatting the observation sequence in HMM method. The weighted feature enhanced HMM achieves higher accuracy, and much faster training and filtering speed for meeting the anti-spam industry requirement. The performance comparison with other machine learning methods is conducted on the same open respiratory data set maintained by University of California, Irvine (UCI). Experimental results show that the weighted features enhanced HMM outperforms the LSTM (long short-term memory model) and close to CNN (convolutional neural network) in terms of classification accuracy. In addition, a Chinese SMS data set is used to further validate filtering accuracy and filtering speed.},
  archive      = {J_NEUCOM},
  author       = {Tian Xia and Xuemin Chen},
  doi          = {10.1016/j.neucom.2021.02.075},
  journal      = {Neurocomputing},
  pages        = {48-58},
  shortjournal = {Neurocomputing},
  title        = {A weighted feature enhanced hidden markov model for spam SMS filtering},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Broad learning system for semi-supervised learning.
<em>NEUCOM</em>, <em>444</em>, 38–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an emerging technique for supervised learning, broad learning system (BLS) has been proved to have many advantages such as fast learning speed, good generalization, etc. However, it is difficult for BLS to perform well on the dataset which only contains few labeled samples. Because the focus of semi-supervised learning is utilizing the information between labeled and unlabeled samples while the original BLS apparently ignores this significant information. In BLS, the mapped features are obtained by sparse autoencoder which is an unsupervised learning method and the enhancement nodes are formed based on the mapped features. But sparse autoencoder will definitely lose the information of labeled instances. Therefore, we propose a novel semi-supervised BLS (S2-BLS) in this paper. In S2-BLS, inspired by the effectiveness of extreme learning machine based autoencoder (ELM-AE), we first propose semi-supervised ELM-AE (SS-ELM-AE) to obtain the mapped features. Then, the discriminative projecting weights between the ground truths and the transformed features (including the mapping features and the enhancement nodes) are calculated directly. Finally, we adopt some public datasets to verify the learning ability of S2-BLS. And the experimental results illustrate that S2-BLS has an obvious advantage to learn labeled and unlabeled data , comparing with related algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zheng Liu and Shiluo Huang and Wei Jin and Ying Mu},
  doi          = {10.1016/j.neucom.2021.02.059},
  journal      = {Neurocomputing},
  pages        = {38-47},
  shortjournal = {Neurocomputing},
  title        = {Broad learning system for semi-supervised learning},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous deep feature extraction based method for
epileptic EEG brain seizure classification. <em>NEUCOM</em>,
<em>444</em>, 30–37. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Epilepsy is a highly prevalent disorder that can affect a person’s quality of life. People with epilepsy are commonly affected by reoccurring seizures that potentially cause injury or death. Neurologists frequently use Electroencephalography (EEG) recordings to diagnose people with epilepsy. However, this can be both laborious and error-prone, as this can rely on competency and insight from undertrained neurologists. Machine learning-based methods have been recently proposed for seizure detection so that neurologists can make a quick and correct diagnosis. However, these methods often require features of the EEG signal to be extracted from data before the data can be used. Furthermore, the choice of features often requires domain knowledge about the data, and depending on the expert knowledge of the user, the selection of which features to extract can have a dramatic impact on the classifier’s performance. In this paper, we propose a novel method that can autonomously extract features from deep within a convolutional neural network (CNN) and generate easy to understand rules/explanations used for the classification of seizures from EEG signals. The aim of creating rules/explanations is to explain the internal logic of our method to give the neurologist insight into the decision-making process. Thus, distilling trust. We evaluate our method against other classifiers in terms of accuracy, sensitivity, and specificity, and achieve an accuracy of 98.65\%, sensitivity of 96.29\%, specificity of 99.25\%.},
  archive      = {J_NEUCOM},
  author       = {Mitchell Woodbright and Brijesh Verma and Ali Haidar},
  doi          = {10.1016/j.neucom.2021.02.052},
  journal      = {Neurocomputing},
  pages        = {30-37},
  shortjournal = {Neurocomputing},
  title        = {Autonomous deep feature extraction based method for epileptic EEG brain seizure classification},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). I2Net: Mining intra-video and inter-video attention for
temporal action localization. <em>NEUCOM</em>, <em>444</em>, 16–29. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on two challenges for temporal action localization community, i.e., lack of long-term relationship and action pattern uncertainty. The former prevents the cooperation among multiple action instances within a video, while the latter may cause incomplete localizations or false positives . The lack of long-term relationship challenge results from the limited receptive field. Instead of stacking multiple layers or using large convolution kernels , we propose the intra-video attention mechanism to bring global receptive field to each temporal point. As for the action pattern uncertainty challenge, although it is hard to precisely depict the desired action pattern, paired videos that share the same action category can provide complementary information about action pattern. Consequently, we propose an inter-video attention mechanism to assist learning accurate action patterns. Based on the intra-video attention and inter-video attention, we propose a unified framework, namely I2Net , to tackle the challenging temporal action localization task. Given two videos containing sharing action categories, I2Net adopts the widely used one-stage action localization paradigm to dispose of them in parallel. As for two neighboring layers within the same video, the intra-video attention brings global information to each temporal point and helps to learn representative features. As for two parallel layers between two videos, the inter-video attention introduces complementary information to each video and helps to learn accurate action patterns. With the cooperation of intra-video and inter-video attention mechanisms, I2Net shows obvious performance gains over the baseline and builds new state-of-the-art on two widely-used benchmarks, i.e., THUMOS14 and ActivityNet v1.3.},
  archive      = {J_NEUCOM},
  author       = {Wei Zhang and Binglu Wang and Songhui Ma and Yani Zhang and Yongqiang Zhao},
  doi          = {10.1016/j.neucom.2021.02.085},
  journal      = {Neurocomputing},
  pages        = {16-29},
  shortjournal = {Neurocomputing},
  title        = {I2Net: Mining intra-video and inter-video attention for temporal action localization},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and analysis of multi-valued auto-associative
quaternion-valued recurrent neural networks based on external inputs.
<em>NEUCOM</em>, <em>444</em>, 1–15. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a design procedure for synthesizing auto-associative memories of quaternion-valued recurrent neural networks (QVRNNs) based on external inputs. By virtue of the geometrical properties of the activation function and the fixed point theorem , several inequalities are given to guarantee the global exponential stability for the QVRNNs. The proposed QVRNNs are robust in terms of the design parameter selection and neurons are reduced. Several illustrative examples applied to true color images are given to guarantee the validity of the results.},
  archive      = {J_NEUCOM},
  author       = {Yuan Wang and Chunlin Sha and Hongyong Zhao},
  doi          = {10.1016/j.neucom.2021.03.013},
  journal      = {Neurocomputing},
  pages        = {1-15},
  shortjournal = {Neurocomputing},
  title        = {Design and analysis of multi-valued auto-associative quaternion-valued recurrent neural networks based on external inputs},
  volume       = {444},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Distributed consensus control for a group of autonomous
marine vehicles with nonlinearity and external disturbances.
<em>NEUCOM</em>, <em>443</em>, 380–387. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the distributed consensus control for a group of autonomous marine vehicles with nonlinearity and external disturbances via sampled-data communications. First, the kinematical equation of autonomous marine vehicle is established. Second, stability criteria is derived to ensure the stability of autonomous marine vehicles by combining Lyapunov function method and free-weighting matrix approach . Third, a distributed sampled-data control strategy is proposed to achieve the consensus of autonomous marine vehicles by designing suitable control parameters. Numerical simulations are provided to verify the effectiveness of the proposed consensus control approach.},
  archive      = {J_NEUCOM},
  author       = {Yanzhou Li and Yuanqing Wu and Shenghuang He},
  doi          = {10.1016/j.neucom.2020.12.058},
  journal      = {Neurocomputing},
  pages        = {380-387},
  shortjournal = {Neurocomputing},
  title        = {Distributed consensus control for a group of autonomous marine vehicles with nonlinearity and external disturbances},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ReinforceNet: A reinforcement learning embedded object
detection framework with region selection network. <em>NEUCOM</em>,
<em>443</em>, 369–379. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, researchers have explored reinforcement learning based object detection methods. However, existing methods always suffer from barely satisfactory performance. The main reasons are that current reinforcement learning based methods generate a sequence of inaccurate regions without a reasonable reward function, and regard the non-optimal one at the final step as the detection result for lack of an effective region selection and refinement strategy. To tackle the above problems, we propose a novel reinforcement learning based object detection framework, namely ReinforceNet, possessing the capability of the region selection and refinement by integrating reinforcement learning agents’ action space with Convolutional Neural Network based feature space. In ReinforceNet, we redevelop a reward function that enables the agent to be trained effectively and provide more accurate region proposals. In order to further optimize them, we design Convolutional Neural Network based region selection network (RS-net) and bounding box refinement network (BBR-net). Particularly, the former consists of two sub-networks: Intersection-of-Union network (IoU-net) and Completeness network (CPL-net) which are employed jointly for selecting the optimal region proposal. The latter aims to refine the selected one as the final result. Extensive experimental results on two standard datasets PASCAL VOC 2007 and VOC 2012 demonstrate that ReinforceNet is capable of improving the region selection and learning better agent action representations for reinforcement learning, resulting in the state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Man Zhou and Rujing Wang and Chengjun Xie and Liu Liu and Rui Li and Fangyuan Wang and Dengshan Li},
  doi          = {10.1016/j.neucom.2021.02.073},
  journal      = {Neurocomputing},
  pages        = {369-379},
  shortjournal = {Neurocomputing},
  title        = {ReinforceNet: A reinforcement learning embedded object detection framework with region selection network},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Micro-expression spotting: A new benchmark. <em>NEUCOM</em>,
<em>443</em>, 356–368. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Micro-expressions (MEs) are brief and involuntary facial expressions that occur when people are trying to hide their true feelings or conceal their emotions. Based on psychology research, MEs play an important role in understanding genuine emotions, which leads to many potential applications. Therefore, ME analysis has become an attractive topic for various research areas, such as psychology, law enforcement, and psychotherapy. In the computer vision field, the study of MEs can be divided into two main tasks, spotting and recognition, which are used to identify positions of MEs in videos and determine the emotion category of the detected MEs, respectively. Recently, although much research has been done, no fully automatic system for analyzing MEs has yet been constructed on a practical level for two main reasons: most of the research on MEs only focuses on the recognition part, while abandoning the spotting task; current public datasets for ME spotting are not challenging enough to support developing a robust spotting algorithm. The contributions of this paper are threefold: (1) we introduce an extension of the SMIC-E database, namely the SMIC-E-Long database, which is a new challenging benchmark for ME spotting; (2) we suggest a new evaluation protocol that standardizes the comparison of various ME spotting techniques; (3) extensive experiments with handcrafted and deep learning-based approaches on the SMIC-E-Long database are performed for baseline evaluation.},
  archive      = {J_NEUCOM},
  author       = {Thuong-Khanh Tran and Quang-Nhat Vo and Xiaopeng Hong and Xiaobai Li and Guoying Zhao},
  doi          = {10.1016/j.neucom.2021.02.022},
  journal      = {Neurocomputing},
  pages        = {356-368},
  shortjournal = {Neurocomputing},
  title        = {Micro-expression spotting: A new benchmark},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid medical text classification framework: Integrating
attentive rule construction and neural network. <em>NEUCOM</em>,
<em>443</em>, 345–355. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of this work is to improve the quality and transparency of the medical text classification solutions. Conventional text classification methods provide users with only a restricted mechanism (based on frequency) for selecting features. In this paper, a three-stage hybrid method combining the gated attention-based bi-directional Long Short-Term Memory (ABLSTM) and the regular expression based classifier is proposed for medical text classification tasks. The bi-directional Long Short-Term Memory (LSTM) architecture with an attention layer allows the network to weigh words according to their perceived importance and focus on crucial parts of a sentence. Feature words (or keywords) extracted by ABLSTM model are utilized to guide the regular expression rule construction. Our proposed approach leverages the advantages of both the interpretability of rule-based algorithms and the computational power of deep learning approaches for a production-ready scenario. Experimental results on real-world medical online query data clearly validate the superiority of our system in selecting domain-specific and topic-related features. Results show that the proposed approach achieves an accuracy of 0.89 0.89 and an F 1 F1 -score of 0.92 0.92 respectively. Furthermore, our experimentation also illustrates the versatility of regular expressions as a user-level tool for focusing on desired patterns and providing interpretable solutions for human modification.},
  archive      = {J_NEUCOM},
  author       = {Xiang Li and Menglin Cui and Jingpeng Li and Ruibin Bai and Zheng Lu and Uwe Aickelin},
  doi          = {10.1016/j.neucom.2021.02.069},
  journal      = {Neurocomputing},
  pages        = {345-355},
  shortjournal = {Neurocomputing},
  title        = {A hybrid medical text classification framework: Integrating attentive rule construction and neural network},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural networks-based real-time optimal navigation for
an automatic guided vehicle with static and dynamic obstacles.
<em>NEUCOM</em>, <em>443</em>, 329–344. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hybrid-intelligent real-time optimal control approach based on deep neural networks (DNNs) is proposed to improve the autonomy and intelligence of automatic guided vehicles (AGVs) navigation control. We first formulate the motion planning problem of an AGV with static and dynamic obstacles as a nonlinear optimal control problem (OCP). Subsequently, a direct method incorporating a smooth transformation technique is utilized to obtain the high-fidelity optimal solutions off-line. The optimal state-action samples are then extracted from the optimal trajectories generated by the OCP from perturbed initial states and stored as a large optimal trajectory data set. Thereafter, the DNNs architecture is designed and trained off-line through the collected data set to learn the optimal state-action relationship. As a result, the well-trained DNNs are used to produce the corresponding to optimal feedback actions on-board. The main advantage of our approach is that the time-consuming computation process is only carried out off-line and thus the traditional repeated off-line planning for the AGV due to changes such as the perturbed initial conditions in the system can be effectively avoided. Numerical experimental results are carried out to demonstrate our designed DNNs-based optimal control approach can generate the optimal control instructions on-board to steer the AGV to the desired location with high robustness to initial conditions as well as satisfying different obstacle constraints.},
  archive      = {J_NEUCOM},
  author       = {Zhigang Ren and Jialun Lai and Zongze Wu and Shengli Xie},
  doi          = {10.1016/j.neucom.2021.02.034},
  journal      = {Neurocomputing},
  pages        = {329-344},
  shortjournal = {Neurocomputing},
  title        = {Deep neural networks-based real-time optimal navigation for an automatic guided vehicle with static and dynamic obstacles},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-instance networks with multiple views for
classification of mammograms. <em>NEUCOM</em>, <em>443</em>, 320–328.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is the most common malignant disease in women, and early screening of breast cancer is crucial for improving the survival rate. Mammography is one of the most popular imaging methods for breast cancer screening with the characteristics of practicality, effectiveness, and low cost. However, the classification of mammograms suffers from large image sizes, indistinct image characteristics of lesions, small proportion of abnormalities, and class imbalance. To address these difficulties, the multi-view input and weighted multi-instance learning (MIL) methods are proposed. A novel model called the weighted MIL DenseNet with multi-view input (WMDNet) is presented that integrates the two methods above. The multi-view inputs method is used to enhance the abnormalities of mammograms and obtain more potential features from mammograms with different views, simultaneously. The weighted MIL is designed to extract the most suspicious lesions from mammograms to resolve the problems of small proportion of abnormalities and class imbalance. To verify the effectiveness of the proposed methods, three binary classification models are evaluated on two public datasets, the INbreast and MIAS datasets. The experimental results demonstrate that the proposed methods can achieve preferably results compared with several other state-of-the-art approaches, especially the proposed WMDNet model gains the best classification results on both datasets.},
  archive      = {J_NEUCOM},
  author       = {Ting Hu and Lei Zhang and Lizhang Xie and Zhang Yi},
  doi          = {10.1016/j.neucom.2021.02.070},
  journal      = {Neurocomputing},
  pages        = {320-328},
  shortjournal = {Neurocomputing},
  title        = {A multi-instance networks with multiple views for classification of mammograms},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Face perception foundations for pattern recognition
algorithms. <em>NEUCOM</em>, <em>443</em>, 302–319. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pattern recognition system developers have looked in multiple directions over the years and designed a broad spectrum of methodologies for face identification and verification, both in 2D and 3D. These techniques rely on sound methods and experimentations, and currently give high to excellent recognition rates in terms of performance. Nonetheless, it seems that the most performing face recognition system, especially when familiar faces are involved, is still the human being, able to detect known faces in the wild, in presence of occlusions or extreme light contrast, caricatures, sketches, partial views, blurred images. This is one of the manifold reasons why the human visual system at eye and brain level and face perception techniques are currently being studied by neuroscientists and psychologists, with the aim to uncover the processes underneath the human vision. The purpose of this work is to review the current literature about perception foundations and related biologically-inspired methodologies for face recognition.},
  archive      = {J_NEUCOM},
  author       = {F. Marcolin and E. Vezzetti and M.G. Monaci},
  doi          = {10.1016/j.neucom.2021.02.074},
  journal      = {Neurocomputing},
  pages        = {302-319},
  shortjournal = {Neurocomputing},
  title        = {Face perception foundations for pattern recognition algorithms},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dual neural network for object detection in UAV images.
<em>NEUCOM</em>, <em>443</em>, 292–301. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer vision analysis in Unmanned Aerial Vehicle (UAV) represents a major trend in the future development. Object detection in UAV images is one of the important techonlogies to analyze scene information. However, the UAV image includes small and dense targets, which easily leads to errors of missed detection. In this paper, we propose a dual neural network review method, which quickly screens the missed targets in the one-stage detection by classifying the secondary features of the suspected target regions, so as to achieve high quality detection of small targets. Firstly, the one-stage detector recognizes UAV images, and the result with confidence greater than or equal to the threshold is detected as the target. The result less than the threshold are considered as suspected areas containing missed targets. Secondly, the feature map of UAV image is extracted by VGG backbone. The feature map and the location information of the suspected areas are combined to secondary identification. Then, the features of the dual network are late fusion, and the re-identified results guide the initial confidence addition. After the addition, regions with confidence greater than the threshold are considered as targets. Finally, we synthesize the targets of initial detection and secondary identification to obtain the final detection results. Experimental results show that our method achieves breakthrough performance on VisDrone, UAVDT and MS COCO datasets.},
  archive      = {J_NEUCOM},
  author       = {Gangyi Tian and Jianran Liu and Wenyuan Yang},
  doi          = {10.1016/j.neucom.2021.03.016},
  journal      = {Neurocomputing},
  pages        = {292-301},
  shortjournal = {Neurocomputing},
  title        = {A dual neural network for object detection in UAV images},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Single image restoration through ℓ2-relaxed truncated ℓ0
analysis-based sparse optimization in tight frames. <em>NEUCOM</em>,
<em>443</em>, 272–291. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration problems , i.e., recovery of an original high-quality image from the degraded observation, arise in various science and engineer areas. Over the past decades, the framelet-based methods are particularly investigated and adopted, owing to the excellent ability of sparse approximating the piecewise-smooth functions such as natural images. In this paper, we propose a novel tight frame-based ℓ 2 ℓ2 -relaxed truncated ℓ 0 ℓ0 analysis-sparsity model that simultaneously exploiting the sparsity and support priors. The resulting nonconvex nonsmooth optimization problem is addressed by using the proposed proximal alternating adaptive hard thresholding (PAAHT) method. We also proved that the sequence generated by the proposed algorithm sublinearly converges. Numerical experiments on several typical image restoration problems demonstrate that the proposed method is more effective than the standard sparsity-inducing algorithms and outperforms several state-of-the-art methods in both objective and perceptual quality .},
  archive      = {J_NEUCOM},
  author       = {Liangtian He and Yilun Wang and Jun Liu and Chao Wang and Shaobing Gao},
  doi          = {10.1016/j.neucom.2021.02.053},
  journal      = {Neurocomputing},
  pages        = {272-291},
  shortjournal = {Neurocomputing},
  title        = {Single image restoration through ℓ2-relaxed truncated ℓ0 analysis-based sparse optimization in tight frames},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual content-enhanced sequential recommendation with
feature-level attention. <em>NEUCOM</em>, <em>443</em>, 262–271. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A sequential recommender system (SRS) takes historical user-item interactions as a sequence to predict the next item that may be of interest to a user. Most of existing SRSs make predictions by only considering item IDs, while ignoring other important factors that may also significantly influence users’ choices, such as the visual content of items. This may not always be true in reality since an item’s appearance usually has great visual impact on users and thus plays an important role in users’ choices. In practice, each item’s appearance has often been specifically designed to represent a particular style or look. In addition, users’ preferences with regard to visual aspects, such as styling, color, etc., may be relatively consistent compared with their dynamic preferences on items for a certain period under sequential transaction scenarios. This motivates us to take the items’ visual content into account to build more reliable SRSs. Accordingly, we propose a novel visual content-enhanced sequential recommender system (VCSRS) for improving the performance of sequential recommendations. Particularly, in VCSRS, a feature-level attention module (FAM) is designed to learn the attentive visual representations of an item’s appearance. Moreover, a vision-concentrated recurrent network (VCRN) is devised to model the sequential dependencies between items while incorporating items’ visual representations. Extensive experiments on real-world datasets demonstrated the effectiveness of visual information and showed the superiority of our approach over other representative and state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Tong Qu and Wanggen Wan and Shoujin Wang},
  doi          = {10.1016/j.neucom.2021.02.037},
  journal      = {Neurocomputing},
  pages        = {262-271},
  shortjournal = {Neurocomputing},
  title        = {Visual content-enhanced sequential recommendation with feature-level attention},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Image super-resolution using multi-granularity perception
and pyramid attention networks. <em>NEUCOM</em>, <em>443</em>, 247–261.
(<a href="https://doi.org/10.1016/j.neucom.2021.03.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, single image super-resolution (SISR) has been widely applied in the fields of multimedia and computer vision communities and obtained remarkable performance. However, most current methods ignore to utilize multi-granularity features of low-resolution (LR) image to further improve the SISR performance. And the channel and spatial features obtained from original LR images are treated equally, resulting in unnecessary computations for abundant uninformative features, thereby hindering the representational ability of super-resolution (SR) models. In this paper, we present a novel Multi-Granularity Pyramid Attention Network (MGPAN) which fully exploits the multi-granularity perception and attention mechanisms to improve the quality of reconstructed images. We design a multi-branch dilated convolution layer with varied kernels corresponding to receptive fields of different sizes to modulate multi-granularity features for adaptively capturing more important information. Moreover, a novel spatial pyramid pooling attention (SPPA) module is constructed to integrate the channel-wise and multi-scale spatial information, which is beneficial to compute the response values from the multi-scale regions of each neuron, and then establish the accurate mapping from low to high dimensional solution space. Besides, for long-short-term information preservation and information flow enhancement, we adopt the short, long, and global skip connection structures to concatenate and fuse the states of each module, which can improve the SR network performance effectively. Extensive experiments on several standard benchmark datasets show that the proposed MGPAN can provide state-of-the-art or even better performance in both quantitative and qualitative measurements.},
  archive      = {J_NEUCOM},
  author       = {Huan Wang and Chengdong Wu and Jianning Chi and Xiaosheng Yu and Qian Hu and Hao Wu},
  doi          = {10.1016/j.neucom.2021.03.010},
  journal      = {Neurocomputing},
  pages        = {247-261},
  shortjournal = {Neurocomputing},
  title        = {Image super-resolution using multi-granularity perception and pyramid attention networks},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Few-shot SAR automatic target recognition based on
conv-BiLSTM prototypical network. <em>NEUCOM</em>, <em>443</em>,
235–246. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent studies, synthetic aperture radar (SAR) automatic target recognition (ATR) algorithms have achieved high recognition accuracy in the moving and stationary target acquisition and recognition (MSTAR) data set. However, these algorithms usually require hundreds or more training samples of each target type. In order to extract azimuth-insensitive features in a SAR ATR task with only a few training samples, a convolutional bidirectional long short-term memory (Conv-BiLSTM) network is designed as an embedding network to map the SAR images into a new feature space where the classification problem becomes easier. Based on the embedding network, a novel few-shot SAR ATR framework called Conv-BiLSTM Prototypical Network (CBLPN) is proposed. Experimental results on the MSTAR benchmark data set have illustrated that the proposed method performs well in SAR image classification with only a few training samples.},
  archive      = {J_NEUCOM},
  author       = {Li Wang and Xueru Bai and Ruihang Xue and Feng Zhou},
  doi          = {10.1016/j.neucom.2021.03.037},
  journal      = {Neurocomputing},
  pages        = {235-246},
  shortjournal = {Neurocomputing},
  title        = {Few-shot SAR automatic target recognition based on conv-BiLSTM prototypical network},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Deep associative learning for neural networks.
<em>NEUCOM</em>, <em>443</em>, 222–234. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural learning plays an important role in many applications. In this paper, we derive a new learning paradigm for neural networks . Most existing neural models train network parameters including connecting weights and biases via optimizing a loss or energy function. Inspired from the associative learning in brain, we propose to associate different patterns via modeling joint distribution of them based on a hierarchical architecture. We first define an energy function based on the distance between hierarchical features of different patterns. Then a Gibbs typological distribution is constructed according to the energy field. To optimize the model, it is necessary to estimate the gradient expectation via sampling. Different from the simple architecture of existing probabilistic neural models such as restricted Boltzmann machine , the difficulty of optimizing this model lies in uncomputable probability for sampling from the distribution. Then we propose an optimization based sampling method. After learning, conditional probability can be derived and the unknown pattern can be generated via sampling as well. Compared with existing neural learning models, the proposed deep associative learning can associate different patterns and can be directly applied to many learning problems. Experiments on problems of classification, image transformation, and image change detection verify the effectiveness of the proposed learning paradigm.},
  archive      = {J_NEUCOM},
  author       = {Jia Liu and Wenhua Zhang and Fang Liu and Liang Xiao},
  doi          = {10.1016/j.neucom.2021.03.012},
  journal      = {Neurocomputing},
  pages        = {222-234},
  shortjournal = {Neurocomputing},
  title        = {Deep associative learning for neural networks},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive NN finite-time tracking control for PMSM with full
state constraints. <em>NEUCOM</em>, <em>443</em>, 213–221. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the tracking control problem for a class of permanent magnet synchronous motors (PMSM) systems with asymmetric full-state constraints. To overcome the difficulty of controller design caused by the state constraint problems of system, a nonlinear transformation function i introduced to transform the state constraint problems into a non-constraint problems. Then, radial basis function neural networks (NN) is employed to approximate the uncertainties in the system. In addition, by combining the techniques of command filter and finite-time control, a novel virtual control signal and modified error compensation signals are proposed to construct the actual control law, which solves the problems of “explosion of complexity” and “singularity”. It is shown that all signals of the closed-loop system are bounded and the tracking error remains in a small neighborhood of the origin in finite time. Finally, the simulations show the performance and feasibility of the proposed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Jin-Zi Yang and Yuan-Xin Li and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2021.02.038},
  journal      = {Neurocomputing},
  pages        = {213-221},
  shortjournal = {Neurocomputing},
  title        = {Adaptive NN finite-time tracking control for PMSM with full state constraints},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). EWNet: An early warning classification framework for smart
grid based on local-to-global perception. <em>NEUCOM</em>, <em>443</em>,
199–212. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Early warning mechanism is crucial for maintaining the security and reliability of the power grid system . It remains to be a difficult task in a smart grid system due to complex environments in practice. In this paper, by considering the lack of vision-based datasets and models for early warning classification, we constructed a large-scale image dataset, namely EWSPG1.0, which contains 12,113 images annotated with five levels of early warnings. Moreover, 104,448 object instances with respect to ten categories of high-risk objects and power gird infrastructure were annotated with labels, bounding boxes and polygon masks. On the other hand, we proposed a local-to-global perception framework for arly warning classification, namely EWNet. Specifically, a local patch responsor is trained by using image patches extracted from the training set according to the labeled bounding box information of objects. The capability of recognizing high-risk objects and power grid infrastructure is transferred by loading the trained local patch responsor with frozen weights. Features are then fed into a feature integration module and a global classification module for early warning classification of an entire image. In order to evaluate the proposed framework, we benchmarked the proposed framework on our constructed dataset with 11 state-of-the-art deep convolutional neural networks (CNNs)-based classification models . Experimental results exhibit the effectiveness of our proposed method in terms of Top-1 classification accuracy . They also indicate that vision-based early warning classification remains challengeable under power grid surveillance and needs further study in future work.},
  archive      = {J_NEUCOM},
  author       = {Feng Gao and Qun Li and Yuzhu Ji and Shengchang Ji and Jie Guo and Haofei Sun and Yang Liu and Simeng Feng and Haokun Wei and Nan Wang and Biao Yang and Haijun Zhang},
  doi          = {10.1016/j.neucom.2021.03.007},
  journal      = {Neurocomputing},
  pages        = {199-212},
  shortjournal = {Neurocomputing},
  title        = {EWNet: An early warning classification framework for smart grid based on local-to-global perception},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Nonlinear loose coupled non-negative matrix factorization
for low-resolution image recognition. <em>NEUCOM</em>, <em>443</em>,
183–198. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the existing coupled mapping-based methods for low-resolution image recognition (LRIR), the potential relationship between the high- and low-resolution images conforming to the nature of the image characteristics is not considered and the mapping process has no strong actual physical meaning. This paper presents a novel nonlinear loose coupled non-negative matrix factorization (NLCNMF) algorithm to deal with LRIR. The target images can be seen as composed of different local features . The local features of high- and low-resolution images are at different resolution levels, but the way different resolution images are composed of corresponding local features should be similar. The kernel trick is used to achieve the nonlinear approach. The nonlinear mapped high- and low-resolution images are represented by corresponding non-negative local features. The representation coefficient vectors of the high- and low-resolution images belonging to the same target image pair are approximately equal. The proposed NLCNMF conforms to the principle of the nonlinear approach used by the human visual system in analyzing images. When the proposed method describe the common features of the images with different resolution, the idea of ”part constitute the whole” is utilized, which has a strong interpretability . The nonlinear algorithm models based on polynomial and Gaussian kernel function are presented. The convergence of the proposed algorithm is proved theoretically. The proposed algorithm performs experiments on 5 image databases. Three different low-resolution (8 × 7, 10 × 10 and 12 × 12) images are involved in the experiment. The experimental results show that the proposed method outperforms the state-of-the-arts in LRIR task.},
  archive      = {J_NEUCOM},
  author       = {Yang Zhao and Chao Wang and Jihong Pei and Xuan Yang},
  doi          = {10.1016/j.neucom.2021.02.068},
  journal      = {Neurocomputing},
  pages        = {183-198},
  shortjournal = {Neurocomputing},
  title        = {Nonlinear loose coupled non-negative matrix factorization for low-resolution image recognition},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neural architecture search based framework for liquid
state machine design. <em>NEUCOM</em>, <em>443</em>, 174–182. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Liquid state machines (LSMs), also known as the recurrent version of spiking neural networks , have garnered significant research interest owing to their high computational power, biological plausibility, simple structure, and low training complexity. By exploring the design space in network architectures and parameters, recent works have demonstrated the great potential for improving the accuracy of LSM models with low complexity. However, these works are based on manually defined network architectures or predefined parameters, which may ignore the potential optimization of the architectures and parameters of LSMs. In this study, we propose a neural architecture search-based framework to explore the architecture and parameter design space for the automatic dataset-oriented LSM models. To manage the exponentially increasing design space, we adopt a three-step search for LSMs, including dynamic multiple-liquid architecture search in multiple layers, variations in the number of neurons in each liquid, and parameter search such as percentage connectivity and excitatory neuron ratio within each liquid. In addition, we propose the use of a simulated annealing algorithm to implement three-step heuristic search . Two datasets, including the image dataset of NMNIST and speech dataset of FSDD, were used to test the effectiveness of the proposed framework. Simulation results demonstrated that our framework can produce the dataset-oriented optimal LSM models with high accuracy and low complexity. The best classification accuracy on the two datasets with only 1000 spiking neurons was observed to be 92.5\% and 84\%. Meanwhile, the network connections of discovered optimal multiple-liquid LSM models for the two datasets, on average, were reduced by 56.3\% and 60.2\% separately compared with a single LSM. Furthermore, the total number of neurons in the optimal multiple-liquid LSM models on the two datasets was reduced by 20\% with an accuracy loss of only 0.5\%.},
  archive      = {J_NEUCOM},
  author       = {Shuo Tian and Lianhua Qu and Lei Wang and Kai Hu and Nan Li and Weixia Xu},
  doi          = {10.1016/j.neucom.2021.02.076},
  journal      = {Neurocomputing},
  pages        = {174-182},
  shortjournal = {Neurocomputing},
  title        = {A neural architecture search based framework for liquid state machine design},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PFWNet: Pretraining neural network via feature jigsaw puzzle
for weakly-supervised temporal action localization. <em>NEUCOM</em>,
<em>443</em>, 162–173. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised temporal action localization is a challenging yet interesting task. Existing methods usually apply a few temporal convolutional layers or linear layers to predict classification scores, where the model capacity is limited. Inspired by counterpart researches, increasing model capacity is the potential to improve the localization performance. However, under the weakly supervised paradigm, the video-level classification label is insufficient to learn large-capacity models. The essential reason lies in that most of the inputs to action localization networks are high-level features extracted by video recognition models. In lack of off-the-shelf initialization weights, the action localization networks have to train from scratch and can only explore low-capacity models. In this work, we are inspired by the self-supervised learning paradigm and propose to learn high-quality representative models via solving the feature jigsaw puzzle task. The proposed self-supervised pretraining process can explore networks with large kernel size and deeper layers, which can provide valuable initialization to action localization networks. In the implementation, we first discover potential action scopes via calculating motion intensity. Then, we cut features into snippets and permute them into out-of-order status. We randomly discard frames for boundaries between two snippets to guide the network learning high-level representations and prevent information leakage . Moreover, because the potential permutation number factorially rises with the increase of snippet number, we select a fixed number of permutation operations via the maximum hamming distance criterion, which eases the learning process. Comprehensive experiments on two benchmarks demonstrate the efficiency of pretraining to weakly supervised action localization task, and the proposed method builds new state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Binglu Wang and Yongqiang Zhao and Yani Zhang},
  doi          = {10.1016/j.neucom.2021.02.086},
  journal      = {Neurocomputing},
  pages        = {162-173},
  shortjournal = {Neurocomputing},
  title        = {PFWNet: Pretraining neural network via feature jigsaw puzzle for weakly-supervised temporal action localization},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accessing dynamic functional connectivity using
l0-regularized sparse-smooth inverse covariance estimation from fMRI.
<em>NEUCOM</em>, <em>443</em>, 147–161. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring dynamic functional connectivity (dFC) from functional magnetic resonance imaging (fMRI) is crucial to understand the time-variant functional inter-relationships among brain regions. Because of the sparse property of functional connectivity networks, sparsity-promoting dFC estimation methods, which are mainly based on l 1 l1 -norm regularization , are gaining popularity. However, l 1 l1 -norm regularization cannot provide the maximum sparsity solution as the most natural sparsity promoting norm, the l 0 l0 -norm. But l 0 l0 -norm is seldom used to infer sparse dFC because an efficient algorithm to address the non-convexity problem of l 0 l0 -norm is lacking. In this work, we develop a new l 0 l0 -norm regularization-based inverse covariance estimation method for estimating dFC from fMRI. This novel method employs l 0 l0 -norm regularizations on both spatial and temporal scales to enhance the spatial sparsity and temporal smoothness of dFC estimates. To overcome the non-convexity of l 0 l0 -norm, we further propose an effective optimization algorithm based on the coordinate descent (CD). The performance of the proposed l 0 l0 -norm-based sparse-smooth regularization (L0-SSR) method is examined using a series of synthetic datasets concerning various types of network topology . We further apply the proposed L0-SSR method to real fMRI data recorded in block-design motor tasks from 45 participants for the exploration of task induced dFC. Results on synthetic and real-world fMRI data show that, the L0-SSR method can achieve more accurate and interpretable dFC estimates than conventional l 1 l1 -norm-based dFC estimation methods. Hence, the proposed L0-SSR method could serve as a powerful analytical tool to infer highly complex, variable, and sparse dFC patterns.},
  archive      = {J_NEUCOM},
  author       = {Li Zhang and Zening Fu and Wenwen Zhang and Gan Huang and Zhen Liang and Linling Li and Bharat B. Biswal and Vince D. Calhoun and Zhiguo Zhang},
  doi          = {10.1016/j.neucom.2021.02.081},
  journal      = {Neurocomputing},
  pages        = {147-161},
  shortjournal = {Neurocomputing},
  title        = {Accessing dynamic functional connectivity using l0-regularized sparse-smooth inverse covariance estimation from fMRI},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust hierarchical feature selection with a capped ℓ2-norm.
<em>NEUCOM</em>, <em>443</em>, 131–146. (<a
href="https://doi.org/10.1016/j.neucom.2021.03.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection methods face new challenges in large-scale classification tasks because massive categories are managed in a hierarchical structure. Hierarchical feature selection can take full advantage of the dependencies among hierarchically structured classes. However, most of the existing hierarchical feature selection methods are not robust for dealing with the inevitable data outliers, resulting in a serious inter-level error propagation problem in the following classification process. In this paper, we propose a robust hierarchical feature selection method with a capped ℓ 2 ℓ2 -norm (HFSCN), which can reduce the adverse effects of data outliers and learn relatively robust and discriminative feature subsets for the hierarchical classification process. Firstly, a large-scale global classification task is split into several small local sub-classification tasks according to the hierarchical class structure and the divide-and-conquer strategy, which makes it easy for feature selection modeling. Secondly, a capped ℓ 2 ℓ2 -norm based loss function is used in the feature selection process of each local sub-classification task to eliminate the data outliers, which can alleviate the negative effects outliers and improve the robustness of the learned feature weighted matrix. Finally, an inter-level relation constraint based on the similarity between the parent and child classes is added to the feature selection model, which can enhance the discriminative ability of the selected feature subset for each sub-classification task with the learned robust feature weighted matrix. Compared with seven traditional and state-of-art hierarchical feature selection methods, the superior performance of HFSCN is verified on 16 real and synthetic datasets .},
  archive      = {J_NEUCOM},
  author       = {Xinxin Liu and Hong Zhao},
  doi          = {10.1016/j.neucom.2021.03.002},
  journal      = {Neurocomputing},
  pages        = {131-146},
  shortjournal = {Neurocomputing},
  title        = {Robust hierarchical feature selection with a capped ℓ2-norm},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Remote sensing image super-resolution using cascade
generative adversarial nets. <em>NEUCOM</em>, <em>443</em>, 117–130. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image super-resolution (SR) is a widely used and cost-effective technology in remote sensing image processing. Deep learning-based SR methods have shown promising performance, but they are prone to losing texture details. Instead, generative adversarial nets (GAN)-based methods can generate more visually acceptable results. However, GAN-based SR methods are suffering from scene variance and uncontrollable performance of discriminators as well as unstable training. Besides, both these two methods cannot yield arbitrary high-time SR images. To solve these issues, we propose a novel SR method for remote sensing images using C ascade G enerative A dversarial N ets (CGAN) with introduction of content fidelity and scene constraint, which can achieve arbitrary high-time high-quality SR image. More specifically, the scene-constraint item is incorporated to constrain generated feature for avoiding the risk of scene change. Then, content fidelity is introduced to stabilize the training and avoid gradient vanishing. Besides, an edge enhancement module is designed to preserve edge detail and suppress the noise. CGAN with these three components has achieved higher quality SR results than other recent state-of-the-art methods. Compared with these methods, our proposed method outperformed average increments of 7.3\% SSIM, 7.3\% FSIM and 6.0\% MSIM on WHU-RS19 and NWPU-RESISC45 datasets. In addition, the evaluation of GAN-train and GAN-test gained average increments of 6.3\% and 4.5\% on the WHU-RS19 and AID datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Dongen Guo and Ying Xia and Liming Xu and Weisheng Li and Xiaobo Luo},
  doi          = {10.1016/j.neucom.2021.02.026},
  journal      = {Neurocomputing},
  pages        = {117-130},
  shortjournal = {Neurocomputing},
  title        = {Remote sensing image super-resolution using cascade generative adversarial nets},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incomplete multi-view learning via half-quadratic
minimization. <em>NEUCOM</em>, <em>443</em>, 106–116. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real applications, to deal with incomplete multi-view data, incomplete multi-view learning has experienced rapid development in recent years. Among various incomplete multi-view learning methods, a considerable number of methods were developed with the matrix factorization technique. Most of the existing matrix factorization based methods adopt the sum of squared ℓ 2 ℓ2 -norm as loss functions directly, which is known to be susceptible to value missing. To overcome this issue, we propose a new matrix factorization method, named Incomplete Multi-view Learning via Half-quadratic Minimization (IMLHM). Different from previous methods, a robust estimator based on half-quadratic minimization theory is imported to our loss function to overcome the sensitivity of ℓ 2 ℓ2 -norm to noise. The influence of bad recovered instances is decreased via the automatic weighting scheme derived from the half-quadratic minimization process, thereby improving the robustness of the proposed method. Additionally, a nuclear norm is introduced to exploit the low-rank structure of the learned representation matrix , further improving the robustness of the proposed method against to noise. An alternating iterative algorithm is developed to optimize the objective function. Comprehensive experimental results on seven data sets verify the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jiacheng Jiang and Hong Tao and Ruidong Fan and Wenzhang Zhuge and Chenping Hou},
  doi          = {10.1016/j.neucom.2021.02.043},
  journal      = {Neurocomputing},
  pages        = {106-116},
  shortjournal = {Neurocomputing},
  title        = {Incomplete multi-view learning via half-quadratic minimization},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MANet: A two-stage deep learning method for classification
of COVID-19 from chest x-ray images. <em>NEUCOM</em>, <em>443</em>,
96–105. (<a href="https://doi.org/10.1016/j.neucom.2021.03.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The early detection of infection is significant for the fight against the ongoing COVID-19 pandemic. Chest X-ray (CXR) imaging is an efficient screening technique via which lung infections can be detected. This paper aims to distinguish COVID-19 positive cases from the other four classes, including normal, tuberculosis (TB), bacterial pneumonia (BP), and viral pneumonia (VP), using CXR images. The existing COVID-19 classification researches have achieved some successes with deep learning techniques while sometimes lacking interpretability and generalization ability . Hence, we propose a two-stage classification method MANet to address these issues in computer-aided COVID-19 diagnosis. Particularly, a segmentation model predicts the masks for all CXR images to extract their lung regions at the first stage. A followed classification CNN at the second stage then classifies the segmented CXR images into five classes based only on the preserved lung regions. In this segment-based classification task , we propose the mask attention mechanism (MA) which uses the predicted masks at the first stage as spatial attention maps to adjust the features of the CNN at the second stage. The MA spatial attention maps for features calculate the percentage of masked pixels in their receptive fields, suppressing the feature values based on the overlapping rates between their receptive fields and the segmented lung regions. In evaluation, we segment out the lung regions of all CXR images through a UNet with ResNet backbone, and then perform classification on the segmented CXR images using four classic CNNs with or without MA, including ResNet34, ResNet50 , VGG16, and Inceptionv3. The experimental results illustrate that the classification models with MA have higher classification accuracy , more stable training process, and better interpretability and generalization ability than those without MA. Among the evaluated classification models, ResNet50 with MA achieves the highest average test accuracy of 96.32\%\% in three runs, and the highest one is 97.06\%\% . Meanwhile, the attention heat maps visualized by Grad-CAM indicate that models with MA make more reliable predictions based on the pathological patterns in lung regions. This further presents the potential of MANet to provide clinicians with diagnosis assistance.},
  archive      = {J_NEUCOM},
  author       = {Yujia Xu and Hak-Keung Lam and Guangyu Jia},
  doi          = {10.1016/j.neucom.2021.03.034},
  journal      = {Neurocomputing},
  pages        = {96-105},
  shortjournal = {Neurocomputing},
  title        = {MANet: A two-stage deep learning method for classification of COVID-19 from chest X-ray images},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning discrete class-specific prototypes for deep
semantic hashing. <em>NEUCOM</em>, <em>443</em>, 85–95. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep supervised hashing methods have become popular for large-scale image retrieval tasks. Recently, some deep supervised hashing methods have utilized the semantic clustering of hash codes to improve their semantic discriminative ability and polymerization. However, there exists a semantic gap between the hash codes learned from the visual features and the semantic labels , which weakens the generalization ability of these methods. In addition, the manifold structure of the hash codes in the Hamming space is ignored. In this paper, we propose a novel deep semantic hashing method by learning discrete class-specific prototypes (DCPH). Specifically, we utilize the label information to learn discrete class-specific prototypes as the intermediate semantic representations of the semantic labels, which can reduce the semantic gap between the semantic labels and the hash codes and improve the correlation between the class-specific prototypes and the hash codes. Subsequently, we construct a bipartite graph to build coarse semantic neighborhood relationship between the hash codes and the class-specific prototypes, which can preserve the manifold structural information. Moreover, we utilize the pairwise supervised information to construct a fine semantic neighborhood relationship between the hash codes. Finally, we propose a novel hashing loss based on multitask learning framework to incorporate them into an end-to-end one-stream deep neural network architecture. Experimental results on several large-scale datasets demonstrate that the proposed method can outperform state-of-the-art hashing methods.},
  archive      = {J_NEUCOM},
  author       = {Lei Ma and Xuan Li and Yu Shi and Likun Huang and Zhenghua Huang and Jinmeng Wu},
  doi          = {10.1016/j.neucom.2021.02.057},
  journal      = {Neurocomputing},
  pages        = {85-95},
  shortjournal = {Neurocomputing},
  title        = {Learning discrete class-specific prototypes for deep semantic hashing},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). URCA-GAN: UpSample residual channel-wise attention
generative adversarial network for image-to-image translation.
<em>NEUCOM</em>, <em>443</em>, 75–84. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal image-to-image translation is a challenging topic in computer vision. In image-to-image translation, an image is translated from a source domain to different target domains. For many translation tasks, the difference between the source image and the target image is only in the foreground. In this paper, we propose a novel deep-learning-based method for image-to-image translation. Our method, named URCA-GAN, is based on a generative adversarial network and it can generate images of higher quality and diversity than existing methods. We introduce Upsample Residual Channel-wise Attention Blocks (URCABs), based on ResNet and softmax channel-wise attention, to extract features associated with the foreground. The URCABs form a parallel architecture module named Upsample Residual Channel-wise Attention Module (URCAM) to merge features from the URCABs. URCAM is embedded after the decoder in the generator to regulate image generation . Experimental results and quantitative evaluations showed that our model has better performance than current state-of-the-art methods in both quality and diversity. Especially, the LPIPS , PSNR, and SSIM of URCA-GAN on CelebA dataset increase by 1.31\% , 1.66\% 1.31\%,1.66\% , and 4.74\% 4.74\% respectively, the PSNR and SSIM on RaFD dataset increase by 1.35\% 1.35\% and 6.71\% 6.71\% respectively. In addition, visualization of the features from URCABs demonstrates that our model puts emphasis on the foreground features.},
  archive      = {J_NEUCOM},
  author       = {Xuan Nie and Haoxuan Ding and Manhua Qi and Yifei Wang and Edward K. Wong},
  doi          = {10.1016/j.neucom.2021.02.054},
  journal      = {Neurocomputing},
  pages        = {75-84},
  shortjournal = {Neurocomputing},
  title        = {URCA-GAN: UpSample residual channel-wise attention generative adversarial network for image-to-image translation},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic determining optimal parameters in multi-kernel
collaborative fuzzy clustering based on dimension constraint.
<em>NEUCOM</em>, <em>443</em>, 58–74. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most cluster assignments using the traditional kernel clustering method strongly depend on the selection of the initial values. Under this scenario, directly using dimension reduction methods to deal with high-dimensional heterogeneous data in preprocessing might destroy the integrity of the original data. To overcome these limitations, this study constructs a high-dimensional kernel feature space that the high-dimensional heterogeneous data is mapped into this space. The proposed method implements kernel dimension constraint (KDC) on the mapped data, from which the data processed by the KDC forms the maximize hyper-plane data. Then we use the multi-kernel collaborative fuzzy clustering based on kernel learning to partition the maximize hyper-plane, called KL-MK-CoC, thus ensures the integrity of original data and also reduces the running time. It determines the optimal parameter in the multi-kernel clustering process , and we also embed the feature weight computation into the clustering procedure. Therefore, the combination of multiple kernels and the automatic adjustment of kernel weights renders the proposed algorithm more immune to unreliable features. Experimental results and comparisons demonstrate the excellent performance of KL-MK-CoC with its effectiveness in practice.},
  archive      = {J_NEUCOM},
  author       = {Dayu Tan and Xin Peng and Qiang Wang and Weimin Zhong and Vladimir Mahalec},
  doi          = {10.1016/j.neucom.2021.02.062},
  journal      = {Neurocomputing},
  pages        = {58-74},
  shortjournal = {Neurocomputing},
  title        = {Automatic determining optimal parameters in multi-kernel collaborative fuzzy clustering based on dimension constraint},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image super-resolution based on residually dense distilled
attention network. <em>NEUCOM</em>, <em>443</em>, 47–57. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (CNNs) have been playing an increasingly important role in image super-resolution (SR). However, if we just deepen or widen the networks, it could result in the excess of parameters and the increase of training difficulty. In this paper, we propose a residually dense distilled attention network (RDDAN) to address the problems in SR. Residual networks could make full use of the information of previous layers. In RDDAN we propose a connection block group (CBG), which is stacked in the feature extraction module of the network. CBG consists of two parts, dense enhancement network (DEN) and channel attention producing (CAP) module. First, instead of simply stacking residual blocks, DEN utilizes feature distillation with both dense concatenation and skip connection to extract deep and shallow features, which could enhance the representation ability. Second, with attention mechanism, CAP pays attention to the channel-wise association to adjust channel-wise features and restore high-frequency feature information. By evaluating the performance of results based on benchmark methods, our method achieves a more desirable performance than state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yujie Dun and Zongyang Da and Shuai Yang and Xueming Qian},
  doi          = {10.1016/j.neucom.2021.02.008},
  journal      = {Neurocomputing},
  pages        = {47-57},
  shortjournal = {Neurocomputing},
  title        = {Image super-resolution based on residually dense distilled attention network},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visible-infrared person re-identification with data
augmentation via cycle-consistent adversarial network. <em>NEUCOM</em>,
<em>443</em>, 35–46. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared person re-identification (VI-ReID) aims to search the same pedestrian images across different modalities, which is a challenging task for video surveillance. Compared to RGB-based re-identification (Re-ID) with sufficient single-modality training samples, VI-ReID suffers from imbalanced dual-modality data which affects the accuracy of deep learning classifiers. To this end, we present a image modality translation (IMT) network that learns to generate translated modality images from given modalities. It performs image modality translation by means of cycle-consistent adversarial network (CycleGAN) and serves as a data augmentation tool to restore balance to imbalanced training images. Concretely, our method mainly includes two steps: first, we train the IMT network on real images and generate target modality samples to enlarge the training dataset size and increase its diversity. Then the source images and modality transferred images are combined to train a Re-ID CNN model for improving cross-modality retrieval performance . To validate the effectiveness of our proposed approach, we perform our work over SYSU-MM01 and RegDB datasets. The experimental results indicate that our proposed method is significantly more accurate than the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Daoxun Xia and Haojie Liu and Lili Xu and Linna Wang},
  doi          = {10.1016/j.neucom.2021.02.088},
  journal      = {Neurocomputing},
  pages        = {35-46},
  shortjournal = {Neurocomputing},
  title        = {Visible-infrared person re-identification with data augmentation via cycle-consistent adversarial network},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). See more than once: Kernel-sharing atrous convolution for
semantic segmentation. <em>NEUCOM</em>, <em>443</em>, 26–34. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The state-of-the-art semantic segmentation solutions usually leverage different receptive fields via multiple parallel branches to handle objects of different sizes. However, employing separate kernels for individual branches may degrade the generalization of the network to objects with different scales, and the computational cost increases with the increase of the number of branches. To tackle this problem, we propose a novel network structure, namely Kernel-Sharing Atrous Convolution (KSAC) , where branches with different receptive fields share the same kernel, i.e., let a single kernel ‘see’ the input feature maps more than once with different receptive fields. Experiments conducted on the benchmark PASCAL VOC 2012 dataset show that our proposed sharing strategy can not only boost the network’s generalization and representation abilities but also reduce the computational cost significantly. Specifically, on the validation set, when compared with DeepLabv3+, about 2.7G FLOPs and 12.7G FLOPs are saved for output stride = 16 and 8 respectively. In addition, different from the widely used ASPP structure, our proposed KSAC is able to further improve the mIOU by taking benefit of wider context with larger atrous rates. Finally, our KSAC achieves mIOUs of 88.1\%, 45.47\% and 80.7\% on the PASCAL VOC 2012 test set (Everingham et al., 2009), ADE20K dataset (Zhou et al., 2017) and Cityscapes datasets (Marius et al., 2016), respectively. Our full code will be released on Github: https://github.com/edwardyehuang/iSeg.},
  archive      = {J_NEUCOM},
  author       = {Ye Huang and Qingqing Wang and Wenjing Jia and Yue Lu and Yuxin Li and Xiangjian He},
  doi          = {10.1016/j.neucom.2021.02.091},
  journal      = {Neurocomputing},
  pages        = {26-34},
  shortjournal = {Neurocomputing},
  title        = {See more than once: Kernel-sharing atrous convolution for semantic segmentation},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A binary harmony search algorithm as channel selection
method for motor imagery-based BCI. <em>NEUCOM</em>, <em>443</em>,
12–25. (<a href="https://doi.org/10.1016/j.neucom.2021.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Channel selection is a key topic in brain-computer interface (BCI). Task-irrelevant and redundant channels used in BCI may lead to low classification accuracy , high computational complexity , and inconvenience for application. By selecting optimal channels, the performance of BCI could enhance significantly. In this paper, a new binary harmony search (BHS) is proposed to select the optimal channel sets and optimize the system accuracy. The BHS is implemented on the training data sets to select the optimal channels and the test data sets are used to evaluate the classification performance on the selected channels. The sparse representation-based classification, linear discriminant analysis , and support vector machine are performed on the common spatial pattern (CSP) features for motor imagery (MI) classification. Two public EEG datasets are employed to validate the proposed BHS method. The paired t -test is conducted on the test classification performance between the BHS and traditional CSP with all channels. The results reveal that the proposed BHS method significantly improved classification accuracy as compared to the conventional CSP method (p &lt; 0.05). This study proposed the BHS method to select the optimal channels in MI -based BCI. On the one hand, the results confirm the validity of the BHS algorithm as a channel selection method for motor imagery data. On the other hand, the BHS method with costing shorter computation time relatively yields a better average test accuracy than the steady-state genetic algorithms. The proposed method could significantly improve the practicability and convenience of the BCI system.},
  archive      = {J_NEUCOM},
  author       = {Bin Shi and Quan Wang and Shuai Yin and Zan Yue and Yaping Huai and Jing Wang},
  doi          = {10.1016/j.neucom.2021.02.051},
  journal      = {Neurocomputing},
  pages        = {12-25},
  shortjournal = {Neurocomputing},
  title        = {A binary harmony search algorithm as channel selection method for motor imagery-based BCI},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic group consensus for delayed heterogeneous
multi-agent systems in cooperative-competitive networks via pinning
control. <em>NEUCOM</em>, <em>443</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distinguished from the stationary group consensus problem, in this paper, the dynamic group consensus for a class of heterogeneous multi-agent systems under the influence of input time delays is investigated. A novel dynamic group consensus protocol is designed, where the coexisted cooperation and competition interaction relationships among the agents are considered. Two cases including identical and diverse input time delays are discussed, respectively. Based on matrix theory, system stability theory and pinning control strategy, some sufficient conditions for the heterogeneous systems are established to achieve dynamic group consensus asymptotically. The obtained results reveal that the achievement of systems’ dynamic group consensus is related to systems control parameters, the in-degree and input time delays of the agents. Finally, the effectiveness of our theoretical results is verified by some numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Lianghao Ji and Shuo Tong and Huaqing Li},
  doi          = {10.1016/j.neucom.2021.02.066},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Dynamic group consensus for delayed heterogeneous multi-agent systems in cooperative-competitive networks via pinning control},
  volume       = {443},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Diagnosis of inter-turn short circuit of permanent magnet
synchronous motor based on deep learning and small fault samples.
<em>NEUCOM</em>, <em>442</em>, 348–358. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An efficient and accurate method based on a conditional generative adversarial net (CGAN) and an optimized sparse auto encoder (OSAE) is proposed to detect the inter-turn short circuit (ITSC) problem for permanent magnet synchronous motors (PMSMs). In order to achieve an accurate detection of the ITSC, the CGAN is adopted to augment the few fault samples, and a noise injection strategy is applied to enhance the generalization ability of the network in the framework of the OSAE. Specifically, we made a combination of two types of signals to create a training set that is augmented by the CGAN, and the parameters of the OSAE are determined by the training process of networks. The experimental results indicate that the proposed method for the fault diagnosis of this fault achieves high accuracy 98.9\%.},
  archive      = {J_NEUCOM},
  author       = {Yuanjiang Li and Yanbo Wang and Yi Zhang and Jinglin Zhang},
  doi          = {10.1016/j.neucom.2020.04.160},
  journal      = {Neurocomputing},
  pages        = {348-358},
  shortjournal = {Neurocomputing},
  title        = {Diagnosis of inter-turn short circuit of permanent magnet synchronous motor based on deep learning and small fault samples},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised adversarial domain adaptation with similarity
diffusion for person re-identification. <em>NEUCOM</em>, <em>442</em>,
337–347. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the scarcity of human identities labels, unsupervised person re-identification (re-ID) draws much attention recently, which attempts to learn discriminative person representation without labels. Domain adaptation based methods utilize the labeled sample in source domain and transfer the knowledge to the unlabeled target domain. However, for person re-ID, no identities overlapping between source and target domain leads to the difficulty during adaptation. To address this problem, we propose an unsupervised adversarial domain adaptation method for person re-ID which exploits the pixel level and feature level alignments. Specifically, we utilize CycleGAN to transfer the target domain style to the source domain for the pixel level, and we propose an adversarial metric adaptation method which aligns between the source domain and target domain for the feature level. We further explore the feature similarity laying on manifold structure revealed by the features through the similarity diffusion. To verify the efficacy of our proposed method, we conduct extensive experiments on three benchmark datasets: Market1501, Duke-MTMC, and MSMT17. Comparing with state-of-the-art unsupervised domain adaptation approaches, we have comparable performance on ranking metric and significant improvement on mAP metric, which validates the efficacy of the proposed technique for person re-identification tasks.},
  archive      = {J_NEUCOM},
  author       = {Geyu Tang and Xingyu Gao and Zhenyu Chen and Huicai Zhong},
  doi          = {10.1016/j.neucom.2020.12.008},
  journal      = {Neurocomputing},
  pages        = {337-347},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised adversarial domain adaptation with similarity diffusion for person re-identification},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). New results on finite-time stability for fractional-order
neural networks with proportional delay. <em>NEUCOM</em>, <em>442</em>,
327–336. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the finite-time stability for a class of fractional-order neural networks with proportional delay. By some analytic techniques , a generalized Gronwall integral inequality with proportional delay is established. Based on this new inequality, a criterion is derived to guarantee the finite-time stability of systems when the fractional order is between 1 and 2. Moreover, when the fractional order is between 0 and 1, a new criterion is developed to ensure the finite-time stability of systems. This criterion is experimentally proved to be less conservative than those in the previous works. Finally, the effectiveness of our criteria is supported by some numerical examples.},
  archive      = {J_NEUCOM},
  author       = {Zhanying Yang and Jie Zhang and Junhao Hu and Jun Mei},
  doi          = {10.1016/j.neucom.2021.02.082},
  journal      = {Neurocomputing},
  pages        = {327-336},
  shortjournal = {Neurocomputing},
  title        = {New results on finite-time stability for fractional-order neural networks with proportional delay},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast scene labeling via structural inference.
<em>NEUCOM</em>, <em>442</em>, 317–326. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene labeling or parsing aims to assign pixelwise semantic labels for an input image. Existing CNN-based models cannot leverage the label dependencies, while RNN-based models predict labels within the local context. In this paper, we propose a fast LSTM scene labeling network via structural inference. A minimum spanning tree is used to build the image structure for constructing semantic relationships . This structure allows efficient generation of direct parent–child dependencies for arbitrary levels of superpixels , and thus structural relationships can be learned with LSTM . In particular, we propose a bi-directional recurrent network to model the information flow along the parent–child path. In this way, the recurrent units in both coarse and fine levels can mutually transfer the global and local context information in the entire image structure. The proposed network is extremely fast, and it is 2.5 × × faster than the state-of-the-art RNN-based models. Extensive expseriments demonstrate that the proposed method provides a significant improvement in learning the label dependencies, and it outperforms state-of-the-art methods on different benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Huaidong Zhang and Chu Han and Xiaodan Zhang and Yong Du and Xuemiao Xu and Guoqiang Han and Jing Qin and Shengfeng He},
  doi          = {10.1016/j.neucom.2020.12.134},
  journal      = {Neurocomputing},
  pages        = {317-326},
  shortjournal = {Neurocomputing},
  title        = {Fast scene labeling via structural inference},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid collaborative recommendation of co-embedded item
attributes and graph features. <em>NEUCOM</em>, <em>442</em>, 307–316.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, personalized recommendation systems have attracted much attention from multiple disciplines for recommending interested products and services to users. Recommendation accentuates both the importance of feature learning tasks and the challenges posed by the sparsity of rating matrix. A common method for addressing the sparsity problem is to extend the feature space by the attributes of users and/or items. However, there are two main drawbacks in most existing recommendation methods. The first is the high computational cost of most existing recommendation models when using additional information from users and/or items to expand the feature space. The second problem is that it is difficult to obtain user additional information due to the high cost of acquiring tag knowledge and the increase in user privacy awareness. In this paper, we propose a novel and simple model to address the abovementioned issues, which employs a semi-autoencoder to co-embed the attributes and the graph features of the items for rating prediction (short for Item-Agrec). More specifially, a semi-autoencoder is introduced to learn the hidden nonlinear features of items for achieving a low computational cost, and thus the proposed Item-Agrec model can flexibly use side information from different sources. Meanwhile, in the case that it is not easy to obtain the user’s additional information, we take the item’s graph features and attributes into consideration for improving the accuracy of recommendation. Experiments on several real-world datasets demonstrate the effectiveness of the proposed Item-Agrec compared with state-of-the-art attribute-aware and content-aware methods.},
  archive      = {J_NEUCOM},
  author       = {Bingbing Dong and Yi Zhu and Lei Li and Xindong Wu},
  doi          = {10.1016/j.neucom.2021.01.129},
  journal      = {Neurocomputing},
  pages        = {307-316},
  shortjournal = {Neurocomputing},
  title        = {Hybrid collaborative recommendation of co-embedded item attributes and graph features},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-paced data augmentation for training neural networks.
<em>NEUCOM</em>, <em>442</em>, 296–306. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data augmentation is widely used for machine learning ; however, an effective method to apply data augmentation has not been established even though it includes several factors that should be tuned carefully. One such factor is sample suitability, which involves selecting samples that are suitable for data augmentation. A typical method that applies data augmentation to all training samples disregards sample suitability, which may reduce classifier performance. To address this problem, we propose the self-paced augmentation (SPA) to automatically and dynamically select suitable samples for data augmentation when training a neural network . The proposed method mitigates the deterioration of generalization performance caused by ineffective data augmentation. We discuss two reasons the proposed SPA works relative to curriculum learning and desirable changes to loss function instability. Experimental results demonstrate that the proposed SPA can improve the generalization performance , particularly when the number of training samples is small. In addition, the proposed SPA outperforms the state-of-the-art RandAugment method.},
  archive      = {J_NEUCOM},
  author       = {Tomoumi Takase and Ryo Karakida and Hideki Asoh},
  doi          = {10.1016/j.neucom.2021.02.080},
  journal      = {Neurocomputing},
  pages        = {296-306},
  shortjournal = {Neurocomputing},
  title        = {Self-paced data augmentation for training neural networks},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Structured discriminative tensor dictionary learning for
unsupervised domain adaptation. <em>NEUCOM</em>, <em>442</em>, 281–295.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation aims at learning a classification model robust to data distribution shift between a labeled source domain and an unlabeled target domain. Most existing approaches have overlooked the multi-dimensional nature of visual data, building classification models in vector space. Meanwhile, the issue of limited training samples is rarely considered by previous methods, yet it is ubiquitous in practical visual applications. In this paper, we develop a structured discriminative tensor dictionary learning method (SDTDL), which enables domain matching in tensor space. SDTDL produces disentangled and transferable representations by explicitly separating domain-specific factor and class-specific factor in data. Classification is achieved based on sample reconstruction fidelity and distribution alignment, which is seamlessly integrated into tensor dictionary learning. We evaluate SDTDL on cross-domain object and digit recognition tasks, paying special attention to the scenarios of limited training samples and test beyond training sample set. Experimental results show that our method outperforms existing mainstream shallow approaches and representative deep learning methods by a significant margin.},
  archive      = {J_NEUCOM},
  author       = {Songsong Wu and Yan Yan and Hao Tang and Jianjun Qian and Jian Zhang and Yuning Dong and Xiao-Yuan Jing},
  doi          = {10.1016/j.neucom.2021.01.111},
  journal      = {Neurocomputing},
  pages        = {281-295},
  shortjournal = {Neurocomputing},
  title        = {Structured discriminative tensor dictionary learning for unsupervised domain adaptation},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble of diluted attractor networks with optimized
topology for fingerprint retrieval. <em>NEUCOM</em>, <em>442</em>,
269–280. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The present study analyzes the retrieval capacity of an Ensemble of diluted Attractor Neural Networks for real patterns (i.e., non-random ones), as it is the case of human fingerprints. We explore the optimal number of Attractor Neural Networks in the ensemble to achieve a maximum fingerprint storage capacity. The retrieval performance of the ensemble is measured in terms of the network connectivity structure, by comparing 1D ring to 2D cross grid topologies for the random shortcuts ratio. Given the nature of the network ensemble and the different characteristics of patterns, an optimization can be carried out considering how the pattern subsets are assigned to the ensemble modules. The ensemble specialization splitting into several modules of attractor networks is explored with respect to the activities of patterns and also in terms of correlations of the subsets of patterns assigned to each module in the ensemble network.},
  archive      = {J_NEUCOM},
  author       = {Mario González and Ángel Sánchez and David Dominguez and Francisco B. Rodríguez},
  doi          = {10.1016/j.neucom.2021.02.033},
  journal      = {Neurocomputing},
  pages        = {269-280},
  shortjournal = {Neurocomputing},
  title        = {Ensemble of diluted attractor networks with optimized topology for fingerprint retrieval},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Heterogeneous graph reasoning for knowledge-grounded
medical dialogue system. <em>NEUCOM</em>, <em>442</em>, 260–268. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Beyond the common difficulties faced in task-oriented dialogue system , medical dialogue has recently attracted increasing attention due to its huge application potential while posing more challenges in reasoning over medical domain knowledge and logic. Existing works resort to neural language models for dialogue embedding and neglect the explicit logical reasoning, leading to poor explainable and generalization ability . In this work, we propose an explainable Heterogeneous Graph Reasoning (HGR) model to unify the relational dialogue context understanding and entity-correlation reasoning into a heterogeneous graph structure. HGR encodes entity context according to the corresponding utterance and deduces next response after fusing the underlying medical knowledge with entity context by attentional graph propagation. To push forward the future research on expert-sensitive task-oriented dialogue system , we first release a large-scale Medical Dialogue Consultant benchmark (MDG-C) with 16 Gastrointestinal diseases for evaluating consultant capability and a Medical Dialogue Diagnosis benchmark (MDG-D) with 6 diseases for measuring diagnosis capability of models, respectively. Extensive experiments on both MDG-C and MDG-D benchmarks demonstrate the superiority of our HGR over state-of-the-art knowledge grounded approaches in general fields of medical dialogue system.},
  archive      = {J_NEUCOM},
  author       = {Wenge Liu and Jianheng Tang and Xiaodan Liang and Qingling Cai},
  doi          = {10.1016/j.neucom.2021.02.021},
  journal      = {Neurocomputing},
  pages        = {260-268},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous graph reasoning for knowledge-grounded medical dialogue system},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Fusion layer attention for image-text matching.
<em>NEUCOM</em>, <em>442</em>, 249–259. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image-text matching aims to find the relationship between image and text data and to establish a connection between them. The main challenge of image-text matching is the fact that images and texts have different data distributions and feature representations. Current methods for image-text matching fall into two basic types: methods that map image and text data into a common space and then use distance measurements and methods that treat image-text matching as a classification problem. In both cases, the two data modes used are image and text data. In our method, we create a fusion layer to extract intermediate modes, thus improving the image-text processing results. We also propose a concise way to update the loss function that makes it easier for neural networks to handle difficult problems. The proposed method was verified on the Flickr30K and MS-COCO datasets and achieved superior matching results compared to existing methods.},
  archive      = {J_NEUCOM},
  author       = {Depeng Wang and Liejun Wang and Shiji Song and Gao Huang and Yuchen Guo and Shuli Cheng and Naixiang Ao and Anyu Du},
  doi          = {10.1016/j.neucom.2021.01.124},
  journal      = {Neurocomputing},
  pages        = {249-259},
  shortjournal = {Neurocomputing},
  title        = {Fusion layer attention for image-text matching},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperspectral image classification with discriminative
manifold broad learning system. <em>NEUCOM</em>, <em>442</em>, 236–248.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has been proved that hyperspectral image (HSI) classification task benefits from introducing additional spatial information. However, how to classify high-dimensional hyperspectral images under the condition of limited training samples is still a challenge. In this paper, we propose a hyperspectral image classification framework based on discriminant manifold broad learning system (DMBLS). We introduce the manifold structure and discriminant information of the data samples as prior knowledge into broad learning system (BLS), which effectively solves the problem of insufficient learning caused by BLS with limited training samples. Firstly we construct two different types of manifold structures for class modelling: the intra-class manifold structures and the inter-class ones. Secondly, we integrate these local discriminant manifold structures to build a manifold regularization framework. Finally, we add this framework to the DMBLS via minimizing the intra-class manifold structures, while maximizing the inter-class ones. And we think this operation can optimize the projection direction of output weights in the DMBLS, enhancing the discrimination ability of these weights. Experimental results on three benchmark HSI datasets show that DMBLS can effectively improve the classification accuracy of hyperspectral images under the condition of limited training samples.},
  archive      = {J_NEUCOM},
  author       = {Yonghe Chu and Hongfei Lin and Liang Yang and Shichang Sun and Yufeng Diao and Changrong Min and Xiaochao Fan and Chen Shen},
  doi          = {10.1016/j.neucom.2021.01.120},
  journal      = {Neurocomputing},
  pages        = {236-248},
  shortjournal = {Neurocomputing},
  title        = {Hyperspectral image classification with discriminative manifold broad learning system},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gradient compensation traces based temporal difference
learning. <em>NEUCOM</em>, <em>442</em>, 221–235. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For online updates and data efficiency, forward-view algorithms are transformed into backward-views, such as temporal difference learning (TD) and its control versions, by eligibility traces. Existing researches on eligibility traces, such as TD( λ λ ) and true-online TD( λ λ ), mainly focus on the equivalence between forward-views and backward-views. However, the choice of λ λ refers to the time scope of the credit-assignment, and a small λ λ accelerates the decay of credit over the time. This paper takes a different implementation of the backward-view named gradient compensation traces (GCT). GCT compensates the difference between a bootstrapping estimated gradient and the true gradient online to remove the extra decay of the credit. Based on GCT, the corresponding temporal difference learning (gradient compensation TD , GCTD) is proved to converge conditionally. The sensitivity of GCTD’s hyper-parameter is analyzed in the nonlinear long-corridor and linear random-walk task. The proposed algorithm is comparable with true-online TD( λ λ ) in the basic Mountain Car task, and outperforms the baselines in the reward sparse setting.},
  archive      = {J_NEUCOM},
  author       = {Wang Bi and Li Xuelian and Gao Zhiqiang and Chen Yang},
  doi          = {10.1016/j.neucom.2021.02.042},
  journal      = {Neurocomputing},
  pages        = {221-235},
  shortjournal = {Neurocomputing},
  title        = {Gradient compensation traces based temporal difference learning},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Containment control in fractional-order multi-agent systems
with intermittent sampled data over directed networks. <em>NEUCOM</em>,
<em>442</em>, 209–220. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The containment control problems of fractional order multi-agent systems (FOMASs) over directed networks are discussed in this paper. Firstly, two distributed intermittent sampled data control (ISDC) protocols which can reduce controllers’ update rates and work hours, are introduced. Subsequently, some necessary and sufficient containment conditions are derived by virtue of Laplace transform and stability theory. The containment conditions reveal the relations among the fractional orders, sampling periods, communication constraints, coupling strengths and network topologies . Finally, two numerical experiments are presented to validate the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Di Wu and Qing An and Yaping Sun and Yifan Liu and Housheng Su},
  doi          = {10.1016/j.neucom.2021.01.136},
  journal      = {Neurocomputing},
  pages        = {209-220},
  shortjournal = {Neurocomputing},
  title        = {Containment control in fractional-order multi-agent systems with intermittent sampled data over directed networks},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). L2AE-d: Learning to aggregate embeddings for few-shot
learning with meta-level dropout. <em>NEUCOM</em>, <em>442</em>,
200–208. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning focuses on learning a new visual concept with very limited labelled examples. A successful approach to tackle this problem is to compare the similarity between examples in a learned metric space based on convolutional neural networks. However, existing methods typically suffer from meta-level overfitting due to the limited amount of training tasks and do not normally consider the importance of the convolutional features of different examples within the same channel. To address these limitations, we make the following two contributions: (a) We propose a novel meta-learning approach for aggregating useful convolutional features and suppressing noisy ones based on a channel-wise attention mechanism to improve class representations. The proposed model does not require fine-tuning and can be trained in an end-to-end manner. The main novelty lies in incorporating a shared weight generation module that learns to assign different weights to the feature maps of different examples within the same channel. (b) We also introduce a simple meta-level dropout technique that reduces meta-level overfitting in several few-shot learning approaches. In our experiments, we find that this simple technique significantly improves the performance of the proposed method as well as various state-of-the-art meta-learning algorithms. Applying our method to few-shot image recognition using Omniglot and miniImageNet datasets shows that it is capable of delivering a state-of-the-art classification performance.},
  archive      = {J_NEUCOM},
  author       = {Heda Song and Mercedes Torres Torres and Ender Özcan and Isaac Triguero},
  doi          = {10.1016/j.neucom.2021.02.024},
  journal      = {Neurocomputing},
  pages        = {200-208},
  shortjournal = {Neurocomputing},
  title        = {L2AE-D: Learning to aggregate embeddings for few-shot learning with meta-level dropout},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic segmentation of organs-at-risk from head-and-neck
CT using separable convolutional neural network with
hard-region-weighted loss. <em>NEUCOM</em>, <em>442</em>, 184–199. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.135">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of Organs-at-Risk (OAR) from Head and Neck (HAN) Computed Tomography (CT) images with uncertainty information is critical for effective planning of radiation therapy for Nasopharyngeal Carcinoma (NPC) treatment. Despite the state-of-the-art performance achieved by Convolutional Neural Networks (CNNs) for the segmentation task , existing methods do not provide uncertainty estimation of the segmentation results for treatment planning, and their accuracy is still limited by the low contrast of soft tissues in CT, highly imbalanced sizes of OARs and large inter-slice spacing. To address these problems, we propose a novel framework for accurate OAR segmentation with reliable uncertainty estimation . First, we propose a Segmental Linear Function (SLF) to transform the intensity of CT images to make multiple organs more distinguishable than existing simple window width/level-based methods. Second, we introduce a novel 2.5D network (named as 3D-SepNet) specially designed for dealing with clinic CT scans with anisotropic spacing. Thirdly, we propose a novel hardness-aware loss function that pays attention to hard voxels for accurate segmentation. We also use an ensemble of models trained with different loss functions and intensity transforms to obtain robust results, which also leads to segmentation uncertainty without extra efforts. Our method won the third place of the HAN OAR segmentation task in StructSeg 2019 challenge and it achieved weighted average Dice of 80.52\% and 95\% 95\% Hausdorff Distance of 3.043 mm. Experimental results show that 1) our SLF for intensity transform helps to improve the accuracy of OAR segmentation from CT images; 2) With only 1/3 parameters of 3D UNet, our 3D-SepNet obtains better segmentation results for most OARs; 3) The proposed hard voxel weighting strategy used for training effectively improves the segmentation accuracy ; 4) The segmentation uncertainty obtained by our method has a high correlation to mis-segmentations, which has a potential to assist more informed decisions in clinical practice. Our code is available at https://github.com/HiLab-git/SepNet .},
  archive      = {J_NEUCOM},
  author       = {Wenhui Lei and Haochen Mei and Zhengwentai Sun and Shan Ye and Ran Gu and Huan Wang and Rui Huang and Shichuan Zhang and Shaoting Zhang and Guotai Wang},
  doi          = {10.1016/j.neucom.2021.01.135},
  journal      = {Neurocomputing},
  pages        = {184-199},
  shortjournal = {Neurocomputing},
  title        = {Automatic segmentation of organs-at-risk from head-and-neck CT using separable convolutional neural network with hard-region-weighted loss},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrating knowledge-based sparse representation for image
detection. <em>NEUCOM</em>, <em>442</em>, 173–183. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image detection has been a primary step and widely adopted in diverse domains, such as autopilot, risk inspection, and robot vision. The main body of current models for image detection treat this task as the feature-based recognition of multiple independent objects. The adoption of semantic relationships , which can provide auxiliary information for joint recognition, is still in its early stage. Inspired by deep dictionary learning, this work proposes a novel framework named SEGNN , which aims at finding and using the sparse representation knowledge to improve the result of image detection. According to this design, both the efficiency and rationality of reasoning over semantic relationships are well captured. The framework includes an improved GGNN model. It can efficiently extract the semantic informations from the image, and map it to sparse vector. The framework also applies a novel SimRank method, to justify the rationality of the semantic reasoning. The performance of the framework is validated extensively on two datasets Visual Genome (VG) and COCO. The experimental results and case study have demonstrated the effectiveness of the proposed framework.},
  archive      = {J_NEUCOM},
  author       = {Guangxi Lu and Ling Tian and Xu Zheng and Bei Hui},
  doi          = {10.1016/j.neucom.2020.09.089},
  journal      = {Neurocomputing},
  pages        = {173-183},
  shortjournal = {Neurocomputing},
  title        = {Integrating knowledge-based sparse representation for image detection},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HELP: An LSTM-based approach to hyperparameter exploration
in neural network learning. <em>NEUCOM</em>, <em>442</em>, 161–172. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperparameter selection is very important for the success of deep neural network training. Random search of hyperparameters for deep neural networks may take a long time to converge and yield good results because the training of deep neural networks with a huge number of parameters for every selected hyperparameter is very time-consuming. In this work, we propose the Hyperparameter Exploration LSTM-Predictor (HELP) which is an improved random exploring method using a probability-based exploration with an LSTM-based prediction. The HELP has a higher probability to find a better hyperparameter with less time. The HELP uses a series of hyperparameters in a time period as input and predicts the fitness values of these hyperparameters. Then, exploration directions in the hyperparameter space yielding higher fitness values will have higher probabilities to be explored in the next turn. Experimental results for training both the Generative Adversarial Net and the Convolution Neural Network show that the HELP finds hyperparameters yielding better results and converges faster.},
  archive      = {J_NEUCOM},
  author       = {Wendi Li and Wing W. Y. Ng and Ting Wang and Marcello Pelillo and Sam Kwong},
  doi          = {10.1016/j.neucom.2020.12.133},
  journal      = {Neurocomputing},
  pages        = {161-172},
  shortjournal = {Neurocomputing},
  title        = {HELP: An LSTM-based approach to hyperparameter exploration in neural network learning},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A memory neural system built based on spiking neural
network. <em>NEUCOM</em>, <em>442</em>, 146–160. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Memory’s mechanism has always been the most tempting treasure for researchers. Many contributions have been delivered to unearth the mystery of memory. In this paper, we present our effort at attempting to reveal the mechanism of memory through computational neuroscience approach. We have constructed a structural efficient memory neural system with three modules, which could simulate the process where new memory is generated and kept and could be extracted. We have proved that new connections grow during the memory forming phase are vital for the keeping of memory. We propose that neurons in the memory layer could be divided into two kinds of neurons: neurons serve as interfaces for memory, and neurons serve as the main body for the keeping of memory. We also provide a method to regulate the memory layer to avoid epileptic states and work properly. The result shows our method could generate memory neural system with reasonably high memory extraction accuracy, high energy efficiency, and high robustness for different input stimulations.},
  archive      = {J_NEUCOM},
  author       = {Hu He and Qilin Wang and Xu Yang and Yunlin Lei and Jian Cai and Ning Deng},
  doi          = {10.1016/j.neucom.2021.02.044},
  journal      = {Neurocomputing},
  pages        = {146-160},
  shortjournal = {Neurocomputing},
  title        = {A memory neural system built based on spiking neural network},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel semi-supervised ensemble algorithm using a
performance-based selection metric to non-stationary data streams.
<em>NEUCOM</em>, <em>442</em>, 125–145. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we consider the semi-supervised data stream classification problems. Most of the semi-supervised learning algorithms suffer from a proper selection metric to select from the newly-labeled data points through the training procedure. These approaches mainly employ the probability estimation of the underlying base learners to their predictions as a selection metric, which is not optimal in many cases. Handling different kinds of concept drifts is another issue in data streams. Considering these issues, we propose a novel Semi-Supervised Ensemble algorithm using a Performance-Based Selection metric to data streams, named SSE-PBS. The proposed selection metric is based on a pseudo-accuracy and energy regularization factor. We show that SSE-PBS improves classification performance and handles different kinds of concept drifts. The proposed algorithm can also employ any kind of incremental base learners. In the experiments, we report the results of two base learners on synthetic and real-world datasets. The experiments show that SSE-PBS significantly improves the classification performance of the used underlying base learners. Furthermore, we compare the results to the state-of-the-art supervised and semi-supervised approaches in data streams. The results further show that SSE-PBS outperforms the other methods when there is a small portion of labeled instances.},
  archive      = {J_NEUCOM},
  author       = {Shirin Khezri and Jafar Tanha and Ali Ahmadi and Arash Sharifi},
  doi          = {10.1016/j.neucom.2021.02.031},
  journal      = {Neurocomputing},
  pages        = {125-145},
  shortjournal = {Neurocomputing},
  title        = {A novel semi-supervised ensemble algorithm using a performance-based selection metric to non-stationary data streams},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Auto-VirtualNet: Cost-adaptive dynamic architecture search
for multi-task learning. <em>NEUCOM</em>, <em>442</em>, 116–124. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-task learning (MTL) improves learning efficiency by solving multiple tasks simultaneously compared to multiple instances of individual learning. However, despite its benefits, there still remain several major challenges: first, negative interference can reduce the learning efficiency when the number of tasks is high or the tasks are of limited relevance. Second, exploring an optimal model structure manually is quite restricted. Last but not least, offering cost-adaptive solutions has not been addressed in the MTL regime. In spite of its notable merits, the combined problem has not been well discussed. In this work, we propose a novel MTL approach to address the combinatorial problem while minimizing memory consumption. The proposed method discovers multiple network models dynamically from a pool of candidate models, and produces a set of widely distributed solutions with respect to different computational costs for each task. For the diversity of candidate models, we modularize the given backbone architecture that generates basic building blocks and then construct a hierarchical structure based on the building blocks . The proposed method is trained to optimize both task performance and computational costs of selected models. The proposed method dynamically generates optimal networks for each task and offers significant performance improvements over existing MTL approaches in a range of experiments.},
  archive      = {J_NEUCOM},
  author       = {Eunwoo Kim and Chanho Ahn and Songhwai Oh},
  doi          = {10.1016/j.neucom.2021.02.050},
  journal      = {Neurocomputing},
  pages        = {116-124},
  shortjournal = {Neurocomputing},
  title        = {Auto-VirtualNet: Cost-adaptive dynamic architecture search for multi-task learning},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-label feature selection with local discriminant model
and label correlations. <em>NEUCOM</em>, <em>442</em>, 98–115. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-label learning, feature selection is an essential preprocessing module , which can be exploited a more compact and precise representation of instances. Most of existing multi-label feature selection methods are either converted into multiple single-label feature selection methods or directly utilize half-baked label information, thus it is difficult for them to obtain a discriminative feature subset across multiple labels. To tackle this problem, we propose multi-label feature selection with local discriminant model and label correlations. First, for each instance, a local clique comprising this instance and its neighboring instances is constructed, and a local discriminant model for each local clique is integrated globally to evaluate the clustering performance of all instances. Second, in terms of clustering results , we explore high-order label correlations to reduce the impact of half-baked label information. Finally, we combine l 2,1 -norm regularization to design the objective function to achieve multi-label feature selection. Comprehensive experiments are conducted on twelve real-world multi-label data sets, and results demonstrate the effectiveness of the proposed method in comparison with several representative methods.},
  archive      = {J_NEUCOM},
  author       = {Yuling Fan and Jinghua Liu and Wei Weng and Baihua Chen and Yannan Chen and Shunxiang Wu},
  doi          = {10.1016/j.neucom.2021.02.005},
  journal      = {Neurocomputing},
  pages        = {98-115},
  shortjournal = {Neurocomputing},
  title        = {Multi-label feature selection with local discriminant model and label correlations},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unbiased FIR, kalman, and game theory h∞ filtering under
bernoulli distributed random delays and packet dropouts.
<em>NEUCOM</em>, <em>442</em>, 89–97. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is known that due to uncertain delays and missing data wireless sensor networks (WSNs) may incur a significant loss in performance. In this work, we solve the problem in discrete-time state-space by developing the unbiased finite impulse response (UFIR) filter, Kalman filter (KF), and game theory H ∞ H∞ filter for systems with randomly delayed data and packet dropouts . The binary Bernoulli distribution is adopted for WSN channels to model the arrival data with supposedly known delay-time probability. The effectiveness of the UFIR filter, KF, and H ∞ H∞ filter is compared experimentally in terms of accuracy and robustness employing the GPS-measured vehicle coordinates transmitted with latency over WSN.},
  archive      = {J_NEUCOM},
  author       = {Karen Uribe-Murcia and Yuriy S. Shmaliy and José A. Andrade-Lucio},
  doi          = {10.1016/j.neucom.2021.01.127},
  journal      = {Neurocomputing},
  pages        = {89-97},
  shortjournal = {Neurocomputing},
  title        = {Unbiased FIR, kalman, and game theory h∞ filtering under bernoulli distributed random delays and packet dropouts},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient activation functions for embedded inference
engines. <em>NEUCOM</em>, <em>442</em>, 73–88. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of the choice of the activation function for training and inferencing in machine learning cannot be overemphasized. Activation functions can influence network training convergence, performance accuracy, and can make training and inference stages computationally expensive. We introduce a family of square-based activation functions for embedded devices that consume only one instruction cycle with the potential of being resource efficient when constructed in silicon. We show that the proposed family are computationally efficient when compared with exponential-based non-linearities. The family includes functions for deep neural network architectures, support vector machines , recurrent neural networks , and others. We demonstrate the universal ability of the square-based family of activation functions on a variety of neural network architectures. We analyze the hidden representations of our trained multilayer perceptron network in an attempt to explain the performance gains, and speed-up observed when using square non-linearities. Speed-up was recorded with the quadratic-based kernel transformation on support vector machines . We record higher performance accuracy for recurrent neural network architectures and logistic regression using this family. Speed up was also recorded for implementation on Intel CPU and ARM processors. This family will find particular importance in low-end hardware devices with limited hardware capabilities.},
  archive      = {J_NEUCOM},
  author       = {Adedamola Wuraola and Nitish Patel and Sing Kiong Nguang},
  doi          = {10.1016/j.neucom.2021.02.030},
  journal      = {Neurocomputing},
  pages        = {73-88},
  shortjournal = {Neurocomputing},
  title        = {Efficient activation functions for embedded inference engines},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Multi-domain few-shot image recognition with knowledge
transfer. <em>NEUCOM</em>, <em>442</em>, 64–72. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot image recognition aims to recognize novel categories with only few labeled images in each class. Existing metric-based and meta-based few-shot learning algorithms have achieved significant progress, but most methods use only visual features. And our humanity can recognize novel categories by learning from prior knowledge, such as semantic information. Based on this intuition, we propose a model that can adaptively integrate visual and semantic information to recognize novel categories. Moreover, the current few-shot learning algorithms fail to generalize to unseen domains due to the domain shift across domains. To reduce the domain shift, we use the weight imprinting strategy as it provides immediate good classification performance and initialization for any further fine-tuning in the future. And we adopt a fine-tuning strategy to simulate various feature distributions under different domains. We conduct extensive experiments to evaluate the effectiveness of the proposed model on three datasets: miniImageNet, CUB, Stanford Dogs. Experimental results demonstrate that our cross-modal scheme gets encouraging improvements in the single-domain and cross-domain few-shot classification tasks .},
  archive      = {J_NEUCOM},
  author       = {Mingxi Li and Ronggui Wang and Juan Yang and Lixia Xue and Min Hu},
  doi          = {10.1016/j.neucom.2021.01.123},
  journal      = {Neurocomputing},
  pages        = {64-72},
  shortjournal = {Neurocomputing},
  title        = {Multi-domain few-shot image recognition with knowledge transfer},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive cooperative dynamic surface control of non-strict
feedback multi-agent systems with input dead-zones and actuator
failures. <em>NEUCOM</em>, <em>442</em>, 48–63. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the consensus tracking problem for a class of nonlinear multi-agent systems (MASs) with output constraints, unmodeled dynamics, nonsymmetric input dead-zones and actuator failures under directed graphs , and proposes an adaptive cooperative neural dynamic surface control (DSC) strategy. Using the properties of invertible nonlinear mapping and Gaussian function, output constraints and non-strict feedback terms are separately dealt with. A measurable dynamic signal produced by an auxiliary first-order system is used to eliminate the influence of unmodeled dynamics on the system. Two input models of input dead-zone and actuator failure are linearized, each follower control signal is constructed via DSC. All the signals of the closed-loop system are proved to be cooperative semi-globally uniformly ultimately bounded, and all the followers can accomplish a desired consensus results. Finally, the simulation results are provided to illustrate the availability of the presented adaptive control approach.},
  archive      = {J_NEUCOM},
  author       = {Tianping Zhang and Manfei Lin and Xiaonan Xia and Yang Yi},
  doi          = {10.1016/j.neucom.2021.02.039},
  journal      = {Neurocomputing},
  pages        = {48-63},
  shortjournal = {Neurocomputing},
  title        = {Adaptive cooperative dynamic surface control of non-strict feedback multi-agent systems with input dead-zones and actuator failures},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integral-based event-triggered fault estimation and
impulsive fault-tolerant control for networked control systems applied
to underwater vehicles. <em>NEUCOM</em>, <em>442</em>, 36–47. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the fault estimation and impulsive fault-tolerant control for networked control systems (NCSs) with via integral-based event-triggered mechanism (IETM). According to a novel IETM, a fault and state estimation observer is established as a distributed delay model. To enhance the reliability and safety of actuator fault model, an impulsive fault tolerant controller is designed to compensate the impact of actuator faults and to estimate faults online. Moreover, based on augmented Lyapunov- Kroasovskii functional (LKF), sufficient conditions to determine the global asymptotical stability for the estimation error system are presented. Furthermore, this fault estimation method based on integral-based event-triggered scheme (IETS) is applied to the underwater vehicle heading control system. The designed fault-tolerant control approach solves the problem of the actuator failure of the nonlinear underwater vehicle heading control system. Finally, numerical examples are further provided to verify the effectiveness and advantages of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Hongfei Li and Jie Pan and Xiaoyu Zhang and Junzhi Yu},
  doi          = {10.1016/j.neucom.2021.02.035},
  journal      = {Neurocomputing},
  pages        = {36-47},
  shortjournal = {Neurocomputing},
  title        = {Integral-based event-triggered fault estimation and impulsive fault-tolerant control for networked control systems applied to underwater vehicles},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convolutional neural network with median layers for
denoising salt-and-pepper contaminations. <em>NEUCOM</em>, <em>442</em>,
26–35. (<a href="https://doi.org/10.1016/j.neucom.2021.02.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a deep fully convolutional neural network with a new type of layer, named median layer, to restore images contaminated by salt-and-pepper (s&amp;p) noise. A median layer simply performs median filtering on all feature channels. By adding this kind of layer into some widely used fully convolutional deep neural networks, we develop an end-to-end network that removes extremely high-level s&amp;p noise without performing any non-trivial preprocessing tasks. Experiments show that inserting median layers into a simple fully-convolutional network with the L 2 L2 loss significantly boosts signal-to-noise ratio. Quantitative comparisons testify that our network outperforms the state-of-the-art methods with a limited amount of training data.},
  archive      = {J_NEUCOM},
  author       = {Luming Liang and Seng Deng and Lionel Gueguen and Mingqiang Wei and Xinming Wu and Jing Qin},
  doi          = {10.1016/j.neucom.2021.02.010},
  journal      = {Neurocomputing},
  pages        = {26-35},
  shortjournal = {Neurocomputing},
  title        = {Convolutional neural network with median layers for denoising salt-and-pepper contaminations},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-adjusting k nearest neighbors for continual learning
from multi-label drifting data streams. <em>NEUCOM</em>, <em>442</em>,
10–25. (<a href="https://doi.org/10.1016/j.neucom.2021.02.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Drifting data streams and multi-label data are both challenging problems. Multi-label instances may simultaneously be associated with many labels and classifiers must predict the complete set of labels. Learning from data streams requires algorithms able to learn from potentially unbounded data that is constantly changing. When multi-label data arrives as a stream, the challenges of both problems must be addressed, but additional challenges unique to the combined problem also arise. Each label may experience different concept drifts, simultaneously or distinctly, and parameter optimizations may be different for each label. In this paper we present a self-adapting algorithm for drifting, multi-label data streams, that can adapt to a variety of concepts drifts, is robust to data-level difficulties, and mitigates the necessity to tune multiple parameters. The window of retained instances self-adjusts in size to retain only the current concept, enabling efficient response to abrupt concept drift. The value k k is self-adapting for each label, relieving the necessity to tune and allowing it to change, over time, for each label individually. A novel, label-based mechanism disables individual labels that contribute to error, while another punitive measure removes erroneous instances entirely, increasing robustness to noise, concept drift and label differences. Extensive experiments on 35 multi-label streams and generators demonstrate the superiority and advantages of the self-adapting mechanisms proposed compared to existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Martha Roseberry and Bartosz Krawczyk and Youcef Djenouri and Alberto Cano},
  doi          = {10.1016/j.neucom.2021.02.032},
  journal      = {Neurocomputing},
  pages        = {10-25},
  shortjournal = {Neurocomputing},
  title        = {Self-adjusting k nearest neighbors for continual learning from multi-label drifting data streams},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive event-triggered consensus control of linear
multi-agent systems with cyber attacks. <em>NEUCOM</em>, <em>442</em>,
1–9. (<a href="https://doi.org/10.1016/j.neucom.2021.02.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the adaptive event-triggered consensus control problem for a class of linear multi-agent systems subject to cyber attacks and communication delays. To effectively alleviate unnecessary signals transmission among the agents and achieve the reasonable allocation of resources, an adaptive event-triggering scheme, whose threshold parameters are adaptively adjusted based on system performance needs, is proposed. The event-triggering scheme can achieve the discontinuous communication and significantly reduce the number of signals transmission while ensuring the desired control performance. By considering the communication scheme and consensus control protocol in a unified framework, the linear multi-agent system is reformulated as a time-delay error system. Sufficient conditions are developed to guarantee the asymptotical stability and security of time-delay error system. Moreover, a co-design for the gain of the controller and the parameters of the adaptive event-triggering scheme is provided. Finally, an example on the tunnel diode circuit system is given to show the effectiveness and advantages of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Shuo Yuan and Chengpu Yu and Jian Sun},
  doi          = {10.1016/j.neucom.2021.02.040},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Adaptive event-triggered consensus control of linear multi-agent systems with cyber attacks},
  volume       = {442},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast human action recognition network based on
spatio-temporal features. <em>NEUCOM</em>, <em>441</em>, 350–358. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence models are widely used in the field of human activity recognition , and human action recognition is an important aspect of human activity recognition . The core of human action recognition is to understand the temporal relationship between video frames. Almost all state-of-the-art methods of human action recognition in videos use optical flow. However, traditional local optical flow estimation methods areexpensive and not trained end-to-end. In this paper, we propose a fast network for human action recognition. Our purpose is to improve the efficiency of optical flow feature extraction and explore the fusion method of spatio-temporal features. For spatio-temporal features, our method combines spatial features and temporal features into fusion features . In addition, we propose CNN with OFF instead of the VGG16 network, which is used to process optical flow features to obtain abundant features. Our model only needs RGB inputs to get the state-of-the-art accuracy of 91.5\% on UCF-101, 67.9\% on HMDB51, 83.3\% on MSR Daily Activity3D, and 91.25\% on Florence 3D action, respectively. Compared with most state-of-the-art video action recognition models, our proposed model can effectively improve the accuracy of human action recognition.},
  archive      = {J_NEUCOM},
  author       = {Jie Xu and Rui Song and Haoliang Wei and Jinhong Guo and Yifei Zhou and Xiwei Huang},
  doi          = {10.1016/j.neucom.2020.04.150},
  journal      = {Neurocomputing},
  pages        = {350-358},
  shortjournal = {Neurocomputing},
  title        = {A fast human action recognition network based on spatio-temporal features},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Couple-group consensus for heterogeneous MASs under switched
topologies in cooperative-competitive systems: A hybrid pinning and
delta operator skills. <em>NEUCOM</em>, <em>441</em>, 335–349. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, pinning control and delta operator skills are applied to study couple-group consensus for heterogeneous MASs (multi-agent systems) with switched topology in cooperative-competitive networks. A new couple-group consensus agreement has been designed for this heterogeneous MASs with time delay . On the basis of delta operator and stability theory, couple-group consensus of the continuous or discrete systems can be transformed to analyze stability of a system with time lag. By using stability theory and LMI (Linear matrix inequality) technique, some meaningful results are put forward to obtain couple-group consensus of the heterogeneous MASs. In addition, these conclusions are also suitable for MASs whose switched topologies networks can’t meet the equilibrium of in-degree or can’t meet the requirements of any sub-topology with a spanning tree. In the end, some digital experiments are listed to prove the validity of the obtained achievements.},
  archive      = {J_NEUCOM},
  author       = {Xingcheng Pu and Li Ren and Yi Liu and Rui Pu},
  doi          = {10.1016/j.neucom.2020.11.013},
  journal      = {Neurocomputing},
  pages        = {335-349},
  shortjournal = {Neurocomputing},
  title        = {Couple-group consensus for heterogeneous MASs under switched topologies in cooperative-competitive systems: A hybrid pinning and delta operator skills},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HTDA: Hierarchical time-based directional attention network
for sequential user behavior modeling. <em>NEUCOM</em>, <em>441</em>,
323–334. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation is one of the most effective ways to alleviate the problem of information explosion. Recurrent Neural Network (RNN) sequential recommendation based on user preference modeling has been widely investigated recently. In this paper, a Hierarchical Time-based Directional Attention (HTDA) network is proposed to enhance sequential recommendation by applying fine-grained user intention representation and dynamic user preference representation with rich global sequential interaction features . Our analyses and results significantly differ from earlier related works in two aspects: 1) We put forward a session-level representation method, based on multi-dimensional attention mechanism, to enhance the degree of matching between the user interaction sequence and the user intention and reduce the impact of noise interaction; 2) We propose to integrate a time-based directional attention mechanism into RNN, to capture the sequential patterns of interaction sessions more effectively and improve the understanding of user dynamic preferences. The main contribution of our work is to effectively combine the accurate description of user intentions and the powerful expression of user dynamic preferences through a hierarchical attention architecture. In turn, our architecture can provide a more favorable framewrok for further enhancing the recommendation results. Extensive experiments are conducted on two public benchmark datasets, and very promising performance can be achieved with our proposed HTDA-based framework.},
  archive      = {J_NEUCOM},
  author       = {Zhenzhen Sheng and Tao Zhang and Yuejie Zhang},
  doi          = {10.1016/j.neucom.2021.02.006},
  journal      = {Neurocomputing},
  pages        = {323-334},
  shortjournal = {Neurocomputing},
  title        = {HTDA: Hierarchical time-based directional attention network for sequential user behavior modeling},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual distance adaptive multiview clustering.
<em>NEUCOM</em>, <em>441</em>, 311–322. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptively adjusting the graph, by taking the clustering capability into consideration, has become popular in graph-based clustering methods and extended to multiview clustering problem. Existing methods learn the graph from pairwise distances of the data in the original space or a linearly projected space, which requires that those representations can finely reflect the implicit data structure . However, the data structure in high-dimensional space may not always lie on a linear manifold, and this problem becomes more critical in multiview conditions. Aim at this, we propose a multiview clustering method based on adaptive graph and dual distance. Specifically, we fuse the distances computed from nonlinear embedding space and original space. An adaptive graph is then constructed based on the fused distance, and it is more reliable for multiview clustering. In our approach, the clustering result with exact number of clusters can be found without post-processing. We evaluate the proposed method on several multiview datasets, the experimental results show our approach is superior to the state-of-the-art multiview clustering methods .},
  archive      = {J_NEUCOM},
  author       = {Jichao Chen and Guang-Bin Huang},
  doi          = {10.1016/j.neucom.2021.01.132},
  journal      = {Neurocomputing},
  pages        = {311-322},
  shortjournal = {Neurocomputing},
  title        = {Dual distance adaptive multiview clustering},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous quadrotor obstacle avoidance based on dueling
double deep recurrent q-learning with monocular vision. <em>NEUCOM</em>,
<em>441</em>, 300–310. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel learning-based framework to realize quadrotor autonomous obstacle avoidance with monocular vision. The framework adopts a two-stage architecture, consisting of a sensing module and a decision module. The sensing module trained in an unsupervised manner can extract depth information from the on-board camera image. Moreover, the decision module uses dueling double deep recurrent Q-learning to eliminate the adverse effects of the on-board monocular camera’s limited observation capacity while choosing practical obstacle avoidance action. The framework has two advantages: (1) it enables the quadrotor to realize autonomous obstacle avoidance without any prior environment information or labeled datasets for training, and (2) its model can be easily updated while facing new application scenarios. The experiments in several different simulation scenes show that the trained framework outperforms a high passing rate in crowded environments and a good generalization ability for transformed scenarios.},
  archive      = {J_NEUCOM},
  author       = {Jiajun Ou and Xiao Guo and Ming Zhu and Wenjie Lou},
  doi          = {10.1016/j.neucom.2021.02.017},
  journal      = {Neurocomputing},
  pages        = {300-310},
  shortjournal = {Neurocomputing},
  title        = {Autonomous quadrotor obstacle avoidance based on dueling double deep recurrent Q-learning with monocular vision},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A multi-cue guidance network for depth completion.
<em>NEUCOM</em>, <em>441</em>, 291–299. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth completion is to predict a dense depth image from a raw sparse depth image with missing values, which is an important yet challenging problem in a myriad of vision, robotics, and multimedia applications . While previous studies have made substantial progress in this issue, most of them directly fuse RGB and depth features without considering the multiple latent cues in data. In this paper, we propose a multi-cue guidance network model for depth completion, which introduces multi-cue features to guide the regression of residual values. This network includes two major parts: multi-cue guidance structure and residual regression structure. The multi-cue guidance structure composed of two parallel convolutional sampling streams extracts features from the raw depth image and the corresponding RGB image, respectively. The extracted features are used as multi-cue guidance to combine with the depth image to feed the residual regression structure, where the estimated residual values are combined with the raw depth values to output the final dense depth values. By virtue of the multi-cue guidance and residual regression, the proposed model can leverage the multiple latent cues in the data to predict more accurate depth values. The proposed method was tested on two challenging datasets of outdoor and indoor scenes: KITTI benchmark and NYUv2 dataset. The experimental results show that the proposed method outperforms the comparison methods. Extensive ablation studies demonstrate the effectiveness of different modules in the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yongchi Zhang and Ping Wei and Nanning Zheng},
  doi          = {10.1016/j.neucom.2021.02.013},
  journal      = {Neurocomputing},
  pages        = {291-299},
  shortjournal = {Neurocomputing},
  title        = {A multi-cue guidance network for depth completion},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A hierarchical depression detection model based on vocal
and emotional cues. <em>NEUCOM</em>, <em>441</em>, 279–290. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective and efficient automatic depression diagnosis is a challenging subject in the field of affective computing . Since speech signals provide useful information for diagnosing depression, in this paper, we propose to extract deep speaker recognition (SR) and speech emotion recognition (SER) features using pretrained models, and combine the two deep speech features to take advantage of the complementary information between the vocal and emotional differences of speakers. In addition, due to the small amount of data for depression recognition and the cost sensitivity of the diagnosis results, we propose a hierarchical depression detection model, in which multiple classifiers are set up prior to a regressor to guide the prediction of depression severity. We test our method on the AVEC 2013 and AVEC 2014 benchmark databases. The results demonstrate that the fusion of deep SR and SER features can improve the prediction performance of the model. The proposed method, using only audio features, can avoid the overfitting problem and achieves better performance than the previous audio-based methods on both databases. It also provides results comparable to those of video-based and multimodal-based methods for depression detection.},
  archive      = {J_NEUCOM},
  author       = {Yizhuo Dong and Xinyu Yang},
  doi          = {10.1016/j.neucom.2021.02.019},
  journal      = {Neurocomputing},
  pages        = {279-290},
  shortjournal = {Neurocomputing},
  title        = {A hierarchical depression detection model based on vocal and emotional cues},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comment toxicity detection via a multichannel convolutional
bidirectional gated recurrent unit. <em>NEUCOM</em>, <em>441</em>,
272–278. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, toxicity identification has become the most serious problem in online communities and social networking sites . Therefore, an automatic toxic identification system needs to be developed for preventing and limiting users from these online environments. In this paper, we present a multichannel convolutional bidirectional gated recurrent unit (MCBiGRU) for detecting toxic comments in a multilabel environment. The proposed model generates word vectors using pre-trained word embeddings . Moreover, this hybrid model extracts local features with many filters and different kernel sizes to model input words with long term dependency . We then integrate multiple channels with a fully connected layer, normalization layer, and an output layer with a sigmoid activation function for predicting multilabel categories. The experimental results indicate that the proposed MCBiGRU model outperforms in terms of multilabel metrics.},
  archive      = {J_NEUCOM},
  author       = {Ashok Kumar J and Abirami S and Tina Esther Trueman and Erik Cambria},
  doi          = {10.1016/j.neucom.2021.02.023},
  journal      = {Neurocomputing},
  pages        = {272-278},
  shortjournal = {Neurocomputing},
  title        = {Comment toxicity detection via a multichannel convolutional bidirectional gated recurrent unit},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated assessment of parkinsonian finger-tapping tests
through a vision-based fine-grained classification model.
<em>NEUCOM</em>, <em>441</em>, 260–271. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Movement disorder of Parkinson’s disease (PD) is usually quantified by the Movement Disorders Society-sponsored Revision of the Unified Parkinson’s Disease Rating Scale (MDS-UPDRS) to evaluate its severity. However, the lack of well-trained experts and subjective inter-rater variability often limit an effective and objective assessment in clinical practice. Hence, developing an automated assessment method for movement disorders in PD is crucial. Here, we present a novel vision-based fine-grained action recognition model to cope with one of the most critical and challenging tasks in clinical scales: the finger-tapping test. Specifically, we establish a three-stream fine-grained classification network with a Markov chain fusion model to aggregate multi-stream information of the skeleton sequence from finger-tapping test videos. Then, we develop a spatial–temporal attention mechanism to capture rich spatial and temporal long-range dependencies from skeleton data and introduce a symmetric bilinear pooling layer to enrich the local feature representation of each stream’s output. Besides, a mini-batch-based balanced algorithm is designed to ensure that the samples in each mini-batch are inter-class balanced, thus mitigating the effect of imbalanced data on neural networks. Finally, our three-stream fine-grained classification network achieved an accuracy of 72.4\% and an acceptable accuracy of 98.3\% on 157 patients and 744 videos. Extensive experiments further confirm our approach’s effectiveness and reliability. This method does not require any wearable device and has excellent potential for remote monitoring of PD patients in the future.},
  archive      = {J_NEUCOM},
  author       = {Hao Li and Xiangxin Shao and Chencheng Zhang and Xiaohua Qian},
  doi          = {10.1016/j.neucom.2021.02.011},
  journal      = {Neurocomputing},
  pages        = {260-271},
  shortjournal = {Neurocomputing},
  title        = {Automated assessment of parkinsonian finger-tapping tests through a vision-based fine-grained classification model},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic proposal sampling for weakly supervised object
detection. <em>NEUCOM</em>, <em>441</em>, 248–259. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to optimize object detectors with only image-level annotations because the target objects are often surrounded by a large number of background clutters. Many existing approaches tackle this problem through object proposal sampling. However, the collected positive proposals are either low in precision or lack of diversity, and the strategy of collecting negative proposals is not carefully designed, neither. In this context, the primary contribution of this work is to improve weakly supervised detection (WSD) with a dynamic proposal sampling (DPS) strategy. The proposed method collects purified positive training samples by progressively removing confident background clutters, and selects discriminative negative samples by mining class-specific hard proposals. To discover erratic number of confident proposals for different images and categories in varying training phase, we introduce class-specific probabilty accumulation score to measure the image complexity and the quality of learned object detectors, and adjust the number of sampled proposals accordingly. This proposal sampling procedure is integrated into a CNN-based WSD framework, and can be performed in each stochastic gradient descent mini-batch during training. Extensive evaluation results on PASCAL VOC 2007, VOC 2010 and VOC 2012 datasets are presented, which demonstrate that the proposed method effectively improves WSD.},
  archive      = {J_NEUCOM},
  author       = {Wenhui Jiang and Zhicheng Zhao and Fei Su and Yuming Fang},
  doi          = {10.1016/j.neucom.2021.02.018},
  journal      = {Neurocomputing},
  pages        = {248-259},
  shortjournal = {Neurocomputing},
  title        = {Dynamic proposal sampling for weakly supervised object detection},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accelerated gradient algorithm for RBF neural network.
<em>NEUCOM</em>, <em>441</em>, 237–247. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient-based algorithms are commonly used for training radial basis function neural network (RBFNN). However, one of the challenges in the training process is determining how to avoid vanishing gradient. To solve this problem, an accelerated gradient algorithm (AGA) is designed to improve the learning performance of RBFNN in this paper. First, an indirect detection mechanism, based on the instantaneous gradient decay rate (IGDR) and instantaneous convergence rate (ICR), is developed to identify the vanishing gradient in learning process. Second, an amplification gradient strategy (AGS), which can increase the gradient value of learning parameters, is designed to accelerate the learning speed of RBFNN. Third, the analysis of AGA-based RBFNN (AGA-RBFNN) is given to guarantee the successful application. Finally, some benchmark and real problems are used to illustrate the effectiveness of AGA-RBFNN. The results demonstrate the effectiveness of AGA-RBFNN.},
  archive      = {J_NEUCOM},
  author       = {Hong-Gui Han and Miao-Li Ma and Jun-Fei Qiao},
  doi          = {10.1016/j.neucom.2021.02.009},
  journal      = {Neurocomputing},
  pages        = {237-247},
  shortjournal = {Neurocomputing},
  title        = {Accelerated gradient algorithm for RBF neural network},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronization analysis for delayed spatio-temporal neural
networks with fractional-order. <em>NEUCOM</em>, <em>441</em>, 226–236.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the problem of synchronization for a class of fractional-order delayed spatio-temporal neural networks with Dirichlet boundary conditions is investigated. Firstly, based on the L’Hopital law, a Caputo fractional partial differential inequality with p p -norm is established to improve the previous results. Besides, a generalized fractional-order Halanay inequality is introduced by rigorous theoretical deduction. Additionally, to realize synchronization, two different control schemes are designed for the networks, respectively, and several criteria are derived based on the developed fractional inequalities. Finally, numerical examples and simulations are provided to verify the correctness of the results.},
  archive      = {J_NEUCOM},
  author       = {Bibo Zheng and Cheng Hu and Juan Yu and Haijun Jiang},
  doi          = {10.1016/j.neucom.2021.01.128},
  journal      = {Neurocomputing},
  pages        = {226-236},
  shortjournal = {Neurocomputing},
  title        = {Synchronization analysis for delayed spatio-temporal neural networks with fractional-order},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Filter gate network based on multi-head attention for
aspect-level sentiment classification. <em>NEUCOM</em>, <em>441</em>,
214–225. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment classification (ASC) is an important branch of sentiment analysis . Its purpose is to identify the sentiment polarity of the context for a given aspect. In recent years, ASC has received widespread attention from more and more researchers. Most of the previous work used word embedding , which was trained from large corpora, as context representation. However, this method cannot fully express the actual meaning of the context. In addition, the attention mechanism in ASC brings noise and captures context words that are irrelevant to the current aspect. Based on the above problems, we propose a novel neural network , named Filter Gate Network based on Multi-head attention (FGNMH). First, we train the context in a domain-specific corpus and integrate the part-of-speech features of the context to enrich the representation of the context. Second, we use multi-head attention mechanism to model contextual semantic information. Finally, a filter layer is designed to remove context words that are irrelevant to current aspect. To verify the effectiveness of FGNMH, we conduct a large number of experiments on SemEval2014, Restaurant15, Restaurant16 and Twitter. Experimental results show that FGNMH can reach 83.92\%, 81.24\%, 84.05\%, 85.37\%and 74.37\% on five data sets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Ziyu Zhou and Fang&#39;ai Liu},
  doi          = {10.1016/j.neucom.2021.02.041},
  journal      = {Neurocomputing},
  pages        = {214-225},
  shortjournal = {Neurocomputing},
  title        = {Filter gate network based on multi-head attention for aspect-level sentiment classification},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TDD-BPR: The topic diversity discovering on bayesian
personalized ranking for personalized recommender system.
<em>NEUCOM</em>, <em>441</em>, 202–213. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The main objective of the recommender system is to determine user behavior or preference and suggest the items of interest to the user. We notice that topic information is one of the significant factors that enables a user to choose the next items. To mimic this behavior , we design a topic diversity discovering (TDD) model to capture user preferences on topics. Unlike the previous studies applied the topic information to recommender systems, which only considered the item topics. In this paper, we not only focus on the item topic information but also consider the user topic information on the recommender system . We develop a TDD model to learn the topic information from the item, and we then utilize the transfer learning to obtain the user topic information. We then integrate the TDD model with the Bayesian personalized ranking (BPR) model to build a novel TDD-BPR recommender system. We experiment on three well-known three datasets MovieLens-1 M, Pinterest, and TMDB dataset, which achieved 71.8\%, 91.2\%, and 96.1\% in the Hit Ratio@10. Empirical evidence showed that TDD-BPR discover the potential topic information to understand the user’s preferences and get better recommendation performance.},
  archive      = {J_NEUCOM},
  author       = {Chi-Shiang Wang and Bo-Syun Chen and Jung-Hsien Chiang},
  doi          = {10.1016/j.neucom.2021.02.016},
  journal      = {Neurocomputing},
  pages        = {202-213},
  shortjournal = {Neurocomputing},
  title        = {TDD-BPR: The topic diversity discovering on bayesian personalized ranking for personalized recommender system},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mask-guided GAN for robust text editing in the scene.
<em>NEUCOM</em>, <em>441</em>, 192–201. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text editing in the scene aims to replace the source text with target text while maintaining the original text style and background, which involves text detection, style transfer and image inpainting techniques. Due to diversified text styles in the real scene, such as colorful outlines and shadows, it is quite challenging to edit complicated text. To address this problem, a mask-guided GAN method is proposed to adequately use the body, outline, and shadow of text to guide the task. First, a mask generating module is designed to detect the body, outline, and shadow regions in the text image. The generated mask in the source image is then used for the proposed text inpainting module and background inpainting module to extract source stylish text and restore the background, respectively. Next, a shape transfer module is designed to infer the target mask that depicts the text structural style from the source mask, which guides a style transfer module to transfer the text style onto the target image. Finally, a fusion module is developed to fuse the target text and background. Each module fulfills its own functional role and collaborates with each other, thus decomposing the complex task into easy-to-learn ones. Experiments and comparisons demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Boxi Yu and Yong Xu and Yan Huang and Shuai Yang and Jiaying Liu},
  doi          = {10.1016/j.neucom.2021.02.045},
  journal      = {Neurocomputing},
  pages        = {192-201},
  shortjournal = {Neurocomputing},
  title        = {Mask-guided GAN for robust text editing in the scene},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). TLSAN: Time-aware long- and short-term attention network
for next-item recommendation. <em>NEUCOM</em>, <em>441</em>, 179–191.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep neural networks are widely applied in recommender systems for their effectiveness in capturing/modeling users’ preferences. Especially, the attention mechanism in deep learning enables recommender systems to incorporate various features in an adaptive way. Specifically, as for the next item recommendation task, we have the following three observations: 1) users’ sequential behavior records aggregate at time positions (“time-aggregation”), 2) users have personalized taste that is related to the “time-aggregation” phenomenon (“personalized time-aggregation”), and 3) users’ short-term interests play an important role in the next item prediction/recommendation. In this paper, we propose a new T ime-aware L ong- and S hort-term A ttention N etwork (TLSAN) to address those observations mentioned above. Specifically, TLSAN consists of two main components. Firstly, TLSAN models “personalized time-aggregation” and learn user-specific temporal taste via trainable personalized time position embeddings with category-aware correlations in long-term behaviors. Secondly, long- and short-term feature-wise attention layers are proposed to effectively capture users’ long- and short-term preferences for accurate recommendation. Especially, the attention mechanism enables TLSAN to utilize users’ preferences in an adaptive way, and its usage in long- and short-term layers enhances TLSAN’s ability of dealing with sparse interaction data. Extensive experiments are conducted on Amazon datasets from different fields (also with different size), and the results show that TLSAN outperforms state-of-the-art baselines in both capturing users’ preferences and performing time-sensitive next-item recommendation.},
  archive      = {J_NEUCOM},
  author       = {Jianqing Zhang and Dongjing Wang and Dongjin Yu},
  doi          = {10.1016/j.neucom.2021.02.015},
  journal      = {Neurocomputing},
  pages        = {179-191},
  shortjournal = {Neurocomputing},
  title        = {TLSAN: Time-aware long- and short-term attention network for next-item recommendation},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review of irregular time series data handling with gated
recurrent neural networks. <em>NEUCOM</em>, <em>441</em>, 161–178. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Irregular time series data is becoming increasingly prevalent with the growth of multi-sensor systems as well as the continued use of unstructured manual data recording mechanisms. Irregular data and the resulting missing values severely limit the data&#39;s ability to be analysed and modelled for classification and forecasting tasks. Often, conventional methods used for handling time series data introduce bias and make strong assumptions on the underlying data generation process , which can lead to poor model predictions. Traditional machine learning and deep learning methods , although at the forefront of data modelling , are at best compromised by irregular time series data sets and fail to model the temporal irregularity of incomplete time series. Gated recurrent neural networks (RNN), such as LSTM and GRU , have had outstanding success in sequential modelling, and have been applied in many application fields, including natural language processing . These models have become an obvious choice for time series modelling and a promising tool for handling irregular time series data. RNNs have a unique ability to be adapted to make effective use of missing value patterns, time intervals and complex temporal dependencies in irregular univariate and multivariate time series data. In this paper, we provide a systematic review of recent studies in which gated recurrent neural networks have been successfully applied to irregular time series data for prediction tasks within several fields, including medical, human activity recognition , traffic monitoring and environmental monitoring. The review highlights the two common approaches for handling irregular time series data: missing value imputation at the data pre-processing stage and modification of algorithms to directly handle missing values in the learning process. Reviewed models are confined to those that can address issues with irregular time series data and does not cover the broader range of models that deal more generally with sequences and regular time series. This paper aims to present the most effective techniques emerging within this branch of research as well as to identify remaining challenges, so that researchers may build upon this platform of work towards further novel techniques for handling irregular time series data.},
  archive      = {J_NEUCOM},
  author       = {Philip B. Weerakody and Kok Wai Wong and Guanjin Wang and Wendell Ela},
  doi          = {10.1016/j.neucom.2021.02.046},
  journal      = {Neurocomputing},
  pages        = {161-178},
  shortjournal = {Neurocomputing},
  title        = {A review of irregular time series data handling with gated recurrent neural networks},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Monocular 3D object detection using dual quadric for
autonomous driving. <em>NEUCOM</em>, <em>441</em>, 151–160. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection is an essential component of scene perception and motion prediction in autonomous driving . Previous methods represent objects as the truncated signed distance fields (3D bounding box), which can only provide the geometric constraints of point-to-line. In this work, we define the object as a more compact representation, quadric (ellipsoid) in a 3D scene and a conic (ellipse) in an image, which can provide stronger geometric constraints of surface-to-curve. Specifically, we estimate a ellipsoid from a conic fitted by a 2D bounding box to obtain 3D object localization and occupancy. We further to formulate this constraint relation as a nonlinear optimization problem in dual space, which enables us to easy recover stable and accurate 3D object parameters by adding only three additional direction-aware branches to the existing 2D detection networks. In addition, we decouple the dimensions of object and update the length and orientation of objects in our iterative algorithm when the estimations from the 2D detection networks have different deviations. The final detection results can be obtained after passing through our geometry-related refinement network. We evaluate our method on the KITTI object detection benchmark and achieve the best performance among published monocular competitors.},
  archive      = {J_NEUCOM},
  author       = {Peixuan Li and Huaici Zhao},
  doi          = {10.1016/j.neucom.2021.01.110},
  journal      = {Neurocomputing},
  pages        = {151-160},
  shortjournal = {Neurocomputing},
  title        = {Monocular 3D object detection using dual quadric for autonomous driving},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Outlier exposure with confidence control for
out-of-distribution detection. <em>NEUCOM</em>, <em>441</em>, 138–150.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks have achieved great success in classification tasks during the last years. However, one major problem to the path towards artificial intelligence is the inability of neural networks to accurately detect samples from novel class distributions and therefore, most of the existent classification algorithms assume that all classes are known prior to the training stage. In this work, we propose a methodology for training a neural network that allows it to efficiently detect out-of-distribution (OOD) examples without compromising much of its classification accuracy on the test examples from known classes. We propose a novel loss function that gives rise to a novel method, Outlier Exposure with Confidence Control (OECC), which achieves superior results in OOD detection with OE both on image and text classification tasks without requiring access to OOD samples. Additionally, we experimentally show that the combination of OECC with state-of-the-art post-training OOD detection methods, like the Mahalanobis Detector (MD) and the Gramian Matrices (GM) methods, further improves their performance in the OOD detection task, demonstrating the potential of combining training and post-training methods for OOD detection.},
  archive      = {J_NEUCOM},
  author       = {Aristotelis-Angelos Papadopoulos and Mohammad Reza Rajati and Nazim Shaikh and Jiamian Wang},
  doi          = {10.1016/j.neucom.2021.02.007},
  journal      = {Neurocomputing},
  pages        = {138-150},
  shortjournal = {Neurocomputing},
  title        = {Outlier exposure with confidence control for out-of-distribution detection},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Interlayer and intralayer scale aggregation for
scale-invariant crowd counting. <em>NEUCOM</em>, <em>441</em>, 128–137.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting is an important vision task, which faces challenges on continuous scale variation within a given scene and huge density shift both within and across images. These challenges are typically addressed using multi-column structures in existing methods. However, such an approach does not provide consistent improvement and transferability due to limited ability in capturing multi-scale features, sensitivity to large density shift, and difficulty in training multi-branch models. To overcome these limitations, a Single-column Scalere-invariant Network (ScSiNet) is presented in this paper, which extracts sophisticated scale-invariant features via the combination of interlayer multi-scale integration and a novel intralayer scale-invariant transformation (SiT). Furthermore, in order to enlarge the diversity of densities, a randomly integrated loss is presented for training our single-branch method. Extensive experiments on public datasets demonstrate that the proposed method outperforms state-of-the-art approaches in counting accuracy and achieves remarkable transferability and scale-invariant property.},
  archive      = {J_NEUCOM},
  author       = {Mingjie Wang and Hao Cai and Jun Zhou and Minglun Gong},
  doi          = {10.1016/j.neucom.2021.01.112},
  journal      = {Neurocomputing},
  pages        = {128-137},
  shortjournal = {Neurocomputing},
  title        = {Interlayer and intralayer scale aggregation for scale-invariant crowd counting},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Light-weight network for real-time adaptive stereo depth
estimation. <em>NEUCOM</em>, <em>441</em>, 118–127. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Self-supervised learning methods have been proved effective in the task of real-time stereo depth estimation with the requirement of lower memory space and less computational cost. In this paper, a light-weight adaptive network (LWANet) is proposed by combining the self-supervised learning method to perform online adaptive stereo depth estimation for low computation cost and low GPU memory space. Instead of a regular 3D convolution, the pseudo 3D convolution is employed in the proposed light-weight network to aggregate the cost volume for achieving a better balance between the accuracy and the computational cost. Moreover, based on U-Net architecture, the downsample feature extractor is combined with a refined convolutional spatial propagation network (CSPN) to further refine the estimation accuracy with little memory space and computational cost. Extensive experiments demonstrate that the proposed LWANet effectively alleviates the domain shift problem by online updating the neural network , which is suitable for embedded devices such as NVIDIA Jetson TX2. The relevant codes are available at https://github.com/GANWANSHUI/LWANet},
  archive      = {J_NEUCOM},
  author       = {Wanshui Gan and Pak Kin Wong and Guokuan Yu and Rongchen Zhao and Chi Man Vong},
  doi          = {10.1016/j.neucom.2021.02.014},
  journal      = {Neurocomputing},
  pages        = {118-127},
  shortjournal = {Neurocomputing},
  title        = {Light-weight network for real-time adaptive stereo depth estimation},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Training very deep neural networks: Rethinking the role of
skip connections. <em>NEUCOM</em>, <em>441</em>, 105–117. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {State-of-the-art deep neural networks (DNNs) typically consist of several layers of features representations, and especially rely on skip connections to avoid the difficulty of model optimization. Despite the proliferation of different DNN models that employ various forms of skip connections to achieve remarkable results on benchmarking datasets , a concrete explanation for the successful operation and improved generalization capability of these DNNs is surprisingly still lacking. In this paper, we focus on investigating the role of skip connections for training very deep DNNs. Our exposition directly provides interesting insights and new interpretations to the following important questions (i) why model optimization is easier (ii) why model generalization is better. Theoretical results reveal that skip connections allow DNNs to circumnavigate the singularity of latent representations that translate to optimization and generalization problems, which plague models without skip connections referred to as PlainNets. For substantiating our analysis, our investigation puts into context some of the most successful skip-connection based DNNs, which include residual networks (ResNets) and residual network with aggregated features (ResNeXt) in relation to PlainNets. Experimental evaluations of these models support the theoretical analysis.},
  archive      = {J_NEUCOM},
  author       = {Oyebade K. Oyedotun and Kassem Al Ismaeil and Djamila Aouada},
  doi          = {10.1016/j.neucom.2021.02.004},
  journal      = {Neurocomputing},
  pages        = {105-117},
  shortjournal = {Neurocomputing},
  title        = {Training very deep neural networks: Rethinking the role of skip connections},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-parallelism inception-like spiking neural networks for
unsupervised feature learning. <em>NEUCOM</em>, <em>441</em>, 92–104.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine learning algorithms that have been widely recognized in producing ultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs based on synaptic plasticity , especially Spike-Timing-Dependent Plasticity (STDP), are considered to have great potential in imitating the learning process of the biological brain. Nevertheless, the existing STDP-based SNNs have limitations in constrained learning capability and/or slow learning speed. Most STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architectures and used a sub-optimal vote-based scheme for spike decoding. In this paper, we overcome these limitations with: 1) a design of high-parallelism network architecture , inspired by the Inception module in Artificial Neural Networks (ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the standard vote-based spike decoding scheme, to reduce the information loss in spike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism that accelerates SNNs’ learning by enhancing spiking activities. Our experimental results on two established benchmark datasets (MNIST/EMNIST) show that our network architecture resulted in superior performance compared to the widely used FC architecture and a more advanced Locally-Connected (LC) architecture, and that our SNN achieved competitive results with state-of-the-art unsupervised SNNs (95.64\%/80.11\% accuracy on the MNIST/EMNISE dataset) while having superior learning efficiency and robustness against hardware damage. Our SNN achieved great classification accuracy with only hundreds of training iterations, and random destruction of large numbers of synapses or neurons only led to negligible performance degradation .},
  archive      = {J_NEUCOM},
  author       = {Mingyuan Meng and Xingyu Yang and Lei Bi and Jinman Kim and Shanlin Xiao and Zhiyi Yu},
  doi          = {10.1016/j.neucom.2021.02.027},
  journal      = {Neurocomputing},
  pages        = {92-104},
  shortjournal = {Neurocomputing},
  title        = {High-parallelism inception-like spiking neural networks for unsupervised feature learning},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). High-emitter identification model establishment using
weighted extreme learning machine and active sampling. <em>NEUCOM</em>,
<em>441</em>, 79–91. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-emitting vehicles cause disproportionate air pollutants, thus making the identification and control of high-emitters a critical issue to reduce air pollution. On-road emission remote sensing (OERS), which can measure the emission of passing vehicles without interfering the normal driving, is an ideal means to identify the on-road high-emitting vehicles. Since the remote sensing measurements only reflect the instantaneous emission status, there is no doubt that OERS-output pollutant concentrations are related to the operation conditions and ambient environments at the measuring moment. Therefore, in order to identify on-road high-emitters effectively and accurately, a high-emitter identification model considering the relationship between OERS-output pollutant concentrations and their influence factors (such as passing speed, passing acceleration, wind speed, wind direction, temperature, etc.) should be established. In this paper, the way to establish the high-emitter identification model by machine learning is investigated. Because of the imbalanced distribution characteristic of emitter dataset, the weighted extreme learning machine is adopted as the identification model. Meanwhile, to enable an efficient establishment of the identification model, the active sampling that considers the dataset imbalance is introduced to select valuable samples to be labeled. The experimental results show that the high-emitter identification model establishment method based on weighted extreme learning machine can reduce the identification error for high-emitters significantly. Additionally, the active sampling can select valuable samples and improve the identification performance through the model update.},
  archive      = {J_NEUCOM},
  author       = {Zerui Li and Yu Kang and Wenjun Lv and Yuping Wu and Cai Chen and Zhenyi Xu},
  doi          = {10.1016/j.neucom.2021.01.074},
  journal      = {Neurocomputing},
  pages        = {79-91},
  shortjournal = {Neurocomputing},
  title        = {High-emitter identification model establishment using weighted extreme learning machine and active sampling},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multilevel clustering technique for community detection.
<em>NEUCOM</em>, <em>441</em>, 64–78. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A network is a composition of many communities, i.e., sets of nodes and edges with stronger relationships, with distinct and overlapping properties. Community detection is crucial for various reasons, such as serving as a functional unit of a network that captures local interactions among nodes. Communities come in various forms and types, ranging from biologically to technology-induced ones. As technology-induced communities, social media networks such as Twitter and Facebook connect a myriad of diverse users, leading to a highly connected and dynamic ecosystem. Although many algorithms have been proposed for detecting socially cohesive communities on Twitter, mining and related tasks remain challenging. This study presents a novel detection method based on a scalable framework to identify related communities in a network. We propose a multilevel clustering technique (MCT) that leverages structural and textual information to identify local communities termed microcosms . Experimental evaluation on benchmark models and datasets demonstrate the efficacy of the approach. This study contributes a new dimension for the detection of cohesive communities in social networks. The approach offers a better understanding and clarity toward describing how low-level communities evolve and behave on Twitter. From an application point of view, identifying such communities can better inform recommendation, among other benefits.},
  archive      = {J_NEUCOM},
  author       = {Isa Inuwa-Dutse and Mark Liptrott and Ioannis Korkontzelos},
  doi          = {10.1016/j.neucom.2021.01.059},
  journal      = {Neurocomputing},
  pages        = {64-78},
  shortjournal = {Neurocomputing},
  title        = {A multilevel clustering technique for community detection},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stable and compact design of memristive GoogLeNet neural
network. <em>NEUCOM</em>, <em>441</em>, 52–63. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the requirements of edge intelligence for circuit volume, power consumption and computing performance, a Memristive GoogLeNet Neural Network (MGNN) circuit is designed using memristor which is a new device integrating storage and computing as the basic circuit element. This circuit adopts 1 × 1 1×1 convolution and multi-scale convolution feature fusion to reduce the number of layers required by the network while ensuring the recognition accuracy of circuit. In order to reduce the size of the memristor crossbars in the circuit, we design word-line pruning and bit-line pruning methods of Memristive Convolution (MC) layers. We also use the parameter distribution of the memristive neural network to further reduce the size of memristor crossbars. The Memristive Batch Normalization (MBN) layer and Memristive Dropout (MD) are merged into front MC layers according mathematical analysis for cutting the number of network layers and decreasing the power consumption of the circuit. We also design the channel optimization and layer optimization methods of MC layers which greatly reduce the negative effect of multi-state conductance of memristors on the accuracy, improve the stability of the circuit, and reduce the circuit volume and power consumption. Experiments show that this circuit can get 89.83\% accuracy on the CIFAR-10 data set, and the power consumption of a single neuron is only 1.3 μ W 1.3μW . When the number of memristor multi-state conductance is 2 4 = 16 24=16 , the accuracy of the MGNN circuit close to float MGNN can still be obtained.},
  archive      = {J_NEUCOM},
  author       = {Huanhuan Ran and Shiping Wen and Kaibo Shi and Tingwen Huang},
  doi          = {10.1016/j.neucom.2021.01.122},
  journal      = {Neurocomputing},
  pages        = {52-63},
  shortjournal = {Neurocomputing},
  title        = {Stable and compact design of memristive GoogLeNet neural network},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Symbolic analysis of bursting dynamical regimes of rulkov
neural networks. <em>NEUCOM</em>, <em>441</em>, 44–51. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neurons modeled by the Rulkov map display a variety of dynamic regimes that include tonic spikes and chaotic bursting. Here we study an ensemble of bursting neurons coupled with the Watts-Strogatz small-world topology. We characterize the sequences of bursts using the symbolic method of time-series analysis known as ordinal analysis, which detects nonlinear temporal correlations. We show that the probabilities of the different symbols distinguish different dynamical regimes, which depend on the coupling strength and the network topology . These regimes have different spatio-temporal properties that can be visualized with raster plots.},
  archive      = {J_NEUCOM},
  author       = {R.C. Budzinski and S.R. Lopes and C. Masoller},
  doi          = {10.1016/j.neucom.2020.05.122},
  journal      = {Neurocomputing},
  pages        = {44-51},
  shortjournal = {Neurocomputing},
  title        = {Symbolic analysis of bursting dynamical regimes of rulkov neural networks},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-varying output formation tracking of heterogeneous
linear multi-agent systems with dynamical controllers. <em>NEUCOM</em>,
<em>441</em>, 36–43. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the problem of time-varying output formation tracking of heterogeneous linear multi-agent systems on a directed communication topology that the leaders do not communicate with each other. Specifically, with injecting impulses to the states of the controllers, a dynamical control protocol is proposed, which not only reduces communication consumption, but also avoids the damage of the impulsive energy to the devices at impulsive instants. Besides, the protocol is designed using the measured output of the agents, which is more practical than those designed using the states of the agents. Then, some sufficient conditions with regard to the gain matrices and the coupling parameter are derived to guarantee that the states of the followers achieve time-varying output formation and track the convex combination of the states of the leaders as well. Finally, a numerical example is shown to validate the effectiveness of the theoretical result.},
  archive      = {J_NEUCOM},
  author       = {Congying Liu and Xiaoqun Wu and Xiaoxiao Wan and Jinhu Lü},
  doi          = {10.1016/j.neucom.2021.01.113},
  journal      = {Neurocomputing},
  pages        = {36-43},
  shortjournal = {Neurocomputing},
  title        = {Time-varying output formation tracking of heterogeneous linear multi-agent systems with dynamical controllers},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Physical intrusion monitoring via local-global network and
deep isolation forest based on heterogeneous signals. <em>NEUCOM</em>,
<em>441</em>, 25–35. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a local–global semi-sharing network (LGSSN) for heterogeneous signals in physical intrusion monitoring. The signals are collected by heterogeneous distributed optical fiber sensor (DOFS). The local classifier of LGSSN is constructed via a hybrid model deep isolation forest (DIF). It can extract the dominant representations of original high-dimensional signals through deep autoencoders (DAE). Then, an isolation forest (IF) is added to the last layer to obtain local classification for extremely imbalanced cases. In addition, the network is simplified by semi-sharing strategy, and a parallel computing framework is presented for accelerating the process. Further, the final decision on monitoring state is acquired by a Bayesian inference-based global integrated monitor (GIM) with enhanced classification accuracy. The proposed strategy is tested on a monitoring application along the Nanjing Metro Line S7, Jiangsu Province, China. Comparative experimental results illustrate the feasibility and effectiveness of proposed strategy.},
  archive      = {J_NEUCOM},
  author       = {Sudao He and Fuyang Chen and Bin Jiang},
  doi          = {10.1016/j.neucom.2021.01.104},
  journal      = {Neurocomputing},
  pages        = {25-35},
  shortjournal = {Neurocomputing},
  title        = {Physical intrusion monitoring via local-global network and deep isolation forest based on heterogeneous signals},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Exponential synchronization of delayed neural networks
involving unmeasurable neuron states via impulsive observer and
impulsive control. <em>NEUCOM</em>, <em>441</em>, 13–24. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of exponential synchronization for a class of drive-response delayed neural networks , where two different cases are fully considered, respectively, that is, drive system involving unmeasurable states and response system involving unmeasurable states. For each case, a corresponding impulsive observer is designed to reconstruct (or estimate) the states of the neural network which involves unmeasurable states. And then based on the observations and measurements, we propose a novel impulsive observer-based impulsive control ( IOBIC ) scheme for response system to achieve the synchronization. With the help of comparison principle and average impulsive interval approach, some sufficient conditions are presented. Moreover, the impulsive observer and impulsive controller gains can be designed by solving the derived linear matrix inequalities ( LMI s). Different from the classical results, our impulsive synchronization conditions can be applied to the problem of synchronization of neural networks involving unmeasurable states. The effectiveness of the proposed methods is illustrated by two examples borrowed from the classical literature.},
  archive      = {J_NEUCOM},
  author       = {Yuhan Wang and Xiaodi Li and Shiji Song},
  doi          = {10.1016/j.neucom.2021.01.119},
  journal      = {Neurocomputing},
  pages        = {13-24},
  shortjournal = {Neurocomputing},
  title        = {Exponential synchronization of delayed neural networks involving unmeasurable neuron states via impulsive observer and impulsive control},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Heterogeneous model parallelism for deep neural networks.
<em>NEUCOM</em>, <em>441</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have transformed computer vision, establishing themselves as the current state-of-the-art for image processing . Nevertheless, the training of current large DNN models is one of the main challenges to be solved. In this sense, data-parallelism has been the most widespread distributed training strategy since it is easy to program and can be applied to almost all cases. However, this solution suffers from several limitations, such as its high communication requirements and the memory constraints when training very large models. To overcome these limitations model-parallelism has been proposed, solving the most substantial problems of the former strategy. However, describing and implementing the parallelization of the training of a DNN model across a set of processes deployed on several devices is a challenging task. Current proposed solutions assume a homogeneous distribution, being impractical when working with devices of different computational capabilities, which is quite common on high performance computing platforms. To address previous shortcomings, this work proposes a novel model-parallelism technique considering heterogeneous platforms , where a load balancing mechanism between uneven devices of an HPC platform has been implemented. Our proposal takes advantage of the Google Brain’s Mesh-TensorFlow for convolutional networks , splitting computing tensors across filter dimension in order to balance the computational load of the available devices. Conducted experiments show an improvement in the exploitation of heterogeneous computational resources, enhancing the training performance. The code is available on: https://github.com/mhaut/HeterogeneusModelDNN.},
  archive      = {J_NEUCOM},
  author       = {Sergio Moreno-Alvarez and Juan M. Haut and Mercedes E. Paoletti and Juan A. Rico-Gallego},
  doi          = {10.1016/j.neucom.2021.01.125},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Heterogeneous model parallelism for deep neural networks},
  volume       = {441},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Asymptotic stability of static neural networks with interval
time-varying delay based on LMI. <em>NEUCOM</em>, <em>440</em>, 375–384.
(<a href="https://doi.org/10.1016/j.neucom.2021.02.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the asymptotic stability of static neural networks with interval time-varying delay is studied. An improved integral inequality based on orthogonal polynomials is proposed, in which three free vectors can be selected independently. A novel Lyapunov–Krasovskii functional containing more delayed state information, instant state information and integrated state information is constructed. Based on the improved non-convex technique, two less conservative delay-dependent stability criteria in terms of linear matrix inequalities (LMIs) are derived. The validity and superiority of the theoretical results derived in this paper are verified by numerical simulation.},
  archive      = {J_NEUCOM},
  author       = {Meilan Tang and Xiaofang Hu and Xinge Liu and Qiao Chen},
  doi          = {10.1016/j.neucom.2021.02.003},
  journal      = {Neurocomputing},
  pages        = {375-384},
  shortjournal = {Neurocomputing},
  title        = {Asymptotic stability of static neural networks with interval time-varying delay based on LMI},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prior-based bayesian pairwise ranking for one-class
collaborative filtering. <em>NEUCOM</em>, <em>440</em>, 365–374. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many real-world applications, only user-item interactions (one-class feedback) can be observed. The recommendation methods have been studied for personalized ranking with one-class feedback in recent years. Pairwise ranking methods have been widely used for dealing with the one-class problem with the assumption that users prefer their observed items over unobserved items. However, existing some items that users have not seen yet. It is unsuitable for treating all unobserved items of the user as negative feedback. In this paper, we propose a Prior-based Bayesian Pairwise Ranking (PBPR) model, which relaxes the simple pairwise preference assumption in previous works by further considering the pairwise preference between two unobserved items. Moreover, we calculate users&#39; potential preference scores on unobserved items, i.e., prior information, based on historical interactions. The prior information can be used to measure the fine-grained preference difference between any two unobserved items of each user. Through extensive experiments on real-world datasets, we demonstrate the effectiveness of our proposed recommendation method.},
  archive      = {J_NEUCOM},
  author       = {Qian Zhang and Fuji Ren},
  doi          = {10.1016/j.neucom.2021.01.117},
  journal      = {Neurocomputing},
  pages        = {365-374},
  shortjournal = {Neurocomputing},
  title        = {Prior-based bayesian pairwise ranking for one-class collaborative filtering},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tensor low-rank sparse representation for tensor subspace
learning. <em>NEUCOM</em>, <em>440</em>, 351–364. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many subspace learning methods are implemented on a matrix of sample data. For multi-dimensional data, these methods have to convert data samples into vectors in advance, which often destroys the inherent spatial structure of the sample data. In this paper, we propose a robust tensor low-rank sparse representation (TLRSR) method that can directly perform subspace learning on three-dimensional tensors. Firstly, the dual constraints of low-rankness and sparseness make the representation tensor effectively capture the global structure and local structure of sample data, respectively. Secondly, in order to deal with outliers and noise, we adopt the tensor ℓ 2 , 1 -norm to characterize the noise of tensor composed of multiple samples. Thirdly, the denoised tensor instead of the original tensor is used as the dictionary to find the low-rank sparse representation tensor. Finally, an iterative update algorithm is proposed for the optimization of TLRSR, compared with the state-of-the-art methods, clustering on face images and denoising on real images verify the good performance of our proposed TLRSR in tensor subspace learning.},
  archive      = {J_NEUCOM},
  author       = {Shiqiang Du and Yuqing Shi and Guangrong Shan and Weilan Wang and Yide Ma},
  doi          = {10.1016/j.neucom.2021.02.002},
  journal      = {Neurocomputing},
  pages        = {351-364},
  shortjournal = {Neurocomputing},
  title        = {Tensor low-rank sparse representation for tensor subspace learning},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new heterogeneous neural network model and its application
in image enhancement. <em>NEUCOM</em>, <em>440</em>, 336–350. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on visual cortical theory of Rybak, a new heterogeneous Rybak neural network (HRYNN) model is proposed for image enhancement. HRYNN is constructed with several Rybak neural network (RYNN) models proposed, which have different parameters corresponding to different neurons. We show that HRYNN can better represent prior information for edge detail enhancement than the logarithmic domain. To capture different resolution texture features of image, a novel receptive field model is proposed to solve the problem of detail enhancement. HRYNN model has excellent enhancement effect on the edge details of image based on the receptive field’s lateral inhibitory characteristics. Moreover, the experimental enhancement results of the colour images from Berkeley image Dataset show the validity and efficiency of the proposed enhancement method. Finally, three evaluation indicators are employed to measure the enhancement result.},
  archive      = {J_NEUCOM},
  author       = {Yunliang Qi and Zhen Yang and Jing Lian and Yanan Guo and Wenhao Sun and Jizhao Liu and Runze Wang and Yide Ma},
  doi          = {10.1016/j.neucom.2021.01.133},
  journal      = {Neurocomputing},
  pages        = {336-350},
  shortjournal = {Neurocomputing},
  title        = {A new heterogeneous neural network model and its application in image enhancement},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrate syntax information for target-oriented opinion
words extraction with target-specific graph convolutional network.
<em>NEUCOM</em>, <em>440</em>, 321–335. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Target-oriented Opinion Words Extraction (TOWE) aims to identify opinion words toward a specific target given the sentence. Syntax structure, which contains dependency relationships among words, is a vital clue for this task. With the help of syntax structure as a constraint, the model could remove irrelevant words and focus on tokens that are relevant to the given target. Directly adapting existing syntactic-based methods faces the problem that these models do not explicitly learn target-centric representations. Another challenge is that prior works only learn fixed order dependency relations , while context words require syntactic information in different scales. To handle these issues, we propose Target-Specific Graph Convolutional Network (TS-GCN) to explicitly integrate dependency structure. The proposed method could build high-quality syntax-aware representations by propagating target information to syntactically related words via graph convolution. Furthermore, we design a memory-based module to dynamically learn multi-granularity syntactic knowledge and infuse local features . Experimental results demonstrate the effectiveness of our method, and we achieve state-of-the-art performances on four SemEval datasets.},
  archive      = {J_NEUCOM},
  author       = {Jingyuan Zhang and Feng Li and Zequn Zhang and Guangluan Xu and Yang Wang and Xinyi Wang and Yunyan Zhang},
  doi          = {10.1016/j.neucom.2020.07.152},
  journal      = {Neurocomputing},
  pages        = {321-335},
  shortjournal = {Neurocomputing},
  title        = {Integrate syntax information for target-oriented opinion words extraction with target-specific graph convolutional network},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging orientation for weakly supervised object
detection with application to firearm localization. <em>NEUCOM</em>,
<em>440</em>, 310–320. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detection of firearms is important for enhancing the security and safety of people, however, it is a challenging task owing to the wide variations in shape, size and appearance of firearms. Also, most of the generic object detectors process axis-aligned rectangular areas though, a thin and long rifle may actually cover only a small percentage of that area and the rest may contain irrelevant details suppressing the required object signatures. To handle these challenges, we propose a weakly supervised Orientation Aware Object Detection (OAOD) algorithm which learns to detect oriented object bounding boxes (OBB) while using Axis-Aligned Bounding Boxes (AABB) for training. The proposed OAOD is different from the existing oriented object detectors which strictly require OBB during training which may not always be present. The goal of training on AABB and detection of OBB is achieved by employing a multistage scheme, with Stage-1 predicting the AABB and Stage-2 predicting OBB. In-between the two stages, the oriented proposal generation module along with the object aligned RoI pooling is designed to extract features based on the predicted orientation and to make these features orientation invariant . A diverse and challenging dataset consisting of eleven thousand images is also proposed for firearm detection which is manually annotated for firearm classification and localization. The proposed ITU Firearm dataset (ITUF) contains a wide range of guns and rifles. The OAOD algorithm is evaluated on the ITUF dataset and compared with current state-of-the-art object detectors, including fully supervised oriented object detectors. OAOD has outperformed both types of object detectors with a significant margin. The experimental results (mAP: 88.3 on AABB &amp; mAP: 77.5 on OBB ) demonstrate effectiveness of the proposed algorithm for firearm detection.},
  archive      = {J_NEUCOM},
  author       = {Javed Iqbal and Muhammad Akhtar Munir and Arif Mahmood and Afsheen Rafaqat Ali and Mohsen Ali},
  doi          = {10.1016/j.neucom.2021.01.075},
  journal      = {Neurocomputing},
  pages        = {310-320},
  shortjournal = {Neurocomputing},
  title        = {Leveraging orientation for weakly supervised object detection with application to firearm localization},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph regularized nonnegative matrix factorization with
label discrimination for data clustering. <em>NEUCOM</em>, <em>440</em>,
297–309. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Non-negative Matrix Factorization (NMF) is an effective method in multivariate data analysis, such as feature learning , computer vision and pattern recognition. For practical clustering tasks , NMF ignores both the local geometry of data and the discriminative information of different classes. In this paper, we propose a new NMF method under graph and label constraints, named Graph Regularized Nonnegative Matrix Factorization with Label Discrimination (GNMFLD), which attempts to find a compact representation of the data so that further learning tasks can be facilitated. The proposed GNMFLD jointly incorporates a graph regularizer and the prior label information as additional constraints, such that it can effectively enhance the discrimination and the exclusivity of clustering, and improve the clustering performance. Empirical experiments demonstrate the effectiveness of our new algorithm through a set of evaluations based on real-world applications.},
  archive      = {J_NEUCOM},
  author       = {Zhiwei Xing and Yingcang Ma and Xiaofei Yang and Feiping Nie},
  doi          = {10.1016/j.neucom.2021.01.064},
  journal      = {Neurocomputing},
  pages        = {297-309},
  shortjournal = {Neurocomputing},
  title        = {Graph regularized nonnegative matrix factorization with label discrimination for data clustering},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A consensus-based decentralized training algorithm for deep
neural networks with communication compression. <em>NEUCOM</em>,
<em>440</em>, 287–296. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facing the challenge of distributed computing on processing large-scale data, this paper proposes a consensus-based decentralized training method with communication compression. First, the decentralized training method is designed based on the decentralized topology to reduce the communication burden on the busiest agent and avoid any agent revealing its locally stored data. The convergence of the decentralized training algorithm is then analyzed, which demonstrates that the decentralized trained model can reach the minimal empirical risk on the whole dataset, without the sharing of data samples. Furthermore, model compression combined with the error-compensated method is considered to reduce communication costs during the decentralized training process. At last, the simulation study shows that the proposed decentralized training with error-compensated communication compression is applicable for both IID and non-IID datasets, and exhibits much better performance than the local training method. Besides, the proposed algorithm with an appropriate compression rate shows comparable performance with decentralized training and centralized training, while saving a lot of communication costs.},
  archive      = {J_NEUCOM},
  author       = {Bo Liu and Zhengtao Ding},
  doi          = {10.1016/j.neucom.2021.01.020},
  journal      = {Neurocomputing},
  pages        = {287-296},
  shortjournal = {Neurocomputing},
  title        = {A consensus-based decentralized training algorithm for deep neural networks with communication compression},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised attention flow for dialogue state tracking.
<em>NEUCOM</em>, <em>440</em>, 279–286. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The performance of existing approaches for dialogue state tracking (DST) is often limited by the deficiency of labeled datasets, and inefficient utilization of data is also a practical yet tough problem of the DST task. In this paper, we aim to tackle these challenges in a self-supervised manner by introducing an auxiliary pre-training task that learns to pick up the correct dialogue response from a group of candidates. Moreover, we propose an attention flow mechanism that is augmented with a soft-threshold function in a dynamic way to better understand the user intent and filter out the redundant information. Extensive experiments on the multi-domain dialogue state tracking dataset MultiWOZ 2.1 demonstrate the effectiveness of our proposed method, and we also show that it is able to adapt to zero/few-shot cases under the proposed self-supervised framework.},
  archive      = {J_NEUCOM},
  author       = {Boyuan Pan and Yazheng Yang and Bo Li and Deng Cai},
  doi          = {10.1016/j.neucom.2021.01.118},
  journal      = {Neurocomputing},
  pages        = {279-286},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised attention flow for dialogue state tracking},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Hyperbolic-valued hopfield neural networks in hybrid mode.
<em>NEUCOM</em>, <em>440</em>, 275–278. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex-valued Hopfield neural network (CHNN) has been applied as a multistate neural associative memory . Although synchronous mode accelerates the recall process, a CHNN with a projection rule may be trapped at a cycle of length two. A hyperbolic-valued Hopfield neural network (HHNN) with a conventional projection rule converges to a fixed point in synchronous mode. A noise robust projection rule improves the noise tolerance of HHNN, though it is not able to be applied to an HHNN in synchronous mode. In this work, we proposed hybrid mode, that is, asynchronous mode after synchronous mode. The conventional projection rule is employed in synchronous mode, and the noise robust projection rule is employed in asynchronous mode. Thus, the HHNN in hybrid mode converges in both modes. The HHNN in hybrid mode is expected to provide better noise tolerance than an HHNN in synchronous mode and faster recall than an HHNN in asynchronous mode. Computer simulations imply that our expectations are achieved.},
  archive      = {J_NEUCOM},
  author       = {Masaki Kobayashi},
  doi          = {10.1016/j.neucom.2021.01.121},
  journal      = {Neurocomputing},
  pages        = {275-278},
  shortjournal = {Neurocomputing},
  title        = {Hyperbolic-valued hopfield neural networks in hybrid mode},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive neural network finite-time tracking quantized
control for uncertain nonlinear systems with full-state constraints and
applications to QUAVs. <em>NEUCOM</em>, <em>440</em>, 264–274. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel adaptive neural network finite-time tracking control strategy is developed for a class of uncertain nonlinear systems with asymmetric time-varying full-state constraints and input quantization. With the help of an introduced TVABLF, all state variables are confined to predefined regions. Based on the backstepping method and NNs approximation technique, a smooth tracking controller and its adaptive laws are co-designed for the uncertain systems. The system effects caused by the input quantization is compensated by the proposed algorithm with nonlinear decomposition. By adopting the SGPFS theory, the tracking performances are ensured to be achieved in finite time. It is rigorously proved that the output of the system follows the specified trajectory in finite time, whilst the system state variables are constrained within asymmetric boundaries. QUAVs are typical nonlinear systems of 6-Dof, and the control input signal requires quantization. We apply the developed method to the controller design of uncertain QUAVs , and the simulation results verify the effectiveness of the main results.},
  archive      = {J_NEUCOM},
  author       = {Changchun Hua and Anqi Jiang and Kuo Li},
  doi          = {10.1016/j.neucom.2020.12.078},
  journal      = {Neurocomputing},
  pages        = {264-274},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural network finite-time tracking quantized control for uncertain nonlinear systems with full-state constraints and applications to QUAVs},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SOSD-net: Joint semantic object segmentation and depth
estimation from monocular images. <em>NEUCOM</em>, <em>440</em>,
251–263. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation and semantic segmentation play essential roles in scene understanding. The state-of-the-art methods employ multi-task learning to simultaneously learn models for these two tasks at the pixel-wise level. They usually focus on sharing the common features or stitching feature maps from the corresponding branches. However, these methods lack in-depth consideration on the correlation of the geometric cues and the scene parsing . In this paper, we first introduce the concept of semantic objectness to exploit the geometric relationship of these two tasks through an analysis of the imaging process , then propose a Semantic Object Segmentation and Depth Estimation Network (SOSD-Net) based on the objectness assumption. To the best of our knowledge, SOSD-Net is the first network that exploits the geometry constraint for simultaneous monocular depth estimation and semantic segmentation . In addition, considering the mutual implicit relationship between these two tasks, we exploit the iterative idea from the expectation–maximization algorithm to train the proposed network more effectively. Extensive experimental results on the Cityscapes and NYU v2 dataset are presented to demonstrate the superior performance of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Lei He and Jiwen Lu and Guanghui Wang and Shiyu Song and Jie Zhou},
  doi          = {10.1016/j.neucom.2021.01.126},
  journal      = {Neurocomputing},
  pages        = {251-263},
  shortjournal = {Neurocomputing},
  title        = {SOSD-net: Joint semantic object segmentation and depth estimation from monocular images},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered neural network control for a class of
uncertain nonlinear systems with input quantization. <em>NEUCOM</em>,
<em>440</em>, 240–250. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a neural network control issue of a class of uncertain nonlinear systems . An adaptive quantized control strategy is developed such that the input quantization can be achieved using three different kinds of quantizers, and uncertain dynamics of system can be approximated and compensated by neural networks (NNs). Besides, a triggering event is addressed on the basis of a fixed and relative combined threshold strategy for relieving the communication load between the controller and actuator. With such control scheme, all signals of the closed-loop system are bounded and Lyapunov method is applied to prove the uniform ultimate boundedness of the control system. Simulation example is provided for illustrating tracking performance of the proposed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Xueyan Xing and Jinkun Liu},
  doi          = {10.1016/j.neucom.2021.01.088},
  journal      = {Neurocomputing},
  pages        = {240-250},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered neural network control for a class of uncertain nonlinear systems with input quantization},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention adjacency matrix based graph convolutional
networks for skeleton-based action recognition. <em>NEUCOM</em>,
<em>440</em>, 230–239. (<a
href="https://doi.org/10.1016/j.neucom.2021.02.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent progress on human action recognition , fueled by the Graph Convolutional Network (GCN), has been substantial. However, two main problems are caused by the design strategy of graph convolution kernels : first, the partitioning strategy of neighbor set for graph vertices relies on the gravity center designed manually, which is limited in generalizability to diverse skeletons in action recognition; second, the existing GCN-based methods can only capture local physical dependencies among joints and result in missing implicit joint correlations due to over-smoothing. In this work, we present (1) a novel attention adjacency matrix (AAM) to design graph convolution kernels and (2) a dimension-attention block to improve the robustness of the model. Specifically, the proposed AAM is designed by a novel partitioning strategy for the neighbor set, through which an adjacency matrix is decomposed into several parametric matrices. Simultaneously, attention mechanism is introduced in the process to generate an attention matrix. Combining the matrix and the parametric matrices into an AAM through ResNet , we further exhibit the AAM based graph convolution network (AAM-GCN). The proposed dimension-attention block strengthens the important information in each dimension of skeleton data by extending the idea of channel-attention. Extensive experiments on two large-scale datasets, NTU-RGB+D and Kinetics, demonstrate that AAM-GCN achieves better performance than the state-of-the-art works.},
  archive      = {J_NEUCOM},
  author       = {Jun Xie and Qiguang Miao and Ruyi Liu and Wentian Xin and Lei Tang and Sheng Zhong and Xuesong Gao},
  doi          = {10.1016/j.neucom.2021.02.001},
  journal      = {Neurocomputing},
  pages        = {230-239},
  shortjournal = {Neurocomputing},
  title        = {Attention adjacency matrix based graph convolutional networks for skeleton-based action recognition},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel pipelined neural FIR architecture for nonlinear
adaptive filter. <em>NEUCOM</em>, <em>440</em>, 220–229. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel adaptive pipelined neural finite impulse response (PNFIR) filter for nonlinear signal processing . Unlike traditional pipelined recurrent neural network (PRNN), each module of the PNFIR filter is a simple architecture that includes a standard FIR filter followed by a nonlinear activation function . The complete design of proposed filter includes two subsections: The nonlinear part consists of neural FIR (NFIR) modules which is interconnected in a chained form and simultaneously executed in a parallel fashion; the linear subsection is a tapped-delay-line (TDL) linear combiner . Based on convex combination architecture, the adaptive algorithm derived from the gradient descent approach is utilized to update weights of the nonlinear and linear parts. Moreover, the analysis of stability conditions and computational complexity is also presented. Numerous simulation experimental results on nonlinear dynamic systems identification, speech signal and chaotic time series prediction show that the proposed PNFIR filter has simpler architecture, faster convergence rate, and lower computation complexity than the PRNN and joint process filter using pipelined feedforward second-order Volterra architecture (JPPSOV).},
  archive      = {J_NEUCOM},
  author       = {Dinh Cong Le and Jiashu Zhang and Yanjie Pang},
  doi          = {10.1016/j.neucom.2020.11.036},
  journal      = {Neurocomputing},
  pages        = {220-229},
  shortjournal = {Neurocomputing},
  title        = {A novel pipelined neural FIR architecture for nonlinear adaptive filter},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level alignment network for domain adaptive
cross-modal retrieval. <em>NEUCOM</em>, <em>440</em>, 207–219. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-modal retrieval is an important but challenging research task in the multimedia community. Most existing works of this task are supervised, which typically train models on a large number of aligned image-text/video-text pairs, making an assumption that training and testing data are drawn from the same distribution. If this assumption does not hold, traditional cross-modal retrieval methods may experience a performance drop at the evaluation. In this paper, we introduce a new task named as domain adaptive cross-modal retrieval , where training (source) data and testing (target) data are from different domains. The task is challenging, as there are not only the semantic gap and modality gap between visual and textual items, but also domain gap between source and target domains. Therefore, we propose a Multi-level Alignment Network (MAN) that has two mapping modules to project visual and textual modalities in a common space respectively, and three alignments are used to learn more discriminative features in the space. A semantic alignment is used to reduce the semantic gap , a cross-modality alignment and a cross-domain alignment are employed to alleviate the modality gap and domain gap. Extensive experiments in the context of domain-adaptive image-text retrieval and video-text retrieval demonstrate that our proposed model, MAN, consistently outperforms multiple baselines, showing a superior generalization ability for target data. Moreover, MAN establishes a new state-of-the-art for the large-scale text-to-video retrieval on TRECVID 2017, 2018 Ad-hoc Video Search benchmark.},
  archive      = {J_NEUCOM},
  author       = {Jianfeng Dong and Zhongzi Long and Xiaofeng Mao and Changting Lin and Yuan He and Shouling Ji},
  doi          = {10.1016/j.neucom.2021.01.114},
  journal      = {Neurocomputing},
  pages        = {207-219},
  shortjournal = {Neurocomputing},
  title        = {Multi-level alignment network for domain adaptive cross-modal retrieval},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progressive principle component analysis for compressing
deep convolutional neural networks. <em>NEUCOM</em>, <em>440</em>,
197–206. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a progressive principal component analysis (PPCA) method for compressing deep convolutional neural networks . The proposed method starts with a prespecified layer and progressively moves on to the final output layer. For each target layer, PPCA conducts kernel principal component analysis for the estimated kernel weights. This leads to a significant reduction in the number of kernels in the current layer. As a consequence, the channels used for the next layer are also reduced substantially. This is because the number of kernels used in the current layer determines the number of channels for the next layer. For convenience, we refer to this as a progressive effect. As a consequence, the entire model structure can be substantially compressed, and both the number of parameters and the inference costs can be substantially reduced. Meanwhile, the prediction accuracy remains very competitive with respect to that of the baseline model . The effectiveness of the proposed method is evaluated on a number of classical CNNs (AlexNet, VGGNet, ResNet and MobileNet) and benchmark datasets. The empirical findings are very encouraging. The code is available at https://github.com/zhoujing89/ppca .},
  archive      = {J_NEUCOM},
  author       = {Jing Zhou and Haobo Qi and Yu Chen and Hansheng Wang},
  doi          = {10.1016/j.neucom.2021.01.035},
  journal      = {Neurocomputing},
  pages        = {197-206},
  shortjournal = {Neurocomputing},
  title        = {Progressive principle component analysis for compressing deep convolutional neural networks},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bi-directional skip connection feature pyramid network and
sub-pixel convolution for high-quality object detection.
<em>NEUCOM</em>, <em>440</em>, 185–196. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In existing state-of-the-art object detectors, feature pyramid networks (FPN) and multiscale feature fusion are still typically used. The traditional FPN fusion strategy is based on the top-down fusion of high-level semantic information. The top-down fusion method generally uses upsampling based on interpolation, which often results in jagged edges, mosaic distortion, and edge blurring. Moreover, in order to improve accuracy, the FPN-based fusion strategy must add multiple top-down components for fusion, which increases computational costs and leads to a poor balance between precision and speed. In this paper, we propose a novel fusion strategy based on a backbone network . We aim to design simple and efficient components for high-quality object detection. Our proposed strategy, bi-directional skip connection FPN (BiSCFPN), consists of three components: a bi-directional skip connection (BiSC), a selective dilated convolution module (SDCM), and sub-pixel convolution (SP). The BiSC aims to enhance semantic information between different feature layers in the backbone network and simultaneously uses the SDCM to improve the receptive fields of differently sized targets in the fusion stage. Finally, SP learns the relationship between the features of upsampling and downsampling images to effectively mitigate the problems caused by the traditional interpolation method. BiSCFPN achieves an average precision of 38.2\% in tests with the Microsoft Common Objects in Context (MS COCO) test-dev dataset at a real-time speed of ~ 50 FPS ( 608 × 608 ) using an Nvidia GeForce RTX 2080 Ti graphics card and significantly improves the balance between precision and speed.},
  archive      = {J_NEUCOM},
  author       = {Shuqi Xiong and Xiaohong Wu and Honggang Chen and Linbo Qing and Tong Chen and Xiaohai He},
  doi          = {10.1016/j.neucom.2021.01.021},
  journal      = {Neurocomputing},
  pages        = {185-196},
  shortjournal = {Neurocomputing},
  title        = {Bi-directional skip connection feature pyramid network and sub-pixel convolution for high-quality object detection},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered control for input constrained non-affine
nonlinear systems based on neuro-dynamic programming. <em>NEUCOM</em>,
<em>440</em>, 175–184. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a neuro-dynamic programming (NDP)-based event-triggered control (ETC) method is proposed for unknown non-affine nonlinear systems with input constraints. A neural network-based identifier is established with measurable input and output data to learn the unknown system dynamics. Then, a critic neural network is employed to approximate the value function for solving the event-triggered Hamilton-Jacobi-Bellman equation. Furthermore, an NDP-based ETC scheme is developed, which samples the states and updates the control law when the triggering condition is violated. Compared with the traditional time-triggered control methods, the ETC method can reduce computational burden, communication cost and bandwidth. In addition, the stability of the closed-loop system and the weight error convergence of the critic neural network are provided based on the Lyapunov’s direct method. The intersamling time is proved to be bounded by a positive constant, which excludes the Zeno behavior. Finally, two case studies are provided to verify the effectiveness of the developed ETC method.},
  archive      = {J_NEUCOM},
  author       = {Shunchao Zhang and Bo Zhao and Yongwei Zhang},
  doi          = {10.1016/j.neucom.2021.01.116},
  journal      = {Neurocomputing},
  pages        = {175-184},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered control for input constrained non-affine nonlinear systems based on neuro-dynamic programming},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-stage dimension reduction for expensive sparse
multi-objective optimization problems. <em>NEUCOM</em>, <em>440</em>,
159–174. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A number of sparse multi-objective optimization problems (SMOPs) exist in the real world. Decision variables in their Pareto optimal solutions are not only large-scale but also very sparse, most decision variables are zero, which poses difficulties for the optimization. Existing multi-objective evolutionary algorithms need many function evaluations to handle the large number of decision variables, which is not available for the real-world problems with expensive function evaluations. However, applying surrogate-assisted evolutionary algorithms (SAEAs), proposed for expensive problems, to SMOPs also often falls into the curse of dimensionality. To deal with the dilemma, we propose a multi-stage dimension reduction method for expensive SMOPs to make SAEAs capable to handle. A non-dominated sorting based feature selection is executed by assessing each decision variable independently in the first stage. The sparsity and the specific non-zero decision variables are adaptively determined in an evolutionary process and the dimension of the problem is further reduced accordingly. Then the number of dimension-reduced subproblems are determined by an estimation of the potential calculation cost based on the determined sparsity and non-zero decision variables. Then, an SAEA is adopted for these dimension-reduced subproblems. Each optimal solution obtained is supplemented with a certain number of zero to ensure that its dimension is consistent with the original problem. The number of function evaluations required for each problem is affected by the varying decision variables in the dimension reduction process, so the cost of the proposed algorithm is determined adaptively in different problems. Experiment results on a test suite and one application problem show that the proposed algorithm achieves good performance on SMOPs in the case of limited computation budget.},
  archive      = {J_NEUCOM},
  author       = {Zheng Tan and Handing Wang and Shulei Liu},
  doi          = {10.1016/j.neucom.2021.01.115},
  journal      = {Neurocomputing},
  pages        = {159-174},
  shortjournal = {Neurocomputing},
  title        = {Multi-stage dimension reduction for expensive sparse multi-objective optimization problems},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel hyperspectral unmixing model based on multilayer NMF
with hoyer’s projection. <em>NEUCOM</em>, <em>440</em>, 145–158. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral remote sensing is an important earth observation method with wide application. But the low spatial resolution of hyperspectral images makes it difficult to distinguish the ground objects. The hyperspectral image unmixing is a task to estimate the spectral signatures and corresponding fractional abundances. However, the unmixing speed and efficiency are still limited by traditional structures. In this paper, a novel multilayer nonnegative matrix factorization framework is proposed with Hoyer’s projector, called HP-MLNMF. The well-known framework, multilayer nonnegative factorization (MLNMF), is completely restructured and enhanced by introducing the Hoyer’s projector to provide the iteration directivity of the structure in the unmixing process. Besides, a novel sparse constraint to spectral signatures suitable for this structure is found as l 1 / 4 l1/4 -norm based on some experimental discussions. Moreover, the l p lp -norm is utilized to find the possible sparest solution for abundance terms. Finally, HP-MLNMF is compared with some representative and state-of-art methods on synthetic and real-world hyperspectral image datasets. Experiments indicate that our method performances well in most cases.},
  archive      = {J_NEUCOM},
  author       = {Yuan Yuan and Zihan Zhang and Ganchao Liu},
  doi          = {10.1016/j.neucom.2021.01.028},
  journal      = {Neurocomputing},
  pages        = {145-158},
  shortjournal = {Neurocomputing},
  title        = {A novel hyperspectral unmixing model based on multilayer NMF with hoyer’s projection},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Minimum unbiased risk estimate based 2DPCA for color image
denoising. <em>NEUCOM</em>, <em>440</em>, 127–144. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Low-rank approximation of matrices plays an important role in many application scenarios, including image denoising . This paper introduces a new low-rank approximation method named minimum unbiased risk estimate formulation of 2DPCA (MURE-2DPCA). MURE-2DPCA starts by considering the problem of estimating noise-free matrices from observations, and can exhibit robustness to outliers. In the case of a single data matrix constructed with Gaussian vectors, we find that the optimal dimension of the principal subspace can be determined automatically from the data itself. Based on MURE-2DPCA, a three-step algorithm is developed for color image denoising . Experiments demonstrate the ability and efficiency of our algorithm in achieving the denoising task.},
  archive      = {J_NEUCOM},
  author       = {Mingli Wang and Xinwei Jiang and Junbin Gao and Tianjiang Wang and Chunlong Hu and Fang Liu and Qi Feng},
  doi          = {10.1016/j.neucom.2020.12.117},
  journal      = {Neurocomputing},
  pages        = {127-144},
  shortjournal = {Neurocomputing},
  title        = {Minimum unbiased risk estimate based 2DPCA for color image denoising},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image scene geometry recognition using low-level features
fusion at multi-layer deep CNN. <em>NEUCOM</em>, <em>440</em>, 111–126.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The image scene geometry recognition is an important element for reconstructing the 3D scene geometry of a single image. It is useful for computer vision applications , such as 3D TV, video categorization, and robot navigation system. A 3D scene geometry with a unique depth represents a rough structure of 2D images. An approach to efficient implementation and achieving high recognition accuracy of 3D scene geometry remains a significant challenges in the computer vision domain. Existing approaches attempt to use the pre-trained deep convolutional neural networks (CNN) models as feature extractor and also explore the benefits of multi-layer features representation for small or medium-size datasets. However, these studies pay little attention to building a discriminative feature representation by exploring the benefits of low-level features fusion with multi-layer feature from a single CNN model. To address this problem, we propose a novel model of image scene geometry recognition in which the low-level handcrafted features are integrated with deep CNN multi-stage features (HF-MSF) by using the feature-fusion and score-level fusion strategies. The low-level features contain rich discriminative information of 3D scene geometry, including shape, color, and depth estimation. In feature-fusion, the multi-layer features at different stages and handcrafted features are fused at an early phase, and in score-level fusion, the handcrafted features are integrated with multi-layer feature of a single CNN model at different stages and each stage is connected with a classifier and then score-level fusion of these classifiers is performed automatically to recognize the scene geometry type. For validation and comparison purposes, two well-known deep learning architectures, namely GoogLeNet and ResNet are employed as a backbone of proposed model. Experimental results exhibited that by taking the advantages of both types of fusion, the proposed HF-MSF model has an improved recognition accuracy of 12.21\% and 4.96\% when compared to G-MS2F model for 12-Scene and 15-Scene image datasets, respectively. Similarly, it improves the accuracy by 3.85\% when compared with the FTOTLM model for the 15-Scene dataset.},
  archive      = {J_NEUCOM},
  author       = {Altaf Khan and Alexander Chefranov and Hasan Demirel},
  doi          = {10.1016/j.neucom.2021.01.085},
  journal      = {Neurocomputing},
  pages        = {111-126},
  shortjournal = {Neurocomputing},
  title        = {Image scene geometry recognition using low-level features fusion at multi-layer deep CNN},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial dimensionality reduction for
diagnosing faults and attacks in cyber-physical systems.
<em>NEUCOM</em>, <em>440</em>, 101–110. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In cyber-physical systems, transforming a large amount of data collected from various sensors onto informative low-dimension data is of paramount importance for efficient monitoring and safe and secure operation of the system. To this aim, this paper proposes two novel dimensionality reduction techniques, where each makes use of two duelling neural networks along with two newly defined constraints of class separability and affinity correlation. Using the original distribution of the high-dimensional data, the goal is to achieve an ideal distribution in a lower-dimensional feature space, while preserving the correlation of features and discriminating samples of distinct classes. These classes are the system states including faults and cyber-attacks. The proposed novel techniques are compared with state-of-the-art dimensionality reduction techniques over several datasets collected from a cyber-physical system. The attained results show that the proposed techniques significantly outperform other techniques.},
  archive      = {J_NEUCOM},
  author       = {Maryam Farajzadeh-Zanjani and Ehsan Hallaji and Roozbeh Razavi-Far and Mehrdad Saif},
  doi          = {10.1016/j.neucom.2021.01.076},
  journal      = {Neurocomputing},
  pages        = {101-110},
  shortjournal = {Neurocomputing},
  title        = {Generative adversarial dimensionality reduction for diagnosing faults and attacks in cyber-physical systems},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Dual part-pooling attentive networks for session-based
recommendation. <em>NEUCOM</em>, <em>440</em>, 89–100. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Session-based recommendation is proposed to predict user preferences in a short anonymous interaction session. There are two kinds of characteristic in the session: sequential dependencies and collective dependencies. Sequential dependencies mean that user-item interactions in the session are strictly ordered, while collective dependencies mean that multiple interactions with a flexible order jointly determine the user’s next behaviors . However, existing methods only take one of the two characteristics into account, which leads to the fact that they can’t model user behavior well. Furthermore, few methods emphasize the first interaction in the session, although user’s initial intention can be reflected by it to a large extent. To this end, we propose a novel model, Dual Part-pooling Attentive Networks for session-based Recommendation (DPAN4Rec), which is capable of capturing the sequential dependencies and collective dependencies of sessions simultaneously. By proposing a part-pooling attention mechanism , DPAN4Rec explores user’s initial intention from first click and filters out noisy clicks in the session. Extensive experiments have been conducted on two benchmark e-commerce datasets, Yoochoose and Diginetica, and the experimental results show that DPAN4Rec outperforms state-of-the-art methods. Furthermore, our study demonstrates that it is necessary to consider both sequential dependencies and collective dependencies in session-based recommendation.},
  archive      = {J_NEUCOM},
  author       = {Xiaokun Zhang and Hongfei Lin and Liang Yang and Bo Xu and Yufeng Diao and Lu Ren},
  doi          = {10.1016/j.neucom.2021.01.092},
  journal      = {Neurocomputing},
  pages        = {89-100},
  shortjournal = {Neurocomputing},
  title        = {Dual part-pooling attentive networks for session-based recommendation},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LSI-LSTM: An attention-aware LSTM for real-time driving
destination prediction by considering location semantics and location
importance of trajectory points. <em>NEUCOM</em>, <em>440</em>, 72–88.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Individual driving final destination prediction supports location-based services such as personalized service recommendations, traffic navigation, and public transport dispatching. However, real-time destination prediction is challenging due to the complexity of temporal dependencies, and the strong influence of travel spatiotemporal semantics and spatial correlations. Besides temporal context, the nearby urban functionalities of traveling zones and departure regions, and the crucial positions on the road network where trajectory points located would reflect the travel intentions of drivers. However, these spatial factors are rarely considered in existing studies. To fill this gap, we propose a real-time individual driving destination prediction model LSI-LSTM based on an attention-aware Long Short-Term Memory (LSTM) by taking Location Semantics and Location Importance of trajectory points into account. More specifically, a trajectory location semantics extraction method (t-LSE) enriches feature description with prior knowledge for implicit travel intentions learning. t-LSE represents urban functionality through Points of Interest (POIs) using Term Frequency-Inverse Document Frequency (TF-IDF). Meanwhile, a novel trajectory spatial attention mechanism (t-SAM) captures the trajectory points that strongly correlate to candidate destinations based on the location importance inferred from the driving status, i.e., turning angle, driving speed, and traveled distance. Comparative experiments with three baseline methods, i.e., Hidden Markov Model, Random Forest, and LSTM, demonstrate significant prediction accuracy improvements of LSI-LSTM on four individual trajectory datasets. Further analyses validate the effectiveness of the proposed semantic extraction method and attention mechanism, and also discuss the factors that may affect the prediction results.},
  archive      = {J_NEUCOM},
  author       = {Zhipeng Gui and Yunzeng Sun and Le Yang and Dehua Peng and Fa Li and Huayi Wu and Chi Guo and Wenfei Guo and Jianya Gong},
  doi          = {10.1016/j.neucom.2021.01.067},
  journal      = {Neurocomputing},
  pages        = {72-88},
  shortjournal = {Neurocomputing},
  title        = {LSI-LSTM: An attention-aware LSTM for real-time driving destination prediction by considering location semantics and location importance of trajectory points},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust license plate signatures matching based on multi-task
learning approach. <em>NEUCOM</em>, <em>440</em>, 58–71. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying a car by its License Plate (LP) is a critical task in many applications, such as travel time estimation, vehicle re-identification, automatic toll collection, etc. Therefore, matching them must be as accurate as possible. This research proposes a novel deep neural network based method and its learning strategy for LP matching (LPM), which is originally from the cognitive-psychology-inspired unified objective function. The proposed method uses a deep Convolutional Neural Network (CNN) model to extract effective visual signature of the LP image. It exploits the multi-task learning approach to optimize the model, which combines two different tasks: (a) parallel letters recognition to transcribe the image-text contents and (b) image classification to classify the distinct LPs. Moreover, it takes profit from the use of image augmentation techniques. The proposed method is evaluated on three datasets of different characteristics. One of them was collected in this research and will be released publicly. The obtained results show that the proposed method performs better than the state-of-the art methods based on the commonly used evaluation metrics and computation time.},
  archive      = {J_NEUCOM},
  author       = {Abul Hasnat and Amir Nakib},
  doi          = {10.1016/j.neucom.2020.12.102},
  journal      = {Neurocomputing},
  pages        = {58-71},
  shortjournal = {Neurocomputing},
  title        = {Robust license plate signatures matching based on multi-task learning approach},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Residual attention graph convolutional network for web
services classification. <em>NEUCOM</em>, <em>440</em>, 45–57. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {More and more attention has been paid to web service classification as it can improve the quality of service discovery and management in the service repository, and can be widely used to locate developers’ desired services. Although traditional classification method based on supervised learning model to this task shows promising results, it still suffered from the following shortcomings: (i) the performance of conventional machine learning methods highly depends on the quality of manual feature engineering; (ii) some classification methods (such as CNN, RNN , etc.) are usually limited to very shallow models due to the vanishing gradient problem and cannot extract more features, which have great impact on the accuracy of web service classification. To overcome these challenges, a novel web service classification model named Residual Attention Graph Convolutional Network (RAGCN) is proposed. Firstly, adding an attention mechanism to the graph convolutional network can assign different weights to the neighborhood nodes without complicated matrix operations or relying on understanding the entire graph structure. Secondly, using residual learning to deepen the depth of the model can extract more features. The comprehensive experimental results on real dataset show that the proposed model outperforms the state-of-the-art approaches and proves its potentially good interpretability for graphical analysis.},
  archive      = {J_NEUCOM},
  author       = {Bing Li and Zhi Li and Yilong Yang},
  doi          = {10.1016/j.neucom.2021.01.089},
  journal      = {Neurocomputing},
  pages        = {45-57},
  shortjournal = {Neurocomputing},
  title        = {Residual attention graph convolutional network for web services classification},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual affordance detection using an efficient attention
convolutional neural network. <em>NEUCOM</em>, <em>440</em>, 36–44. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual affordance detection is an important issue in the field of robotics and computer vision. This paper proposes a novel and practical convolutional neural network architecture that adopts an encoder-decoder architecture for pixel-wise affordance detection. The encoder network comprises two modules: a dilated residual network that is the backbone for feature extraction, and an attention mechanism that is used for modeling long-range, multi-level dependency relations . The decoder network consists of a novel up-sampling layer that maps the low-resolution encoder feature to a high-resolution pixel-wise prediction map. Specifically, integrating an attention mechanism into our network reduces the loss of salient details and improves the feature representation performance of the model. The results of experiments conducted on the University of Maryland dataset (UMD) verify that the proposed network with the attention mechanism and up-sampling layer improved performance compared with classical methods. The proposed method lays the foundation for subsequent research on multi-task learning by physical robots.},
  archive      = {J_NEUCOM},
  author       = {Qipeng Gu and Jianhua Su and Lei Yuan},
  doi          = {10.1016/j.neucom.2021.01.018},
  journal      = {Neurocomputing},
  pages        = {36-44},
  shortjournal = {Neurocomputing},
  title        = {Visual affordance detection using an efficient attention convolutional neural network},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive swarm control for high-order self-organized system
with unknown heterogeneous nonlinear dynamics and unmeasured states.
<em>NEUCOM</em>, <em>440</em>, 24–35. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an adaptive swarm controller for a kind of high-order self-organized system. There are always unknown heterogeneous nonlinear dynamics and unmeasured states in practical systems, which may lead to poor control effects and even system instability. To eliminate these possible problems, a radial basis function neural network approximator is designed to approximate unknown heterogeneous nonlinear dynamics, and a neural network high-gain state observer method is introduced to estimate the unmeasured states of intelligent units. Besides, a novel sliding mode switching approach law is designed to improve sliding mode control . Based on these works, an adaptive swarm controller is proposed to ensure trajectory tracking. With the designed adaptive swarm controller, the high-order self-organized system can achieve aggregation, dispersion, and formation switching in the process of swarm movement. Based on Lyapunov stability theory , we prove the stability of the proposed controller. Finally, according to numerical simulation, the effectiveness of the designed controller is proved.},
  archive      = {J_NEUCOM},
  author       = {Hao Xu and Shengjin Li and Dengxiu Yu and C.L.Philip Chen and Tieshan Li.},
  doi          = {10.1016/j.neucom.2021.01.069},
  journal      = {Neurocomputing},
  pages        = {24-35},
  shortjournal = {Neurocomputing},
  title        = {Adaptive swarm control for high-order self-organized system with unknown heterogeneous nonlinear dynamics and unmeasured states},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TabCellNet: Deep learning-based tabular cell structure
detection. <em>NEUCOM</em>, <em>440</em>, 12–23. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is an increasing demand for automated document processing techniques as the volume of electronic component documents increase. This is most prevalent in the supply chain optimization sector where vast amount of documents need to be processed and is time consuming and prone to error. Detection of tables and table structures serves as a crucial step to automate document processing. While table detection is a well investigated problem, tabular structure detection is more complex, and requires further improvements. To address this, this study proposes a deep learning model that focuses on high precision tabular cell structure detection. The proposed model creates a benchmark for the ICDAR2013 dataset cell structure with comparison to the previous state of the art table detection models as well as proposing alternative models. Our methodology approaches improving table structure detection through the detection of cells instead of row and columns for better generalization capabilities for heterogeneous table structures. Our proposed model advances prior models by improving major parts of the detection pipeline , mainly the two-stage detector, backbone, backbone architecture, and non-maximum-suppression (NMS). TabCellNet consists of Hybrid Task Cascade (HTC) with Combinational Backbone Network (CBNet), dual ResNeXt101 and Soft-NMS to achieve a precision of 89.2\% and recall of 98.7\% on the hand annotated ICDAR2013 cell structure dataset.},
  archive      = {J_NEUCOM},
  author       = {JiChu Jiang and Murat Simsek and Burak Kantarci and Shahzad Khan},
  doi          = {10.1016/j.neucom.2021.01.103},
  journal      = {Neurocomputing},
  pages        = {12-23},
  shortjournal = {Neurocomputing},
  title        = {TabCellNet: Deep learning-based tabular cell structure detection},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visible-infrared cross-modality person re-identification
based on whole-individual training. <em>NEUCOM</em>, <em>440</em>, 1–11.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visible-infrared cross-modality person re-identification (VI-ReID) aims to search person images across cameras of different modalities, which can make up for the problem that ReID cannot be performed through visible images in a dark environment. The difficulty of VI-ReID task is the huge discrepancy between the visible modality and the infrared modality. In this paper, a novel whole-individual training (WIT) model is proposed for VI-ReID, which is based on the idea of pulling in the whole and distinguishing the individuals. Specifically, the model is divided into a whole part and an individual part. Two loss functions are developed in the whole part, namely center maximum mean discrepancy (CMMD) loss and intra-class heterogeneous center (ICHC) loss. Ignoring identity difference and treating each modality as a whole, the CMMD loss pulls in the centers of the two modalities. Ignoring modality difference and treating each identify as a whole, the ICHC loss pulls images with the same identity to its cross-modality center. In the individual part, a cross-modality triplet (CMT) loss is employed, which can distinguish the pedestrian images with different identities. The WIT model can help the network identify pedestrian images in an all-round way. Experiments show that the VI-ReID performance of the proposed method is better than existing technologies on two most popular benchmark datasets SYSU-MM01 and RegDB.},
  archive      = {J_NEUCOM},
  author       = {Jia Sun and Yanfeng Li and Houjin Chen and Yahui Peng and Xiaodi Zhu and Jinlei Zhu},
  doi          = {10.1016/j.neucom.2021.01.073},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Visible-infrared cross-modality person re-identification based on whole-individual training},
  volume       = {440},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The feature generator of hard negative samples for
fine-grained image recognition. <em>NEUCOM</em>, <em>439</em>, 374–382.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The key to solving the fine-grained image recognition is exploring more discriminative features for capturing tiny hints. In particular, the triplet objective function fits well with the fine-grained image recognition task because they capture the semantic similarity between images. However, triplet loss needs many pairs of tuples with hard negative samples, and it takes too much cost. To alleviate this problem, we propose a new framework that generates features of the hard negative samples. The proposed framework consists of three stages: learning part-wise features, enriching refined hard negative samples, and fine-grained image recognition. Our proposed method has achieved state-of-the-art performance in CUB-200-2011, Stanford Cars, FGVC-Aircraft, and DeepFashion datasets. Also, our extensive experiments demonstrate that each stage has a good effect on the final goal.},
  archive      = {J_NEUCOM},
  author       = {Taehung Kim and Kibeom Hong and Hyeran Byun},
  doi          = {10.1016/j.neucom.2020.10.032},
  journal      = {Neurocomputing},
  pages        = {374-382},
  shortjournal = {Neurocomputing},
  title        = {The feature generator of hard negative samples for fine-grained image recognition},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Almost periodic solutions for quaternion-valued neural
networks with mixed delays on time scales. <em>NEUCOM</em>,
<em>439</em>, 363–373. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a class of quaternion-valued neural networks with mixed delays on time scales. By using general Lipschitz condition , contraction mapping principle and exponential dichotomy of linear dynamic equations, we prove the existence and uniqueness and the stability of almost periodic solutions of global exponential neural networks . Finally, one example is given to illustrate the efficiency of our theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Quande Jiang and Qi-Ru Wang},
  doi          = {10.1016/j.neucom.2020.09.063},
  journal      = {Neurocomputing},
  pages        = {363-373},
  shortjournal = {Neurocomputing},
  title        = {Almost periodic solutions for quaternion-valued neural networks with mixed delays on time scales},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph partitioning and graph neural network based
hierarchical graph matching for graph similarity computation.
<em>NEUCOM</em>, <em>439</em>, 348–362. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph similarity computation aims to predict a similarity score between one pair of graphs to facilitate downstream applications, such as finding the most similar chemical compounds similar to a query compound or Fewshot 3D Action Recognition. Recently, some graph similarity computation models based on neural networks have been proposed, which are either based on graph-level interaction or node-level comparison. However, when the number of nodes in the graph increases, it will inevitably bring about reduced representation ability or high computation cost. Motivated by this observation, we propose a graph partitioning and graph neural network-based model, called PSimGNN, to effectively resolve this issue. Specifically, each of the input graphs is partitioned into a set of subgraphs to extract the local structural features directly. Next, a novel graph neural network with an attention mechanism is designed to map each subgraph into an embedding vector. Some of these subgraph pairs are automatically selected for node-level comparison to supplement the subgraph-level embedding with fine-grained information. Finally, coarse-grained interaction information among subgraphs and fine-grained comparison information among nodes in different subgraphs are integrated to predict the final similarity score. Experimental results on graph datasets with different graph sizes demonstrate that PSimGNN outperforms state-of-the-art methods in graph similarity computation tasks using approximate Graph Edit Distance (GED) as the graph similarity metric.},
  archive      = {J_NEUCOM},
  author       = {Haoyan Xu and Ziheng Duan and Yueyang Wang and Jie Feng and Runjian Chen and Qianru Zhang and Zhongbin Xu},
  doi          = {10.1016/j.neucom.2021.01.068},
  journal      = {Neurocomputing},
  pages        = {348-362},
  shortjournal = {Neurocomputing},
  title        = {Graph partitioning and graph neural network based hierarchical graph matching for graph similarity computation},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability analysis of delayed neural networks based on a
relaxed delay-product-type lyapunov functional. <em>NEUCOM</em>,
<em>439</em>, 340–347. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the stability analysis of delayed neural networks . A necessary and sufficient condition for positivity or negativity of the high-order polynomial over a finite interval is derived. An appropriate Lyapunov–Krasovskii functional (LKF), including a relax delay-product-type Lyapunov functional, is constructed. The necessary and sufficient condition of the polynomial inequality and a relaxed delay-product-type Lyapunov functional are employed to derive less conservative stability criteria. Finally, three commonly used numerical examples are presented to demonstrate the effectiveness and less conservativeness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yun Chen and Gang Chen},
  doi          = {10.1016/j.neucom.2021.01.098},
  journal      = {Neurocomputing},
  pages        = {340-347},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of delayed neural networks based on a relaxed delay-product-type lyapunov functional},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical assessment of deep learning approaches to
task-oriented dialog management. <em>NEUCOM</em>, <em>439</em>, 327–339.
(<a href="https://doi.org/10.1016/j.neucom.2020.01.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is providing very positive results in areas related to conversational interfaces, such as speech recognition, but its potential benefit for dialog management has still not been fully studied. In this paper, we perform an assessment of different configurations for deep-learned dialog management with three dialog corpora from different application domains and varying in size, dimensionality and possible system responses. Our results have allowed us to identify several aspects that can have an impact on accuracy, including the approaches used for feature extraction, input representation, context consideration and the hyper-parameters of the deep neural networks employed.},
  archive      = {J_NEUCOM},
  author       = {Lukáš Matějů and David Griol and Zoraida Callejas and José Manuel Molina and Araceli Sanchis},
  doi          = {10.1016/j.neucom.2020.01.126},
  journal      = {Neurocomputing},
  pages        = {327-339},
  shortjournal = {Neurocomputing},
  title        = {An empirical assessment of deep learning approaches to task-oriented dialog management},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved landcover classification using online spectral data
hallucination. <em>NEUCOM</em>, <em>439</em>, 316–326. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We deal with the problem of information fusion driven satellite remote sensing (RS) image/scene classification and propose a generic hallucination architecture considering that all the available sensor information is present during training while some of the image modalities may be absent while testing. It is well-known that different sensors are capable of capturing complementary information for a given geographical area, and a classification module incorporating information from all the sources are expected to produce an improved performance as compared to considering only a subset of the modalities. However, the classical classifier systems inherently require all the features used to train the module to be present for the test instances as well, which may not always be possible for typical remote sensing applications (say, disaster management). As a remedy, we provide a robust solution in terms of a hallucination module that can approximate the missing modalities from the available ones during the decision-making stage. In order to ensure better knowledge transfer during modality hallucination, we explicitly incorporate concepts of knowledge distillation for the purpose of exploring the privileged (side) information in our framework and subsequently introduce an intuitive modular training approach. The proposed network is evaluated extensively on a large-scale corpus of PAN-MS image pairs (scene recognition) as well as on a benchmark hyperspectral image dataset (image classification) where we follow different experimental scenarios and find that the proposed hallucination based module indeed is capable of capturing the multi-source information, albeit the explicit absence of some of the sensor information, and aid in improved scene characterization.},
  archive      = {J_NEUCOM},
  author       = {Saurabh Kumar and Biplab Banerjee and Subhasis Chaudhuri},
  doi          = {10.1016/j.neucom.2021.01.101},
  journal      = {Neurocomputing},
  pages        = {316-326},
  shortjournal = {Neurocomputing},
  title        = {Improved landcover classification using online spectral data hallucination},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep top similarity hashing with class-wise loss for
multi-label image retrieval. <em>NEUCOM</em>, <em>439</em>, 302–315. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the major challenges of learning to hash in large-scale image retrieval is the projective transformation from raw image to binary space with preserving semantic similarity. Recently, several deep hashing methods show many excellent properties compared with traditional hashing based on hand-designed representation. However, most of the existing hashing models only pay attention to the semantic similarity between image pairs, ignoring the ranking information of retrieval results, which limits its performance. In this paper, a novel deep hashing framework, named Deep Top Similarity Hashing with Class-wise loss (DTSH-CW), is proposed to preserve semantic similarity between top images of ranking list and query images. In this proposed framework, CNNs architecture with batch normalization module is adopted to extract deep semantic characteristics. With integrating the position information of images, a top similarity loss is carefully designed to ensure the similarities between top images of ranking list and query images. Unlike pair-wise or triplet-wise loss, by directly leveraging the class labels, a cubic constraint based on Gaussian distribution is introduced to optimize objective function so as to maintain semantic variations of different classes. Furthermore, in order to solve discrete optimization problem, Two-Stage strategy is developed to provide efficient model training. Quantities of comparison experiments on three multi-label benchmark datasets show that our proposed DTSH-CW achieves promising performance compared to several state-of-the-art hashing methods .},
  archive      = {J_NEUCOM},
  author       = {Qibing Qin and Zhiqiang Wei and Lei Huang and Kezhen Xie and Wenfeng Zhang},
  doi          = {10.1016/j.neucom.2021.01.107},
  journal      = {Neurocomputing},
  pages        = {302-315},
  shortjournal = {Neurocomputing},
  title        = {Deep top similarity hashing with class-wise loss for multi-label image retrieval},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain adaptation with feature and label adversarial
networks. <em>NEUCOM</em>, <em>439</em>, 294–301. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning a cross-domain representation from labeled source domains to unlabeled target domains is an important research problem in representation learning . Despite the success of traditional adversarial methods, they proposed to align features from each domain only while neglecting the importance of labels, when fooling a special domain discriminator network. Thus, the discriminator of these approaches merely distinguishes whether the generated features are in-domain or not, which may lead to less class-discriminative features. In this paper, by considering the joint distributions of features and labels in both domains, we present Feature and Label Adversarial Networks (FLAN). As a result, FLAN can generate more discriminative features in both domains. Experimental results on standard unsupervised domain adaptation benchmarks have demonstrated that FLAN can outperform the state-of-art domain invariant representation learning methods.},
  archive      = {J_NEUCOM},
  author       = {Peng Zhao and Wenhua Zang and Bin Liu and Zhao Kang and Kun Bai and Kaizhu Huang and Zenglin Xu},
  doi          = {10.1016/j.neucom.2021.01.062},
  journal      = {Neurocomputing},
  pages        = {294-301},
  shortjournal = {Neurocomputing},
  title        = {Domain adaptation with feature and label adversarial networks},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sparse additive machine with pinball loss. <em>NEUCOM</em>,
<em>439</em>, 281–293. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse additive models have shown promising performance for classification and variable selection in high-dimensional data analysis. However, existing methods are limited to the error metric associated with hinge loss, which are sensitive to noise around the decision boundary. In this paper, we propose a new sparse additive machine with the pinball loss, called as pin-SAM, to make the model more robust to noise around the decision boundary. Theoretical analysis on the excess misclassification error is established by integrating error decomposition and concentration estimation techniques, which shows our pin-SAM can achieve the fast learning rate under appropriate parameter conditions. The empirical studies confirm the effectiveness of the proposed approach on simulated, benchmark and coronal mass ejection data.},
  archive      = {J_NEUCOM},
  author       = {Yingjie Wang and Xin Tang and Hong Chen and Tianjiao Yuan and Yanhong Chen and Han Li},
  doi          = {10.1016/j.neucom.2020.12.129},
  journal      = {Neurocomputing},
  pages        = {281-293},
  shortjournal = {Neurocomputing},
  title        = {Sparse additive machine with pinball loss},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble of autonomous auto-encoders for human activity
recognition. <em>NEUCOM</em>, <em>439</em>, 271–280. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human Activity Recognition is focused on the use of sensing technology to classify human activities and to infer human behavior . While traditional machine learning approaches use hand-crafted features to train their models, recent advancements in neural networks allow for automatic feature extraction. Auto-encoders are a type of neural network that can learn complex representations of the data and are commonly used for anomaly detection . In this work we propose a novel multi-class algorithm which consists of an ensemble of auto-encoders where each auto-encoder is associated with a unique class. We compared the proposed approach with other state-of-the-art approaches in the context of human activity recognition. Experimental results show that ensembles of auto-encoders can be efficient, robust and competitive. Moreover, this modular classifier structure allows for more flexible models. For example, the extension of the number of classes, by the inclusion of new auto-encoders, without the necessity to retrain the whole model.},
  archive      = {J_NEUCOM},
  author       = {Kemilly Dearo Garcia and Cláudio Rebelo de Sá and Mannes Poel and Tiago Carvalho and João Mendes-Moreira and João M.P. Cardoso and André C.P.L.F. de Carvalho and Joost N. Kok},
  doi          = {10.1016/j.neucom.2020.01.125},
  journal      = {Neurocomputing},
  pages        = {271-280},
  shortjournal = {Neurocomputing},
  title        = {An ensemble of autonomous auto-encoders for human activity recognition},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Two-stream deep spatial-temporal auto-encoder for
surveillance video abnormal event detection. <em>NEUCOM</em>,
<em>439</em>, 256–270. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the improvement of public security awareness, video anomaly detection has become an indispensable demand in surveillance videos . To improve the accuracy of video anomaly detection , this paper proposes a novel two-stream spatial-temporal architecture called Two-Stream Deep Spatial-Temporal Auto-Encoder (Two-Stream DSTAE), which is composed of a spatial stream DSTAE and a temporal stream DSTAE. Firstly, the spatial stream extracts appearance characteristics whereas the temporal stream extracts the motion patterns, respectively. Then, based on the novel policy joint reconstruction error, this model fuses the spatial stream and the temporal stream to extract spatial-temporal characteristics to detect anomalies . Furthermore, since the optical flow is invariant to appearances such as color or light, we introduce optical flow to enhance the capability of extracting continuity between adjacent frames and inter-frame motion information. We demonstrate the accuracy of the proposed method on the publicly available standard datasets: UCSD, Avenue and UMN datasets. Our experiments demonstrate high accuracy, which is superior to the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Tong Li and Xinyue Chen and Fushun Zhu and Zhengyu Zhang and Hua Yan},
  doi          = {10.1016/j.neucom.2021.01.097},
  journal      = {Neurocomputing},
  pages        = {256-270},
  shortjournal = {Neurocomputing},
  title        = {Two-stream deep spatial-temporal auto-encoder for surveillance video abnormal event detection},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural-network-based formation control with collision,
obstacle avoidance and connectivity maintenance for a class of
second-order nonlinear multi-agent systems. <em>NEUCOM</em>,
<em>439</em>, 243–255. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a formation control strategy with collision, obstacle avoidance and connectivity maintenance is developed for a class of second-order nonlinear multi-agent systems under external disturbances. Firstly, in order to handle the nonlinear dynamics of the multi-agent systems and the unknown disturbances in the environment, neural network (NN) techniques are employed in the proposed control strategy. Then, the distributed formation controller with collision, obstacle avoidance is designed by combining artificial potential field (APF) methods and leader–follower formation methods. Secondly, due to the collision or obstacle avoidance terms within the formation controller may result in large separation distance among agents and each agent’s communication distance is limited by its hardware, the collision or obstacle avoidance terms increase the chance of losing connectivity between agents. In order to guarantee the connectivity of the formation, the connectivity maintenance controller is designed with taking the communication topology into account. Based on Lyapunov stability theory , it is proved that the stability of the closed-loop multi-agent systems can be guaranteed. Finally, the simulation results verify the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Shun Yang and Weiwei Bai and Tieshan Li and Quan Shi and Yue Yang and Yue Wu and C. L. Philip Chen},
  doi          = {10.1016/j.neucom.2020.12.106},
  journal      = {Neurocomputing},
  pages        = {243-255},
  shortjournal = {Neurocomputing},
  title        = {Neural-network-based formation control with collision, obstacle avoidance and connectivity maintenance for a class of second-order nonlinear multi-agent systems},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging neighborhood session information with dual
attentive neural network for session-based recommendation.
<em>NEUCOM</em>, <em>439</em>, 234–242. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of user uncertainty and limited information, predicting user preference is a challenging work in many online services, e.g., e-commerce and media streaming. Recent advances in session-based recommendation mostly focus on mining more available information within the current session. However, those methods ignored the sessions with similar context for the current session, which contains rich collaborative information. Therefore, in this study, we proposed a novel Leveraging Neighborhood Session Information with Dual Attentive Neural Network (LNIDA) for session-based recommendation. Specifically, LNIDA contains two main components, i.e., Current Session Encoder (CSE) and Neighborhood Session Encoder (NSE). The CSE module exploits an item-level attention mechanism to model user’s own information in the current session, and the NSE module further captures neighborhood collaborative information via a session-level attention. Then, a simple co-attention fusion mechanism is used to dynamically combine information from the CSE and NSE. Finally, to verify the performance of LNIDA, we conduct extensive experiments on three benchmark datasets, YOOCHOOSE and DIGINETICA, and the experiment results clearly show the effectiveness of LNIDA. Furthermore, we find out that LNIDA can improve performance when modeling the current session information and the neighborhood session information simultaneously.},
  archive      = {J_NEUCOM},
  author       = {Yuan Wu and Jin Gou},
  doi          = {10.1016/j.neucom.2021.01.051},
  journal      = {Neurocomputing},
  pages        = {234-242},
  shortjournal = {Neurocomputing},
  title        = {Leveraging neighborhood session information with dual attentive neural network for session-based recommendation},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting energy cost of public buildings by artificial
neural networks, CART, and random forest. <em>NEUCOM</em>, <em>439</em>,
223–233. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper deals with modeling the cost of energy consumed in public buildings by leveraging three machine learning methods: artificial neural networks, CART, and random forest regression trees. Energy consumption is one of the major issues in global and national policies, therefore scientific efforts in creating prediction models of energy consumption and cost are highly important. One of the largest energy consumers in every state is its public sector, consisting of educational, health, public administration, military, and other types of public buildings. Recent technologies based on sensor networks and Big data platforms enable collection of large amounts of data that could be used to analyze energy consumption and cost. A real data from Croatian public sector is used in this paper including a large number of constructional, energetic, occupational, climate and other attributes. The algorithms for data pre-processing and modeling by optimizing parameters are suggested. Three strategies were tested: (1) with all available variables, (2) with a filter-based variable selection, and (3) with a wrapper-based variable selection which integrates Boruta algorithm and random forest. Prediction models of energy cost are created using two approaches: (a) comparative usage of artificial neural networks and two types of regression trees, CART and random forest, and (b) integration of RF-Boruta variable selection and machine learning methods for prediction. A cross-validation procedure was used to optimize the artificial neural network and regression tree topology, as well to select the most appropriate activation function. Along with creating a prediction model, the aim of the paper was also to extract the relevant predictors of energy cost in public buildings which are important in planning the construction or renovation of buildings. The results have shown that the second approach which integrates machine learning with Boruta method, where the random forest algorithm is used for both variable reduction and prediction modeling, has produced a higher accuracy of prediction than the individual usage of three machine learning methods. Such findings confirm the potential of hybrid machine learning methods which are suggested in previous research, but in favor of random forest method over CART and artificial neural networks. Regarding the variable selection, the model has extracted heating and occupational data as the most important, followed by constructional, cooling, electricity, and lighting attributes. The model could be implemented in public buildings information systems and their IoT networks within the concept of smart buildings and smart cities.},
  archive      = {J_NEUCOM},
  author       = {Marijana Zekić-Sušac and Adela Has and Marinela Knežević},
  doi          = {10.1016/j.neucom.2020.01.124},
  journal      = {Neurocomputing},
  pages        = {223-233},
  shortjournal = {Neurocomputing},
  title        = {Predicting energy cost of public buildings by artificial neural networks, CART, and random forest},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed reinforcement learning algorithm of operator
service slice competition prediction based on zero-sum markov game.
<em>NEUCOM</em>, <em>439</em>, 212–222. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a key enabling technology in the emerging network, network slicing can dynamically provide on-demand service with distinct logical slice instance. While most related studies have mainly focused on resource management, this study targets solving business competition between two operator slices using artificial intelligence . In this competition, each operator slice tries to maximize its own payoff, meanwhile its opponent strives to minimize it. Moreover, two operators update their marketing strategies over time. Therefore, predicting its result is a challenge. After the zero-sum Markov game is modeled for the research problem, we present the min–max Q learning algorithm. In each market state, each slice attains its temporary optimal strategy using the min–max algorithm. In the Markov decision process , Q value is dynamically modified under different market states, and the final Q value presents predictive result for this competition. Finally, a mass of numerical results prove that the min–max Q learning algorithm outperforms the repeated game, in which market state is invariable over time.},
  archive      = {J_NEUCOM},
  author       = {Guomin Wu and Guoping Tan and Jinxin Deng and Defu Jiang},
  doi          = {10.1016/j.neucom.2021.01.061},
  journal      = {Neurocomputing},
  pages        = {212-222},
  shortjournal = {Neurocomputing},
  title        = {Distributed reinforcement learning algorithm of operator service slice competition prediction based on zero-sum markov game},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Meta-learning for few-shot bearing fault diagnosis under
complex working conditions. <em>NEUCOM</em>, <em>439</em>, 197–211. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based bearing fault diagnosis has been systematically studied in recent years. However, the success of most of these methods relies heavily on massive labeled data, which is not always available in real production environments. Training a robust bearing fault diagnosis model with limited data and working well under complex working conditions remains a challenge. In this paper, a novel meta-learning fault diagnosis method (MLFD) based on model-agnostic meta-learning is proposed to address this issue. The raw signals of different working conditions are first converted to time–frequency images and then randomly sampled to form tasks for MLFD according to the protocol of meta-learning. The MLFD model acquires prior knowledge by optimizing initialization parameters based on multiple fault classification tasks of known working conditions during the meta-training process, and achieves fast and accurate few-shot bearing fault diagnosis under unseen working conditions by leveraging the learned knowledge. To comprehensively evaluate the performance of our method, a series of experiments were conducted to simulate different industrial scenarios based on the Case Western Reserve University Bearing Fault Benchmark, and the results demonstrate the superiority of MLFD in solving the few-shot fault classification problem under complex working conditions.},
  archive      = {J_NEUCOM},
  author       = {Chuanjiang Li and Shaobo Li and Ansi Zhang and Qiang He and Zihao Liao and Jianjun Hu},
  doi          = {10.1016/j.neucom.2021.01.099},
  journal      = {Neurocomputing},
  pages        = {197-211},
  shortjournal = {Neurocomputing},
  title        = {Meta-learning for few-shot bearing fault diagnosis under complex working conditions},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Online common change-point detection in a set of
nonstationary categorical time series. <em>NEUCOM</em>, <em>439</em>,
176–196. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Categorical sequences are widely used in various domains to describe the evolutionary state of the process under study. This article addresses the problem of behavioral change detection for multiple categorical time series. Relying on the sequential likelihood ratio test, an online change detection method is proposed based on the joint modeling of all the categorical sequences. To model the joint probability density, a nonhomogeneous Markov model is used. It allows modeling the transition dynamics over time and considering their dependence on some exogenous factors that may influence the behavior changes . An adaptive threshold is learned using Monte Carlo simulations to detect different changes and reduce false alarms. The performance of the proposed method is evaluated using two real-world and four synthetic datasets . It is compared with two state-of-the-art change detection methods, namely logistic regression and homogeneous Markov model . The experimentation using synthetic datasets highlights the proposed method’s effectiveness in terms of both the detection precision and the detection delay. The real-world data are issued from a water network and school-to-work transition. The analysis of the model estimated parameters allows us to characterize the detected changes in a real-world context.},
  archive      = {J_NEUCOM},
  author       = {Milad Leyli-Abadi and Allou Samé and Latifa Oukhellou and Nicolas Cheifetz and Pierre Mandel and Cédric Féliers and Véronique Heim},
  doi          = {10.1016/j.neucom.2021.01.066},
  journal      = {Neurocomputing},
  pages        = {176-196},
  shortjournal = {Neurocomputing},
  title        = {Online common change-point detection in a set of nonstationary categorical time series},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Zero-shot action recognition in videos: A survey.
<em>NEUCOM</em>, <em>439</em>, 159–175. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot action recognition has attracted attention in the last years and many approaches have been proposed for recognition of objects, events and actions in images and videos. There is a demand for methods that can classify instances from classes that are not present in the training of models, especially in the complex problem of automatic video understanding, since collecting, annotating and labeling videos are difficult and laborious tasks. We have identified that there are many methods available in the literature, however, it is difficult to categorize which techniques can be considered state of the art. Despite the existence of some surveys about zero-shot action recognition in still images and experimental protocol, there is no work focused on videos. Therefore, we present a survey of the methods that comprise techniques to perform visual feature extraction and semantic feature extraction as well to learn the mapping between these features considering specifically zero-shot action recognition in videos. We also provide a complete description of datasets, experiments and protocols, presenting open issues and directions for future work, essential for the development of the computer vision research field.},
  archive      = {J_NEUCOM},
  author       = {Valter Estevam and Helio Pedrini and David Menotti},
  doi          = {10.1016/j.neucom.2021.01.036},
  journal      = {Neurocomputing},
  pages        = {159-175},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot action recognition in videos: A survey},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks with finite-time convergence for solving
time-varying linear complementarity problem. <em>NEUCOM</em>,
<em>439</em>, 146–158. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-varying linear complementarity problem (TLCP) has received a great deal of attention due to its broad variety of scientific and engineering applications. Several efficient Zhang neural networks are introduced for solving TLCP in this paper. Theoretical analysis shows that the related error function of the model proposed in this paper eventually tends to zero. The state convergence time periods of those Zhang neural networks with three types of activation functions are proved to be finite and can be quantitatively estimated by using some given parameters. Further, it is shown that the proposed neural network is of noise-tolerance, which means the neural network is more appropriate for a wider application. Moreover, in order to implement neural network numerically, a related discrete-time version is also studied. Finally, numerical simulations confirm the analysis of the proposed models concretely.},
  archive      = {J_NEUCOM},
  author       = {Haojin Li and Shuai Shao and Sitian Qin and Yunbo Yang},
  doi          = {10.1016/j.neucom.2021.01.015},
  journal      = {Neurocomputing},
  pages        = {146-158},
  shortjournal = {Neurocomputing},
  title        = {Neural networks with finite-time convergence for solving time-varying linear complementarity problem},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Real-time semantic segmentation via sequential knowledge
distillation. <em>NEUCOM</em>, <em>439</em>, 134–145. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep model-based semantic segmentation has received ever increasing research focus in recent years. However, due to the complex model architectures, existing works are still unable to achieve high accuracy in real-time applications. In this paper, we propose a novel Sequential Prediction Network (termed SPNet) to seek a better trade-off between accuracy and efficiency. SPNet is also an end-to-end encoder-decoder architecture, which introduces a sequential prediction method to spread the contextual information from the low-level layers to the high-level layers. Besides, the proposed method is equipped with a stream Spatial Semantic and Edge Loss (termed SEL) and an adversarial network at multiple resolutions, which greatly improves the segmentation accuracy with a negligible increase in computation cost. To further utilize the extra unlabeled data , we present a knowledge distillation scheme to distill the structured knowledge from cumbersome to compact networks. Without using any pre-trained model, our method achieves state-of-the-art performance among exiting real-time segmentation models on several challenging datasets. Impressively, on the Cityscapes test dataset, it obtains 75.8\% 75.8\% mIoU at a speed of 61.2 61.2 FPS.},
  archive      = {J_NEUCOM},
  author       = {Jipeng Wu and Rongrong Ji and Jianzhuang Liu and Mingliang Xu and Jiawen Zheng and Ling Shao and Qi Tian},
  doi          = {10.1016/j.neucom.2021.01.086},
  journal      = {Neurocomputing},
  pages        = {134-145},
  shortjournal = {Neurocomputing},
  title        = {Real-time semantic segmentation via sequential knowledge distillation},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochastic stability of fractional-order markovian jumping
complex-valued neural networks with time-varying delays.
<em>NEUCOM</em>, <em>439</em>, 122–133. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the problem of stochastic stability analysis for fractional-order Markovian jumping complex-valued neural networks (MJCVNNs) with time-varying delays. The novelty of this study is emphasized in two phases. In first phase, MJCVNNs is considered in the form of fractional-order systems. Secondly, complex-valued Wirtinger based integral inequality is newly constructed. The existence and uniqueness conditions of the proposed systems are derived based on the homeomorphism theorem in the complex domain. Then, the stochastic stability condition is derived in terms of linear matrix inequalities (LMIs) for the MJCVNNs by employing Lyapunov indirect method. The feasibility of the derived conditions is verified by the numerical examples and their simulation results are demonstrated to show the effectiveness of the fractional-order derivatives and proposed approach.},
  archive      = {J_NEUCOM},
  author       = {R. Vijay Aravind and P. Balasubramaniam},
  doi          = {10.1016/j.neucom.2021.01.053},
  journal      = {Neurocomputing},
  pages        = {122-133},
  shortjournal = {Neurocomputing},
  title        = {Stochastic stability of fractional-order markovian jumping complex-valued neural networks with time-varying delays},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy k-nearest neighbors with monotonicity constraints:
Moving towards the robustness of monotonic noise. <em>NEUCOM</em>,
<em>439</em>, 106–121. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.152">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a new model based on Fuzzy k -Nearest Neighbors for classification with monotonic constraints, Monotonic Fuzzy k -NN (MonF k NN). Real-life data-sets often do not comply with monotonic constraints due to class noise. MonF k NN incorporates a new calculation of fuzzy memberships, which increases robustness against monotonic noise without the need for relabeling. Our proposal has been designed to be adaptable to the different needs of the problem being tackled. In several experimental studies, we show significant improvements in accuracy while matching the best degree of monotonicity obtained by comparable methods. We also show that MonF k NN empirically achieves improved performance compared with Monotonic k -NN in the presence of large amounts of class noise.},
  archive      = {J_NEUCOM},
  author       = {Sergio González and Salvador García and Sheng-Tun Li and Robert John and Francisco Herrera},
  doi          = {10.1016/j.neucom.2019.12.152},
  journal      = {Neurocomputing},
  pages        = {106-121},
  shortjournal = {Neurocomputing},
  title        = {Fuzzy k-nearest neighbors with monotonicity constraints: Moving towards the robustness of monotonic noise},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Efficient index-independent approaches for the collective
spatial keyword queries. <em>NEUCOM</em>, <em>439</em>, 96–105. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In abundant location-based service applications, it is necessary to process continuous spatial keyword queries over geo-textual data streaming. As an important spatial keyword query, the collective spatial keyword (CSK) query aims to find a set of objects such that it covers all the given keywords collectively, the objects within the set are nearest to the query point, and it has the minimum distance between different objects. The existing approaches for the CSK query are mostly index-based algorithms. Although these approaches gain superior performance, their applicability is significantly limited by the necessity to create an index to organize the dataset. Therefore, these index-based approaches cannot be utilized to process data streaming that prevalently exists in most location-based service applications. In addition, the existing algorithms have much room for improvement as the distances between different objects are overlooked when generating feasible candidate sets. Moreover, the results returned by the proposed algorithms could be further refined to offer better decision support for users. In this paper, a greedy algorithm and an approximate algorithm with a provable approximate bound are proposed for the CSK query. Our approaches are appropriate to the CSK queries where the datasets are not suitable to be organized by indexes and can get better query results with less objects and smaller function scores. To boost the query performance , new pruning strategies and heuristic rules are developed. The experimental results demonstrate scalability, efficiency, and effectiveness of the proposed algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zhibang Yang and Yifu Zeng and Jiayi Du and Fangmin Li and Ahmad Salah},
  doi          = {10.1016/j.neucom.2020.06.150},
  journal      = {Neurocomputing},
  pages        = {96-105},
  shortjournal = {Neurocomputing},
  title        = {Efficient index-independent approaches for the collective spatial keyword queries},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Consensus of time-delay stochastic multiagent systems with
impulsive behavior and exogenous disturbances. <em>NEUCOM</em>,
<em>439</em>, 86–95. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This note investigates the consensus problem of stochastic time-delay dynamical multiagent systems with impulsive behavior . The impulse instants of each agent are not necessarily synchronized with other agents. We provide a compact framework of the overall system then a classical distributed consensus protocol is investigated to guarantee practical exponential consensus of the multiagent system. For each agent, an event-triggered mechanism is used to sample and update the control signals only when its error exceeds the combinational measurements of its neighboring agents. By using the stability theory of stochastic dynamics and the properties of the Laplacian matrix , sufficient condition is presented to guarantee the synchronization among agents. A numerical example is presented to show the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Bilal J. Karaki and Magdi S. Mahmoud},
  doi          = {10.1016/j.neucom.2020.12.077},
  journal      = {Neurocomputing},
  pages        = {86-95},
  shortjournal = {Neurocomputing},
  title        = {Consensus of time-delay stochastic multiagent systems with impulsive behavior and exogenous disturbances},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Haze concentration adaptive network for image dehazing.
<em>NEUCOM</em>, <em>439</em>, 75–85. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based methods have attracted considerable interest in image dehazing. However, most existing methods are not well adapted to different hazy conditions, especially when dealing with the heavily hazy scene. There is often a significant amount of haze that remains in the images recovered by most methods. To address this issue, we propose an end-to-end Haze Concentration Adaptive Network (HCAN), including a pyramid feature extractor (PFE), a feature enhancement module (FEM), and a multi-scale feature attention module (MSFAM) for image dehazing. Specifically, PFE based on the feature pyramid structure leverages complementary features from different CNN layers to help the clear image prediction. Then, FEM fuses four kinds of images with different haze density (i.e., three recovered images in the FEM with light haze density, and the input hazy image with strong haze condition) to guide the network to adaptively perceive images under different haze conditions. Finally, MSFAM is designed under two principles, multi-scale structure and attention mechanism . It is used to help the network produce a clear image with more details, and ease the network training. Comprehensive experiments demonstrate that the proposed HCAN performs favorably against the state-of-the-art methods in terms of PSNR, SSIM, and visual effect. The results, per-trained models and code are available at https://github.com/TaoWangzj/HCAN .},
  archive      = {J_NEUCOM},
  author       = {Tao Wang and Li Zhao and Pengcheng Huang and Xiaoqin Zhang and Jiawei Xu},
  doi          = {10.1016/j.neucom.2021.01.042},
  journal      = {Neurocomputing},
  pages        = {75-85},
  shortjournal = {Neurocomputing},
  title        = {Haze concentration adaptive network for image dehazing},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards accurate RGB-d saliency detection with complementary
attention and adaptive integration. <em>NEUCOM</em>, <em>439</em>,
63–74. (<a href="https://doi.org/10.1016/j.neucom.2020.12.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Saliency detection based on the complementary information from RGB images and depth maps has recently gained great popularity. In this paper, we propose C omplementary A ttention and A daptive I ntegration Net work ( CAAI-Net ), a novel RGB-D saliency detection model that integrates complementary attention based feature concentration and adaptive cross-modal feature fusion into a unified framework for accurate saliency detection. Specifically, we propose a context-aware complementary attention (CCA) module, which consists of a feature interaction component, a complementary attention component, and a global-context component. The CCA module first utilizes the feature interaction component to extract rich local context features. The resulting features are then fed into the complementary attention component, which employs the complementary attention generated from adjacent levels to guide the attention at the current layer so that the mutual background disturbances are suppressed and the network focuses more on the areas with salient objects. Finally, we utilize a specially-designed adaptive feature integration (AFI) module, which sufficiently considers the low-quality issue of depth maps, to aggregate the RGB and depth features in an adaptive manner. Extensive experiments on six challenging benchmark datasets demonstrate that CAAI-Net is an effective saliency detection model and outperforms nine state-of-the-art models in terms of four widely-used metrics. In addition, extensive ablation studies confirm the effectiveness of the proposed CCA and AFI modules.},
  archive      = {J_NEUCOM},
  author       = {Hong-Bo Bi and Zi-Qi Liu and Kang Wang and Bo Dong and Geng Chen and Ji-Quan Ma},
  doi          = {10.1016/j.neucom.2020.12.125},
  journal      = {Neurocomputing},
  pages        = {63-74},
  shortjournal = {Neurocomputing},
  title        = {Towards accurate RGB-D saliency detection with complementary attention and adaptive integration},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep convolutional neural network architecture design as a
bi-level optimization problem. <em>NEUCOM</em>, <em>439</em>, 44–62. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the last decade, deep neural networks have shown a great performance in many machine learning tasks such as classification and clustering. One of the most successful networks is the CNN (Convolutional Neural Network), which has been applied in many application domains such as pattern recognition, medical diagnosis, and signal processing. Despite the very interesting performance of CNNs, their architecture design is still so far a major challenge for researchers and practitioners. Several works have been proposed in the literature with the aim to find optimized architectures such as ResNet and VGGNet. Unfortunately, most of these architectures are either manually defined by experts or automatically designed by greedy induction algorithms. Recent works suggest the use of Evolutionary Algorithms (EAs) thanks to their ability to escape locally-optimal architectures. Despite the fact that EAs have shown interesting performance, researchers in this direction have considered the design task as a single-level optimization problem ; which represents the main research gap we tackle in this paper. The main contribution behind our work consists in the fact that CNN architecture design has a hierarchical nature and thus could be seen as a Bi-Level Optimization Problem (BLOP) where: (1) the upper level minimizes the network complexity defined by the number of blocks and the number of nodes per block; and (2) the lower level optimizes the convolution block ‘graphs’ topologies by maximizing the classification accuracy. Motivated by the originality of our observation with respect to the state of the art, we frame for the first time the CNN architecture design problem as a BLOP and then solve it using an adapted version of an existing efficient bi-level EA; through the definition of the solution encoding, the fitness function, and the variation operators at each level. The adapted EA is named BLOP-CNN and is assessed on the image classification task using the commonly employed CIFAR-10 and CIFAR-100 benchmark data sets. The analysis of our experimental results show the merits of our proposed method in providing the user with optimized architectures that outperform many recent and prominent architectures coming from the three different approaches, namely: manual design, reinforcement learning-based generation, and evolutionary optimization. Moreover, to show the applicability of our approach, we have conducted a case study on the detection of the COVID-19 using a set of benchmark chest X-ray and Computed Tomography (CT) images.},
  archive      = {J_NEUCOM},
  author       = {Hassen Louati and Slim Bechikh and Ali Louati and Chih-Cheng Hung and Lamjed Ben Said},
  doi          = {10.1016/j.neucom.2021.01.094},
  journal      = {Neurocomputing},
  pages        = {44-62},
  shortjournal = {Neurocomputing},
  title        = {Deep convolutional neural network architecture design as a bi-level optimization problem},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). An enhanced dynamic interaction network for claim
verification. <em>NEUCOM</em>, <em>439</em>, 34–43. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Claim verification aims to verify the truthfulness of claims according to the evidence. In the real-world scenarios, the claim verification methods are required 1) to identify and filter out the noise; 2) to enable the interaction among evidence; and 3) to predict the labels in mixed label sets. However, the prior studies adopt either the implicit or cumbersome interaction processes, which disable them from capturing the commonalities among evidence nor reducing the impact of noise, and few of them consider the label prediction in mixed label sets. To alleviate these issues, we propose an Enhanced Dynamic Interaction Network (EDIN). The EDIN contains two main modules: A Gate-based Dynamic Interaction Module to promote the interaction of evidence and summarize the commonality to verify the claim, which employs hub node and gates to control the information transmission and denoise. An Enhancement Module to assist the EDIN with predicting labels in a mixed label sets environment, where we introduce the auxiliary domain detection task and label transition component to enhance the expressiveness of label representation. Experimental results on multiple public datasets reveal the superiority of our method, and further analysis validates the effectiveness of our proposed modules.},
  archive      = {J_NEUCOM},
  author       = {Peiguang Li and Xian Sun and Hongfeng Yu and Wenkai Zhang and Guangluan Xu},
  doi          = {10.1016/j.neucom.2020.12.112},
  journal      = {Neurocomputing},
  pages        = {34-43},
  shortjournal = {Neurocomputing},
  title        = {An enhanced dynamic interaction network for claim verification},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning-based aerial image segmentation with open data
for disaster impact assessment. <em>NEUCOM</em>, <em>439</em>, 22–33.
(<a href="https://doi.org/10.1016/j.neucom.2020.02.139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Satellite images are an extremely valuable resource in the aftermath of natural disasters such as hurricanes and tsunamis where they can be used for risk assessment and disaster management. In order to provide timely and actionable information for disaster response, a framework utilising segmentation neural networks is proposed to identify impacted areas and accessible roads in post-disaster scenarios. The effectiveness of pretraining with ImageNet -for the task of aerial image segmentation has been analysed and performances of popular segmentation models compared. Experimental results show that pretraining on ImageNet usually improves the segmentation performance for a number of models. Open data available from OpenStreetMap (OSM) is used for training, forgoing the need for time-consuming manual annotation. The method also makes use of graph theory to update road network data available from OSM and to detect the changes caused by a natural disaster. Extensive experiments on data from the 2018 tsunami that struck Palu, Indonesia show the effectiveness of the proposed framework. ENetSeparable, with 30\% fewer parameters compared to ENet, achieved comparable segmentation results to that of the state-of-the-art networks.},
  archive      = {J_NEUCOM},
  author       = {Ananya Gupta and Simon Watson and Hujun Yin},
  doi          = {10.1016/j.neucom.2020.02.139},
  journal      = {Neurocomputing},
  pages        = {22-33},
  shortjournal = {Neurocomputing},
  title        = {Deep learning-based aerial image segmentation with open data for disaster impact assessment},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical self-adaptation network for multimodal named
entity recognition in social media. <em>NEUCOM</em>, <em>439</em>,
12–21. (<a href="https://doi.org/10.1016/j.neucom.2021.01.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal Named Entity Recognition task aims to identify named entities in user-generated posts containing both images and texts. Previous multimodal named entity recognition methods greatly benefit from visual features when the text and the image are well aligned, but this is not always the case in social media. On condition that the image is missing or mismatched with the text, these models usually fail to provide excellent performance. Besides, previous models use only single attention to capture the semantic interaction between different modalities, which largely ignore the existence of multiple entity objects in images and texts of the posts. To alleviate these issues, we present a novel model named Hierarchical Self-adaptation Network (HSN) to address these issues. The HSN contains 1) a Cross-modal Interaction Module to promote semantic interaction for the multiple entity objects in different modalities, which is proved to suppress wrong or incomplete attention in multimodal interactivity; 2) a Self-adaptive Multimodal Integration module to handle the problems that the images are missing or mismatched with the texts. Additionally, to evaluate the adaptability of HSN in real-life social media, we construct a Real-world NER dataset consisting of plain text posts and multimodal posts from Twitter. Extensive experiments demonstrate that our model achieves state-of-the-art results on the Real-world multimodal NER dataset and the Twitter multimodal NER dataset.},
  archive      = {J_NEUCOM},
  author       = {Yu Tian and Xian Sun and Hongfeng Yu and Ya Li and Kun Fu},
  doi          = {10.1016/j.neucom.2021.01.060},
  journal      = {Neurocomputing},
  pages        = {12-21},
  shortjournal = {Neurocomputing},
  title        = {Hierarchical self-adaptation network for multimodal named entity recognition in social media},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SpaceNet: Make free space for continual learning.
<em>NEUCOM</em>, <em>439</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The continual learning (CL) paradigm aims to enable neural networks to learn tasks continually in a sequential fashion. The fundamental challenge in this learning paradigm is catastrophic forgetting previously learned tasks when the model is optimized for a new task, especially when their data is not accessible. Current architectural-based methods aim at alleviating the catastrophic forgetting problem but at the expense of expanding the capacity of the model. Regularization-based methods maintain a fixed model capacity; however, previous studies showed the huge performance degradation of these methods when the task identity is not available during inference (e.g. class incremental learning scenario). In this work, we propose a novel architectural-based method referred as SpaceNet 1 for class incremental learning scenario where we utilize the available fixed capacity of the model intelligently. SpaceNet trains sparse deep neural networks from scratch in an adaptive way that compresses the sparse connections of each task in a compact number of neurons. The adaptive training of the sparse connections results in sparse representations that reduce the interference between the tasks. Experimental results show the robustness of our proposed method against catastrophic forgetting old tasks and the efficiency of SpaceNet in utilizing the available capacity of the model, leaving space for more tasks to be learned. In particular, when SpaceNet is tested on the well-known benchmarks for CL: split MNIST, split Fashion-MNIST, CIFAR-10/100, and iCIFAR100, it outperforms regularization-based methods by a big performance gap. Moreover, it achieves better performance than architectural-based methods without model expansion and achieves comparable results with rehearsal-based methods, while offering a huge memory reduction.},
  archive      = {J_NEUCOM},
  author       = {Ghada Sokar and Decebal Constantin Mocanu and Mykola Pechenizkiy},
  doi          = {10.1016/j.neucom.2021.01.078},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {SpaceNet: Make free space for continual learning},
  volume       = {439},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive output-feedback optimal control for continuous-time
linear systems based on adaptive dynamic programming approach.
<em>NEUCOM</em>, <em>438</em>, 334–344. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the adaptive output-feedback optimal control problem for a class of continuous-time (CT) linear systems with dynamic uncertainties. Data-based controller design algorithm with policy iteration form is developed through adaptive dynamic programming (ADP) technique. In the process of proposed algorithm, only measured input and output information of the system is used to learn optimal control gain, but the exactly knowledge of the system is not required. Different from the existing works, the adaptive controllers learned by the algorithm has certain robustness to the dynamic uncertainties. Three examples are given to test the effectiveness and feasibility of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Zhan Shi and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2021.01.070},
  journal      = {Neurocomputing},
  pages        = {334-344},
  shortjournal = {Neurocomputing},
  title        = {Adaptive output-feedback optimal control for continuous-time linear systems based on adaptive dynamic programming approach},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards computational analytics of 3D neuron images using
deep adversarial learning. <em>NEUCOM</em>, <em>438</em>, 323–333. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Benefited from advances of neuron tracing techniques, the ever-increasing number of digitally reconstructed 3D neuron images have greatly facilitated the research in neuromorphology. However, the sheer volume and the complexity of these 3D neuron data pose significant challenges for computational analytics, e.g., effectively finding neurons sharing similar morphologies, identifying neuron types, correlating neuron morphologies with properties, all of which require accurate measuring and fast indexing methods especially designed for the massive 3D neuronal images. In this paper, we present an accurate and efficient framework for the computational analytics of 3D neuronal structures based on advances of deep learning and data mining techniques . Particularly, unlike previous methods quantitatively describe neurons by measuring pre-defined metrics according to the tree-topological structures, we first develop a new method for the morphological feature representation by a proposed 3D neuron mapping and a modified generative adversarial networks (GANs). Subsequently, considering the computational complexity when retrieving large-scale neuron datasets, we integrate the neuron features with graph-based indexing, which can significantly improve the retrieval efficiency without losing accuracy. Experimental results show that our framework can effectively measure the similarity among massive neurons (e.g., 100 , 000 100,000 neurons), outperforming state-of-the-arts with more than 10\% in accuracy and hundreds of times in efficiency improvements.},
  archive      = {J_NEUCOM},
  author       = {Zhongyu Li and Xiayue Fan and Zengyi Shang and Lina Zhang and Haotian Zhen and Chaowei Fang},
  doi          = {10.1016/j.neucom.2020.03.129},
  journal      = {Neurocomputing},
  pages        = {323-333},
  shortjournal = {Neurocomputing},
  title        = {Towards computational analytics of 3D neuron images using deep adversarial learning},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Label-guided attention distillation for lane segmentation.
<em>NEUCOM</em>, <em>438</em>, 312–322. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contemporary segmentation methods are usually based on deep fully convolutional networks (FCNs). However, the layer-by-layer convolutions with a growing receptive field is not good at capturing long-range contexts such as lane markers in the scene. In this paper, we address this issue by designing a distillation method that exploits label structure when training segmentation network. The intuition is that the ground-truth lane annotations themselves exhibit internal structure. We broadcast the structure hints throughout a teacher network, i.e., we train a teacher network that consumes a lane label map as input and attempts to replicate it as output. Then, the attention maps of the teacher network are adopted as supervisors of the student segmentation network. The teacher network, with label structure information embedded, knows distinctly where the convolutional layers should pay visual attention into. The proposed method is named as Label-guided Attention Distillation (LGAD). It turns out that the student network learns significantly better with LGAD than when learning alone. As the teacher network is deprecated after training, our method does not increase the inference time. Note that LGAD can be easily incorporated in any lane segmentation network. To validate the effectiveness of the proposed LGAD method, extensive experiments have been conducted on two popular lane detection benchmarks: TuSimple and CULane. The results show consistent improvement across a variety of convolutional neural network architectures. Specifically, we demonstrate the accuracy boost of LGAD on the lightweight model ENet. It turns out that the ENet-LGAD surpasses existing lane segmentation algorithms. The main contributions of this paper include a newly proposed distillation training strategy (LGAD) and solid experimental investigation of the inner mechanism of LGAD.},
  archive      = {J_NEUCOM},
  author       = {Zhikang Liu and Lanyun Zhu},
  doi          = {10.1016/j.neucom.2021.01.100},
  journal      = {Neurocomputing},
  pages        = {312-322},
  shortjournal = {Neurocomputing},
  title        = {Label-guided attention distillation for lane segmentation},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple perspective attention based on double BiLSTM for
aspect and sentiment pair extract. <em>NEUCOM</em>, <em>438</em>,
302–311. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect category sentiment analysis has attracted increasing attention because of its outstanding performance in mining the fine-grained sentiment expression of users. In recent years, a new aspect category and sentiment pair extraction (ASPE) task has been proposed to simultaneously extract aspect categories and sentiment pairs. Most existing research works are designed in a two step pipeline, that is, they first perform aspect category detection, and subsequently conduct aspect category sentiment analysis . However, the pipeline method can clearly lead to error propagation from previous step. In this work, we propose a new framework for multiple perspective attention based on double BiLSTM with a novel joint strategy for ASPE to alleviate the accumulation of errors in the pipeline method. The experimental results on benchmark datasets SemEval and BDCI-2018 demonstrate the effectiveness of the proposed approach in terms of both accuracy and explainability for the ASPE task.},
  archive      = {J_NEUCOM},
  author       = {Yujie Fu and Jian Liao and Yang Li and Suge Wang and Deyu Li and Xiaoli Li},
  doi          = {10.1016/j.neucom.2021.01.079},
  journal      = {Neurocomputing},
  pages        = {302-311},
  shortjournal = {Neurocomputing},
  title        = {Multiple perspective attention based on double BiLSTM for aspect and sentiment pair extract},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One-step multi-view subspace clustering with incomplete
views. <em>NEUCOM</em>, <em>438</em>, 290–301. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering has gained soar attention in the field of data mining in recent years. Most multi-view clustering methods are considered to be complete for each view. However, in many applications, some views may contain missing instances, resulting in the incomplete multi-view learning problem. Incomplete views cannot be directly dealt with traditional multi-view clustering methods . In this paper, we propose a One-step multi-view subspace clustering with incomplete views (OMVSC-IV) method based on low-rank matrix factorization to overcome this problem. Specifically, the proposed algorithm uses low-rank matrix factorization to learn a consensus representation matrix , and then combined with the objective function of non-negative embedding and spectral embedding subspace clustering proposed in this paper. The whole process is established into the same objective function for joint optimization and requires no post-processing (e.g., K -means), thus avoiding the defect of being sensitive to initial values. Furthermore, the accuracy, parameter, sensitivity and convergence of the algorithm are studied by experiments. Experimental results on nine data sets show that the proposed algorithm performs superior to some of the latest algorithms.},
  archive      = {J_NEUCOM},
  author       = {Guoli Niu and Youlong Yang and Liqin Sun},
  doi          = {10.1016/j.neucom.2021.01.080},
  journal      = {Neurocomputing},
  pages        = {290-301},
  shortjournal = {Neurocomputing},
  title        = {One-step multi-view subspace clustering with incomplete views},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automated vertebral landmarks and spinal curvature
estimation using non-directional part affinity fields. <em>NEUCOM</em>,
<em>438</em>, 280–289. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vertebral landmarks of posterior-anterior X-ray images can be used to determine the curvature of the spine, which is essential for the assessment of Adolescent Idiopathic Scoliosis. Recently, automatic methods are presented to assist the annotation process of vertebral landmarks. However, previous methods expect a fixed number of landmark outputs regardless of the occlusion and diversity in the X-ray images, which may result in inaccurate predictions in practical cases. The use of dense layers and fractional numbers with respect to image dimensions as landmark outputs also limited the accuracy of the prediction. In this paper, we propose a novel method based on fully convolutional architecture and non-directional part affinity fields to label arbitrary number of vertebral landmarks and keep track of the connection relations between them to compute the Cobb angles. Comparing with conventional methods which predict each landmark by dense layers directly, our method use image segmentation to predict the landmarks and their connection relationships with seven heatmap channels: four for corner landmarks and two for vertical center landmarks of each vertebra, and one for non-directional part affinity fields to express the pairing relations between left and right center landmarks. This design allows arbitrary number of landmarks as output, and reduces the impact of occluded landmark and malformed vertebrae on Cobb angles prediction. To evaluate our methods, mean squared error for landmarks and absolute percentage error for Cobb angles are tested. The results show that our method outperforms other methods on both metrics.},
  archive      = {J_NEUCOM},
  author       = {Cheng Zhang and Jun Wang and Jian He and Peng Gao and Guotong Xie},
  doi          = {10.1016/j.neucom.2020.05.120},
  journal      = {Neurocomputing},
  pages        = {280-289},
  shortjournal = {Neurocomputing},
  title        = {Automated vertebral landmarks and spinal curvature estimation using non-directional part affinity fields},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). TTPP: Temporal transformer with progressive prediction for
efficient action anticipation. <em>NEUCOM</em>, <em>438</em>, 270–279.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video action anticipation aims to predict future action categories from observed frames. Current state-of-the-art approaches mainly resort to recurrent neural networks to encode history information into hidden states, and predict future actions from the hidden representations. It is well known that the recurrent pipeline is inefficient in capturing long-term information which may limit its performance in predication task. To address this problem, this paper proposes a simple yet efficient Temporal Transformer with Progressive Prediction (TTPP) framework, which repurposes a Transformer-style architecture to aggregate observed features, and then leverages a light-weight network to progressively predict future features and actions. Specifically, predicted features along with predicted probabilities are accumulated into the inputs of subsequent prediction. We evaluate our approach on three action datasets, namely TVSeries, THUMOS-14, and TV-Human-Interaction. Additionally we also conduct a comprehensive study for several popular aggregation and prediction strategies. Extensive results show that TTPP not only outperforms the state-of-the-art methods but also more efficient.},
  archive      = {J_NEUCOM},
  author       = {Wen Wang and Xiaojiang Peng and Yanzhou Su and Yu Qiao and Jian Cheng},
  doi          = {10.1016/j.neucom.2021.01.087},
  journal      = {Neurocomputing},
  pages        = {270-279},
  shortjournal = {Neurocomputing},
  title        = {TTPP: Temporal transformer with progressive prediction for efficient action anticipation},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active learning for road lane landmark inventory with v-ELM
in highly uncontrolled image capture conditions. <em>NEUCOM</em>,
<em>438</em>, 259–269. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road landmark inventory is becoming an important data product for the maintenance of transport infrastructures. Several commercial sensors are available which include synchronized optical cameras that allowto build 360° panoramic images of the surroundings of the vehicle used for road inspection. This paper is devoted to the analysis of such panorama images,specifically the area that contains themost relevant information. Road lane landmark detection is posed as a two class classification problem that may be solved bymachine learningapproaches, such as Random Forest (RF) and ensembles of Extreme Learning Machines (V-ELM). Besides model parameter selection, a central problem is the construction of a labeled training and validation datasetto cope with the highly uncontrolled conditions of image capture. Besides, human labor cost makes image data labeling a very expensive process. This paper proposes an open ended Active Learning (AL) approach involving a human oraclein the loop who provides the data labeling and can trigger the AL process when detection quality is degraded by the change in imaging conditions. The paper reports encouraging results over a collection of sample images selected from an industrial road landmark inventory operation. As an additional contribution, this paper assesses the ability of AL to overcomesome of the issues raised by highly class imbalanced datasets.},
  archive      = {J_NEUCOM},
  author       = {Jose Manuel Lopez-Guede and Asier Izquierdo and Julian Estevez and Manuel Graña},
  doi          = {10.1016/j.neucom.2020.07.151},
  journal      = {Neurocomputing},
  pages        = {259-269},
  shortjournal = {Neurocomputing},
  title        = {Active learning for road lane landmark inventory with V-ELM in highly uncontrolled image capture conditions},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Construction and analysis of cortical–muscular functional
network based on EEG-EMG coherence using wavelet coherence.
<em>NEUCOM</em>, <em>438</em>, 248–258. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on the brain functional network is important in understanding the normal function of the brain and diagnosing neuropsychiatric diseases. Inspired by the brain functional network, we constructed a cortical–muscular functional network using electroencephalography and electromyography to explore the motion control mechanism of the central nervous system and understand the organization and coordination mechanisms of limb motion control. In the process of constructing the network, 12 signal acquisition channels were selected as nodes, and the wavelet coherence is used as the index of connection between network nodes. Based on the original network, we used a fixed weighted edge and threshold methods to remove weak weighted edges and compare the performance of the two methods. The experimental results showed that the constructed network had a higher clustering coefficient , and the smaller characteristic path length indicated a small-world characteristic. At the same time, the weighted characteristic path length and weighted clustering coefficient of the functional network simplified by the threshold method can show promising classification accuracy under Fisher and artificial neural network .},
  archive      = {J_NEUCOM},
  author       = {Xugang Xi and Ziyang Sun and Xian Hua and Changmin Yuan and Yun-Bo Zhao and Seyed M. Miran and Zhizeng Luo and Zhong Lü},
  doi          = {10.1016/j.neucom.2021.01.102},
  journal      = {Neurocomputing},
  pages        = {248-258},
  shortjournal = {Neurocomputing},
  title        = {Construction and analysis of cortical–muscular functional network based on EEG-EMG coherence using wavelet coherence},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Calibrating feature maps for deep CNNs. <em>NEUCOM</em>,
<em>438</em>, 235–247. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many performance improvement techniques calibrate the outputs of convolutional layers to improve the performance of convolutional neural networks , e.g., Squeeze-and-Excitation Networks (SENets). These techniques train the network to extract calibration weights from the input itself. However, these methods increase the complexity of the model in order to perform calibration. We propose an approach to calibrate the outputs of convolutional layers efficiently. Specifically, we propose an architectural block called Accuracy Booster, which calibrates the convolutional layer outputs channel-wise while introducing minimal extra parameters and computation. We experimentally show that our approach achieves higher performance than existing calibration methods over several datasets and architectures while introducing lesser parameters than them. We also generalize our proposed block to calibrate the channel, width, and height of the layer output in parallel. We empirically show that this type of composite calibration performs better than applying channel-wise calibration, spatial calibration, or both. We validate our approach on the CIFAR-10/100, CUB, ImageNet, and MS-COCO datasets for various tasks. The ResNet-50 architecture with the accuracy booster block performs comparably on the classification task to the ResNet-152 architecture, which has more than twice the number of parameters. We empirically show that our method generalizes well to other tasks such as object detection. We perform extensive ablation experiments to validate our approach.},
  archive      = {J_NEUCOM},
  author       = {Pravendra Singh and Pratik Mazumder and Mohammed Asad Karim and Vinay P. Namboodiri},
  doi          = {10.1016/j.neucom.2020.12.119},
  journal      = {Neurocomputing},
  pages        = {235-247},
  shortjournal = {Neurocomputing},
  title        = {Calibrating feature maps for deep CNNs},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ArrowGAN: Learning to generate videos by learning arrow of
time. <em>NEUCOM</em>, <em>438</em>, 223–234. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training GANs on videos is even more sophisticated than on images because videos have a distinguished dimension: time. While recent methods designed a dedicated architecture considering time, generated videos are still far from indistinguishable from real videos. In this paper, we introduce ArrowGAN framework, where the discriminators learns to classify arrow of time as an auxiliary task and the generators tries to synthesize forward-running videos. We argue that the auxiliary task should be carefully chosen regarding the target domain. In addition, we explore categorical ArrowGAN with recent techniques in conditional image generation upon ArrowGAN framework, achieving the state-of-the-art performance on categorical video generation. Our extensive experiments validate the effectiveness of arrow of time as a self-supervisory task, and demonstrate that all our components of categorical ArrowGAN lead to the improvement regarding video inception score and Fréchet video distance on three datasets: Weizmann, UCFsports, and UCF-101.},
  archive      = {J_NEUCOM},
  author       = {Kibeom Hong and Youngjung Uh and Hyeran Byun},
  doi          = {10.1016/j.neucom.2021.01.043},
  journal      = {Neurocomputing},
  pages        = {223-234},
  shortjournal = {Neurocomputing},
  title        = {ArrowGAN: Learning to generate videos by learning arrow of time},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic segmentation of gross target volume of nasopharynx
cancer using ensemble of multiscale deep neural networks with spatial
attention. <em>NEUCOM</em>, <em>438</em>, 211–222. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radiotherapy is the main treatment method for nasopharynx cancer. Delineation of Gross Target Volume (GTV) from medical images is a prerequisite for radiotherapy. As manual delineation is time-consuming and laborious, automatic segmentation of GTV has a potential to improve the efficiency of this process. This work aims to automatically segment GTV of nasopharynx cancer from Computed Tomography (CT) images. However, it is challenged by the small target region, anisotropic resolution of clinical CT images, and the low contrast between the target region and surrounding soft tissues. To deal with these problems, we propose a 2.5D Convolutional Neural Network (CNN) to handle the different in-plane and through-plane resolutions. We also propose a spatial attention module to enable the network to focus on the small target, and use channel attention to further improve the segmentation performance . Moreover, we use a multi-scale sampling method for training so that the networks can learn features at different scales, which are combined with a multi-model ensemble method to improve the robustness of segmentation results. We also estimate the uncertainty of segmentation results based on our model ensemble, which is of great importance for indicating the reliability of automatic segmentation results for radiotherapy planning. Experiments with 2019 MICCAI StructSeg dataset showed that (1) Our proposed 2.5D network has a better performance on images with anisotropic resolution than the commonly used 3D networks. (2) Our attention mechanism can make the network pay more attention to the small GTV region and improve the segmentation accuracy . (3) The proposed multi-scale model ensemble achieves more robust results, and it can simultaneously obtain uncertainty information that can indicate potential mis-segmentations for better clinical decisions.},
  archive      = {J_NEUCOM},
  author       = {Haochen Mei and Wenhui Lei and Ran Gu and Shan Ye and Zhengwentai Sun and Shichuan Zhang and Guotai Wang},
  doi          = {10.1016/j.neucom.2020.06.146},
  journal      = {Neurocomputing},
  pages        = {211-222},
  shortjournal = {Neurocomputing},
  title        = {Automatic segmentation of gross target volume of nasopharynx cancer using ensemble of multiscale deep neural networks with spatial attention},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Guest editorial: Deep learning for medical image analysis.
<em>NEUCOM</em>, <em>438</em>, 209–210. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Hongsheng Li and Shaoting Zhang and Dimitris N. Metaxas},
  doi          = {10.1016/j.neucom.2021.01.065},
  journal      = {Neurocomputing},
  pages        = {209-210},
  shortjournal = {Neurocomputing},
  title        = {Guest editorial: Deep learning for medical image analysis},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust leak localization in water distribution networks
using computational intelligence. <em>NEUCOM</em>, <em>438</em>,
195–208. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.159">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The search for new strategies for leak detection, estimation and localization in Water Distributions Networks (WDNs) is a state-of-the-art research topic. In this paper, a methodology for leak detection, estimation and location that combines data-driven and model-based methods is proposed. A deep neural network is used in the leak detection task. Subsequently, the estimation of a leakage size range is accomplished by using Gaussian process regression. Then, a novel approach based on the solution of an inverse problem is developed for leak location. Knowing the range of possible values for the leak size allows to improve the location task when solved as an inverse problem. The proposed location method considers the topological configuration of the network as well as the leak size range. One of the main advantages of the proposal is that it does not depend on the labeling of the nodes. In this sense, a modified variant of the Differential Evolution algorithm, which considers the topological structure of the WDN to modify the search space and incorporates a temporal analysis, is used to find the solution of the inverse problem. Moreover, thanks to the topological evolution of the solutions a set of candidate nodes for the leakage creates a zone of reduced possible locations very useful in practical terms. The proposed approach is tested with the model of a real case study: the large-scale Modena WDN. The results demonstrate the effectiveness of the proposal with satisfactory leak detection, leak size estimation, and location performance when considering only 9 sensors installed in a network formed by 268 nodes.},
  archive      = {J_NEUCOM},
  author       = {Marcos Quiñones-Grueiro and Marlon Ares Milián and Maibeth Sánchez Rivero and Antônio J. Silva Neto and Orestes Llanes-Santiago},
  doi          = {10.1016/j.neucom.2020.04.159},
  journal      = {Neurocomputing},
  pages        = {195-208},
  shortjournal = {Neurocomputing},
  title        = {Robust leak localization in water distribution networks using computational intelligence},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neural architecture search method based on gradient
descent for remaining useful life estimation. <em>NEUCOM</em>,
<em>438</em>, 184–194. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remaining useful life is the estimated continuous normal working time of a component or system from the current moment to the potential failure. The traditional methods have high trial-and-error costs and poor migration capabilities. Fortunately, the neural architecture search (NAS) that has emerged partially solves the problem of automatic construction of network models. However, the search strategy for NAS is reinforcement learning or evolutionary algorithms , which essentially search in discrete space and treating the objective function as a black box, which is very time-consuming. To solve this problem, we proposed a gradient-based neural architecture search method. This method regards a cell in the search space as a directed acyclic graph (DAG) containing N ordered nodes. Each node is a latent representation, and the directed edges represent the conversion operation of two nodes. By mixing the candidate operations (ReLU, tanh) with the softmax function , the search space becomes a continuous space and the objective function becomes a differentiable function, so gradient-based optimization methods can be used to find the optimal structure. A neural architecture search method based on gradient descent for RUL estimation, with extensive experiments showing apparently, outperforms traditional approaches as well as Long Short-Term Memory (LSTM), and it takes much less computing resources than the reinforcement neural architecture search method.},
  archive      = {J_NEUCOM},
  author       = {Jiakun Zhao and Ruifeng Zhang and Zheng Zhou and Si Chen and Ju Jin and Qingfang Liu},
  doi          = {10.1016/j.neucom.2021.01.072},
  journal      = {Neurocomputing},
  pages        = {184-194},
  shortjournal = {Neurocomputing},
  title        = {A neural architecture search method based on gradient descent for remaining useful life estimation},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level colonoscopy malignant tissue detection with
adversarial CAC-UNet. <em>NEUCOM</em>, <em>438</em>, 165–183. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.154">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The automatic and objective medical diagnostic model can be valuable to achieve early cancer detection, and thus reducing the mortality rate. In this paper, we propose a highly efficient multi-level malignant tissue detection through the designed adversarial CAC-UNet. A patch-level model with a pre-prediction strategy and a malignancy area guided label smoothing is adopted to remove the negative WSIs, with which to lower the risk of false positive detection. For the selected key patches by multi-model ensemble, an adversarial context-aware and appearance consistency UNet (CAC-UNet) is designed to achieve robust segmentation . In CAC-UNet, mirror designed discriminators are able to seamlessly fuse the whole feature maps of the skillfully designed powerful backbone network without any information loss. Besides, a mask prior is further added to guide the accurate segmentation mask prediction through an extra mask-domain discriminator. The proposed scheme achieves the best results in MICCAI DigestPath2019 challenge 1 on colonoscopy tissue segmentation and classification task. The full implementation details and the trained models are available at https://github.com/Raykoooo/CAC-UNet.},
  archive      = {J_NEUCOM},
  author       = {Chuang Zhu and Ke Mei and Ting Peng and Yihao Luo and Jun Liu and Ying Wang and Mulan Jin},
  doi          = {10.1016/j.neucom.2020.04.154},
  journal      = {Neurocomputing},
  pages        = {165-183},
  shortjournal = {Neurocomputing},
  title        = {Multi-level colonoscopy malignant tissue detection with adversarial CAC-UNet},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Beyond softmax loss: Intra-concentration and
inter-separability loss for classification. <em>NEUCOM</em>,
<em>438</em>, 155–164. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the past years, most works have focused on designing an indigenous network architecture to advance progress in classification, but another potential opportunity for improvement, that is, research on classification losses, is underdeveloped. Although some new losses have been proposed, most of them either are variants of softmax loss or should combine with softmax loss. Hence, the inherent deficiencies of softmax loss, such as sensitiveness, class-balanced restriction, closed-set limitation, non-scale-invariance and incoordination between the intraclass distance and interclass distance, cannot be completely overcome. In light of this, we pave a new way to design a loss that has no relation to softmax loss and can avoid its weaknesses. We also propose an efficient algorithm to optimize the new loss that can circumvent computing the complicated gradients of a fraction, and the convergence is theoretically ensured. Extensive experimental results on benchmark datasets demonstrate that the new loss is competitive with state-of-the-art losses for classification. Additionally, other specially designed experiments show that the new loss is also effective at handling class-imbalanced problems, is robust in addressing outliers and can discover samples of unseen classes in open-set cases.},
  archive      = {J_NEUCOM},
  author       = {Hanyang Peng and Shiqi Yu},
  doi          = {10.1016/j.neucom.2020.11.030},
  journal      = {Neurocomputing},
  pages        = {155-164},
  shortjournal = {Neurocomputing},
  title        = {Beyond softmax loss: Intra-concentration and inter-separability loss for classification},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification and optimal control of nonlinear systems
using recurrent neural networks and reinforcement learning: An overview.
<em>NEUCOM</em>, <em>438</em>, 145–154. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper reviews the identification and optimal control problems using recurrent neural networks and reinforcement learning for nonlinear systems both in discrete- and continuous-time. Since neural networks can approximate any nonlinear function , then is shown that it can approximate a dynamical system using some well-identified elements and different neural structures. Existing methods using Lyapunov and Riccati equations to get the neural weights update rules are reviewed. Optimal control using a linear quadratic regulator formulation or reinforcement learning methods are discussed. We discuss the normalized gradient descent algorithm as core algorithm for the optimal control design using reinforcement learning.},
  archive      = {J_NEUCOM},
  author       = {Adolfo Perrusquía and Wen Yu},
  doi          = {10.1016/j.neucom.2021.01.096},
  journal      = {Neurocomputing},
  pages        = {145-154},
  shortjournal = {Neurocomputing},
  title        = {Identification and optimal control of nonlinear systems using recurrent neural networks and reinforcement learning: An overview},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Polynomial approximation based spectral dual graph
convolution for scene parsing and segmentation. <em>NEUCOM</em>,
<em>438</em>, 133–144. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation requires both a large receptive field and accurate spatial information. Although existing methods based on the FCN have greatly improved the accuracy, it still does not show satisfactory results on complex scene parsing and tiny object identification. The convolution operation in FCN suffers from a restricted receptive field, while global modeling is fundamental to dense prediction tasks. In this work, we apply graph convolution into the semantic segmentation task and propose a spectral dual graph convolution module to solve the above problems. Moreover, the semantic segmentation task can be divided into two directions, one of which is to get a large receptive field and consider the global context information; the other is to focus on extracting spatial and contour clues, such as sharply changing curves and tiny objects. From the spectral-domain, it is supposed that low-frequency information is critical to the former task, while high-frequency information is vital to the latter task. Accordingly, high-frequency and low-frequency biased graph convolutions are proposed to process the above information separately. Experiments on Cityscapes, COCO Stuff, PASCAL Context, and PASCAL VOC demonstrate the effectiveness of our methods on semantic segmentation. The proposal achieves comparable performance with advantages in computational and memory overhead.},
  archive      = {J_NEUCOM},
  author       = {Zitang Sun and Ruojing Wang and Zhengbo Luo},
  doi          = {10.1016/j.neucom.2021.01.002},
  journal      = {Neurocomputing},
  pages        = {133-144},
  shortjournal = {Neurocomputing},
  title        = {Polynomial approximation based spectral dual graph convolution for scene parsing and segmentation},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GAPointNet: Graph attention based point neural network for
exploiting local feature of point cloud. <em>NEUCOM</em>, <em>438</em>,
122–132. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting fine-grained semantic features on point cloud data is still challenging because of its irregular and sparse structure in a non-Euclidean space. In order to represent the local feature for each central point that is helpful towards better contextual learning, a max pooling operation is often used to highlight the most important feature in the local region. However, all other geometric local correlations between each central point and corresponding neighbourhood are ignored during the max pooling operation. To this end, the attention mechanism is promising in capturing node representation on graph-based data by attending over all the neighbouring nodes. In this paper, we propose a novel neural network for point cloud analysis , GAPointNet, which is able to learn local geometric representations by embedding graph attention mechanism within stacked Multi-Layer-Perceptron (MLP) layers. Specifically, we highlight different attention weights on the neighbourhood of each center point to efficiently exploit local features. We also combine attention features with local signature features generated by our attention pooling to fully extract local geometric structures and enhance the network robustness. The proposed GAPointNet architecture is tested on various benchmark datasets (i.e. ModelNet40, ShapeNet part, S3DIS, KITTI) and achieves state-of-the-art performance in both the shape classification and segmentation tasks .},
  archive      = {J_NEUCOM},
  author       = {Can Chen and Luca Zanotti Fragonara and Antonios Tsourdos},
  doi          = {10.1016/j.neucom.2021.01.095},
  journal      = {Neurocomputing},
  pages        = {122-132},
  shortjournal = {Neurocomputing},
  title        = {GAPointNet: Graph attention based point neural network for exploiting local feature of point cloud},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial learning for detail-preserving face
sketch synthesis. <em>NEUCOM</em>, <em>438</em>, 107–121. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face sketch synthesis aims to generate a face sketch image from a corresponding photo image and has wide applications in law enforcement and digital entertainment. Despite the remarkable achievements that have been made in face sketch synthesis, most existing works pay main attention to the facial content transfer, at the expense of facial detail information. In this paper, we present a new generative adversarial learning framework to focus on detail preservation for realistic face sketch synthesis. Specifically, the high-resolution network is modified as generator to transform a face image from photograph to sketch domain. Except for the common adversarial loss, we design a detail loss to force the synthesized face sketch images have proximate details to its corresponding photo images. In addition, the style loss is adopted to restrain the synthesized face sketch images have vivid sketch style as the hand-drawn sketch images. Experimental results demonstrate that the proposed approach achieves superior performance, compared to state-of-the-art approaches, both on visual perception and objective evaluation. Specifically, this study indicated the higher FSIM values (0.7345 and 0.7080) and Scoot values (0.5317 and 0.5091) than most comparison methods on the CUFS and CUFSF datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Weiguo Wan and Yong Yang and Hyo Jong Lee},
  doi          = {10.1016/j.neucom.2021.01.050},
  journal      = {Neurocomputing},
  pages        = {107-121},
  shortjournal = {Neurocomputing},
  title        = {Generative adversarial learning for detail-preserving face sketch synthesis},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rotation adaptive correlation filter for moving object
tracking in satellite videos. <em>NEUCOM</em>, <em>438</em>, 94–106. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new method of Earth observation, video satellite can provide high-temporal resolution remote sensing images for object tracking. Object tracking in satellite videos is promising yet challenging in computer vision. Although many algorithms for satellite video object tracking have been proposed, none of them solve the problem of tracking rotating object. Due to the nadir view, the rotation of an object is very common in the satellite videos. This problem urgently needs to be addressed. In this paper, a rotation-adaptive correlation filter (RACF) tracking algorithm is proposed to address the problem caused by the rotation of object. The proposed algorithm provides the following improvements: (a) A method of estimating the object rotation angle to keep the feature map stable during the object rotation is proposed. This method can overcome the drawback of histogram of oriented gradient (HOG) based trackers, which cannot deal with the rotation of objects in satellite videos; and (b) making the algorithm capable of estimating the change in the bounding box size caused by object’s rotation. The experimental results demonstrate that our algorithm can track object with a 99.84\% precision score and 92.96\% success score in six videos from the Jilin-1 satellite constellation.},
  archive      = {J_NEUCOM},
  author       = {Shiyu Xuan and Shengyang Li and Zifei Zhao and Zhuang Zhou and Wanfeng Zhang and Hong Tan and Guisong Xia and Yanfeng Gu},
  doi          = {10.1016/j.neucom.2021.01.058},
  journal      = {Neurocomputing},
  pages        = {94-106},
  shortjournal = {Neurocomputing},
  title        = {Rotation adaptive correlation filter for moving object tracking in satellite videos},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive prostate MR image segmentation based on
ConvLSTMs and GGNN. <em>NEUCOM</em>, <em>438</em>, 84–93. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate segmentation of the prostate on magnetic resonance (MR) images plays an important role for prostate cancer diagnosis and treatment. Although many automated prostate segmentation methods have been proposed, the performance still faces several challenges, which includes large variability in prostate shape, unclear boundary, and complex intensity distribution. Therefore, the results obtained from the automated methods should be further refined by users to get a more accurate and reliable segmentation. In this paper, we propose an end-to-end interactive segmentation method to refine the automated results. A convolutional long short term memory (convLSTM) module and a gated graph neural network (GGNN) are presented in the proposed method for prostate segmentation in both automated and interactive manners. A boundary loss is proposed to train our model. We evaluated the proposed method on two public available datasets and one in–house dataset. Experimental results show that the proposed convLSTM module could obtain a DSC of 91.78\% on the test dataset, which outperforms eight state-of-the-art methods. A further 1.5\% improvements can be obtained by user interactions based on the GGNN. The segmentation time including user interactions and inference time was 2.3 min on average for segmenting one volume.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Tian and Xiaojian Li and Zhang Chen and Yaoyue Zheng and Hongcheng Fan and Zhongyu Li and Ce Li and Shaoyi Du},
  doi          = {10.1016/j.neucom.2020.05.121},
  journal      = {Neurocomputing},
  pages        = {84-93},
  shortjournal = {Neurocomputing},
  title        = {Interactive prostate MR image segmentation based on ConvLSTMs and GGNN},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic method for glaucoma diagnosis using a
three-dimensional convoluted neural network. <em>NEUCOM</em>,
<em>438</em>, 72–83. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Glaucoma is as an abnormality of the optic system that alters the patient’s vision, causing damage to the nervous system and potentially increasing intraocular pressure . Early detection is essential in glaucoma – a progressive disease – in order to initiate preventive treatment and thus avoid total vision loss in patients. Efficient glaucoma diagnosis is expensive and time consuming. Considering these aspects, computer vision techniques have been developed to obtain a rapid and cost-effective diagnosis. This paper presents a new method of classification for glaucomatous and healthy background images of the eye. Here, we propose the use of a three-dimensional convolutional neural network (3DCNN) applied to volumes constructed from a transformation, which converts two-dimensional (2D) background images of the eye. The proposed method showed favorable results, reaching 96.4\% accuracy, 100\% sensitivity, 93.02\% specificity, a 0.965 area under the curve (AUC), and a 0.928 Kappa.},
  archive      = {J_NEUCOM},
  author       = {Nonato Rodrigues de Sales Carvalho and Maria da Conceição Leal Carvalho Rodrigues and Antonio Oseas de Carvalho Filho and Mano Joseph Mathew},
  doi          = {10.1016/j.neucom.2020.07.146},
  journal      = {Neurocomputing},
  pages        = {72-83},
  shortjournal = {Neurocomputing},
  title        = {Automatic method for glaucoma diagnosis using a three-dimensional convoluted neural network},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generative adversarial networks for single channel
separation of convolutive mixed speech signals. <em>NEUCOM</em>,
<em>438</em>, 63–71. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The suppression of interference for speech recognition is of great significance in noisy situation, especially in single channel receiving mode, the suppression of interference is much more difficult. In this paper, we propose a generative adversarial network (GAN) based method for single channel dereverberation and speech separation. Different from the existing methods, our method considers the influence of strong reverberation on the observed signals. The proposed network involves two parts: reverberation suppression and target speech enhancement. Firstly, we use an improved CyclyGAN to compensate the multi-path effect on both target speech and interference. Secondly, we propose a differentialGAN to extract both target speech and interference while the interference enhancement network can indirectly improve the performance of target speech enhancement network. We use the real and imaginary parts of the complex spectrum as the feature vector, which avoids the phase mismatch during signal recovery. Simulation results show that our method is superior to its competitors in terms of multiple metrics in severe reverberation environment.},
  archive      = {J_NEUCOM},
  author       = {Yang Li and Wei-Tao Zhang and Shun-Tian Lou},
  doi          = {10.1016/j.neucom.2021.01.052},
  journal      = {Neurocomputing},
  pages        = {63-71},
  shortjournal = {Neurocomputing},
  title        = {Generative adversarial networks for single channel separation of convolutive mixed speech signals},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Discriminative feature and dictionary learning with
part-aware model for vehicle re-identification. <em>NEUCOM</em>,
<em>438</em>, 55–62. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.148">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of smart cities, urban surveillance video analysis plays a further significant role in intelligent transportation systems . Vehicle re-identification (re-ID) aims at identifying the same target vehicle in large datasets from non-overlapping cameras, which has grown into a hot topic in promoting intelligent transportation systems . However, due to the similar appearances, vehicle re-ID has become a challenging task. In this paper, we tackle this challenge by proposing Triplet Center Loss based Part-aware Model (TCPM) that leverages the discriminative features in part details of vehicles to refine the accuracy of vehicle re-ID. TCPM mainly partitions the vehicle from horizontal and vertical directions to strengthen the details of the vehicle and reinforce the internal consistency of the parts. In addition, to eliminate intra-class differences in local regions of the vehicle, we utilize the external memory modules to emphasize the consistency of each part to learn the discriminating features, which form a global dictionary over all categories in the dataset. Moreover, in TCPM, triplet-center loss is introduced to ensure that each part of vehicle features has intra-class consistency and inter-class separability. Experimental results show that our proposed TCPM has competitive results over the existing state-of-the-art methods on benchmark datasets VehicleID and VeRi-776.},
  archive      = {J_NEUCOM},
  author       = {Huibing Wang and Jinjia Peng and Guangqi Jiang and Fengqiang Xu and Xianping Fu},
  doi          = {10.1016/j.neucom.2020.06.148},
  journal      = {Neurocomputing},
  pages        = {55-62},
  shortjournal = {Neurocomputing},
  title        = {Discriminative feature and dictionary learning with part-aware model for vehicle re-identification},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust model-free control for redundant robotic manipulators
based on zeroing neural networks activated by nonlinear functions.
<em>NEUCOM</em>, <em>438</em>, 44–54. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent studies have verified that zeroing neural network is suitable for model-free feedback control of redundant robot manipulators with excellent convergence and accuracy. Unlike previous studies using a linear activation function , this paper employs zeroing neural networks activated by nonlinear functions to control redundant robots to track desired paths without knowing kinematic models of robots, and systematically investigates the finite-time convergence and robustness of the proposed control scheme. Specifically, two nonlinear-function-activated zeroing neural networks are employed to solve the Jacobian estimation problem and trajectory tracking problem respectively. After introducing a model-free control scheme generally applicable to different types of robots, theoretical analysis proves that the proposed control scheme has finite-time convergence when employing nonlinear activation functions and the tracking error will not exceed the upper bound with the bounded noise interference. Finally, simulations based on a five-link planar robot and a PUMA 560 robot reveal the finite-time convergence of the proposed control scheme and verify that nonlinear functions can effectively increase the error convergence rate and reduce the tracking error caused by noises, compared with conventional method based on linear-function-activated zeroing neural networks.},
  archive      = {J_NEUCOM},
  author       = {Ning Tan and Peng Yu},
  doi          = {10.1016/j.neucom.2021.01.093},
  journal      = {Neurocomputing},
  pages        = {44-54},
  shortjournal = {Neurocomputing},
  title        = {Robust model-free control for redundant robotic manipulators based on zeroing neural networks activated by nonlinear functions},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Auto-encoder based structured dictionary learning for visual
classification. <em>NEUCOM</em>, <em>438</em>, 34–43. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dictionary learning and deep learning can be combined to boost the performance of classification tasks . However, existing combined methods often learn multi-level dictionaries each of which is embedded in a network layer, involve a large number of parameters (elements of many dictionaries) and thus easily result in prohibitive computational cost and even overfitting. In this paper, we present a novel deep Auto-Encoder based Structured Dictionary (AESD) learning model, where we need to learn only one dictionary which is composed of class-specific sub-dictionaries, and supervision is introduced by imposing discriminative category constraints to empower the dictionary with discrimination. The encoding layers are designed with shared parameters which are exactly dependent on the dictionary carried by the decoding layer. This characterizes the learning process by forward-propagation based optimization w.r.t the dictionary only, leading to a light-weight network training. In addition to utilizing directly the trained encoding network combined with a minimum-reconstruction-residual scheme for single image based classification, to expand the application spectrum of our method, in the testing phase, we extend the proposed prototype into a Convolutional Encoder based Block Sparse Representation (CEBSR) model to promote the latent block sparsity in the joint representation of an image set, achieving improved image set based classification. Extensive experiments verify the performance of the learned dictionary for image classification , and the superiority of our extended model over the state-of-the-art image set classification methods.},
  archive      = {J_NEUCOM},
  author       = {Deyin Liu and Chengwu Liang and Shaokang Chen and Yun Tie and Lin Qi},
  doi          = {10.1016/j.neucom.2020.09.088},
  journal      = {Neurocomputing},
  pages        = {34-43},
  shortjournal = {Neurocomputing},
  title        = {Auto-encoder based structured dictionary learning for visual classification},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for monocular depth estimation: A review.
<em>NEUCOM</em>, <em>438</em>, 14–33. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation is a classic task in computer vision, which is of great significance for many applications such as augmented reality, target tracking and autonomous driving. Traditional monocular depth estimation methods are based on depth cues for depth prediction with strict requirements, e.g. shape-from-focus/ defocus methods require low depth of field on the scenes and images. Recently, a large body of deep learning methods have been proposed and has shown great promise in handling the traditional ill-posed problem. This paper aims to review the state-of-the-art development in deep learning-based monocular depth estimation. We give an overview of published papers between 2014 and 2020 in terms of training manners and task types. We firstly summarize the deep learning models for monocular depth estimation. Secondly, we categorize various deep learning-based methods in monocular depth estimation. Thirdly, we introduce the publicly available dataset and the evaluation metrics. And we also analysis the properties of these methods and compare their performance. Finally, we highlight the challenges in order to inform the future research directions.},
  archive      = {J_NEUCOM},
  author       = {Yue Ming and Xuyang Meng and Chunxiao Fan and Hui Yu},
  doi          = {10.1016/j.neucom.2020.12.089},
  journal      = {Neurocomputing},
  pages        = {14-33},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for monocular depth estimation: A review},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Palmprint orientation field recovery via attention-based
generative adversarial network. <em>NEUCOM</em>, <em>438</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Orientation field is the key foundation of palmprint feature extraction and recognition. However, due to the presence of numerous wide creases, the palmprint orientation field can hardly be accurately estimated by previous methods, especially in the thenar region, which still faces huge challenges. To solve this problem, we formulate palmprint orientation field recovery as an inpainting task and propose a palmprint orientation field recovery model named attention-based generative adversarial network. The deep generative architecture provides a powerful representation and an attention module guides the network to adaptively focus on the inpainting region. To avoid manually marking orientation field, we design a quality evaluation module to iteratively obtain pseudo labels for model training and incorporate palmprint abundant prior knowledge as extra supervision information. Palmprint identification results on public THUPALMLAB palmprint database show that our proposed algorithm improves the rank-1 recognition rate from 91.7\% to 99.3\%, which significantly outperforms the state-of-the-arts. Besides, we also compare the sensitivity of our algorithm to different optimization methods and noise distributions. Robust performance provides a reliable evidence for law enforcement and biometric identification.},
  archive      = {J_NEUCOM},
  author       = {Bing Liu and Jufu Feng},
  doi          = {10.1016/j.neucom.2021.01.049},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {Palmprint orientation field recovery via attention-based generative adversarial network},
  volume       = {438},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). A novel voting convergent difference neural network for
diagnosing breast cancer. <em>NEUCOM</em>, <em>437</em>, 339–350. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Breast cancer is one of the most frequently occurred cancers for females, and thus diagnosing breast cancer is very important. Neural dynamic algorithm (NDA) has been successfully applied in many fields with the characteristics of parallel computing and exponential convergence. However, there is no research on applying NDA-based neural network for pattern classification. In this paper, a novel voting convergent difference neural network (V-CDNN) is proposed. To do so, samples are firstly handled by feature selection, feature weighting and sample normalization. Secondly, the preprocessed samples are used to simultaneously and independently train several convergent difference neural networks in different types of mapping functions. Thirdly, in the testing process, voting strategy for these networks is applied to make diagnosis results more accurate and convincing. Being different from most existing neural networks, the proposed V-CDNN adopts neural dynamic learning algorithm, which greatly improves computation efficiency and increases accuracy rate of diagnosis. Experimental results verify that the proposed V-CDNN can achieve 100\% 100\% average diagnosis accuracy, which is the highest among existing state-of-the-art methods on the open data set.},
  archive      = {J_NEUCOM},
  author       = {Zhijun Zhang and Bozhao Chen and Songqing Xu and Guangqiang Chen and Jilong Xie},
  doi          = {10.1016/j.neucom.2021.01.083},
  journal      = {Neurocomputing},
  pages        = {339-350},
  shortjournal = {Neurocomputing},
  title        = {A novel voting convergent difference neural network for diagnosing breast cancer},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Denoising auto-encoding priors in undecimated wavelet domain
for MR image reconstruction. <em>NEUCOM</em>, <em>437</em>, 325–338. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressive sensing is an impressive approach for fast MRI. It aims at reconstructing MR image using only a few under-sampled data in k-space, enhancing the efficiency of the data acquisition. In this study, we propose to learn priors based on undecimated wavelet transform and an iterative image reconstruction algorithm . At the stage of prior learning, transformed feature images obtained by undecimated wavelet transform are stacked as an input of denoising autoencoder network (DAE). The highly redundant and multi-scale input enables the correlation of feature images at different channels, which allows a robust network-driven prior. At the iterative reconstruction, the transformed DAE prior is incorporated into the classical iterative procedure by means of proximal gradient algorithm. Experimental comparisons on different sampling trajectories and ratios validated the great potential of the presented algorithm.},
  archive      = {J_NEUCOM},
  author       = {Siyuan Wang and Junjie Lv and Zhuonan He and Dong Liang and Yang Chen and Minghui Zhang and Qiegen Liu},
  doi          = {10.1016/j.neucom.2020.09.086},
  journal      = {Neurocomputing},
  pages        = {325-338},
  shortjournal = {Neurocomputing},
  title        = {Denoising auto-encoding priors in undecimated wavelet domain for MR image reconstruction},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based h∞ sliding mode control for networked systems
subject to communication channel fading and randomly varying
nonlinearities. <em>NEUCOM</em>, <em>437</em>, 312–324. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the H ∞ H∞ sliding mode control (SMC) problem is discussed for a class of uncertain discrete networked systems with channel fading and randomly varying nonlinearities (RVNs) by employing the observer-based approach. Here, the J th-order Rice fading model is adopted to describe the phenomenon of channel fading, where the channel coefficients are mutually independent random variables that take the values on certain interval. In addition, a sequence of mutually independent Bernoulli distributed random variables is utilized to characterize the phenomenon of the RVNs, where the occurrence probabilities of RVNs consist of the nominal mean and the bound of error. The main objective of the addressed problem is to design the observer-based sliding mode controller such that the closed-loop system is asymptotically stable in mean-square sense and the pre-specified H ∞ H∞ performance requirement is guaranteed. By employing novel Lyapunov–Krasovskii functional, sufficient criteria are derived to force the system state trajectories onto a pre-specified sliding mode region. Afterwards, the solvability of non-convex problem is discussed by testifying the feasibility of a minimization problem . Finally, an illustrative example is given to demonstrate the effectiveness of aforementioned SMC technique.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Guan and Jun Hu and Jun Qi and Dongyan Chen and Fanyueyang Zhang and Guang Yang},
  doi          = {10.1016/j.neucom.2021.01.023},
  journal      = {Neurocomputing},
  pages        = {312-324},
  shortjournal = {Neurocomputing},
  title        = {Observer-based h∞ sliding mode control for networked systems subject to communication channel fading and randomly varying nonlinearities},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Multistability of state-dependent switching neural networks
with discontinuous nonmonotonic piecewise linear activation functions.
<em>NEUCOM</em>, <em>437</em>, 300–311. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents the theoretical results on the multistability of state-dependent switching neural networks with discontinuous nonmonotonic piecewise linear activation functions . For n -neurons switching model, this paper shows that neural networks have 7 n equilibrium points, 6 n of which are located at the continuous points of activation functions and others are located at the discontinuous points of activation functions. Among these equilibrium points, 4 n or 5 n are stable and others are unstable, which depend on the relationship between the switching threshold and the discontinuous points of the activation functions. Compared with existing results, this paper reveals that switching threshold and discontinuous character are crucial in increasing the number of equilibrium points. Two examples are presented to verify the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Jiahui Zhang and Song Zhu and Nannan Lu and Shiping Wen},
  doi          = {10.1016/j.neucom.2021.01.046},
  journal      = {Neurocomputing},
  pages        = {300-311},
  shortjournal = {Neurocomputing},
  title        = {Multistability of state-dependent switching neural networks with discontinuous nonmonotonic piecewise linear activation functions},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual guide automatic berthing control of marine ships
based on heuristic dynamic programming iteration method.
<em>NEUCOM</em>, <em>437</em>, 289–299. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the berthing control problem for automatic ships by using a virtual guide system based on heuristic dynamic programming (HDP) method. Firstly, by introducing an automatic virtual guide system, the berthing control problem can be transformed into a tracking control problem, and then can be further transformed into an optimal regulation problem. Secondly, the HDP method is used to solve the optimal regulation control problem of the marine surface ship with unknown ship model. Then, it is proven that the tracking error, the adaptation laws and the control inputs are uniformly bounded on the basis of the Lyapunov theory . Finally, simulations are carried out on an automatic model ship and the HDP method is compared with the backstepping control to verify the effectiveness of the developed control scheme.},
  archive      = {J_NEUCOM},
  author       = {Qi Liu and Tieshan Li and Qihe Shan and Renhai Yu and Xiaoyang Gao},
  doi          = {10.1016/j.neucom.2021.01.022},
  journal      = {Neurocomputing},
  pages        = {289-299},
  shortjournal = {Neurocomputing},
  title        = {Virtual guide automatic berthing control of marine ships based on heuristic dynamic programming iteration method},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sequence to sequence model for dialogue generation with
gated mixture of topics. <em>NEUCOM</em>, <em>437</em>, 282–288. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose GMoT-Seq2Seq, a sequence to sequence (Seq2Seq) model with a gated mixture of topics (MoT) designed to utilize topic information to generate fluent and coherent responses. Seq2Seq model is good at capturing the local structure of word sequence which affects the fluency due to their sequential nature, but probably has difficulty to extract topic information from the utterance. In contrast, topic models are very capable of capturing global semantic information that has a direct impact on the coherence. Absorbing the advantages of both, the proposed GMoT-Seq2Seq model uses a Seq2Seq to capture the temporal dependencies, and an MoT layer to obtain the topic vector that provides global semantic dependencies in the conversation. The MoT layer can summarize the utterances into a proportion vector over several underlying topics. To balance the fluency and coherence, we utilize a topic gate to dynamically control the information from the inferred topic vector and the partially generated responses. Experiment results show that our proposed model outperforms the compared baselines, and can generate more fluent and coherent responses.},
  archive      = {J_NEUCOM},
  author       = {Hongwei Zeng and Jun Liu and Meng Wang and Bifan Wei},
  doi          = {10.1016/j.neucom.2021.01.014},
  journal      = {Neurocomputing},
  pages        = {282-288},
  shortjournal = {Neurocomputing},
  title        = {A sequence to sequence model for dialogue generation with gated mixture of topics},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GSA-GAN: Global spatial attention generative adversarial
networks. <em>NEUCOM</em>, <em>437</em>, 274–281. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a solution to translating the visible images into infrared images, which is challenging in computer vision. Our solution belongs to unsupervised learning , which has recently become popular in image-to-image translation. However, existing methods do not produce satisfactory results because (1) most existing methods are mainly used in entertainment scenarios with single scenes and low complexity. The problem solved by this article is more diverse and more complicated. (2) The infrared response of objects depends not only on itself but also on the current environment, and existing methods cannot correlate long-range dependent objects. In this paper, We propose Global Spatial Attention (GSA), which enhances dependence between long-range objects and improves the synthesized image quality. Compared with other methods, GSA can save more space and time. Moreover, we introduce the idea of subspace learning into the neural network to make training more stable. Our method takes unpaired visible images and infrared images for training, which are easy to collect. Experimental results show that our method can generate high-quality infrared images from visible images and outperforms state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Lei An and Jiajia Zhao and Bo Ma},
  doi          = {10.1016/j.neucom.2021.01.047},
  journal      = {Neurocomputing},
  pages        = {274-281},
  shortjournal = {Neurocomputing},
  title        = {GSA-GAN: Global spatial attention generative adversarial networks},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-task adversarial autoencoder network for face
alignment in the wild. <em>NEUCOM</em>, <em>437</em>, 261–273. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face alignment has been applied widely in the field of computer vision, which is still a very challenging task for the existence of large pose, partial occlusion, and illumination, etc. The method based on deep regression neural network has achieved the most advanced performance in the field of face alignment in recent years, and how to learn more representative facial appearance is the key to face alignment. Based on the idea of Multi-task Learning, we propose a Multi-task Adversarial Autoencoder (MTAAE) network, which can learn more representative facial appearance for heatmap regression and improve the performance of face alignment in the wild. MTAAE is composed of three tasks. The main task uses the heatmap regression method to locate the position of landmarks and introduces a discriminator on the landmark heatmaps to generate more realistic heatmaps. Facial attribute estimation tasks and face reconstruction task based on Adversarial Autoencoder respectively extract discriminative and generative representations to improve the effect of heatmap regression. At the same time, the dynamic weight network is designed to assign a weight coefficient dynamically and reasonably for each auxiliary task. Extensive experiments on 300 W, MTFL, and WFLW datasets demonstrate that our method is more robust in complex environments and outperforms state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqian Yue and Jing Li and Jia Wu and Jun Chang and Jun Wan and Jinyan Ma},
  doi          = {10.1016/j.neucom.2021.01.027},
  journal      = {Neurocomputing},
  pages        = {261-273},
  shortjournal = {Neurocomputing},
  title        = {Multi-task adversarial autoencoder network for face alignment in the wild},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RPCA-induced self-representation for subspace clustering.
<em>NEUCOM</em>, <em>437</em>, 249–260. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The self-expressiveness property of the data, i.e., each sample is linearly represented as a combination of other samples, has recently aroused much attention in the community of data mining and machine learning and shown great promising for subspace clustering. However, real-world data are usually contaminated by noise and outliers. The true similarity between samples directly learned from the original data may deviate from the intrinsic structure of the data, and subsequent clustering results will be severely affected. Hence naively taking a corrupted dictionary, i.e., data itself, will not always obtain the desired clustering performance. To address the above issues, this paper proposes a robust principal component analysis induced self-representation clustering method via adaptively learning the similarity graph from the clean data in the self-representation framework, where the original data are recovered, and the representation coefficients are obtained simultaneously in a unified framework. Specifically, we jointly integrate a nonnegative constraint and a distance regularization into the proposed framework, which guarantees the learned affinity matrix can simultaneously capture the global and local structure of data. Experimental results on both synthetic data and several famous multimedia datasets demonstrate that the proposed method performs much better against state-of-the-arts.},
  archive      = {J_NEUCOM},
  author       = {Guo Zhong and Chi-Man Pun},
  doi          = {10.1016/j.neucom.2021.01.077},
  journal      = {Neurocomputing},
  pages        = {249-260},
  shortjournal = {Neurocomputing},
  title        = {RPCA-induced self-representation for subspace clustering},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generalized varying-parameter recurrent neural network for
super solution of quadratic programming problem. <em>NEUCOM</em>,
<em>437</em>, 238–248. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To obtain superior convergent speed, a generalized varying-parameter recurrent neural network (GVP-RNN) is established and analyzed for solving quadratic programming (QP) problems. Different from the classical fix-parameter neural network , such as Zhang neural network (ZNN) and finite-time convergent differential neural network (FT-CDNN), GVP-RNN dynamics can achieve exponential convergent results and possess high precision. By Lagrange theorem, QP problems can be transformed to a time-varying matrix equation , which is prepared for the GVP-RNN model. Theoretical analysis has shown the GVP-RNN model takes a super-exponential convergence comparing the corresponding simulated results of ZNN and FT-CDNN. Simulation comparisons are presented to evaluate the theoretical performance of the GVP-RNN with three types of activation functions . Furthermore, the proposed GVP-RNN model is analyzed and applied to control kinematic trajectory of redundant manipulators.},
  archive      = {J_NEUCOM},
  author       = {Y. Kong and Y. Jiang and R. Han and H. Wu},
  doi          = {10.1016/j.neucom.2021.01.084},
  journal      = {Neurocomputing},
  pages        = {238-248},
  shortjournal = {Neurocomputing},
  title        = {A generalized varying-parameter recurrent neural network for super solution of quadratic programming problem},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Semi-supervised point cloud segmentation using
self-training with label confidence prediction. <em>NEUCOM</em>,
<em>437</em>, 227–237. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud segmentation is a key problem in 3D content understanding. The existing methods based on deep neural network for point cloud segmentation mainly train the network in a supervised fashion, which heavily rely on a large amount of high-quality manual-labeled training point clouds. However, it is very tedious and time-consuming to manually assign part labels for each point in point clouds. Meanwhile, a lot of unlabeled point clouds can easily be obtained from 3D scanners, Internet or reconstruction. Therefore, we introduce self-training to utilize these unlabeled point clouds. So the proposed semi-supervised point cloud segmentation method can employ both labeled point clouds and unlabeled point clouds for training. Moreover, in order to make better use of unlabeled point clouds, the adopted adversarial architecture proposes confidence discrimination of label prediction for unlabeled point clouds. Thus, pseudo labels on unlabeled point clouds with higher reliability can be picked out to participate the network training, which further improves segmentation performance . The experiments show that the proposed method can make full use of the unlabeled point clouds in training. In addition, segmentation performance improves by self-training with label confidence prediction.},
  archive      = {J_NEUCOM},
  author       = {Hongyan Li and Zhengxing Sun and Yunjie Wu and Youcheng Song},
  doi          = {10.1016/j.neucom.2021.01.091},
  journal      = {Neurocomputing},
  pages        = {227-237},
  shortjournal = {Neurocomputing},
  title        = {Semi-supervised point cloud segmentation using self-training with label confidence prediction},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised graph convolutional clustering by preserving
latent distribution. <em>NEUCOM</em>, <em>437</em>, 218–226. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Node clustering has attracted widespread concern due to the fact that graph structure helps to seek the geometric structure of data. Existing graph convolutional networks (GCNs) based node clustering methods usually contain two steps. First, learning latent nodes representations. Second, inferring the unknown labels. Despite the promising preliminary results, it cannot take full advantage of the information embedded in current pseudo clustering labels, resulting in suboptimal performance. In fact, it is the truth we do not know the true label of the node in clustering, but the pseudo clustering label of the node generated by each iteration is known. Under this condition, although the pseudo labels of some nodes are incorrect, the partial correct label information is useful and significant. Moreover, GCNs based node clustering aims to learn satisfactory low dimensional node representations which are usually used for clustering. However, existing GCNs based clustering methods fail to take into account distribution consistency between the raw data space and the latent space of nodes representations, resulting in insufficient representations. To address the above problems, we propose a novel GCN-based node clustering method. By introducing a self-supervision module, it can employ the good property of pseudo clustering labels to self-supervise the learning of node representations. Moreover, a latent distribution preserving term, which is measured by KL divergence, is employed to help the latent representations of the same sample to further have a consistent distribution in dimension space as well as in the original dimension space. We formulate the above two concerns into a unified optimization framework. Experimental results on several public datasets indicate our method is effective compared with the state-of-the-art node clustering methods.},
  archive      = {J_NEUCOM},
  author       = {Shiwen Kou and Wei Xia and Xiangdong Zhang and Quanxue Gao and Xinbo Gao},
  doi          = {10.1016/j.neucom.2021.01.082},
  journal      = {Neurocomputing},
  pages        = {218-226},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised graph convolutional clustering by preserving latent distribution},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A nonparametric-learning visual servoing framework for robot
manipulator in unstructured environments. <em>NEUCOM</em>, <em>437</em>,
206–217. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current visual servoing methods used in robot manipulation require system modeling and parameters, only working in structured environments. This paper presents a nonparametric visual servoing for a robot manipulator operated in unstructured environments. A Gaussian-mapping likelihood process is used in Bayesian stochastic state estimation (SSE) for Robotic coordination control, in which the Monte Carlo sequential importance sampling (MCSIS) algorithm and a learning-remedied method are created for robotic visual-motor mapping estimation. The self-learning strategy described takes advantage of remedy the particles deterioration to maintain the robust performance at a low rate of particle sampling, rather than likes MCSIS rely on enlarge the sampling variance to cover the whole state distribution. Additionally, the servoing controller is deduced for robotic coordination directly by visual observation. The stability of the proposed framework is illustrated by Lyapunov theory and applied to a manipulator with eye-in-hand configuration no system parameters. Finally, the simulation and experimental results demonstrate consistently that the proposed algorithm involving learning-remedied outperforms traditional visual servoing approaches.},
  archive      = {J_NEUCOM},
  author       = {Xungao Zhong and Xunyu Zhong and Huosheng Hu and Xiafu Peng},
  doi          = {10.1016/j.neucom.2021.01.029},
  journal      = {Neurocomputing},
  pages        = {206-217},
  shortjournal = {Neurocomputing},
  title        = {A nonparametric-learning visual servoing framework for robot manipulator in unstructured environments},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparison detector for cervical cell/clumps detection in
the limited data scenario. <em>NEUCOM</em>, <em>437</em>, 195–205. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated detection of cervical cancer cells/clumps has the potential to significantly reduce error rate and increase productivity in cervical cancer screening. However, most traditional methods rely on the success of accurate cell segmentation and discriminative hand-crafted features extraction. Recently there are emerging deep learning-based methods which train Convolutional Neural Networks (CNN) to classify cell patches or to detect cells from the whole image. But the former is computationally expensive, while the latter often requires a large-scale dataset with expensive annotations. In this paper we propose an efficient cervical cancer cells/clumps detection method, called Comparison detector, to deal with the limited data problem. Specifically, we utilize the state-of-the-art proposal-based object detection method, Faster R-CNN with Feature Pyramid Network (FPN) as the baseline and replace the classification of each proposal by comparing it with the prototype representation of each category. In addition, we propose to learn the prototype representation of the background category from data instead of manually choosing them by some heuristic rules. Experimental results show that the proposed Comparison detector yields significant improvement on the small dataset, achieving a mean Average Precision (mAP) of 26.3\% and an Average Recall (AR) of 35.7\%, both improved by about 20\% comparing to the baseline. Moreover, when training on the medium-sized dataset, our Comparison detector gains a mAP of 48.8\% and an AR of 64.0\%, improving the AR by 5.1\% and the mAP by 3.6\% respectively. Our method is promising for the development of automation-assisted cervical cancer screening systems. Code and datasets are available at https://github.com/kuku-sichuan/ComparisonDetector .},
  archive      = {J_NEUCOM},
  author       = {Yixiong Liang and Zhihong Tang and Meng Yan and Jialin Chen and Qing Liu and Yao Xiang},
  doi          = {10.1016/j.neucom.2021.01.006},
  journal      = {Neurocomputing},
  pages        = {195-205},
  shortjournal = {Neurocomputing},
  title        = {Comparison detector for cervical cell/clumps detection in the limited data scenario},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpreting chest x-rays via CNNs that exploit hierarchical
disease dependencies and uncertainty labels. <em>NEUCOM</em>,
<em>437</em>, 186–194. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Chest radiography is one of the most common types of diagnostic radiology exams, which is critical for screening and diagnosis of many different thoracic diseases. Specialized algorithms have been developed to detect several specific pathologies such as lung nodules or lung cancer. However, accurately detecting the presence of multiple diseases from chest X-rays (CXRs) is still a challenging task. This paper presents a supervised multi-label classification framework based on deep convolutional neural networks (CNNs) for predicting the presence of 14 common thoracic diseases and observations. We tackle this problem by training state-of-the-art CNNs that exploit hierarchical dependencies among abnormality labels. We also propose to use the label smoothing technique for a better handling of uncertain samples, which occupy a significant portion of almost every CXR dataset. Our model is trained on over 200,000 CXRs of the recently released CheXpert dataset and achieves a mean area under the curve (AUC) of 0.940 in predicting 5 selected pathologies from the validation set. This is the highest AUC score yet reported to date. The proposed method is also evaluated on the independent test set of the CheXpert competition, which is composed of 500 CXR studies annotated by a panel of 5 experienced radiologists. The performance is on average better than 2.6 out of 3 other individual radiologists with a mean AUC of 0.930, which ranks first on the CheXpert leaderboard at the time of writing this paper.},
  archive      = {J_NEUCOM},
  author       = {Hieu H. Pham and Tung T. Le and Dat Q. Tran and Dat T. Ngo and Ha Q. Nguyen},
  doi          = {10.1016/j.neucom.2020.03.127},
  journal      = {Neurocomputing},
  pages        = {186-194},
  shortjournal = {Neurocomputing},
  title        = {Interpreting chest X-rays via CNNs that exploit hierarchical disease dependencies and uncertainty labels},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepEC: Adversarial attacks against graph structure
prediction models. <em>NEUCOM</em>, <em>437</em>, 168–185. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the practical importance of graph structured data, link prediction, one of the most frequently applied tasks on graph data, has garnered considerable attention in recent years, and they have been widely applied in item recommendation, privacy inference attack, knowledge graph completion, fraud detection, and other fields. However, recent studies show that machine learning-based intelligent systems are vulnerable to adversarial attacks , which has recently inspired much research on the security problems of machine learning in the context of computer vision, natural language processing , physical world, etc. Nonetheless, there is a lack of understanding of the vulnerability of link prediction methods in face of adversarial attacks . To unveil the weaknesses and aid in the development of robust link prediction methods, we propose a deep architecture-based adversarial attack method, called Deep Ensemble Coding, against link prediction. In particular, based on the assumption that links play different structural roles in structure organization, we propose a deep linear coding-based structure enhancement mechanism to generate adversarial examples . We also empirically investigate other adversarial attack methods for graph data, including heuristic and evolutionary perturbation methods. Based on the comprehensive experiments conducted on various real-world networks, we can conclude that the proposed adversarial attack method has satisfactory performance for link prediction. Moreover, we can observe that state-of-the-art link prediction algorithms are vulnerable to adversarial attacks and, for adversarial defense, the attack can be viewed as a robustness evaluation for the construction of robust link prediction methods.},
  archive      = {J_NEUCOM},
  author       = {Xingping Xian and Tao Wu and Shaojie Qiao and Wei Wang and Chao Wang and Yanbing Liu and Guangxia Xu},
  doi          = {10.1016/j.neucom.2020.07.126},
  journal      = {Neurocomputing},
  pages        = {168-185},
  shortjournal = {Neurocomputing},
  title        = {DeepEC: Adversarial attacks against graph structure prediction models},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recurrent convolutional neural network for session-based
recommendation. <em>NEUCOM</em>, <em>437</em>, 157–167. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of session-based recommendation is predicting the next recommendation item when available information only includes the anonymous behavior sequence. Previous methods of session-based recommendation usually integrate the general interest, dynamic interest, and current interest to promote recommendation performance. However, most existing methods ignore the non-monotone feature interactions when building user’s dynamic interest and model item-item transitions through a linear way when building user’s current interest, which reduces the performance of model. In this paper, we design a novel method for session-based recommendation with recurrent and convolutional neural network. Specifically, The Gated Recurrent Unit with item-level attention mechanism learns the user’s general interest, while the convolutional operation with horizontal filter and vertical filter search for user’s current interest and dynamic interest. Moreover, the outputs of recurrent operation and convolutional operation are concatenated to generate the recommendation. Furthermore, we evaluate the proposed model on three real-world datasets which come from e-commerce and music API, respectively. The experimental results show that our model outperforms the state-of-the-art methods on session-based recommendation.},
  archive      = {J_NEUCOM},
  author       = {Jinjin Zhang and Chenhui Ma and Xiaodong Mu and Peng Zhao and Chengliang Zhong and A. Ruhan},
  doi          = {10.1016/j.neucom.2021.01.041},
  journal      = {Neurocomputing},
  pages        = {157-167},
  shortjournal = {Neurocomputing},
  title        = {Recurrent convolutional neural network for session-based recommendation},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attentive u-recurrent encoder-decoder network for image
dehazing. <em>NEUCOM</em>, <em>437</em>, 143–156. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Haze removal is an important pre-processing step in many computer vision tasks. Convolutional neural networks, especially the U-shaped networks, have shown to be effective in image dehazing. Nevertheless, these networks have three main limitations. First, the relevant haze information, e.g. concentration of haze, is totally ignored. Second, spatial inconsistency and information dilution usually occur when the networks refine the dehazed results with a coarse-to-fine strategy. Third, the receptive field of the network is not large enough to capture structural information. Motivated by these problems, a new attentive U-recurrent encoder-decoder dehazing network is presented, which consists of an attentive recurrent network and a U-recurrent encoder-decoder network. By assuming that haze layers with different depths can be detected by multiple stages, we use an attentive recurrent network to generate the haze attention map for guiding the U-recurrent encoder-decoder network with the concentration of haze to better estimate the clear image. Meanwhile, the features for dehazing are further enhanced and the dehazing results are refined in the U-recurrent encoder-decoder network. This design not only enables spatial consistency but also reduces information dilution with short recurrent pathways. Furthermore, a novel residual pyramid pooling module is also proposed and used in the U-recurrent encoder-decoder network, which provides the network with structural information and with an enlarged receptive field. The experimental results demonstrate that our method outperforms state-of-the-art dehazing algorithms on both synthetic and real hazy images.},
  archive      = {J_NEUCOM},
  author       = {Shibai Yin and Yibin Wang and Yee-Hong Yang},
  doi          = {10.1016/j.neucom.2020.12.081},
  journal      = {Neurocomputing},
  pages        = {143-156},
  shortjournal = {Neurocomputing},
  title        = {Attentive U-recurrent encoder-decoder network for image dehazing},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive and opposite k-means operation based memetic
algorithm for data clustering. <em>NEUCOM</em>, <em>437</em>, 131–142.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evolutionary algorithm (EA) incorporating with k-means local search operator represents an important approach for cluster analysis. In the existing EA approach, however, the k-means operators are usually directly employed on the individuals and generally applied with fixed intensity as well as frequency during evolution, which could significantly limit their performance. In this paper, we first introduce a hybrid EA based clustering framework such that the frequency and intensity of k-means operator could be arbitrarily configured during evolution. Then, an adaptive strategy is devised to dynamically set its frequency and intensity according to the feedback of evolution. Further, we develop an opposite search strategy to implement the proposed adaptive k-means operation, thus appropriately exploring the search space. By incorporating the above two strategies, a memetic algorithm with adaptive and opposite k-means operation is finally proposed for data clustering . The performance of the proposed method has been evaluated on a series of data sets and compared with relevant algorithms. Experimental results indicate that our proposed algorithm is generally able to deliver superior performance and outperform related methods.},
  archive      = {J_NEUCOM},
  author       = {Xi Wang and Zidong Wang and Mengmeng Sheng and Qi Li and Weiguo Sheng},
  doi          = {10.1016/j.neucom.2021.01.056},
  journal      = {Neurocomputing},
  pages        = {131-142},
  shortjournal = {Neurocomputing},
  title        = {An adaptive and opposite K-means operation based memetic algorithm for data clustering},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A refined equilibrium generative adversarial network for
retinal vessel segmentation. <em>NEUCOM</em>, <em>437</em>, 118–130. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.143">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Retinal vessel morphological parameters are vital indicator for early diagnosis of ophthalmological diseases and cardiovascular events. However, segmentation performance is highly influenced by elusive vessels, especially in low-contrast background and lesion regions. In this work, we present an end-to-end synthetic neural network to strengthen elusive vessels segmentation capability, containing a symmetric equilibrium generative adversarial network (SEGAN), multi-scale features refine blocks (MSFRB), and attention mechanism (AM). The proposed network is superior in detail information extraction by maximizing multi-scale features representation. First, SEGAN constructs a symmetric adversarial architecture in which generator is forced to produce more realistic images with local details. Second, MSFRB are devised to optimize the feature merging process, thereby maximally maintaining high resolution information. Finally, the AM is employed to encourage the network to concentrate on discriminative features. On public dataset DRIVE, STARE, CHASEDB1, and HRF, we evaluate our network quantitatively and compare it with state-of-the-art works. The ablation experiment shows that SEGAN, MSFRB, and AM both contribute to the desirable performance. Conclusion: The proposed network outperforms the existing methods and effectively functions in elusive vessels segmentation, achieving highest scores in Sensitivity, G-Mean, Precision, and F1-Score while maintaining the top level in other metrics. Significance: The satisfactory performance and computational efficiency offer great potential in clinical retinal vessel segmentation application. Meanwhile, the network could be utilized to extract detail information in other biomedical image computing.},
  archive      = {J_NEUCOM},
  author       = {Yukun Zhou and Zailiang Chen and Hailan Shen and Xianxian Zheng and Rongchang Zhao and Xuanchu Duan},
  doi          = {10.1016/j.neucom.2020.06.143},
  journal      = {Neurocomputing},
  pages        = {118-130},
  shortjournal = {Neurocomputing},
  title        = {A refined equilibrium generative adversarial network for retinal vessel segmentation},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multilevel fusion network for 3D object detection.
<em>NEUCOM</em>, <em>437</em>, 107–117. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D object detection is an important yet challenging problem in a myriad of vision, robotics, and human–machine interaction applications. Given an RGB-D image, the task is to infer the class labels and the 3D bounding boxes of the objects in the image. While the previous studies have made remarkable progress over the past decade, how to effectively exploit the feature fusion with neural networks for boosting 3D object detection performance remains an open problem. This paper proposes a multilevel fusion network (MFN) model to detect 3D objects in RGB-D images. The MFN model contains two streams of neural networks which respectively extracts the RGB and depth features with cascaded convolutional modules. To effectively exploit the information of 3D objects, a multilevel fusion mechanism is adopted to fuse the convolutional RGB and depth features at multiple levels. To train the network, we propose a new weighted loss function by encoding the difference of geometric attributes on 3D bounding box regression. Since the original depth data is full of noisy holes, we also develop an adaptive filtering algorithm to restore and correct the depth images. We test the proposed model on challenging RGB-D datasets. The experimental results on the datasets prove the strength and advantage of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Chunlong Xia and Ping Wei and Wenwen Wei and Nanning Zheng},
  doi          = {10.1016/j.neucom.2021.01.025},
  journal      = {Neurocomputing},
  pages        = {107-117},
  shortjournal = {Neurocomputing},
  title        = {A multilevel fusion network for 3D object detection},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facial image inpainting using attention-based multi-level
generative network. <em>NEUCOM</em>, <em>437</em>, 95–106. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial image inpainting is a challenging task since the facial images lose much content causing blur and unnaturalness. In this paper, we propose facial image inpainting using attention-based multi-level generative network. We adopt multi-level feature processing to reduce the training and testing time while enhancing the performance by reducing the number of channels of each convolutional layer in the generator. We combine attention with multi-level feature processing to maintain soft correlation with the surrounding content. For network optimization, we utilize two kinds of loss functions: content and texture. Content loss consists of mean absolute error (MAE) and edge-preserving losses, and produces inpainting results close to the ground truth. Texture loss consists of adversarial and perceptual losses to fine-tune the texture synthesis. Besides, we use the edge-preserving loss to take edge and patch similarity. Comparative experiments indicate that the proposed method produces photo-realistic and plausible inpainting results in random masks as well as outperforms the state-of-the-art ones in terms of quantitative measurements and subjective evaluations.},
  archive      = {J_NEUCOM},
  author       = {Jie Liu and Cheolkon Jung},
  doi          = {10.1016/j.neucom.2020.12.118},
  journal      = {Neurocomputing},
  pages        = {95-106},
  shortjournal = {Neurocomputing},
  title        = {Facial image inpainting using attention-based multi-level generative network},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Change detection with various combinations of fluid pyramid
integration networks. <em>NEUCOM</em>, <em>437</em>, 84–94. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An increasing number of change detection models are designed with different convolutional neural network (CNNs). However, the mechanism for designing network layers that can effectively extract robust features for different scenes remains unclear. Thus, novel networks with fluid pyramid integration network (FPIN) to detect changes are proposed in this study. Specifically, we first extract multi-scale deep features from feature extraction network . Higher layers extract semantic features robust to illumination and camera pose variations, while lower layers extract texture features that generate clear boundaries and changes with small scales. To employ the advantages of the features extracted from different layers, FPIN progressively fuses higher and lower layer features in a hierarchical order. We propose three different change detection networks based on FPIN and validate them on three publicly available change detection benchmark datasets. Experimental results showed that the proposed networks are better than state-of-the-art change detection methods .},
  archive      = {J_NEUCOM},
  author       = {Rui Huang and Mo Zhou and Yan Xing and Yaobin Zou and Wei Fan},
  doi          = {10.1016/j.neucom.2021.01.030},
  journal      = {Neurocomputing},
  pages        = {84-94},
  shortjournal = {Neurocomputing},
  title        = {Change detection with various combinations of fluid pyramid integration networks},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Affective analysis of visual scenes using face pareidolia
and scene-context. <em>NEUCOM</em>, <em>437</em>, 72–83. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a new computer vision approach to perform affective analysis of a scene or object. The approach utilises a simulation of the phenomenon of face pareidolia that can be described as the perception of non-existent faces, for example, in random textures, clouds or rock formations. The emergence of face pareidolia in product designs and natural scenes can modulate affective perception of our everyday experiences without our conscious awareness. We propose a new deep learning method to simulate the face pareidolia ability of humans and predict associated emotional responses in two-dimensional valence and arousal space. Starting from a face detector that was trained on images of human faces, we propose a novel cross-domain weakly supervised three-step progressive domain adaptation approach to simulate face pareidolia by fine-tuning the human face detector on three types of synthetically generated sample images. Our approach fuses two deep network models, one model for predicting valence and arousal from abstract and minimal face-like patterns producing face pareidolia, and a second for recognising overall moods and context associated with the scene. To evaluate our approach, we constructed a new dataset containing instance-level annotations of face pareidolia occurrences as well as valence and arousal emotional values associated with the overall scene. The quantitative and qualitative experimental results of the present study demonstrate that our approach can outperform other state-of-the-art methods in face pareidolia detection as well as in predicting associated emotions.},
  archive      = {J_NEUCOM},
  author       = {Asad Abbas and Stephan Chalup},
  doi          = {10.1016/j.neucom.2021.01.016},
  journal      = {Neurocomputing},
  pages        = {72-83},
  shortjournal = {Neurocomputing},
  title        = {Affective analysis of visual scenes using face pareidolia and scene-context},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BCNet: Bidirectional collaboration network for edge-guided
salient object detection. <em>NEUCOM</em>, <em>437</em>, 58–71. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The boundary quality is a key factor determining the success of accurate salient object detection (SOD). A number of edge-guided SOD methods have been proposed to improve the boundary quality, but shown unsatisfactory performance due to the lack of a comprehensive consideration of multi-level feature fusion and multi-type feature aggregation. To resolve this issue, we propose a novel Bidirectional Collaboration Network (BCNet), which integrates effective multi-level feature fusion and multi-type feature aggregation into a unified edge-guided SOD framework. Specifically, we first utilize multiple Consistency Saliency Maximization (CSM) modules to propagate the highest level semantic representations in a top-down progressive pathway to generate both global edge representations and a series of region representations. Multiple Bounded Feature Fusion (BFF) modules are then utilized to refine the region features with the edge features. The CSM and BFF modules enable robust multi-level feature fusion and multi-type feature aggregation with only little extra computation, which allows a high computational efficiency. Finally, BCNet is jointly trained with edge and region losses in an end-to-end manner. Extensive comparisons are conducted with 17 state-of-the-art methods on five challenging benchmark datasets. Thanks to the use of CSM and BFF modules, our BCNet outperforms existing deep learning based SOD methods, including the latest edge-guided ones, in terms of both detection accuracy and processing speed.},
  archive      = {J_NEUCOM},
  author       = {Bo Dong and Yan Zhou and Chuanfei Hu and Keren Fu and Geng Chen},
  doi          = {10.1016/j.neucom.2021.01.034},
  journal      = {Neurocomputing},
  pages        = {58-71},
  shortjournal = {Neurocomputing},
  title        = {BCNet: Bidirectional collaboration network for edge-guided salient object detection},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Spatial-aware stacked regression network for real-time 3D
hand pose estimation. <em>NEUCOM</em>, <em>437</em>, 42–57. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Making full use of the spatial information of the depth data is crucial for 3D hand pose estimation from a single depth image. In this paper, we propose a Spatial-aware Stacked Regression Network (SSRN) for fast, robust and accurate 3D hand pose estimation from a single depth image. By adopting a differentiable pose re-parameterization process, our method efficiently encodes the pose-dependent 3D spatial structure of the depth data as spatial-aware representations. Taking such spatial-aware representations as inputs, the stacked regression network utilizes multi-joint spatial context and the 3D spatial relationship between the estimated pose and the depth data to predict a refined hand pose. To further improve the estimation accuracy, we adopt a spatial attention mechanism to reduce the influence of irrelevant features for pose regression. In order to improve the speed of the network, we propose a cross-stage self-distillation mechanism to distill knowledge within the network itself. Experiments on four datasets show that our proposed method achieves state-of-the-art accuracy with high running speed around 330 FPS on a single GPU and 35 FPS on a single CPU.},
  archive      = {J_NEUCOM},
  author       = {Pengfei Ren and Haifeng Sun and Weiting Huang and Jiachang Hao and Daixuan Cheng and Qi Qi and Jingyu Wang and Jianxin Liao},
  doi          = {10.1016/j.neucom.2021.01.045},
  journal      = {Neurocomputing},
  pages        = {42-57},
  shortjournal = {Neurocomputing},
  title        = {Spatial-aware stacked regression network for real-time 3D hand pose estimation},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal pricing in black box producer-consumer stackelberg
games using revealed preference feedback. <em>NEUCOM</em>, <em>437</em>,
31–41. (<a href="https://doi.org/10.1016/j.neucom.2021.01.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers an optimal pricing problem for the black box producer-consumer Stackelberg game . A producer sets price over a set of goods to maximize profit (the difference in revenue and cost function). The consumer buys a quantity to maximize the difference between the value of the quantity consumed and the cost. The value function of the consumer and the cost function of the producer are ‘black box’ functions (unknown functions with limited or costly evaluations). Using Gaussian processes , Bayesian optimization and Bayesian quadrature we derive an algorithm for learning the optimal price. The method has the following significant advantages: (i) the method is efficient and scales well compared to existing techniques, (ii) the cost function of the producer could be non-convex, (iii) the value function and/or cost function can be time varying. We illustrate, using a real dataset, optimal pricing in electricity markets.},
  archive      = {J_NEUCOM},
  author       = {Anup Aprem and Stephen J. Roberts},
  doi          = {10.1016/j.neucom.2021.01.026},
  journal      = {Neurocomputing},
  pages        = {31-41},
  shortjournal = {Neurocomputing},
  title        = {Optimal pricing in black box producer-consumer stackelberg games using revealed preference feedback},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Recognition and counting of wheat mites in wheat fields by
a three-step deep learning method. <em>NEUCOM</em>, <em>437</em>, 21–30.
(<a href="https://doi.org/10.1016/j.neucom.2020.07.140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The wheat mite always causes major damage in wheat plants and results in significant yield losses. Therefore, detecting wheat mites can provide important information, such as pest population dynamics and integrated pest management by monitoring wheat mite populations. However, the automatic classification and counting of wheat mites from images taken from crop fields are more difficult than those obtained under laboratory conditions, due to complicated background in crop fields, light instability and small wheat mites in images. Furthermore, the manual identification of wheat mites is very time-consuming and complex. Deep learning technique provides an efficiently automated way for address the issue. This paper proposes a three-step deep learning method to identify and count wheat mites from digital images. First, original large images are separated into smaller images as datasets. Then, the small images are labeled and then enlarged so that each of them can be located in corresponding position of original image. Second, one CNN takes an image (of any size) as input and outputs a set of feature maps for the image. Afterwards, the extracted feature maps are input to Region Proposal Network (RPN), which may be most likely the areas of wheat mites and output a set of rectangular objective proposals, each with an object score. Then one 256-d vector is generated from the obtained proposals by the other CNN . The vector is input into two fully connected layers, a box-regression layer and a box-classification layer, which output the probability scores of the position information and the population of wheat mites, respectively. Moreover, the superposition of the results for the small images is taken as the number of wheat mites for each original image. By using different backbone deep learning networks, ZFnet with five layers and VGG16 with sixteen layers achieved the accuracies of 94.6\% and 96.4\%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Peng Chen and WeiLu Li and SiJie Yao and Chun Ma and Jun Zhang and Bing Wang and ChunHou Zheng and ChengJun Xie and Dong Liang},
  doi          = {10.1016/j.neucom.2020.07.140},
  journal      = {Neurocomputing},
  pages        = {21-30},
  shortjournal = {Neurocomputing},
  title        = {Recognition and counting of wheat mites in wheat fields by a three-step deep learning method},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-representation and class-specificity distribution based
multi-view clustering. <em>NEUCOM</em>, <em>437</em>, 9–20. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the promising performance for clustering, weighted tensor nuclear norm based multi-view subspace clustering needs to artificially predefine a weighted vector when shrinking all the singular values of tensor. It is very difficult to select a suitable weighted vector due to the complex and unknown distribution of data in real applications. Another limitation is that, the learned affinity matrix does not well exploit the cluster structure. To tackle these problems, we propose a novel multi-view subspace clustering method , called SCSD-MVC. The method adaptively allocates a suitable weighted vector to all singular values. The weighted vector well characterizes the significant difference between the singular values. Drawing the inspiration of one finding that ℓ 1 , 2 ℓ1,2 -norm can well characterize class-specificity distribution, which well encodes the cluster structure, we impose ℓ 1 , 2 ℓ1,2 -norm constraint on affinity matrix such that it can well characterize the cluster structure. Experimental results on several databases indicate that SCSD-MVC outperforms state-of-the-art self-representation based multi-view subspace clustering methods.},
  archive      = {J_NEUCOM},
  author       = {Yu Yun and Wei Xia and Yongqing Zhang and Quanxue Gao and Xinbo Gao},
  doi          = {10.1016/j.neucom.2021.01.039},
  journal      = {Neurocomputing},
  pages        = {9-20},
  shortjournal = {Neurocomputing},
  title        = {Self-representation and class-specificity distribution based multi-view clustering},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Zero-shot learning with self-supervision by shuffling
semantic embeddings. <em>NEUCOM</em>, <em>437</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning and self-supervised learning have been widely studied due to the advantage of performing representation learning in a data shortage situation efficiently. However, few studies consider zero-shot learning using semantic embeddings (e.g., CNN features or attributes) and self-supervision simultaneously. The reason is that most zero-shot learning works employ vector-level semantic embeddings . However, most self-supervision studies only consider image-level domains, so a novel self-supervision method for vector-level CNN features is needed. We propose a simple way to shuffle semantic embeddings. Furthermore, we propose a method to enrich feature representation and improve zero-shot learning performance effectively. We show that our model outperforms current state-of-the-art methods on the large-scale ImageNet 21K and the small-scale CUB and SUN datasets.},
  archive      = {J_NEUCOM},
  author       = {Hoseong Kim and Jewook Lee and Hyeran Byun},
  doi          = {10.1016/j.neucom.2021.01.037},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {Zero-shot learning with self-supervision by shuffling semantic embeddings},
  volume       = {437},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning spatio-temporal correlation filter for visual
tracking. <em>NEUCOM</em>, <em>436</em>, 273–282. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Correlation filter (CF) trackers have performed impressive performance with high frame rates. However, the limited information in both spatial and temporal domains is only used in the learning of correlation filters, which might limit the tracking performance. To handle this problem, we propose a novel spatio-temporal correlation filter approach, which employs both spatial and temporal cues in the learning, for visual tracking. In particular, we explore the spatial contexts from background whose contents are ambiguous to the target and integrate them into the correlation filter model for more discriminative learning. Moreover, to capture the appearance variations in temporal domain, we also compute a set of target templates and incorporate them into our model. At the same time, the solution of the proposed spatio-temporal correlation filter is closed-form and the tracking efficiency is thus guaranteed. Experimental experiments on benchmark datasets demonstrate the effectiveness of the proposed tracker against several CF ones.},
  archive      = {J_NEUCOM},
  author       = {Youmin Yan and Xixian Guo and Jin Tang and Chenglong Li and Xin Wang},
  doi          = {10.1016/j.neucom.2021.01.057},
  journal      = {Neurocomputing},
  pages        = {273-282},
  shortjournal = {Neurocomputing},
  title        = {Learning spatio-temporal correlation filter for visual tracking},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CSART: Channel and spatial attention-guided residual
learning for real-time object tracking. <em>NEUCOM</em>, <em>436</em>,
260–272. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Siamese networks have achieved great success in object tracking due to the balance of precision and speed. However, Siamese trackers usually utilize the local feature of the last layer, which may degrade tracking performance in some difficult scenarios. In this paper, we propose a novel Channel and Spatial Attention-guided Residual learning framework for Tracking, referred to as CSART, which can improve feature representation of Siamese networks by exploiting self-attention mechanism to capture powerful contextual information. Specifically, to be efficient and seamless integration, different kinds of self-attention are appended on the template and search branches of Siamese networks respectively, that model global semantic inter-dependencies in channel and spatial dimensions. To avoid representation degradation, we consider to adaptively aggregate basic feature and its attention-weighted features with residual learning. Furthermore, a joint loss consisting of classic logistic loss as well as focal softmax loss is designed to emphasize difficult samples and guide the learning process of the whole model. Benefiting from the above scheme, CSART alleviates the over-fitting problem to some extent and enhances the discriminability . Extensive experiments on six popular tracking datasets indicate that the proposed tracker achieves better performance with a speed of 65 fps than other state-of-the-art trackers.},
  archive      = {J_NEUCOM},
  author       = {Dawei Zhang and Zhonglong Zheng and Minglu Li and Rixian Liu},
  doi          = {10.1016/j.neucom.2020.11.046},
  journal      = {Neurocomputing},
  pages        = {260-272},
  shortjournal = {Neurocomputing},
  title        = {CSART: Channel and spatial attention-guided residual learning for real-time object tracking},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to detect anomaly events in crowd scenes from
synthetic data. <em>NEUCOM</em>, <em>436</em>, 248–259. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, due to its widespread applications in public safety, anomaly detection in crowd scenes has become a hot topic. Some deep-learning-based methods attain significant achievements in this field. Nevertheless, most of them suffer from over-fitting to some extent because of scarce data, which are usually abrupt and low-frequency in the real world. To remedy the above problem, this paper firstly develops a synthetic anomaly event generating system, which could simulate typical specific abnormal events. By utilizing this system, a large synthetic, diverse anomaly event dataset is built, which contains 2,149 video sequences. After getting the dataset, a 3D CNN is designed to detect the abnormal types at the video level. However, we find that there are obvious domain differences (also named as “domain gap/shifts”) between synthetic videos and real-world data, which results in performance degradation when applying the model to the real world. Thus, this paper further proposes a cyclic 3D GAN for domain adaption to reduce the domain gap, which translates the synthetic data to the photorealistic video sequences. Then the detection model is trained on the translated data and it can perform well in the real data. Experimental results illustrate that the proposed method outperforms these baselines for the domain adaptation anomaly detection .},
  archive      = {J_NEUCOM},
  author       = {Wei Lin and Junyu Gao and Qi Wang and Xuelong Li},
  doi          = {10.1016/j.neucom.2021.01.031},
  journal      = {Neurocomputing},
  pages        = {248-259},
  shortjournal = {Neurocomputing},
  title        = {Learning to detect anomaly events in crowd scenes from synthetic data},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-label thresholding for cost-sensitive classification.
<em>NEUCOM</em>, <em>436</em>, 232–247. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label classification associates each instance with a set of labels which reflects the nature of a wide range of real-world applications. However, existing approaches assume that all labels have the same misclassification cost, whereas in real-world problems different types of misclassification errors have different costs, which are generally unknown in the training context or might change from one context to another. Thus, there is a demand for cost-sensitive classification methods that minimise the average misclassification cost rather than error rates or counts. In this paper, we adopt a simple yet general method, called thresholding, which applies to most classification algorithms to adapt them to cost-sensitive multi-label classification. This paper investigates current threshold choice approaches for multi-label classification. It explores the choice of single and multiple thresholds and extends some of the current techniques to support multi-label problems. Moreover, it proposes cost curves and scatter diagrams for performance evaluation in the multi-label setting. Experimental evaluation on 13 multi-label datasets demonstrates that there is no significant loss by adjusting a global threshold rather than a per-label threshold considering different misclassification costs across labels. Although tuning multiple thresholds is the obvious solution, the global threshold can also be valid.},
  archive      = {J_NEUCOM},
  author       = {Reem Alotaibi and Peter Flach},
  doi          = {10.1016/j.neucom.2020.12.004},
  journal      = {Neurocomputing},
  pages        = {232-247},
  shortjournal = {Neurocomputing},
  title        = {Multi-label thresholding for cost-sensitive classification},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Micro-expression action unit detection with spatial and
channel attention. <em>NEUCOM</em>, <em>436</em>, 221–231. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Action Unit ( AU ) detection plays an important role in facial behaviour analysis. In the literature, AU detection has extensive researches in macro-expressions. However, to the best of our knowledge, there is limited research about AU analysis for micro-expressions. In this paper, we focus on AU detection in micro-expressions. Due to the small quantity and low intensity of micro-expression databases, micro-expression AU detection becomes challenging. To alleviate these problems, in this work, we propose a novel micro-expression AU detection method by utilizing self high-order statistics of spatio-wise and channel-wise features which can be considered as spatial and channel attentions, respectively. Through such spatial attention module, we expect to utilize rich relationship information of facial regions to increase the AU detection robustness on limited micro-expression samples. In addition, considering the low intensity of micro-expression AUs, we further propose to explore high-order statistics for better capturing subtle regional changes on face to obtain more discriminative AU features. Intensive experiments show that our proposed approach outperforms the basic framework by 0.0859 on CASME II, 0.0485 on CASME, and 0.0644 on SAMM in terms of the average F1-score.},
  archive      = {J_NEUCOM},
  author       = {Yante Li and Xiaohua Huang and Guoying Zhao},
  doi          = {10.1016/j.neucom.2021.01.032},
  journal      = {Neurocomputing},
  pages        = {221-231},
  shortjournal = {Neurocomputing},
  title        = {Micro-expression action unit detection with spatial and channel attention},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). NGDNet: Nonuniform gaussian-label distribution learning for
infrared head pose estimation and on-task behavior understanding in the
classroom. <em>NEUCOM</em>, <em>436</em>, 210–220. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Head pose estimation (HPE) under active infrared (IR) illumination has attracted much attention in the fields of computer vision and machine learning . However, IRHPE often suffers from the problems of low-quality IR images and ambiguous head pose. To tackle these issues, we propose a novel nonuniform Gaussian-label distribution learning network (NGDNet) for the HPE task. First, we reveal the essential properties from two different perspectives: 1) two head pose images change differently in pitch and yaw directions with the same angle increasing on the central pose; 2) the IR head pose variation first increases and then decreases in the pitch direction. Subsequently, the first property indicates the pose image label as a nonuniform label distribution (Gaussian function) with different long and short axes. The second property is leveraged to determine the distribution size in accordance with the similarities of adjacent hand poses. Lastly, the proposed NGDNet is verified on a new IRHPE dataset, which is built by our research group. Experimental results on several datasets demonstrate the effectiveness of the proposed model. Compared with conventional algorithms, our NGDNet model achieves state-of-the-art performance with 77.39\% on IRHPE, 99.08\% on CAS-PEAL-R1, and 87.41\% on Pointing’04. Our code is publicly available at https://github.com/TingtingSL/NGDNet.},
  archive      = {J_NEUCOM},
  author       = {Tingting Liu and Jixin Wang and Bing Yang and Xuan Wang},
  doi          = {10.1016/j.neucom.2020.12.090},
  journal      = {Neurocomputing},
  pages        = {210-220},
  shortjournal = {Neurocomputing},
  title        = {NGDNet: Nonuniform gaussian-label distribution learning for infrared head pose estimation and on-task behavior understanding in the classroom},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep convolutional neural network-based bernoulli heatmap
for head pose estimation. <em>NEUCOM</em>, <em>436</em>, 198–209. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Head pose estimation is a crucial problem for many tasks, such as driver attention, fatigue detection, and human behaviour analysis. It is well known that neural networks are better at handling classification problems than regression problems . It is an extremely nonlinear process to let the network output the angle value directly for optimization learning, and the weight constraint of the loss function will be relatively weak. This paper proposes a novel Bernoulli heatmap for head pose estimation from a single RGB image . Our method can achieve the positioning of the head area while estimating the angles of the head. The Bernoulli heatmap makes it possible to construct fully convolutional neural networks without fully connected layers and provides a new idea for the output form of head pose estimation. A deep convolutional neural network (CNN) structure with multiscale representations is adopted to maintain high-resolution information and low-resolution information in parallel. This kind of structure can maintain rich, high-resolution representations. In addition, channelwise fusion is adopted to make the fusion weights learnable instead of simple addition with equal weights. As a result, the estimation is spatially more precise and potentially more accurate. The effectiveness of the proposed method is empirically demonstrated by comparing it with other state-of-the-art methods on public datasets.},
  archive      = {J_NEUCOM},
  author       = {Zhongxu Hu and Yang Xing and Chen Lv and Peng Hang and Jie Liu},
  doi          = {10.1016/j.neucom.2021.01.048},
  journal      = {Neurocomputing},
  pages        = {198-209},
  shortjournal = {Neurocomputing},
  title        = {Deep convolutional neural network-based bernoulli heatmap for head pose estimation},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered sliding mode control with adaptive neural
networks for uncertain nonlinear systems. <em>NEUCOM</em>, <em>436</em>,
184–197. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a robust non-singular fast terminal sliding mode control scheme with adaptive neural networks is presented for a class of nonlinear systems with unknown bounds of uncertainties. To reduce transmission and computation burden in resource-constrained networked systems, two kinds of event-triggering mechanisms are taken into consideration in the proposed adaptive sliding mode control scheme. The one, from the sensor to the controller, can guarantee finite-time convergence of system states into a predesigned band; and ensure that Zeno behavior does not occur. The other, from the controller to the actuator, can guarantee the asymptotically stability and Zeno behavior exclusion. Simulation results are given to verify the effectiveness and feasibility of the proposed schemes.},
  archive      = {J_NEUCOM},
  author       = {Nana Wang and Fei Hao},
  doi          = {10.1016/j.neucom.2021.01.055},
  journal      = {Neurocomputing},
  pages        = {184-197},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered sliding mode control with adaptive neural networks for uncertain nonlinear systems},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Non-reduced order strategies for global dissipativity of
memristive neutral-type inertial neural networks with mixed time-varying
delays. <em>NEUCOM</em>, <em>436</em>, 174–183. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The issue of the global dissipativity of memristive neutral-type inertial neural networks with distributed and discrete time-varying delays is discussed without converting the original system to first-order equations. By taking some new Lyapunov–Krasovskii functionals and adopting inequality techniques, several effective criteria formulated by testable algebraic inequalities are derived to assure the global dissipativity and exponential dissipativity for the concerned models, which generalize and refine some previous results. Different from existing ones, the proposed Lyapunov–Krasovskii functionals contain not only the state variables but also their derivatives. The estimations of the globally attractive sets and globally exponentially attractive sets are also proposed. Two examples are given to validate the efficiency of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Kai Wu and Jigui Jian},
  doi          = {10.1016/j.neucom.2020.12.120},
  journal      = {Neurocomputing},
  pages        = {174-183},
  shortjournal = {Neurocomputing},
  title        = {Non-reduced order strategies for global dissipativity of memristive neutral-type inertial neural networks with mixed time-varying delays},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based dynamic surface control for flexible-joint
manipulator system with input saturation and unknown disturbance using
type-2 fuzzy neural network. <em>NEUCOM</em>, <em>436</em>, 162–173. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the nonlinear disturbance observer (NDO) based dynamic surface control (DSC) with interval type-2 fuzzy neural network (IT2FNN) approximator is proposed for flexible-joint manipulator with the input saturation and unknown nonlinear disturbance. The DSC technique has tremendous advantages in eliminating the ’explosion of complexity’ problem. The IT2FNN approximator is used to deal with parameter uncertainties. The NDO is applied to estimate the unknown external disturbance and compensate the saturation constrain. From Lyapunov stability analysis, it is proved that with the proposed control scheme, all signals of the closed-loop system are semiglobally uniformly ultimately bounded. Simulation results are carried out to demonstrate the effectiveness of the proposed scheme. Compared with the adaptive DSC with neural network (NN) approximator and type-1 fuzzy (T1F) approximator, the tracking error of the proposed control scheme converges to a sufficiently small value.},
  archive      = {J_NEUCOM},
  author       = {Yi Hu and Songyi Dian and Rui Guo and Shengchuan Li and Tao Zhao},
  doi          = {10.1016/j.neucom.2020.12.121},
  journal      = {Neurocomputing},
  pages        = {162-173},
  shortjournal = {Neurocomputing},
  title        = {Observer-based dynamic surface control for flexible-joint manipulator system with input saturation and unknown disturbance using type-2 fuzzy neural network},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale stacking attention pooling for remote sensing
scene classification. <em>NEUCOM</em>, <em>436</em>, 147–161. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Remote sensing image scene classification is challenging due to the complicated spatial arrangement and varied object sizes inside a large-scale aerial image. Among the bottlenecks for current deep learning methods to depict and discriminate the complexity of remote sensing scenes, strengthening the local semantic representation and multi-scale feature representation is necessary. In this paper, we propose a multi-scale staking attention pooling (MS2AP) to tackle these challenges, which has three main contributions. Firstly, it can be conveniently embedded into current CNN models in an end-to-end manner to enhance the feature representation capability for remote sensing scenes. Secondly, we propose a novel residual channel-spatial attention module to mine the key local semantics in the feature maps. Compared with current attention modules, it can fuse top-down discriminative features and bottom-up convolution features from both the channel and spatial domain. Thirdly, we propose a multi-scale dilated convolutional operator which can extract multi-scale feature maps and keep their sizes the same. In our MS2AP, these multi-scale feature maps are firstly staked and then down-sampled by a weighted pooling whose weight matrix comes from our attention module. Extensive experiments demonstrate that our MS2AP outperforms the baseline by 4.24\% on UCM, 7.22\% on AID and 14.12\% on NWPU benchmark respectively, and substantially outperforms current state-of-the-art methods by a large margin.},
  archive      = {J_NEUCOM},
  author       = {Qi Bi and Han Zhang and Kun Qin},
  doi          = {10.1016/j.neucom.2021.01.038},
  journal      = {Neurocomputing},
  pages        = {147-161},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale stacking attention pooling for remote sensing scene classification},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relevant information undersampling to support imbalanced
data classification. <em>NEUCOM</em>, <em>436</em>, 136–146. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional classification algorithms suppose that the sample distribution among classes is balanced. Yet, such an assumption leads to biased performance over the majority class. This paper proposes a Relevant Information-based UnderSampling (RIUS) approach to select the most relevant examples from the majority class to improve the classification performance for imbalanced data scenarios. RIUS builds on the information-preservation principle that extracts the majority class’s underlying structure with fewer samples. Additionally, we couple our RIUS approach to the well-known Clustering-based Undersampling algorithm (CBUS) to enhance the data representation, and named this RIUS enhancement as CRIUS. Experimental results show that RIUS and CRIUS reveal the data’s relevant structure and reduce the loss of information by selecting the most informative instances.},
  archive      = {J_NEUCOM},
  author       = {J. Hoyos-Osorio and A. Alvarez-Meza and G. Daza-Santacoloma and A. Orozco-Gutierrez and G. Castellanos-Dominguez},
  doi          = {10.1016/j.neucom.2021.01.033},
  journal      = {Neurocomputing},
  pages        = {136-146},
  shortjournal = {Neurocomputing},
  title        = {Relevant information undersampling to support imbalanced data classification},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Effects of burst-timing-dependent plasticity on synchronous
behaviour in neuronal network. <em>NEUCOM</em>, <em>436</em>, 126–135.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain plasticity or neuroplasticity refers to the ability of the nervous system to reorganise itself in response to stimuli. For instance, sensory and motor stimulation, memory formation, and learning depend on brain plasticity. Neuronal synchronisation can be enhanced or suppressed by the plasticity. Synchronisation is related to many functions in the brain, as well as to some brain disorders. One possible plasticity rule is the burst-timing-dependent plasticity (BTDP), that induces synaptic alteration according to the timing of neuronal bursts. In this work, we build a network of coupled Rulkov maps where the excitatory connections are randomly distributed. We consider the BTDP to study its effects on the synchronous neuronal activities . In our simulations, we observe that depending on the initial synaptic weights , the whole network or part of it can have its neuronal synchronisation improved. This increase can be reached by two different mechanisms, the initial burst synchronisation and random statistical coincidence. A mix of these two mechanism is also found in the network. BTDP can induce the formation of desynchronised and synchronised clusters that operate in different frequencies, but only if the noise level is low. Our results show possible mechanisms of cluster formation in burst neuronal networks. We also consider the BTDP rule on a small-world network and show that, depending on the initial connection strength, the network can exhibit local or non-local properties.},
  archive      = {J_NEUCOM},
  author       = {João Antonio Paludo Silveira and Paulo Ricardo Protachevicz and Ricardo Luiz Viana and Antonio Marcos Batista},
  doi          = {10.1016/j.neucom.2021.01.044},
  journal      = {Neurocomputing},
  pages        = {126-135},
  shortjournal = {Neurocomputing},
  title        = {Effects of burst-timing-dependent plasticity on synchronous behaviour in neuronal network},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Anti-interference analysis of bio-inspired musculoskeletal
robotic system. <em>NEUCOM</em>, <em>436</em>, 114–125. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared with general joint-link robotic systems, bio-inspired musculoskeletal robotic systems offer the advantages of higher robustness, flexibility, and redundancy. Hence, they are a promising option for the development of next-generation robots. However, theoretical analysis regarding the superiorities of musculoskeletal systems is scarce. This study analyzes and proves the anti-interference of a musculoskeletal system both mathematically and experimentally. a) A new method to calculate the control signals of a highly nonlinear and deeply coupled musculoskeletal system is proposed, and the redundancy range is provided. The result shows that each movement of the system can be realized by multiple control signals in a subspace. b) The anti-interference to control signals caused by the nonlinear driving mechanism of muscles and the coupled feedback effect of the skeletal system are analyzed. The simulation results prove that the bio-inspired musculoskeletal robotic arm has a smaller tracking error than the joint-link robotic arm under the same perturbations of the control signals. The theoretical analysis is consistent with the simulation results, thereby providing a theoretical reference for the application of bio-inspired musculoskeletal robotic systems.},
  archive      = {J_NEUCOM},
  author       = {Yaxiong Wu and Jiahao Chen and Hong Qiao},
  doi          = {10.1016/j.neucom.2021.01.054},
  journal      = {Neurocomputing},
  pages        = {114-125},
  shortjournal = {Neurocomputing},
  title        = {Anti-interference analysis of bio-inspired musculoskeletal robotic system},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft-sensing of wastewater treatment process via deep belief
network with event-triggered learning. <em>NEUCOM</em>, <em>436</em>,
103–113. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the complex dynamic behavior of a Wastewater Treatment Process (WWTP), the existing soft-sensing models usually fail to efficiently and accurately predict its effluent water quality. Especially when a lot of practical data is provided and we do not know which data-pair is more valuable, WWTP modeling becomes a time-consuming process. The main reason is that the existing soft-sensing models update their parameters at each data-pair in one iteration, while some update operations are meaningless. To address this thorny problem, this paper proposes a Deep Belief Network with Event-triggered Learning (DBN-EL) to improve the efficiency and accuracy of soft-sensing model in WWTP. First, some events are defined according to different running condition during the process of training DBN-based soft-sensing model. The different running condition is dominated by the fluctuation of error-reduction rate. Second, an event-triggered learning strategy is designed to construct DBN-EL, whose parameters are updated only when a positive event is triggered. Thirdly, we present the convergence analysis of DBN-EL based on the optimization in a Markov process . Finally, the effectiveness of DBN-EL is demonstrated on soft-sensing of total phosphorus concentration in a practical WWTP system. In experiment, DBN-EL is compared with nine different models on soft-sensing of WWTP. The experimental results show that the efficiency of DBN-EL is 27.6\%–64.9\% higher than that of nine competitive models, which indicates that the proposed model is readily available for industrial deployment.},
  archive      = {J_NEUCOM},
  author       = {Gongming Wang and Qing-Shan Jia and MengChu Zhou and Jing Bi and Junfei Qiao},
  doi          = {10.1016/j.neucom.2020.12.108},
  journal      = {Neurocomputing},
  pages        = {103-113},
  shortjournal = {Neurocomputing},
  title        = {Soft-sensing of wastewater treatment process via deep belief network with event-triggered learning},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Regularization graph convolutional networks with data
augmentation. <em>NEUCOM</em>, <em>436</em>, 92–102. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, there is a lot of progress in designing effective convolutional schemes on irregular graph structures. These graph convolutional networks mostly solve the semi-supervised learning problem on the graph where the number of labeled nodes typically is very small and the number of unlabeled nodes is very large. In the standard GCN, only labeled nodes will enter the loss function; unlabeled data will not get into the loss function. The model will be unstable due to the unconstrained nature of unlabeled nodes. This will lead to overfitting and negatively affect the generalization ability of the model. To solve this problem, we propose to regularize the graph convolutional networks using data augmentation . We provide the details of the regularization GCN and SGC model and design rich data augmentation schemes including individual features perturbation, individual edge addition, and combination of them. To verify the performance of our method, we conduct experiments on standard benchmarks and explore the intensity effect of different data augmentation strategies. The experimental results on the node classification tasks demonstrate that our method can outperform baseline methods .},
  archive      = {J_NEUCOM},
  author       = {Xiuzhi Tian and Chris H.Q. Ding and Sibao Chen and Bin Luo and Xin Wang},
  doi          = {10.1016/j.neucom.2020.12.124},
  journal      = {Neurocomputing},
  pages        = {92-102},
  shortjournal = {Neurocomputing},
  title        = {Regularization graph convolutional networks with data augmentation},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The intermittent fault diagnosis of analog circuits based on
EEMD-DBN. <em>NEUCOM</em>, <em>436</em>, 74–91. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at the intermittent faults widely existing in analog circuits , caused by poor soldering and performance degradation of components, a method for the intermittent fault diagnosis of analog circuits based on ensemble empirical mode decomposition (EEMD) and deep belief network (DBN) is proposed. The amplitude and frequency anomaly signals in the frequency domain is regarded as triggering signals for intermittent fault detection, so the signal segments containing intermittent faults can be detected. The signal segment with intermittent fault is decomposed into multiple intrinsic mode functions (IMFs) by EEMD, and the IMF and fault features are optimized by using Pearson correlation coefficient and feature separability. The optimization feature set is established, which is used as feature vector to transmitted to DBN for fault diagnosis. The proposed method can autonomously realize the feature selection and the diagnosis of intermittent fault. The optimization features make DBN improve diagnostic accuracy , reduce diagnostic time, and can locate intermittent faults to the circuit branch with intermittent faults. The simulation experiments show that the proposed method has strong fault diagnosis capability. And the comparative experiments prove that compared with other commonly used methods, the EEMD-DBN method has higher diagnostic accuracy in intermittent fault diagnosis of analog circuits.},
  archive      = {J_NEUCOM},
  author       = {Ting Zhong and Jianfeng Qu and Xiaoyu Fang and Hao Li and Zeping Wang},
  doi          = {10.1016/j.neucom.2021.01.001},
  journal      = {Neurocomputing},
  pages        = {74-91},
  shortjournal = {Neurocomputing},
  title        = {The intermittent fault diagnosis of analog circuits based on EEMD-DBN},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effects of eye movements on the visual cortical
responding variability based on a spiking network. <em>NEUCOM</em>,
<em>436</em>, 58–73. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural responses in the primary visual cortex are variable. There are abundant experimental data characterizing how the visual cortical responding variability depends on the eye movements, but the underlying mechanism is still debatable. To explore this underlying mechanism, we take the eye movements into a two-layer plastic k-winner-take-all (k-WTA) spiking network. In our simulations, grayscale images serve as outside stimuli to the network and several example traces of eye movements are set specifically. To a same image, different eye movements induce the downstream responding variability of our network. These induced responses, in conjunction with the traces of eye movements, provide distinguishing reconstructions of the image. These results suggest a novel interpretation of how the eye movements affect the primary visual cortical responding variability.},
  archive      = {J_NEUCOM},
  author       = {Weisi Liu and Xinsheng Liu},
  doi          = {10.1016/j.neucom.2021.01.013},
  journal      = {Neurocomputing},
  pages        = {58-73},
  shortjournal = {Neurocomputing},
  title        = {The effects of eye movements on the visual cortical responding variability based on a spiking network},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronization for fractional-order reaction–diffusion
competitive neural networks with leakage and discrete delays.
<em>NEUCOM</em>, <em>436</em>, 47–57. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the synchronization of fractional-order competitive neural networks with reaction–diffusion terms and time delays . A novel method that combines the fractional-order Lyapunov theorem with M-matrix theory is utilized to cope with synchronization for the addressed networks. Based on such approach and developing two different controllers, some sufficient criteria are derived to guarantee global synchronization by employing the properties about Mittag–Leffler and trigonometric functions , comparison principle as well as the method of contradiction. Finally, a numerical example is provided to show the effectiveness of the established result.},
  archive      = {J_NEUCOM},
  author       = {Shuai Yang and Haijun Jiang and Cheng Hu and Juan Yu},
  doi          = {10.1016/j.neucom.2021.01.009},
  journal      = {Neurocomputing},
  pages        = {47-57},
  shortjournal = {Neurocomputing},
  title        = {Synchronization for fractional-order reaction–diffusion competitive neural networks with leakage and discrete delays},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Extended dissipative state estimation for static neural
networks via delay-product-type functional. <em>NEUCOM</em>,
<em>436</em>, 39–46. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the issue of extended dissipative state estimation for static neural networks with time-varying delays. A new delay-product-type (DPT) functional is constructed to introduce triple integrals, which can encompass some existing DPT functionals as its special cases, which leads to less conservative results. A parameter-dependent reciprocally convex inequality (PDRCI) covering some existing results is proposed to estimate the DPT functional, which can reach a tighter bound. Based on these ingredients, a novel estimator design condition is obtained to ensure the estimation error system to be asymptotically stable and extended dissipative. By using a matrix inequality decoupling technique, the estimator gain matrices can be solved by linear matrix inequalities (LMIs). Compared with some existing works, the restrictions on slack matrices are overcome, which increase the flexibility of estimator solutions. The effectiveness of the developed method is illustrated by an example.},
  archive      = {J_NEUCOM},
  author       = {Yufeng Tian and Zhanshan Wang},
  doi          = {10.1016/j.neucom.2020.12.107},
  journal      = {Neurocomputing},
  pages        = {39-46},
  shortjournal = {Neurocomputing},
  title        = {Extended dissipative state estimation for static neural networks via delay-product-type functional},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OpenNAS: Open source neuromorphic auditory sensor HDL code
generator for FPGA implementations. <em>NEUCOM</em>, <em>436</em>,
35–38. (<a href="https://doi.org/10.1016/j.neucom.2020.12.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {OpenNAS is an open-source tool for automatically generating the source files to create a Neuromorphic Auditory Sensor (NAS) VHDL project for FPGA. OpenNAS guides the user with a friendly interface that allows configuring the NAS’ parameters using a five-step wizard for code generation. OpenNAS provides support to several audio input interfaces (AC’97 audio codec, I2S-ADC and PDM microphones), different processing architectures (cascade and parallel), and neuromorphic output interfaces (parallel AER, SpiNNaker). After NAS generation, users have everything ready for building, simulating, and synthesizing the VHDL project for a target FPGA. OpenNAS is fully modular, which allows providing support to new features in an easy way.},
  archive      = {J_NEUCOM},
  author       = {D. Gutierrez-Galan and J.P. Dominguez-Morales and A. Jimenez-Fernandez and A. Linares-Barranco and G. Jimenez-Moreno},
  doi          = {10.1016/j.neucom.2020.12.062},
  journal      = {Neurocomputing},
  pages        = {35-38},
  shortjournal = {Neurocomputing},
  title        = {OpenNAS: Open source neuromorphic auditory sensor HDL code generator for FPGA implementations},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Information capacity of a stochastically responding neuron
assembly. <em>NEUCOM</em>, <em>436</em>, 22–34. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, certain aspects of the structure of the overlapping groups of neurons encoding specific signals are examined. Individual neurons are assumed to respond stochastically to input signal. Identification of a particular signal is assumed to result from the aggregate activity of a group of neurons, which we call information pathway. Conditions for definite response and for non-interference of pathways are derived. These conditions constrain the response properties of individual neurons and the allowed overlap among pathways. Under these constrains, and under the simplifying assumption that all pathways have similar structure, the information capacity of the system is derived. Furthermore, we show that there is a definite advantage in the information capacity if pathway neurons areinterspersed among the neuron assembly.},
  archive      = {J_NEUCOM},
  author       = {I. Smyrnakis and M. Papadopouli and G. Pallagina and S. Smirnakis},
  doi          = {10.1016/j.neucom.2020.12.130},
  journal      = {Neurocomputing},
  pages        = {22-34},
  shortjournal = {Neurocomputing},
  title        = {Information capacity of a stochastically responding neuron assembly},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Active label distribution learning. <em>NEUCOM</em>,
<em>436</em>, 12–21. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Label Distribution Learning (LDL) is a new learning paradigm to describe supervision as probability distribution and has been successfully applied in many real-world scenarios in recent years. In LDL applications, the availability of a large amount of labeled data guarantees the prediction performance. In this paper, we cogitate the active learning for LDL to reduce the annotation cost. The center element in practice any active learning strategy is building the criterion that measures the usefulness of the unlabeled data and decides the instances to be selected to label manually. We are probably the first to focus on active instance selecting for label distribution learning. We propose a strategy named Active Label Distribution Learning (ALDL) to select the most informative instances for LDL applications. The fundamental idea of the ALDL strategy is to quantify the degree of disagreement for each unlabeled instance by the committee consisted of selected LDL algorithms, and identify the instances to be labeled manually. ALDL maintains composing the committee with selected LDL algorithms and measure the value of unlabeled instances, and a weight vector is used both parts. Besides, we discuss the convergence and the parameter selecting of ALDL. Finally, compared with other active learning methods, the experimental results on the datasets show the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Xinyue Dong and Shilin Gu and Wenzhang Zhuge and Tingjin Luo and Chenping Hou},
  doi          = {10.1016/j.neucom.2020.12.128},
  journal      = {Neurocomputing},
  pages        = {12-21},
  shortjournal = {Neurocomputing},
  title        = {Active label distribution learning},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Learning to estimate smooth and accurate semantic
correspondence. <em>NEUCOM</em>, <em>436</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We tackle the problem of estimating dense semantic correspondence between two images depicting different instances of the same category. In this paper, we consider semantic context and correspondence information from the neighborhood in order to overcome the drawback of previous works that estimate the correspondence of each pixel or patch independently. To this end, a novel network, called SANet, with a trainable spatial aggregation module is proposed, which is trained in an end-to-end manner and outputs semantic flow. We train this SANet by adopting two complementary loss terms: landmark loss, focusing on keypoints with ground truth, and consistency loss, applicable to all pixels without ground truth. Qualitative and quantitative experimental results demonstrate the improved network achieves a better balance between accuracy and smoothness comparing with the baseline and warps images with better visual quality.},
  archive      = {J_NEUCOM},
  author       = {Huaiyuan Xu and Xiaodong Chen and Jiaqi Xi and Jing Liao},
  doi          = {10.1016/j.neucom.2021.01.005},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Learning to estimate smooth and accurate semantic correspondence},
  volume       = {436},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conflux LSTMs network: A novel approach for multi-view
action recognition. <em>NEUCOM</em>, <em>435</em>, 321–329. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view action recognition (MVAR) is an optimal technique to acquire numerous clues from different views data for effective action recognition, however, it is not well explored yet. There exist several challenges to MVAR domain such as divergence in viewpoints, invisible regions, and different scales of appearance in each view require better solutions for real world applications. In this paper, we present a conflux long short-term memory (LSTMs) network to recognize actions from multi-view cameras. The proposed framework has four major steps; 1) frame level feature extraction, 2) its propagation through conflux LSTMs network for view self-reliant patterns learning, 3) view inter-reliant patterns learning and correlation computation, and 4) action classification . First, we extract deep features from a sequence of frames using a pre-trained VGG19 CNN model for each view. Second, we forward the extracted features to conflux LSTMs network to learn the view self-reliant patterns. In the next step, we compute the inter-view correlations using the pairwise dot product from output of the LSTMs network corresponding to different views to learn the view inter-reliant patterns. In the final step, we use flatten layers followed by SoftMax classifier for action recognition. Experimental results over benchmark datasets compared to state-of-the-art report an increase of 3\% and 2\% on northwestern-UCLA and MCAD datasets, respectively.},
  archive      = {J_NEUCOM},
  author       = {Amin Ullah and Khan Muhammad and Tanveer Hussain and Sung Wook Baik},
  doi          = {10.1016/j.neucom.2019.12.151},
  journal      = {Neurocomputing},
  pages        = {321-329},
  shortjournal = {Neurocomputing},
  title        = {Conflux LSTMs network: A novel approach for multi-view action recognition},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring multiobjective training in multiclass
classification. <em>NEUCOM</em>, <em>435</em>, 307–320. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multinomial logistic loss and L 2 L2 regularization are often conflicting objectives as more robust regularization leads to restrained multinomial parameters. For many practical problems, leveraging the best of both worlds would be invaluable for better decision-making processes. This research proposes a novel framework to obtain representative and diverse L 2 L2 -regularized multinomial models, based on valuable trade-offs between prediction error and model complexity. The framework relies upon the Non-Inferior Set Estimation (NISE) method – a deterministic multiobjective solver. NISE automatically implements hyperparameter tuning in a multiobjective context. Given the diverse set of efficient learning models, model selection and aggregation of the multiple models in an ensemble framework promote high performance in multiclass classification . Additionally, NISE uses the weighted sum method as scalarization, thus being able to deal with the learning formulation directly. Its deterministic nature and the convexity of the learning problem confer scalability to the proposal. The experiments show competitive performance in various setups, taking a broad set of multiclass classification methods as contenders.},
  archive      = {J_NEUCOM},
  author       = {Marcos M. Raimundo and Thalita F. Drumond and Alan Caio R. Marques and Christiano Lyra and Anderson Rocha and Fernando J. Von Zuben},
  doi          = {10.1016/j.neucom.2020.12.087},
  journal      = {Neurocomputing},
  pages        = {307-320},
  shortjournal = {Neurocomputing},
  title        = {Exploring multiobjective training in multiclass classification},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Neural network-based adaptive tracking control for switched
nonlinear systems with prescribed performance: An average dwell time
switching approach. <em>NEUCOM</em>, <em>435</em>, 295–306. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates a problem of adaptive neural output-feedback tracking control for a class of switched uncertain nonlinear systems in nonstrict-feedback structure with average dwell time. For the system under study, many factors are taken into consideration, such as unknown nonlinearities, unmeasurable states, external disturbance, unknown dead-zone input, and prescribed performance bounds. A switched NN state observer is established to observe the unmeasurable states and alleviate the conservativeness induced by taking advantage of a common observer. In order to defeat the trouble originated from the nonstrict-feedback structure, an effective adaptive law is introduced by adopting the properties of NNs. The influence of dead-zone on control performance is restricted by designing a special adaptive law in the last step of the backstepping design frame. The stability of the closed-loop system is proved by average dwell time approach and Lyapunov stability theory . By utilizing the multiple Lyapunov function method and the backstepping technique together with the prescribed performance bounds, an adaptive NN controller is established which can ensure that all the signals in the closed-loop system are bounded under a class of switching signals with average dwell time and the tracking error converges to the predefined bounds. The feasibility of the presented control scheme is illustrated by the simulation results.},
  archive      = {J_NEUCOM},
  author       = {Yuanqing Wang and Ben Niu and Huanqing Wang and N. Alotaibi and E. Abozinadah},
  doi          = {10.1016/j.neucom.2020.10.023},
  journal      = {Neurocomputing},
  pages        = {295-306},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based adaptive tracking control for switched nonlinear systems with prescribed performance: An average dwell time switching approach},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A markov regime switching model for asset pricing and
ambiguity measurement of stock market. <em>NEUCOM</em>, <em>435</em>,
283–294. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Based on the theoretical framework of expected utility with uncertain probabilities, this paper uses actual prices of CSI300 and Hang Seng index to empirically measure ambiguity degrees in the Chinese mainland and Hong Kong stock markets. A Markov regime-switching model is proposed to divide the stock market into bear and bull states, and then test whether there exist significant differences in the ambiguity degrees under different states. An ambiguity factor and a risk factor are then proposed to analyze the time-varying relationship among risk, ambiguity, and return under different states. In addition to the mean and variance, the high-order moments, including skewness and kurtosis , are used to test whether they affect the relationship among them. The results show that the ambiguity degrees in the Chinese mainland stock market are significantly higher than those in the Hong Kong stock market, and there are significant differences between bear and bull states for the two markets. Moreover, the regression results among risk, ambiguity, and return indicate that with ambiguity, the effects of risk factors on excess returns is significantly negative under bear state, and significantly positive under bull state, while it is significantly negative under the two states without ambiguity.},
  archive      = {J_NEUCOM},
  author       = {Jia Wang and MengChu Zhou and Xiwang Guo and Liang Qi and Xu Wang},
  doi          = {10.1016/j.neucom.2020.12.103},
  journal      = {Neurocomputing},
  pages        = {283-294},
  shortjournal = {Neurocomputing},
  title        = {A markov regime switching model for asset pricing and ambiguity measurement of stock market},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive NN tracking control with prespecified accuracy for
a class of uncertain periodically time-varying and nonlinearly
parameterized switching systems. <em>NEUCOM</em>, <em>435</em>, 273–282.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on a tracking control issue for a class of uncertain switching nonlinear systems under arbitrary switching with unknown time-varying parameters. An approximator is designed by combining Multilayer neural network (MNN) with Fourier series expansion (FSE) to approximate the nonlinearly parameterized unknown functions. Then, a common Lyapunov function (CLF) is constructed and a novel adaptive neural network (NN) control scheme is proposed by using the adaptive Backstepping technique. It can be proven that the tracking error falls into a prespecified domain of equilibrium and the whole system is semi-globally uniformly ultimately bounded (SGUUB). The effectiveness of the designed approach is verified through two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Xiaoli Yang and Jing Li and Zhaohui Zhang},
  doi          = {10.1016/j.neucom.2021.01.017},
  journal      = {Neurocomputing},
  pages        = {273-282},
  shortjournal = {Neurocomputing},
  title        = {Adaptive NN tracking control with prespecified accuracy for a class of uncertain periodically time-varying and nonlinearly parameterized switching systems},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PdlADMM: An ADMM-based framework for parallel deep learning
training with efficiency. <em>NEUCOM</em>, <em>435</em>, 264–272. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alternating Direction Methods of Multipliers (ADMM) has been proven to be a useful alternative to the popular gradient-based optimizers and successfully applied to train the DNN model. Whereas existing ADMM-based approaches generally do not achieve a good trade-off between the rapid convergence and fast training and do not support parallel DNN training with multiple GPUs as well. These drawbacks seriously hinder them from effectively training DNN models with modern GPU computing platforms which are always equipped with multiple GPUs. In this paper, we propose pdlADMM that can effectively train DNN in a data-parallel manner. The key insight of pdlADMM lies in that it explores efficient solutions for each sub-problem by comprehensively considering three main factors including computational complexity , convergence, and suitability to parallel computing . With more number of GPUs, pdlADMM remains rapid convergence and the computational complexity on each GPU tends to decline. Extensive experiments demonstrate the effectiveness of our proposal. Compared to the other two state state-of-the-art ADMM-based approaches, pdlADMM converges significantly faster, obtains better accuracy, and achieves very competitive training speed at the same time.},
  archive      = {J_NEUCOM},
  author       = {Lei Guan and Zhihui Yang and Dongsheng Li and Xicheng Lu},
  doi          = {10.1016/j.neucom.2020.09.029},
  journal      = {Neurocomputing},
  pages        = {264-272},
  shortjournal = {Neurocomputing},
  title        = {PdlADMM: An ADMM-based framework for parallel deep learning training with efficiency},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attractiveness of pseudo almost periodic solutions for
delayed cellular neural networks in the context of measure theory.
<em>NEUCOM</em>, <em>435</em>, 253–263. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we use recent results on pseudo almost periodicity to study a class of non-autonomous cellular neural networks with mixed delays. Sufficient conditions are obtained in context of general measure theory ( d μ ( x ) = ρ ( x ) dx + d μ 1 ( x ) dμ(x)=ρ(x)dx+dμ1(x) ), for existence, uniqueness and global exponentially stability of μ μ -pseudo almost periodic solutions of the considered model. As a consequence, we establish the exponential attractiveness of μ μ -pseudo almost periodic solutions of the addressed model as t ⟶ + ∞ t⟶+∞ . Some examples and numerical simulations are given to illustrate our results.},
  archive      = {J_NEUCOM},
  author       = {David Békollè and Khalil Ezzinbi and Samir Fatajou and Duplex Elvis Houpa Danga and Fritz Mbounja Béssémè},
  doi          = {10.1016/j.neucom.2020.12.047},
  journal      = {Neurocomputing},
  pages        = {253-263},
  shortjournal = {Neurocomputing},
  title        = {Attractiveness of pseudo almost periodic solutions for delayed cellular neural networks in the context of measure theory},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised bayesian non parametric approach for
non-intrusive load monitoring based on time of usage. <em>NEUCOM</em>,
<em>435</em>, 239–252. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infinite Factorial Hidden Markov Model (iFHMM) is an attractive extension of Factorial Hidden Markov Model for Non-Intrusive Load Monitoring (NILM) which infers automatically the number of appliances in households and adapts its effective model complexity to fit the data. However, due to the infinite dimension nature of the model, its inference is difficult and faces several issues in the context of NILM. First, the model is hindered by computational complexity because it cannot deal with a number of appliances greater than ten. Second, it still requires accuracy improvement. Third, the model convergence may take a too long time. Therefore, a new infinite Factorial Hidden Markov Model constrained on Contextual features (iFHMMCC) is developed to overcome these shortcomings. To this end, appliances’ time of usage is added to the model in order improve disaggregation accuracy. Besides, it is used to alleviate the inference’s computational complexity and makes the model more tractable than Bayesian Non-Parametric (BNP) state of the art algorithms. Evaluation is performed on REDD database and the proposed approach is compared to five different well-known BNP disaggregation algorithms. The obtained results demonstrate an encouraging improvement in disaggregation accuracy as well as the inference’s computational complexity.},
  archive      = {J_NEUCOM},
  author       = {Hajer Salem and Moamar Sayed-Mouchaweh and Moncef Tagina},
  doi          = {10.1016/j.neucom.2020.12.096},
  journal      = {Neurocomputing},
  pages        = {239-252},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised bayesian non parametric approach for non-intrusive load monitoring based on time of usage},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised and semi-supervised deep probabilistic models for
indoor positioning problems. <em>NEUCOM</em>, <em>435</em>, 228–238. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {WiFi fingerprint-based indoor localization has been a popular research topic recently. In this work, we propose two novel deep learning-based models, the convolutional mixture density recurrent neural network and the variational autoencoder-based semi-supervised learning model. The convolutional mixture density recurrent neural network is designed for indoor next location prediction, in which the advantages of convolutional neural networks, recurrent neural networks and mixture density networks are combined. Furthermore, since most of real-world WiFi fingerprint data are not labeled, we devise a variational autoencoder-based model to compute accurate user location in a semi-supervised learning manner. Finally, in order to evaluate the proposed models, we conduct the validation experiments on two real-world datasets. The final results are compared to other existing methods and verify the effectiveness of our approaches.},
  archive      = {J_NEUCOM},
  author       = {Weizhu Qian and Fabrice Lauri and Franck Gechter},
  doi          = {10.1016/j.neucom.2020.12.131},
  journal      = {Neurocomputing},
  pages        = {228-238},
  shortjournal = {Neurocomputing},
  title        = {Supervised and semi-supervised deep probabilistic models for indoor positioning problems},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal function approximation with ReLU neural networks.
<em>NEUCOM</em>, <em>435</em>, 216–227. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the optimal approximations of univariate functions with feed-forward ReLU neural networks . We attempt to answer the following questions. For given function and network, what is the minimal possible approximation error? How fast does the optimal approximation error decrease with network size? Is optimal approximation attainable by current network training techniques? Theoretically, we introduce necessary and sufficient conditions for optimal approximations of convex functions . We give lower and upper bounds of optimal approximation errors, and approximation rate that measures how fast approximation error decreases with network size. ReLU network architectures are presented to generate optimal approximations. We then propose an algorithm to compute optimal approximations and prove its convergence. We conduct experiments to validate its effectiveness and compare with other approaches. We also demonstrate that the theoretical limit of approximation errors is not attained by ReLU networks trained with stochastic gradient descent optimization, which indicates that the expressive power of ReLU networks has not been exploited to its full potential.},
  archive      = {J_NEUCOM},
  author       = {Bo Liu and Yi Liang},
  doi          = {10.1016/j.neucom.2021.01.007},
  journal      = {Neurocomputing},
  pages        = {216-227},
  shortjournal = {Neurocomputing},
  title        = {Optimal function approximation with ReLU neural networks},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust low-rank tensor completion via transformed tensor
nuclear norm with total variation regularization. <em>NEUCOM</em>,
<em>435</em>, 197–215. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust low-rank tensor completion plays an important role in multidimensional data analysis against different degradations, such as Gaussian noise , sparse noise, and missing entries, and has a variety of applications in image processing and computer vision. In this paper, we investigate the problem of low-rank tensor completion with different degradations for third-order tensors, and propose a transformed tensor nuclear norm method combined the tensor ℓ 1 ℓ1 norm with total variational (TV) regularization . Our model is based on a recently proposed algebraic framework in which the transformed tensor nuclear norm is introduced to capture lower transformed multi-rank by using suitable unitary transformations . We adopt the tensor ℓ 1 ℓ1 norm to detect the sparse noise, and the TV regularization to preserve the piecewise smooth structure along the spatial and tubal dimensions. Moreover, a symmetric Gauss–Seidel based alternating direction method of multipliers is developed to solve the resulting model and its global convergence is established under very mild conditions. Extensive numerical examples on both hyperspectral images and video datasets are carried out to demonstrate the superiority of the proposed model compared with several existing state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Duo Qiu and Minru Bai and Michael K. Ng and Xiongjun Zhang},
  doi          = {10.1016/j.neucom.2020.12.110},
  journal      = {Neurocomputing},
  pages        = {197-215},
  shortjournal = {Neurocomputing},
  title        = {Robust low-rank tensor completion via transformed tensor nuclear norm with total variation regularization},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Attentive multi-view deep subspace clustering net.
<em>NEUCOM</em>, <em>435</em>, 186–196. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel Attentive Multi-View Deep Subspace Nets (AMVDSN), which deeply explores underlying consistent and view-specific information from multiple views and fuse them by considering each view’s dynamic contribution obtained by attention mechanism . Unlike most multi-view subspace learning methods that they directly reconstruct data points on raw data or only consider consistency or complementarity when learning representation in deep or shallow space, our proposed method seeks to find a joint latent representation that explicitly considers both consensus and view-specific information among multiple views, and then performs subspace clustering on learned joint latent representation. Besides, different views contribute differently to representation learning, we therefore introduce attention mechanism to derive dynamic weight for each view, which performs much better than previous fusion methods in the field of multi-view subspace clustering. The proposed algorithm is intuitive and can be easily optimized just by using Stochastic Gradient Descent (SGD) because of the neural network framework, which also provides strong non-linear characterization capability compared with traditional subspace clustering approaches . The experimental results on seven real-world data sets have demonstrated the effectiveness of our proposed algorithm against some state-of-the-art subspace learning approaches.},
  archive      = {J_NEUCOM},
  author       = {Run-kun Lu and Jian-wei Liu and Xin Zuo},
  doi          = {10.1016/j.neucom.2021.01.011},
  journal      = {Neurocomputing},
  pages        = {186-196},
  shortjournal = {Neurocomputing},
  title        = {Attentive multi-view deep subspace clustering net},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint distortion rectification and super-resolution for
self-driving scene perception. <em>NEUCOM</em>, <em>435</em>, 176–185.
(<a href="https://doi.org/10.1016/j.neucom.2020.12.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisheye lenses are widely applied in the self-driving system due to its large field of view (FOV), which also induces the strong radial distortion in captured data. Distortion rectification is a crucial preprocessing step for scene perception since the non-linear projection heavily destroys the original geometric distribution of objects. Previous methods rectify the distorted image with a plausible global distribution, but they perform poorly on the local appearance such as the detailed texture of vehicles and pedestrians, which are hard to meet the fine requirements of object detection and semantic recognition. To solve this problem, we propose a joint distortion rectification (DR) and super-resolution (SR) end-to-end framework to generate the realistic rectification result with a visually pleasing local appearance. To the best of our knowledge, this is the first parametric framework that combines the challenging techniques DR and SR in the field of computer vision, which learns the accurate mapping function from the distorted and low-resolution domain into the corrected and high-resolution domain simultaneously. Moreover, the devised network architecture using the channel attention mechanism and object-aware loss function enables better-reconstructed scenes compared with the state-of-the-art methods. Experimental results show that our approach achieves superior rectification and enhancement performance in both quantitative measure and visual qualitative appearance, contributing a comprehensive and promising vision algorithm to the perception of the self-driving scene.},
  archive      = {J_NEUCOM},
  author       = {Keyao Zhao and Kang Liao and Chunyu Lin and Meiqin Liu and Yao Zhao},
  doi          = {10.1016/j.neucom.2020.12.115},
  journal      = {Neurocomputing},
  pages        = {176-185},
  shortjournal = {Neurocomputing},
  title        = {Joint distortion rectification and super-resolution for self-driving scene perception},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An enhanced differential evolution algorithm with a new
oppositional-mutual learning strategy. <em>NEUCOM</em>, <em>435</em>,
162–175. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Global optimization has been a hot research topic in various engineering applications, where differential evolution (DE) is one of the most popular approaches. Actually, it is inevitable for DE to trap into local optima when dealing with complex optimization problems . Dynamic opposite learning (DOL), which is a new variant of opposition-based learning (OBL), has the potential for enhancing DE, due to its strong exploration capability contributed by the asymmetric and dynamic search space. To balance exploration and exploitation, an adjustable weight parameter of the search space is adopted, yet adjusting the value needs a lot of tests and expert experience. Instead of relying on the additional weight parameter, a mutual learning (ML) strategy, which leads individuals to learn from each other deterministically, is combined with DOL for raising exploitation. The trade-off between exploration and exploitation is guaranteed by randomly switching DOL and ML in the population initialization process and the generation jumping process. A hybrid strategy , named oppositional-mutual learning (OML), is thereby generated, and it is applied for the performance improvement of DE. Benchmarks from CEC 2014, including unimodal, multi-modal, hybrid and composition functions, were adopted to evaluate the performance of the oppositional-mutual learning DE (OMLDE). Numerical results with the comparisons to the state-of-the-art counterparts show that OMLDE has significant advantages of converging to the global optimum on most functions, which also validates the superiority of the novel OML strategy.},
  archive      = {J_NEUCOM},
  author       = {Yunlang Xu and Xiaofeng Yang and Zhile Yang and Xiaoping Li and Pang Wang and Runze Ding and Weike Liu},
  doi          = {10.1016/j.neucom.2021.01.003},
  journal      = {Neurocomputing},
  pages        = {162-175},
  shortjournal = {Neurocomputing},
  title        = {An enhanced differential evolution algorithm with a new oppositional-mutual learning strategy},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel improved trigonometric neural network algorithm for
solving price-dividend functions of continuous time one-dimensional
asset-pricing models. <em>NEUCOM</em>, <em>435</em>, 151–161. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Asset pricing model is the pillar of modern financial market price theory. It is of great practical and theoretical significance to solve the equilibrium price-dividend function of the asset pricing model. To solve the asset pricing model, this paper develops a novel neural network method called improved trigonometric neural network , which consists of three parts: the improved trigonometric function , the initial-condition extreme learning machine algorithm and the reduction algorithm . First, the equilibrium price-dividend function is described as a stochastic differential equation and this function is translated into a second-order ordinary differential equation equivalently. Second, the improved trigonometric neural network is used to solve the differential equation with initial conditions, where the improved trigonometric function is used to serve as the activation function . The reduction algorithm is proposed to obtain a simpler network structure and a faster computing speed. Third, numerical experiments of the improved trigonometric neural network show that the numerical solution of the price-dividend function will be obtained precisely, quickly and feasibly. Compared with several methods to solve asset pricing model, the improved trigonometric neural network has the highest accuracy and fastest speed.},
  archive      = {J_NEUCOM},
  author       = {Mingjie Ma and Lunan Zheng and Jianhui Yang},
  doi          = {10.1016/j.neucom.2021.01.012},
  journal      = {Neurocomputing},
  pages        = {151-161},
  shortjournal = {Neurocomputing},
  title        = {A novel improved trigonometric neural network algorithm for solving price-dividend functions of continuous time one-dimensional asset-pricing models},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Android malware detection through machine learning on
kernel task structures. <em>NEUCOM</em>, <em>435</em>, 126–150. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advent of smart phones, the popularity of free Android applications has risen rapidly. This has led to malicious Android apps being involuntarily installed, which violate the user privacy or conduct attack. Malware detection on Android platforms therefore is a growing concern because of the undesirable similarity between malicious behavior and benign behavior , which can lead to slow detection, and allow compromises to persist for comparatively long periods of time in infected phones. The contributions of this paper are first a multiple dimensional, kernel feature-based framework and feature weight-based detection (WBD) designed to categorize and comprehend the characteristics of Android malware and benign apps. Furthermore, our software agent is orchestrated and implemented for the data collection and storage to scan thousands of benign and malicious apps automatically. We examine 112 kernel attributes of executing the task data structure in the Android system and evaluate the detection accuracy with a number of datasets of various dimensions. We find that memory- and signal-related features contribute to more precise classification than schedule-related and other descriptors of task states listed in our paper. Particularly, memory-related features provide fine-grain classification policies for preserving higher classification precision than the signal-related and others. Furthermore, we study and evaluate 80 newly infected attributes of the Android kernel task structure, prioritizing the 70 features of most significance based on dimensional reduction to optimize the efficiency of high-dimensional classification. Our second contribution is that our experiments demonstrate that, as compared to existing techniques with a short list of task structure features (16 or 32 features), our method can achieve 94\%-98\% accuracy and 2\%–7\% false positive rate, while detecting malware apps with reduced-dimensional features that adequately abbreviate online malware detections and advance offline malware inspections.},
  archive      = {J_NEUCOM},
  author       = {Xinning Wang and Chong Li},
  doi          = {10.1016/j.neucom.2020.12.088},
  journal      = {Neurocomputing},
  pages        = {126-150},
  shortjournal = {Neurocomputing},
  title        = {Android malware detection through machine learning on kernel task structures},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Passivity analysis for uncertain BAM inertial neural
networks with time-varying delays. <em>NEUCOM</em>, <em>435</em>,
114–125. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Without reducing the second order terms into first order, this paper analyzes the passivity for uncertain BAM inertial neural networks with time-varying delays. Two different types of uncertainties covering parameter and Markovian Jump uncertainties are considered, respectively. Based on Lyapunov functional method, inequality techniques and applying relaxed integral inequality, a few new Lyapunov functionals are proposed to straightway address the passivity of the concerned systems, several delay-dependent criteria are acquired in terms of linear matrix inequalities to insure the passivity. Moreover, the time-varying delays here can be non-differentiable and the conservatism of the obtained results is further reduced by using relaxed integral inequality. Finally, some numerical simulations are provided to demonstrate the feasibility of proposed results.},
  archive      = {J_NEUCOM},
  author       = {Mengying Yan and Jigui Jian and Sheng Zheng},
  doi          = {10.1016/j.neucom.2020.12.073},
  journal      = {Neurocomputing},
  pages        = {114-125},
  shortjournal = {Neurocomputing},
  title        = {Passivity analysis for uncertain BAM inertial neural networks with time-varying delays},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DA-DSUnet: Dual attention-based dense SU-net for automatic
head-and-neck tumor segmentation in MRI images. <em>NEUCOM</em>,
<em>435</em>, 103–113. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Precise and accurate segmentation of the most common head-and-neck tumor, nasopharyngeal carcinoma (NPC), in magnetic resonance images (MRI) sheds light on treatment and regulatory decisions making, especially on radiotherapy planning. However, segmenting NPC manually is time-consuming and expensive. Thus, automatic segmentation of NPC is highly demanded. Whereas, problems such as large variations in the lesion size and shape of NPC, boundary ambiguity, as well as limited available annotated samples, conspire NPC segmentation towards a formidable task. Consequently, existing NPC segmentation methods cannot satisfy the high requirements for medical practice. Motivated by these challenges and prevalence of deep learning, in this paper, we propose a Dual Attention-based Dense SU-net (DA-DSUnet) framework for automatic NPC segmentation. It is an encoder-decoder network taking 2D NPC MRI slices as input and outputting the corresponding segmentation results. The main innovations of our method are fourfold. First, different from the traditional decoder in the baseline (U-net) which uses upconvolution for upsamling, we argue that the restoration from low resolution features to high resolution outputs should be capable of preserving the information related to boundary localization. Therefore, we use unpooling as the upsampling method in our model. Second, to combat the vanishing-gradient problem, we introduce dense block which can facilitate feature propagation to replace the traditional convolutional block. Third, we incorporate a dual attention mechanism in our network, which models the inter-dependencies in position and channel dimensions. Fourth, using only binary cross entropy (BCE) as loss function may bring about troubles such as miss-prediction. Hence, we propose to use a loss function named BCEDice to train the network. Quantitative and qualitative comparisons are carried out extensively on in–house dataset. The experimental results show that the proposed method achieves a DSC of 0.8050, a PM of 0.8026 and a CR of 0.7065, which respectively has a relative gain of 5.17\%, 13.8\% and 10.3\% over U-net, indicating the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Pin Tang and Chen Zu and Mei Hong and Rui Yan and Xingchen Peng and Jianghong Xiao and Xi Wu and Jiliu Zhou and Luping Zhou and Yan Wang},
  doi          = {10.1016/j.neucom.2020.12.085},
  journal      = {Neurocomputing},
  pages        = {103-113},
  shortjournal = {Neurocomputing},
  title        = {DA-DSUnet: Dual attention-based dense SU-net for automatic head-and-neck tumor segmentation in MRI images},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Addressing the multi-label imbalance for neural networks: An
approach based on stratified mini-batches. <em>NEUCOM</em>,
<em>435</em>, 91–102. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced learning in the multi-label scenario is a challenging issue, and it also exists in the training of deep neural network . Previous studies have demonstrated that the resampling methods are capable of reducing bias towards the majority group. Nonetheless, when being extended to neural network , these methods display some obvious drawbacks, such as the introduction of extra hyperparameters, the fixed training mode, etc. In order to eliminate the disadvantages, in this paper, an efficient training technique named Mini-Batch Gradient Descent with S tratified s ampling (MBGD- Ss ) is proposed to alliviate the issue with imbalanced data by dynamically sampling. In view of the specialty of multi-label domain, we put forward two specific strategies as L abel P owerset based ( SsLP ) and L abel-based ( SsL ), respectively. Particularly, SsLP takes the label combination (labelset) that appears in the dataset as a stratum, and SsL directly sets the label as a stratum. Extensive experiments validate the effectiveness of the proposed approach in decreasing the imbalance of sampled data. Moreover, the empirical analysis also shows that the proposed method can mitigate the classifier’s bias against labels, especially improve the prediction accuracy of minority labels.},
  archive      = {J_NEUCOM},
  author       = {Dunlu Peng and Tianfei Gu and Xue Hu and Cong Liu},
  doi          = {10.1016/j.neucom.2020.12.122},
  journal      = {Neurocomputing},
  pages        = {91-102},
  shortjournal = {Neurocomputing},
  title        = {Addressing the multi-label imbalance for neural networks: An approach based on stratified mini-batches},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Identification of dynamic community in temporal network via
joint learning graph representation and nonnegative matrix
factorization. <em>NEUCOM</em>, <em>435</em>, 77–90. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The accumulated temporal networks provide an opportunity to explore the dynamics of complex systems, and detecting the dynamic communities is of considerable significance because they shed light on revealing the mechanisms of the underlying systems. In comparison to static communities, identifying dynamic community must simultaneously take into account the clustering accuracy and drift, which are challenging to balance. Furthermore, the available algorithms cannot fully characterize the dynamics of networks, thereby resulting in undesirable performance. To attack these issues, we propose a novel j oint L earning of D ynamic E mbedding and C lustering (jLDEC) algorithm for dynamic community detection, where network embedding, dynamics of edges, and clustering are integrated into an overall objective function. Specifically, the graph representation and dynamics at the edge level are fused, which provide a better way to characterize the dynamics of communities. The joint learning framework extracts the graph representation under the guidance of clustering, which promotes the accuracy of clustering in return. The experimental results on the artificial and real-world networks demonstrate that the proposed method outperforms state-of-the-art approaches for dynamic community detection in temporal networks.},
  archive      = {J_NEUCOM},
  author       = {Dongyuan Li and Qiang Lin and Xiaoke Ma},
  doi          = {10.1016/j.neucom.2021.01.004},
  journal      = {Neurocomputing},
  pages        = {77-90},
  shortjournal = {Neurocomputing},
  title        = {Identification of dynamic community in temporal network via joint learning graph representation and nonnegative matrix factorization},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive fuzzy output feedback FTC for nonstrict-feedback
systems with sensor faults and dead zone input. <em>NEUCOM</em>,
<em>435</em>, 67–76. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper solves the fault-tolerant control (FTC) problem of uncertain nonlinear systems in nonstrict-feedback form. The controlled plants considered in this paper are more complicated than existing ones, which is composed of the unknown nonlinearities, unmeasured states, and sensor faults and unknown dead zone input nonlinearity. Fuzzy logic systems and a fault-estimation-based state observer are used for identifying the unknown nonlinearities and obtaining the unmeasured states, respectively. By designing the sensor faults compensation and the dead zone inverse compensation methods, an observer-based fault-tolerant compensation control scheme is developed under backstepping recursive design frame. And it is testified that the closed-loop signals are bounded, and the tracking performance is satisfied even when the controlled systems are not free of sensor faults and unknown dead zone input nonlinearity. An electromechanical system is used to test the effectiveness of the developed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Jun Zhang and Shaocheng Tong},
  doi          = {10.1016/j.neucom.2021.01.008},
  journal      = {Neurocomputing},
  pages        = {67-76},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fuzzy output feedback FTC for nonstrict-feedback systems with sensor faults and dead zone input},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Auto-ReID+: Searching for a multi-branch ConvNet for person
re-identification. <em>NEUCOM</em>, <em>435</em>, 53–66. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of person re-identification (ReID), multi-branch models are more effective in learning robust features than single-branch models. The current popular multi-branch models are based on ResNet or GoogleNet. These networks are designed initially to solve classification problems. There is an essential difference between ReID and classification problems, so it is particularly important to find a corresponding multi-branch backbone for ReID tasks. We propose to automatically search for a multi-branch convolutional neural network (CNN) for ReID tasks utilizing neural architecture search (NAS). First, we designed a multi-resolution, multi-branch macro search architecture that can extract more abundant scale information. Then in the searching process, the early stopping mechanism is proposed to improve the effectiveness and efficiency of the entire searching process. Finally, we experimentally prove on four mainstream datasets that the searched model can achieve state-of-the-art performance with only 5.7 million parameters.},
  archive      = {J_NEUCOM},
  author       = {Hongyang Gu and Guangyuan Fu and Jianmin Li and Jun Zhu},
  doi          = {10.1016/j.neucom.2020.12.105},
  journal      = {Neurocomputing},
  pages        = {53-66},
  shortjournal = {Neurocomputing},
  title        = {Auto-ReID+: Searching for a multi-branch ConvNet for person re-identification},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Residual attention and other aspects module for aspect-based
sentiment analysis. <em>NEUCOM</em>, <em>435</em>, 42–52. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis task designed to predict the sentiment polarity of each aspect term in a text. Recent research mainly uses neural networks to model text and utilizes attention mechanisms to interact for associate aspect terms and context to obtain more effective feature representation. However, the general attention mechanism is easy to lose the original information. Besides, in the multi-aspect text, the sentiment information of other aspect terms interferes with the sentiment analysis of the current aspect term likely. In this paper, we propose two models named RA-CNN and RAO-CNN for ABSA tasks. In RA-CNN, we apply CNN to model the aspect term and utilize a specially designed residual attention mechanism to interact with the text. Based on the RA-CNN, RAO-CNN adds other aspect terms module, which can reduce interference of sentiment information related to other aspect terms in the multi-aspect text. To verify the proposed models’ effectiveness, we conduct a large number of experiments and comparisons on seven public datasets. Experimental results show that our proposed models are useful and achieve state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Chao Wu and Qingyu Xiong and Zhengyi Yang and Min Gao and Qiude Li and Yang Yu and Kaige Wang and Qiwu Zhu},
  doi          = {10.1016/j.neucom.2021.01.019},
  journal      = {Neurocomputing},
  pages        = {42-52},
  shortjournal = {Neurocomputing},
  title        = {Residual attention and other aspects module for aspect-based sentiment analysis},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The theoretical research of generative adversarial networks:
An overview. <em>NEUCOM</em>, <em>435</em>, 26–41. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative adversarial networks (GAN) has received great attention and made great progress since its emergence in 2014. In this paper, we focus on the theoretical achievements of GAN and discuss them in detail for readers who wish to know more about GAN. Based on the number of the implemented network architectures , we category the improved methods into two groups: GAN variants, which are composed of two networks, to improve the performance by adding some regularization to the loss function; hybrid GANs, which are usually combined with other generative models to improve the training stability. For GAN variants, we discuss the theoretical results of the distribution divergence, training dynamics and various improved methods. For hybrid GANs, we introduce the improved methods of combining encoder, autoencoder or VAE. We also cover some other important issues, such as the quantify metrics of generated samples and the basic construction structure. In addition, we discuss the advantages of the GAN over other deep generative models , the future directions worthy of study, as well as the open issues that the community should further address.},
  archive      = {J_NEUCOM},
  author       = {Yanchun Li and Qiuzhen Wang and Jie Zhang and Lingzhi Hu and Wanli Ouyang},
  doi          = {10.1016/j.neucom.2020.12.114},
  journal      = {Neurocomputing},
  pages        = {26-41},
  shortjournal = {Neurocomputing},
  title        = {The theoretical research of generative adversarial networks: An overview},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Graph active learning for GCN-based zero-shot
classification. <em>NEUCOM</em>, <em>435</em>, 15–25. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.127">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the supervised learning approach, classification models can only categorize objects into seen classes for which labeled data instances are available for training. Zero-shot learning, especially the recent graph neural network-based zero-shot learning, is commonly accepted as an effective approach to address this limitation by exploiting relations between seen classes and unseen classes. However, lots of seen classes are still necessary for most zero-shot learning frameworks to infer the classification model for unseen classes, especially in the image classification task. In this paper, we propose an active learning framework of graph convolutional network (GCN)-based zero-shot learning for image classification and design a new active learning algorithm called GAZL that can enable the zero-shot learning model to achieve a higher performance with a fixed amount of seen classes. Our algorithm extends the k-center algorithm with a new Laplacian energy-based strategy to select the most representative and crucial classes as seen classes for training. Extensive experiments on ImageNet demonstrate that our active learning method is superior to a wide spectrum of active learning methods for GCN-based zero-shot learning.},
  archive      = {J_NEUCOM},
  author       = {Qunbo Wang and Wenjun Wu and Yongchi Zhao and Yuzhang Zhuang},
  doi          = {10.1016/j.neucom.2020.12.127},
  journal      = {Neurocomputing},
  pages        = {15-25},
  shortjournal = {Neurocomputing},
  title        = {Graph active learning for GCN-based zero-shot classification},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level cross-view consistent feature learning for
person re-identification. <em>NEUCOM</em>, <em>435</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2021.01.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification plays an important role in searching for a specific person in a camera network with non-overlapping cameras. The most critical problem for re-identification is feature representation. In this paper, a multi-level cross-view consistent feature learning framework is proposed for person re-identification. First, local deep, LOMO and SIFT features are extracted to form multi-level features. Specifically, local features from the lower and higher layers of a convolutional neural network (CNN) are extracted, these features complement each other as they extract apparent and semantic properties. Second, an ID-based cross-view multi-level dictionary learning (IDB-CMDL) is carried out to obtain sparse and discriminant feature representation. Third, a cross-view consistent word learning is performed to get the cross-view consistent BoVW histograms from sparse feature representation. Finally, a multi-level metric learning fuses multiple BoVW histograms , and learns the sample distance in the subspace for ranking. Experiments on the public CUHK03, Market1501, and DukeMTMC-ReID datasets show results that are superior to many state-of-the-art methods for person re-identification.},
  archive      = {J_NEUCOM},
  author       = {Yixiu Liu and Yunzhou Zhang and Bir Bhanu and Sonya Coleman and Dermot Kerr},
  doi          = {10.1016/j.neucom.2021.01.010},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Multi-level cross-view consistent feature learning for person re-identification},
  volume       = {435},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inductive semi-supervised learning with graph convolution
based regression. <em>NEUCOM</em>, <em>434</em>, 315–322. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This brief paper introduces a framework for supervised and semi-supervised learning by estimating a non-linear embedding that incorporates Spectral Graph Convolutions structure. The proposed algorithm exploits data-driven graphs in two ways. First, it integrates data smoothness over graphs. Second, its regression loss function jointly uses the data and its graph in the sense that the regressor model sees convolved data samples. The resulting framework can solve the problem of over-fitting on local neighborhood structures for image data having varied natures like outdoor scenes, faces and man-made objects. The proposed Graph Convolution based Semi-supervised Embedding (GCSE) not only provides a new perspective to non-linear embedding research but also induces the standpoint on Spectral Graph Convolutions methods. A series of experiments are conducted on four image datasets in order to compare the proposed method with some state-of-art semi-supervised methods. This evaluation demonstrates the effectiveness of the proposed embedding method.},
  archive      = {J_NEUCOM},
  author       = {Ruifeng Zhu and Fadi Dornaika and Yassine Ruichek},
  doi          = {10.1016/j.neucom.2020.12.084},
  journal      = {Neurocomputing},
  pages        = {315-322},
  shortjournal = {Neurocomputing},
  title        = {Inductive semi-supervised learning with graph convolution based regression},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SLRTA: A sparse and low-rank tensor-based approach to
internet traffic anomaly detection. <em>NEUCOM</em>, <em>434</em>,
295–314. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet traffic anomaly detection (ITAD) is a critical task for various network tasks such as traffic engineering and network security . Matrix-based approaches of ITAD have limitations for traffic data with multi-way structures, while the emerging tensor-based approaches of ITAD lack of sufficient consideration for circumstances including incomplete measurements or link-load measurements. To address these issues, we formulate ITAD by a sparse low-rank tensor optimization model, taking into full consideration the intrinsic and potential properties including the sparsity of anomalies, the low-rankness, the temporal stability and periodicity of the normal traffic data. Although the resulting optimization model is non-convex and discontinuous due to the involved ℓ 0 ℓ0 -norm and the tensor rank function, optimality analysis via stationarity is established, based on which an efficient proximal gradient method with theoretical convergence to stationary points is designed. Numerical experiments on internet traffic trace data Abilene and GÉANT demonstrate the high efficiency of our proposed sparse and low-rank tensor-based approach (SLRTA) for ITAD.},
  archive      = {J_NEUCOM},
  author       = {Xiaotong Yu and Ziyan Luo and Liqun Qi and Yanwei Xu},
  doi          = {10.1016/j.neucom.2020.12.123},
  journal      = {Neurocomputing},
  pages        = {295-314},
  shortjournal = {Neurocomputing},
  title        = {SLRTA: A sparse and low-rank tensor-based approach to internet traffic anomaly detection},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). JROTM: Jointly reinforced object tracking with temporal
content reference and motion guidance. <em>NEUCOM</em>, <em>434</em>,
285–294. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the existing visual object tracking methods have made noticeable progress, many chokepoints remain unsettled. One of the most significant performance bottlenecks is the drastic change of the target, such as fast motion, scale variation, appearance changes, etc. Focusing on this major barrier, we propose our object tracking method, JROTM. It adopts the two-stage tracking-by-detection strategy, and it is reinforced by the temporal content reference (TCR) module and the motion guidance (MG) module. TCR precisely provides auxiliary frame-wise information of two consecutive frames of a video. With this information, the rapid change of the object’s appearance and position is retarded. MG module accurately offers more target position hints at the current frame. Our proposed JROTM is evaluated in multiple popular tracking benchmark, including OTB-100, TempleColor-128, and VOT-2016. It outperforms the state-of-the-art tracking methods by a non-neglectable margin.},
  archive      = {J_NEUCOM},
  author       = {Jichun Li and Bo Yan and Chuming Lin and Weimin Tan},
  doi          = {10.1016/j.neucom.2020.12.111},
  journal      = {Neurocomputing},
  pages        = {285-294},
  shortjournal = {Neurocomputing},
  title        = {JROTM: Jointly reinforced object tracking with temporal content reference and motion guidance},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High speed long-term visual object tracking algorithm for
real robot systems. <em>NEUCOM</em>, <em>434</em>, 268–284. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although many visual tracking algorithms have made many achievements in video sequences, they have not been confirmed to work well on the real robot systems with the unpredictable changes and limited computing capabilities. In order to face the complex practical conditions, including huge scale variation, occlusion and long-term task, this paper develops a CF-based long-term tracking algorithm. The main strategies are as follows. A novel confidence score is proposed to judge tracking reliability, and the tracking drift is corrected to keep the target’s long-term appearance. Furthermore, once the target is lost, it can be relocated by the multi-scale search. Our tracker performs favorably against other CF-based trackers with strong engineering applicability. Finally, experiments on the datasets and an UAV are carried out to verify the effectiveness for real robot systems.},
  archive      = {J_NEUCOM},
  author       = {Muxi Jiang and Rui Li and Qisheng Liu and Yingjing Shi and Esteban Tlelo-Cuautle},
  doi          = {10.1016/j.neucom.2020.12.113},
  journal      = {Neurocomputing},
  pages        = {268-284},
  shortjournal = {Neurocomputing},
  title        = {High speed long-term visual object tracking algorithm for real robot systems},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Conditional image generation with one-vs-all classifier.
<em>NEUCOM</em>, <em>434</em>, 261–267. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper explores conditional image generation with a One-Vs-All classifier based on the Generative Adversarial Networks (GANs). Instead of the real/fake discriminator used in vanilla GANs, we propose to extend the discriminator to a One-Vs-All classifier (GAN-OVA) that can distinguish each input data to its category label. Specifically, we feed certain additional information as conditions to the generator and take the discriminator as a One-Vs-All classifier to identify each conditional category. Our model can be applied to different divergence or distances used to define the objective function, such as Jensen-Shannon divergence and Earth-Mover (or called Wasserstein-1) distance. We evaluate GAN-OVAs on MNIST and CelebA-HQ datasets, and the experimental results show that GAN-OVAs improve generation quality and the stability of training.},
  archive      = {J_NEUCOM},
  author       = {Xiangrui Xu and Yaqin Li and Cao Yuan},
  doi          = {10.1016/j.neucom.2020.12.091},
  journal      = {Neurocomputing},
  pages        = {261-267},
  shortjournal = {Neurocomputing},
  title        = {Conditional image generation with one-vs-all classifier},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adversarial learning with collaborative attention for facial
makeup removal. <em>NEUCOM</em>, <em>434</em>, 249–260. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose an adversarial learning method with collaborative attention to remove facial makeup in profile photos using generative adversarial networks (GANs). One challenge of makeup removal is how to preserve key characteristics, such as eye color, while thoroughly removing makeup. A collaborative attention mechanism is proposed to selectively manipulate face regions. In the mechanism, intra-attention takes the self-correlation of faces with makeup into consideration, which restricts inter-attention to pay more attention to regions with heavier makeup while leaving other regions untouched ( e.g ., eyes and hair). Another challenge is that the similarity between light makeup and non-makeup images results in a small domain gap. In such cases, it is hard to distinguish and thoroughly remove light makeup. To strengthen discriminative ability, we propose using input makeup images as negative samples to train a new-style classifier for the discriminator . The classifier enhances the discriminator to extract more discriminative style features and helps the generator to thoroughly remove light makeup. To validate the proposed algorithm, a large-scale makeup/non-makeup dataset was built. Extensive experiments demonstrated the effectiveness of the proposed method, achieving new state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Xueling Chen and Yu Zhu and Yanning Zhang},
  doi          = {10.1016/j.neucom.2020.12.101},
  journal      = {Neurocomputing},
  pages        = {249-260},
  shortjournal = {Neurocomputing},
  title        = {Adversarial learning with collaborative attention for facial makeup removal},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pinning synchronization for delayed coupling complex
dynamical networks with incomplete transition rates markovian jump.
<em>NEUCOM</em>, <em>434</em>, 239–248. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization problem is investigated for a class of time-varying delayed coupling complex dynamical networks subject to incomplete transition rates Markovian switching typologies via pinning control scheme. Compared with most of previous relative networks, a more general network model is discussed and in which the transition rates in Markovian processes are uncertain or completely unknown. The complete knowledge on the transition rates is difficult to precisely acquire on account of the limitations of equipment and environmental impacts. Only a single feedback controller is utilized and, by constructing time dependent Lyapunov–Krasovskii functions, applying an extended Jensen’s integral inequality as well as some inequality techniques, some criteria are obtained for guaranteeing stochastic synchronization of considered networks. Moreover, similar results can be also presented for Markovian jump complex dynamical networks without time-varying delay. The obtained results improve and extend some existing relevant results. In the end, some simulation examples are provided to illustrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jianwen Feng and Ke Cheng and Jingyi Wang and Juan Deng and Yi Zhao},
  doi          = {10.1016/j.neucom.2020.12.104},
  journal      = {Neurocomputing},
  pages        = {239-248},
  shortjournal = {Neurocomputing},
  title        = {Pinning synchronization for delayed coupling complex dynamical networks with incomplete transition rates markovian jump},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient attention based deep fusion CNN for smoke
detection in fog environment. <em>NEUCOM</em>, <em>434</em>, 224–238.
(<a href="https://doi.org/10.1016/j.neucom.2021.01.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Smoke detection based on video monitoring is of great importance for early fire warning. However, most of the smoke detection methods based on neural network only consider the normal weather. The harsh weather such as the fog environment is ignored. In this paper, we propose a smoke detection in normal and fog weather, which combines attention mechanism and feature-level and decision-level fusion module. First, a new fog smoke dataset with diverse positive and hard negative samples dataset is established through online collection and offline shooting. Then, an attention mechanism module combining spatial attention and channel attention is proposed to solve the problem of small smoke detection. Next, a lightweight feature-level and decision-level fusion module is proposed, which can not only improve the discrimination of smoke, fog and other similar objects, but also ensure the real-time performance of the model. Finally, a large number of comparative experiments on the existing dataset and our self-created dataset, show that our method can obtain higher detection accuracy rate, precision rate, recall rate, and F1 score from the perspective of overall, each category, small smoke and hard negative samples detection than the existing methods.},
  archive      = {J_NEUCOM},
  author       = {Lijun He and Xiaoli Gong and Sirou Zhang and Liejun Wang and Fan Li},
  doi          = {10.1016/j.neucom.2021.01.024},
  journal      = {Neurocomputing},
  pages        = {224-238},
  shortjournal = {Neurocomputing},
  title        = {Efficient attention based deep fusion CNN for smoke detection in fog environment},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-based temporal action co-localization from an
untrimmed video. <em>NEUCOM</em>, <em>434</em>, 211–223. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present an efficient approach for temporal action co-localization (TACL), which means to simultaneously localize all action instances in an untrimmed video. Compared with the conventional instance-by-instance action localization, TACL can exploit the contextual and temporal relationships among action instances to reduce the localization ambiguities. Motivated by the strong relational modeling capability of graph neural networks , we propose a Graph-based Temporal Action Co-Localization (G-TACL) method. By considering each action proposal as a node, G-TACL effectively aggregates contextual and temporal features from related action proposals to jointly recognize and localize all action instances in a single shot. Moreover, we introduce a novel multi-level consistency evaluator to measure the relatedness between any two action proposals. This is achieved by considering their high-level contextual similarities, low-level temporal coincidences and feature correlations. We exploit the Gated Recurrent Units (GRUs) to iteratively update the features of each node, which are then used to regress the temporal boundaries of action proposals and finally achieve action co-localization. Experimental results on three datasets, i.e. , THUMOS14, MEXaction2 and ActivityNet v1.3 datasets demonstrate that our G-TACL is superior or comparable to the state-of-the-arts.},
  archive      = {J_NEUCOM},
  author       = {Le Wang and Changbo Zhai and Qilin Zhang and Wei Tang and Nanning Zheng and Gang Hua},
  doi          = {10.1016/j.neucom.2020.12.126},
  journal      = {Neurocomputing},
  pages        = {211-223},
  shortjournal = {Neurocomputing},
  title        = {Graph-based temporal action co-localization from an untrimmed video},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Bicomplex-valued twin-hyperbolic hopfield neural networks.
<em>NEUCOM</em>, <em>434</em>, 203–210. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex-valued multistate Hopfield neural network (CMHNN) is a multistate model of a Hopfield neural network and has been applied as a multistate neural associative memory . CMHNNs require many resources for weight parameters. To reduce the number of weight parameters, twin-multistate activation functions were introduced. A quaternion-valued twin-multistate Hopfield neural network (QTMHNN) is the first model to employ a twin-multistate activation function. A bicomplex-valued twin-multistate Hopfield neural network (BTMHNN) was also introduced. Weak noise tolerance is a disadvantage of QTMHNNs and BTMHNNs. To improve the noise tolerance, a BTMHNN can be modified to a bicomplex-valued twin–hyperbolic Hopfield neural network (BTHHNN). A BTMHNN is defined by the decomposition of a bicomplex number to a pair of complex numbers, whereas a BTHHNN is defined by decomposition of a bicomplex number to a pair of hyperbolic numbers. Computer simulations have improved the noise tolerance of BTHHNNs.},
  archive      = {J_NEUCOM},
  author       = {Masaki Kobayashi},
  doi          = {10.1016/j.neucom.2020.12.109},
  journal      = {Neurocomputing},
  pages        = {203-210},
  shortjournal = {Neurocomputing},
  title        = {Bicomplex-valued twin-hyperbolic hopfield neural networks},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Demonstration actor critic. <em>NEUCOM</em>, <em>434</em>,
194–202. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the problem of Reinforcement Learning from Demonstrations (RLfD), where the agent has access to not only reward signals from the environment, but also some available expert demonstrations. Recent works absorb ingredients from imitation learning and utilize demonstration data as reward reshaping. Despite their success, these methods update policy over these states seen in the demonstration data, in the same way as other states in the state space, overlooking the validity of direct supervision signals on these states. To address this issue, we propose a novel RLfD objective function with a new shaping reward, by optimizing which can directly leverage the supervision signal on these demonstrated states. We propose a general framework for policy optimization of the proposed objective, with convergence guarantees under the classic tabular setting. Based on that, we further make some approximations based on deep neural networks , and then introduce a new practical algorithm, called Demonstration Actor Critic (DAC) in large continuous domains. Extensive experiments on a range of popular benchmark sparse-reward tasks show that our method can lead to significant performance gains over several strong and off-the-shelf baselines.},
  archive      = {J_NEUCOM},
  author       = {Guoqing Liu and Li Zhao and Pushi Zhang and Jiang Bian and Tao Qin and Nenghai Yu and Tie-Yan Liu},
  doi          = {10.1016/j.neucom.2020.12.116},
  journal      = {Neurocomputing},
  pages        = {194-202},
  shortjournal = {Neurocomputing},
  title        = {Demonstration actor critic},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised or unsupervised learning? Investigating the role
of pattern recognition assumptions in the success of binary predictive
prescriptions. <em>NEUCOM</em>, <em>434</em>, 165–193. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning (ML) employs classification algorithms such as artificial neural networks to make automated decisions. While the proposed solutions have made significant contributions toward improving decision-making efficiency, their effectiveness to serve our multifaceted and complex society has recently come under question. This paper attempts to theorize an answer to why ML lacks effectiveness by studying the assumptions that are made to facilitate efficient pattern recognition. Specifically, this study recognizes five assumptions and investigates their influence on the effectiveness of decision-making for three well-known case studies. The results suggest including the assumptions needed for metric-optimizing supervised learning can only be justifiable and lead to decision-making effectiveness for cases in which a fair and equitable definition of success can be formulated as an objective function. In contrast, the results show using unsupervised learning or non-metric-optimizing supervised learning leads to a more reasonable balance of effectiveness and efficiency when the formulation of a fair and equitable definition of success is not possible. Moreover, the results demonstrate that the current ML approaches that employ supervised learning can improve their efficacy by rethinking the assumptions made at the stage of pattern recognition.},
  archive      = {J_NEUCOM},
  author       = {Ruholla Jafari-Marandi},
  doi          = {10.1016/j.neucom.2020.12.063},
  journal      = {Neurocomputing},
  pages        = {165-193},
  shortjournal = {Neurocomputing},
  title        = {Supervised or unsupervised learning? investigating the role of pattern recognition assumptions in the success of binary predictive prescriptions},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Identity-constrained noise modeling with metric learning
for face anti-spoofing. <em>NEUCOM</em>, <em>434</em>, 149–164. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face presentation attack detection (PAD) has become a key component in face-based application systems. Typical face de-spoofing algorithms estimate the noise pattern of a spoof image to detect presentation attacks. These algorithms are device-independent and have good generalization ability . However, the noise modeling is not very effective because there is no ground truth (GT) with identity information for training the noise modeling network . To address this issue, we propose using the bona fide image of the corresponding subject in the training set as a type of GT called appr-GT with the identity information of the spoof image. A metric learning module is proposed to constrain the generated bona fide images from the spoof images so that they are near the appr-GT and far from the input images. This can reduce the influence of imaging environment differences between the appr-GT and GT of a spoof image. Extensive experimental results demonstrate that the reconstructed bona fide image and noise with high discriminative quality can be clearly separated from a spoof image. The proposed algorithm achieves competitive performance.},
  archive      = {J_NEUCOM},
  author       = {Yaowen Xu and Lifang Wu and Meng Jian and Wei-Shi Zheng and Yukun Ma and Zhuming Wang},
  doi          = {10.1016/j.neucom.2020.12.095},
  journal      = {Neurocomputing},
  pages        = {149-164},
  shortjournal = {Neurocomputing},
  title        = {Identity-constrained noise modeling with metric learning for face anti-spoofing},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NeuroSense: Short-term emotion recognition and understanding
based on spiking neural network modelling of spatio-temporal EEG
patterns. <em>NEUCOM</em>, <em>434</em>, 137–148. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition still poses a challenge lying at the core of the rapidly growing area of affective computing and is crucial for establishing a successful human–computer interaction. Identification and understanding of emotions are achieved through various measures, such as subjective self-reports, face-tracking, voice analysis, gaze-tracking, as well as the analysis of autonomic and central neurophysiological measurements. Current approaches to emotion recognition based on electroencephalography (EEG) mostly rely on various handcrafted features extracted over relatively long time windows of EEG during participants exposure to appropriate affective stimuli. In this paper, we present a short-term emotion recognition framework based on spiking neural network (SNN) modelling of spatio-temporal EEG patterns. Our method relies on EEG signal segmentation based on detection of short-term changes in facial landmarks, and as such includes no computation of handcrafted EEG features. Differences between participants’ EEG properties are taken into account via subject-dependent spike encoding in the formulated subject-independent emotion recognition task. We test our methods on the publicly available DEAP and MAHNOB-HCI databases due to the availability of both EEG and frontal face video data. Through an exhaustive hyperparameter optimisation strategy, we show that the proposed SNN-based representation of EEG spiking patterns provides valuable information for short- term emotion recognition. The obtained accuracies are 78.97\% and 79.39\% in arousal classification, and 67.76\% and 72.12\% in valence classification, on the DEAP and MAHNOB-HCI datasets, respectively. Furthermore, through the application of a brain-inspired SNN model, this study provides novel insight and helps in the understanding of the neural mechanisms involved in emotional processing in the context of audiovisual stimuli, such as affective videos. The presented results encourage the use of the proposed EEG processing methodology as a complement to existing features and methods commonly used for EEG-based emotion recognition, especially for short-term arousal recognition.},
  archive      = {J_NEUCOM},
  author       = {Clarence Tan and Marko Šarlija and Nikola Kasabov},
  doi          = {10.1016/j.neucom.2020.12.098},
  journal      = {Neurocomputing},
  pages        = {137-148},
  shortjournal = {Neurocomputing},
  title        = {NeuroSense: Short-term emotion recognition and understanding based on spiking neural network modelling of spatio-temporal EEG patterns},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft sensor based on eXtreme gradient boosting and
bidirectional converted gates long short-term memory self-attention
network. <em>NEUCOM</em>, <em>434</em>, 126–136. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a new soft sensor that combines eXtreme Gradient Boosting (Xgboost) decision trees and a bidirectional, converted gate long short-term memory (BiCG-LSTMs) self-attention (SEA) mechanism network is proposed. Xgboost is first utilized to select relevant input variables according to their importance. It then acts as an encoder to weigh the selected input variables based on their importance scores. The encoded input variables are normalized and then sent to the bidirectional converted gates LSTM (BiCG-LSTMs) to extract dynamic information hidden in the process data. The BiCG-LSTMs is designed to avoid multiple gates function, a characteristic of traditional LSTM units in bidirectional LSTM that consumes additional calculation time. Next, a regularization method by smoothing dynamic features based on self-attention weights is utilized to denoise and alleviate the overfitting of the regression once new features are added. In addition, self-attention takes into account the internal dependence of input variables regardless how far the distance between input variables. Finally, the effectiveness of the proposed Xgboost-BiCG-LSTM-SEA soft sensor framework is demonstrated by an application to the prediction of melt intrinsic viscosity of the polyester polymerization process.},
  archive      = {J_NEUCOM},
  author       = {Xiuli Zhu and Kuangrong Hao and Ruimin Xie and Biao Huang},
  doi          = {10.1016/j.neucom.2020.12.028},
  journal      = {Neurocomputing},
  pages        = {126-136},
  shortjournal = {Neurocomputing},
  title        = {Soft sensor based on eXtreme gradient boosting and bidirectional converted gates long short-term memory self-attention network},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Vibration fault diagnosis based on stochastic configuration
neural networks. <em>NEUCOM</em>, <em>434</em>, 98–125. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a study on fault diagnosis in vibration signal processing. Rather than building a fault model through frequently used approaches to handling the series data such as LSTM or hidden Markov field, this work processes the vibration signal by moving the time window to generate multiple samples and then transfers fault diagnosis into a traditional supervised learning problem. Stochastic configuration neural network (SCN) which gives a clear condition of guaranteeing high performance of randomly weighted neural networks is selected as the model for training and testing. Different classifiers are used to conduct a performance comparison, and their comparative advantages including why SCN particularly suitable for this type of learning and more discussions about the experimental results are shown. The paper provides a new scheme to processing vibration signal for fault diagnosis and some useful guidelines of building an appropriate model with high performance.},
  archive      = {J_NEUCOM},
  author       = {Jingna Liu and Rujiang Hao and Tianlun Zhang and XiZhao Wang},
  doi          = {10.1016/j.neucom.2020.12.080},
  journal      = {Neurocomputing},
  pages        = {98-125},
  shortjournal = {Neurocomputing},
  title        = {Vibration fault diagnosis based on stochastic configuration neural networks},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opinion separation in leader–follower coopetitive social
networks. <em>NEUCOM</em>, <em>434</em>, 90–97. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Opinion dynamics on social networks describe the time evolution of the opinions within the leader–follower coopetitive (cooperative-competitive) interactions. When does opinion formation result in opinion separation with the single leader? This paper investigates a continuous-time model of such opinion separation problems with signed networks. Our model combines the positive/negative weighting rule of Degroot to describe the impact of their neighbors and the reflected leader–follower mechanism of Jadbabaie to describe trust/distrust relationships from followers to the leader. When the leader is stationary, we establish a necessary and sufficient condition, which ensure all opinions finally converge to bipartite consensus as long as the network topology is structurally balanced. When the leader is dynamic, a sufficient condition is proposed to ensure the opinions of followers move with the opinion of leader or the opposite value in the same velocity. Subsequently, we introduce Laplacian schemes, the framework of signed networks and matrix analysis to develop the stability of networked systems. Numerical simulation examples are given to illustrate the performance of the proposed leader–follower coopetitive systems.},
  archive      = {J_NEUCOM},
  author       = {Haili Liang and Fanli Yuan and Zhao Zhou and Housheng Su},
  doi          = {10.1016/j.neucom.2020.12.079},
  journal      = {Neurocomputing},
  pages        = {90-97},
  shortjournal = {Neurocomputing},
  title        = {Opinion separation in leader–follower coopetitive social networks},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prediction of drug-target interactions based on multi-layer
network representation learning. <em>NEUCOM</em>, <em>434</em>, 80–89.
(<a href="https://doi.org/10.1016/j.neucom.2020.12.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prediction of drug-target interactions aims to identify potential targets for the treatment of new and rare diseases. The large number of unknown combinations between drugs and targets makes them difficult to verify with experimental methods. There are computational methods that predict drug-target interactions; however, these methods are insufficient in integrating multiple types of data and managing network noise, which affects the accuracy of the prediction. We report a multilayer network representation learning method for drug-target interaction prediction that can integrate useful information from different networks, reduce noise in the multilayer network, and learn the feature vectors of drugs and targets. The feature vectors of the drug and the target are put into the drug-target space to predict the potential drug-target interactions. This work improves the method of multilayer network representation learning and prediction accuracy by increasing the parameter regularization constraints.},
  archive      = {J_NEUCOM},
  author       = {Yifan Shang and Lin Gao and Quan Zou and Liang Yu},
  doi          = {10.1016/j.neucom.2020.12.068},
  journal      = {Neurocomputing},
  pages        = {80-89},
  shortjournal = {Neurocomputing},
  title        = {Prediction of drug-target interactions based on multi-layer network representation learning},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A denoising carbon price forecasting method based on the
integration of kernel independent component analysis and least squares
support vector regression. <em>NEUCOM</em>, <em>434</em>, 67–79. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the past few decades, accurately forecasting carbon price has become a significant research field and aroused concerns from both scholars and policymakers, which contributes the Organized Exchange to scientifically and rationally allocate a fixed-quantity of carbon emissions among prospective polluters. The conventional forecasting approaches, however, suffer from the poor prediction accuracy due to the nonlinearity and non-stationarity of the carbon price series. Meanwhile, monitoring and filtering the inherent noise in carbon price series, which are the main steps in the forecasting model, are perceived as the challenging tasks to work in. To address these obstacles, a denoising-hybridization procedure, which is a hybrid model of extreme-point symmetric mode decomposition (ESMD), kernel independent component analysis (KICA) and least squares support vector regression (LSSVR), is put forward for predicting the carbon price. Firstly, the carbon price is decomposed into several intrinsic mode functions (IMFs) via the ESMD method. Secondly, independent components (ICs), which reflect the internal formation mechanism, are separated out from the IMFs via KICA method. Further, the IC comprised of the noise is eliminated according to the results of noise monitoring. Finally, the LSSVR method is applied to the remaining ICs for achieving the forecasting results of carbon price, wherein the particle swarm optimization (PSO) algorithm is employed to synchronously optimize the hyper parameters in LSSVR. The empirical results on four carbon futures prices from European Union Emissions Trade System (EU ETS) demonstrate the effectiveness and robustness of the promoted denoising-hybridization procedure. Comparative experiments illustrate the superiority of the proposed method from the perspective of statistical performance criteria.},
  archive      = {J_NEUCOM},
  author       = {Jianwei E and Jimin Ye and Lulu He and Haihong Jin},
  doi          = {10.1016/j.neucom.2020.12.086},
  journal      = {Neurocomputing},
  pages        = {67-79},
  shortjournal = {Neurocomputing},
  title        = {A denoising carbon price forecasting method based on the integration of kernel independent component analysis and least squares support vector regression},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Visual relationship detection with recurrent attention and
negative sampling. <em>NEUCOM</em>, <em>434</em>, 55–66. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting relationships between objects is important for the complete understanding of visual scenes, which will be helpful for applications such as visual question answering, image search, and robotic interactions. It is however a challenging task due to the high variation of object appearance and interactions, and the often incomplete annotations. In this paper, we propose a fast method for visual relationship detection based on recurrent attention and negative sampling. First, to learn non-visual features, we use the Word2Vec model to extract semantic embedding features of object categories, and use binary masks to represent spatial location features. And we integrate the recurrent attention mechanism into the detection pipeline , enabling the network to focus on several specific parts of an image when scoring predicates for a given object pair. Then we use an undersampling technique to alleviate the influence of imbalanced annotations, particularly for zero-shot detection. The proposed method is simple but experiments prove that it is efficient and achieves state-of-the-art results on the benchmark VRD and Visual Genome (VG) datasets in most cases.},
  archive      = {J_NEUCOM},
  author       = {Lei Wang and Peizhen Lin and Jun Cheng and Feng Liu and Xiaoliang Ma and Jianqin Yin},
  doi          = {10.1016/j.neucom.2020.12.099},
  journal      = {Neurocomputing},
  pages        = {55-66},
  shortjournal = {Neurocomputing},
  title        = {Visual relationship detection with recurrent attention and negative sampling},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). RNN-transducer based chinese sign language recognition.
<em>NEUCOM</em>, <em>434</em>, 45–54. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign Language Recognition (SLR) targets on interpreting sign language video into natural language, which largely facilitates mutual communication between the deaf and general public. SLR is usually formulated as a sequence alignment problem, wherein connectionist temporal classification (CTC) plays an important role in building effective alignment between video sequence and sentence-level labels. However, CTC-based SLR methods tend to fail if the output label sequence is longer than the input video sequence. Besides, they ignore the interdependencies between output predictions. This paper addresses these two issues and proposes a new RNN-Transducer based SLR framework, i.e., visual hierarchy to lexical sequence alignment network (H2SNet). In the framework, we design a visual hierarchy transcription network to capture the spatial appearance and temporal motion cues of sign video on multiple levels. Meanwhile, we utilize a lexical prediction network to extract effective contextual information from output predictions. RNN-Transducer is applied to learn the mapping between sequential video features and sentence-level labels. Extensive experiments validate the effectiveness and superiority of our approach over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Liqing Gao and Haibo Li and Zhijian Liu and Zekang Liu and Liang Wan and Wei Feng},
  doi          = {10.1016/j.neucom.2020.12.006},
  journal      = {Neurocomputing},
  pages        = {45-54},
  shortjournal = {Neurocomputing},
  title        = {RNN-transducer based chinese sign language recognition},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Facial expression recognition with polynomial legendre and
partial connection MLP. <em>NEUCOM</em>, <em>434</em>, 33–44. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a partially connected Multilayer Perceptron (PCM) neural network as an optimal new MLP with a supervised algorithm and three hidden layers to detect face emotions. Compared with the traditional MLP, the proposed network shows improvements in speed, accuracy, and computational time. Six emotions have been considered in this study, namely anger, surprise, fear, sadness, normal, and happiness. The image dataset with the fixed background is used to test and train the network. Canny edge detection algorithm is employed to separate regions of the face including eyes, mouth, and eyebrows from the background. A binary image is extracted to represent the areas of eye, mouth, and eyebrow. The feature extraction is carried out by Legendre coefficients of Legendre polynomials which are selected for the best accuracy. Results show that the partial network is faster and has a lower computational complexity compared with the full connection network. It also has a faster convergence with higher accuracy.},
  archive      = {J_NEUCOM},
  author       = {Gholamreza Karimi and Mehdi Heidarian},
  doi          = {10.1016/j.neucom.2020.12.070},
  journal      = {Neurocomputing},
  pages        = {33-44},
  shortjournal = {Neurocomputing},
  title        = {Facial expression recognition with polynomial legendre and partial connection MLP},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Densely connected convolutional extreme learning machine for
hyperspectral image classification. <em>NEUCOM</em>, <em>434</em>,
21–32. (<a href="https://doi.org/10.1016/j.neucom.2020.12.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extreme Learning Machine (ELM) has gained lots of research interests due to its universal approximation capability and fast learning speed. Although several prior works have focused on developing deep ELM, it is still an open problem to design effective deep ELM. Stacking random layers will result in overfitting and accumulation of random errors. To address this issue, this paper presents a simple yet effective deep ELM called Densely Connected Convolutional ELM (DC 2 ELM) for hyperspectral image spectral-spatial classification. First, we introduce dense connection into ELM to make full use of intermediate feature maps produced by randomized convolutional layers , which is beneficial to reduce the random error. Secondly, stacked ELM auto-encoders are employed to generate reduced representation, leading to a deeper architecture. The proposed approach consists of fewer trainable parameters than traditional convolutional neural networks and can easily be trained without any iterative parameters tuning, making it easier to implement and apply in practice. We compare the proposed approach with many prior arts over three real hyperspectral images, showing that the proposed approach can achieve superior performance using limited training data and with a reduced risk of overfitting the training data.},
  archive      = {J_NEUCOM},
  author       = {Yaoming Cai and Zijia Zhang and Qin Yan and Dongfang Zhang and Mst Jainab Banu},
  doi          = {10.1016/j.neucom.2020.12.064},
  journal      = {Neurocomputing},
  pages        = {21-32},
  shortjournal = {Neurocomputing},
  title        = {Densely connected convolutional extreme learning machine for hyperspectral image classification},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TreeLSTM with tag-aware hypernetwork for sentence
representation. <em>NEUCOM</em>, <em>434</em>, 11–20. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tree-structured neural networks , such as TreeLSTM and its variants, have proven effective for learning semantic representations of sentences, which are useful for a variety of tasks in natural language processing such as text categorisation, text semantic matching and machine translation. These neural network models take as inputs parse trees of sentences, which are generated by a language parser. However, most existing tree-structured neural network models lack the ability of distinguishing different syntactic compositions, thus the expressive power of these models is limited. Moreover, the syntactic knowledge provided by Part-of-Speech tags in a parse tree has not been fully utilised in existing tree-structured neural network models. It is expected that such syntactic knowledge should help distinguish syntactic compositions, so should result in better semantic representation. This paper proposes a novel neural network model, TagHyperTreeLSTM, which contains two components, a tag-aware hypernetwork and a sentence encoder. The tag-aware hypernetwork, which accepts tags as inputs, generates the parameters of the sentence encoder dynamically in order to distinguish different syntactic compositions. The sentence encoder, which accepts words as inputs, generates the final sentence representation. Experimental results show that the proposed model achieves superior or competitive performance in text classification and text semantic matching based on six benchmark datasets when compared against previous tree-structured models.},
  archive      = {J_NEUCOM},
  author       = {Chunlin Xu and Hui Wang and Shengli Wu and Zhiwei Lin},
  doi          = {10.1016/j.neucom.2020.12.074},
  journal      = {Neurocomputing},
  pages        = {11-20},
  shortjournal = {Neurocomputing},
  title        = {TreeLSTM with tag-aware hypernetwork for sentence representation},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast vertex-based graph convolutional neural network and its
application to brain images. <em>NEUCOM</em>, <em>434</em>, 1–10. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a vertex-based graph convolutional neural network (vertex-CNN) for analyzing structured data on graphs. We represent graphs using semi-regular triangulated meshes in which each vertex has 6 connected neighbors. We generalize classical CNN defined on equi-spaced grids to that defined on semi-regular triangulated meshes by introducing main building blocks of the CNN, including convolution, down-sampling, and pooling, on a vertex domain. By exploiting the regularity of semi-regular meshes in terms of vertex connections, the proposed vertex-CNN keeps the inherent properties of classical CNN in a Euclidean space, such as shift-invariance and down-sampling at a rate of 2, 4, etc. We employ brain images from Alzheimer’s Disease Neuroimaging Initiative (ADNI) (n = 6767) and extract cortical features (e.g., cortical thickness , surface area, curvature, Jacobian, sulcal depth, and volume) for the classification of healthy controls (CON), patients with mild cognitive impairment (MCI) and Alzheimer’s disease (AD). Based on cortical thickness , we show that the proposed vertex-CNN is near 3 times faster and performs significantly better in the classification performance of CON, MCI, and AD than an existing graph CNN defined on the graph spectral domain given in Defferrard (2016). Moreover, we examine the robustness of a multi-channel implementation of vertex-CNN on 6 cortical measures for the MCI and AD classification. Finally, we show a promising finding of the prediction accuracy from MCI to AD as a function of years before the onset of AD. Our experiments demonstrate the fast computation and promising classification performance of the vertex-CNN.},
  archive      = {J_NEUCOM},
  author       = {Chaoqiang Liu and Hui Ji and Anqi Qiu},
  doi          = {10.1016/j.neucom.2020.12.097},
  journal      = {Neurocomputing},
  pages        = {1-10},
  shortjournal = {Neurocomputing},
  title        = {Fast vertex-based graph convolutional neural network and its application to brain images},
  volume       = {434},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Anisotropic angle distribution learning for head pose
estimation and attention understanding in human-computer interaction.
<em>NEUCOM</em>, <em>433</em>, 310–322. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Head pose estimation is an important way to understand human attention in the human-computer interaction. In this paper, we propose a novel anisotropic angle distribution learning (AADL) network for head pose estimation task. Firstly, two key findings are revealed as following: 1) Head pose image variations are different at the yaw and pitch directions with the same pose angle increasing on a fixed central pose; 2) With the fixed angle interval increasing, the image variations increase firstly and then decrease in yaw angle direction. Then, the maximum a posterior technology is employed to construct the head pose estimation network, which includes three parts, such as convolutional layer , covariance pooling layer and output layer. In the output layer, the labels are constructed as the anisotropic angle distributions on the basis of two key findings. And the anisotropic angle distributions are fitted by the 2D Gaussian-like distributions (groundtruth labels). Furthermore, the Kullback-Leibler divergence is selected to measure the predication label and the groundtruth one. The features of head pose images are perceived at the AADL-based convolutional neural network in an end-to-end manner. Experimental results demonstrate that the developed AADL-based labels have several advantages, such as robustness for head pose image missing, insensitivity for the motion blur. Moreover, the proposed method has achieved good performance compared to several state-of-the-art methods on the Pointing’04 and CAS_PEAL_R1 databases.},
  archive      = {J_NEUCOM},
  author       = {Hai Liu and Hanwen Nie and Zhaoli Zhang and You-Fu Li},
  doi          = {10.1016/j.neucom.2020.09.068},
  journal      = {Neurocomputing},
  pages        = {310-322},
  shortjournal = {Neurocomputing},
  title        = {Anisotropic angle distribution learning for head pose estimation and attention understanding in human-computer interaction},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A divide-and-conquer approach to neural natural language
generation from structured data. <em>NEUCOM</em>, <em>433</em>, 300–309.
(<a href="https://doi.org/10.1016/j.neucom.2020.12.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Current approaches that generate text from linked data for complex real-world domains can face problems including rich and sparse vocabularies as well as learning from examples of long varied sequences. In this article, we propose a novel divide-and-conquer approach that automatically induces a hierarchy of “generation spaces” from a dataset of semantic concepts and texts. Generation spaces are based on a notion of similarity of partial knowledge graphs that represent the domain and feed into a hierarchy of sequence-to-sequence or memory-to-sequence learners for concept-to-text generation. An advantage of our approach is that learning models are exposed to the most relevant examples during training which can avoid bias towards majority samples. We evaluate our approach on two common benchmark datasets and compare our hierarchical approach against a flat learning setup. We also conduct a comparison between sequence-to-sequence and memory-to-sequence learning models. Experiments show that our hierarchical approach overcomes issues of data sparsity and learns robust lexico-syntactic patterns, consistently outperforming flat baselines and previous work by up to 30\%. We also find that while memory-to-sequence models can outperform sequence-to-sequence models in some cases, the latter are generally more stable in their performance and represent a safer overall choice.},
  archive      = {J_NEUCOM},
  author       = {Nina Dethlefs and Annika Schoene and Heriberto Cuayáhuitl},
  doi          = {10.1016/j.neucom.2020.12.083},
  journal      = {Neurocomputing},
  pages        = {300-309},
  shortjournal = {Neurocomputing},
  title        = {A divide-and-conquer approach to neural natural language generation from structured data},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Realize your surroundings: Exploiting context information
for small object detection. <em>NEUCOM</em>, <em>433</em>, 287–299. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small object detection is a highly challenging problem due to the limited resolution and information of small objects. Current state-of-the-art detectors only utilize the appearance feature to locate and classify objects. However, such detectors are prone to failure when detecting small objects, especially in the case of heavy appearance changes and background distractors, in which the appearance feature alone is not sufficient for robust detection. Exploiting context information in the surrounding scene can be highly beneficial in such cases. In this paper, we propose a novel detector, the Internal-External Network (IENet), which uses both the appearance and context information of the object for robust detection. In the proposed approach, small object detection is improved from feature extraction, proposal location, and classification. Specifically, three customized modules are designed, including the Bidirectional Feature Fusion Module (Bi-FFM), Context Reasoning Module (CRM), and Context Feature Augmentation Module (CFAM). Bi-FFM is designed to capture the internal feature of objects by transferring the semantic feature of deeper-level layers to lower-level layers and the detailed feature of lower-level layers to deeper-level layers in neural networks . The proposed approach not only utilizes the hierarchy of convolutional features but also improves its prediction via context relationships. CRM is designed to improve the quality of region proposals by context reasoning that uses easily detected objects to help understand hard ones. Furthermore, CFAM is designed to learn pair-wise relations between region proposals produced by CRM, and such relations are used to produce global feature information associated with the region proposals for accurate classification. Extensive experiments are conducted on the challenging COCO and WIDER FACE datasets to demonstrate the effectiveness of the proposed approach. Experimental results show that the detection performance of small objects is greatly improved over state-of-the-art detectors.},
  archive      = {J_NEUCOM},
  author       = {Jiaxu Leng and Yihui Ren and Wen Jiang and Xiaoding Sun and Ye Wang},
  doi          = {10.1016/j.neucom.2020.12.093},
  journal      = {Neurocomputing},
  pages        = {287-299},
  shortjournal = {Neurocomputing},
  title        = {Realize your surroundings: Exploiting context information for small object detection},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrimination and correction of abnormal data for condition
monitoring of drilling process. <em>NEUCOM</em>, <em>433</em>, 275–286.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the drilling process, the data quality influences the reliability of condition monitoring results. However, the actual drilling data may encounter various kinds of abnormal data, and different kinds of them need to be handled differently. The abnormal data caused by external factors such as sensor failure, storage errors, etc., should be corrected, while the abnormal data caused by drilling accidents should be protected. Therefore, not only the anomaly detection is needed, but the causes of anomalies should be further discriminated. This paper proposes a method for discrimination and correction of abnormal data in the drilling process. First, the local outlier factor anomaly detection algorithm is developed to detect all kinds of the abnormal data. Then, the dynamic time warping and fuzzy c-means are combined for the discrimination of causes of anomalies. Finally, the discriminated abnormal data caused by external factors are corrected with the k nearest neighbor interpolation. Simulation results involving actual data illustrate that the causes of anomalies can be discriminated effectively, and the monitoring results of monitoring models based on neural network improve after using the proposed method, which verify the necessity of anomaly discrimination.},
  archive      = {J_NEUCOM},
  author       = {Aoxue Yang and Min Wu and Jie Hu and Luefeng Chen and Chengda Lu and Weihua Cao},
  doi          = {10.1016/j.neucom.2020.11.064},
  journal      = {Neurocomputing},
  pages        = {275-286},
  shortjournal = {Neurocomputing},
  title        = {Discrimination and correction of abnormal data for condition monitoring of drilling process},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Containment control of general linear multi-agent systems by
event-triggered control mechanisms. <em>NEUCOM</em>, <em>433</em>,
263–274. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper discusses the containment control (CC) problem of general linear multi-agent systems (MAS)s by means of two kinds of distributed event-triggered mechanisms. Two types of event-triggered control protocols, namely, the state feedback control law and the dynamic output feedback control protocol, are designed for each follower. Under the proposed control protocols and triggering mechanisms, the containment control problem can be solved by proving that the containment error converges to zero based on the assumption and algorithms. At last, we verify the rationality of the theoretical results. Through two numerical simulation, we can see that the trajectory of each follower converges to the convex hull formed by all leaders. In addition, in order to verify the advantages of the obtained results, we give a simulation example and compare the methods designed in this paper with the methods in other literature.},
  archive      = {J_NEUCOM},
  author       = {juan zhang and Huaguang Zhang and Yuliang Cai and Weihua Li},
  doi          = {10.1016/j.neucom.2020.11.008},
  journal      = {Neurocomputing},
  pages        = {263-274},
  shortjournal = {Neurocomputing},
  title        = {Containment control of general linear multi-agent systems by event-triggered control mechanisms},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Harvest shopping advice: Neural question generation from
multiple information sources in e-commerce. <em>NEUCOM</em>,
<em>433</em>, 252–262. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of recent efforts in Question Generation (QG) has amazed scientists from academia and industry. In this paper, we explore to harvest shopping advice through a novel QG engine for e-commerce platforms. Unlike traditional QG methods conditioned on factual data, generating purchase-oriented questions depends on open-ended product properties and customer reviews. Besides, these questions should follow not only natural expressions but also user-interested aspects simultaneously. For this challenging task, an innovative generative adversarial net-based QG model is proposed – a generator featuring multi-source attention mechanism is employed to yield questions from multiple information sources; a discriminator featuring quality control is applied to fine-tune generated questions in terms of both language performance and aspect compatibility. We conduct extensive experiments on a new dataset comprised of Question-Review-Aspect-Property (Q-RAP) tuples from a real e-commerce site. Our experimental results demonstrate that the proposed approach achieves a significant superiority over seven state-of-the-art QG solutions. Meanwhile, this study indicates that customer reviews play a critical role in generating purchase-oriented questions, which confirms the validity of previous practices using buyer feedback to address natural language generation in e-commerce.},
  archive      = {J_NEUCOM},
  author       = {Yongzhen Wang and Kaisong Song and Lidong Bing and Xiaozhong Liu},
  doi          = {10.1016/j.neucom.2020.12.013},
  journal      = {Neurocomputing},
  pages        = {252-262},
  shortjournal = {Neurocomputing},
  title        = {Harvest shopping advice: Neural question generation from multiple information sources in E-commerce},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-stage fault diagnosis framework for rolling bearing
based on OHF elman AdaBoost-bagging algorithm. <em>NEUCOM</em>,
<em>433</em>, 237–251. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing complexity of industrial equipment, it is urgent to provide timely diagnosis and accurate evaluation to avoid failure. For rolling bearings, it is important to achieve the multi-stage (incipient, intermediate, late) fault diagnosis under random noise. Different from traditional methods, an Output Hidden Feedback Elman Adaptive Boosting-Bootstrap Aggregating algorithm is proposed under a comprehensive diagnosis framework. First, the original signal is decomposed, denoised and reconstructed by Ensemble Empirical Mode Decomposition . Then, OHF Elman neural network is designed by increasing a feedback from the output layer to the hidden layer based on Elman neural network . This improves the memory function for dynamic data of rolling bearings. Furthermore, for achieving diagnostic accuracy and algorithm stability, OHF Elman AdaBoost-Bagging algorithm is developed as a strong learner through the dual integration of AdaBoost algorithm and Bagging algorithm. Experimental results show that the proposed algorithm not only has a good diagnostic performance on different stages of rolling bearing faults, but also achieves higher generalization ability and stability. This multi-stage fault diagnosis framework provides a novel tool and an effective solution for rolling bearing fault diagnosis.},
  archive      = {J_NEUCOM},
  author       = {Tangbin Xia and Pengcheng Zhuo and Lei Xiao and Shichang Du and Dong Wang and Lifeng Xi},
  doi          = {10.1016/j.neucom.2020.10.003},
  journal      = {Neurocomputing},
  pages        = {237-251},
  shortjournal = {Neurocomputing},
  title        = {Multi-stage fault diagnosis framework for rolling bearing based on OHF elman AdaBoost-bagging algorithm},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). End-to-end attack on text-based CAPTCHAs based on
cycle-consistent generative adversarial network. <em>NEUCOM</em>,
<em>433</em>, 223–236. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a widely deployed security scheme, text-based completely automated public Turing tests to tell computers and humans apart (CAPTCHAs) have become increasingly unable to resist machine learning-based attacks. So far, many researchers have conducted studies on approaches for attacking text-based CAPTCHAs deployed by different companies, such as Microsoft, Amazon, and Apple, and achieved specific results. However, most of these attacks have shortcomings, such as the poor portability of attack methods, which require a series of data preprocessing steps and rely on large amounts of labeled CAPTCHAs. In this study, we propose an efficient and simple end-to-end attack method based on cycle-consistent generative adversarial networks (Cycle-GANs). Compared to previous studies, our approach significantly reduces the cost of data labeling. Additionally, this method has high portability. It can attack ordinary text-based CAPTCHA schemes only by modifying a few configuration parameters , which makes the attack easier to execute. First, we train CAPTCHA synthesizers based on the Cycle-GAN to generate some fake samples. Basic recognizers based on a convolutional recurrent neural network are trained using the fake data. Subsequently, an active transfer learning method is employed to optimize the basic recognizer utilizing tiny amounts of labeled real-world CAPTCHA samples. Our approach efficiently cracked the CAPTCHA schemes deployed by 10 popular websites, indicating that our attack method may be universal. Additionally, we analyzed the current most popular anti-recognition mechanisms. The results show that the combination of more anti-recognition mechanisms can improve the security of CAPTCHAs. However, the improvement is limited. Conversely, generating more complex CAPTCHAs may cost more resources and reduce the usability of CAPTCHAs.},
  archive      = {J_NEUCOM},
  author       = {Chunhui Li and Xingshu Chen and Haizhou Wang and Peiming Wang and Yu Zhang and Wenxian Wang},
  doi          = {10.1016/j.neucom.2020.11.057},
  journal      = {Neurocomputing},
  pages        = {223-236},
  shortjournal = {Neurocomputing},
  title        = {End-to-end attack on text-based CAPTCHAs based on cycle-consistent generative adversarial network},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predicting short-term next-active-object through visual
attention and hand position. <em>NEUCOM</em>, <em>433</em>, 212–222. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human intention prediction is of great significance in many applications, such as human-robot interaction, intelligent rehabilitation robots. This paper studies the problem of short-term next-active-object prediction in egocentric images. The short-term next-active-object refers to the object that a human is going to interact with in the short-term future, which is an embodiment of human intention. Most current methods usually use object-centered cues, such as the deviation of object appearance change and the unique shape of the egocentric object trajectory, to predict the next-active-object. In this paper, inspired by the fact that human intention is also revealed by human-centered cues, we propose a deep neural network model that integrates the cues from visual attention and hand positions to predict the next-active-object. Firstly, the probability maps of visual attention and hand positions are constructed, and then the probability distribution of next-active-object is generated. We experimentally compare our method with several baseline methods using two datasets and confirm its effectiveness. In addition, ablation experiments are conducted, and crucial points concerning the next-active-object are discussed.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Jiang and Zhixiong Nan and Hui Chen and Shitao Chen and Nanning Zheng},
  doi          = {10.1016/j.neucom.2020.12.069},
  journal      = {Neurocomputing},
  pages        = {212-222},
  shortjournal = {Neurocomputing},
  title        = {Predicting short-term next-active-object through visual attention and hand position},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised deep clustering via adaptive GMM modeling and
optimization. <em>NEUCOM</em>, <em>433</em>, 199–211. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Supervised deep learning techniques have achieved success in many computer vision tasks . However, most deep learning methods are data hungry and rely on a large number of labeled data in the training process. This work introduces an unsupervised deep clustering framework and studies the discovery of knowledge from a set of unlabeled data samples. Specifically, we propose a new network structure for both representation learning and GMM (Gaussian Mixture Model)-based representation modeling. In the training process of our proposed network, we not only adjust the Gaussian components to better model the distribution of representations, but also adjust the data representations towards their associating Gaussian centers to provide more adaptive support for the GMM. In this way, we take the data representations as the supervisory signal for the update of the GMM parameters and the GMM as the supervisory signal for the update of the representations, yet keeping the entire deep clustering as unsupervised. Consequently, we train the network based on an objective function with two learning targets. With the first target, we learn a GMM to model the representations properly and make each Gaussian component to be compact as much as possible. With the second target, we improve the inter-cluster distance by adapting the cluster centers to be further away from their neighbors. Thus, the training procedure simultaneously improves the intra-cluster compactness and inter-cluster separability for all the evolved clusters. Experimental results on eight datasets show that the proposed method can improve the clustering performance in comparison with the existing state of the art techniques.},
  archive      = {J_NEUCOM},
  author       = {Jinghua Wang and Jianmin Jiang},
  doi          = {10.1016/j.neucom.2020.12.082},
  journal      = {Neurocomputing},
  pages        = {199-211},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised deep clustering via adaptive GMM modeling and optimization},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semantic-consistent cross-modal hashing for large-scale
image retrieval. <em>NEUCOM</em>, <em>433</em>, 181–198. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With an emphasis on saving storage and computation costs, hashing learning has got considerable success in cross-modal image retrieval . Most pioneer efforts in this direction either consider similarity across modalities or leverage discriminative information of the class labels to learn the common latent representation. However, the learnt representation only contains coherent semantics across modalities but could not be line with class-wise semantic structure. To attack this issue, we propose a semantic-consistent cross-modal hashing (SCCH) to take class semantic structure into consideration. It not only ensures the common representation to be consistent across modalities by directly learning the shared binary codes of samples via rotation transformation, but also restricts the class-wise representation line with the learnt binary codes. In this way, SCCH jointly preserves class semantic structure and avoids large quantization errors caused by the approximation of real values to binary codes. Moreover, we efficiently optimize SCCH via an iterative algorithm . Experiments on three publicly datasets demonstrate the superiority of SCCH against several representative start-of-the-art counterparts in light of performance metrics.},
  archive      = {J_NEUCOM},
  author       = {Xuesong Gu and Guohua Dong and Xiang Zhang and Long Lan and Zhigang Luo},
  doi          = {10.1016/j.neucom.2020.11.007},
  journal      = {Neurocomputing},
  pages        = {181-198},
  shortjournal = {Neurocomputing},
  title        = {Semantic-consistent cross-modal hashing for large-scale image retrieval},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Commonalities-, specificities-, and dependencies-enhanced
multi-task learning network for judicial decision prediction.
<em>NEUCOM</em>, <em>433</em>, 169–180. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {J udicial D ecision P rediction ( JDP ) aims to determine judicial decisions per the fact description of a criminal case. It comprises multiple subtasks, i.e., law article prediction, charge prediction, and term of the penalty prediction. Besides, there exist three properties among the subtasks, i.e., Commonalities , Specificities Commonalities,Specificities , and Dependencies . Nonetheless, existing approaches are usually well-designed for only a specific subtask, or take one of the properties into consideration for multiple subtasks. In this paper, we propose a novel Commonalities-, Specificities- and Dependencies-Enhanced Multi-Task Learning Network, to unify multiple subtasks accompanied by the properties in a framework. Further, while handling the Dependencies , we elaborate a learning module to ensure each subtask to learn contributions from other subtasks to varying degrees, a denoising module to minimize noise interferences among subtasks, and a reinforcing module to guarantee further enhancement for each subtask. Experimental results on two widely used datasets demonstrate that our model significantly and consistently outperforms previous state-of-the-art methods on most evaluation metrics across all subtasks.},
  archive      = {J_NEUCOM},
  author       = {Fanglong Yao and Xian Sun and Hongfeng Yu and Wenkai Zhang and Kun Fu},
  doi          = {10.1016/j.neucom.2020.10.010},
  journal      = {Neurocomputing},
  pages        = {169-180},
  shortjournal = {Neurocomputing},
  title        = {Commonalities-, specificities-, and dependencies-enhanced multi-task learning network for judicial decision prediction},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Can edges help convolution neural networks in emotion
recognition? <em>NEUCOM</em>, <em>433</em>, 162–168. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial emotion recognition has gained importance for its applications in diverse areas. Facial expressions of a subject, when experiencing the same emotion, have wider variations. On the other hand, different subjects experiencing the same emotion may exhibit different facial features . All these make facial emotion recognition challenging. The ability of convolutional neural network (CNN) has been exploited to analyze visual imagery for different applications. It has also been used in developing automatic facial emotion recognition systems. Our objective in this study is to check if an explicit use of edges can help emotion recognition from images using CNN. Edges in an image represent discriminatory information and hence their explicit use is likely to help the training of CNNs and improve emotion recognition. Keeping this in mind we propose a two-tower CNN architecture to classify images into seven basic classes of emotion including the neutral expression. The proposed CNN has an additional tower, called edge-tower, which is simpler in architecture compared to the other tower and it uses edge images as inputs. Our experiments on two benchmark datasets demonstrate that the explicit use of edge information improves the classifier performance.},
  archive      = {J_NEUCOM},
  author       = {Arkaprabha Bhandari and Nikhil R. Pal},
  doi          = {10.1016/j.neucom.2020.12.092},
  journal      = {Neurocomputing},
  pages        = {162-168},
  shortjournal = {Neurocomputing},
  title        = {Can edges help convolution neural networks in emotion recognition?},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Residual error based knowledge distillation.
<em>NEUCOM</em>, <em>433</em>, 154–161. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge distillation (KD) is one of the most popular ways for model compression. The key idea is to transfer the knowledge from a deep teacher model ( T ) to a shallower student ( S ). However, existing methods suffer from performance degradation due to the substantial gap between the learning capacities of S and T . To remedy this problem, this paper proposes Residual error based Knowledge Distillation (RKD), which further distills the knowledge by introducing an assistant model( A ). Specifically, S is trained to mimic the feature maps of T , and A aids this process by learning the residual error between them. In this way, S and A complement with each other to get better knowledge from T . Furthermore, we devise an effective method to derive S and A from a given model without increasing the total computational cost. Extensive experiments show that our approach achieves appealing results on popular classification datasets, CIFAR-100 and ImageNet, surpassing state-of-the-art methods and keep strong robustness to adversarial samples.},
  archive      = {J_NEUCOM},
  author       = {Mengya Gao and Yujun Wang and Liang Wan},
  doi          = {10.1016/j.neucom.2020.10.113},
  journal      = {Neurocomputing},
  pages        = {154-161},
  shortjournal = {Neurocomputing},
  title        = {Residual error based knowledge distillation},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Segment spatial-temporal representation and cooperative
learning of convolution neural networks for multimodal-based action
recognition. <em>NEUCOM</em>, <em>433</em>, 142–153. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multimodal based human action recognition is an attracting increasing topic since the different modalities can provide complementary information. However, it is difficult to improve the recognition performance due to the limitation of the ability to learn spatial-temporal features. In this paper, we propose a novel approach for multimodal human action recognition by learning complementary features from RGB-D sequence. Firstly, a segmented rank pooling method is proposed to compress the entire RGB-D sequence into dynamic images as inputs to the Convolutional Networks (ConvNets) for capturing spatial-temporal information. Secondly, a Segment Cooperative ConvNets (SC-ConvNets) is designed to learn the complementary features from RGB-D modalities. Different from the ConvNets-based approaches that learn multimodal features with multiple separate networks, the proposed SC-ConvNets enhance the recognition performance through joint optimization learning of single ConvNets. Then a single loss function is optimized to narrow the variance between RGB and depth modalities. In order to verify the effectiveness of the proposed method, we evaluate the SC-ConvNets on four public benchmark multimodal datasets, including NTU RGB+D 60, NTU RGB+D 120, SYSU 3D HOI, and PKU-MMD datasets. The proposed method achieves an accuracy of 89.4\% and 91.2\% for cross-subject and cross-view on NTU RGB+D 60, 86.9\% and 87.7\% for cross-subject and cross-setup on NTU RGB+D 120, 92.1\% and 93.2\% for cross-subject and cross-view on PKU-MMD, which are the state-of-the-art, and the accuracy of 84.2\% and 82.9\% for setting-1 and setting-2 on SYSU 3D HOI, which are comparable to the state-of-the-art. The experimental results demonstrate that the proposed segmented rank pooling can represent discriminative spatial-temporal information from the entire RGB and depth sequence, and the proposed SC-ConvNets can enhance recognition performance by learning complementary features from different modalities.},
  archive      = {J_NEUCOM},
  author       = {Ziliang Ren and Qieshi Zhang and Jun Cheng and Fusheng Hao and Xiangyang Gao},
  doi          = {10.1016/j.neucom.2020.12.020},
  journal      = {Neurocomputing},
  pages        = {142-153},
  shortjournal = {Neurocomputing},
  title        = {Segment spatial-temporal representation and cooperative learning of convolution neural networks for multimodal-based action recognition},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fixed-time synchronization-based secure communication
scheme for two-layer hybrid coupled networks. <em>NEUCOM</em>,
<em>433</em>, 131–141. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This literature mainly investigates the fixed-time synchronization-based secure communication issue with two-layer hybrid coupled networks, which consist of multitudinous subnets with different transmittal time-delays. By the application of appropriate cluster strategy, the subnets, in both transmitter and receiver, make up several matched subnet-pairs (encryption/encryption units). The nodes may behave different dynamics in different subnet-pairs but identical ones in the same subnet-pair. Similar to the block encryption method , every matched subnet-pair is merely in charge a portion of information encryption/decryption. Many encryption/encryption units working simultaneously can manifest the intricate characteristics of nodes and increase the encryption/decryption rate. Fixed-time synchronization is applied, which means that the time for information encryption/decryption is computable. Moreover, the chaos message, generated by a chaotic system, is taken as a key array, the key space will be enlarged with node-size at transmitter. With the design of some suitable chattering-free feedback controllers , a simple fixed-time synchronization-based secure communication scheme is given and the effectiveness is proved. This scheme shows not only good performance with regard to the complexity of key arrays and timeliness but also excellent robustness to the effect of time-delays. Both the theoretic analysis and numerical emulations indicate the feasibility and utility of the given scheme.},
  archive      = {J_NEUCOM},
  author       = {Lili Zhou and Fei Tan and Xiaohui Li and Ling Zhou},
  doi          = {10.1016/j.neucom.2020.12.033},
  journal      = {Neurocomputing},
  pages        = {131-141},
  shortjournal = {Neurocomputing},
  title        = {A fixed-time synchronization-based secure communication scheme for two-layer hybrid coupled networks},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-level attentive deep user-item representation learning
for recommendation system. <em>NEUCOM</em>, <em>433</em>, 119–130. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of e-commerce platforms, user reviews have become a vital source of information to address the sparsity problems for enhancing the predictive performance of the recommendation systems (RSs). However, the traditional methods of the RSs used to model user/item latent features based on static vectors in an independent manner without considering the dynamic nature of the user-item interactions which potentially affect the accuracy of the recommendation process. Thus, this paper proposes a RS model that exploits neural attention techniques to learn user/item representations by jointly considering the fine-grained semantic information for the user-item pairs. The proposed model utilizes both review-based and interaction-specific features for the user/item reviews to learn heterogeneous user/item representations. First, a BiLSTM sequence encoder is used to learn the contextual information of words, and a Co-attention network is then designed to jointly capture the most relevant semantic information of reviews for the user-item pair. To better capture user/item latent factors comprehensively, interaction-specific features based on the rating scores are further integrated with the review-specific latent features via a shared hidden layer. Finally, an attentive factorization machine (FM) is then applied on the shared hidden layer of the integrated user/item features for the final prediction. We carry out a series of experiments using real-world datasets and the results demonstrate that our proposed method is better than the baseline approaches in terms of both rating prediction and ranking performance.},
  archive      = {J_NEUCOM},
  author       = {Aminu Da&#39;u and Naomie Salim and Rabiu Idris},
  doi          = {10.1016/j.neucom.2020.12.043},
  journal      = {Neurocomputing},
  pages        = {119-130},
  shortjournal = {Neurocomputing},
  title        = {Multi-level attentive deep user-item representation learning for recommendation system},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). NetKI: A kirchhoff index based statistical graph embedding
in nearly linear time. <em>NEUCOM</em>, <em>433</em>, 108–118. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advancements in learning from graph-structured data have shown promising results on the graph classification task . However, due to their high time complexities, making them scalable on large graphs, with millions of nodes and edges, remains a challenge. In this paper, we propose NetKI, an algorithm to extract sparse representation from a given graph with n nodes and m edges in O ( m ∊ - 2 log 4 n ) O(m∊-2log4n) time. Our approach follows the notion of Kirchhoff index that encodes the structure of the graph by estimating effective resistance - relying on this approach yields nearly linear time graph representation method that allows scalability on sufficiently large graphs. Through extensive experiments, we show that NetKI provides improved results in terms of running time on large networks and the classification accuracy is within range 2\% from the state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Anwar Said and Saeed-Ul Hassan and Waseem Abbas and Mudassir Shabbir},
  doi          = {10.1016/j.neucom.2020.12.075},
  journal      = {Neurocomputing},
  pages        = {108-118},
  shortjournal = {Neurocomputing},
  title        = {NetKI: A kirchhoff index based statistical graph embedding in nearly linear time},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep embedding clustering based on contractive autoencoder.
<em>NEUCOM</em>, <em>433</em>, 96–107. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Clustering large and high-dimensional document data has got a great interest. However, current clustering algorithms lack efficient representation learning . Implementing deep learning techniques in document clustering can strengthen the learning processes. In this work, we simultaneously disentangle the problem of learned representation by preserving important information from the initial data while pushing the original samples and their augmentations together in one hand. Furthermore, we handle the cluster locality preservation issue by pushing neighboring data points together. To that end, we first introduce Contractive Autoencoders . Then we propose a deep embedding clustering framework based on contractive autoencoder (DECCA) to learn document representations. Furthermore, to grasp relevant document or word features, we append the Frobenius norm as penalty term to the conventional autoencoder framework, which helps the autoencoder to perform better. In this way, the contractive autoencoders apprehend the local manifold structure of the input data and compete with the representations learned by existing methods. Finally, we confirm the supremacy of our proposed algorithm over the state-of-the-art results on six real-world images and text datasets.},
  archive      = {J_NEUCOM},
  author       = {Bassoma Diallo and Jie Hu and Tianrui Li and Ghufran Ahmad Khan and Xinyan Liang and Yimiao Zhao},
  doi          = {10.1016/j.neucom.2020.12.094},
  journal      = {Neurocomputing},
  pages        = {96-107},
  shortjournal = {Neurocomputing},
  title        = {Deep embedding clustering based on contractive autoencoder},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A lowlight image enhancement method learning from both
paired and unpaired data by adversarial training. <em>NEUCOM</em>,
<em>433</em>, 83–95. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has been widely used in the field of lowlight image enhancement. In this paper, we propose a novel deep-learning-based lowlight image enhancement method, which could learn from both paired and unpaired data, and perform end-to-end contrast enhancement and noise reduction simultaneously. Concretely, we first employ a multi-level content loss on paired synthesized data for training enhancer to recover detail better. Then, we propose a GAN-based domain adaptation mechanism, which applies an adversarial training strategy and a novel gamma-correction-based self-supervised content loss on abundant unpaired real data, for training the enhancer to perform better on real lowlight images. Furthermore, a Patch-GAN-based noise reduction mechanism is proposed to adversarially train the enhancer to better reduce noise in real lowlight images. Finally, we improve the enhancer by introduce attention mechanism and global feature to original U-net, make it more suitable for lowlight image enhancement task. We conduct experiments on several common datasets and the results show that our method outperforms other state-of-the-arts under a variety of image quality assessment metrics. And when applied as pre-processing module, our method can improve the classification accuracy on lowlight dataset by 1.7\%, outperforming other methods too.},
  archive      = {J_NEUCOM},
  author       = {Qun Yang and Yubin Wu and Danhua Cao and Mandi Luo and Taoran Wei},
  doi          = {10.1016/j.neucom.2020.12.057},
  journal      = {Neurocomputing},
  pages        = {83-95},
  shortjournal = {Neurocomputing},
  title        = {A lowlight image enhancement method learning from both paired and unpaired data by adversarial training},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Observer-based adaptive event-triggered tracking control
for nonlinear MIMO systems based on neural networks technique.
<em>NEUCOM</em>, <em>433</em>, 71–82. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the issue of adaptive neural networks event-triggered control for nonstrict-feedback nonlinear multi-input-multi-output(MIMO) systems containing unmeasured states is investigated. All unmeasured states are approximated by using neural networks observer. Meanwhile, the neural networks are used to estimate the unknown continuous function at each step of recursion. Then, an observer-based adaptive neural networks event-triggered tracking control strategy is proposed based on backstepping technique. The designed controller enables the outputs of the system to track the target trajectory within a small bounded error range, and all signals in the closed-loop system are bounded.},
  archive      = {J_NEUCOM},
  author       = {Sanxia Wang and Jianwei Xia and Wei Sun and Hao Shen and Huasheng Zhang},
  doi          = {10.1016/j.neucom.2020.12.050},
  journal      = {Neurocomputing},
  pages        = {71-82},
  shortjournal = {Neurocomputing},
  title        = {Observer-based adaptive event-triggered tracking control for nonlinear MIMO systems based on neural networks technique},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TTFNeXt for real-time object detection. <em>NEUCOM</em>,
<em>433</em>, 59–70. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern object detectors rarely achieve short training time, fast inference speed, and high accuracy at the same time. To strike a balance among them, we propose single-scale TTFNet and multi-scale TTFNeXt. In this work, we use light-head, single-stage, and anchor-free designs, which enable fast inference speed. Then, we focus on reducing training time and improving accuracy. We notice that encoding more training samples from annotated boxes plays a similar role as increasing batch size, which helps enlarge the learning rate and accelerate the training process. To this end, we introduce a dense regression approach based on Gaussian kernels . We also show through experiments that deformable convolutions in our single-scale detector are not sufficient to handle the scale-variation problem. Therefore, we extend the single-scale detector to a multi-scale version. The multi-scale design will yield redundant detections from different pyramid levels, thus we introduce our cross-level NMS algorithm to efficiently eliminate redundant results. Experiments on MS COCO show that our TTFNet and TTFNeXt have great advantages in balancing training time, inference speed, and accuracy. They can reduce training time by more than three times compared to previous real-time detectors under similar detection accuracy and faster inference speed. When training 120 epochs, our TTFNeXt is able to achieve 33.7 AP/99 FPS and 41.8 AP/40 FPS with single GTX 1080Ti.},
  archive      = {J_NEUCOM},
  author       = {Zili Liu and Tu Zheng and Guodong Xu and Zheng Yang and Haifeng Liu and Deng Cai},
  doi          = {10.1016/j.neucom.2020.12.055},
  journal      = {Neurocomputing},
  pages        = {59-70},
  shortjournal = {Neurocomputing},
  title        = {TTFNeXt for real-time object detection},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time lag synchronization of inertial neural networks
with mixed infinite time-varying delays and state-dependent switching.
<em>NEUCOM</em>, <em>433</em>, 50–58. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we design a new control scheme to investigate the finite-time lag synchronization (FTLS) of inertial neural networks (INNs) with mixed infinite time-varying delays and state-dependent switching. Several novel and easily verified conditions are gained guaranteeing the FTLS of INNs via the finite-time stability theory and nonsmooth analysis. Moreover, it is worth emphasizing that here we directly analyze INNs without using variable substitution, which is different from the reduced-order approach used in correspondingly previous works. At last, a numerical example and an application in image encryption are given to verify the correctness and practicability of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Changqing Long and Guodong Zhang and Zhigang Zeng and Junhao Hu},
  doi          = {10.1016/j.neucom.2020.12.059},
  journal      = {Neurocomputing},
  pages        = {50-58},
  shortjournal = {Neurocomputing},
  title        = {Finite-time lag synchronization of inertial neural networks with mixed infinite time-varying delays and state-dependent switching},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intermediate fused network with multiple timescales for
anomaly detection. <em>NEUCOM</em>, <em>433</em>, 37–49. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an intermediate fused network with multiple timescales to predict future video segments for video anomaly detection . Video prediction technique for anomaly detection requires to derive an anomaly-distinguishable future frame from normal distributions provided by training data. Then by measuring the difference between generated frames and reference frames, the model can tell which frames represent anomalous events in certain video sequence. In order to synthesize more distinctive future frames, we propose to boost image predictions by integrating several input video segments in multiple timescales. Specifically, the diversity in timescales means the diversity in sampling frequencies of video frames. In addition, we introduce a novel intermediate fusion strategy by concatenating feature maps from intermediate layers to better preserve different characteristics from different timescales. We evaluate the proposed method on some public video surveillance datasets and achieve competitive results with respect to the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Wenqian Wang and Faliang Chang and Huadong Mi},
  doi          = {10.1016/j.neucom.2020.12.025},
  journal      = {Neurocomputing},
  pages        = {37-49},
  shortjournal = {Neurocomputing},
  title        = {Intermediate fused network with multiple timescales for anomaly detection},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust adversarial discriminative domain adaptation for
real-world cross-domain visual recognition. <em>NEUCOM</em>,
<em>433</em>, 28–36. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional networks (CNNs) are able to learn robust representations and empower many computer vision tasks such as object recognition. However, when applying CNNs to industrial visual systems, they usually suffer from domain shift that exists between the training data and testing data. Such shift can be caused by different environment, types of cameras and exteriors of objects, leading to degrading performance and hindering the practical applications of CNNs in real-world visual recognition. To tackle this problem, Adversarial domain adaptation (ADA) reduces such shift by min–max optimization. However, current CNNs with ADA are hard to train due to training instability of adversarial network. In this paper, we propose a unified and easy-to-train domain adaptation framework, namely Attention-based Domain-confused Adversarial Domain ADaptation (AD 3 ). Our method leverages both adversarial and statistical domain alignment, allows flexibility for source and target feature extractors and simultaneously performs feature-level and attention-level alignment. The statistical domain alignment promotes and stabilizes the adversarial domain learning, which reduces the manual work of tuning the hyper-parameters. The experimental results validate that our method performs better adaptation and faster convergence for adversarial domain learning than existing state-of-the-art methods on DIGITS, Office-31 and VisDA domain adaptation benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Jianfei Yang and Han Zou and Yuxun Zhou and Lihua Xie},
  doi          = {10.1016/j.neucom.2020.12.046},
  journal      = {Neurocomputing},
  pages        = {28-36},
  shortjournal = {Neurocomputing},
  title        = {Robust adversarial discriminative domain adaptation for real-world cross-domain visual recognition},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Viewpoint transform matching model for person
re-identification. <em>NEUCOM</em>, <em>433</em>, 19–27. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification is a challenging problem that aims at matching persons across multiple non-overlapping cameras. Previous works on person re-identification mainly focus on solving the problems caused by pose variations, backgrounds, and occlusion while ignoring the viewpoint variations. To address the viewpoint problem, we propose a Viewpoint Transform Matching (VTM) model, which reduces the inference of viewpoints by feature-level viewpoint transformation. Overall, we design a framework by using viewpoint specific branches to separately extract the representation of different viewpoints. Specifically, we first select the branch for an input image, according to its viewpoint information. In the branch, we transform the feature to other viewpoints by establishing a mutually transformable connection between the features of different viewpoints. To suppress the interference among viewpoints, we propose a viewpoint transform classifier module to independently train a classifier for each viewpoint. To improve the effectiveness of the transform, we propose a viewpoint transform loss to guarantee the consistency of the original features and the transformed features. Experiments conducted on Market-1501, DukeMTMC-reID and CUHK03 show the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Ruochen Zheng and Changxin Gao and Nong Sang},
  doi          = {10.1016/j.neucom.2020.12.100},
  journal      = {Neurocomputing},
  pages        = {19-27},
  shortjournal = {Neurocomputing},
  title        = {Viewpoint transform matching model for person re-identification},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Triplet online instance matching loss for person
re-identification. <em>NEUCOM</em>, <em>433</em>, 10–18. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mining the shared features of the same identity in different scenes and the unique features of different identities in the same scene are the most significant challenges in the field of person re-identification (ReID). The Online Instance Matching (OIM) loss function and triplet loss function are the main methods for person ReID. Unfortunately, both of them have drawbacks. The OIM loss treats all samples equally and puts no emphasis on hard samples. The triplet loss processes batch construction in a complicated and fussy way and converges slowly. For these problems, we propose a Triplet Online Instance Matching (TOIM) loss function, which emphasizes hard samples and improves the person ReID accuracy effectively. It combines the advantages of the OIM loss and triplet loss and simplifies the batch construction process, which leads to quicker convergence. It can be trained on-line when handling the joint detection and identification task. To validate our loss function, we collect and annotate a large-scale benchmark dataset (UESTC-PR), which contains 499 identities and 60,437 images taken from surveillance cameras. We evaluated our proposed loss function on the Duke, Marker-1501 and UESTC-PR datasets using ResNet-50, and the results show that our proposed loss function outperforms the baseline methods , including Softmax loss, OIM loss and triplet loss.},
  archive      = {J_NEUCOM},
  author       = {Ye Li and Guangqiang Yin and Chunhui Liu and Xiaoyu Yang and Zhiguo Wang},
  doi          = {10.1016/j.neucom.2020.12.018},
  journal      = {Neurocomputing},
  pages        = {10-18},
  shortjournal = {Neurocomputing},
  title        = {Triplet online instance matching loss for person re-identification},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Second-order consensus of multiagent systems with
matrix-weighted network. <em>NEUCOM</em>, <em>433</em>, 1–9. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies second-order consensus problem on the matrix-weighted undirected network , which is a generalization of second-order scalar-weighted network. The matrix coupling can describe the interdependencies of multi-dimensional states among agents. To highlight the influence of matrix coupling, we analyze the double integral model in matrix-weighted multiagent system network. A sufficient and necessary algebraic condition based on coupling strength, matrix theory and Lyapunov stability theory is established to achieve second-order consensus. With aid of the established property, a fairly straightforward algebraic graph condition is obtained, which ensures that the matrix-weighted multiagent system achieves second-order consensus. Moreover, owing to the existence of positive semi-definite connections, the clustering phenomena naturally exists, which shows that matrix coupling plays an important role in the convergence of the matrix-weighted multiagent system network. And an algebraic graph condition for finding all clusters is offered, which can guarantee the desired number of clusters via designing matrix-weights in practical applications. Finally, four simulation examples are given to illustrate the effectiveness of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Suoxia Miao and Housheng Su},
  doi          = {10.1016/j.neucom.2020.12.056},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {Second-order consensus of multiagent systems with matrix-weighted network},
  volume       = {433},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Geometric attentional dynamic graph convolutional neural
networks for point cloud analysis. <em>NEUCOM</em>, <em>432</em>,
300–310. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes geometric attentional dynamic graph convolutional neural networks for point cloud analysis . The core operation is a geometric attentional edge convolution module which extends classic CNN to extract both extrinsic and intrinsic properties of point clouds for a rich representation learning of point features. The relations in geometric space regarding the extrinsic geometric topological prior are modeled as geometric attention and incorporated in the EdgeConv of DGCNN which captures the intrinsic feature likelihood of point clouds. Therefore, the proposed geometric attentional edge convolution is able to learn point cloud representations from both intrinsic and extrinsic properties. To form a hierarchical architecture to capture rich information of point clouds from these two kinds of underlying properties, two graphs are dynamic constructed in the geometric and feature space respectively layer by layer. Extensive experiments on several benchmarks for various point cloud analysis tasks, including shape classification, share retrieval, normal estimation, shape part segmentation, have verified the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yiming Cui and Xin Liu and Hongmin Liu and Jiyong Zhang and Alina Zare and Bin Fan},
  doi          = {10.1016/j.neucom.2020.12.067},
  journal      = {Neurocomputing},
  pages        = {300-310},
  shortjournal = {Neurocomputing},
  title        = {Geometric attentional dynamic graph convolutional neural networks for point cloud analysis},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). One-shot cross-dataset palmprint recognition via adversarial
domain adaptation. <em>NEUCOM</em>, <em>432</em>, 288–299. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based palmprint recognition algorithms have obtained promising performance. However, the previous methods require a large amount of labeled samples, which are difficult to obtain. In this paper, a novel cross-dataset palmprint recognition method is proposed using as low as one labelled sample per subject in the target palmprint dataset based on adversarial domain adaptation. Two different palmprint datasets are adopted as source dataset and target dataset. The training samples from two datasets are grouped into four categories. MobileFaceNets-based deep hashing network (DHN) is introduced to extract discriminative features, which can improve the efficiencies of feature extracting and matching. To align the features in two datasets, a typical adversarial discriminator is augmented to distinguish between the four different categories. With adversarial learning, the target network is becoming adaptive to the unlabeled target palmprint images. Extensive experiments on the benchmarks including constrained and unconstrained palmprint databases demonstrate that our method can outperform the baseline models on cross-dataset palmprint verification and identification.},
  archive      = {J_NEUCOM},
  author       = {Huikai Shao and Dexing Zhong},
  doi          = {10.1016/j.neucom.2020.12.072},
  journal      = {Neurocomputing},
  pages        = {288-299},
  shortjournal = {Neurocomputing},
  title        = {One-shot cross-dataset palmprint recognition via adversarial domain adaptation},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performing multi-target regression via gene expression
programming-based ensemble models. <em>NEUCOM</em>, <em>432</em>,
275–287. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Target Regression problem comprises the prediction of multiple continuous variables given a common set of input features, unlike traditional regression tasks , where just one output target is available. There are two major challenges when addressing this problem, namely the exploration of the inter-target dependencies and the modeling of complex input–output relationships. This work proposes a Symbolic Regression method following the basis of Gene Expression Programming paradigm to solve the multi-target regression problem, and called GEPMTR. It evolves a population of individuals, where each one represents a complete solution to the problem by using a multi-genic chromosome, and encodes a mathematical function for each target variable involving the input attributes. The proposed model can estimate the inter-target dependencies by applying some genetic operators. Furthermore, three ensemble-based methods are developed to better exploit the inter-target and input–output relationships. The effectiveness of the proposals is analyzed through an extensive experimental study on 18 datasets. The codification schema and the process followed to ensure a diverse population in GEPMTR lead to obtain an effective proposal to solve the MTR problem. Furthermore, the EGEPMTR-B ensemble method obtained the best performance across all proposed models, being the best in 8 out of 11 cases, demonstrating that more sophisticated mechanisms were not needed for ensuring that GEPMTR method would properly model the existing inter-target dependencies. Finally, the experimental results also showed that the proposed approach attains competitive results compared to state-of-the-art, showing the possibilities that can bring this research line for effectively solving the MTR problem.},
  archive      = {J_NEUCOM},
  author       = {Jose M. Moyano and Oscar Reyes and Habib M. Fardoun and Sebastián Ventura},
  doi          = {10.1016/j.neucom.2020.12.060},
  journal      = {Neurocomputing},
  pages        = {275-287},
  shortjournal = {Neurocomputing},
  title        = {Performing multi-target regression via gene expression programming-based ensemble models},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Synchronization of neural networks with memristor-resistor
bridge synapses and lévy noise. <em>NEUCOM</em>, <em>432</em>, 262–274.
(<a href="https://doi.org/10.1016/j.neucom.2020.12.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a kind of memristor-resistor bridge synapses are applied to neural networks , which makes the connection weights of networks continuously adjustable. A novel model for this new kind of neural networks is established, in which the memory characteristic of memristors is retained. The state synchronization of the model with the influence of Lévy noise is investigated. By making use of the Itô formula for Lévy process and Lyapunov method, a sufficient condition is obtained for exponentially state synchronization in mean square of the drive and response networks. Moreover, by applying controller to each synapse, the complete synchronization of the drive and response networks is achieved. Finally, numerical examples are carried out to illustrate the feasibility of theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Liangchen Li and Rui Xu and Qintao Gan and Jiazhe Lin},
  doi          = {10.1016/j.neucom.2020.12.041},
  journal      = {Neurocomputing},
  pages        = {262-274},
  shortjournal = {Neurocomputing},
  title        = {Synchronization of neural networks with memristor-resistor bridge synapses and lévy noise},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Wearables-based multi-task gait and activity segmentation
using recurrent neural networks. <em>NEUCOM</em>, <em>432</em>, 250–261.
(<a href="https://doi.org/10.1016/j.neucom.2020.08.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human activity recognition (HAR) and cycle analysis, such as gait analysis , have become an integral part of daily lives from gesture recognition to step counting. As the available data and the possible application areas grow, an efficient solution without the need of handcrafted feature extraction is needed. We propose a multi-task recurrent neural network architecture that uses inertial sensor data to both segment and recognise activities and cycles. The solution is validated using three publicly available datasets consisting of more than 120 subjects and 8 activities, 6 of which are cyclic. Our architecture is smaller than comparable HAR models while being robust to different sensor placements and channels. Our proposed solution outperforms or defines state-of-the-art for HAR and cycle analysis using inertial sensors. We achieve an overall activity F1-score of 92.6\% and a phase detection F1-score of 98.2\%. The gait analysis achieves a mean stride time error of 5.3 ± ± 51.9 ms and swing duration error of 0.0 ± ± 5.9\%. The overall step count error for all activities is −1.5 ± ± 2.8\%. Thus, we provide a method that is not dependent on feature extraction and a model that is sensor and location independent.},
  archive      = {J_NEUCOM},
  author       = {Chrsitine F. Martindale and Vincent Christlein and Philipp Klumpp and Bjoern M. Eskofier},
  doi          = {10.1016/j.neucom.2020.08.079},
  journal      = {Neurocomputing},
  pages        = {250-261},
  shortjournal = {Neurocomputing},
  title        = {Wearables-based multi-task gait and activity segmentation using recurrent neural networks},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Asynchronous finite-time state estimation for
semi-markovian jump neural networks with randomly occurred sensor
nonlinearities. <em>NEUCOM</em>, <em>432</em>, 240–249. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the finite-time state estimation problem for semi-Markovian jump neural networks with sensor nonlinearities under the consideration of leakage delay and time-varying delay. The modes of original system and desired estimator are supposed to be asynchronous. Some sufficient conditions are proposed to guarantee the finite-time boundedness as well as mixed H ∞ H∞ and passive performance of the error system in terms of constructing Lyapunov–Krasovskii functionals. By utilizing affine Bessel-Legendre inequalities, a less conservative result can be achieved. By virtue of linear matrices inequalities approach, the asynchronous state estimator gains are obtained. Two numerical examples are provided to demonstrate the less conservativeness and effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Yao Wang and Shengyuan Xu and Yongmin Li and Yuming Chu and Zhengqiang Zhang},
  doi          = {10.1016/j.neucom.2020.12.027},
  journal      = {Neurocomputing},
  pages        = {240-249},
  shortjournal = {Neurocomputing},
  title        = {Asynchronous finite-time state estimation for semi-markovian jump neural networks with randomly occurred sensor nonlinearities},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Binary classification of floor vibrations for human activity
detection based on dynamic mode decomposition. <em>NEUCOM</em>,
<em>432</em>, 227–239. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing small amplitude of floor vibrations is a new promising means for identifying the types of human activities, e.g., walking around and accidental falls. In this paper, we consider the binary classification problem of floor vibrations for the applications like fall detection. For practical use, there are two main issues of the problem. First, the prediction of the classifier should be fast. Second, the training set is sometimes small and the diversity of negative samples brings extra challenges when the training samples are insufficient. The state-of-the-art methods for time series classification, such as HIVE-COTE and ResNet , are computationally intensive or susceptible to the size of the training set. Therefore, we propose a new feature extraction method based on dynamic mode decomposition (DMD) and high-frequency characteristics, whose time complexity is linear with the size of training set and quadratic with the length of time series. The method is evaluated on the dataset of floor vibrations proposed by Madarshahian et al. (2016). The results show higher accuracy compared to the ResNet classifier and time series forests, especially when the negative training samples are deficient in type.},
  archive      = {J_NEUCOM},
  author       = {Shichao Zhou and Guang Lin and Qinfang Qian and Chao Xu},
  doi          = {10.1016/j.neucom.2020.12.066},
  journal      = {Neurocomputing},
  pages        = {227-239},
  shortjournal = {Neurocomputing},
  title        = {Binary classification of floor vibrations for human activity detection based on dynamic mode decomposition},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep convolutional neural networks for data delivery in
vehicular networks. <em>NEUCOM</em>, <em>432</em>, 216–226. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular networks , most content delivery schemes only utilize vehicle cooperation or powerful infrastructure to satisfy data requests. How to fully utilize vehicle-to-vehicle and vehicle-to-infrastructure communications to improve data acquisition still requires further analysis. In this paper, the content delivery problem is formulated as a maximum flow of a directed network, which implies the encounters and the requests. Despite of a high delivery ratio, the proposed Content delivery scheme using mAximum Flow (CAF) is infeasible in large-scale real-time applications due to high computational complexity . To solve this problem, we transform the GPS trajectory data into two-dimensional coverage grid maps which indicate the communication opportunities between vehicles and infrastructures in CAF. The map set, which consists of coverage grid maps in a storage cycle, and the number of satisfied requests obtained from CAF compose the training set that can be trained by the deep convolutional neural networks . This solution combining CAF with deep neural networks is called CAF-Net. In the experiments, we evaluate the performances of four popular architectures of deep convolutional neural networks when outputting the targets. The results show that ResNet 50 has the smallest error and the computation time of a delivery ratio is only 82.84 ms, which is a lot shorter than 4531.53 s using CAF. The results also demonstrate the feasibility of applying the deep learning framework to vehicular networks .},
  archive      = {J_NEUCOM},
  author       = {Hejun Jiang and Xiaolan Tang and Kai Jin and Wenlong Chen and Juhua Pu},
  doi          = {10.1016/j.neucom.2020.12.024},
  journal      = {Neurocomputing},
  pages        = {216-226},
  shortjournal = {Neurocomputing},
  title        = {Deep convolutional neural networks for data delivery in vehicular networks},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning multi-granularity features from multi-granularity
regions for person re-identification. <em>NEUCOM</em>, <em>432</em>,
206–215. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Part-based methods for person re-identification have been widely studied. In existing part-based methods, although multiple parts are explored, only coarse-grained features of these parts are utilized. Thus, too much fine-grained information is discarded, which limits their ability to extract detailed discriminative features . To tackle this problem, we propose a novel person re-identification network to learn discriminative features across multiple granularities from body regions which are also multi-grained. Specifically, we detect multi-granularity body regions at different stages of a backbone network , and multi-granularity features are learned from body regions with corresponding granularities . To overcome the severe mismatching problem of fine-grained regions and to learn discriminative features, the detection of multi-granularity body regions and the learning of multi-granularity features are jointly optimized. This joint optimization pushes the learned features concentrating on body regions. Moreover, with the body regions well located, the multi-granularity features can be well aligned. Extensive experiments on four popular datasets show that our method is the state-of-the-art in recent years.},
  archive      = {J_NEUCOM},
  author       = {Kaiwen Yang and Jiwei Yang and Xinmei Tian},
  doi          = {10.1016/j.neucom.2020.12.016},
  journal      = {Neurocomputing},
  pages        = {206-215},
  shortjournal = {Neurocomputing},
  title        = {Learning multi-granularity features from multi-granularity regions for person re-identification},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fully integer-based quantization for mobile convolutional
neural network inference. <em>NEUCOM</em>, <em>432</em>, 194–205. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deploying deep convolutional neural networks on mobile devices is challenging because of the conflict between their heavy computational overhead and the hardware’s restricted computing capacity. Network quantization is typically used to alleviate this problem. However, we found that a “datatype mismatch” issue in existing low bitwidth quantization approaches can generate severe instruction redundancy, dramatically reducing their running efficiency on mobile devices . We therefore propose a novel quantization approach which ensures that only integer-based arithmetic is needed during the inference stage of the quantized model. To this end, we improved the quantization function to compel the quantized value to follow a standard integer format. Then we presented to simultaneously quantize the batch normalization parameters by a logarithm-like method. By doing so, the quantized model can keep the advantage of low bitwidth representation, while preventing the occurrence of “datatype mismatch” issue and corresponding instruction redundancy. Comprehensive experiments show that our method can achieve comparable prediction accuracy to other state-of-the-art methods while reducing the run-time latency by a large margin. Our fully integer-based quantized Resnet-18 has 4-bit weights, 4-bit activations and only a 0.7\% top-1 and 0.4\% top-5 accuracy drop on the ImageNet dataset. The assembly language implementation of a series of building blockscan reach a maximum of 4.33 × × the speed of the original full-precision version on an ARMv8 CPU.},
  archive      = {J_NEUCOM},
  author       = {Peng Peng and Mingyu You and Weisheng Xu and Jiaxin Li},
  doi          = {10.1016/j.neucom.2020.12.035},
  journal      = {Neurocomputing},
  pages        = {194-205},
  shortjournal = {Neurocomputing},
  title        = {Fully integer-based quantization for mobile convolutional neural network inference},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-global bipartite consensus tracking of singular
multi-agent systems with input saturation. <em>NEUCOM</em>,
<em>432</em>, 183–193. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of bipartite consensus tracking for a class of linear singular multi-agent systems under a signed graph topology , where the control input of each agent is subject to saturation. By exploiting a parametric algebraic Riccati equation (ARE)-based low-gain feedback approach, a static state feedback control protocol and a dynamic observer-based output feedback control protocol are developed utilizing local information. It is shown that under the presented protocols, semi-global bipartite consensus tracking can be achieved if the underlying signed communication graph is structurally balanced and contains a spanning tree rooted at the leader. A numerical example is finally given to illustrate the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Zhen-Hua Zhu and Zhi-Hong Guan and Bin Hu and Ding-Xue Zhang and Xin-Ming Cheng and Tao Li},
  doi          = {10.1016/j.neucom.2020.12.049},
  journal      = {Neurocomputing},
  pages        = {183-193},
  shortjournal = {Neurocomputing},
  title        = {Semi-global bipartite consensus tracking of singular multi-agent systems with input saturation},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A competitive mechanism integrated multi-objective whale
optimization algorithm with differential evolution. <em>NEUCOM</em>,
<em>432</em>, 170–182. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a competitive mechanism integrated whale optimization algorithm (CMWOA) is proposed to deal with multi-objective optimization problems. By introducing the novel competitive mechanism, a better leader can be generated for guiding the update of whale population, which benefits the convergence of the algorithm. It should also be highlighted that in the competitive mechanism, an improved calculation of crowding distance is adopted which substitutes traditional addition operation with multiplication operation, providing a more accurate depiction of population density. In addition, differential evolution (DE) is concatenated to diversify the population, and the key parameters of DE have been assigned different adjusting strategies to further enhance the overall performance. Proposed CMWOA is evaluated comprehensively on a series of benchmark functions with different shapes of true Pareto front. Results demonstrate that proposed CMWOA outperforms other three methods in most cases regarding several performance indicators. Particularly, influences of model parameters have also been discussed in detail. At last, proposed CMWOA is successfully applied to three real world problems , which further verifies the practicality of proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Nianyin Zeng and Dandan Song and Han Li and Yancheng You and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2020.12.065},
  journal      = {Neurocomputing},
  pages        = {170-182},
  shortjournal = {Neurocomputing},
  title        = {A competitive mechanism integrated multi-objective whale optimization algorithm with differential evolution},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). LBAN-IL: A novel method of high discriminative
representation for facial expression recognition. <em>NEUCOM</em>,
<em>432</em>, 159–169. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing facial expression recognition (FER) works have achieved significant progress on constrained datasets. However, these methods only consider the sample distribution and achieve limited performance on unconstrained datasets. Facial expressions in the wild are influenced by various factors, e.g. illumination and partial occlusion, providing great challenge for model design and putting forward the higher requirement for feature discrimination. In this paper, we propose a novel LBAN-IL for FER in the wild, including local binary attention network (LBAN) and islets loss (IL). LBAN is based on two operations, local binary standard layer and encoder-decoder module. The former is derived from local binary convolution, so as to prevent excessive sparseness of feature maps and reduce the number of learnable parameters. The purpose of the latter is to generate attention-aware features and accurately discover local changes in the face. The proposed IL aims to enhance the discrimination of expression features by increasing the amplitude of vectors. Experimental results on RAF-DB, SFEW 2.0, FER-2013 and ExpW datasets validate the effectiveness of LBAN-IL and perform over some state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Hangyu Li and Nannan Wang and Yi Yu and Xi Yang and Xinbo Gao},
  doi          = {10.1016/j.neucom.2020.12.076},
  journal      = {Neurocomputing},
  pages        = {159-169},
  shortjournal = {Neurocomputing},
  title        = {LBAN-IL: A novel method of high discriminative representation for facial expression recognition},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extended variational inference for gamma mixture model in
positive vectors modeling. <em>NEUCOM</em>, <em>432</em>, 145–158. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian estimation of finite Gamma mixture model (GaMM) has attracted considerable attention recently due to its capability of modeling positive data. With conventional variational inference (VI) frameworks, we cannot derive an analytically tractable solution for the variational posterior, since the expectation of the joint distribution of all the random variables cannot be estimated in a closed form. Therefore, numerical techniques are commonly utilized to simulate the posterior distribution . However, the optimization process of these methods can be prohibitively slow for practical applications. In order to obtain closed-form solutions, some lower-bound approximations are then introduced into the evidence lower bound (ELBO), following the recently proposed extended variational inference (EVI) framework. The problem in numerical simulation can be overcome. In this paper, we address the Bayesian estimation of the finite Gamma mixture model (GaMM) under the EVI framework in a flexible way. Moreover, the optimal mixture component number can be automatically determined based on the observed data and the over-fitting problem related to the conventional expectation–maximization (EM) is overcome. We demonstrate the excellent performance of the proposed method with synthesized data and real data evaluations. In the real data evaluation, we compare the proposed method on object detection and image categorization tasks with referred methods and find statistically significant improvement on accuracies and runtime.},
  archive      = {J_NEUCOM},
  author       = {Yuping Lai and Huirui Cao and Lijuan Luo and Yongmei Zhang and Fukun Bi and Xiaolin Gui and Yuan Ping},
  doi          = {10.1016/j.neucom.2020.12.042},
  journal      = {Neurocomputing},
  pages        = {145-158},
  shortjournal = {Neurocomputing},
  title        = {Extended variational inference for gamma mixture model in positive vectors modeling},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Adaptive fuzzy control of switched nonlinear systems with
uncertain dead-zone: A mode-dependent fuzzy dead-zone model.
<em>NEUCOM</em>, <em>432</em>, 133–144. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an adaptive fuzzy control scheme is addressed for switched nonlinear systems with uncertain dead-zone, unknown nonlinearities and immeasurable states. A novel proposed mode-dependent fuzzy dead-zone model (MFDM) can not only describe the uncertain dead-zone, but also overcome the common fuzzy dead-zone model (CFDM) problems caused by disconnected parameters and conservativeness. The unknown functions are approximated by fuzzy logic systems. To estimate the immeasurable states, a switched fuzzy state observer is constructed. By using multiple Lyapunov function and defuzzifying for MFDM, a new mode-dependent fuzzy controller is proposed to assure the boundedness of the closed-loop system and the desired tracking performance. The feasibility of the presented control technique is proved by simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Yanxian Chen and Zhi Liu and C.L.Philip Chen and Yun Zhang},
  doi          = {10.1016/j.neucom.2020.12.044},
  journal      = {Neurocomputing},
  pages        = {133-144},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fuzzy control of switched nonlinear systems with uncertain dead-zone: A mode-dependent fuzzy dead-zone model},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Meta weight learning via model-agnostic meta-learning.
<em>NEUCOM</em>, <em>432</em>, 124–132. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While meta learning approaches have achieved remarkable success, obtaining a stable and unbiased meta -learner remains a significant challenge, since the initial model of a meta -learner could be too biased towards existing tasks to adapt to new tasks. In order to avoid a biased meta -learner and improve its generalizability , this paper proposes a generic meta learning method that aims to learn an unbiased meta -learner towards a variety of tasks before its initial model is adapted to unseen tasks. Specifically, this paper presents a meta weight learning method for minimizing the inequality of performance across different training tasks. An end-to-end training approach is introduced for the proposed algorithm that allows for effectively learning weight and initializing the network model. Alternatively, a variety of measurement methods of weight is also designed to test the effectiveness of different weight learning methods on the improvement of model-agnostic meta -learning algorithm. The simulation results show that the proposed meta weight learning method not only outperforms state-of-the-art meta learning algorithms, but also is superior to other manually designed measurement methods of weight on discrete and continuous control problems.},
  archive      = {J_NEUCOM},
  author       = {Zhixiong Xu and Xiliang Chen and Wei Tang and Jun Lai and Lei Cao},
  doi          = {10.1016/j.neucom.2020.08.034},
  journal      = {Neurocomputing},
  pages        = {124-132},
  shortjournal = {Neurocomputing},
  title        = {Meta weight learning via model-agnostic meta-learning},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hypercomplex-valued recurrent correlation neural networks.
<em>NEUCOM</em>, <em>432</em>, 111–123. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent correlation neural networks (RCNNs), introduced by Chiueh and Goodman as an improved version of the bipolar correlation-based Hopfield neural network, can be used to implement high-capacity associative memories . In this paper, we extend the bipolar RCNNs for processing hypercomplex-valued data. Precisely, we present the mathematical background for a broad class of hypercomplex-valued RCNNs. Then, we address the stability of the new hypercomplex-valued RCNNs using synchronous and asynchronous update modes. Examples with bipolar, complex, hyperbolic, quaternion, and octonion-valued RCNNs are given to illustrate the theoretical results. Finally, computational experiments confirm the potential application of hypercomplex-valued RCNNs as associative memories designed for the storage and recall of gray-scale images.},
  archive      = {J_NEUCOM},
  author       = {Marcos Eduardo Valle and Rodolfo Anibal Lobo},
  doi          = {10.1016/j.neucom.2020.12.034},
  journal      = {Neurocomputing},
  pages        = {111-123},
  shortjournal = {Neurocomputing},
  title        = {Hypercomplex-valued recurrent correlation neural networks},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MAPD: An improved multi-attribute pedestrian detection in a
crowd. <em>NEUCOM</em>, <em>432</em>, 101–110. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, CNN (convolutional neural networks) based pedestrian detection has made significant progress, but pedestrian detection in a crowd is still a challenge. Pedestrians are close to each other in a crowd, which is difficult for discriminating individuals. To address this issue, we propose an improved Multi-attribute pedestrian detection (MAPD) method, which coptimize person intra-class compactness and inter-class discrepancy. The contributions are fourfold: (1) We analyze the effect of positive setting on the detector and adopt a better positive settings strategy to mitigate extreme class imbalance problems . (2) Inspired by Person Reid, we employ the triplet loss function to learn the advanced id feature of pedestrians. (3) We propose a novel Piecewise NMS algorithm to reduce false positive of small objects. (4) We propose a novel multi-attribute NMS algorithm based on Piecewise NMS algorithm and id information, which can adaptively distinguish predicted boxes of different pedestrians and improve the detector performance. Finally, we evaluate the MAPD detector on two benchmark datasets, including CityPersons and CrowdHuman. Results show that our approach outperforms state-of-the-art methods with a big margin.},
  archive      = {J_NEUCOM},
  author       = {Yang Wang and Chong Han and Guangle Yao and Wanlin Zhou},
  doi          = {10.1016/j.neucom.2020.12.005},
  journal      = {Neurocomputing},
  pages        = {101-110},
  shortjournal = {Neurocomputing},
  title        = {MAPD: An improved multi-attribute pedestrian detection in a crowd},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3-d relation network for visual relation recognition in
videos. <em>NEUCOM</em>, <em>432</em>, 91–100. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video visual relation recognition aims at mining the dynamic relation instances between objects in the form of 〈 subject , predicate , object 〉 〈subject,predicate,object〉 , such as “person1-towards-person2” and “person-ride-bicycle”. Existing solutions treat the problem as several independent sub-tasks, i.e., image object detection, video object tracking and trajectory-based relation prediction. We argue that such separation results in the lack of information flow between different sub-models, which creates redundant representation while each sub-task cannot share a common set of task-specific features. Toward this end, we connect these three sub-tasks in an end-to-end manner by proposing the 3-D relation proposal that serves as a bridge for relation feature learning . Specifically, we put forward a novel deep neural network , named 3DRN, to fuse the spatio-temporal visual characteristics, object label features, and spatial interactive features for learning the relation instances with multi-modal cues. In addition, a three-staged training strategy is also provided to facilitate large-scale parameter optimization. We conduct extensive experiments on two public datasets with different emphasis to demonstrate the effectiveness of the proposed end-to-end feature learning method for visual relation recognition in videos. Furthermore, we verify the potential of our approach by tackling the video relation detection task.},
  archive      = {J_NEUCOM},
  author       = {Qianwen Cao and Heyan Huang and Xindi Shang and Boran Wang and Tat-Seng Chua},
  doi          = {10.1016/j.neucom.2020.12.029},
  journal      = {Neurocomputing},
  pages        = {91-100},
  shortjournal = {Neurocomputing},
  title        = {3-D relation network for visual relation recognition in videos},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel fuzzy ARTMAP with area of influence.
<em>NEUCOM</em>, <em>432</em>, 80–90. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fuzzy ARTMAP (FAM) is a neural network model based on the adaptive resonance theory (ART). Its main advantage relies on its capability to successfully deal with the stability-plasticity dilemma. Even though FAM models have been used in many applications with remarkable performance, such model suffers from a well-known problem, named category proliferation, which results in the creation of a large number of categories in the training step. In that case, the FAM model may present lower generalization capability for unseen data. In this work, we aim to handle the category proliferation problem by proposing a new model that modifies the vigilance criterion and the weight update rule to pursue the generation of a sparse set of categories. Our model named FAM with Area of Influence (FAM-AI) is compared to the original FAM and some proposed variants. We perform several computational experiments and verify that, in general, the proposed FAM-AI achieves higher accuracy with a lower number of categories.},
  archive      = {J_NEUCOM},
  author       = {Alan L.S. Matias and Ajalmar R. Rocha Neto and César Lincoln C. Mattos and João Paulo P. Gomes},
  doi          = {10.1016/j.neucom.2020.11.053},
  journal      = {Neurocomputing},
  pages        = {80-90},
  shortjournal = {Neurocomputing},
  title        = {A novel fuzzy ARTMAP with area of influence},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Correlation between situational awareness and EEG signals.
<em>NEUCOM</em>, <em>432</em>, 70–79. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important aspect in safety–critical domains is Situational Awareness (SA) where operators consolidate data into an understanding of the situation that needs to be updated dynamically as the situation changes over time. Among existing measures of SA, only physiological measures can assess the cognitive processes associated with SA in real-time. Some studies showed promise in detecting cognitive states associated with SA in complex tasks using brain signals (e.g. electroencephalogram/EEG). In this paper, an analytical methodology is proposed to identify EEG signatures associated with SA on various regions of the brain. A new data set from 32 participants completing the SA test in the PEBL is collected using a 32-channel dry-EEG headset. The proposed method is tested on the new data set and a correlation is identified between the frequency bands of β β ( 12 - 30 Hz 12-30Hz ) and γ γ ( 30 - 45 Hz 30-45Hz ) and SA. Also, activation of neurons in the left and right hemisphere of the parietal and temporal lobe is observed. These regions are responsible for the visuo-spatial ability and memory and reasoning tasks. Among the presented results, the highest achieved accuracy on test data is 67\% 67\% .},
  archive      = {J_NEUCOM},
  author       = {Jan Luca Kästle and Bani Anvari and Jakub Krol and Helge A Wurdemann},
  doi          = {10.1016/j.neucom.2020.12.026},
  journal      = {Neurocomputing},
  pages        = {70-79},
  shortjournal = {Neurocomputing},
  title        = {Correlation between situational awareness and EEG signals},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-filtering image dehazing with self-supporting module.
<em>NEUCOM</em>, <em>432</em>, 57–69. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a pre-processing step of computer vision applications , single image dehazing remains challenging due to existing inefficiencies in the restoration of content and details. In this paper, the self-supporting dehazing network (SSDN) is proposed to overcome these two problems. For the restoration of image content, the self-filtering block is introduced to remove redundant features, hence improving the representation abilities of learned features. For the recovery of image details, a novel self-supporting module is proposed as a crucial component of the proposed SSDN. With this module, the complementary information among support images that are transformed from multi-level features is explored. By incorporating such information, the self-supporting module can learn more intrinsic image characteristics and generate fine-detail images. Experimental results demonstrate that the proposed SSDN outperforms state-of-the-art dehazing methods in terms of both quantitative accuracy and qualitative visual effect.},
  archive      = {J_NEUCOM},
  author       = {Pengcheng Huang and Li Zhao and Runhua Jiang and Tao Wang and Xiaoqin Zhang},
  doi          = {10.1016/j.neucom.2020.11.039},
  journal      = {Neurocomputing},
  pages        = {57-69},
  shortjournal = {Neurocomputing},
  title        = {Self-filtering image dehazing with self-supporting module},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Depth quality-aware selective saliency fusion for RGB-d
image salient object detection. <em>NEUCOM</em>, <em>432</em>, 44–56.
(<a href="https://doi.org/10.1016/j.neucom.2020.12.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Previous RGB-D salient object detection (SOD) methods have widely adopted the deep learning tools to automatically strike a trade-off between RGB and depth (D). The key rationale is to take full advantage of the complementary nature between RGB and D, aiming for a much-improved SOD performance than that of using either of them solely. However, because to the D quality itself usually varies from scene to scene, such fully automatic fusion schemes may not always be helpful for the SOD task. Moreover, as an objective factor, the D quality has long been overlooked by previous work. Thus, this paper proposes a simple yet effective scheme to measure D quality in advance. The key idea is to devise a series of features in accordance with the common attributes of the high-quality D regions. To be more concrete, we advocate to conduct D quality assessments following a multi-scale methodology, which includes low-level edge consistency, mid-level regional uncertainty and high-level model variance. All these components will be computed independently and later be combined with RGB and D saliency cues to guide the selective RGBD fusion. Compared with the SOTA fusion schemes, our method can achieve better fusion result between RGB and D. Specifically, the proposed D quality measurement method is able to achieve steady performance improvements for almost 2.0\% averagely.},
  archive      = {J_NEUCOM},
  author       = {Xuehao Wang and Shuai Li and Chenglizhao Chen and Aimin Hao and Hong Qin},
  doi          = {10.1016/j.neucom.2020.12.071},
  journal      = {Neurocomputing},
  pages        = {44-56},
  shortjournal = {Neurocomputing},
  title        = {Depth quality-aware selective saliency fusion for RGB-D image salient object detection},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Synergies between synaptic and intrinsic plasticity in echo
state networks. <em>NEUCOM</em>, <em>432</em>, 32–43. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Synaptic plasticity and intrinsic plasticity, as two of the most common neural plasticity mechanisms, occur in all neural circuits throughout life. Neurobiological studies indicated that the interplay between synaptic and intrinsic plasticity contributes to the adaptation of the nervous system to different synaptic input signals. However, most existing computational models of neural plasticity consider these two plasticity mechanisms separately, which is biologically implausible. In this paper, a synergistic plasticity learning rule is proposed to adapt the reservoir connections in echo state networks (ESNs), which not only takes into account the regulation of synaptic weights , but also considers the adjustment of neuronal intrinsic excitability. The proposed synergetic plasticity rule is verified on a number of prediction and classification benchmark problems and our empirical results demonstrate that the ESN with synergistic plasticity learning rule performs much better than the state-of-the-art ESN models, and an ESN with a single neural plasticity rule.},
  archive      = {J_NEUCOM},
  author       = {Xinjie Wang and Yaochu Jin and Kuangrong Hao},
  doi          = {10.1016/j.neucom.2020.12.007},
  journal      = {Neurocomputing},
  pages        = {32-43},
  shortjournal = {Neurocomputing},
  title        = {Synergies between synaptic and intrinsic plasticity in echo state networks},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AEGCN: An autoencoder-constrained graph convolutional
network. <em>NEUCOM</em>, <em>432</em>, 21–31. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a novel neural network architecture, called autoencoder-constrained graph convolutional network , to solve node classification task on graph domains. As suggested by its name, the core of this model is a convolutional network operating directly on graphs, whose hidden layers are constrained by an autoencoder . Comparing with vanilla graph convolutional networks, the autoencoder step is added to reduce the information loss brought by Laplacian smoothing . We consider applying our model on both homogeneous graphs and heterogeneous graphs. For homogeneous graphs, the autoencoder approximates to the adjacency matrix of the input graph by taking hidden layer representations as encoder and another one-layer graph convolutional network as decoder. For heterogeneous graphs, since there are multiple adjacency matrices corresponding to different types of edges, the autoencoder approximates to the feature matrix of the input graph instead, and changes the encoder to a particularly designed multi-channel pre-processing network with two layers. In both cases, the error occurred in the autoencoder approximation goes to the penalty term in the loss function. In extensive experiments on citation networks and other heterogeneous graphs, we demonstrate that adding autoencoder constraints significantly improves the performance of graph convolutional networks. Further, we notice that our technique can be applied on graph attention network to improve the performance as well. This reveals the wide applicability of the proposed autoencoder technique.},
  archive      = {J_NEUCOM},
  author       = {Mingyuan Ma and Sen Na and Hongyu Wang},
  doi          = {10.1016/j.neucom.2020.12.061},
  journal      = {Neurocomputing},
  pages        = {21-31},
  shortjournal = {Neurocomputing},
  title        = {AEGCN: An autoencoder-constrained graph convolutional network},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning performance of LapSVM based on markov subsampling.
<em>NEUCOM</em>, <em>432</em>, 10–20. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It has become common to collect massive datasets in modern applications. The massive and highly noise contaminated data pose serious challenges to conventional semi-supervised learning methods. To tackle such challenges from the large-quantity-low-quality situation, we propose a distribution-free Markov subsampling strategy based on Laplacian support vector machine (LapSVM) to achieve robust and effective estimation. The core idea is to construct an informative subset which allows us to conservatively correct a rough initial estimate towards the true classifier. Specifically, the proposed subsampling strategy selects samples with small losses via a probabilistic procedure, constructing a subset which stands a good chance of excluding the noise data and providing a safe improvement over the rough initial estimate. Theoretically, we show that the obtained classifier is statistically consistent and can achieve fast learning rate under mild conditions. The promising performance is also supported by simulation studies and real data examples.},
  archive      = {J_NEUCOM},
  author       = {Tieliang Gong and Hong Chen and Chen Xu},
  doi          = {10.1016/j.neucom.2020.12.014},
  journal      = {Neurocomputing},
  pages        = {10-20},
  shortjournal = {Neurocomputing},
  title        = {Learning performance of LapSVM based on markov subsampling},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PWM-driven model predictive speed control for an unmanned
surface vehicle with unknown propeller dynamics based on parameter
identification and neural prediction. <em>NEUCOM</em>, <em>432</em>,
1–9. (<a href="https://doi.org/10.1016/j.neucom.2020.12.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the surge speed tracking of an unmanned surface vehicle (USV) subject to unknown surge and propeller dynamics. A two-phase on-line identification and control strategy is proposed for designing a speed tracking controller without any a priori knowledge of the model parameters in surge dynamics, propeller and drive motor. In the identification phase, an adaptive parameter estimation law is used for identifying the unknown parameters in the surge speed control system. Two-layer filters are employed to assure the convergence of estimation errors in the first learning phase. In the control phase, a pulse-width-modulation-driven (PWM-driven) adaptive model predictive speed control law is proposed where neural predictors are used to estimate the identification errors and unknown sea loads based on input–output data. The stability analysis of two neural predictors is proved on the basis of input-to-state stability. Simulation results are provided to demonstrate the efficacy of the proposed end-to-end surge speed tracking of the USV without any a priori knowledge of the surge and propeller dynamics.},
  archive      = {J_NEUCOM},
  author       = {Zhouhua Peng and Chengcheng Meng and Lu Liu and Dan Wang and Tieshan Li},
  doi          = {10.1016/j.neucom.2020.12.036},
  journal      = {Neurocomputing},
  pages        = {1-9},
  shortjournal = {Neurocomputing},
  title        = {PWM-driven model predictive speed control for an unmanned surface vehicle with unknown propeller dynamics based on parameter identification and neural prediction},
  volume       = {432},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Projection neural network for a class of sparse regression
problems with cardinality penalty. <em>NEUCOM</em>, <em>431</em>,
188–200. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider a class of sparse regression problems , whose objective function is the summation of a convex loss function and a cardinality penalty. By constructing a smoothing function for the cardinality function, we propose a projection neural network and design a correction method for solving this problem. The solution of the proposed neural network is unique, global existent, bounded and globally Lipschitz continuous. Besides, we prove that all accumulation points of the proposed neural network have a common support set and a unified lower bound for the nonzero entries. Combining the proposed neural network with the correction method, any corrected accumulation point is a local minimizer of the considered sparse regression problem. Moreover, we analyze the equivalence on the local minimizers between the considered sparse regression problem and another sparse regression problem. Finally, some numerical experiments are provided to show the efficiency of the proposed neural network in solving some sparse regression problems .},
  archive      = {J_NEUCOM},
  author       = {Wenjing Li and Wei Bian},
  doi          = {10.1016/j.neucom.2020.12.045},
  journal      = {Neurocomputing},
  pages        = {188-200},
  shortjournal = {Neurocomputing},
  title        = {Projection neural network for a class of sparse regression problems with cardinality penalty},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Matrix multiplication by neuromorphic computing.
<em>NEUCOM</em>, <em>431</em>, 179–187. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With increased requirements of processing power in many computing applications, and the consequent huge increases in resource costs including electrical power consumption, there is a push to find alternative computing architectures that achieve high speeds but require less resources. One direction that shows promise is brain-inspired neuromorphic computing; it has thus become an active area of research. Much of the current work in neuromorphic computing targets its applicability in solving machine learning and pattern recognition problems. We push this boundary to show the possibility of using neuromorphic architectures to solve matrix multiplication, a core mathematical task pertinent to a host of engineering problems. We use a neuromorphic simulator to present a solution to matrix multiplication that demonstrates a significant performance improvement, both in terms of processing time and intermediate storage over existing approaches. The basic principle of proposed method is operating on a single intermediate transformation matrix that is flattened into an ensemble array represented as a neural node that is operated on. This is an optimisation over memory and time over the existing approach which uses two sparse intermediate matrices. Theoretical and experimental analysis indicates the importance of the proper choice of neuromorphic parameters, specifically the number of neurons and radius of the ensemble along with the dimensions and elements in input matrices has on accuracy, time and memory. We indicate an approach to compute the proper choice of neuromorphic resources given relevant benchmark constraints.},
  archive      = {J_NEUCOM},
  author       = {Sheril Lawrence and Aishwarya Yandapalli and Shrisha Rao},
  doi          = {10.1016/j.neucom.2020.10.064},
  journal      = {Neurocomputing},
  pages        = {179-187},
  shortjournal = {Neurocomputing},
  title        = {Matrix multiplication by neuromorphic computing},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stability analysis of riemann-liouville fractional-order
neural networks with reaction-diffusion terms and mixed time-varying
delays. <em>NEUCOM</em>, <em>431</em>, 169–178. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability analysis of time-delay neural networks with reaction-diffusion terms in the sense of Riemann–Liouville derivative is still an open problem, which will be considered in this paper. We first extend a new inequality on Riemann–Liouville fractional-order derivative, which plays an important role in the subsequent proof. Using the Lyapunov direct method, Jensen’s integral inequality, and the linear matrix inequality (LMI) method, several easy-to-test criteria expressed by system parameters and given parameters are given to ensure the stability of the system under consideration. The advantage of our method is that we can directly calculate the integral-order derivative of the Lyapunov function , which can be very convenient to test the stability of practical system. Finally, the validity and conciseness of the results are verified by numerical simulation.},
  archive      = {J_NEUCOM},
  author       = {Xiang Wu and Shutang Liu and Yin Wang},
  doi          = {10.1016/j.neucom.2020.12.053},
  journal      = {Neurocomputing},
  pages        = {169-178},
  shortjournal = {Neurocomputing},
  title        = {Stability analysis of riemann-liouville fractional-order neural networks with reaction-diffusion terms and mixed time-varying delays},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Information geometry of hyperbolic-valued boltzmann
machines. <em>NEUCOM</em>, <em>431</em>, 163–168. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information geometry is a useful tool for analysis of neural networks . In this work, information geometry is introduced to analysis of hyperbolic-valued neural networks . First, hyperbolic-valued Boltzmann machines (HBMs) are organized. Next, the HBMs are analyzed as a neuro manifold from standpoint of information geometry. We prove that the HBMs form an exponential family and provide the natural and mixture parameters. Moreover, the Fisher metric is determined. In addition, we prove the existence of mixed parameters for all the distributions, which are useful for learning algorithms.},
  archive      = {J_NEUCOM},
  author       = {Masaki Kobayashi},
  doi          = {10.1016/j.neucom.2020.12.048},
  journal      = {Neurocomputing},
  pages        = {163-168},
  shortjournal = {Neurocomputing},
  title        = {Information geometry of hyperbolic-valued boltzmann machines},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). JDGAN: Enhancing generator on extremely limited data via
joint distribution. <em>NEUCOM</em>, <em>431</em>, 148–162. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Network (GAN) is a thriving generative model and considerable efforts have been made to enhance the generation capabilities via designing a different adversarial framework of GAN (e.g., the discriminator and the generator) or redesigning the penalty function. Although existing models have been demonstrated to be very effective, their generation capabilities have limitations. Existing GAN variants either result in identical generated instances or generate simulation data with low quality when the training data are diverse and extremely limited (a dataset consists of a set of classes but each class holds several or even one single sample) or extremely imbalanced (a category holds a set of samples and other categories hold one single sample). In this paper, we present an innovative approach to tackle this issue, which jointly employs joint distribution and reparameterization method to reparameterize the randomized space as a mixture model and learn the parameters of this mixture model along with that of GAN. In this way, we term our approach Joint Distribution GAN (JDGAN). In our work, we show that the JDGAN can not only generate high quality simulation data with diversity, but also increase the overlapping area between the generating distribution and the raw data distribution. We proceed to conduct extensive experiments, utilizing MNIST, CIFAR10 and Mass Spectrometry datasets, all using extremely limited amounts of data, to demonstrate the significant performance of JDGAN in both achieving the smallest Fréchet Inception Distance (FID) score and producing diverse generated data.},
  archive      = {J_NEUCOM},
  author       = {Wei Li and Linchuan Xu and Zhixuan Liang and Senzhang Wang and Jiannong Cao and Thomas C. Lam and Xiaohui Cui},
  doi          = {10.1016/j.neucom.2020.12.001},
  journal      = {Neurocomputing},
  pages        = {148-162},
  shortjournal = {Neurocomputing},
  title        = {JDGAN: Enhancing generator on extremely limited data via joint distribution},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). SCSA-net: Presentation of two-view reliable correspondence
learning via spatial-channel self-attention. <em>NEUCOM</em>,
<em>431</em>, 137–147. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Seeking reliable correspondences between pairwise images is non-trivial in feature matching. In this paper, we propose a novel network, called the Spatial-Channel Self-Attention Network (SCSA-Net), to capture abundant contextual information of correspondences for obtaining reliable correspondences and estimating accurate camera pose of the matching images. In our proposed SCSA-Net, we introduce two types of attention modules, i.e ., the spatial attention module and the channel attention module. The two types of attention modules are able to capture complex global context of the feature maps by selectively aggregating mutual information in the spatial dimension and channel dimension, respectively. Meanwhile, we combine the outputs of two modules to generate rich global context and obtain feature maps with strong representative ability. Our SCSA-Net is able to effectively remove outliers, and simultaneously estimate accurate camera pose between pairwise images. These reliable correspondences and camera pose are vital for many computer vision tasks , such as SfM , SLAM and stereo matching . The tremendous experiments on outlier removal and pose estimate tasks have shown the better performance improvements of our SCSA-Net over current state-of-the-art methods on both outdoor and indoor datasets. Especially, our SCSA-Net outperforms the recent state-of-the-art OANet++ by 5.55\% mAP5°on unknown outdoor datasets. Code is available at https://github.com/x-gb/SCSA-Net.},
  archive      = {J_NEUCOM},
  author       = {Xin Liu and Guobao Xiao and Luanyuan Dai and Kun Zeng and Changcai Yang and Riqing Chen},
  doi          = {10.1016/j.neucom.2020.12.052},
  journal      = {Neurocomputing},
  pages        = {137-147},
  shortjournal = {Neurocomputing},
  title        = {SCSA-net: Presentation of two-view reliable correspondence learning via spatial-channel self-attention},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gated graph neural attention networks for abstractive
summarization. <em>NEUCOM</em>, <em>431</em>, 128–136. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sequence to sequence (Seq2Seq) model for abstractive summarization have aroused widely attention due to their powerful ability to represent sequence. However, the sequence structured data is a simple format, which cannot describe the complexity of graphs and may lead to ambiguous, and hurt the performance of summarization. In this paper, we propose a Gated Graph Neural Attention Networks (GGNANs) for abstractive summarization . The proposed GGNANs unified graph neural network and the celebrated Seq2seq for better encoding the full graph-structured information. We propose a graph transform method based on PMI, self-connection, forward-connection and backward-connection to better combine graph-structured information and the sequence-structured information. Extensive experimental results on the LCSTS and Gigaword show that our proposed model outperforms most of strong baseline models .},
  archive      = {J_NEUCOM},
  author       = {Zeyu Liang and Junping Du and Yingxia Shao and Houye Ji},
  doi          = {10.1016/j.neucom.2020.09.066},
  journal      = {Neurocomputing},
  pages        = {128-136},
  shortjournal = {Neurocomputing},
  title        = {Gated graph neural attention networks for abstractive summarization},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Periodicity and global exponential periodic synchronization
of delayed neural networks with discontinuous activations and impulsive
perturbations. <em>NEUCOM</em>, <em>431</em>, 111–127. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, periodic dynamics and periodic synchronization of a class of delayed neural networks with discontinuous neuron activations and impulsive perturbations are investigated. Firstly, based on Filippov’s functional differential inclusion and impulsive differential inclusions theory, the existence of solutions of the considered neural network system is studied. Secondly, according to Krasnoselskii’s fixed point theorem on cones of set-valued analysis, sufficient conditions are provided for the existence of at least one periodic solution and at least two periodic solutions for the neural network systems. Furthermore, we also use Kakutani’s fixed point theorem to give sufficient criteria for the existence of at least one periodic solution of the neural network systems. These results shown that there are still one or more periodic solutions for the neural networks with discontinuous activations under the impulsive effects. Moreover, sufficient criteria are given to the exponential periodic synchronization under the switching state-feedback control strategy with or without delay. Finally, two numerical simulation examples are presented to verify the correctness and validity of our main conclusions.},
  archive      = {J_NEUCOM},
  author       = {Zhilong He and Chuandong Li and Zhengran Cao and Hongfei Li},
  doi          = {10.1016/j.neucom.2020.09.080},
  journal      = {Neurocomputing},
  pages        = {111-127},
  shortjournal = {Neurocomputing},
  title        = {Periodicity and global exponential periodic synchronization of delayed neural networks with discontinuous activations and impulsive perturbations},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A trust-aware latent space mapping approach for cross-domain
recommendation. <em>NEUCOM</em>, <em>431</em>, 100–110. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cross-domain recommendation is becoming increasingly popular recently. Existing cross-domain recommendation often assumes that, a sufficient set of bridged users across domains is given in advance which disregards the scenario with insufficient bridged users. In this paper, we propose a novel Trust-aware Latent Space Mapping approach for Cross-domain Recommendation, called TLSM-CDR. This represents one of the first attempts to address the challenge of insufficient bridged users from the perspective of users’ trust relationships to facilitate user sharing cross-domain recommendation. First, our model employs the Probabilistic Matrix Factorization (PMF) to generate user and item matrices. Then, Deep Neural Network (DNN) and graph Laplacian are seamlessly incorporated into our trust-aware non-linear mapping function to capture the latent space relationships between both bridged and non-bridged users. Finally, we predict the optimized users’ rating matrix in the target domain. Extensive experiments conducted on two real-world datasets demonstrate that, our TLSM-CDR model significantly outperforms several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Guofang Ma and Yuexuan Wang and Xiaolin Zheng and Xiaoye Miao and Qianqiao Liang},
  doi          = {10.1016/j.neucom.2020.12.015},
  journal      = {Neurocomputing},
  pages        = {100-110},
  shortjournal = {Neurocomputing},
  title        = {A trust-aware latent space mapping approach for cross-domain recommendation},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive finite-time quantized synchronization of complex
dynamical networks with quantized time-varying delayed couplings.
<em>NEUCOM</em>, <em>431</em>, 90–99. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the finite-time synchronization problem of the complex dynamical networks ( CDNs ) with quantized time-varying delayed couplings and adaptive coupling strengths. A novel finite-time adaptive quantized control algorithm and the corresponding updated laws are developed to address the aforementioned problem. Then based on the convex combination technique and nonsmooth analysis, the sufficient conditions are derived to guarantee the finite-time synchronization in the sense of Lyapunov stability . Finally, numerical simulations are performed to verify the effectiveness and feasibility of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Juan-Juan He and Hui Chen and Ming-Feng Ge and Teng-Fei Ding and Leimin Wang and Chang-Duo Liang},
  doi          = {10.1016/j.neucom.2020.12.038},
  journal      = {Neurocomputing},
  pages        = {90-99},
  shortjournal = {Neurocomputing},
  title        = {Adaptive finite-time quantized synchronization of complex dynamical networks with quantized time-varying delayed couplings},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep blind image quality assessment based on multiple
instance regression. <em>NEUCOM</em>, <em>431</em>, 78–89. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the research of image quality assessment (IQA) based on deep learning, especially convolutional neural network (CNN), has made rapid development. The most widely used way to build a CNN-based IQA model is to divide image into patches and conduct a patch-based training. However, this method has a critical defect that the local ground-truth for each patch is not available. This defect leads to a sub-optimal result. To address this issue, we propose a novel deep blind IQA algorithm under the multiple instance regression (MIR) framework. Specifically, we assume each instance (patch) has a certain probability to be the prime instance of the bag (image), which is responsible for the bag label. Then the global quality score of the bag can be computed by the weighted summation of the local quality scores of the instances, where the weights are the probabilities of the instances to be the prime one. To simplify the training procedure, we propose an EM-like algorithm, called conditional EM algorithm, to train the deep MIR IQA model. Experimental results show that the proposed deep MIR IQA algorithm performs better than the traditional deep blind IQA algorithm. Moreover, the proposed algorithm can be used as a unified framework to improve the performance of any patch-based deep IQA models.},
  archive      = {J_NEUCOM},
  author       = {Dong Liang and Xinbo Gao and Wen Lu and Jie Li},
  doi          = {10.1016/j.neucom.2020.12.009},
  journal      = {Neurocomputing},
  pages        = {78-89},
  shortjournal = {Neurocomputing},
  title        = {Deep blind image quality assessment based on multiple instance regression},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prescribed-time containment control based on distributed
observer for multi-agent systems. <em>NEUCOM</em>, <em>431</em>, 69–77.
(<a href="https://doi.org/10.1016/j.neucom.2020.12.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The prescribed-time containment control problem for second-order multi-agent systems with multiple leaders is studied in this paper. The control objective is that all the followers are able to enter the convex hull formed by leaders at any preassigned time. Suppose that only a few followers can obtain the information of leaders, we design the distributed observer to estimate the information of the convex hull spanned by leaders firstly. Furthermore, the prescribed-time containment controller is designed with the estimation of the distributed observer. Based on a nonlinear scaling function, the tracking process is divided into four stages. The results imply that the tracking error between the followers and the convex hull could converge to zero within prescribed time. Finally, two numerical examples illustrate the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Qiong Lin and Yingjiang Zhou and Guo-Ping Jiang and Shengyu Ge and Shuai Ye},
  doi          = {10.1016/j.neucom.2020.12.030},
  journal      = {Neurocomputing},
  pages        = {69-77},
  shortjournal = {Neurocomputing},
  title        = {Prescribed-time containment control based on distributed observer for multi-agent systems},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new nonlocal means based framework for mixed noise
removal. <em>NEUCOM</em>, <em>431</em>, 57–68. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many image-denoising approaches seek to remove either additive white Gaussian noise (AWGN) or impulse noise (IN), because both types are easier to process when considered separately. However, images can be corrupted by a mixture of AWGN and IN during image acquisition and transmission. The major difficulty of mixed noise removal arises through the complex distribution of noise, which cannot be fitted by a simple parametric model . In this paper, a new nonlocal means based framework (NMF) is proposed. A median-type filter is used to detect the locations of outlier pixels; these pixels are then replaced by their nonlocal means, which makes the mixed noise distribution approximately Gaussian. To prove the effectiveness of our NMF, a low rank approximation combined with NMF (LRNM) model is presented for mixed noise removal. In the LRNM, we group similar nonlocal patches in a matrix and apply a low rank approximation to reconstruct the clean image. Gradient regularization is added to better preserve the image texture details. A convolutional neural network (CNN) combined with the NMF (NMF-CNN) is also presented, to prove the generality of the NMF. Experimental results show that LRNM and NMF-CNN achieve a strong mixed noise removal performance and also produce visually pleasing denoising results.},
  archive      = {J_NEUCOM},
  author       = {Jielin Jiang and Kang Yang and Jian Yang and Zhi-Xin Yang and Yadang Chen and Lei Luo},
  doi          = {10.1016/j.neucom.2020.12.039},
  journal      = {Neurocomputing},
  pages        = {57-68},
  shortjournal = {Neurocomputing},
  title        = {A new nonlocal means based framework for mixed noise removal},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Persuasive dialogue understanding: The baselines and
negative results. <em>NEUCOM</em>, <em>431</em>, 47–56. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Persuasion aims at forming one’s opinion and action via a series of persuasive messages containing persuader’s strategies. Due to its potential application in persuasive dialogue systems, the task of persuasive strategy recognition has gained much attention lately. Previous methods on user intent recognition in dialogue systems adopt recurrent neural network (RNN) or convolutional neural network (CNN) to model context in conversational history, neglecting the tactic history and intra-speaker relation. In this paper, we demonstrate the limitations of a Transformer-based approach coupled with Conditional Random Field (CRF) for the task of persuasive strategy recognition. In this model, we leverage inter- and intra-speaker contextual semantic features, as well as label dependencies to improve the recognition. Despite extensive hyper-parameter optimizations, this architecture fails to outperform the baseline methods. We observe two negative results. Firstly, CRF cannot capture persuasive label dependencies, possibly as strategies in persuasive dialogues do not follow any strict grammar or rules as the cases in Named Entity Recognition (NER) or part-of-speech (POS) tagging. Secondly, the Transformer encoder trained from scratch is less capable of capturing sequential information in persuasive dialogues than Long Short-Term Memory (LSTM). We attribute this to the reason that the vanilla Transformer encoder does not efficiently consider relative position information of sequence elements.},
  archive      = {J_NEUCOM},
  author       = {Hui Chen and Deepanway Ghosal and Navonil Majumder and Amir Hussain and Soujanya Poria},
  doi          = {10.1016/j.neucom.2020.11.040},
  journal      = {Neurocomputing},
  pages        = {47-56},
  shortjournal = {Neurocomputing},
  title        = {Persuasive dialogue understanding: The baselines and negative results},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A recurrent video quality enhancement framework with
multi-granularity frame-fusion and frame difference based attention.
<em>NEUCOM</em>, <em>431</em>, 34–46. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning has attracted substantial research attention for video restoration. Among the existing contributions, the single-frame based approaches purely rely on one reference frame and neglect the rest neighboring frames when enhancing a target frame. By contrast, the multi-frame based contributions exploit temporal information in a sliding window and the existing recurrent design only employ a single preceding enhanced frame. It is intuitive to exploit both multiple original neighboring frames and the preceding enhanced frames for video quality enhancement. In this paper, we propose a Recurrent video quality Enhancement framework with Multi-granularity frame-fusion and frame Difference based attention (REMD). Firstly, we devise a three-dimensional convolutional neural network based encoder-decoder fusion model, which fuses multiple frames in multi-granularity. Secondly, severe compression artifacts tend to emerge on the edges and textures of the compressed frames. We propose a frame difference based spatial attention method to intensify the edges and textures of motioning regions. Finally, a recurrent sliding window design is conceived for exploiting the temporal information in preceding enhanced frames and subsequent neighboring frames. Experiments demonstrate that our method achieves superior performance in comparison to the state-of-the-art contributions with substantially reduced spatial and computational complexity .},
  archive      = {J_NEUCOM},
  author       = {Yongkai Huo and Qiyan Lian and Shaoshi Yang and Jianmin Jiang},
  doi          = {10.1016/j.neucom.2020.12.019},
  journal      = {Neurocomputing},
  pages        = {34-46},
  shortjournal = {Neurocomputing},
  title        = {A recurrent video quality enhancement framework with multi-granularity frame-fusion and frame difference based attention},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning from multiple dynamic graphs of student and course
interactions for student grade predictions. <em>NEUCOM</em>,
<em>431</em>, 23–33. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting students’ course grades has important university-related applications, such as providing predictive assistance to students who may fail to graduate. However, it is a quite challenging task. On the one hand, each student has very limited historical course grades. On the other hand, a student may exhibit very different performance on different types of courses. As a result, most existing grade prediction methods don’t address such challenges and cannot achieve good results. Through empirical data analysis, we find that a group of students achieve similar grades over a set of similar courses. Based on the observations, we first construct student-course graphs, student-student graphs and course-course graphs to capture student-course dependency, student similarity and course similarity, respectively. Then, we propose a model named DGTEAM to specifically deal with these three dynamic graphs to obtain the representations of students and courses. The obtained representations of each course and student are applied to predict the grades. We conduct experiments on a real-world dataset and the result verifies the superiority of our model.},
  archive      = {J_NEUCOM},
  author       = {Xuansheng Lu and Yanmin Zhu and Yanan Xu and Jiadi Yu},
  doi          = {10.1016/j.neucom.2020.12.023},
  journal      = {Neurocomputing},
  pages        = {23-33},
  shortjournal = {Neurocomputing},
  title        = {Learning from multiple dynamic graphs of student and course interactions for student grade predictions},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A method for mixed data classification base on RBF-ELM
network. <em>NEUCOM</em>, <em>431</em>, 7–22. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The classification tasks for numerical or categorical data have been well developed. However, the data collected in the real world are frequently the mixed type containing numerical and categorical values, and how to classify the mixed data quickly and efficiently is a critical yet challenging task. Existing classification models for mixed data usually treat the mixed data processing and subsequent classification as two independent phases, without considering their compatibility. By fusing the mixed data processing into a classification algorithm , this paper proposes an extended version of RBF-ELM (Radial Basis Function-Extreme Learning Machine), a Mixed Data RBF-ELM method (MD-RBF-ELM for short), which can achieve direct, fast, and efficient classification for mixed data. Specifically, a distance metric method for mixed data is firstly designed to calculate the distances between the input data and the RBF centers, and then these distances are used to train the network structure and weights of MD-RBF-ELM, thereby realizing the fusion of data processing with model learning. In addition, to alleviate the problem of MD-RBF-ELM’s unstable performance caused by randomly selecting the RBF centers, we propose an improved density peak clustering algorithm and use it to select the optimal RBF centers automatically and adaptively. Extensive experimental results on 34 data sets demonstrate that MD-RBF-ELM significantly enhances the classification performance (increasing 2.37\% for F1-score, up to 14/34 for the number of best results, and reaching 2.4/8 for the averaged ranks), compared with seven state-of-the-art competitors.},
  archive      = {J_NEUCOM},
  author       = {Qiude Li and Qingyu Xiong and Shengfen Ji and Yang Yu and Chao Wu and Hualing Yi},
  doi          = {10.1016/j.neucom.2020.12.032},
  journal      = {Neurocomputing},
  pages        = {7-22},
  shortjournal = {Neurocomputing},
  title        = {A method for mixed data classification base on RBF-ELM network},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for detection of text polarity in natural
scene images. <em>NEUCOM</em>, <em>431</em>, 1–6. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text extraction and recognition from natural scene images is a challenging task due to their complex background. It has several computer vision applications like license plate recognition, content based image retrieval, digitization for visually impaired etc. In these images, dark text can be present on a bright background or vice versa and there is an imperative need to determine this polarity for the recognition process. In the present work, we have proposed to use deep learning approaches to determine text polarity. We have used Convolutional Neural Network (CNN) to classify whether a scene image contains dark text on a bright background or vice versa. CNN has been trained on image samples collected from benchmarking datasets like ICDAR, IIIT5K etc. We have also extracted CNN features by removing its final fully connected layers and trained support vector machine (SVM) classifier using these features. Our experiments have shown that this transfer learning approach has given better accuracy than original CNN and the corresponding results are reported.},
  archive      = {J_NEUCOM},
  author       = {Pavan Kumar Perepu},
  doi          = {10.1016/j.neucom.2020.12.054},
  journal      = {Neurocomputing},
  pages        = {1-6},
  shortjournal = {Neurocomputing},
  title        = {Deep learning for detection of text polarity in natural scene images},
  volume       = {431},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Towards augmented kernel extreme learning models for
bankruptcy prediction: Algorithmic behavior and comprehensive analysis.
<em>NEUCOM</em>, <em>430</em>, 185–212. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bankruptcy prediction is a crucial application in financial fields to aid in accurate decision making for business enterprises. Many models may stagnate to low-accuracy results due to the uninformed choice of parameters. This paper presents a forward-thinking bankruptcy prediction model based on kernel extreme learning machine (KELM), which proposes a new efficient version of a fruit fly optimization (FOA) algorithm called LSEOFOA, to evolve and harmonize the penalty and the kernel parameter in KELM. The upgraded version of FOA is conceptualized based on three reorganizations. The first attempt is to include Levy&#39;s flight for improving exploration inclinations, and the second is based on slime mould algorithm (SMA) for avoiding premature convergence and enhancing the stability of the exploration and exploitation patterns. As the last modification, we utilized the elite opposition-based learning for accelerating the convergence. The algorithmic trends of this optimizer are verified, and then, it is verified on a bankruptcy prediction module. Therefore, to further demonstrate the superiority of the LSEOFOA method, comparison studies are performed using the conventional FOA and other variants of FOA and a set of advanced algorithms including EBOwithCMAR. Experimental results for every optimization task demonstrate that LSEOFOA can provide a high-performance and self-assured tradeoff between exploration and exploitation. Also, the developed KELM classifier is utilized for bankruptcy prediction, and its optimal parameters set are revealed by the proposed FOA. The effectiveness of the LSEOFOA-KELM model is rigorously evaluated using a financial dataset and comparison with KELM-based models with other competitive optimizers such as LSHADE-RSP. Overall research findings show that the proposed model is superior in terms of classification accuracy , Matthews correlation coefficient, sensitivity, and specificity. Towards more evolutionary and efficient prediction models, the proposed LSEOFOA-KELM prediction model can be regarded as a promising warning tool for financial decision making, with successful performance in bankruptcy prediction. Interested readers to the idea and related material of LSEOFOA-KELM can find the designed public web service at https://aliasgharheidari.com. Also, the info and source codes of the slime mould algorithm (SMA) in python, matlab and other languages are shared publicly at https://aliasgharheidari.com/SMA.html.},
  archive      = {J_NEUCOM},
  author       = {Yanan Zhang and Renjing Liu and Ali Asghar Heidari and Xin Wang and Ying Chen and Mingjing Wang and Huiling Chen},
  doi          = {10.1016/j.neucom.2020.10.038},
  journal      = {Neurocomputing},
  pages        = {185-212},
  shortjournal = {Neurocomputing},
  title        = {Towards augmented kernel extreme learning models for bankruptcy prediction: Algorithmic behavior and comprehensive analysis},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robot recognizing humans intention and interacting with
humans based on a multi-task model combining ST-GCN-LSTM model and YOLO
model. <em>NEUCOM</em>, <em>430</em>, 174–184. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is hoped that the robot could interact with the human when the robots help us in our daily lives. And understanding humans’ specific intention is the first crucial task for human-robot interaction. In this paper, we firstly develop a multi-task model for recognizing humans’ intention, which is composed of two sub-tasks: human action recognition and hand-held object identification. For the front subtask, an effective ST-GCN-LSTM model is proposed by fusing the Spatial Temporal Graph Convolutional Networks and Long Short Term Memory Networks. And for the second subtask, the YOLO v3 model is adopted for the hand-held object identification. Then, we build a framework for robot interacting with the human. Finally, these proposed models and the interacting framework are verified on several datasets and the testing results show the effectiveness of the proposed models and the framework.},
  archive      = {J_NEUCOM},
  author       = {Chunfang Liu and Xiaoli Li and Qing Li and Yaxin Xue and Huijun Liu and Yize Gao},
  doi          = {10.1016/j.neucom.2020.10.016},
  journal      = {Neurocomputing},
  pages        = {174-184},
  shortjournal = {Neurocomputing},
  title        = {Robot recognizing humans intention and interacting with humans based on a multi-task model combining ST-GCN-LSTM model and YOLO model},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A cognitive brain model for multimodal sentiment analysis
based on attention neural networks. <em>NEUCOM</em>, <em>430</em>,
159–173. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal sentiment analysis is one of the most attractive interdisciplinary research topics in artificial intelligence (AI). Different from other classification issues, multimodal sentiment analysis of human is a much finer classification problem. However, most current work accept all multimodalities as the input together and then output final results at one time after fusion and decision processes. Rare models try to divide their models into more than one fusion modules with different fusion strategies for better adaption of different tasks. Additionally, most recent multimodal sentiment analysis methods pay great focuses on binary classification , but the accuracy of multi-classification still remains difficult to improve. Inspired by the emotional processing procedure in cognitive science, both binary and multi-classification abilities are improved in our method by dividing the complicated problem into smaller issues which are easier to be handled. In this paper, we propose a Hierarchal Attention-BiLSTM (Bidirectional Long-Short Term Memory) model based on Cognitive Brain limbic system (HALCB). HALCB splits the multimodal sentiment analysis into two modules responsible for two tasks, the binary classification and the multi-classification. The former module divides the input items into two categories by recognizing their polarity and then sends them to the latter module separately. In this module, Hash algorithm is utilized to improve the retrieve accuracy and speed. Correspondingly, the latter module contains a positive sub-net dedicated for positive inputs and a negative sub-nets dedicated for negative inputs. Each of these binary module and two sub-nets in multi-classification module possesses different fusion strategy and decision layer for matching its respective function. We also add a random forest at the final link to collect outputs from all modules and fuse them at the decision-level at last. Experiments are conducted on three datasets and compare the results with baselines on both binary classification and multi-classification tasks. Our experimental results surpass the state-of-the-art multimodal sentiment analysis methods on both binary and multi-classification by a big margin.},
  archive      = {J_NEUCOM},
  author       = {Yuanqing Li and Ke Zhang and Jingyu Wang and Xinbo Gao},
  doi          = {10.1016/j.neucom.2020.10.021},
  journal      = {Neurocomputing},
  pages        = {159-173},
  shortjournal = {Neurocomputing},
  title        = {A cognitive brain model for multimodal sentiment analysis based on attention neural networks},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inference guided feature generation for generalized
zero-shot learning. <em>NEUCOM</em>, <em>430</em>, 150–158. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generalized zero-shot learning suffers from an extreme data imbalance problem, that is, the training data only come from seen classes while no unseen class data are available. Recently, a number of feature generation methods based on generative adversarial networks (GAN) have been proposed to address this problem. Existing feature generation methods, however, have never considered the under-constrained problem, and thus could generate an unrestricted visual feature corresponding to no meaningful object class. In this paper, we propose to equip the feature generation framework with a parallel inference network that projects visual feature to the semantic descriptor space, constraining to avoid the generation of unrestricted visual features. The two-parallel-stream framework (1) enables our method, termed inference guided feature generation (Inf-FG), to mitigate the under-constrained problem and (2) makes our Inf-FG applicable to transductive ZSL. Our Inf-FG learns the feature generator and the inference network simultaneously by aligning the joint distribution of visual features and semantic descriptors from the feature generator and the joint distribution from the inference network. We evaluate our approach on four benchmark ZSL datasets, including AWA, CUB, SUN, and FLO, on which our method improves our baselines on generalized zero-shot learning.},
  archive      = {J_NEUCOM},
  author       = {Zongyan Han and Zhenyong Fu and Guangyu Li and Jian Yang},
  doi          = {10.1016/j.neucom.2020.10.080},
  journal      = {Neurocomputing},
  pages        = {150-158},
  shortjournal = {Neurocomputing},
  title        = {Inference guided feature generation for generalized zero-shot learning},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Nonrecurrent traffic congestion detection with a coupled
scalable bayesian robust tensor factorization model. <em>NEUCOM</em>,
<em>430</em>, 138–149. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonrecurrent traffic congestion (NRTC) usually brings unexpected delays to commuters. Hence, it is critical to accurately detect and recognize the NRTC in a real-time manner. The advancement of road traffic detectors provides researchers with a large-scale multivariable temporal-spatial traffic data, which allows the deep research on NRTC to be conducted. However, it remains a challenging task to construct an analytical framework through which the natural temporal-spatial structural properties of multivariable traffic information can be effectively represented and exploited to better understand and detect NRTC. In this paper, we present a novel analytical training-free framework based on the coupled scalable Bayesian robust tensor factorization (Coupled SBRTF). The framework can couple multivariable traffic variables including traffic flow, road speed, and occupancy through sharing the same sparse structure. Moreover, it naturally captures the high-dimensional temporal-spatial patterns of the traffic data by tensor factorization. With its entries revealing the distribution and magnitude of NRTC, the shared sparse structure of the framework compasses sufficiently abundant information about NRTC. While the low-rank part of the framework, expresses the distribution of general expected traffic conditions as an auxiliary product. Experimental results on real-world traffic data show that the proposed method outperforms the NRTC detection models based on the coupled Bayesian robust principal component analysis (coupled BRPCA), the rank sparsity tensor decomposition (RSTD), and standard normal deviates (SND). The proposed method performs even better when only traffic data in weekdays are utilized, and hence can provide more precise estimations of NRTC for daily commuters.},
  archive      = {J_NEUCOM},
  author       = {Qin Li and Huachun Tan and Zhuxi Jiang and Yuankai Wu and Linhui Ye},
  doi          = {10.1016/j.neucom.2020.10.091},
  journal      = {Neurocomputing},
  pages        = {138-149},
  shortjournal = {Neurocomputing},
  title        = {Nonrecurrent traffic congestion detection with a coupled scalable bayesian robust tensor factorization model},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Uncertainty analysis of wind power probability density
forecasting based on cubic spline interpolation and support vector
quantile regression. <em>NEUCOM</em>, <em>430</em>, 121–137. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate forecasting of wind power plays an important role in an effective and reliable power system. However, the fact of non-schedulability and fluctuation of wind power significantly increases the uncertainty of power systems. The output power of a wind farm is usually mixed with uncertainties, which reduce the effectiveness and accuracy of wind power forecasting. In order to handle the uncertainty of wind power, this paper first proposes to conduct outlier detection and reconstruct data before the prediction. Then, a wind power probability density forecasting method is proposed, based on cubic spline interpolation and support vector quantile regression (CSI-SVQR), which can better estimate the whole wind power probability density curve. However, the probability density prediction method can not acquire the optimal point prediction and interval prediction results at the same time. In order to analyze the uncertainty of wind power, the present study considers the prediction results from the perspective of probabilistic point prediction and interval prediction respectively. Three sets of real-world wind power data from Canada and China are used to validate the CSI-SVQR method. The results show that the proposed method not only efficiently eliminates the outliers of wind power but also provides the probability density function, offering a complete description of wind power generation fluctuation. Furthermore, more accurate point prediction and prediction interval (PI) can be obtained compared to existing methods. Wilcoxon signed rank test is used to verify that CSI can improve the performance of forecasting methods.},
  archive      = {J_NEUCOM},
  author       = {Yaoyao He and Haiyan Li and Shuo Wang and Xin Yao},
  doi          = {10.1016/j.neucom.2020.10.093},
  journal      = {Neurocomputing},
  pages        = {121-137},
  shortjournal = {Neurocomputing},
  title        = {Uncertainty analysis of wind power probability density forecasting based on cubic spline interpolation and support vector quantile regression},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Distributed fixed-time leader-following consensus tracking
control for nonholonomic multi-agent systems with dynamic uncertainties.
<em>NEUCOM</em>, <em>430</em>, 112–120. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of distributed fixed-time leader-following consensus tracking control for nonholonomic chained-form dynamic systems with nonlinear disturbances is considered in this paper. Compared with the existing works, this paper considers a class of more general nonholonomic multi-agent systems where both the leader and the followers have nonlinear uncertainties. For undirected graphs , a distributed observer for each follower is investigated such that both the leader state and input can be estimated by the followers in a fixed time. Based on the distributed observers, a consensus tracking controller is proposed to ensure that the tracking errors convergence to zero within a fixed time. Lyapunov analysis proves the stability of the closed-loop system. A simulation example of wheeled mobile robots is given to demonstrate the effectiveness of the proposed controllers.},
  archive      = {J_NEUCOM},
  author       = {Dengyu Liang and Chaoli Wang and Xuan Cai and Yu Li and Yujing Xu},
  doi          = {10.1016/j.neucom.2020.10.094},
  journal      = {Neurocomputing},
  pages        = {112-120},
  shortjournal = {Neurocomputing},
  title        = {Distributed fixed-time leader-following consensus tracking control for nonholonomic multi-agent systems with dynamic uncertainties},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A knowledge graph method for hazardous chemical management:
Ontology design and entity identification. <em>NEUCOM</em>,
<em>430</em>, 104–111. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hazardous chemicals are widely used in the production activities of the chemical industry. The risk management of hazardous chemicals is critical to the safety of life and property. Hence, the effective risk management of hazardous chemicals has always been important to the chemical industry. Since a large quantity of knowledge and information of hazardous chemicals is stored in isolated databases, it is challenging to manage hazardous chemicals in an information-rich manner. Herein, we prompt a knowledge graph to overcome the information gap between decentralized databases, which would improve the hazardous chemical management. In the implementation of the knowledge graph, we design an ontology schema of hazardous chemicals management. To facilitate enterprises to master the knowledge in the full lifecycle of hazardous chemicals, including production, transportation, storage, etc., we jointly use data from companies and open data from the public domain of hazardous chemicals to construct the knowledge graph. The named entity recognition task is one of the key tasks in the implementation of the knowledge graph, which is of great significance for extracting entity information from unstructured data, namely the hazardous chemical accidents records. To extract useful information from multi-source data, we adopt the pre-trained BERT-CRF model to conduct named entity recognition for incidents records. The model achieves good results, exhibiting the effectiveness in the task of named entity recognition in the chemical industry.},
  archive      = {J_NEUCOM},
  author       = {Xue Zheng and Bing Wang and Yunmeng Zhao and Shuai Mao and Yang Tang},
  doi          = {10.1016/j.neucom.2020.10.095},
  journal      = {Neurocomputing},
  pages        = {104-111},
  shortjournal = {Neurocomputing},
  title        = {A knowledge graph method for hazardous chemical management: Ontology design and entity identification},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). 3D-RVP: A method for 3D object reconstruction from a single
depth view using voxel and point. <em>NEUCOM</em>, <em>430</em>, 94–103.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-dimensional object reconstruction technology has a wide range of applications such as augment reality, virtual reality, industrial manufacturing and intelligent robotics . Although deep learning-based 3D object reconstruction technology has developed rapidly in recent years, there remain important problems to be solved. One of them is that the resolution of reconstructed 3D models is hard to improve because of the limitation of memory and computational efficiency when deployed on resource-limited devices. In this paper, we propose 3D-RVP to reconstruct a complete and accurate 3D geometry from a single depth view, where R, V and P represent Reconstruction, Voxel and Point, respectively. It is a novel two-stage method that combines a 3D encoder-decoder network with a point prediction network. In the first stage, we propose a 3D encoder-decoder network with residual learning to output coarse prediction results. In the second stage, we propose an iterative subdivision algorithm to predict the labels of adaptively selected points. The proposed method can output high-resolution 3D models by increasing a small number of parameters. Experiments are conducted on widely used benchmarks of a ShapeNet dataset in which four categories of models are selected to test the performance of neural networks . Experimental results show that our proposed method outperforms the state-of-the-arts, and achieves about 2.7\% 2.7\% improvement in terms of the intersection-over-union metric.},
  archive      = {J_NEUCOM},
  author       = {Meihua Zhao and Gang Xiong and MengChu Zhou and Zhen Shen and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2020.10.097},
  journal      = {Neurocomputing},
  pages        = {94-103},
  shortjournal = {Neurocomputing},
  title        = {3D-RVP: A method for 3D object reconstruction from a single depth view using voxel and point},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local-binarized very deep residual network for visual
categorization. <em>NEUCOM</em>, <em>430</em>, 82–93. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Residual networks usually require more layers to achieve remarkable performance in complex visual categorization tasks, such as pose estimation. However, the increasing number of layers leads to a heavy burden on training and forward inference as well as over-fitting. This paper proposed local binary residual block (LBB) to promote the very deep residual networks on the trainable parameters, FLOPs and accuracy. In each LBB, the 3 × 3 3×3 filters are binarized based on Bernoulli distribution under a sparse constraint, an activation function is prepared to trigger the non-linear response, and the linear 1 × 1 1×1 filters are learned in a real-valued way. After stochastic binarized initialization, the 3 × 3 3×3 filters in LBB need not be updated during training. The above architecture reduces at least 69.2\% trainable parameters and 70.5\% FLOPs compared to the original model. The LBB is derived from three observations: 1) Activated responses of one standard k × k k×k convolutional layer can be approximated by combining binarized k × k k×k filters with 1 × 1 1×1 filters; 2) Most computation in the very deep residual networks is spent on the 3 × 3 3×3 convolutions; and 3) 1 × 1 1×1 filters play an important role in cross-channel information integration . In addition, the LBB module is suitable for the very deep network framework, including stacked hourglass network and pyramid residual modules. Experiments are conducted on MPII and LSP dataset for pose estimation task; CIFAR-10, CIFAR-100 and ImageNet datasets for object recognition; ECSSD, HKU-IS, PASCAL-S, DUT-OMRON, DUTS for saliency detection . The results show that our model can accelerate the training and inference of the network with only a slight performance degradation .},
  archive      = {J_NEUCOM},
  author       = {Xuejing Liu and Liang Li and Shuhui Wang and Zheng-Jun Zha and Qingming Huang},
  doi          = {10.1016/j.neucom.2020.11.041},
  journal      = {Neurocomputing},
  pages        = {82-93},
  shortjournal = {Neurocomputing},
  title        = {Local-binarized very deep residual network for visual categorization},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential stability analysis for discrete-time
quaternion-valued neural networks with leakage delay and discrete
time-varying delays. <em>NEUCOM</em>, <em>430</em>, 71–81. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider the issue of exponential stability analysis for discrete-time quaternion-valued neural networks(DTQVNNs) with leakage delay and discrete time-varying delays. The DTQVNNs are investigated directly rather than through real decomposition method or plural decomposition method. Firstly, the existence and uniqueness of the equilibrium point for DTQVNNs are proposed by using homeomorphic mapping theorem and Cauchy-Schwarz inequality. Then, based on Lyapuinov-Krasovskii functional and matrix inequality, a delay-dependent sufficient condition is provided to guarantee the exponential stability of the equilibrium point for DTQVNNs. Finally, a numerical example is utilized to illustrate the effectiveness of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Xingxing You and Songyi Dian and Rui Guo and Shengchuan Li},
  doi          = {10.1016/j.neucom.2020.12.021},
  journal      = {Neurocomputing},
  pages        = {71-81},
  shortjournal = {Neurocomputing},
  title        = {Exponential stability analysis for discrete-time quaternion-valued neural networks with leakage delay and discrete time-varying delays},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple populations co-evolutionary particle swarm
optimization for multi-objective cardinality constrained portfolio
optimization problem. <em>NEUCOM</em>, <em>430</em>, 58–70. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of financial market, a growing number of stocks become available on the financial market. How to efficiently select these stocks to achieve higher return and lower risk has become a hot research topic in financial management. This is usually called the portfolio optimization problem (POP). When the cardinality constrained (CC) is added to limit the number of selected stocks to a certain value, the resulting CCPOP is more challenging with the following two difficulties: i) Due to the complexity of CC in finical market, how to efficiently deal with CC in POP to obtain feasible solution is difficult and time-consuming. ii) The objectives of portfolio return and risk always conflict with each other and their relation is difficult to balance. To better deal with above difficulties, this paper focuses on the multi-objective CCPOP (MoCCPOP) and proposes a multiple populations co-evolutionary particle swarm optimization (MPCoPSO) algorithm, which is based on multiple populations for multiple objectives (MPMO) framework and has the following four advantages. Firstly, a hybrid binary and real (HBR) encoding strategy is introduced to better represent the stock selection and the asset weight of the solutions in MoCCPOP. Secondly, a return risk ratio heuristic (R 3 H) strategy based on the historical return and risk of each stock is proposed as a fast CC handling method to obtain feasible solutions. Thirdly, a new particle update method based on bi-directional local search (BLS) strategy is designed to increase the chance to improve the solution accuracy and to approach the global Pareto front (PF). Last but not least, a hybrid elite competition (HEC) strategy is proposed to assist the archive update, which provides more promising solutions and brings diversity to avoid local PF. The first two strategies help to efficiently deal with the CC challenge, while the last two strategies are efficient in solving the multi-objective challenge. By comparing with some recent well-performing and state-of-the-art multi-objective optimization algorithms, MPCoPSO shows the superior performance in solving the MoCCPOP.},
  archive      = {J_NEUCOM},
  author       = {Hong Zhao and Zong-Gan Chen and Zhi-Hui Zhan and Sam Kwong and Jun Zhang},
  doi          = {10.1016/j.neucom.2020.12.022},
  journal      = {Neurocomputing},
  pages        = {58-70},
  shortjournal = {Neurocomputing},
  title        = {Multiple populations co-evolutionary particle swarm optimization for multi-objective cardinality constrained portfolio optimization problem},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Command filtered neural control of multi-agent systems with
input quantization and unknown control direction. <em>NEUCOM</em>,
<em>430</em>, 47–57. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the leader–follower cooperative tracking control for nonlinear multi-agent systems with unknown nonlinearities, quantized input and unknown control gain. Moreover, the system order of each follower agent can be different from each other. The obstacle of unknown nonlinearities is removed by utilizing the universal approximation property of neural network , and then we introduce a command filter to the backstepping design to generate the virtual control signal and its derivative, which averts the ”explosion of complexity” phenomenon. Meanwhile, by developing a novel decomposition of quantizer, Nussbaum-based scheme can be implemented to overcome the difficulties of input quantization and unknown control input coefficient. The controllers are designed only using local information, and the control scheme is fully distributed. Furthermore, there is only one online estimator needs to be calculated for each follower agent. By implementing the proposed controller into the MASs, the consensus tracking errors converge to zero with adjustable accuracy. The examples demonstrate the performance of the presented approach.},
  archive      = {J_NEUCOM},
  author       = {Zhuangbi Lin and Zhi Liu and Yun Zhang and C.L.Philip Chen},
  doi          = {10.1016/j.neucom.2020.12.031},
  journal      = {Neurocomputing},
  pages        = {47-57},
  shortjournal = {Neurocomputing},
  title        = {Command filtered neural control of multi-agent systems with input quantization and unknown control direction},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Differentially private ensemble learning for classification.
<em>NEUCOM</em>, <em>430</em>, 34–46. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training machine learning models requires large amounts of data, which may contain personal sensitive information . Machine learning based on privacy protection has become a research hotspot. In this paper, differential privacy is applied to the ensemble learning , a branch of machine learning, to prevent privacy leakage in the classification process. We propose a differentially private ensemble learning algorithm for classification, which achieves privacy protection while ensures prediction accuracy. Firstly, we adopt the Bag of Little Bootstrap technique and the Jaccard similarity coefficient to generate a set of training data sets, and construct corresponding differentially private base classifiers by adding a carefully chosen amount of perturbation noise with a privacy budget allocation strategy. Furthermore, to reduce the impact of perturbation noise on the accuracy of prediction, an effective ensemble algorithm is proposed. Specifically, the base classifiers are selected based on some criterion functions, and the corresponding weights are assigned simultaneously. Then, the final result of the classification is obtained by a weighted voting scheme. Experiments are executed on 9 real data sets from the UCI Machine Learning Repository to demonstrate that our differentially private ensemble classification algorithm achieves a better trade-off in terms of privacy protection and prediction accuracy.},
  archive      = {J_NEUCOM},
  author       = {Xianxian Li and Jing Liu and Songfeng Liu and Jinyan Wang},
  doi          = {10.1016/j.neucom.2020.12.051},
  journal      = {Neurocomputing},
  pages        = {34-46},
  shortjournal = {Neurocomputing},
  title        = {Differentially private ensemble learning for classification},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fault diagnosis with synchrosqueezing transform and
optimized deep convolutional neural network: An application in modular
multilevel converters. <em>NEUCOM</em>, <em>430</em>, 24–33. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High voltage direct current (HVDC) transmission mode with modular multilevel converters (MMC) topology is the future direction of transmission engineering, and security is their fundamental issue. Submodule fault of MMC in HVDC is the most common problem, nevertheless, traditional time–frequency based diagnosis technology can’t achieve high accuracy. To solve this pain spot, a new diagnosis strategy based on the synchrosqueezing transform (SST) and genetic algorithm optimized deep convolution neural network (GA-DCNN) is proposed in this paper. Firstly, the time–frequency representations (TFRs) of the raw signals which is synthesized by ac current and inner circulating current of the MMC are calculated with SST. Then, DCNN is introduced to learn the underlying features from the TFRs, and its key hyperparameters are optimized with genetic algorithm. Meanwhile, batch normalization , dropout and data augment technologies are explored to prevent DCNN model from overfitting and improve model performance. Compared to traditional SVM and BP-based algorithms, SST-GA-DCNN achieve high diagnosis accuracy. The experimental results show the feasibility and applicability of the proposed fault diagnosis framework.},
  archive      = {J_NEUCOM},
  author       = {Longzhang Ke and Yong Zhang and Bo Yang and Zhen Luo and Zhenxing Liu},
  doi          = {10.1016/j.neucom.2020.11.037},
  journal      = {Neurocomputing},
  pages        = {24-33},
  shortjournal = {Neurocomputing},
  title        = {Fault diagnosis with synchrosqueezing transform and optimized deep convolutional neural network: An application in modular multilevel converters},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). MSCAN: Multimodal self-and-collaborative attention network
for image aesthetic prediction tasks. <em>NEUCOM</em>, <em>430</em>,
14–23. (<a href="https://doi.org/10.1016/j.neucom.2020.10.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-expanding volume of visual images on the Internet, automatic image aesthetic prediction is becoming more and more important in computer vision field. Considering the image aesthetic assessment is a highly subjective and complex task, some researchers resort to the user comments to aid aesthetic prediction. However, these methods only achieve limited success because 1) they rely heavily on convolution to extract visual features, which is difficult to capture the spatial interaction of visual elements in image composition; 2) they treat the image features extraction and textual feature extraction as two distinct tasks and ignore the inter-relationships between these two features. We address these challenges by proposing a Multimodal Self-and-Collaborative Attention Network (MSCAN). More specifically, the self-attention module calculates the response at a position by attending to all positions in the images, thus it can effectively encode spatial interaction of the visual elements. To model the complex image-textual feature relations, a co-attention module is used to jointly perform the textual-guided visual attention and visual-guided textual attention. Then the attended multimodal features are aggregated and sent into a two-layer MLP to obtain the aesthetic values. Extensive experiments over two large benchmarks demonstrate that the proposed MSCAN outperforms the state-of-the-arts by a large margin for unified aesthetic prediction tasks.},
  archive      = {J_NEUCOM},
  author       = {Xiaodan Zhang and Xinbo Gao and Lihuo He and Wen Lu},
  doi          = {10.1016/j.neucom.2020.10.046},
  journal      = {Neurocomputing},
  pages        = {14-23},
  shortjournal = {Neurocomputing},
  title        = {MSCAN: Multimodal self-and-collaborative attention network for image aesthetic prediction tasks},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A recurrent neural network model of c. Elegans responses to
aversive stimuli. <em>NEUCOM</em>, <em>430</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although the synaptic connections of the C. elegans connectome have been precisely mapped with detailed electron microscopy studies of nematode slices, their excitatory or inhibitory character is mostly unknown. This makes the C. elegans neural dynamics unpredictable, and limits our understanding of how specific sub-circuits work. The present study proposes a recurrent neural network model that reproduces known escape behaviours of C. elegans . To do this, our model uses the known information about the connectome, and makes guesses on the excitatory or inhibitory character of the synapses, which are iteratively updated until the model is able to reproduce the known behaviours. Specifically, we apply this model-based approach to study the neuronal sub-circuits involved in the association of aversive stimuli with escape responses. To form an escape response dataset that allows us to adjust our model parameters, we performed a meta-study on the C. elegans stimulus–response behaviours reported in literature, focusing on robust escape reactions triggered by aversive stimuli. Given a wide sample of all possible parameter sets that satisfy the behavioural constraints of the dataset, we find that more than 75\% of the synaptic connections reach a univocal optimal assignment of the inhibitory or excitatory character. To validate our model, we show that in the few cases where the excitatory/inhibitory character is already known, our retrieved optimum in synaptic characters matches the results reported in literature. Finally, we assess the accuracy of this approach by applying it on recurrent neural networks that have the same connectivity structure of C. elegans but random inhibitory or excitatory character. These findings confirm the predictive power of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Enrico Lanza and Silvia Di Angelantonio and Giorgio Gosti and Giancarlo Ruocco and Viola Folli},
  doi          = {10.1016/j.neucom.2020.11.067},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {A recurrent neural network model of c. elegans responses to aversive stimuli},
  volume       = {430},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Deep face recognition: A survey. <em>NEUCOM</em>,
<em>429</em>, 215–244. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning applies multiple processing layers to learn representations of data with multiple levels of feature extraction. This emerging technique has reshaped the research landscape of face recognition (FR) since 2014, launched by the breakthroughs of DeepFace and DeepID. Since then, deep learning technique , characterized by the hierarchical architecture to stitch together pixels into invariant face representation, has dramatically improved the state-of-the-art performance and fostered successful real-world applications. In this survey, we provide a comprehensive review of the recent developments on deep FR, covering broad topics on algorithm designs , databases, protocols, and application scenes. First, we summarize different network architectures and loss functions proposed in the rapid evolution of the deep FR methods . Second, the related face processing methods are categorized into two classes: “one-to-many augmentation” and “many-to-one normalization”. Then, we summarize and compare the commonly used databases for both model training and evaluation. Third, we review miscellaneous scenes in deep FR, such as cross-factor, heterogenous, multiple-media and industrial scenes. Finally, the technical challenges and several promising directions are highlighted.},
  archive      = {J_NEUCOM},
  author       = {Mei Wang and Weihong Deng},
  doi          = {10.1016/j.neucom.2020.10.081},
  journal      = {Neurocomputing},
  pages        = {215-244},
  shortjournal = {Neurocomputing},
  title        = {Deep face recognition: A survey},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Attention-aware concentrated network for saliency
prediction. <em>NEUCOM</em>, <em>429</em>, 199–214. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a biologically-inspired saliency prediction method to imitate two main characteristics of the human perception process: focalization and orienting. The proposed network, named ACNet is composed of two modules. The first one is an essential concentrated module (CM), which assists the network to “see” images with appropriate receptive fields by perceiving rich multi-scale multi-receptive-field contexts of high-level features. The second is a parallel attention module (PAM), which explicitly guides the network to learn “what” and “where” is salient by simultaneously capturing global and local information with channel-wise and spatial attention mechanisms . These two modules compose the core component of the proposed method, named ACBlock, which is cascaded to progressively refine the inference of saliency estimation in a manner similar to that humans zoom in their lens to focus on the saliency. Experimental results on seven public datasets demonstrate that the proposed ACNet outperforms the state-of-the-art models without any prior knowledge or post-processing.},
  archive      = {J_NEUCOM},
  author       = {Pengqian Li and Xiaofen Xing and Xiangmin Xu and Bolun Cai and Jun Cheng},
  doi          = {10.1016/j.neucom.2020.10.083},
  journal      = {Neurocomputing},
  pages        = {199-214},
  shortjournal = {Neurocomputing},
  title        = {Attention-aware concentrated network for saliency prediction},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). PointVGG: Graph convolutional network with progressive
aggregating features on point clouds. <em>NEUCOM</em>, <em>429</em>,
187–198. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Shape classification and part segmentation are essential problems in computer vision. Although convolutional neural networks have achieved excellent performance on regular grid data , such as images, they have difficulty in accurately describing the shape information and geometric representation of point clouds because point clouds are irregular and disordered. Inspired by the convolution and pooling techniques used in images, we propose point convolution (Pconv) and point pooling (Ppool) on point clouds to learn high-level features from point clouds. Pconv obtains considerable local geometric information by magnifying receptive fields gradually. Ppool solves the disorder of point clouds similar to a symmetric function . However, in contrast to the symmetric function that directly aggregates local geometric information into a vector, Ppool acquires a more detailed local geometric representation by aggregating points progressively. A novel network, namely, PointVGG, with Pconv, Ppool, and graph structure for feature learning of point clouds, is presented and applied to object classification and part segmentation. Experiments show that PointVGG achieves state-of-the-art results on challenging benchmarks of 3D point clouds.},
  archive      = {J_NEUCOM},
  author       = {Rongkang Li and Yumeng Zhang and Dongmei Niu and Guangchao Yang and Numan Zafar and Caiming Zhang and Xiuyang Zhao},
  doi          = {10.1016/j.neucom.2020.10.086},
  journal      = {Neurocomputing},
  pages        = {187-198},
  shortjournal = {Neurocomputing},
  title        = {PointVGG: Graph convolutional network with progressive aggregating features on point clouds},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust kernels for robust location estimation.
<em>NEUCOM</em>, <em>429</em>, 174–186. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper shows that least-square estimation (mean calculation) in a reproducing kernel Hilbert space (RKHS) F F corresponds to different M-estimators in the original space depending on the kernel function associated with F F . In particular, we present a proof of the correspondence of mean estimation in an RKHS for the Gaussian kernel with robust estimation in the original space performed with the Welsch M-estimator. This result is generalized to other types of M-estimators. This generalization facilitates the definition of new robust kernels associated to Huber, Tukey, Cauchy and Andrews M-estimators. The new kernels are empirically evaluated in different clustering tasks where state-of-the-art robust clustering methods are compared to kernel-based clustering using robust kernels. The results show that some robust kernels perform on a par with the best state-of-the-art robust clustering methods .},
  archive      = {J_NEUCOM},
  author       = {Joseph A. Gallego and Fabio A. González and Olfa Nasraoui},
  doi          = {10.1016/j.neucom.2020.10.090},
  journal      = {Neurocomputing},
  pages        = {174-186},
  shortjournal = {Neurocomputing},
  title        = {Robust kernels for robust location estimation},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multimodal metaphor detection based on distinguishing
concreteness. <em>NEUCOM</em>, <em>429</em>, 166–173. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaphors are a common linguistic phenomenon, and metaphor identification plays an essential role in metaphor processing. Most existing metaphor computing techniques use only texts to gain features, but we acquire additional knowledge from other modalities. At present, the multimodal model in the metaphor field is in the exploratory stage, and the few multimodal models available are still relatively crude. We propose a multimodal metaphor detection method according to the idea that different types of words are suitable for different modality calculations. First, our proposed framework uses a fine-grained concreteness calculation method based on part of speech to distinguish abstract and concrete words. We then choose a different appropriate modal feature and a different metaphor computational method for words with different concreteness. Additionally, we also improve the use of image features in the field of metaphor detection.},
  archive      = {J_NEUCOM},
  author       = {Chang Su and Weijie Chen and Ze Fu and Yijiang Chen},
  doi          = {10.1016/j.neucom.2020.11.051},
  journal      = {Neurocomputing},
  pages        = {166-173},
  shortjournal = {Neurocomputing},
  title        = {Multimodal metaphor detection based on distinguishing concreteness},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive prescribed performance neural network control for
switched stochastic pure-feedback systems with unknown hysteresis.
<em>NEUCOM</em>, <em>429</em>, 151–165. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the problem of neural network (NN) prescribed performance tracking control for a class of switched stochastic nonlinear pure-feedback systems which contain unknown nonlinear functions , unmeasured state variables, and unknown hysteresis input. It provides an adaptive NN controller which is not restricted to a particular type of hysteresis input. A general mathematical model is introduced to describe two kinds of hysteresis nonlinearities and to utilize in the control design producer. Other focus of this paper is on the performance constraint problem to avoid performance degradation and system damage in practical control systems. Prescribed performance control (PPC) and backstepping technique are thus synthesized to develop an adaptive NN output feedback tracking control scheme under deterministic switching signal. Regarding this concern, to cope with the cause of non-differentiable difficulties and complex deductions in traditional PPC, a new asymmetry error transformation is employed. Moreover, radial basis function NNs (RBFNNs) are applied to approximate the unknown nonlinear functions and to construct a NN nonlinear observer to estimate the immeasurable state variables. Based on Lyapunov stability theory , it is demonstrated that the proposed controller can guarantee that all signals in the closed-loop system are semiglobally uniformly ultimately bounded in probability and the tracking error converges to a small neighborhood of the origin with the prescribed performance bounds. Finally, two simulation examples are provided to confirm the advantages of the presented control design approach.},
  archive      = {J_NEUCOM},
  author       = {Zahra Namadchian and Modjtaba Rouhani},
  doi          = {10.1016/j.neucom.2020.11.044},
  journal      = {Neurocomputing},
  pages        = {151-165},
  shortjournal = {Neurocomputing},
  title        = {Adaptive prescribed performance neural network control for switched stochastic pure-feedback systems with unknown hysteresis},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Linear time identification of local and global outliers.
<em>NEUCOM</em>, <em>429</em>, 141–150. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection methods differ in their time complexity, sensitivity to data dimensions, and their ability to detect local/global outliers. The recently proposed algorithm FiRE is a ‘sketching’ based linear-time algorithm for identifying global outliers. This work details FiRE.1, an extended implementation of FiRE that fares well on local outliers as well. We provide an extensive comparison with 18 state-of-the-art anomaly detection algorithms on a diverse collection of 1000 annotated datasets. Five different evaluation metrics have been employed. FiRE.1’s performance was particularly remarkable on datasets featuring a large number of local outliers. In the sequel, we propose a new “outlierness” criterion to infer the local or global identity of outliers.},
  archive      = {J_NEUCOM},
  author       = {Prashant Gupta and Aashi Jindal and Jayadeva and Debarka Sengupta},
  doi          = {10.1016/j.neucom.2020.11.059},
  journal      = {Neurocomputing},
  pages        = {141-150},
  shortjournal = {Neurocomputing},
  title        = {Linear time identification of local and global outliers},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint entity and relation extraction model based on rich
semantics. <em>NEUCOM</em>, <em>429</em>, 132–140. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting entities and relations from unstructured texts has become an important task in the natural language processing (NLP), especially knowledge graphs (KG). However, relation classification (RC) and named entity recognition (NER) tasks are usually considered separately, which lost a lot of associated contextual information. Therefore, a novel end-to-end method based on the attention mechanism integrating convolutional and recurrent neural networks is proposed for joint entity and relation extraction, which can obtain rich semantics and takes full advantage of the associated information between entities and relations without introducing external complicated features. The convolutional operation is employed to obtain character-level and word-level embeddings which are transferred to the multi-head attention mechanism . Then the multi-head attention mechanism can encode contextual semantics and embeddings to obtain efficient semantic representation . Moreover, the rich semantics are encoded to obtain final tag sequence based on recurrent neural networks . Finally, the experiments are performed on NYT10 and NYT11 benchmarks to demonstrate the proposed method. Compared with the current pipelined and joint approaches, the experimental results indicate that the proposed method can obtain state-of-the-art performance in terms of the standard F1-score.},
  archive      = {J_NEUCOM},
  author       = {Zhiqiang Geng and Yanhui Zhang and Yongming Han},
  doi          = {10.1016/j.neucom.2020.12.037},
  journal      = {Neurocomputing},
  pages        = {132-140},
  shortjournal = {Neurocomputing},
  title        = {Joint entity and relation extraction model based on rich semantics},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domain-aware stacked AutoEncoders for zero-shot learning.
<em>NEUCOM</em>, <em>429</em>, 118–131. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Zero-shot learning (ZSL), which focuses on transferring the knowledge from the seen (source) classes to unseen (target) ones, is getting more and more attention in the computer vision community. However, there often has a large domain gap between the source and target classes, resulting in the projection domain shift problem. To this end, we propose a novel model, named Domain-aware Stacked AutoEncoders (DaSAE), that consists of two interactive stacked auto-encoders to learn the domain-aware projections for adapting source and target domains respectively. In each of them, the first-layer encoder aims to project a visual feature vector into the semantic space, and the second-layer encoder connects the semantic description of a sample with its label directly. Meanwhile, the two-layer decoders seek to reconstruct the visual representation from the label information and semantic description successively. Moreover, the manifold regularization that explores the manifold structure residing in the target data is integrated to the basic DaAE, which further improves the generalization ability of our model. Extensive experiments on the benchmark datasets clearly demonstrate that our DaSAE outperforms the state-of-the-art alternatives by the significant margins.},
  archive      = {J_NEUCOM},
  author       = {Jianqiang Song and Guangming Shi and Xuemei Xie and Qingtao Wu and Mingchuan Zhang},
  doi          = {10.1016/j.neucom.2020.12.017},
  journal      = {Neurocomputing},
  pages        = {118-131},
  shortjournal = {Neurocomputing},
  title        = {Domain-aware stacked AutoEncoders for zero-shot learning},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PFLU and FPFLU: Two novel non-monotonic activation functions
in convolutional neural networks. <em>NEUCOM</em>, <em>429</em>,
110–117. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The choice of activation functions in Convolutional Neural Networks (CNNs) is very important. Rectified Linear Unit (ReLU) has been widely-used in most CNNs. Recently, a series of non-monotonic activation functions gradually become the new standard to enhance performance of CNNs. Inspired by them, this paper firstly proposes a novel non-monotonic activation function called Power Function Linear Unit (PFLU). The negative part of PFLU is non-monotonic and closer to zero with the negative input decreasing, which can maintain sparsity of the negative part while introducing negative activation values and non-zero derivative values for the negative part. The positive part of PFLU does not use identity mapping but is closer to identity mapping with the positive input increasing, which can bring non-linearity property for the positive part. Next, this paper proposes faster PFLU (FPFLU). A wide range of classification experiments show that PFLU tends to work better than current state-of-the-art non-monotonic activation functions, and FPFLU can run faster than most non-monotonic activation functions.},
  archive      = {J_NEUCOM},
  author       = {Meng Zhu and Weidong Min and Qi Wang and Song Zou and Xinhao Chen},
  doi          = {10.1016/j.neucom.2020.11.068},
  journal      = {Neurocomputing},
  pages        = {110-117},
  shortjournal = {Neurocomputing},
  title        = {PFLU and FPFLU: Two novel non-monotonic activation functions in convolutional neural networks},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deepening the IDA* algorithm for knowledge graph reasoning
through neural network architecture. <em>NEUCOM</em>, <em>429</em>,
101–109. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inferring missing links in Knowledge Graphs (KGs) is a key evaluation task for KG reasoning, which aims to find relations for a given entity pair. Existing research often employs the IDA* (Iterative Deepening A*) algorithm for the path discovery task owing to its efficiency and accuracy. However, it relies on heuristics to set cost functions and is also difficult to utilize useful context information in the search process. In this paper, we propose the Deep-IDA* framework which applies neural networks and reinforcement learning (RL) to empower the IDA* algorithm to tackle the path discovery problem in KG reasoning. We model KG reasoning as a Markov Decision Process (MDP) and divide our Deep-IDA* framework and the resulting path into two parts: path-finding and path-reasoning. For path-finding, we propose a policy network to model the cost from the source to a candidate location. In this process, we employ the GCN (Graph Convolutional Network) to embed the observable sub-track, then employ the LSTM (Long Short-Term Memory) to record the historical trajectory, and introduce the attention to utilize the context information, and finally form policy. For path-reasoning with the searched candidate paths passed from the former process, we employ a value network to estimate the cost from the candidate to the destination entity, using the GNN (Graph Neural Networks) to learn a message-passing algorithm that solves the path inference problem, and using the GRU (Gated Recurrent Unit) to update the historical information. Finally, the actor-learner algorithm is utilized to minimize the sum of the losses of the two parts. Experiment results on three datasets demonstrate the effectiveness and efficiency of our framework.},
  archive      = {J_NEUCOM},
  author       = {Qi Wang and Yongsheng Hao and Feng Chen},
  doi          = {10.1016/j.neucom.2020.12.040},
  journal      = {Neurocomputing},
  pages        = {101-109},
  shortjournal = {Neurocomputing},
  title        = {Deepening the IDA* algorithm for knowledge graph reasoning through neural network architecture},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fast DC-based dictionary learning algorithm with the SCAD
penalty. <em>NEUCOM</em>, <em>429</em>, 89–100. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, there has been growing concerns on the study of dictionary learning with the nonconvex sparsity-including penalty. However, how to efficiently address the dictionary learning with the nonconvex penalty is still an open problem. In this paper, we present an efficient DC-based algorithm for dictionary learning with the nonconvex smoothly clipped absolute deviation (SCAD) penalty for strong sparsity and accurate estimation. The optimization problem we considered can be generalized as a minimization of the representation error with the SCAD penalty. The approach we proposed is based on a decomposition scheme which decomposes the whole problem into a set of subproblems with regard to single-vector factors. For handling the nonconvexity of the representation error in the subproblems, we use an alternating optimization scheme to update one factor with the other factor fixed. For tackling the nonconvexity of the SCAD penalty in the subproblems, we apply the Difference of Convex functions (DC) technology to convert the nonconvex subproblem into the resulting convex problems and thus employ DC algorithm to solve the corresponding optimization; thus the simple and straightforward solutions in the closed form can be easily derived. As verified by the numerical experiments with synthetic and real-world data, the proposed algorithm performs better than the state-of-the-art algorithms with different sparsity-including constraints.},
  archive      = {J_NEUCOM},
  author       = {Zhenni Li and Chao Wan and Benying Tan and Zuyuan Yang and Shengli Xie},
  doi          = {10.1016/j.neucom.2020.12.003},
  journal      = {Neurocomputing},
  pages        = {89-100},
  shortjournal = {Neurocomputing},
  title        = {A fast DC-based dictionary learning algorithm with the SCAD penalty},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Enhancing knowledge graph embedding with relational
constraints. <em>NEUCOM</em>, <em>429</em>, 77–88. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding is studied to embed entities and relations of a knowledge graph into continuous vector spaces, which benefits a variety of real-world applications. Among existing solutions, translational models, which employ geometric translation to design score function, have drawn much attention. However, these models primarily concentrate on evidence from observing whether the triplets are plausible, and ignore the fact that the relation also implies certain semantic constraints on its subject or object entity. In this paper, we present a general framework for enhancing knowledge graph embedding with relational constraints (KRC). Specifically, we elaborately design the score function by encoding regularities between a relation and its arguments into the translational embedding space. Additionally, we propose a soft margin-based ranking loss for effectively training the KRC model, which characterizes different semantic distances between negative and positive triplets. Furthermore, we combine regularities with distributional representations to predict the missing triplets, which can possess certain robust guarantee. We evaluate our method on the tasks of knowledge graph completion and entity classification. Extensive experiments show that KRC achieves a better, or comparable performance against state-of-the-art methods. Besides, KRC makes a great improvement when dealing with long-tail entities, which have few instances in the knowledge graph.},
  archive      = {J_NEUCOM},
  author       = {Mingda Li and Zhengya Sun and Siheng Zhang and Wensheng Zhang},
  doi          = {10.1016/j.neucom.2020.12.012},
  journal      = {Neurocomputing},
  pages        = {77-88},
  shortjournal = {Neurocomputing},
  title        = {Enhancing knowledge graph embedding with relational constraints},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequence generative adversarial nets with a conditional
discriminator. <em>NEUCOM</em>, <em>429</em>, 69–76. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of Generative Adversarial Networks (GANs) in image generation attracts researchers to design sequence GANs in text generation. However, the discriminators of those sequence GANs usually provide only one signal per sequence, which can not reflect detailed information, e.g. whether a token is appropriate in a sequence. In addition, maximum likelihood pre-training is typically used in those models, which is time-consuming and obscures the effects of adversarial training . To cope with these problems, we propose a new sequence GAN that consists of a conditional discriminator and a discriminator-augmented generator. The conditional discriminator provides a sequence with token-level signals. The generator is designed to approximate a discriminator-augmented distribution, which avoids pre-training. Experiments show that the conditional discriminator provides more informative guidance, and our model outperforms existing models according to metrics involving both sampling quality and sampling diversity.},
  archive      = {J_NEUCOM},
  author       = {Yongfei Yan and Gehui Shen and Song Zhang and Ting Huang and Zhi-Hong Deng and Unil Yun},
  doi          = {10.1016/j.neucom.2020.10.108},
  journal      = {Neurocomputing},
  pages        = {69-76},
  shortjournal = {Neurocomputing},
  title        = {Sequence generative adversarial nets with a conditional discriminator},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Entropy guided adversarial model for weakly supervised
object localization. <em>NEUCOM</em>, <em>429</em>, 60–68. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly Supervised Object Localization is challenging due to the lack of bounding box annotations. Previous works tend to generate a Class Activation Map (CAM) to localize the object. However, the CAM highlights only the most discirminative part of the object and does not highlight the whole object. To address this problem, we propose an Entropy Guided Adversarial model (EGA model) to perform better localization of objects. EGA model uses adversarial learning method to create adversarial examples , i.e., images where a perturbation is added. Treating adversarial examples as data augmentation regularize our model as well as detect more discriminative visual pattern on the CAM. We further apply the Shannon entropy on the generated CAM to guide the model during training. Minimizing the entropy loss forces the model to generate a high-confident CAM. The high-confident CAM detects the whole object while excludes the background. Extensive experiments show that EGA model improves classification and localization performances on state-of-the-art benchmarks. Ablation experiments also show that both the adversarial learning and the entropy loss contribute to the algorithm performance.},
  archive      = {J_NEUCOM},
  author       = {Sabrina Narimene Benassou and Wuzhen Shi and Feng Jiang},
  doi          = {10.1016/j.neucom.2020.11.006},
  journal      = {Neurocomputing},
  pages        = {60-68},
  shortjournal = {Neurocomputing},
  title        = {Entropy guided adversarial model for weakly supervised object localization},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A kernel-based weight decorrelation for regularizing CNNs.
<em>NEUCOM</em>, <em>429</em>, 47–59. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years has witnessed the success of convolutional neural networks (CNNs) in many machine learning and pattern recognition applications, especially in image recognition. However, due to the increasing model complexity, the parameter redundancy problem arises, and greatly degrades the performance of CNNs. To alleviate this problem, various regularization techniques, such as Dropout, have been proposed and proved their effectiveness. In this paper, we propose a novel adaptive kernel-based weight decorrelation (AKWD) framework, in order to regularize CNNs for better generalization. Different from existing works, the correlation between paring weights is measured by the cosine distance defined in RKHS associated with a specific kernel. The case with the well-known Gaussian kernel is investigated in detail, where the bandwidth parameter is adaptively estimated. By regularizing CNN models of different capacities using AKWD, better performance is achieved on several benchmark databases for both object classification and face verification tasks. In particular, when Dropout or BatchNorm is present, even higher improvements are obtained using the proposed AKWD, that demonstrates a good compatibility of the proposed regularizer with other regularization techniques.},
  archive      = {J_NEUCOM},
  author       = {Yanhong Zhang and Fei Zhu},
  doi          = {10.1016/j.neucom.2020.11.065},
  journal      = {Neurocomputing},
  pages        = {47-59},
  shortjournal = {Neurocomputing},
  title        = {A kernel-based weight decorrelation for regularizing CNNs},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiple graph semi-supervised clustering with automatic
calculation of graph associations. <em>NEUCOM</em>, <em>429</em>, 33–46.
(<a href="https://doi.org/10.1016/j.neucom.2020.12.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiple graph clustering is an important tool in data integration and data mining for graph-based data. The prediction and classification accuracy can be significantly improved by integrating information from multiple sources and data sets. The aim of multiple graph clustering is to partition objects into several clusters such that clusters in each graph are well-separated and clusters across different graphs are consistent. Existing methods assume that the degrees of association among different graphs are the same. However, some graphs may be strongly or weakly associated with the other graphs due to high or low correlation of their associated cluster structures. When their cluster structures are (or are not) similar, their degree of association should be high (or low). Accurate clustering results can be obtained by integrating such association information in multiple graphs. The main aim of this paper is to study multiple graph semi-supervised clustering by considering a large amount of multiple graph data and a small amount of labeled data. We propose a constrained optimization problem that can determine cluster structures and degrees of association simultaneously in multiple graph clustering. In our formulation, we make use of orthogonality for cluster structure indicator and cosine correlation for degree of association. With orthogonality constraint in the clustering process , we develop a gradient flow method to solve the resulting optimization problem . And the convergence of the proposed iterative method is also shown. Numerical examples including synthetic data and real data sets with few known labels are tested, and are presented to show the efficiency and effectiveness of our proposed method compared with the testing methods in the literature.},
  archive      = {J_NEUCOM},
  author       = {Ye Liu and Michael K. Ng and Hong Zhu},
  doi          = {10.1016/j.neucom.2020.12.002},
  journal      = {Neurocomputing},
  pages        = {33-46},
  shortjournal = {Neurocomputing},
  title        = {Multiple graph semi-supervised clustering with automatic calculation of graph associations},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coexistence of continuous attractors with different
dimensions for neural networks. <em>NEUCOM</em>, <em>429</em>, 25–32.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work briefly investigates the coexistence of continuous attractors in the neural networks with Rectified Linear Unit (RELU) transfer function. Memory is stored as a manifold of stable states, or a continuous attractor. Continuous attractors are some low-dimensional manifolds embedded in a high-dimensional state space. One neural network may possess more than one continuous attractors. More importantly, we found that these multiple continuous attractors may have different dimensional, some are 2-D plane attractors and others are 1-D line attractors. It is also an enlightenment to study the continuous attractors of high dimensional models.},
  archive      = {J_NEUCOM},
  author       = {Wanyu Xiang and Jiali Yu and Zhang Yi and Chunxiao Wang and Qing Gao and Yong Liao},
  doi          = {10.1016/j.neucom.2020.11.047},
  journal      = {Neurocomputing},
  pages        = {25-32},
  shortjournal = {Neurocomputing},
  title        = {Coexistence of continuous attractors with different dimensions for neural networks},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Central moment discrepancy based domain adaptation for
intelligent bearing fault diagnosis. <em>NEUCOM</em>, <em>429</em>,
12–24. (<a href="https://doi.org/10.1016/j.neucom.2020.11.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep learning based bearing fault diagnosis is developing rapidly due to the increasing amount of industrial data. However, two major issues limit the application for deep learning: a) labeled data is difficult to obtain, and a lot of unlabeled data is more common in actual industrial production; b) the distribution of training and testing dataset will be different under different production environments or operations, which makes it difficult to generalize the trained model to another working condition. To solve these issues, we propose a domain adaptation convolutional neural network to diagnostic fault using Central Moment Discrepancy (CMD). In the proposed method, a convolutional neural network is applied to extract features from two differently distributed raw vibration signals, and the distribution discrepancy is reduced using CMD criterion. The proposed method can extract features with similar distribution from two different domains and make fault diagnosis for unlabeled data. The proposed method is proved to be effective in using CWRU dataset and Paderborn dataset under different working conditions.},
  archive      = {J_NEUCOM},
  author       = {Xudong Li and Yang Hu and Jianhua Zheng and Mingtao Li and Wenzhen Ma},
  doi          = {10.1016/j.neucom.2020.11.063},
  journal      = {Neurocomputing},
  pages        = {12-24},
  shortjournal = {Neurocomputing},
  title        = {Central moment discrepancy based domain adaptation for intelligent bearing fault diagnosis},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic batch size tuning based on stopping criterion for
neural network training. <em>NEUCOM</em>, <em>429</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the neural network training, the selection of the minibatch size affects not only the computational cost but also the training performance, as it underlies the loss function. Generally, an approach based on increasing the batch size according to the linear and step functions during the training process is known to be effective in improving the generalization performance of a network. However, it requires specifying the way of increasing the batch size beforehand. In this study, we propose a more flexible method that implies temporarily varying a small batch size to destabilize the loss function when a change in the training loss satisfies the predefined stopping criterion. Repeating the destabilization step allows a parameter to avoid being trapped at the local minima and to converge at a robust minimum, thereby improving generalization performance . We experimentally demonstrate the superiority of the proposed method considering several benchmark datasets and neural network models.},
  archive      = {J_NEUCOM},
  author       = {Tomoumi Takase},
  doi          = {10.1016/j.neucom.2020.11.054},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Dynamic batch size tuning based on stopping criterion for neural network training},
  volume       = {429},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Worker collaborative group estimation in spatial
crowdsourcing. <em>NEUCOM</em>, <em>428</em>, 385–391. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial crowdsourcing (SC) has gained much attention in recent years. On SC platforms , requesters can publish spatial tasks on a specific topic such as taking photos at certain locations which is reflected by some tags of the task, and workers can choose tasks according to their tags. An interesting phenomenon is that workers often form groups based on their social relationships and common interests to perform same tasks. A nature question often raised when a task is published is how to predict which (or how many) workers are attracted by the task if its tags are specified. In particular, the tags of a new task affect the willingness of the workers to choose it. On the other hand, workers are also affected by the willingness of their co-workers or friends when deciding to choose a task or not. In this paper, we study the problem of potential workers estimation for a spatial crowdsourcing task, the Worker Collaborative Group Estimation (WCGE) problem, and model whether workers will join the group of a task as a game. We present efficient algorithms to find the Nash Equilibrium of the game and estimate the potential workers for the new task. Using synthetic datasets , we experimentally study the performance of proposed solutions. Our solutions can also help understand big geospatial data for self-driving cars and more intelligent transportation applications.},
  archive      = {J_NEUCOM},
  author       = {Zhi Wang and Yubing Li and Kun Zhao and Wei Shi and Liangliang Lin and Jizhong Zhao},
  doi          = {10.1016/j.neucom.2019.11.121},
  journal      = {Neurocomputing},
  pages        = {385-391},
  shortjournal = {Neurocomputing},
  title        = {Worker collaborative group estimation in spatial crowdsourcing},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A graph embedding based model for fine-grained POI
recommendation. <em>NEUCOM</em>, <em>428</em>, 376–384. (<a
href="https://doi.org/10.1016/j.neucom.2020.01.118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-of-interest (POI) recommendation is an important technique widely used in self-driving services. While POI recommendation aims to recommend unvisited POIs to self-driving users, users always expect their intended items can be suggested together with these POIs, e.g. what activities to perform at the recommended places. However, existing methods cannot well support such POI recommendation in a finer granularity . In this paper, we investigate this new problem and propose a novel POI-based item recommendation model via graph embedding. The model accurately captures the joint effect of geographical and temporal influences on both POI-level and item-level recommendation in a shared space, which can address data sparsity and cold start problems effectively. To optimize the model efficiently and accurately, a novel weighted negative sampling strategy is designed. Besides, we propose a novel fine-grained user dynamic preference modeling method, which can accurately capture dynamic user preferences in a finer granularity based on the embeddings of both POIs and items. Comprehensive experimental studies have been conducted on three datasets. Results show that our model achieves significant improvement over state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Xiaojiao Hu and Jiajie Xu and Weiqing Wang and Zhixu Li and An Liu},
  doi          = {10.1016/j.neucom.2020.01.118},
  journal      = {Neurocomputing},
  pages        = {376-384},
  shortjournal = {Neurocomputing},
  title        = {A graph embedding based model for fine-grained POI recommendation},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CISK: An interactive framework for conceptual inference
based spatial keyword query. <em>NEUCOM</em>, <em>428</em>, 368–375. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatial keyword query is an important technique for recommending users their desired POIs in self-driving services. Inferring query intention has been recognized as an important yet challenging issue for spatial keyword search . However, existing methods are inadequate to discover qualified results due to the inability to capture the intention of short-text input keywords. In this paper, we adopt a conceptual inference based method to deduce implicit intentions of users and thus are able to find more meaningful answers. Firstly, a locality-aware inference model is designed to generate concepts by considering typicality, granularity and spatial distribution, taking into account the hypernym–hyponym relationships in knowledge graphs. Afterwards, we propose a novel interactive framework to learn conceptual preferences for users, by using k -skyband to prune unpromising objects at the beginning and employing dense subgraph to select promising candidates in each interaction round. After a small number of rounds of learning, all objects can be rationally ordered by a user’s personalized ranking function which is unknown in advance. Empirical study on two real datasets demonstrates the effectiveness of our proposed conceptual inference and preference learning based methods.},
  archive      = {J_NEUCOM},
  author       = {Jiajie Xu and Jiabao Sun and Rui Zhou and Chengfei Liu and Lihua Yin},
  doi          = {10.1016/j.neucom.2020.02.129},
  journal      = {Neurocomputing},
  pages        = {368-375},
  shortjournal = {Neurocomputing},
  title        = {CISK: An interactive framework for conceptual inference based spatial keyword query},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Few-labeled visual recognition for self-driving using
multi-view visual-semantic representation. <em>NEUCOM</em>,
<em>428</em>, 361–367. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a car self-driving system, it is vital to accurately recognize the objects on the road. This is often achieved by analyzing the images captured by various cameras. However, in real applications, we often have limited number of labeled images. Besides, it is very expensive to manually annotate objects in images. It is hard to learn reliable classifiers when only few-labeled images are available. To alleviate these problems, multi-view information is used. However, only using visual information is not enough for reliable classification. Besides, we often have limited images with labels. To cope with these problems, in this paper, we propose a novel multi-view visual-semantic representation method for few-labeled visual recognition ( MV 2 S MV2S ). We make use of the state-of-the-art deep convolutional neural networks by viewing them as different views to extract semantic representations of images. This is achieved by using the learned deep convolutional neural networks to make predictions of the semantics of images. Both the visual and semantic representations of images are then used to predict the categories of images by combining the predictions of multi-views with visual and semantic consistency constraints. Experiments on four public available datasets prove the effectiveness of the proposed MV 2 S MV2S method.},
  archive      = {J_NEUCOM},
  author       = {Da-Han Wang and Jianmin Li and Shunzhi Zhu},
  doi          = {10.1016/j.neucom.2020.02.128},
  journal      = {Neurocomputing},
  pages        = {361-367},
  shortjournal = {Neurocomputing},
  title        = {Few-labeled visual recognition for self-driving using multi-view visual-semantic representation},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Classification of malware for self-driving systems.
<em>NEUCOM</em>, <em>428</em>, 352–360. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.131">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Classification and distinguishing of malware is key to predict the malicious attack , which is essential in self-driving systems. In order to handle large number of malware variants, many machine learning methods have been proposed. However, the accuracy and efficiency of multiple class classification of malware still remained inadequate to meet demand. In this paper, we propose a 4-LFE method to deal with the issues above. We extract multi-features from malicious programs by combining pixel and n-gram features. In the process of feature selection, we apply L1-L2 penalty into the Logistic Regression , then use LDA to reduce dimensions of malware features. Based on the selected features, we study the performance of classification on ten machine learning algorithms . We assess our approach’s precision on a public dataset consisting 10,868 malware samples . Experimental results show our method could classify malware to their family with accuracy of 99.99\%.},
  archive      = {J_NEUCOM},
  author       = {Xiangyu Han and Fusheng Jin and Runan Wang and Shuliang Wang and Ye Yuan},
  doi          = {10.1016/j.neucom.2020.02.131},
  journal      = {Neurocomputing},
  pages        = {352-360},
  shortjournal = {Neurocomputing},
  title        = {Classification of malware for self-driving systems},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Social space keyword query based on semantic trajectory.
<em>NEUCOM</em>, <em>428</em>, 340–351. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.130">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the booming development of smart phones and location-based services, spatial keyword queries of semantic trajectories can take location information and multiple keywords as parameters and return semantic trajectories related to these parameters in space and text. With the development of the Location Based Social Network (LBSN) in recent years, social data can be used to improve query results. Generally, the semantic trajectory of having more supporters (users with positive comments about the location) who are more closely related to the query user is more likely to be the recommended result. Considering social information in the query can recommend more satisfactory results for users, this paper studies a new problem of semantic trajectory space keyword query: Social space Keyword Query based on semantic Trajectory (SKQT). This paper proposes a hybrid index structure that introduces social factors called Social Inverted Linear Quadtree (SIL-Quadtree) to improve the efficiency of SKQT query. The experiments use two datasets, Gowalla and Brightkite. The results show that the algorithm and index structure proposed in this paper perform better on running time and I/O.},
  archive      = {J_NEUCOM},
  author       = {Keyan Cao and Qimeng Sun and Haoli Liu and Yefan Liu and Gongjie Meng and Jingjing Guo},
  doi          = {10.1016/j.neucom.2020.02.130},
  journal      = {Neurocomputing},
  pages        = {340-351},
  shortjournal = {Neurocomputing},
  title        = {Social space keyword query based on semantic trajectory},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). TrajVAE: A variational AutoEncoder model for trajectory
generation. <em>NEUCOM</em>, <em>428</em>, 332–339. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale trajectory dataset is always required for self-driving and many other applications. In this paper, we focus on the trajectory generation problem, which aims to generate qualified trajectory dataset that is indistinguishable from real trajectories, for fulfilling the needs of large-scale trajectory data by self-driving simulation and traffic analysis tasks in data sparse cities or regions. We propose two advanced solutions, namely TrajGAN and TrajVAE, which utilize LSTM to model the characteristics of trajectories first, and then take advantage of Generative Adversarial Network (GAN) and Variational AutoEncoder (VAE) frameworks respectively to generate trajectories. In order of compare the similarity of existing trajectories in our dataset and the generated trajectories, we utilize multiple trajectory similarity metrics. Through several experiments, we demonstrate that our method is more accurate and stable than the baseline.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Chen and Jiajie Xu and Rui Zhou and Wei Chen and Junhua Fang and Chengfei Liu},
  doi          = {10.1016/j.neucom.2020.03.120},
  journal      = {Neurocomputing},
  pages        = {332-339},
  shortjournal = {Neurocomputing},
  title        = {TrajVAE: A variational AutoEncoder model for trajectory generation},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Detecting urban hot regions by using massive geo-tagged
image data. <em>NEUCOM</em>, <em>428</em>, 325–331. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting hot regions plays an important role in urban traffic planning and analytics, which is also useful in self-driving car routing and navigation. In this light, we propose and study a novel urban hot-region detection method by using massive geo-tagged image data. Given a set Q of regions (each region q is made up by a set of geo-tagged images), and a matching threshold θ θ , if a region q is matched with m other regions, its hot degree is defined by m . The hot-region detection (HRD) search finds the regions with the highest hot degrees. We believe that this type of search may benefit many applications in self-driving cars, including route planning and navigation, and traffic management and analytics in general. The HRD search is challenging due to two reasons. First, how to evaluate the similarity when matching different regions. Second, how to compute the HRD search efficiently, since its time complexity is O ( | Q | 2 ) O(|Q|2) . To overcome the challenges, we define a novel spatial-density correlation measure to evaluate the similarity between two regions, and develop a parallel search framework to process the HRD efficiently. In addition, a series of optimization techniques, e.g., pruning techniques, are defined to further enhance the query efficiency. Finally, we conduct extensive experiments on real data sets to study the performance of the developed methods.},
  archive      = {J_NEUCOM},
  author       = {Dahan Wang and Jianmin Li and Shunzhi Zhu},
  doi          = {10.1016/j.neucom.2020.03.121},
  journal      = {Neurocomputing},
  pages        = {325-331},
  shortjournal = {Neurocomputing},
  title        = {Detecting urban hot regions by using massive geo-tagged image data},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). GeoTraPredict: A machine learning system of web
spatio-temporal traffic flow. <em>NEUCOM</em>, <em>428</em>, 317–324.
(<a href="https://doi.org/10.1016/j.neucom.2020.06.121">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic flow prediction is an important component for self-driving. Traffic flow is closely related to population distribution, and the traffic flow is not only related to the absolute number of human population but also to their concerns and interests. Accurate spatio-temporal web traffic flow prediction is critical in many applications, such as bandwidth allocation , anomaly detection , congestion control and admission control. Most existing traffic flow prediction methods use models based on time-series analysis and remain inadequate for many real-world applications. Web traffic flow is found to be strongly associated with the spatio-temporal distribution of the population. Increasingly, it is critical to understand and make decisions based on the relationship between population patterns and web traffic flow patterns. It has been proven that different people have different responses to web events. Due to the complexity of spatial data structures and the huge volume of web traffic flow log data, it is difficult to routinely find the relationship between web events and population distributions without an appropriate processing framework. In this paper, we propose an innovative framework named GeoTrafficPredict to support the accurate spatio-temporal prediction of web traffic flow. GeoTrafficPredict provides a machine learning platform to learn the spatio-temporal pattern of traffic flow and use the pattern to predict the trend in both spatial and temporal dimension. Also, GeoTrafficPredict provide data aggregation portal and cloud-based computation function . GeoTrafficPredict deploys a series of computational images in a cloud computing environment , and the implementation on China’s CSTNET illustrates the performance of our platform.},
  archive      = {J_NEUCOM},
  author       = {Jingjing Li and Jun Li and Nan Jia and Xunchun Li and Wenzhen Ma and Shanshan Shi},
  doi          = {10.1016/j.neucom.2020.06.121},
  journal      = {Neurocomputing},
  pages        = {317-324},
  shortjournal = {Neurocomputing},
  title        = {GeoTraPredict: A machine learning system of web spatio-temporal traffic flow},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Virtual machine placement strategy using cluster-based
genetic algorithm. <em>NEUCOM</em>, <em>428</em>, 310–316. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of virtual machine (VM) live migration in self-driving systems targets reallocating resources among VMs running different self-driving services for load balance. It is of great importance to enable a running VM to be moved to another physical machine (host) seamlessly. Due to the nature of self-driving applications, it is important to select an optimal set of hosts to place VMs within an interactive time. The VM placement problem can be formalized as a bin packing problem , which is proved to be NP-hard. To solve the problem, we develop a cluster-based genetic algorithm that outputs an approximation result of the bin pack problem. In particular, our proposed algorithm clusters the population of current generation and selects individuals from different groups with reduced crossover operations. The number of crossover operations is directly related to the algorithm efficiency. We use the run-time features to evaluate the preference of VMs on hardware resources, which is utilized to generate initial solutions and avoid overload. Experimental results show that our approach is able to outperform the tradition genetic algorithm regarding both accuracy and efficiency.},
  archive      = {J_NEUCOM},
  author       = {Binbin Zhang and Xiao Wang and Hao Wang},
  doi          = {10.1016/j.neucom.2020.06.120},
  journal      = {Neurocomputing},
  pages        = {310-316},
  shortjournal = {Neurocomputing},
  title        = {Virtual machine placement strategy using cluster-based genetic algorithm},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep understanding of big geospatial data for self-driving
cars. <em>NEUCOM</em>, <em>428</em>, 308–309. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.119">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Shuo Shang and Jianbing Shen and Ji-Rong Wen and Panos Kalnis},
  doi          = {10.1016/j.neucom.2020.06.119},
  journal      = {Neurocomputing},
  pages        = {308-309},
  shortjournal = {Neurocomputing},
  title        = {Deep understanding of big geospatial data for self-driving cars},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pseudo-rehearsal: Achieving deep reinforcement learning
without catastrophic forgetting. <em>NEUCOM</em>, <em>428</em>, 291–307.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks can achieve excellent results in a wide variety of applications. However, when they attempt to sequentially learn, they tend to learn the new task while catastrophically forgetting previous ones. We propose a model that overcomes catastrophic forgetting in sequential reinforcement learning by combining ideas from continual learning in both the image classification domain and the reinforcement learning domain. This model features a dual memory system which separates continual learning from reinforcement learning and a pseudo-rehearsal system that “recalls” items representative of previous tasks via a deep generative network. Our model sequentially learns Atari 2600 games without demonstrating catastrophic forgetting and continues to perform above human level on all three games. This result is achieved without: demanding additional storage requirements as the number of tasks increases, storing raw data or revisiting past tasks. In comparison, previous state-of-the-art solutions are substantially more vulnerable to forgetting on these complex deep reinforcement learning tasks.},
  archive      = {J_NEUCOM},
  author       = {Craig Atkinson and Brendan McCane and Lech Szymanski and Anthony Robins},
  doi          = {10.1016/j.neucom.2020.11.050},
  journal      = {Neurocomputing},
  pages        = {291-307},
  shortjournal = {Neurocomputing},
  title        = {Pseudo-rehearsal: Achieving deep reinforcement learning without catastrophic forgetting},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bearing feature extraction using multi-structure locally
linear embedding. <em>NEUCOM</em>, <em>428</em>, 280–290. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The locally linear embedding aims to extract the significant features by only digging the individual geometric structure of original data set, for which the intrinsic features can not be completely expressed. In this study, two LLE-based multi-structure fusion methods are proposed. In the proposed methods, the least squares and sparse structures are first estimated in original space, and then the coefficient and function fusion approaches are introduced to integrate the least squares and sparse structures. Furthermore, the relationship between the two fusion methods are analyzed and we demonstrate that the solution of coefficient fusion is a subset of the one of the function fusion. Extensive experiments are carried out on benchmark fault data set and the bearing data set collected from our own laboratory, and experimental results indicate that the proposed multi-structure methods outperform the existing state-of-art related methods.},
  archive      = {J_NEUCOM},
  author       = {Yuanhong Liu and Zebiao Hu and Yansheng Zhang},
  doi          = {10.1016/j.neucom.2020.11.048},
  journal      = {Neurocomputing},
  pages        = {280-290},
  shortjournal = {Neurocomputing},
  title        = {Bearing feature extraction using multi-structure locally linear embedding},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Metaphor identification: A contextual inconsistency based
neural sequence labeling approach. <em>NEUCOM</em>, <em>428</em>,
268–279. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metaphor identification helps improve the performance of various natural language understanding tasks such as word sense disambiguation and sentiment analysis . Though many efforts have been made to deal with metaphor identification, most existing studies largely overlook a fact of contextual inconsistency of the metaphors in natural language. We observe that the greater the semantic inconsistency between current word and contextual words is, the more likely the word belongs to the metaphorical category. In this paper, we formulate the metaphor identification as a sequential tagging problem, and then develop a novel contextual inconsistency based neural sequence labeling approach, which can leverage the semantic contextual inconsistency among words of a sentence to address the problem. We propose to rely on distance metric to measure the contextual inconsistency, and evaluate four widely used distance functions in experiments. Experimental results on publicly available datasets validate the benefit of the proposed model over state-of-the-art baselines for metaphor identification.},
  archive      = {J_NEUCOM},
  author       = {Xin Chen and Zhen Hai and Suge Wang and Deyu Li and Chao Wang and Huanbo Luan},
  doi          = {10.1016/j.neucom.2020.12.010},
  journal      = {Neurocomputing},
  pages        = {268-279},
  shortjournal = {Neurocomputing},
  title        = {Metaphor identification: A contextual inconsistency based neural sequence labeling approach},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mutual-learning sequence-level knowledge distillation for
automatic speech recognition. <em>NEUCOM</em>, <em>428</em>, 259–267.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic speech recognition (ASR) is a crucial technology for man-machine interaction. End-to-end models have been studied recently in deep learning for ASR. However, these models are not suitable for the practical application of ASR due to their large model sizes and computation costs. To address this issue, we propose a novel mutual-learning sequence-level knowledge distillation framework enjoying distinct student structures for ASR. Trained mutually and simultaneously, each student learns not only from the pre-trained teacher but also from its distinct peers, which can improve the generalization capability of the whole network, through making up for the insufficiency of each student and bridging the gap between each student and the teacher. Extensive experiments on the TIMIT and large LibriSpeech corpuses show that, compared with the state-of-the-art methods, the proposed method achieves an excellent balance between recognition accuracy and model compression .},
  archive      = {J_NEUCOM},
  author       = {Zerui Li and Yue Ming and Lei Yang and Jing-Hao Xue},
  doi          = {10.1016/j.neucom.2020.11.025},
  journal      = {Neurocomputing},
  pages        = {259-267},
  shortjournal = {Neurocomputing},
  title        = {Mutual-learning sequence-level knowledge distillation for automatic speech recognition},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Audiovisual saliency prediction via deep learning.
<em>NEUCOM</em>, <em>428</em>, 248–258. (<a
href="https://doi.org/10.1016/j.neucom.2020.12.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neuroscience study verifies that synchronized audiovisual stimuli would make a stronger response of visual perception than an independent stimulus. Many researches show that audio signals would affect human gaze behavior in the viewing of natural video scenes. Thus in this paper, we propose a multi-sensory framework of audio and visual signals for video saliency prediction. It mainly includes four modules: auditory feature extraction, visual feature extraction, semantic interaction between auditory feature and visual feature, and feature fusion . With the inputs of audio and visual signals, we present a network architecture of deep learning to undertake the tasks of these four modules. It is an end-to-end architecture that could interact the semantics from its learned features of audio and visual stimuli. The numerical and visual results show our method achieves a significant improvement over eleven recent saliency models that are regardless of the audio stimuli, even some of them are state-of-the-art deep learning models .},
  archive      = {J_NEUCOM},
  author       = {Jiazhong Chen and Qingqing Li and Hefei Ling and Dakai Ren and Ping Duan},
  doi          = {10.1016/j.neucom.2020.12.011},
  journal      = {Neurocomputing},
  pages        = {248-258},
  shortjournal = {Neurocomputing},
  title        = {Audiovisual saliency prediction via deep learning},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accurately modeling the human brain functional correlations
with hypergraph laplacian. <em>NEUCOM</em>, <em>428</em>, 239–247. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The relationship between the structural connectivity (SC) of human brain networks and their functional connectivity (FC) is of immense importance in understanding brain cognition and disorders and has gained significant attention in the neuroscience over the past decade. However, the underlying mechanism of how SC gives rise to the whole pattern of FC especially the negative correlations still remains poorly understood. In this paper, we propose a model that can accurately simulate the resting-state human brain functional correlations based on hypergraph Laplacian, including the negative correlations. We firstly assume that, for each brain region, there are some links showing positive correlations and some other links showing negative correlations. Then we derive a hypergraph model with the two matrices indicating positive and negative correlations respectively using the SC of human brain network. We apply the model to two empirical datasets and the results show that the simulated FC can achieve higher Pearson correlations with the empirical FC, outperforming the state-of-art graph diffusion (GD) model.},
  archive      = {J_NEUCOM},
  author       = {Jichao Ma and Yanjiang Wang and Baodi Liu and Weifeng Liu},
  doi          = {10.1016/j.neucom.2020.11.021},
  journal      = {Neurocomputing},
  pages        = {239-247},
  shortjournal = {Neurocomputing},
  title        = {Accurately modeling the human brain functional correlations with hypergraph laplacian},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A deep neural architecture based meta-review generation and
final decision prediction of a scholarly article. <em>NEUCOM</em>,
<em>428</em>, 218–238. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Peer reviews form an essential part of scientific communications. Research papers and proposals are reviewed by several peers before they are finally accepted or rejected for publication and funding, respectively. With the steady increase in the number of research domains, scholarly venues (journal and/or conference), researchers, and papers, managing the peer review process is becoming a daunting task. Application of recommender systems to assist peer reviewing is, therefore, being explored and becoming an emerging research area. In this paper, we present a deep learning network based Meta-Review Generation considering peer review prediction of the scholarly article (MRGen). MRGen is able to provide solutions for: (i) Peer review prediction (Task 1) and (ii) Meta-review generation (Task 2). First, the system takes the peer reviews as input and produces a draft meta-review. Then it employs an integrated framework of convolution layer , long short-term memory (LSTM) model, Bi-LSTM model, and attention mechanism to predict the final decision (accept/reject) of the scholarly article. Based on the final decision, the proposed model MRGen incorporates Pointer Generator Network-based abstractive summarization to generate the final meta-review. The focus of our approach is to give a concise meta-review that maximizes information coverage, coherence, readability and also reduces redundancy. Extensive experiments conducted on the PeerRead dataset demonstrate good consistency between the recommended decisions and original decisions. We also compare the performance of MRGen with some of the existing state-of-the-art multi-document summarization methods. The system also outperforms a few existing models based on accuracy, Rouge scores, readability, non-redundancy, and cohesion.},
  archive      = {J_NEUCOM},
  author       = {Tribikram Pradhan and Chaitanya Bhatia and Prashant Kumar and Sukomal Pal},
  doi          = {10.1016/j.neucom.2020.11.004},
  journal      = {Neurocomputing},
  pages        = {218-238},
  shortjournal = {Neurocomputing},
  title        = {A deep neural architecture based meta-review generation and final decision prediction of a scholarly article},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Cascaded hourglass feature fusing network for saliency
detection. <em>NEUCOM</em>, <em>428</em>, 206–217. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks have been widely applied in saliency detection task because of its powerful feature extraction capability. Most of existing saliency detection models have achieved great progress by aggregating the strong multi-level features. However, it is still a challenging task to design the feature fusing strategy because of the various differences between multi-level features. In this paper, we explore the effect of cascaded pooling operations for saliency detection and propose a novel network to decode saliency cues from multi-level features progressively. We refer to the architecture as “cascaded hourglass” feature fusing network. The proposed network equips with three cascaded sub-modules to capture the multi-scale context and integrate multi-level features progressively. Specifically, we first propose a multi-scale context-aware feature extraction block with different dilated convolutional branches to obtain multi-scale context-aware saliency cues. Then, a hourglass feature fusing block with successive steps of pooling operations is applied to convert the features to multiple feature spaces. Furthermore, we stack a serial of the hourglass feature fusing blocks to purify the multi-level coarse features progressively. Finally, we combine the selective features with cascaded feature decoder to produce final saliency map. Extensive experiments demonstrate the proposed network compares favorably against state-of-the-art methods. Additionally, our model is efficient with the real-time speed of 28 FPS when processing a 400 × 300 400×300 image.},
  archive      = {J_NEUCOM},
  author       = {Huiyuan Luo and Guangliang Han and Xiaotian Wu and Peixun Liu and Hang Yang and Xin Zhang},
  doi          = {10.1016/j.neucom.2020.11.058},
  journal      = {Neurocomputing},
  pages        = {206-217},
  shortjournal = {Neurocomputing},
  title        = {Cascaded hourglass feature fusing network for saliency detection},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Aspect-level sentiment analysis using context and aspect
memory network. <em>NEUCOM</em>, <em>428</em>, 195–205. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the popularity of social networks, sentiment analysis has become one of the hottest topics in natural language processing (NLP). As the development of research on the fine-grained sentiment analysis , more and more researchers pay attention to aspect-level sentiment analysis. It aims to identify the same or different sentiment polarity in different aspects of the context. In this paper, a context and aspect memory network (CAMN) method is proposed to solve the problem of aspect level sentiment analysis. In this method, deep memory network, bi-directional long short-term memory network and multi-attention mechanism are introduced to better capture the sentiment features in short texts. It includes two strategies: one is to use the self-attention mechanism (i.e., CAMN-SA) to calculate the context relevance ; the other is to use the encoder-decoder attention mechanism (i.e., CAMN-ED) to calculate the context and aspect relevance. In order to verify the function of each component in the proposed method, and to test the effect of different hops on the memory network, we conduct many experiments on three real-world datasets to compare the baseline models with our proposed method. Experimental results show that our proposed method can achieve better performance than the baseline models .},
  archive      = {J_NEUCOM},
  author       = {Yanxia Lv and Fangna Wei and Lihong Cao and Sancheng Peng and Jianwei Niu and Shui Yu and Cuirong Wang},
  doi          = {10.1016/j.neucom.2020.11.049},
  journal      = {Neurocomputing},
  pages        = {195-205},
  shortjournal = {Neurocomputing},
  title        = {Aspect-level sentiment analysis using context and aspect memory network},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pinning exponential cluster synchronization for
fractional-order complex dynamical networks with switching topology and
mode-dependent impulses. <em>NEUCOM</em>, <em>428</em>, 182–194. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we focus on the global exponential cluster synchronization of switched fractional-order complex dynamical networks (FCDNs) with switching topology and impulses, where the impulse effects are independent or dependent of switched modal. Compared with the literature, impulsive effects can occur not at the mode switched moment, but also at the instants without me AII) with the average dwell time (ADT) and the mode-dependent average impulsive interval (MDAII) with the mode-dependent average dwell time, by adopting multiple Lyapunov functional approach, the inequality analysis technique and pinning control strategy, the global exponential cluster synchronization conditions are achieved. Finally, the validity of theoretical results is verified by two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Qijing Yang and Huaiqin Wu and Jinde Cao},
  doi          = {10.1016/j.neucom.2020.11.031},
  journal      = {Neurocomputing},
  pages        = {182-194},
  shortjournal = {Neurocomputing},
  title        = {Pinning exponential cluster synchronization for fractional-order complex dynamical networks with switching topology and mode-dependent impulses},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). BayeSuites: An open web framework for massive bayesian
networks focused on neuroscience. <em>NEUCOM</em>, <em>428</em>,
166–181. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {BayeSuites is the first web framework for learning, visualizing, and interpreting Bayesian networks (BNs) that can scale to tens of thousands of nodes while providing fast and friendly user experience . All the necessary features that enable this are reviewed in this paper; these features include scalability, extensibility, interoperability, ease of use, and interpretability . Scalability is the key factor in learning and processing massive networks within reasonable time; for a maintainable software open to new functionalities, extensibility and interoperability are necessary. Ease of use and interpretability are fundamental aspects of model interpretation, fairly similar to the case of the recent explainable artificial intelligence trend. We present the capabilities of our proposed framework by highlighting a real example of a BN learned from genomic data obtained from Allen Institute for Brain Science. The extensibility properties of the software are also demonstrated with the help of our BN-based probabilistic clustering implementation, together with another genomic-data example.},
  archive      = {J_NEUCOM},
  author       = {Mario Michiels and Pedro Larrañaga and Concha Bielza},
  doi          = {10.1016/j.neucom.2020.11.066},
  journal      = {Neurocomputing},
  pages        = {166-181},
  shortjournal = {Neurocomputing},
  title        = {BayeSuites: An open web framework for massive bayesian networks focused on neuroscience},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hardware-based spiking neural network architecture using
simplified backpropagation algorithm and homeostasis functionality.
<em>NEUCOM</em>, <em>428</em>, 153–165. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bio-inspired hardware-based spiking neural networks (SNNs) has been suggested as a promising computing system with low power consumption and parallel operation. We propose the supervised on-chip training method approximating the backpropagation algorithm and the pulse scheme applicable to the hardware-based SNNs with the low memory dependency. The performance evaluation through the MNIST data set classification shows that the proposed system achieves a similar recognition rate compared to that of the software-based network. In addition, we also propose novel homeostasis functionality using bias synapse to achieve high performances. The homeostasis functionality well regulates the firing rate of the neurons and improves the recognition rate. The TFT-type flash memory cells are used as synaptic devices. A fully connected two-layer neural network with non-leaky integrate-and-fire (I&amp;F) neurons is used in the simulation. We then investigate the effect of the variation of the hardware-based network on the recognition rate. The simulation results show that the proposed system is resistant to weight variation because on-chip training is adopted.},
  archive      = {J_NEUCOM},
  author       = {Jangsaeng Kim and Dongseok Kwon and Sung Yun Woo and Won-Mook Kang and Soochang Lee and Seongbin Oh and Chul-Heung Kim and Jong-Ho Bae and Byung-Gook Park and Jong-Ho Lee},
  doi          = {10.1016/j.neucom.2020.11.016},
  journal      = {Neurocomputing},
  pages        = {153-165},
  shortjournal = {Neurocomputing},
  title        = {Hardware-based spiking neural network architecture using simplified backpropagation algorithm and homeostasis functionality},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bi-DAINet: Bi-directional discard-accept-integrate network
for salient object detection. <em>NEUCOM</em>, <em>428</em>, 142–152.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent deep learning-based salient object detection methods have achieved impressive performance by leveraging multi-level convolutional features, which contain informative and complementary saliency cues. However, it remains a major challenge to make full use of multi-scale feature maps and alleviate the influence of redundant information. To address this problem, we propose a Bi-directional Discard-Accept-Integrate Network (Bi-DAINet) for salient object detection. A Discard-Accept-Integrate (DAI) module is exploited to extract meaningful messages from the feature maps and pass it to the subsequent layer. The DAI module discards redundant information of the previous layer, accepts useful information of the current layer, and integrates the remained information from multiple scales. Therefore, noisy responses are suppressed in this process. A bi-directional Convolutional Neural Network (CNN) is designed to enforce messages flowing from low-to-high level and high-to-low level, respectively. We infer a foreground map and a background map by the bi-directional CNN and then fuse them to predict a final saliency map. On one hand, low-level detailed information and high-level semantic feature are potentially integrated; on the other hand, fine-grained saliency cues around the boundary of target objects are explored. An edge-preserving loss function is further employed to ensure the boundary accuracy in prediction results. Extensive experiments on five benchmark datasets demonstrate the effectiveness and robustness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Cuili Yao and Lin Feng and Yuqiu Kong and Bo Jin and Yiwei Liu and Leheng Li},
  doi          = {10.1016/j.neucom.2020.11.035},
  journal      = {Neurocomputing},
  pages        = {142-152},
  shortjournal = {Neurocomputing},
  title        = {Bi-DAINet: Bi-directional discard-accept-integrate network for salient object detection},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Leveraging multi-level dependency of relational sequences
for social spammer detection. <em>NEUCOM</em>, <em>428</em>, 130–141.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Much recent research has shed light on developing the relation-dependent but the content-independent framework for social spammer detection. This is mainly because the relation among users is difficult to be altered when spammers attempt to conceal their malicious intentions. Our study investigates the spammer detection problem in the context of multi-relation social networks and makes an attempt to fully exploit the sequences of heterogeneous relations for enhancing the detection accuracy. Specifically, we present the Multi-level Dependency Model ( MDM ). The MDM is able to exploit the user’s long-term dependency hidden in their relational sequences along with short-term dependency. Moreover, MDM fully considers short-term relational sequences from the perspectives of individual-level and union-level, due to the fact that the type of short-term sequences is multi-folds. Experimental results on a real-world multi-relational social network demonstrate the effectiveness of our proposed MDM on multi-relational social spammer detection.},
  archive      = {J_NEUCOM},
  author       = {Jun Yin and Qian Li and Shaowu Liu and Zhiang Wu and Guandong Xu},
  doi          = {10.1016/j.neucom.2020.10.070},
  journal      = {Neurocomputing},
  pages        = {130-141},
  shortjournal = {Neurocomputing},
  title        = {Leveraging multi-level dependency of relational sequences for social spammer detection},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MIDPhyNet: Memorized infusion of decomposed physics in
neural networks to model dynamic systems. <em>NEUCOM</em>, <em>428</em>,
116–129. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating simplified or partial physics models with data-driven machine learning models is an emerging concept targeted at facilitating generalizability and extrapolability of complex system behavior predictions. In this paper, we introduce a novel machine learning based fusion model MIDPhyNet that decomposes, memorizes, and integrates first principle physics-based information with data-driven models. In MIDPhyNet the output of partial physics is decomposed into Intrinsic Mode Functions (IMFs), which are then infused to a Memorization Unit to generate embedded vectors. A Prediction Unit synthesizes all of the data to generate prediction results. We test the performance of MIDPhyNet on modeling the behavior of dynamic systems such as an inverted pendulum under wind drag. The results clearly demonstrate the performance benefits of our hybrid architecture over both purely data-driven models and state-of-art hybrid models in terms of generalizability and extrapolability. The MIDPhyNet architecture’s superiority is most significant when the models are trained over sparse data sets and in general, MIDPhyNet provides a generic way to explore how physical information can be infused with data-driven models.},
  archive      = {J_NEUCOM},
  author       = {Zhibo Zhang and Rahul Rai and Souma Chowdhury and David Doermann},
  doi          = {10.1016/j.neucom.2020.11.042},
  journal      = {Neurocomputing},
  pages        = {116-129},
  shortjournal = {Neurocomputing},
  title        = {MIDPhyNet: Memorized infusion of decomposed physics in neural networks to model dynamic systems},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Considering anatomical prior information for low-dose CT
image enhancement using attribute-augmented wasserstein generative
adversarial networks. <em>NEUCOM</em>, <em>428</em>, 104–115. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, many deep learning (DL)-based low-dose CT image postprocessing technologies fail to consider the anatomical differences in training data among different human body sites, such as the cranium, lung and pelvis. In addition, we can observe evident anatomical similarities at the same site among individuals. However, these anatomical differences and similarities are ignored in the current DL-based methods during the network training process. In this paper, we propose a deep network trained by introducing anatomical site labels, termed attributes for training data. Then, the network can adaptively learn to obtain the optimal weight for each anatomical site. By doing so, the proposed network can take full advantage of anatomical prior information to estimate high-resolution CT images. Furthermore, we employ a Wasserstein generative adversarial network (WGAN) augmented with attributes to preserve more structural details. Compared with the traditional networks that do not consider the anatomical prior and whose weights are consequently the same for each anatomical site, the proposed network achieves better performance by adaptively adjusting to the anatomical prior information.},
  archive      = {J_NEUCOM},
  author       = {Zhenxing Huang and Xinfeng Liu and Rongpin Wang and Jincai Chen and Ping Lu and Qiyang Zhang and Changhui Jiang and Yongfeng Yang and Xin Liu and Hairong Zheng and Dong Liang and Zhanli Hu},
  doi          = {10.1016/j.neucom.2020.10.077},
  journal      = {Neurocomputing},
  pages        = {104-115},
  shortjournal = {Neurocomputing},
  title        = {Considering anatomical prior information for low-dose CT image enhancement using attribute-augmented wasserstein generative adversarial networks},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploring multi-scale deformable context and channel-wise
attention for salient object detection. <em>NEUCOM</em>, <em>428</em>,
92–103. (<a href="https://doi.org/10.1016/j.neucom.2020.11.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Contextual information has played an important role in salient object detection. However, due to the fixed geometric structures of convolution kernels employed by existing Convolutional Neural Networks (CNNs) based methods, it is difficult to extract meaningfully visual contexts for those salient objects with varying sizes and non-rigid shapes. To address this problem, in this paper, we propose a Multi-Scale Deformation Module (MSDM) to capture multi-scale visual cues and varying shapes of salient objects. Moreover, most existing CNNs based methods treat all channels of feature maps equally, which tends to differ from the fact that different channels actually contribute differently to saliency prediction. For that, we involve a novel Channel-Wise Attention Mechanism (CWAM) after MSDM to highlight those informative channels while suppressing those confusing ones. Experimental results on five benchmark datasets demonstrate the superiority of the proposed method over the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Yi Liu and Mingxing Duanmu and Zhen Huo and Hang Qi and Zuntian Chen and Lei Li and Qiang Zhang},
  doi          = {10.1016/j.neucom.2020.11.022},
  journal      = {Neurocomputing},
  pages        = {92-103},
  shortjournal = {Neurocomputing},
  title        = {Exploring multi-scale deformable context and channel-wise attention for salient object detection},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards accurate HDR imaging with learning generator
constraints. <em>NEUCOM</em>, <em>428</em>, 79–91. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High dynamic range (HDR) image generation is a useful technology in various applications. An easy way to obtain an HDR image is the multiple exposures fusion technique which fuses a set of sequential exposures. However it suffers from the ghosting artifacts for scenes with significant motion objects, which is the key challenge in HDR imaging. Detecting and removing ghosting artifacts is a crucial issue for automatically generating HDR images of dynamic scenes. Although previous methods align the low dynamic range (LDR) images or detect motion regions to remove the ghosting artifacts in the final HDR, they still cannot generate a well-pleasing HDR image. In this paper, we propose a novel deep neural network with learning generator constraints called GHDRNet that blends information from all the exposures. Different from previous methods which only use ground truth to learn parameters of the network for HDR image reconstruction, our method is based on a novel successive network which not only estimates HDR results from dynamic scenes but also restores the static LDR images from the estimated HDR image. This special designed network restrains the estimated HDR image by restoring the corresponding LDR images. To capture deep hierarchical features and increase the receptive field for recovering the abundant details, we also propose an enhancement block (EBlock) that is a topology structure to aggregate several scale features. Furthermore, considering the cumbersome networks have a redundant parameter, we introduce a light-weight residual module to EBlock which effectively reduces the network parameters. Extensive evaluations show the advantages of our method over related state-of-the-art methods on three benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Qingsen Yan and Bo Wang and Lei Zhang and Jingyu Zhang and Zheng You and Qinfeng Shi and Yanning Zhang},
  doi          = {10.1016/j.neucom.2020.11.056},
  journal      = {Neurocomputing},
  pages        = {79-91},
  shortjournal = {Neurocomputing},
  title        = {Towards accurate HDR imaging with learning generator constraints},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A loss-balanced multi-task model for simultaneous detection
and segmentation. <em>NEUCOM</em>, <em>428</em>, 65–78. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scene understanding comes in many flavors, two of the most popular being object detection and semantic segmentation , which act as two important aspects for scene understanding, and are applied to many areas, such as autonomous driving and intelligent surveillance. Although much progress has already been made, the two tasks of object detection and semantic segmentation are often investigated independently. In practice, scene understanding is complicated, and comprises many sub-tasks, so that research of learning multiple tasks simultaneously with a single model is feasible. With the interrelated goals of these two tasks, there is a strong motivation to improve the object detection accuracy with the help of semantic segmentation, and vice versa. In this paper, we propose a loss-balanced multi-task model for simultaneous object detection and semantic segmentation. We explore multi-task learning with sharing parameters based on deep learning to realize improved object detection and segmentation, and propose a single-stage deep architecture based on multi-task learning, jointly performing object detection and semantic segmentation to boost each other. With no more computation load in the inference compared with the baselines of SSD and FCN , we show that these two tasks, object detection and semantic segmentation, benefit from each other. Experimental results on Pascal VOC and COCO show that our method improves much in object detection and semantic segmentation compared with the corresponding baselines of both tasks.},
  archive      = {J_NEUCOM},
  author       = {Wenwen Zhang and Kunfeng Wang and Yutong Wang and Lan Yan and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2020.11.024},
  journal      = {Neurocomputing},
  pages        = {65-78},
  shortjournal = {Neurocomputing},
  title        = {A loss-balanced multi-task model for simultaneous detection and segmentation},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Class label autoencoder with structure refinement for
zero-shot learning. <em>NEUCOM</em>, <em>428</em>, 54–64. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing zero-shot learning (ZSL) methods usually learn a projection function between a feature space and a semantic embedding space(text or attribute space) for recognizing unseen classes. However, the projection function is difficult to generalize the relationship description between the feature space and multi-semantic embedding spaces(all kinds of class names are embedded as different vectors in terms of the various semantic interpretation, for example attributes, word vectors, global vectors and hierarchical embedding), which have the diversity characteristic for detailing the different semantic information of the same class. To deal with this issue, we present a novel method to ZSL based on learning class label autoencoder with structure refinement(CLASR). CLASR can not only build a scalable framework for adapting to multi-semantic embedding spaces, but also utilize the encoder-decoder paradigm for constraining the bidirectional projection between the feature space and the class label space. Moreover, CLASR can focus on the fusion model between the relationship of feature classes (visual feature classes structure) and the relevance of the semantic classes (semantic classes structure) for improving zero-shot classification by structure refinement. The CLASR solution can provide both unseen class labels and the relation of the different classes structure(visual feature and semantic classes structure) that can encode the intrinsic structure of classes. Extensive experiments demonstrate the CLASR outperforms the state-of-art methods on four benchmark datasets, which are AwA, CUB, Dogs and ImNet-2.},
  archive      = {J_NEUCOM},
  author       = {Guangfeng Lin and Caixia Fan and Wanjun Chen and Yajun Chen and Fan Zhao},
  doi          = {10.1016/j.neucom.2020.11.061},
  journal      = {Neurocomputing},
  pages        = {54-64},
  shortjournal = {Neurocomputing},
  title        = {Class label autoencoder with structure refinement for zero-shot learning},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-stage attention spatial-temporal graph networks for
traffic prediction. <em>NEUCOM</em>, <em>428</em>, 42–53. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate traffic prediction plays an important role in Intelligent Transportation System . This problem is very challenging due to the heterogeneity and dynamic spatio-temporal dependence of large-scale traffic data. Existing models often suffer two limitations: (1) They usually only consider one type of data in the input, or simply treat other collected time series data as features, ignoring the non-linear interactions among different series. In fact, heterogeneous data at a specific location has direct impacts on the predicted series. (2) The method based on graph convolutional network uses a fixed Laplacian matrix to model spatial correlation , without considering its dynamics. The aggregations also occur only in the neighborhood, making it difficult to capture long-range dependencies. In this paper, we propose a M ulti-Stage A ttention S patial- T emporal G raph N etworks (MASTGN). First, an internal attention mechanism is designed to capture the interactions among multiple time series collected by the same sensor. Second, to model the complex spatial correlations, we apply a dynamic neighborhood-based attention mechanism . Unlike the general attention-based methods that ignore the structure information of the road network, we use the adjacency relations as a prior to divide the nodes of a road network into different neighborhood sets. In this way, attention can capture spatial correlations both within the same order neighborhood, and among different neighborhoods dynamically. Furthermore, a temporal attention mechanism is used to extract the dynamic temporal dependencies. Experiments are conducted on two real traffic datasets, and the results verify the effectiveness of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Xueyan Yin and Genze Wu and Jinze Wei and Yanming Shen and Heng Qi and Baocai Yin},
  doi          = {10.1016/j.neucom.2020.11.038},
  journal      = {Neurocomputing},
  pages        = {42-53},
  shortjournal = {Neurocomputing},
  title        = {Multi-stage attention spatial-temporal graph networks for traffic prediction},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel decentralized detection framework for
quality-related faults in manufacturing industrial processes.
<em>NEUCOM</em>, <em>428</em>, 30–41. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Quality-related fault detection is the key subject under process monitoring and fault diagnosis (PM-FD) framework, which is an effective mean to guarantee safety production and obtain reliable product quality, and thus, has recently become active areas of process control fields. In this paper, a novel decentralized detection method for quality-related faults is proposed for manufacturing industrial processes, which will help field engineers to purposefully and real-time observe the operation state of the production process. Specifically, the main innovations are: 1) the linear and nonlinear dynamic interdependencies between process and quality variables are revealed and quantified by the minimal redundancy maximal relevance (mRMR) algorithm, and the most representative variables are selected in each subprocess; 2) a new mixed kernel function based dynamic mixed kernel principal component analysis (DMKPCA) model is designed for enhancing the generalization ability and maintaining the data characteristics of original sample space; 3) unified monitoring statistics are constructed in the subprocess level, and Bayesian fusion is implemented for forming monitoring decisions from the plant-wide level. Finally, a case study on an actual hot rolling mill process (HSMP) is finally given to validate the effectiveness of the proposed scheme, and several competitive methods are applied to carry out the quality-related fault detection process.},
  archive      = {J_NEUCOM},
  author       = {Liang Ma and Jie Dong and Changjun Hu and Kaixiang Peng},
  doi          = {10.1016/j.neucom.2020.11.045},
  journal      = {Neurocomputing},
  pages        = {30-41},
  shortjournal = {Neurocomputing},
  title        = {A novel decentralized detection framework for quality-related faults in manufacturing industrial processes},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DeepPPF: A deep learning framework for predicting protein
family. <em>NEUCOM</em>, <em>428</em>, 19–29. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning pipelines for protein functional family prediction are urgently needed especially now that only 1\% of raw protein sequences have been manually annotated. Although existing machine learning algorithms have achieved a decent performance in modeling and predicting the functional families of protein sequences, they still have two drawbacks. First, biological dependencies among nucleotides are not rich enough to describe motifs for these methods. Also, existing algorithms are not accurate enough to predict the functional families of newly discovered proteins. To address the above limitations simultaneously, we propose a novel deep learning framework for predicting protein family, DeepPPF, which employs the word2vec technique in capturing distributional dependencies among nucleotides and discovers rich features from diverse motif lengths to characterize proteins. The novelty of the DeepPPF is in utilizing distributional dependencies among nucleotides. Experimental results on G protein-coupled receptor hierarchical datasets show the effectiveness of DeepPPF in achieving the state-of-the-art performance in items of Mathew’s correlation coefficients (MCC) of 97.62\%, 88.45\% and, 83.09\% for family, sub-family and, sub-subfamily hierarchical levels, respectively. Also, DeepPPF outperformed existing methods in terms of prediction accuracy and Mathew’s correlation coefficients on the cluster of orthologous groups (COG) and phage of orthologous groups (POG) datasets. Furthermore, we analyzed the ability of DeepPPF framework to discover rich motifs for functional classes with the least sets of protein sequences. The experimental results show that rich motif discovery is key to improving the modeling performance of protein families through deep learning techniques . Finally, we investigated the effect of transferring a low-level functional domain level to a high-level functional domain and results show that the target domain prediction can be improved with transfer learning . Therefore, our proposed deep learning framework can be useful in characterizing protein functional families. The codes and datasets are available at https://github.com/CSUBioGroup/DeepPPF .},
  archive      = {J_NEUCOM},
  author       = {Shehu Mohammed Yusuf and Fuhao Zhang and Min Zeng and Min Li},
  doi          = {10.1016/j.neucom.2020.11.062},
  journal      = {Neurocomputing},
  pages        = {19-29},
  shortjournal = {Neurocomputing},
  title        = {DeepPPF: A deep learning framework for predicting protein family},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive fully distributed consensus for a class of
heterogeneous nonlinear multi-agent systems. <em>NEUCOM</em>,
<em>428</em>, 12–18. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the consensus problem for a class of nonlinear multi-agent systems is investigated, where each agent is described by a first- or second-order differential equation. Due to the presence of unknown control gain, unknown parameter vector in the dynamical systems of agents, and the unknown interaction topology information, an adaptive consensus protocol is proposed. It is proven that the asymptotic consensus of the nonlinear multi-agent systems can be achieved without using any global information via the given protocol. Finally, a demonstrative example is presented in the simulation studies to illustrative the effectiveness of the given protocol.},
  archive      = {J_NEUCOM},
  author       = {Xiaoqin Feng and Yucui Yang and Dongxu Wei},
  doi          = {10.1016/j.neucom.2020.11.043},
  journal      = {Neurocomputing},
  pages        = {12-18},
  shortjournal = {Neurocomputing},
  title        = {Adaptive fully distributed consensus for a class of heterogeneous nonlinear multi-agent systems},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image guidance based 3D vehicle detection in traffic scene.
<em>NEUCOM</em>, <em>428</em>, 1–11. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {3D vehicle detection is a significant step for traffic scene understanding. Several recent works have achieved state-of-the-art performance with only LiDAR point clouds. However, there are still existing challenges due to the intrinsic limitations of lidar data. In this paper, we propose a novel 3D vehicle detection method, in which visual information is introduced to remedy the deficiency of sparse point clouds. Our method is composed of two stages. In first stage, a novel proposal generator with the guidance of visual information is proposed. In the proposal generator, 2D detected bounding boxes are registered with 3D candidates from LiDAR by calibrating and then weighted non-maximum suppression (WNMS) is applied to increase the confidence of proposals to remove redundant proposals. In second stage, to construct a box predictor, instead of sampling in a sphere space, a novel sampling with cylinder space for pointnet++ is leveraged to learn local features of the point clouds. Furthermore, to achieve a better balance between confidence and localization accuracy of boxes, an Intersection-over-Union (IoU) prediction branch is modified and attached to the network. We conduct multiple experiments on the KITTI 3D object detection dataset and compare our method with state-of-the-art methods. The comparison results show that our algorithm is effective and can improve the performance of 3D vehicle detection.},
  archive      = {J_NEUCOM},
  author       = {Deyun Dai and Jikai Wang and Zonghai Chen and Hao Zhao},
  doi          = {10.1016/j.neucom.2020.11.060},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Image guidance based 3D vehicle detection in traffic scene},
  volume       = {428},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multilayer network analysis of c. Elegans: Looking into the
locomotory circuitry. <em>NEUCOM</em>, <em>427</em>, 238–261. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate how locomotory behavior is generated in the brain focusing on the paradigmatic connectome of nematode Caenorhabditis elegans ( C. elegans ) and on neuronal and muscular activity patterns that control forward locomotion. We map the neuronal network of the worm as a multilayer network that takes into account various neurotransmitters and neuropeptides. Using logistic regression analysis, we predict the neurons of the locomotory subnetwork. Combining Hindmarsh-Rose equations for neuronal activity with a leaky integrator model for muscular activity, we study the dynamics within this subnetwork and predict the forward locomotion of the worm using a harmonic wave model. The application of time-delayed feedback control reveals synchronization patterns that contribute to a coordinated locomotion of C. elegans . Analyzing the synchronicity when the activity of certain neurons is silenced informs us about their significance for a coordinated locomotory behavior. Since the information processing is the same in humans and C. elegans , the study of the locomotory circuitry provides new insights for understanding how the brain generates motion behavior.},
  archive      = {J_NEUCOM},
  author       = {Thomas Maertens and Eckehard Schöll and Jorge Ruiz and Philipp Hövel},
  doi          = {10.1016/j.neucom.2020.11.015},
  journal      = {Neurocomputing},
  pages        = {238-261},
  shortjournal = {Neurocomputing},
  title        = {Multilayer network analysis of c. elegans: Looking into the locomotory circuitry},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph-based multi-view binary learning for image clustering.
<em>NEUCOM</em>, <em>427</em>, 225–237. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.132">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hashing techniques, also known as binary code learning, have recently attracted increasing attention in large-scale data analysis and storage. Generally, most existing hash clustering methods are single-view ones, which lack complete structure or complementary information from multiple views. For clustering tasks , most hashing research mainly mapped the original data into the Hamming space while heavily ignoring the original feature space structure. To solve these problems, we propose a novel binary code algorithm for clustering, which adopts graph embedding to preserve the original data structure , called Graph-based Multi-view Binary Learning (GMBL). The binary code learning combines the graph structure of original data and the complementary information of different views for clustering. Specifically, GMBL preserves the local linear relationship utilizing the Laplacian matrix aim to maintain the graph-based structure of the original data in Hamming space. Moreover, by automatically assigning weights for each view to improve clustering performance, which takes distinctive contributions of multiple views into considerations. Besides, an alternating iterative optimization method is designed to solve the resulting optimization problems . Extensive experimental results on five public datasets are provided to reveal the effectiveness of the algorithm and its superior performance over other state-of-the-art alternatives.},
  archive      = {J_NEUCOM},
  author       = {Guangqi Jiang and Huibing Wang and Jinjia Peng and Dongyan Chen and Xianping Fu},
  doi          = {10.1016/j.neucom.2020.07.132},
  journal      = {Neurocomputing},
  pages        = {225-237},
  shortjournal = {Neurocomputing},
  title        = {Graph-based multi-view binary learning for image clustering},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive neural decentralized output-feedback control for
nonlinear large-scale systems with input time-varying delay and
saturation. <em>NEUCOM</em>, <em>427</em>, 212–224. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a class of nonstrict-feedback nonlinear large-scale systems with input delay, saturation and unknown virtual control gains, we propose a decentralized output-feedback control scheme in this paper. In the process of control design, a novel auxiliary system is proposed to overcome the difficulty caused by time-varying input delay. The convex combination technique is used to overcome the difficulty caused by unknown virtual control gains, and further construct the state observer. Then a decentralized output-feedback controller is designed by using the adaptive neural backstepping control approach. By Lyapunov stability theory , it is proved that the proposed decentralized output-feedback controller can ensure that tracking errors converge to a small neighborhood of the origin and other closed-loop states are bounded. Finally, the results of simulation example further verify the validity of this decentralized output-feedback control scheme.},
  archive      = {J_NEUCOM},
  author       = {Ya-Dong Li and Bing Chen and Chong Lin and Yun Shang},
  doi          = {10.1016/j.neucom.2020.11.027},
  journal      = {Neurocomputing},
  pages        = {212-224},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural decentralized output-feedback control for nonlinear large-scale systems with input time-varying delay and saturation},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Residual scale attention network for arbitrary scale image
super-resolution. <em>NEUCOM</em>, <em>427</em>, 201–211. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Research on super-resolution has achieved great success on synthetic data with deep convolutional neural networks . Some recent works tend to apply super-resolution to practical scenarios. Learning an accurate and flexible model for super-resolution of arbitrary scale factor is important for realistic applications, while most existing works only focus on integer scale factor. In this work, we present a residual scale attention network for super-resolution of arbitrary scale factor. Specifically, we design a scale attention module to learn discriminative features of low-resolution images by introducing the scale factor as prior knowledge. Then, we utilize quadratic polynomial of the coordinate information and scale factor to predict pixel-wise reconstruction kernels and achieve super-resolution of arbitrary scale factor. Besides, we use the predicted reconstruction kernels in image domain to interpolate low-resolution image and obtain coarse high-resolution image first, then make our main network learn high-frequency residual image from feature domain. Extensive experiments on both synthetic and real data show that the proposed method outperforms state-of-the-art super-resolution methods of arbitrary scale factor in terms of both objective metrics and subjective visual quality.},
  archive      = {J_NEUCOM},
  author       = {Ying Fu and Jian Chen and Tao Zhang and Yonggang Lin},
  doi          = {10.1016/j.neucom.2020.11.010},
  journal      = {Neurocomputing},
  pages        = {201-211},
  shortjournal = {Neurocomputing},
  title        = {Residual scale attention network for arbitrary scale image super-resolution},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient hardware-oriented dropout algorithm.
<em>NEUCOM</em>, <em>427</em>, 191–200. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a hardware-oriented dropout algorithm, which is efficient for field programmable gate array (FPGA) implementation. In deep neural networks (DNNs), overfitting occurs when networks are overtrained and adapt too well to training data. Consequently, they fail in predicting unseen data used as test data. Dropout is a common technique that is often applied in DNNs to overcome this problem. In general, implementing such training algorithms of DNNs in embedded systems is difficult due to power and memory constraints. Training DNNs is power-, time-, and memory- intensive; however, embedded systems require low power consumption and real-time processing. An FPGA is suitable for embedded systems for its parallel processing characteristic and low operating power; however, due to its limited memory and different architecture, it is difficult to apply general neural network algorithms. Therefore, we propose a hardware-oriented dropout algorithm that can effectively utilize the characteristics of an FPGA with less memory required. Software program verification demonstrates that the performance of the proposed method is identical to that of conventional dropout, and hardware synthesis demonstrates that it results in significant resource reduction.},
  archive      = {J_NEUCOM},
  author       = {Y.J. Yeoh and T. Morie and H. Tamukoh},
  doi          = {10.1016/j.neucom.2020.11.055},
  journal      = {Neurocomputing},
  pages        = {191-200},
  shortjournal = {Neurocomputing},
  title        = {An efficient hardware-oriented dropout algorithm},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Posture coordination control of two-manipulator system using
projection neural network. <em>NEUCOM</em>, <em>427</em>, 179–190. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nowadays, there are many models/algorithms designed for redundant manipulator control. Nevertheless, two-manipulator system is usually more efficient than single manipulator. However, there are a few studies investigated for the two-manipulator system control. Specifically, the posture control of the two-manipulator system is investigated in this paper. By analyzing the kinematics and considering the control task, two posture control schemes are proposed for two manipulators, respectively. Then, a posture coordination control scheme is proposed in the form of standard quadratic programming (QP). The projection neural network (PNN) model is further developed to handle the posture coordination control scheme. In addition, a one-iteration discrete PNN (DPNN) model is proposed for convenient numerical algorithm development and digital hardware implementation. Finally, sufficient experiments based on the two-manipulator system verify the effectiveness and superiority of the posture coordination control scheme, PNN model and one-iteration DPNN model.},
  archive      = {J_NEUCOM},
  author       = {Min Yang and Yunong Zhang and Haifeng Hu},
  doi          = {10.1016/j.neucom.2020.11.012},
  journal      = {Neurocomputing},
  pages        = {179-190},
  shortjournal = {Neurocomputing},
  title        = {Posture coordination control of two-manipulator system using projection neural network},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A temporal-aware LSTM enhanced by loss-switch mechanism for
traffic flow forecasting. <em>NEUCOM</em>, <em>427</em>, 169–178. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Short-term traffic flow forecasting at isolated points is a fundamental yet challenging task in many intelligent transportation systems . We present a novel long short-term memory (LSTM) network enhanced by temporal-aware convolutional context (TCC) blocks and a new loss-switch mechanism (LSM) to carry out this task. Compared with conventional recurrent neural networks (RNN) or LSTM networks, the proposed network can capture much more distinguishable temporal features and effectively counteracting noise and outliers for more accurate prediction. The proposed TCC blocks, leveraging dilated convolution, produce an enlarged receptive field in temporal contexts, and formulate a temporal-aware attention mechanism to learn the complicated and subtle temporal features from the traffic flows. We further cascade multiple TCC blocks in the network to learn more temporal features at different scales. To deal with the noise and outliers, we propose a novel loss-switch mechanism (LSM) by combining the traditional mean square error loss and the generalized correntropy induced metric (GCIM), which is capable of effectively counteracting non-Gaussian disturbances. The whole network is trained in an end-to-end manner guided by the loss-switch mechanism. Extensive experiments are conducted on two typical benchmark datasets and the experimental results corroborate the superiority of the proposed model over state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Huakang Lu and Zuhao Ge and Youyi Song and Dazhi Jiang and Teng Zhou and Jing Qin},
  doi          = {10.1016/j.neucom.2020.11.026},
  journal      = {Neurocomputing},
  pages        = {169-178},
  shortjournal = {Neurocomputing},
  title        = {A temporal-aware LSTM enhanced by loss-switch mechanism for traffic flow forecasting},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributional representation of resting-state fMRI for
functional brain connectivity analysis. <em>NEUCOM</em>, <em>427</em>,
156–168. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most analyses on functional brain connectivity across a group of brains are under the assumption that the positions of the voxels are aligned into a common space. However, the alignment errors are inevitable. To address this issue, the distributional representation avoids the alignment in such a way that the spatial structure of connectivity is captured by the distance between voxels to preserve the relative position information. Unlike other relevant connectivity analyses that only consider connections with higher correlation values between voxels, the distributional approach takes the whole picture. It can find outliers visually in a large dataset. The centroid of a group of brains and the orbit of brains around their categorical centroid are discovered, on a basis of which a clear boundary appears between a disordered category and the control group in a distributional representation space. Moreover, it can guide correlation threshold selection for conventional brain network analysis. In contrast to the main-stream representation such as selected network properties for disease classification, the distributional representation is task-free, which provides a promising foundation for further analysis on functional brain connectivity in various ends.},
  archive      = {J_NEUCOM},
  author       = {Jiating Zhu and Jiannong Cao},
  doi          = {10.1016/j.neucom.2020.07.106},
  journal      = {Neurocomputing},
  pages        = {156-168},
  shortjournal = {Neurocomputing},
  title        = {Distributional representation of resting-state fMRI for functional brain connectivity analysis},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Minimization of the logarithmic function in sparse
recovery. <em>NEUCOM</em>, <em>427</em>, 141–155. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In sparse information recovery, the key issue is to solve the l 0 -minimization which is NP-hard. Therefore we consider the logarithmic alternative function to replace 0-norm. In this paper, theoretical analysis of logarithmic alternative model is given in detail. First, we discuss the equivalence between l 0 -minimization and the logarithmic function minimization. It is proved that the solution of the alternative model also solves the l 0 -minimization in both noiseless and noisy cases. Second, the recovery condition of logarithmic minimization is presented. By this new condition and a new concept named Logarithms Null Space Constant (L-NSC), we demonstrate the advantages of this model over classical approaches. Third, we study the optimal properties of the alternative model including the analytic property of optimal solution, a fixed point iterative algorithm and the corresponding convergence conclusion. Finally, we use the logarithmic function and the proposed algorithm to solve the multi-source time difference of arrival (TDOA) location problem. Compared with classic approaches, the experimental results demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Changlong Wang and Feng Zhou and Kaiqiang Ren and Shijie Ren Doctor},
  doi          = {10.1016/j.neucom.2020.11.033},
  journal      = {Neurocomputing},
  pages        = {141-155},
  shortjournal = {Neurocomputing},
  title        = {Minimization of the logarithmic function in sparse recovery},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). STiDi-BP: Spike time displacement based error
backpropagation in multilayer spiking neural networks. <em>NEUCOM</em>,
<em>427</em>, 131–140. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Error backpropagation is the most common approach for direct training of spiking neural networks . However, the non-differentiability of spiking neurons makes the backpropagation of error a challenge. In this paper, we introduce a new temporal learning algorithm, STiDi-BP, in which we ignore backward recursive gradient computation , and to avoid the non-differentiability of SNNs, we use a linear approximation to compute the derivative of latency with respect to the potential. We apply gradient descent to each layer independently based on an estimation of the temporal error in that layer. To do so, we calculate the desired firing time of each neuron and compare it to its actual firing time. In STiDi-BP, we employ the time-to-first-spike temporal coding, one spike per neuron, and use spiking neuron models with piecewise linear postsynaptic potential which provide large computational benefits. To evaluate the performance of the proposed learning rule, we run three experiments on the XOR problem, the face/motorbike categories of the Caltech 101 dataset, and the MNIST dataset. Experimental results show that the STiDi-BP outperforms traditional BP in terms of accuracy and/or computational cost.},
  archive      = {J_NEUCOM},
  author       = {Maryam Mirsadeghi and Majid Shalchian and Saeed Reza Kheradpisheh and Timothée Masquelier},
  doi          = {10.1016/j.neucom.2020.11.052},
  journal      = {Neurocomputing},
  pages        = {131-140},
  shortjournal = {Neurocomputing},
  title        = {STiDi-BP: Spike time displacement based error backpropagation in multilayer spiking neural networks},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Recalibration convolutional networks for learning
interaction knowledge graph embedding. <em>NEUCOM</em>, <em>427</em>,
118–130. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.137">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge graph embedding aims to learn the embedded representation of entities and relations in knowledge graphs which is very important for the subsequent link prediction task. However, two key issues are existed for learning knowledge graph embedding: 1) How to take full advantage of the deep learning algorithms to generate expressive embeddings? 2) How to solve the polysemy phenomenon caused by multi-relations knowledge graphs that entities and relations show different semantics after involving different predictions? In this article, to tackle the first problem, the multi-layer convolutional networks are adopted to generate features about entities and relations then used to predict candidate entity. Moreover, the representation power of the networks is strengthened by integrating an effective recalibration mechanism which can accentuate informative features selectively. To tackle the second problem, we propose to learn multiple specific interaction embeddings. Instead of directly learning one general embedding to preserve all information for each entity and relation, their interactions are captured to model the cross-semantic influence from relations to entities and from entities to relations. Compared to traditional embedding models, the proposed model can provide more generalization capabilities and effectively capture potential links between entities and relations. Experimental results have revealed that the proposed model achieves the state-of-the-art performance for general evaluation metrics on link prediction tasks.},
  archive      = {J_NEUCOM},
  author       = {Zhifei Li and Hai Liu and Zhaoli Zhang and Tingting Liu and Jiangbo Shu},
  doi          = {10.1016/j.neucom.2020.07.137},
  journal      = {Neurocomputing},
  pages        = {118-130},
  shortjournal = {Neurocomputing},
  title        = {Recalibration convolutional networks for learning interaction knowledge graph embedding},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronization of coupled memristive competitive BAM neural
networks with different time scales. <em>NEUCOM</em>, <em>427</em>,
110–117. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, synchronization of coupled memristive competitive bidirectional associative memory (BAM) neural networks with different time scales is discussed. Two kinds of feedback controllers are designed such that the response system and the drive system can reach synchronization. By using the differential inclusions theory, and constructing a proper Lyapunov–Krasovskii functional, novel sufficient conditions are obtained to achieve asymptotical synchronization of competitive BAM neural networks . The proposed synchronization can be easily realized. An illustrative example is given to show the feasibility of our theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Yong Zhao and Shanshan Ren and Jürgen Kurths},
  doi          = {10.1016/j.neucom.2020.11.023},
  journal      = {Neurocomputing},
  pages        = {110-117},
  shortjournal = {Neurocomputing},
  title        = {Synchronization of coupled memristive competitive BAM neural networks with different time scales},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new method for intelligent fault diagnosis of machines
based on unsupervised domain adaptation. <em>NEUCOM</em>, <em>427</em>,
96–109. (<a href="https://doi.org/10.1016/j.neucom.2020.10.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data driven fault diagnosis has attracted a lot of attention in recent years owing to its intelligent and accurate detection of fault categories. However, it is a challenge for its applications in real world. The abundant labeled data is extremely necessary for data driven fault diagnosis to train a favorable model. Even though enough labeled data is prepared for training a model, we still cannot ensure the data used for training and testing draw from identical distribution. In other words, the labeled source domain has different distribution compared with the unlabeled target domain. In this paper, we introduce the domain adaptation strategy into deep neural networks to propose a deep domain adaptation architecture, which realizes to learn knowledge from the labeled source domain to facilitate the target classification. In the proposed model, the conditional and marginal distribution are adapted together in multiple layers of neural network, which uses MMD to measure the distribution discrepancy. Besides, the relative importance between marginal and conditional distributions is explored, and an adaptively weighted strategy is further introduced to learn the relative importance of the two distributions. To evaluate the proposed method, we conduct the simulations on different workloads, sensor deployment locations, and even different platforms. The results show the superiority of the proposed model to other intelligent fault diagnosis methods, meanwhile verify the necessity of marginal and conditional distribution adaptation and adaptive weighted strategy.},
  archive      = {J_NEUCOM},
  author       = {Nannan Lu and Hanhan Xiao and Yanjing Sun and Min Han and Yanfen Wang},
  doi          = {10.1016/j.neucom.2020.10.039},
  journal      = {Neurocomputing},
  pages        = {96-109},
  shortjournal = {Neurocomputing},
  title        = {A new method for intelligent fault diagnosis of machines based on unsupervised domain adaptation},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cauchy loss induced block diagonal representation for robust
multi-view subspace clustering. <em>NEUCOM</em>, <em>427</em>, 84–95.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid emergence of data that can be described by different feature sets or different “views”, multi-view subspace clustering has attracted considerable research attention. To uncover the common latent structure shared by multiple views, existing models usually impose the sparse or/and low-rank constraint on the coefficients of each view data, and use Frobenius norm or ℓ 1 ℓ1 -norm based metric to measure the residuals of multi-view data. However, the intuition behind the sparse or low-rank regularization is implicit. Besides, the Frobenius norm or ℓ 1 ℓ1 -norm based metric is suitable to handle either Gaussian noise or sparse noise, which are very sensitive to larger noise or outliers. When the data is contaminated by large noise or densely corrupted, performance of existing models is degraded dramatically. In this article, we propose a novel multi-view subspace clustering method to provide superior robustness against large noise or outliers embedded in multi-view data. Our method adopts a more direct and intuitive block diagonal regularization to preserve the underlying structure of each view, and meantime introduces the cauchy loss function to deal with large noise. The derived consensus representation matrix can effectively preserve the underlying common structure of multi-view data and be robust to large noise and data corruptions. Experimental results show that our method outperforms the state-of-the-arts on both synthetic and real-world benchmark datasets.},
  archive      = {J_NEUCOM},
  author       = {Ming Yin and Wei Liu and Mingsuo Li and Taisong Jin and Rongrong Ji},
  doi          = {10.1016/j.neucom.2020.11.017},
  journal      = {Neurocomputing},
  pages        = {84-95},
  shortjournal = {Neurocomputing},
  title        = {Cauchy loss induced block diagonal representation for robust multi-view subspace clustering},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-scale attention u-net for segmenting clinical target
volume in graves’ ophthalmopathy. <em>NEUCOM</em>, <em>427</em>, 74–83.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graves’ ophthalmopathy (GO) is an autoimmune inflammatory disorder associated with thyroid disease, and radiotherapy is an effective treatment that causes few side effects among patients in the moderate-to-severe stage. The clinical target volume (CTV) refers to tissues with potential tumor spread or subclinical diseases, where accurate segmentation of these tissues is required for the successful radiotherapy. Traditional segmentation methods for the CTV are based on low-level hand-crafted features that require significant domain knowledge and sensitive to the variations. To overcome these shortcomings, a novel neural network architecture called multi-scale attention U-Net (MAU-Net) is proposed to automatically segment the CTV by computed tomography for GO disease. Abstract features ranging from low- to high-levels are extracted by a deep residual network , then processed by a multi-scale module composed of multiple convolutional operations to accommodate various scales of the CTV. A novel attention module is proposed and applied following the multi-scale module, which uses signals from high-level features to selectively highlight the low-features. A total of 178 CT cases are used to train and evaluate the proposed MAU-Net. The experimental results show that MAU-Net achieves higher segmentation accuracy than the state-of-the-art methods. The MAU-Net converges more quickly in the training phase, and achieves lower error on the validation dataset than the vanilla U-Net.},
  archive      = {J_NEUCOM},
  author       = {Junjie Hu and Ying Song and Lei Zhang and Sen Bai and Zhang Yi},
  doi          = {10.1016/j.neucom.2020.11.028},
  journal      = {Neurocomputing},
  pages        = {74-83},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale attention U-net for segmenting clinical target volume in graves’ ophthalmopathy},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Training deep neural networks for wireless sensor networks
using loosely and weakly labeled images. <em>NEUCOM</em>, <em>427</em>,
64–73. (<a href="https://doi.org/10.1016/j.neucom.2020.09.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although deep learning has achieved remarkable successes over the past years, few reports have been published about applying deep neural networks to Wireless Sensor Networks (WSNs) for image targets recognition where data, energy, computation resources are limited. In this work, a Cost-Effective Domain Generalization (CEDG) algorithm has been proposed to train an efficient network with minimum labor requirements. CEDG transfers networks from a publicly available source domain to an application-specific target domain through an automatically allocated synthetic domain. The target domain is isolated from parameters tuning and used for model selection and testing only. The target domain is significantly different from the source domain because it has new target categories and is consisted of low-quality images that are out of focus, low in resolution, low in illumination, low in photographing angle. The trained network has about 7 M (ResNet-20 is about 41 M) multiplications per prediction that is small enough to allow a digital signal processor chip to do real-time recognitions in our WSN. The category-level averaged error on the unseen and unbalanced target domain has been decreased by 41.12\%.},
  archive      = {J_NEUCOM},
  author       = {Qianwei Zhou and Yuhang Chen and Baoqing Li and Xiaoxin Li and Chen Zhou and Jingchang Huang and Haigen Hu},
  doi          = {10.1016/j.neucom.2020.09.040},
  journal      = {Neurocomputing},
  pages        = {64-73},
  shortjournal = {Neurocomputing},
  title        = {Training deep neural networks for wireless sensor networks using loosely and weakly labeled images},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021f). Traffic flow prediction over muti-sensor data correlation
with graph convolution network. <em>NEUCOM</em>, <em>427</em>, 50–63.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate and real-time traffic flow prediction plays an important role in improving the traffic planning capability of intelligent traffic systems. However, traffic flow prediction is a very challenging problem because the spatial–temporal correlation among roads is complex and changeable. Most of the existing methods do not reasonably analyze the dynamic spatial–temporal correlation caused by the changing relationship of traffic patterns among roads, thus cannot get satisfactory results in the medium and long-term traffic prediction . To address these issues, a novel M ultisensor D ata C orrelation G raph C onvolution N etwork model, named MDCGCN, is proposed in this paper. The MDCGCN model consists of three parts: recent, daily period and weekly period components, and each of which consists of two parts: 1) benchmark adaptive mechanism and 2) multisensor data correlation convolution block. The first part can eliminate the differences among the periodic data and effectively improve the quality of data input. The second part can effectively capture the dynamic temporal and spatial correlation caused by the changing relationship of traffic patterns among roads. Through substantial experiments conducted on two real data sets , results indicate that the proposed MDCGCN model can significantly improve the medium and long-term prediction accuracy for traffic networks of different sizes, and is superior to existing prediction methods.},
  archive      = {J_NEUCOM},
  author       = {Wei Li and Xin Wang and Yiwen Zhang and Qilin Wu},
  doi          = {10.1016/j.neucom.2020.11.032},
  journal      = {Neurocomputing},
  pages        = {50-63},
  shortjournal = {Neurocomputing},
  title        = {Traffic flow prediction over muti-sensor data correlation with graph convolution network},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic ultrasound image report generation with adaptive
multimodal attention mechanism. <em>NEUCOM</em>, <em>427</em>, 40–49.
(<a href="https://doi.org/10.1016/j.neucom.2020.09.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text report writing for medical images is a fundamental task for diagnosis and treatment in clinical medicine. However, this work is tedious and time-consuming because of the special report features (e.g., boundary conditions and fixed templates). The existing works mainly adopt image captioning methods for medical report generation but the special report features are not fully considered in these models. This paper proposes an Adaptive Multimodal Attention network (AMAnet) to generate high-quality medical image reports. First, a Multi-Label Classification network is designed to predict the essential local properties. And then the word embedding vectors of these properties can serve as the semantic features to aid report generation. Second, we develop a semantic attention mechanism to imitate the spatial attention. Third, we introduce an adaptive attention mechanism with a sentinel gate to control the attention level at current visual features and language model memories when generating the next word. Experimental results demonstrate AMAnet outperforms the state-of-the-art image captioning methods with over 1 CIDEr score improvement.},
  archive      = {J_NEUCOM},
  author       = {Shaokang Yang and Jianwei Niu and Jiyan Wu and Yong Wang and Xuefeng Liu and Qingfeng Li},
  doi          = {10.1016/j.neucom.2020.09.084},
  journal      = {Neurocomputing},
  pages        = {40-49},
  shortjournal = {Neurocomputing},
  title        = {Automatic ultrasound image report generation with adaptive multimodal attention mechanism},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A proportional-integral-derivative-incorporated stochastic
gradient descent-based latent factor analysis model. <em>NEUCOM</em>,
<em>427</em>, 29–39. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large-scale relationships like user-item preferences in a recommender system are mostly described by a high-dimensional and sparse (HiDS) matrix. A latent factor analysis (LFA) model extracts useful knowledge from an HiDS matrix efficiently, where stochastic gradient descent (SGD) is frequently adopted as the learning algorithm. However, a standard SGD algorithm updates a decision parameter with the stochastic gradient on the instant loss only, without considering information described by prior updates. Hence, an SGD-based LFA model commonly consumes many iterations to converge, which greatly affects its practicability. On the other hand, a proportional-integral-derivative (PID) controller makes a learning model converge fast with the consideration of its historical errors from the initial state till the current moment. Motivated by this discovery, this paper proposes a P ID-incorporated S GD-based L FA (PSL) model. Its main idea is to rebuild the instant error on a single instance following the principle of PID, and then substitute this rebuilt error into an SGD algorithm for accelerating model convergence. Empirical studies on six widely-accepted HiDS matrices indicate that compared with state-of-the-art LFA models, a PSL model achieves significantly higher computational efficiency as well as highly competitive prediction accuracy for missing data of an HiDS matrix.},
  archive      = {J_NEUCOM},
  author       = {Jinli Li and Ye Yuan and Tao Ruan and Jia Chen and Xin Luo},
  doi          = {10.1016/j.neucom.2020.11.029},
  journal      = {Neurocomputing},
  pages        = {29-39},
  shortjournal = {Neurocomputing},
  title        = {A proportional-integral-derivative-incorporated stochastic gradient descent-based latent factor analysis model},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). GEME: Dual-stream multi-task GEnder-based micro-expression
recognition. <em>NEUCOM</em>, <em>427</em>, 13–28. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recognition of micro-expressions remains a topic of concern considering its brief span and low intensity. This issue is addressed through convolutional neural networks (CNNs) by developing multi-task learning (MTL) method to effectively leverage a side task: gender detection. A dual-stream multi-task framework called GEME is introduced that recognises micro-expressions by incorporating unique gender characteristics and subsequently improves the micro-expression recognition accuracy. This research aims to examine how gender differences influence the way micro-expressions are displayed. The current study proves that selecting relevant features of micro-expressions distinctive to the gender and added to the micro-expression features improves the micro-expression recognition accuracy. This network learns gender-specific features and micro-expression features and adds them together to learn the combination of shared and task-specific representations. A multi-class focal loss is used to mitigate the class imbalance issue by down-weighing the easy samples and concentrate more on misclassified samples. The Class-Balanced (CB) focal loss is also implemented for a better class balancing during Leave-One-Subject-Out (LOSO) validations where CB loss re-balances and re-weights the loss. The experimental results on three widely used databases demonstrate the improved performance of the proposed network and achieve comparable results with the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Xuan Nie and Madhumita A. Takalkar and Mengyang Duan and Haimin Zhang and Min Xu},
  doi          = {10.1016/j.neucom.2020.10.082},
  journal      = {Neurocomputing},
  pages        = {13-28},
  shortjournal = {Neurocomputing},
  title        = {GEME: Dual-stream multi-task GEnder-based micro-expression recognition},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reward fairness-based optimal distributed real-time pricing
to enable supply–demand matching. <em>NEUCOM</em>, <em>427</em>, 1–12.
(<a href="https://doi.org/10.1016/j.neucom.2020.11.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time pricing (RTP) is the pivotal component of demand response (DR) that promotes the power utilization of users in a cost-efficient way. This paper presents a reward fairness-based distributed RTP (RFbDRTP) framework for electric users to reduce the electricity consumption cost as well as experience the fairness from participating in DR. In RFbDRTP, a behavior welfare model (BWM) is developed to exploit the reward fairness strategy that returns the cost savings as a reward to the users in proportion to their load increase or decrease in DR. The model can motivate users to react to the price signal through adjusting their electricity consumption patterns, to in turn enable optimal distributed RTP for matching supply–demand. In this paper, users are assumed to interact with each other because of pricing based on the imbalance between load demand and electricity supply. We formulate the interactions among the users into a noncooperative game and give a sufficient condition to ensure the unique equilibrium in the game. After that, we develop a distributed algorithm and give a sufficient convergence condition of the algorithm. The simulation results show that the proposed RFbDRTP is effective in motivating users to participate in DR and matching demand with supply, and the distributed algorithm can converge to the equilibrium with a significant convergence rate.},
  archive      = {J_NEUCOM},
  author       = {L.L. Wang and J.J. Chen and K. Peng and Y.L. Zhao and X.H. Zhang},
  doi          = {10.1016/j.neucom.2020.11.034},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Reward fairness-based optimal distributed real-time pricing to enable supply–demand matching},
  volume       = {427},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design and analysis of a noise-suppression zeroing neural
network approach for robust synchronization of chaotic systems.
<em>NEUCOM</em>, <em>426</em>, 299–308. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust synchronization of chaotic systems with time-varying external disturbances is a hot topic in the field of science and engineering. In view of the negative influence of complex noise on the synchronization of chaotic systems, a noise-suppression zeroing neural network (NSZNN) is designed and proposed to effectively resist time-varying external disturbances. Compared with existing zeroing neural network models only for bounded noise, the proposed (NSZNN) model has consistent robustness for both bounded and unbounded noises. Furthermore, the design process, theoretical analysis and numerical verification of the NSZNN are presented in detail. Both theoretical and numerical results show that the NSZNN has better synchronization control performance of chaotic systems under bounded and unbounded noises, as compared with existing zeroing neural network models.},
  archive      = {J_NEUCOM},
  author       = {Jianhua Dai and Yingkun Cao and Lin Xiao and Haiyan Tan and Lei Jia},
  doi          = {10.1016/j.neucom.2020.10.035},
  journal      = {Neurocomputing},
  pages        = {299-308},
  shortjournal = {Neurocomputing},
  title        = {Design and analysis of a noise-suppression zeroing neural network approach for robust synchronization of chaotic systems},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). STConvS2S: Spatiotemporal convolutional sequence to sequence
network for weather forecasting. <em>NEUCOM</em>, <em>426</em>, 285–298.
(<a href="https://doi.org/10.1016/j.neucom.2020.09.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Applying machine learning models to meteorological data brings many opportunities to the Geosciences field, such as predicting future weather conditions more accurately. In recent years, modeling meteorological data with deep neural networks has become a relevant area of investigation. These works apply either recurrent neural networks (RNN) or some hybrid approach mixing RNN and convolutional neural networks (CNN). In this work, we propose STConvS2S (Spatiotemporal Convolutional Sequence to Sequence Network), a deep learning architecture built for learning both spatial and temporal data dependencies using only convolutional layers . Our proposed architecture resolves two limitations of convolutional networks to predict sequences using historical data: (1) they violate the temporal order during the learning process and (2) they require the lengths of the input and output sequences to be equal. Computational experiments using air temperature and rainfall data from South America show that our architecture captures spatiotemporal context and that it outperforms or matches the results of state-of-the-art architectures for forecasting tasks. In particular, one of the variants of our proposed architecture is 23\% better at predicting future sequences and five times faster at training than the RNN-based model used as a baseline.},
  archive      = {J_NEUCOM},
  author       = {Rafaela Castro and Yania M. Souto and Eduardo Ogasawara and Fabio Porto and Eduardo Bezerra},
  doi          = {10.1016/j.neucom.2020.09.060},
  journal      = {Neurocomputing},
  pages        = {285-298},
  shortjournal = {Neurocomputing},
  title        = {STConvS2S: Spatiotemporal convolutional sequence to sequence network for weather forecasting},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design, analysis and verification of recurrent neural
dynamics for handling time-variant augmented sylvester linear system.
<em>NEUCOM</em>, <em>426</em>, 274–284. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Augmented Sylvester linear system (ASLS) is one of the most important issues in various science and engineering fields. In this study, two recurrent neural dynamics (RND) methods in a continuous-time manner (termed as CTRND) and a discrete-time manner (termed as DTRND) are proposed for handling the continuous-form time-variant ASLS (CF-TV-ASLS) and discrete-form time-variant ASLS (DF-TV-ASLS), respectively. Specifically, first of all, aided with the Kronecker product and vectorization techniques, the CF-TV-ASLS is finally transformed into a continuous-form time-variant matrix-vector equation (CF-TV-MVE) by introducing an additional time-variant nonnegative variable. Analogously, the corresponding DF-TV-ASLS is transformed into a discrete-form time-variant matrix-vector equation (DF-TV-MVE). Whereafter, by exploiting the RND design formula, the CTRND method and DTRND method are proposed and investigated for solving obtained CF-TV-MVE and DF-TV-MVE, respectively. In addition, theoretical analyses about the convergence of CTRND method and DTRND method are presented. Finally, the instructive experiments, including a continuous-time example and a corresponding discrete-time one, substantiate the efficacy and superiority of the proposed CTRND method and DTRND method.},
  archive      = {J_NEUCOM},
  author       = {Yang Shi and Chao Mou and Yimeng Qi and Bin Li and Shuai Li and Baoqing Yang},
  doi          = {10.1016/j.neucom.2020.10.036},
  journal      = {Neurocomputing},
  pages        = {274-284},
  shortjournal = {Neurocomputing},
  title        = {Design, analysis and verification of recurrent neural dynamics for handling time-variant augmented sylvester linear system},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Selective generative adversarial network for raindrop
removal from a single image. <em>NEUCOM</em>, <em>426</em>, 265–273. (<a
href="https://doi.org/10.1016/j.neucom.2020.06.134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The removal of raindrops from a single image is still challenging because of the diversity and density of raindrops existing in the rainy image. Moreover, the colors of raindrops are constantly changing with the background which also makes the raindrops cannot be well removed by using the current methods. In this paper, we tackle these limitations by combining the raindrops shape features with the background structure features to guide the network to accurately remove raindrops. Specifically, we propose a selective skip connection GAN (SSCGAN) combining the selective skip connection and self-attention mechanism to restoring the clean image from a raindrop degraded one. Our main idea is selectively transmitting the information of raindrops to the decoder through Gated Recurrent Units (GRU) to better generate a clean image. During the training, the selective skip connection model (SSCM) extract raindrops binary mask from the rainy image and eliminate the interference of background noise. Simultaneously, we use self-attention blocks (SABs) to make the generator network pay more attention to global structure features of the rainy image and conversely correct the raindrops binary mask. Experiments show that our method has better performance than previous methods.},
  archive      = {J_NEUCOM},
  author       = {Mingwen Shao and Le Li and Hong Wang and Deyu Meng},
  doi          = {10.1016/j.neucom.2020.06.134},
  journal      = {Neurocomputing},
  pages        = {265-273},
  shortjournal = {Neurocomputing},
  title        = {Selective generative adversarial network for raindrop removal from a single image},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A proactive autoscaling and energy-efficient VM allocation
framework using online multi-resource neural network for cloud data
center. <em>NEUCOM</em>, <em>426</em>, 248–264. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work proposes an energy-efficient resource provisioning and allocation framework to meet dynamic demands of the future applications. The frequent variations in a cloud user’s resource demand leads to the problem of an excess power consumption, resource wastage, performance and Quality-of-Service (QoS) degradation. The proposed framework addresses these challenges by matching the application’s predicted resource requirement with resource capacity of VMs precisely and thereby consolidating entire load on the minimum number of energy-efficient physical machines (PMs). The three consecutive contributions of the proposed work are: (1) Online Multi-Resource Feed-forward Neural Network (OM-FNN) to forecast the multiple resource demands concurrently for the future applications, (2) autoscaling of VMs based on the clustering of the predicted resource requirements, (3) allocation of the scaled VMs on the energy-efficient PMs. The integrated approach successively optimizes resource utilization, saves energy and automatically adapts to the changes in future application resource demand. The proposed framework is evaluated by using real workload traces of the benchmark Google Cluster Dataset and compared against different scenarios including energy-efficient VM placement (VMP) with resource prediction only, VMP without resource prediction and autoscaling, and optimal VMP with autoscaling based on actual resource utilization. The observed results demonstrate that the proposed integrated approach achieves near-optimal performance against optimal VMP and outperforms rest of the VMPs in terms of power saving and resource utilization up to 88.5\% and 21.12\% respectively. In addition, OM-FNN predictor shows better accuracy, lesser time and space complexity over a traditional single-input and single-output feed-forward neural network (SISO-FNN) predictor.},
  archive      = {J_NEUCOM},
  author       = {Deepika Saxena and Ashutosh Kumar Singh},
  doi          = {10.1016/j.neucom.2020.08.076},
  journal      = {Neurocomputing},
  pages        = {248-264},
  shortjournal = {Neurocomputing},
  title        = {A proactive autoscaling and energy-efficient VM allocation framework using online multi-resource neural network for cloud data center},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attentive preference personalized recommendation with
sentence-level explanations. <em>NEUCOM</em>, <em>426</em>, 235–247. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Personalized recommendation mostly employs users’ historical data to improve their user profiles, and these profiles are then used as the bases for recommendations. Because reviews can contain a large amount of information regarding user preferences and item features, they can be naturally into recommender systems (RSs) as contextual information, thus solving the problem of data sparsity and helping to provide personalized recommendations. The existing technology mainly extracts latent representations of users or items in an independent and static manner. We argue that static embedding cannot fully capture a user&#39;s preferences. Indeed, a user will have different preferences corresponding to different items. This type of review-based recommendation model cannot provide a personalized, and complete semantic explanation of a candidate recommendation item to a user. In this paper, we introduce an attention mechanism to explore the importance of specific sentences in reviews for different users and propose a novel a ttentive p reference personalized recommendation with s entence-level e xplanations (APSE). The APSE employs the latent features of users and items and the latent factors of their pairwise interactions to obtain review representations. Then, the APSE uses probability matrix factorization to model additional high-level feature interactions based on these user-item pairs for rating prediction. We implement review feature learning in the APSE to exploit review data in which an attentive mechanism is used to highlight the influences of words and sentences to achieve focused paragraph embedding. Finally, the APSE also employs an explanation sentence judgment mechanism that implements the user-item pair interaction method to extract comments or statements that pertain to user preferences as recommendation interpretations. Experiments are performed on real-world datasets for validation. Additionally, we show the important words and sentences highlighted by the attentive mechanism. At the end of the experiment, a specific item explanation for a user is produced and compared with the user&#39;s existing comments. The results show that the performance of the APSE can exceed that of various recommended models when the available ratings are limited.},
  archive      = {J_NEUCOM},
  author       = {Jin Xie and Fuxi Zhu and Xuefei Li and Sheng Huang and Shichao Liu},
  doi          = {10.1016/j.neucom.2020.10.041},
  journal      = {Neurocomputing},
  pages        = {235-247},
  shortjournal = {Neurocomputing},
  title        = {Attentive preference personalized recommendation with sentence-level explanations},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards unsupervised text multi-style transfer with
parameter-sharing scheme. <em>NEUCOM</em>, <em>426</em>, 227–234. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text style transfer is an important task in the field of natural language generation . Because of the lack of parallel data, it is a challenge to address this problem in an unsupervised manner . Existing methods mainly focus on the two-style transfer task, i.e. from one source style to one target style. In this paper, we first propose the task of unsupervised text multi-style transfer to address the problem of efficient text transfer from a source style to multiple target styles. To tackle this new task, we present a novel model based on Non-Autoregressive Transformer (NAT). The model consists of two parts: a parameter-shared style-independent module and a style-dependent module. In practice, we only need to reinitialize the parameter of style-dependent modules and retrain the whole model which can converge fast. Experimental results show that our model not only performs well in two-style transfer task, but also promises good results in the multi-style scenario.},
  archive      = {J_NEUCOM},
  author       = {Xi Chen and Song Zhang and Gehui Shen and Zhi-Hong Deng and Unil Yun},
  doi          = {10.1016/j.neucom.2020.09.064},
  journal      = {Neurocomputing},
  pages        = {227-234},
  shortjournal = {Neurocomputing},
  title        = {Towards unsupervised text multi-style transfer with parameter-sharing scheme},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Disentangled features with direct sum decomposition for
zero shot learning. <em>NEUCOM</em>, <em>426</em>, 216–226. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The core problem of zero-shot learning (ZSL) is extracting concise feature from cumbersome and intricate semantic space. While semantic vectors were mainly used to constrain the distance between different classes in embedding space in existing ZSL methods, we first emphasize the importance of the relationship between different dimensions in semantic space. In this paper, we propose a novel inductive approach, Multiple Semantic Subspaces Network (MSSN), to simplify the complex and intractable semantic features . Our method generates multiple disentangled subfeatures via direct sum decomposition, which not only retain completely semantic information, but also obtain simple independent hierarchical features. Specially, instead of original space, using projection subspace to map embedding space can reduce the difficulty of model optimization and enhance the generalization ability of the model. Full experiments are achieved on almost all datasets and comparision with many algorithms which exist in the present latest literature. Compared with nineteen competitors, the results show that our model outperforms the state-of-the-art on conventional ZSL setting and has a very competitive performance on generalized ZSL setting.},
  archive      = {J_NEUCOM},
  author       = {Bonan Li and Congying Han and Tiande Guo and Tong Zhao},
  doi          = {10.1016/j.neucom.2020.09.065},
  journal      = {Neurocomputing},
  pages        = {216-226},
  shortjournal = {Neurocomputing},
  title        = {Disentangled features with direct sum decomposition for zero shot learning},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). New ideas and trends in deep multimodal content
understanding: A review. <em>NEUCOM</em>, <em>426</em>, 195–215. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The focus of this survey is on the analysis of two modalities of multimodal deep learning: image and text. Unlike classic reviews of deep learning where monomodal image classifiers such as VGG, ResNet and Inception module are central topics, this paper will examine recent multimodal deep models and structures, including auto-encoders, generative adversarial nets and their variants. These models go beyond the simple image classifiers in which they can do uni-directional ( e.g. image captioning, image generation) and bi-directional ( e.g. cross-modal retrieval, visual question answering) multimodal tasks. Besides, we analyze two aspects of the challenge in terms of better content understanding in deep multimodal applications. We then introduce current ideas and trends in deep multimodal feature learning, such as feature embedding approaches and objective function design, which are crucial in overcoming the aforementioned challenges. Finally, we include several promising directions for future research.},
  archive      = {J_NEUCOM},
  author       = {Wei Chen and Weiping Wang and Li Liu and Michael S. Lew},
  doi          = {10.1016/j.neucom.2020.10.042},
  journal      = {Neurocomputing},
  pages        = {195-215},
  shortjournal = {Neurocomputing},
  title        = {New ideas and trends in deep multimodal content understanding: A review},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-modal constraint propagation via compatible
conditional distribution reconstruction. <em>NEUCOM</em>, <em>426</em>,
185–194. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In many applications, the pairwise constraint is a kind of weaker supervisory information which can be collected more efficiently than the label information. The constraint propagation is a constrained clustering approach , which has been proved to be a success of exploiting such side-information. Recent years have witnessed many methods of multi-modal constraint propagation . However, the problem of reasonably fusing different modalities under the framework of constraint propagation remains unaddressed. In this paper, we first identify a necessary and sufficient condition for compatible conditional distributions under a specific assumption and address the problem of Compatible Conditional Distributions Reconstruction (CCDR). With the help of CCDR, we propose a multi-modal constraint propagation method dubbed Instance Level Multi-Modal Constraint Propagation (ILMCP). ILMCP fuses the affinity of different modalities at the data instance level instead of the modality level and constructs a unified affinity matrix . Extensive experiments on two publicly available multi-modal datasets show the superior performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Yaoyi Li and Hongtao Lu},
  doi          = {10.1016/j.neucom.2020.09.067},
  journal      = {Neurocomputing},
  pages        = {185-194},
  shortjournal = {Neurocomputing},
  title        = {Multi-modal constraint propagation via compatible conditional distribution reconstruction},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature-fusion-kernel-based gaussian process model for
probabilistic long-term load forecasting. <em>NEUCOM</em>, <em>426</em>,
174–184. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we present a feature fusion method designed for the Gaussian process model’s kernel functions for the probabilistic long-term load forecasting. To enrich the amount of information sent to the Gaussian kernel function, we propose a data conversion method that can convert one dimension time series data into multidimensional feature space. Besides, to improve computing efficiency in this data conversion method, we design a sparse approximation method according to the variational free energy principle with the Determinantal Point Processes (DPPs) as the pseudo inputs selection method. Also, the probabilistic distribution of our prediction is specially modified to bridge further the gap between the forecast and the original data set. Our approach is tested and presents a notable performance in the Global Energy Forecasting Competition data set.},
  archive      = {J_NEUCOM},
  author       = {Yaonan Guan and Dewei Li and Shibei Xue and Yugeng Xi},
  doi          = {10.1016/j.neucom.2020.10.043},
  journal      = {Neurocomputing},
  pages        = {174-184},
  shortjournal = {Neurocomputing},
  title        = {Feature-fusion-kernel-based gaussian process model for probabilistic long-term load forecasting},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A semi-supervised learning algorithm via adaptive laplacian
graph. <em>NEUCOM</em>, <em>426</em>, 162–173. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many semi-supervised learning methods have been developed in recent years, especially graph-based approaches, which have achieved satisfactory performance in the practical applications. There are two points that need to be noticed. Firstly, the quality of the graph directly affects the final classification accuracy . However, graph-based algorithms mostly use k -Nearest Neighbor to construct the graph. And the directly constructed graph is inaccurate due to outliers and erroneous features in the data. Secondly, the amount of labeled data is a small part of all data. It cannot be guaranteed that all categories of data are included in the labeled data and the labels of data are not totally correct in practice. To address the aforementioned problems, we propose a new graph-based semi-supervised method named ALGSSL via adaptive Laplacian graph. In the algorithm, we adaptively update the graph to reduce the sensitiveness of the construction of initial graph. Meanwhile, we use the regularization parameters to set confidence on existing labels , which can reduce the impact of the error labels on the result and discover the new category. Experiments on three toy datasets and nine benchmark datasets demonstrate the proposed method can achieve good performance.},
  archive      = {J_NEUCOM},
  author       = {Yuan Yuan and Xin Li and Qi Wang and Feiping Nie},
  doi          = {10.1016/j.neucom.2020.09.069},
  journal      = {Neurocomputing},
  pages        = {162-173},
  shortjournal = {Neurocomputing},
  title        = {A semi-supervised learning algorithm via adaptive laplacian graph},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep recursive network for image denoising with global
non-linear smoothness constraint prior. <em>NEUCOM</em>, <em>426</em>,
147–161. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image denoising is a longstanding research topic in low-level visions. The model-based methods mainly depend on certain handcrafted prior terms to regularize the image denoising problem. However, designing a prior with significantly higher denoising performance than the existing priors is challenging, and reconstructing a clean image via the traditional iterative framework is also time-consuming. Recently, deep neural networks-based denoising methods have achieved tremendous advances. Despite their good denoising performance, some of current architectures face weak interpretability to some extent as their network design is empirical. In this paper, we propose a novel deep neural network for the denoising task, which is designed by following the optimization process of a model-based denoising method. Specifically, by incorporating a novel global non-linear smoothness constraint prior term into a maximum a posteriori (MAP)-based cost function, a model-based denoising method can be obtained. After that, inspired by the powerful modelling ability of deep learning techniques , we exploit the proposed denoising method to inform the network design, leading to a novel end-to-end trainable and interpretable deep network, called GNSCNet. In GNSCNet, each network module corresponds to the processing step of the proposed model-based method. Furthermore, to boost the performance, GNSCNet performs denoising in a high-dimensional transforms space (i.e., feature domain). Experimental results demonstrate that the proposed network is superior to other state-of-the-art denoising methods.},
  archive      = {J_NEUCOM},
  author       = {Chuncheng Wang and Chao Ren and Xiaohai He and Linbo Qing},
  doi          = {10.1016/j.neucom.2020.09.070},
  journal      = {Neurocomputing},
  pages        = {147-161},
  shortjournal = {Neurocomputing},
  title        = {Deep recursive network for image denoising with global non-linear smoothness constraint prior},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Relative geometry-aware siamese neural network for 6DOF
camera relocalization. <em>NEUCOM</em>, <em>426</em>, 134–146. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {6DOF camera relocalization is an important component of autonomous driving and navigation. Deep learning has recently emerged as a promising technique to tackle this problem. In this paper, we present a novel relative geometry-aware Siamese neural network to enhance the performance of deep learning-based methods through explicitly exploiting the relative geometry constraints between images. We perform multi-task learning and predict the absolute and relative poses simultaneously. We regularize the shared-weight twin networks in both the pose and feature domains to ensure that the estimated poses are globally as well as locally correct. We employ metric learning and design a novel adaptive metric distance loss to learn a feature that is capable of distinguishing poses of visually similar images from different locations.We evaluate the proposed method on public indoor and outdoor benchmarks and the experimental results demonstrate that our method can significantly improve localization performance. Furthermore, extensive ablation evaluations are conducted to demonstrate the effectiveness of different terms of the loss function.},
  archive      = {J_NEUCOM},
  author       = {Qing Li and Jiasong Zhu and Rui Cao and Ke Sun and Jonathan M. Garibaldi and Qingquan Li and Bozhi Liu and Guoping Qiu},
  doi          = {10.1016/j.neucom.2020.09.071},
  journal      = {Neurocomputing},
  pages        = {134-146},
  shortjournal = {Neurocomputing},
  title        = {Relative geometry-aware siamese neural network for 6DOF camera relocalization},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local differential privacy for data collection and analysis.
<em>NEUCOM</em>, <em>426</em>, 114–133. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Local Differential Privacy (LDP) can provide each user with strong privacy guarantees under untrusted data curators while ensuring accurate statistics derived from privatized data. Due to its powerfulness, LDP has been widely adopted to protect privacy in various tasks (e.g., heavy hitters discovery, probability estimation) and systems (e.g., Google Chrome, Apple iOS). In particular, ∊ ( ∊ , δ ) (∊,δ) -LDP has been studied in related statistical tasks like private learning and hypothesis testing, but is mainly achieved by using Gaussian mechanism, leading to the limited data utility. In this paper, we investigate several novel mechanisms that achieve ∊ ( ∊ , δ ) (∊,δ) -LDP with higher data utility in collecting and analyzing users’ data. Specifically, we first design two ∊ ( ∊ , δ ) (∊,δ) -LDP algorithms for mean estimations on multi-dimensional numeric data, which can ensure higher accuracy than the optimal Gaussian mechanism. Then, we investigate different local protocols for frequency estimations on categorical attributes under ∊ ( ∊ , δ ) (∊,δ) -LDP. Based on the proposed mechanisms, we further study on ∊ ( ∊ , δ ) (∊,δ) -LDP-compliant stochastic gradient descent algorithms for machine learning models. Besides, the theoretical analysis of the error bound and the variance of the proposed algorithms are also presented in the paper. We have conducted extensive experiments on both real-world and synthetic datasets and demonstrated the high data utility of our proposed algorithms in the perspectives of simple data statistics tasks and complex machine learning tasks. The experimental results have shown that our proposed algorithms can effectively improve the data utility in different tasks while alleviating the privacy concerns of each individual.},
  archive      = {J_NEUCOM},
  author       = {Teng Wang and Jun Zhao and Zhi Hu and Xinyu Yang and Xuebin Ren and Kwok-Yan Lam},
  doi          = {10.1016/j.neucom.2020.09.073},
  journal      = {Neurocomputing},
  pages        = {114-133},
  shortjournal = {Neurocomputing},
  title        = {Local differential privacy for data collection and analysis},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An event-triggered recursive state estimation approach for
time-varying nonlinear complex networks with quantization effects.
<em>NEUCOM</em>, <em>426</em>, 104–113. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel robust extended Kalman filter (REKF) for a class of discrete time-varying nonlinear complex networks with event-triggered communication and quantization effects. In this approach, it is assumed that each sensor transmits data to its estimator over two redundant communication channels. Before the data from each sensor is sent to its estimator, an event-triggered strategy is employed to reduce the wastage of communication bandwidth and unnecessary executions. Afterwards, a logarithmic quantizer is implemented to quantize data. The estimator parameters for each node are derived separately into two Riccati-like difference equations so that the achieved upper bound is minimized by the proposed estimator parameters. Finally, the simulation results are included to illustrate the performance of the derived filtering method.},
  archive      = {J_NEUCOM},
  author       = {F. Rahimi and H. Rezaei},
  doi          = {10.1016/j.neucom.2020.09.074},
  journal      = {Neurocomputing},
  pages        = {104-113},
  shortjournal = {Neurocomputing},
  title        = {An event-triggered recursive state estimation approach for time-varying nonlinear complex networks with quantization effects},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A novel method for time series prediction based on error
decomposition and nonlinear combination of forecasters. <em>NEUCOM</em>,
<em>426</em>, 85–103. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For time series prediction, hybrid systems that combine linear and nonlinear models can provide more accurate performance than a single model. However, the irregularity of the error series and the unknown nature of combinations of different forecasters may strongly impact the performance of hybrid systems. Therefore, in this paper, we propose a novel method for time series prediction, in which error decomposition and a nonlinear combination of forecasters are introduced. The proposed method performs the following: (i) linear modeling to obtain the error series, (ii) error decomposition by using variational mode decomposition (VMD), (iii) nonlinear modeling and a phase fix procedure for the error subseries, and (iv) a combination of forecasters through an appropriate combination function generated by a nonlinear model. By using the proposed method, this paper constructs two hybrid systems, in which the autoregressive integrated moving average (ARIMA) is used for linear modeling, and two artificial intelligence (AI) models, namely, the multilayer perceptron (MLP) and support vector regression (SVR), are used for nonlinear modeling and combination, respectively. Finally, four time series data sets, six evaluation metrics , two single models and thirteen hybrid systems are used to assess the effectiveness of the proposed method. The empirical results show that hybrid systems based on error decomposition and a nonlinear combination of forecasters can achieve better performance than some existing systems and models.},
  archive      = {J_NEUCOM},
  author       = {Wei Chen and Huilin Xu and Zhensong Chen and Manrui Jiang},
  doi          = {10.1016/j.neucom.2020.10.048},
  journal      = {Neurocomputing},
  pages        = {85-103},
  shortjournal = {Neurocomputing},
  title        = {A novel method for time series prediction based on error decomposition and nonlinear combination of forecasters},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Knowledge-guided semantic computing network.
<em>NEUCOM</em>, <em>426</em>, 70–84. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The excellent performance of deep neural networks mainly relies on the attributes of the dataset, such as the size, diversity, completeness. However, it is usually difficult to obtain a high-qualified training dataset for some scenarios. Inspired by the human visual cognition process with few sample learning, and strong robustness, we believe the experience knowledge is more powerful than large-scale data. To combine the power of knowledge and data, we propose a knowledge-guided semantic computing network (SCN) in this paper, which is constructed with a primary knowledge-guided semantic tree module and an auxiliary data-driven lightweight neural network module. The semantic tree module can calculate the classification results by a forward computing process rapidly. The lightweight neural network module can aid the semantic tree module for higher classification ability. We also propose a hinge cross-entropy loss function to train the SCN, which enables the SCN to focus on those misclassified training samples and further improve the classification accuracy . The experimental results on MNIST and GTSRB data sets prove that the SCN achieves excellent classification accuracy comparable to the state-of-the-art methods on the original training samples and higher classification accuracy than the state-of-the-art methods on few training samples. What is more, at BIM eps = 0.3 on MNIST and FGSM eps = 0.03 on GTSRB adversarial test samples, the proposed SCN(1/4) and SCN(1/8) obtain over 75\% and 14\% accuracy improvement than the original CapsNet.},
  archive      = {J_NEUCOM},
  author       = {Guangming Shi and Zhongqiang Zhang and Dahua Gao and Jie Lin and Xuemei Xie and Danhua Liu},
  doi          = {10.1016/j.neucom.2020.09.075},
  journal      = {Neurocomputing},
  pages        = {70-84},
  shortjournal = {Neurocomputing},
  title        = {Knowledge-guided semantic computing network},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TWilBert: Pre-trained deep bidirectional transformers for
spanish twitter. <em>NEUCOM</em>, <em>426</em>, 58–69. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the Natural Language Processing community have been moving from uncontextualized word embeddings towards contextualized word embeddings . Among these contextualized architectures, BERT stands out due to its capacity to compute bidirectional contextualized word representations. However, its competitive performance in English downstream tasks is not obtained by its multilingual version when it is applied to other languages and domains. This is especially true in the case of the Spanish language used in Twitter. In this work, we propose TWiLBERT, a specialization of BERT architecture both for the Spanish language and the Twitter domain. Furthermore, we propose a Reply Order Prediction signal to learn inter-sentence coherence in Twitter conversations, which improves the performance of TWilBERT in text classification tasks that require reasoning on sequences of tweets. We perform an extensive evaluation of TWilBERT models on 14 different text classification tasks, such as irony detection, sentiment analysis , or emotion detection. The results obtained by TWilBERT outperform the state-of-the-art systems and Multilingual BERT. In addition, we carry out a thorough analysis of the TWilBERT models to study the reasons of their competitive behavior. We release the pre-trained TWilBERT models used in this paper, along with a framework for training, evaluating, and fine-tuning TWilBERT models.},
  archive      = {J_NEUCOM},
  author       = {José Ángel González and Lluís-F. Hurtado and Ferran Pla},
  doi          = {10.1016/j.neucom.2020.09.078},
  journal      = {Neurocomputing},
  pages        = {58-69},
  shortjournal = {Neurocomputing},
  title        = {TWilBert: Pre-trained deep bidirectional transformers for spanish twitter},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dual-view semantic inference network for image-text
matching. <em>NEUCOM</em>, <em>426</em>, 47–57. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, image-text matching based on local region-word semantic alignment has attracted considerable research attention. The fine-grained interplay can be achieved by aggregating the similarities of the region-word pairs. However, the similarities of aligned region-word pairs are treated equally in most cross-modal matching literatures, without considering their respective importance. Moreover, the local alignment methods are prone to bring about a global semantic drift due to the ignorance of thematic considerations for the image-text pairs. In this paper, a novel Dual-View Semantic Inference (DVSI) network is proposed to leverage both local and global semantic matching in a holistic deep framework. For the local view, a region enhancement module is proposed to mine the priorities for different regions in the image, which provides differentiate abilities to discover the latent region-word relationships. For the global view, the overall semantics of image is summarized for global semantic matching to avoid global semantic drift. The two views are unified together for final image-text matching. Extensive experiments conducted on MSCOCO and Flicr30K demonstrate the effectiveness of the proposed DVSI.},
  archive      = {J_NEUCOM},
  author       = {Chunlei Wu and Jie Wu and Haiwen Cao and Yiwei Wei and Leiquan Wang},
  doi          = {10.1016/j.neucom.2020.09.079},
  journal      = {Neurocomputing},
  pages        = {47-57},
  shortjournal = {Neurocomputing},
  title        = {Dual-view semantic inference network for image-text matching},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bidirectional heuristic search to find the optimal bayesian
network structure. <em>NEUCOM</em>, <em>426</em>, 35–46. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Bayesian networks have many applications. Learning the optimal structure of a Bayesian network has always been important in this respect. In this paper, a bidirectional heuristic search algorithm is proposed for the order graph space commonly used in a Bayesian network. At the same time, heuristic functions that are admissible and consistent in terms of both forward and backward search are proposed to ensure convergence of the algorithm to the optimal solution. The experimental results show that, compared with traditional unidirectional heuristic search, in most cases, the bidirectional heuristic search proposed in this paper needs to expand fewer states, the convergence efficiency is higher, and less running time is needed.},
  archive      = {J_NEUCOM},
  author       = {Xiangyuan Tan and Xiaoguang Gao and Zidong Wang and Chuchao He},
  doi          = {10.1016/j.neucom.2020.10.049},
  journal      = {Neurocomputing},
  pages        = {35-46},
  shortjournal = {Neurocomputing},
  title        = {Bidirectional heuristic search to find the optimal bayesian network structure},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cross-subject transfer learning in human activity
recognition systems using generative adversarial networks.
<em>NEUCOM</em>, <em>426</em>, 26–34. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Application of intelligent systems especially in smart homes and health-related topics has been drawing more attention in the last decades. Training Human Activity Recognition (HAR) models - as a major module- requires a fair amount of labeled data. Despite training with large datasets, most of the existing models will face a dramatic performance drop when they are tested against unseen data from new users. Moreover, recording enough data for each new user is non-viable due to the limitations and challenges of working with human users. Transfer learning techniques aim to transfer the knowledge which has been learned from the source domain (subject) to the target domain in order to decrease the models’ performance loss in the target domain. This paper presents a novel method of adversarial knowledge transfer named SA-GAN stands for S ubject A daptor GAN, which utilizes the G enerative A dversarial N etwork framework to perform cross-subject transfer learning in the domain of wearable sensor-based Human Activity Recognition . SA-GAN outperformed other state-of-the-art methods in more than 66\% of experiments and showed the second-best performance in the remaining 25\% of experiments. In some cases, it reached up to 90\% of the accuracy which can be obtained by supervised training over the same domain data.},
  archive      = {J_NEUCOM},
  author       = {Elnaz Soleimani and Ehsan Nazerfard},
  doi          = {10.1016/j.neucom.2020.10.056},
  journal      = {Neurocomputing},
  pages        = {26-34},
  shortjournal = {Neurocomputing},
  title        = {Cross-subject transfer learning in human activity recognition systems using generative adversarial networks},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal distributed cooperative control for multi-agent
systems with constrains on convergence speed and control input.
<em>NEUCOM</em>, <em>426</em>, 14–25. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the distributed optimal cooperative control for multi-agent systems (MASs) over fixed communication graphs . Firstly, it is proved that the optimal distributed control for the local quadratic performance indexes of all agents is equivalent to solve a globally optimal problem, the resulting optimal Laplacian matrix associates with a complete graph hence the optimal distributed protocols do not exist. Consequently, we turn to solve the globally optimal distributed control problem for the candidate protocols with specified distributed structure. Furthermore, suboptimal fully distributed protocols can be designed when the Laplacian matrix and the initial states of all agents are unavailable. As a simple application, the minimum energy distributed cooperative control problem is addressed. Then, from a practical viewpoint, we solve the distributed optimal control problem with constrains on specified convergence speed and control input. Sufficient conditions for existence of the optimal solutions are derived. Finally, simulation examples are given to verify the effectiveness of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Jinsong Li and Tao Feng and Jilie Zhang and Fei Yan},
  doi          = {10.1016/j.neucom.2020.10.058},
  journal      = {Neurocomputing},
  pages        = {14-25},
  shortjournal = {Neurocomputing},
  title        = {Optimal distributed cooperative control for multi-agent systems with constrains on convergence speed and control input},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A sparse code increases the speed and efficiency of
neuro-dynamic programming for optimal control tasks with correlated
inputs. <em>NEUCOM</em>, <em>426</em>, 1–13. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse codes in neuroscience have been suggested to offer certain computational advantages over other neural representations of sensory data. To explore this viewpoint, a sparse code is used to represent natural images in an optimal control task solved with neuro-dynamic programming, and its computational properties are investigated. The central finding is that when feature inputs to a linear network are correlated, an over-complete sparse code increases the memory capacity of the network in an efficient manner beyond that possible for any complete code with the same-sized input, and also increases the speed of learning the network weights. A complete sparse code is found to maximise the memory capacity of a linear network by decorrelating its feature inputs to transform the design matrix of the least-squares problem to one of full rank. It also conditions the Hessian matrix of the least-squares problem, thereby increasing the rate of convergence to the optimal network weights. Other types of decorrelating codes would also achieve this. However, an over-complete sparse code is found to be approximately decorrelated, extracting a larger number of approximately decorrelated features from the same-sized input, allowing it to efficiently increase memory capacity beyond that possible for any complete code: a 2.25 times over-complete sparse code is shown to at least double memory capacity compared with a complete sparse code using the same input. This is used in sequential learning to store a potentially large number of optimal control tasks in the network, while catastrophic forgetting is avoided using a partitioned representation, yielding a cost-to-go function approximator that generalizes over the states in each partition. Sparse code advantages over dense codes and local codes are also discussed.},
  archive      = {J_NEUCOM},
  author       = {Peter N. Loxley},
  doi          = {10.1016/j.neucom.2020.10.069},
  journal      = {Neurocomputing},
  pages        = {1-13},
  shortjournal = {Neurocomputing},
  title        = {A sparse code increases the speed and efficiency of neuro-dynamic programming for optimal control tasks with correlated inputs},
  volume       = {426},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A tutorial on distance metric learning: Mathematical
foundations, algorithms, experimental analysis, prospects and
challenges. <em>NEUCOM</em>, <em>425</em>, 300–322. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distance metric learning is a branch of machine learning that aims to learn distances from the data, which enhances the performance of similarity-based algorithms. This tutorial provides a theoretical background and foundations on this topic and a comprehensive experimental analysis of the most-known algorithms. We start by describing the distance metric learning problem and its main mathematical foundations, divided into three main blocks: convex analysis, matrix analysis and information theory . Then, we will describe a representative set of the most popular distance metric learning methods used in classification. All the algorithms studied in this paper will be evaluated with exhaustive testing in order to analyze their capabilities in standard classification problems, particularly considering dimensionality reduction and kernelization. The results, verified by Bayesian statistical tests, highlight a set of outstanding algorithms. Finally, we will discuss several potential future prospects and challenges in this field. This tutorial will serve as a starting point in the domain of distance metric learning from both a theoretical and practical perspective.},
  archive      = {J_NEUCOM},
  author       = {Juan Luis Suárez and Salvador García and Francisco Herrera},
  doi          = {10.1016/j.neucom.2020.08.017},
  journal      = {Neurocomputing},
  pages        = {300-322},
  shortjournal = {Neurocomputing},
  title        = {A tutorial on distance metric learning: Mathematical foundations, algorithms, experimental analysis, prospects and challenges},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Summary-aware attention for social media short text
abstractive summarization. <em>NEUCOM</em>, <em>425</em>, 290–299. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.136">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural sequence-to-sequence (Seq2Seq) models are currently dominant approaches in social media short text abstractive summarization task. However, the computation of source attention weight in Seq2Seq models does not fully consider the information of the previously generated summary, which harms the coherence of the summary. In addition, given the noisy source text, it is difficult for Seq2Seq models to learn an accurate source context. To address these two shortcomings, we propose summary-aware attention for social media short text abstractive summarization. In this work, we use the source hidden states and attended summary vectors to compute summary-aware attention weight. The attended summary vectors contribute to generate a coherent summary. Moreover, under the guidance of the attended summary vectors, the attention mechanism increases the weight of the related content and reduces the weight of noise. Following the previous work, we evaluate our model on a popular Chinese social media dataset. Both automatic and human evaluation results demonstrate that our model achieves significant improvements compared with strong baselines.},
  archive      = {J_NEUCOM},
  author       = {Qianlong Wang and Jiangtao Ren},
  doi          = {10.1016/j.neucom.2020.04.136},
  journal      = {Neurocomputing},
  pages        = {290-299},
  shortjournal = {Neurocomputing},
  title        = {Summary-aware attention for social media short text abstractive summarization},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Multi-branch guided attention network for irregular text
recognition. <em>NEUCOM</em>, <em>425</em>, 278–289. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reading irregular text of arbitrary shape or low quality in natural scene images is a challenging task. Existing irregular scene text recognition methods mainly focus on irregular text with arbitrary shape, but rarely focus on irregular text of low quality. In this work, we propose a simple but effective method for recognizing irregular texts with arbitrary shape and low quality simultaneously. The proposed Multi-Branch guided Attention Network (MBAN) makes mutual guidance among multi-branch data in training, so as to learn invariant semantic representation between regular text images and the corresponding irregular images. Compared with the standard attention framework for text recognition, MBAN can significantly improve the performance of irregular text recognition while preserving similar performance for regular text recognition. In addition, regarding the attention drift problem encountered in standard attention network, MBAN can significantly improve the accuracy of alignment factors at each time step. We verify the effectiveness of MBAN in irregular text recognition and attention drift problem through extensive experiments. The performance of MBAN is shown to be comparable on regular datasets and superior on some irregular datasets with state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Cong Wang and Cheng-Lin Liu},
  doi          = {10.1016/j.neucom.2020.04.129},
  journal      = {Neurocomputing},
  pages        = {278-289},
  shortjournal = {Neurocomputing},
  title        = {Multi-branch guided attention network for irregular text recognition},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attentive interaction-driven entity resolution over
multi-source web information. <em>NEUCOM</em>, <em>425</em>, 266–277.
(<a href="https://doi.org/10.1016/j.neucom.2020.04.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The task of multi-source web entity resolution (MSWER) aims to automatically discover entity references from multiple web sources that refer to the same real-world entity, which plays an important role in tasks such as question answering and recommendations. However, existing approaches typically suffer from three major limitations: (1) they usually treat the MSWER as an information retrieval task and focus on learning the similarity between entity references based on the associated features extracted from multiple sources; (2) they ignore the valuable implicit interactions between the associated features of different entities that cannot be directly captured based on the given data without any external knowledge; (3) they didn’t consider the redundant and noisy interactions between features. To overcome these limitations, this paper presents a novel attentive interaction-driven entity resolution model (AIDER). Our theme is to capture both the explicit and implicit interactions of features associated with entity references in the form of paths, and further develop an end-to-end entity resolution model for inferring the equivalent entity references. Accordingly, an external knowledge base is leveraged to construct paths for implicit interactions, and a well-designed attention mechanism is further employed to measure the importance of each path-based interaction, which focuses on useful interactions and neglects those redundant and noisy ones. Experimental results on three real-world datasets demonstrate that AIDER outperforms the state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Ying He and Gongqing Wu and Desheng Cai and Shengjie Hu and Xianyu Bao and Xuegang Hu},
  doi          = {10.1016/j.neucom.2020.04.094},
  journal      = {Neurocomputing},
  pages        = {266-277},
  shortjournal = {Neurocomputing},
  title        = {Attentive interaction-driven entity resolution over multi-source web information},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Memory level neural network: A time-varying neural network
for memory input processing. <em>NEUCOM</em>, <em>425</em>, 256–265. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.093">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Affective computing is an important foundation for implementing brain-like computing and advanced machine intelligence . However, the instantaneous and memory fusion input characteristic makes current neural networks not suitable for affective computing. In this paper, we propose an affective computing oriented memory level neural network. A “switch” has been added to the memory level neurons, which will achieve a transition from the instantaneous input to the memory input when the temporal integration of inputs above a certain threshold. Then, the “switch” is continualized by an adjustable sigmoid function whose parameters are tuned to adjust the speed of the transition and the mixing ratio of the two inputs. Multiple memory level neurons form a deep time-varying neural network capable of handling fusional inputs. We demonstrate on both process datasets and static datasets that the memory level neural network successfully converges on both datasets and meets the error accuracy requirements.},
  archive      = {J_NEUCOM},
  author       = {Chao Gong and Xianwei Zhou and Xing Lü and Fuhong Lin},
  doi          = {10.1016/j.neucom.2020.04.093},
  journal      = {Neurocomputing},
  pages        = {256-265},
  shortjournal = {Neurocomputing},
  title        = {Memory level neural network: A time-varying neural network for memory input processing},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). OSCD: A one-shot conditional object detection framework.
<em>NEUCOM</em>, <em>425</em>, 243–255. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The current advances in object detection depend on large-scale datasets to get good performance. However, there may not always be sufficient samples in many scenarios, resulting in the performance degradation of the current deep learning based object detection models. To overcome this problem, we propose a novel one-shot conditional detection framework (OSCD). Given a support image of the target object and a query image as input, OSCD can detect all objects belonging to the target object category in the query image. Specifically, OSCD is composed of a Siamese network and a two-stage detection model. In each stage of the two-stage detection pipeline, a feature fusion module and a learnable metric module are designed for effective conditional detection respectively. Once trained, OSCD can detect objects of both seen and unseen classes without further training, which also has advantages including class-agnostic, training-free for unseen classes, and without catastrophic forgetting. Experiments show that the proposed approach achieves state-of-the-art performance on the proposed datasets based on Fashion-MNIST and Pascal VOC.},
  archive      = {J_NEUCOM},
  author       = {Kun Fu and Tengfei Zhang and Yue Zhang and Xian Sun},
  doi          = {10.1016/j.neucom.2020.04.092},
  journal      = {Neurocomputing},
  pages        = {243-255},
  shortjournal = {Neurocomputing},
  title        = {OSCD: A one-shot conditional object detection framework},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). CascNet: No-reference saliency quality assessment with
cascaded applicability sorting and comparing network. <em>NEUCOM</em>,
<em>425</em>, 231–242. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, saliency detection is playing vital role in many computer vision tasks . Due to the diversity of visual pattern in natural images, a specific saliency approach is hardly suitable for any type of images. The optimal selection of no-reference saliency map without the pixel-wise ground-truth mask as reference is an important problem, which directly influences the performance of the higher-level tasks. This is essentially a saliency quality assessment problem. Unlike other existing solutions, we propose CascNet for both highly efficient and accurate quality assessment. CascNet is consisted of Applicability Sorting Net (ASNet) and Comparing Net (CompNet), where ASNet serves as an efficient filter to only keep suitable saliency algorithms for the given image with no need of generating saliency maps beforehand, while CompNet is used for further fine assessment with a deep Siamese structure. Comprehensive experiments conducted on the commonly used salient object detection datasets THUS10000, DUT-OMRON and the currently most challenging dataset SOC demonstrate the good performance of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Kunqian Li and Duo Shi and Yongchang Zhang and Q.M. Jonathan Wu and Xin Luan and Dalei Song},
  doi          = {10.1016/j.neucom.2020.04.090},
  journal      = {Neurocomputing},
  pages        = {231-242},
  shortjournal = {Neurocomputing},
  title        = {CascNet: No-reference saliency quality assessment with cascaded applicability sorting and comparing network},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explore double-opponency and skin color for saliency
detection. <em>NEUCOM</em>, <em>425</em>, 219–230. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent advances in salient detection have exploited the foreground or background information to assist other saliency cues such as contrast to achieve state-of-the-art results. However the problem remains challenging. For example, human skin color is easily overlooked during saliency detection . Simulating the human visual mechanism to improve the current algorithm, we propose a saliency model based on the color-opponent mechanisms of a certain type of color-sensitive double-opponent (DO) cells in the primary visual cortex (V1) of human visual system . Firstly, DO cells with concentric receptive fields (RFs) can detect region contrast for yielding foreground saliency map. Our approach is intuitive and easy to interpret, and it allows fast implementation. Then, skin saliency map is built in a way that is different from high-level factors such as face detection, combining skin region and spatial Euclidean distance weight in the RGB space, and the significant skin features can be obtained effectively. Finally, a linear fusion strategy is proposed to integrate different saliency maps. Experimental results with three well-known benchmark databases demonstrate that the proposed method can achieve competitive performance when compared to state-of-the-art methods. Saliency regions contain important skin features compared to other traditional methods.},
  archive      = {J_NEUCOM},
  author       = {Baohua Yuan and Lixin Han and Hong Yan},
  doi          = {10.1016/j.neucom.2020.04.089},
  journal      = {Neurocomputing},
  pages        = {219-230},
  shortjournal = {Neurocomputing},
  title        = {Explore double-opponency and skin color for saliency detection},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new financial data forecasting model using genetic
algorithm and long short-term memory network. <em>NEUCOM</em>,
<em>425</em>, 207–218. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Financial data forecasting is conducive to get a better understanding of the future economic situation. Recently, variational mode decomposition (VMD) is introduced into the field of financial data forecasting. However, the prediction accuracy of the current methods is low. We propose a new VMD-based financial data prediction model. In this model, the genetic algorithm is utilized to optimize the parameters of VMD. Then VMD decomposes the data sequence into long-term and short-term trends. Finally, we employ the long short-term memory (LSTM) network to predict the future data with inputs generated by VMD. The contributions are: (1) We propose an improved VMD and LSTM based financial data forecasting model; (2) A guideline on the parameter selection of VMD to process financial data is designed; (3) A prediction-error reducing method which reduces the inherent error caused by VMD insensitivity to fluctuation is proposed. Experimental results indicate our model is accuracy-promising and superior to the baseline models in one-step-ahead forecasting of financial time series.},
  archive      = {J_NEUCOM},
  author       = {Yusheng Huang and Yelin Gao and Yan Gan and Mao Ye},
  doi          = {10.1016/j.neucom.2020.04.086},
  journal      = {Neurocomputing},
  pages        = {207-218},
  shortjournal = {Neurocomputing},
  title        = {A new financial data forecasting model using genetic algorithm and long short-term memory network},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep embedding of concept ontology for hierarchical fashion
recognition. <em>NEUCOM</em>, <em>425</em>, 191–206. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The natural concept ontology structure of clothes has enabled easy management of large quantities of fashion images for online retailers and it is meaningful to study how to automatically recognize fashion images for both commercial promotion and academic research. In this paper, a new hierarchical approach is developed for large-scale fashion recognition. We first embed concept ontology into deep convolutional neural network (CNN) by adopting multiple deep CNN branches to learn node-specific features and classifiers explicitly. Then, we introduce a hierarchical knowledge distillation method to further improve the performance of fashion recognition. Finally, we employ the proposed approach for fashion recommendation. To deal with hierarchical deep learning constrains, we leverage back propagation to simultaneously refine the shared deep CNNs and the diverse CNN branches for relevant node features and classifiers by using our joint objective function. The main advantages of this paper lie in (1) providing an effective way for recognizing rich semantic explanations of fashion images without training large or multiple networks, and (2) saving the storage&amp;time costs by learning personalized features and classifiers for each tree node. The experimental results on both our organized fashion dataset and the public DeepFashion dataset have verified the effectiveness and efficiency of the proposed approach on both hierarchical fashion recognition and within category fine-grained fashion recommendation.},
  archive      = {J_NEUCOM},
  author       = {Zhenzhong Kuang and Xin Zhang and Jun Yu and Zongmin Li and Jianping Fan},
  doi          = {10.1016/j.neucom.2020.04.085},
  journal      = {Neurocomputing},
  pages        = {191-206},
  shortjournal = {Neurocomputing},
  title        = {Deep embedding of concept ontology for hierarchical fashion recognition},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Joint representation learning with ratings and reviews for
recommendation. <em>NEUCOM</em>, <em>425</em>, 181–190. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender system is an important technique to find the information that the users may be interested by their feedbacks. However, it is still a challenge to model the preference of users due to the sparsity of user feedbacks. To alleviate this problem, many methods are developed by extracting information from various kinds of auxiliary information that are related to the users. In the auxiliary information, review is the popular one, since it can reflect both user preferences and item characteristics. Moreover, the review can generate plausible recommendation explanations in the recommendation results. In this paper, we propose a hybrid deep collaborative filtering model that jointly learns rating embedding and textural feature from ratings and reviews respectively. Specifically, two embedding layers are employed to learn rating embedding for users and items based on the interactions, and two attention-based GRU networks attempt to learn context-aware representation as textural feature for users and items from reviews. To leverage the contribution between rating embedding and textual feature and obtain the fused features for users and items, a proposed gating mechanism is used. Then an interaction-learning layer is adopted to learn the user and item interaction information based on the fused user and item features. The prediction score is obtained with the factorization machine. Experimental results on six real-world datasets demonstrate the superior performance of the proposed method over several state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Zengmao Wang and Haifeng Xia and Shuai Chen and Gang Chun},
  doi          = {10.1016/j.neucom.2020.04.033},
  journal      = {Neurocomputing},
  pages        = {181-190},
  shortjournal = {Neurocomputing},
  title        = {Joint representation learning with ratings and reviews for recommendation},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep-reinforcement-learning-based images segmentation for
quantitative analysis of gold immunochromatographic strip.
<em>NEUCOM</em>, <em>425</em>, 173–180. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gold immunochromatographic strip (GICS) is a widely used lateral flow immunoassay technique. A novel image segmentation method is developed in this paper for quantitative analysis of GICS based on the deep reinforcement learning (DRL), which can accurately distinguish the test line and the control line in the GICS images. The deep belief network (DBN) is employed in the deep Q network in our DRL algorithm. Meanwhile, the multi-factor learning curve is introduced in the DRL algorithm to dynamically adjust the capacity of the replay buffer and the sampling size, which leads to enhanced learning efficiency. It is worth mentioning that the states, actions, and rewards in the developed DRL algorithm are determined based on the characteristics of GICS images. Experiment results demonstrate the feasibility and reliability of the proposed DRL-based image segmentation method and show that the proposed new image segmentation method outperforms some existing image segmentation methods for quantitative analysis of GICS images.},
  archive      = {J_NEUCOM},
  author       = {Nianyin Zeng and Han Li and Zidong Wang and Weibo Liu and Songming Liu and Fuad E. Alsaadi and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2020.04.001},
  journal      = {Neurocomputing},
  pages        = {173-180},
  shortjournal = {Neurocomputing},
  title        = {Deep-reinforcement-learning-based images segmentation for quantitative analysis of gold immunochromatographic strip},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Single underwater image enhancement by attenuation map
guided color correction and detail preserved dehazing. <em>NEUCOM</em>,
<em>425</em>, 160–172. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The attenuation (sum of absorption and scattering), which caused by the dense and non-uniform medium, generally leads to problems of color degradation and detail loss in underwater imaging. To address these problems, we propose a systematic underwater image enhancement method, which includes an attenuation map guided underwater image color correction approach and a detail preserved dehazing approach. The color correction approach fully considers the main causes of color degradation in underwater imaging, namely wavelength-dependent attenuation of different colors. According to the attenuation map of each color channel, a piece-wise linear transform is used to process the information of each color channel. Then, the detail preserved dehazing approach based on multi-scale decomposition is proposed to compensate for the lost details while eliminating the effects of haze. Especially, an adaptive Maximum Intensity Prior (MIP) measurement based on maximum attenuation identification is proposed to estimate transmission of the medium. Experiments on a variety types of degraded underwater images have proven that our proposed method can produce accurate results with vivid color and fine details, even better than other state-of-the-art underwater image dehazing methods.},
  archive      = {J_NEUCOM},
  author       = {Zheng Liang and Yafei Wang and Xueyan Ding and Zetian Mi and Xianping Fu},
  doi          = {10.1016/j.neucom.2020.03.091},
  journal      = {Neurocomputing},
  pages        = {160-172},
  shortjournal = {Neurocomputing},
  title        = {Single underwater image enhancement by attenuation map guided color correction and detail preserved dehazing},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Active disturbance rejection controller for multi-area
interconnected power system based on reinforcement learning.
<em>NEUCOM</em>, <em>425</em>, 149–159. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a method of Active Disturbance Rejection Controller (ADRC) is proposed based on Q-learning of Reinforcement Learning (RL) for multi-area interconnected power system. Excessive changes in load can cause instability to the system. Therefore, the ADRC controller is used to keep the load within rated range for its strong anti-interference performance and Q-learning algorithm to select the adaptive parameters of the controller. Finally, through simulation experiments on traditional and deregulated three-area interconnected power system respectively, the effectiveness of the proposed method is proved and the results show that reinforcement learning can indeed be used to solve the problem of controller parameter adjustment.},
  archive      = {J_NEUCOM},
  author       = {Yuemin Zheng and Zengqiang Chen and Zhaoyang Huang and Mingwei Sun and Qinglin Sun},
  doi          = {10.1016/j.neucom.2020.03.070},
  journal      = {Neurocomputing},
  pages        = {149-159},
  shortjournal = {Neurocomputing},
  title        = {Active disturbance rejection controller for multi-area interconnected power system based on reinforcement learning},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Action unit analysis enhanced facial expression recognition
by deep neural network evolution. <em>NEUCOM</em>, <em>425</em>,
135–148. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Facial expression is one of the most powerful and natural signals for human beings conveying their emotional states and intentions. Recently, facial expression recognition from facial cues based on FACS is investigated, where facial expressions can be described by a subset of AUs, and the facial expression categories could be easily extended. The goal of our work is the proposal of an action unit analysis enhanced facial expression recognition system based on evolutional deep learning approach. The main contributions of our work include the following three aspects: (1) the temporal dynamic based 3DLeNets is exploited for video analysis based AUs detection. And a general evolutionary framework is conducted for the deep neural networks optimization. (2) The correlations among AUs and the correlation between AUs and emotions are investigated, and the relationship probability model between AUs and emotions is derived by the concept of discriminative power coefficients. (3) An adaptive subsequence matching algorithm (ASMA) is adopted to measure the similarity between AUs sequences, so that to construct the inference scheme of mapping AUs to emotions. Experimental results proved that the AUs enhanced facial expression recognition system performs well comparing to existing facial expression analysis methods, and each AU has different contribution roles for different facial expressions. It is also found to be more practical than discrete facial expression recognition as most of the facial expressions can be described using a subset of AUs.},
  archive      = {J_NEUCOM},
  author       = {Ruicong Zhi and Caixia Zhou and Tingting Li and Shuai Liu and Yi Jin},
  doi          = {10.1016/j.neucom.2020.03.036},
  journal      = {Neurocomputing},
  pages        = {135-148},
  shortjournal = {Neurocomputing},
  title        = {Action unit analysis enhanced facial expression recognition by deep neural network evolution},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bioinspired neurodynamics based formation control for
unmanned surface vehicles with line-of-sight range and angle
constraints. <em>NEUCOM</em>, <em>425</em>, 127–134. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a leader–follower formation control for a group of waterjet unmanned marine surface vehicles (USV) is proposed under the consideration of formation tracking errors constraints. To guarantee line-of-sight (LOS) range and angle tracking errors constraints, a time-varying tan-type barrier Lyapunov function (BLF) is used. In addition, the bioinspired neurodynamics is introduced to solve the traditional differential explosion problem which can not only avoid the differential of the virtual control but can limit the output in a certain range. Further, an observer is involved to overcome the leader’s velocity unavailable problem and decrease the communication burden. Simulation results verify that under the proposed method, the LOS range and angle errors can converge into an arbitrary small neighborhood around 0, while the requirements of the constraints are never violated during the maneuver.},
  archive      = {J_NEUCOM},
  author       = {Duansong Wang and Shuzhi Sam Ge and Mingyu Fu and Dongyu Li},
  doi          = {10.1016/j.neucom.2020.02.107},
  journal      = {Neurocomputing},
  pages        = {127-134},
  shortjournal = {Neurocomputing},
  title        = {Bioinspired neurodynamics based formation control for unmanned surface vehicles with line-of-sight range and angle constraints},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A two-stage chinese text summarization algorithm using
keyword information and adversarial learning. <em>NEUCOM</em>,
<em>425</em>, 117–126. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {At present, most Chinese text summarization algorithms use the sequence-to-sequence model, but this model is prone to the problems of unknown words and incomplete content generation. To address these problems, we propose a new two-stage automatic text summarization method using keyword information and adversarial learning in this paper. On the one hand, the proposed method integrates the keyword information into the sequence-to-sequence model. The main information and keywords of the article are considered simultaneously through the attention mechanism to improve the information of summary generation. On the other hand, adversarial learning is introduced into the proposed model to avoid the problem that the semantic vector after passing through the encoder cannot save the context information better. Experiments are carried out on the Chinese dataset LCSTS, and the comparison results show that the proposed method has advantages in abstractive summarization .},
  archive      = {J_NEUCOM},
  author       = {Zhenrong Deng and Fuxin Ma and Rushi Lan and Wenming Huang and Xiaonan Luo},
  doi          = {10.1016/j.neucom.2020.02.102},
  journal      = {Neurocomputing},
  pages        = {117-126},
  shortjournal = {Neurocomputing},
  title        = {A two-stage chinese text summarization algorithm using keyword information and adversarial learning},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delving deep into the imbalance of positive proposals in
two-stage object detection. <em>NEUCOM</em>, <em>425</em>, 107–116. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalance issue is a major yet unsolved bottleneck for the current object detection models. In this work, we observe two crucial yet never discussed imbalance issues. The first imbalance lies in the large number of low-quality RPN proposals, which makes the R-CNN module ( i.e. , post-classification layers) become highly biased towards the negative proposals in the early training stage. The second imbalance stems from the unbalanced ground-truth numbers across different testing images, resulting in the imbalance of the number of potentially existing positive proposals in testing phase. To tackle these two imbalance issues, we incorporates two innovations into Faster R-CNN: 1) an R-CNN Gradient Annealing (RGA) strategy to enhance the impact of positive proposals in the early training stage. 2) a set of Parallel R-CNN Modules (PRM) with different positive/negative sampling ratios during training on one same backbone. Our RGA and PRM can totally bring 2.0\% improvements on AP on COCO minival . Experiments on CrowdHuman further validates the effectiveness of our innovations across various kinds of object detection tasks.},
  archive      = {J_NEUCOM},
  author       = {Zheng Ge and Zequn Jie and Xin Huang and Chengzheng Li and Osamu Yoshie},
  doi          = {10.1016/j.neucom.2020.10.098},
  journal      = {Neurocomputing},
  pages        = {107-116},
  shortjournal = {Neurocomputing},
  title        = {Delving deep into the imbalance of positive proposals in two-stage object detection},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CompSNN: A lightweight spiking neural network based on
spatiotemporally compressive spike features. <em>NEUCOM</em>,
<em>425</em>, 96–106. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain-inspired spiking neural networks (SNNs) have become a research hotspot in recent years. These SNNs communicate and process information in a form of spatiotemporally sparse spikes, leading to high energy efficiency and low computational cost for object classification tasks . However, to reduce computational complexity while maintaining SNN classification accuracy still remains a challenge. Extracting representative and robust feature is the key. This paper proposes efficient spatiotemporally compressive spike features and presents a lightweight SNN framework that includes a feature extraction layer to extract such compressive features. Our experiments based on popular benchmark datasets demonstrated that the spatiotemporally compressive spike features are competent and robust in representing the input spike trains. The experimental results also suggest that our lightweight SNN framework with such compressive spike feature requires a small amount of processing time consumption while achieving comparable classification rate across many popular datasets: MNIST, MNIST-DVS, Poker-DVS, Posture-DVS and more challenging Fashion-MNIST datasets. The SNN framework has a potential to be applied in low-cost or resource-limited edge computing systems and embedded devices.},
  archive      = {J_NEUCOM},
  author       = {Tengxiao Wang and Cong Shi and Xichuan Zhou and Yingcheng Lin and Junxian He and Ping Gan and Ping Li and Ying Wang and Liyuan Liu and Nanjian Wu and Gang Luo},
  doi          = {10.1016/j.neucom.2020.10.100},
  journal      = {Neurocomputing},
  pages        = {96-106},
  shortjournal = {Neurocomputing},
  title        = {CompSNN: A lightweight spiking neural network based on spatiotemporally compressive spike features},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prescribed-time leader-following consensus for stochastic
second-order multi-agent systems subject to actuator failures via
sliding mode control strategy. <em>NEUCOM</em>, <em>425</em>, 82–95. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two control protocols based on the sliding mode control scheme are proposed to solve the prescribed-time leader-following consensus problem for second-order nonlinear multi-agent systems with actuator failures and stochastic noises under directed topology. First, a discontinuous controller protocol is proposed when the parameters related to the actuator failures can be acquired in advance. The controller can drive the system trajectories to reach the sliding manifold before a predefined time, and then ensure that the leader-following consensus is achieved in predefined time also. The upper bound of the reaching time and the upper bound of the setting time do not depend on initial conditions and system parameters, and can be arbitrarily specified offline. Next, when the prior knowledge of the actuator faults and nonlinearities cannot be obtained, a continuous control protocol is proposed, which can adaptively adjust the control gains to compensate for these unknown uncertainties. We theoretically prove that the prescribed-time leader-following consensus in mean square can be achieved under the designed control schemes. Finally, several examples are presented to illustrate the effectiveness of the proposed solutions.},
  archive      = {J_NEUCOM},
  author       = {Yuanhong Ren and Wuneng Zhou and Zhiwei Li and Ling Liu and Yuqing Sun},
  doi          = {10.1016/j.neucom.2020.10.103},
  journal      = {Neurocomputing},
  pages        = {82-95},
  shortjournal = {Neurocomputing},
  title        = {Prescribed-time leader-following consensus for stochastic second-order multi-agent systems subject to actuator failures via sliding mode control strategy},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021d). Robust and structural sparsity auto-encoder with l21-norm
minimization. <em>NEUCOM</em>, <em>425</em>, 71–81. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The mean square error (MSE), as the most commonly used cost function for auto-encoder, is sensitive to outliers or impulsive noises in real-world application, which may misguide the training process. At the same time, stacked auto-encoder(SAE) is indeed a totally fully connected network, the parameters exponentially increase as the nodes and layers increase, which may cause over-fitting, huge computational complexity and storage overhead . So the robustness and sparseness problem of the auto-encoder need to be further investigated. In this paper, we develop a robust and structural sparsity stacked auto-encoder with L21-norm loss function and regularization (LR21-SAE). Our L21-norm loss function can alleviate the negative impact of outlier samples, thus show superior robust performance. Our L21-norm regularization can enforce some rows/columns of weight matrix shrink to zero entirely, thus promote to learn sparse features and choose compact network. We have validated our LR21-SAE model on several common datasets. Experimental results show that LR21-SAE is significantly robust to outlier noises for real-world data, it also can get sparse nodes connection deep neural network with notable less number of parameters than what the original non-sparse network has, while maintain outstanding performance.},
  archive      = {J_NEUCOM},
  author       = {Rui Li and Xiaodan Wang and Wen Quan and Yafei Song and Lei Lei},
  doi          = {10.1016/j.neucom.2020.02.051},
  journal      = {Neurocomputing},
  pages        = {71-81},
  shortjournal = {Neurocomputing},
  title        = {Robust and structural sparsity auto-encoder with l21-norm minimization},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed data-driven tracking control for networked
nonlinear MIMO multi-agent systems subject to communication delays.
<em>NEUCOM</em>, <em>425</em>, 62–70. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the tracking control issue of networked nonlinear MIMO multi-agent systems under random delay. Since the model of nonlinear system is difficult to be obtained accurately, a data-driven control strategy called model-free adaptive control method is introduced, which only needs the information of input and output data. Based on the above approach and the networked delay compensation technique, a data-based delay compensation tracking control scheme is proposed. And the sufficient condition for the asymptotic stability is given. The proposed method can achieve a good tracking performance, and actively compensate the networked-induced delay. The feasibility of the proposed method is validated through numerical simulations.},
  archive      = {J_NEUCOM},
  author       = {Ji Zhang and Sen-Chun Chai and Bai-Hai Zhang and Guo-Ping Liu},
  doi          = {10.1016/j.neucom.2019.12.075},
  journal      = {Neurocomputing},
  pages        = {62-70},
  shortjournal = {Neurocomputing},
  title        = {Distributed data-driven tracking control for networked nonlinear MIMO multi-agent systems subject to communication delays},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete-time signed bounded confidence model for opinion
dynamics. <em>NEUCOM</em>, <em>425</em>, 53–61. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the classic discrete-time bounded confidence (BC) model is modified by using the sign function such that signs of opinions never change during the opinion evolution. Considering the antagonistic and indifference behaviors between individuals, we propose two discrete-time signed BC models. Then, by comparing our proposed signed BC models with the classic BC model, we investigate dynamics characteristic of them in detail. We find that opinion evolution of our proposed signed BC models is more complicated than the classic BC model, but they retain clustering behavior of the classic BC model. Furthermore, several examples are given to test and verify the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Guang He and Jing Liu and Huimin Hu and Jian-An Fang},
  doi          = {10.1016/j.neucom.2019.12.061},
  journal      = {Neurocomputing},
  pages        = {53-61},
  shortjournal = {Neurocomputing},
  title        = {Discrete-time signed bounded confidence model for opinion dynamics},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A few filters are enough: Convolutional neural network for
p300 detection. <em>NEUCOM</em>, <em>425</em>, 37–52. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade convolutional neural networks (CNNs) have become the driving force of an ever-increasing set of applications, achieving state-of-the-art performance. Modern CNN architectures are often composed of many convolutional and some fully connected layers, and have thousands or millions of parameters. CNNs have shown to be effective in the detection of Event-Related Potentials from electroencephalogram (EEG) signals, notably the P300 component which is frequently employed in Brain-Computer Interfaces (BCIs). However, for this task, the increase in detection rates compared to approaches based on human-engineered features has not been as impressive as in other areas and might not justify such a large number of parameters. In this paper, we study the performance of existing CNN architectures with diverse complexities for single-trial within-subject and cross-subject P300 detection on four different datasets. We also proposed SepConv1D, a very simple CNN architecture consisting of a single depthwise separable 1D convolutional layer followed by a fully connected Sigmoid classification neuron. We found that with as few as four filters in its convolutional layer and an overall small number of parameters, SepConv1D obtained competitive performances in the four datasets. We believe these results may represent an important step towards building simpler, cheaper, faster, and more portable BCIs.},
  archive      = {J_NEUCOM},
  author       = {Montserrat Alvarado-González and Gibran Fuentes-Pineda and Jorge Cervantes-Ojeda},
  doi          = {10.1016/j.neucom.2020.10.104},
  journal      = {Neurocomputing},
  pages        = {37-52},
  shortjournal = {Neurocomputing},
  title        = {A few filters are enough: Convolutional neural network for p300 detection},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Convex clustering method for compositional data via sparse
group lasso. <em>NEUCOM</em>, <em>425</em>, 23–36. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional sparse clustering with compositional data is of great practical importance, as exemplified by applications in high-throughput gene expression profiles analysis. In this paper, we develop a compositional clustering framework based on convex clustering, which is a convex relaxation of hierarchical clustering that incorporates a fused penalty term on the cluster prototypes. To explicitly deal with the issue of high dimensionality and sparsity, we propose the C C ompositional C C onvex C C lustering with S S parse G G roup L L asso (CCC-SGL). The isometric logratio (ilr) transformation is first applied to transform the composition in the simplex space to the standard Euclidean geometry. Then, a group lasso penalty and a lasso penalty are imposed on the cluster centers, which effectively selects informative features and promotes within-feature sparsity. The proposed convex clustering formulation is numerically and efficiently solved with the proximal gradient descent algorithm within the Alternating Direction Method of Multipliers (ADMM) framework. Simulation studies are carried out to evaluate the performance of the proposed methodology and also a real data set in microbiome sequencing is analyzed.},
  archive      = {J_NEUCOM},
  author       = {Xiaokang Wang and Huiwen Wang and Shanshan Wang and Jidong Yuan},
  doi          = {10.1016/j.neucom.2020.10.105},
  journal      = {Neurocomputing},
  pages        = {23-36},
  shortjournal = {Neurocomputing},
  title        = {Convex clustering method for compositional data via sparse group lasso},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Utterance-focusing multiway-matching network for
dialogue-based multiple-choice machine reading comprehension.
<em>NEUCOM</em>, <em>425</em>, 12–22. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dialogue-based multiple-choice machine reading comprehension (MRC) is one of most difficult and novel tasks because it requires more advanced reading comprehension skills, such as speaker’s intention analysis, non-extractive reasoning, commonsense knowledge . Previous models usually only compute attention scores from the fixed representation of entire dialogue, and also do not fully consider the contribution of dialogue, question, options, and their combinations respectively. In this paper, we introduce Utterance-focusing Multiway-matching Network (UMN), a simple but effective human mimicking model for dialogue-based multiple-choice MRC. First, two utterance-focusing mechanisms called ParaUF and AutoUF are proposed to extract the utterances that are most relevant to the question and option: ParaUF gets the bilinear weighted distance between each utterance of dialogue and question and option during training while AutoUF obtains the scores by the relevance, overlap and coverage (ROC) rules before training process. Second, we adopted the multiway-matching mechanism to capture the relationship among the question, option and selected utterances through calculating the attention weights between the quadruplet of four sequences: utterances, question, option and the concatenation of each two. We evaluate the proposed model on dialogue-based multiple-choice MRC tasks, DREAM, and outperformed recently published methods under the same pre-trained model. A series of detailed analysis is also conducted to interpret the differences of two utterance-focusing mechanisms and the effectiveness of the proposed multiway-matching mechanism.},
  archive      = {J_NEUCOM},
  author       = {Yingjie Gu and Xiaolin Gui and Defu Li},
  doi          = {10.1016/j.neucom.2020.10.107},
  journal      = {Neurocomputing},
  pages        = {12-22},
  shortjournal = {Neurocomputing},
  title        = {Utterance-focusing multiway-matching network for dialogue-based multiple-choice machine reading comprehension},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Parallel pathway dense neural network with weighted fusion
structure for brain tumor segmentation. <em>NEUCOM</em>, <em>425</em>,
1–11. (<a href="https://doi.org/10.1016/j.neucom.2020.11.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Brain tumor segmentation is one of the most challenging tasks for radiomics analysis. Manual segmentation by radiologists is both laborious and subjective, which limits the number of study cases and the reproductivity of each clinical study. Hence, the automatic tumor segmentation method is in high demand, not only to segment the tumor, but also divide it into several fine-grained specific categories in voxel level. To this end, we propose a 3D Center-crop Dense Block for medical images by introducing high-level supervision into the lower layers of neural networks and adopt a parallel pathway network architecture of attention and context pathways. The attention pathway is of normal resolution and mainly concentrate on the detailed information of each voxel, while the context pathway is of low resolution and focus on the surrounding information. Furthermore, we also involve cross-pathway connections from attention pathway to context pathway with weighted fusion structure to compensate the missing detailed information caused by downsampling. The segmentation performance on the BraTS 2015 and BraTS 2017 datasets corroborate the effectiveness of the proposed deep learning architecture over the state-of-the-art results.},
  archive      = {J_NEUCOM},
  author       = {Fangyan Ye and Yingbin Zheng and Hao Ye and Xiaohao Han and Yuxin Li and Jun Wang and Jian Pu},
  doi          = {10.1016/j.neucom.2020.11.005},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {Parallel pathway dense neural network with weighted fusion structure for brain tumor segmentation},
  volume       = {425},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fractional-order controllability of multi-agent systems with
time-delay. <em>NEUCOM</em>, <em>424</em>, 268–277. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generally, nature is understood and explored from the point of view of integer order, however, lots of physical systems in complex practical environments can exhibit the fractional-order (non-integer order) dynamics, which can better reveal the essential properties, behaviors and the law of basic development. A novel fractional-order model with time-delay is built and the fractional-order controllability problem of networked multi-agent systems (MASs) is discussed. Comparing with the integer-order controllability problem for MASs, the fractional-order controllability problem of MASs not only needs to consider the dynamics of the agent itself, the communication and connection between the agents and the protocols followed by the evolution of the agent undefined state, but also to consider the order number of MASs. It is also shown that the fractional-order controllability of MASs with time-delay only lies on the communication interaction from the leaders to followers and the order number of such system, but time-delay has no effect on the controllability via the controllable rank criterion. Some computationally efficient conditions of the fractional-order controllability for MASs with time-delay are obtained based on fixed and switching topologies , respectively.},
  archive      = {J_NEUCOM},
  author       = {Bo Liu and Housheng Su and Licheng Wu and Xiali Li and Xue Lu},
  doi          = {10.1016/j.neucom.2020.04.083},
  journal      = {Neurocomputing},
  pages        = {268-277},
  shortjournal = {Neurocomputing},
  title        = {Fractional-order controllability of multi-agent systems with time-delay},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Neural-network-based decentralized output-feedback control
for nonlinear large-scale delayed systems with unknown dead-zones and
virtual control coefficients. <em>NEUCOM</em>, <em>424</em>, 255–267.
(<a href="https://doi.org/10.1016/j.neucom.2020.02.086">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An adaptive decentralized output-feedback control problem is investigated for a class of pure-feedback large-scale nonlinear systems with mismatched uncertainties, unknown dead-zones and unknown virtual control coefficients. At the same time, the nonlinear interconnections involve time-varying delays. Because only output information can be obtained, a state observer is constructed first. By using the infinite approximation ability of the radial basis function neural networks , the difficulty caused by the unknown nonlinearities is successfully overcome. Based on the appropriate Lyapunov–Krasovskii functions, the time-delay terms are compensated. The unknown virtual control coefficients are disposed by the convex combination method. By combining the backstepping technique with decentralized control principle, the adaptive neural decentralized output-feedback controllers are constructed to guarantee all the signals of the resulting closed-loop systems are bounded. And meanwhile, the error signals can converge to a small neighborhood of the origin. The simulation examples are provided to test our results.},
  archive      = {J_NEUCOM},
  author       = {Honghong Wang and Bing Chen and Chong Lin and Yumei Sun},
  doi          = {10.1016/j.neucom.2020.02.086},
  journal      = {Neurocomputing},
  pages        = {255-267},
  shortjournal = {Neurocomputing},
  title        = {Neural-network-based decentralized output-feedback control for nonlinear large-scale delayed systems with unknown dead-zones and virtual control coefficients},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using a low correlation high orthogonality feature set and
machine learning methods to identify plant pentatricopeptide repeat
coding gene/protein. <em>NEUCOM</em>, <em>424</em>, 246–254. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying whether a pentatricopeptide repeat (PPR) exists in an amino acid is a significant task in the field of bioinformatics. To address this problem, an identification method that combines an optimal feature set selection framework and machine learning algorithms is proposed to recognize the PPR coding genes and proteins in the sequence of amino acid. The original 188-dimensional (D) features are obtained using a feature extraction method, which is successively optimised through a covariance analysis , max-relevant-max-distance processing, and principal component analysis to reduce it to an optimal feature set that has fewer but more expressive features. Four machine learning methods are then used to serve as the classifiers for the identification task. The final number of feature data dimensions is reduced from 188 to only 10, and according to the experimental results from support vector machine methods, the loss of the AUC and the F 1 values are only 3.26\% and 10.1\%, respectively. Moreover, after applying the J48, random forest , and naïve Bayes methods as classifiers, it was also found that the optimal feature set with 10 dimensions has an almost equivalent performance for a 10-fold validation test.},
  archive      = {J_NEUCOM},
  author       = {Changli Feng and Quan Zou and Donghua Wang},
  doi          = {10.1016/j.neucom.2020.02.079},
  journal      = {Neurocomputing},
  pages        = {246-254},
  shortjournal = {Neurocomputing},
  title        = {Using a low correlation high orthogonality feature set and machine learning methods to identify plant pentatricopeptide repeat coding gene/protein},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LDGRNMF: LncRNA-disease associations prediction based on
graph regularized non-negative matrix factorization. <em>NEUCOM</em>,
<em>424</em>, 236–245. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emerging evidence suggests that long non-coding RNAs (lncRNAs) play an important role in various biological processes and human diseases. Exploring the associations between lncRNAs and diseases can better understand the complex disease mechanisms. However, expensive and time-consuming for exploring by biological experiments, it is imperative to develop more accurate and efficient computational approaches to predicting lncRNA-disease associations. In this work, we develop a new computational approach to predict lncRNA-disease associations using graph regularized nonnegative matrix factorization (LDGRNMF), which considers disease-associated lncRNAs identification as recommendation system problem. More specifically, we calculate the similarity of disease based on Gaussian interaction profile kernel and disease semantic information, and calculate the similarity of lncRNA based on Gaussian interaction profile kernel. Secondly, the weighted K nearest known neighbor interaction profiles is applied to reconstruct lncRNA-disease association adjacency matrix . Finally, graph regularized nonnegative matrix factorization is exploited to predict the potential associations between lncRNAs and diseases. In the five-fold cross-validation experiments, LDGRNMF achieves AUC of 0.8985 which outperforms other compared methods. Moreover, in case studies for stomach cancer, breast cancer and lung cancer, 9, 8 and 6 of the top 10 candidate lncRNAs predicted by LDGRNMF are verified, respectively. Rigorous experimental results indicate that our method can be regarded as an effectively tool for predicting potential lncRNA-disease associations.},
  archive      = {J_NEUCOM},
  author       = {Mei-Neng Wang and Zhu-Hong You and Lei Wang and Li-Ping Li and Kai Zheng},
  doi          = {10.1016/j.neucom.2020.02.062},
  journal      = {Neurocomputing},
  pages        = {236-245},
  shortjournal = {Neurocomputing},
  title        = {LDGRNMF: LncRNA-disease associations prediction based on graph regularized non-negative matrix factorization},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered state estimation for markovian jumping
neural networks: On mode-dependent delays and uncertain transition
probabilities. <em>NEUCOM</em>, <em>424</em>, 226–235. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the event-triggered state estimation (ETSE) problem for a class of discrete-time Markovian jumping neural networks with mode-dependent time-delays and uncertain transition probabilities. The parameters of the neural networks experience switches that are characterized by a Markovian chain whose transition probabilities are allowed to be uncertain. The event-triggered mechanism is introduced in the sensor-to-estimator channel to reduce the frequency of signal communication. The aim of this paper is to develop an ETSE scheme such that the estimation error dynamics is exponentially ultimately bounded in the mean square. To achieve the aim, two sufficient conditions are proposed with the first one guaranteeing the existence of the required state estimator , and the second one giving the algorithm for designing the corresponding estimator gain by solving some matrix inequalities. In the end, the validity of the proposed estimation scheme is illustrated by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Hua Yang and Zidong Wang and Yuxuan Shen and Fuad E. Alsaadi and Fawaz E. Alsaadi},
  doi          = {10.1016/j.neucom.2020.10.050},
  journal      = {Neurocomputing},
  pages        = {226-235},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered state estimation for markovian jumping neural networks: On mode-dependent delays and uncertain transition probabilities},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Multiple kernel clustering with pure graph learning scheme.
<em>NEUCOM</em>, <em>424</em>, 215–225. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing graph-based multiple kernel clustering (GMKC) methods usually adopt a hybridization scheme, termed HGMKC for short, which binds multiple kernel learning (MKL) and graph-based clustering (GBC) together, the former aims to construct a consensus kernel and the latter is used to learn an affinity graph based on the consensus kernel. Obviously, HGMKC performs graph learning and spectral clustering separately. Additionally, the performance of this hybridization is largely determined by MKL, which is empirically contrary to the fact that graph learning is the key of graph-based methods, rather than kernel learning. In this paper, we propose a pure GMKC method, dubbed PGMKC, which contains two parts, including candidate kernel graphs learning (CKGL) and kernel graph fusion (KGF). Specially, CKGL concentrates on constructing multiple candidate kernel graphs in Hilbert kernel space relying on kernel self-expressiveness; KGF leverages a flexibly auto-weighted graph fusion strategy and a connectivity regularizer to yield a consensus kernel graph directly. Compared to HGMKC, PGMKC avoids paying too much attention to consensus kernel construction, thus can focus more on affinity graph learning. Moreover, an efficient and effective optimization algorithm is developed to solve the proposed model. Experimental results on ten benchmark datasets demonstrate that the proposed PGMKC performs better than the state-of-the-art HGMKC competitors.},
  archive      = {J_NEUCOM},
  author       = {Xingfeng Li and Zhenwen Ren and Haoyun Lei and Yuqing Huang and Quansen Sun},
  doi          = {10.1016/j.neucom.2020.10.052},
  journal      = {Neurocomputing},
  pages        = {215-225},
  shortjournal = {Neurocomputing},
  title        = {Multiple kernel clustering with pure graph learning scheme},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Utility-efficient differentially private k-means clustering
based on cluster merging. <em>NEUCOM</em>, <em>424</em>, 205–214. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy is widely used in data analysis. State-of-the-art k -means clustering algorithms with differential privacy typically add an equal amount of noise to centroids for each iterative computation. In this paper, we propose a novel differentially private k -means clustering algorithm, DP-KCCM, that significantly improves the utility of clustering by adding adaptive noise and merging clusters. Specifically, to obtain k clusters with differential privacy, the algorithm first generates n × k n×k initial centroids, adds adaptive noise for each iteration to get n × k n×k clusters, and finally merges these clusters into k ones. We theoretically prove the differential privacy of the proposed algorithm. Surprisingly, extensive experimental results show that: 1) cluster merging with equal amounts of noise improves the utility somewhat; 2) while adding adaptive noise only does not improve the utility, combining both cluster merging and adaptive noise further improves the utility significantly.},
  archive      = {J_NEUCOM},
  author       = {Tianjiao Ni and Minghao Qiao and Zhili Chen and Shun Zhang and Hong Zhong},
  doi          = {10.1016/j.neucom.2020.10.051},
  journal      = {Neurocomputing},
  pages        = {205-214},
  shortjournal = {Neurocomputing},
  title        = {Utility-efficient differentially private K-means clustering based on cluster merging},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distribution equalization learning mechanism for road crack
detection. <em>NEUCOM</em>, <em>424</em>, 193–204. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual-based road crack detection becomes a hot research topic over the last decade because of its huge application demands. Road crack detection is actually a special form of salient object detection task, whose objects are small and distribute randomly in the image compared to the traditional ones, which increase the difficulty of detecting. Most conventional methods utilize bottom information, such as color, texture, and contrast, to extract the crack regions in the image. Even though these methods can achieve satisfactory performances for images with simple scenarios, they are easily interfered by some factors such as light and shadow, which may decrease the detection result directly. Inspired by the competitive performances of deep convolutional neural networks on many visual tasks, we propose a distribution equalization learning mechanism for road crack detection in this paper. Firstly, we consider the crack detection task as a pixel-level classification and use a U-Net based architecture to finalize it. Secondly, the occurrence probability of crack and non-crack are so different, which results in the ill-conditioned classifier and undesirable detection performance, especially the high false detection rate. In this case, we propose a weighted cross entropy loss term and a data augmentation strategy to avoid influence from imbalanced samples through emphasizing the crack regions. Additionally, we propose an auxiliary interaction loss, and combine it with the popular self-attention strategy to alleviate the fracture situations through considering relationships among different local regions in the image. Finally, we tested the proposed method on three public and challenging datasets, and the experimental results demonstrate its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Jie Fang and Bo Qu and Yuan Yuan},
  doi          = {10.1016/j.neucom.2019.12.057},
  journal      = {Neurocomputing},
  pages        = {193-204},
  shortjournal = {Neurocomputing},
  title        = {Distribution equalization learning mechanism for road crack detection},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel automatic classification detection for epileptic
seizure based on dictionary learning and sparse representation.
<em>NEUCOM</em>, <em>424</em>, 179–192. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) signals play an important role in the epilepsy detection. In the past decades, the automatic detection system of epilepsy has emerged and performed well. In this paper, a novel sparse representation-based epileptic seizure classification based on the dictionary learning with homotopy (DLWH) algorithm is proposed. The performance of the proposed method evaluates on two public EEG databases provided by the Bonn University and Childrens Hospital Boston-Massachusetts Institute of Technology (CHB-MIT), various classification cases that include health and seizure; non-seizure and seizure; inter ictal (seizure-free interval) and ictal (seizure). The results show that the DLWH only completes the test with 19.671 s compared with the traditional sparse representation methods with high degree of automation, which are better than those obtained using the well-known dictionary learning method. Besides, two publicly available benchmark databases recognition rates are as high as 100\%, 99.5\%, with average of 99.5\% and 95.06\%,\% respectively, and the results show that the epileptic detection system based on the dictionary learning has a high application value.},
  archive      = {J_NEUCOM},
  author       = {Hong Peng and Cancheng Li and Jinlong Chao and Tao Wang and Chengjian Zhao and Xiaoning Huo and Bin Hu},
  doi          = {10.1016/j.neucom.2019.12.010},
  journal      = {Neurocomputing},
  pages        = {179-192},
  shortjournal = {Neurocomputing},
  title        = {A novel automatic classification detection for epileptic seizure based on dictionary learning and sparse representation},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Discrete-time high-order neural network identifier trained
with high-order sliding mode observer and unscented kalman filter.
<em>NEUCOM</em>, <em>424</em>, 172–178. (<a
href="https://doi.org/10.1016/j.neucom.2019.12.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a method to identify an unknown discrete-time nonlinear system , using high-order neural networks and high-order sliding mode algorithms, which may be subject to internal and external disturbances. Based on the information obtained from available system states, a high-order neural network model is proposed to approximate the system dynamics. Neural network weights are trained by means of the unscented Kalman filter and high-order sliding mode observer. A simulation example is included to illustrate effectiveness of the proposed scheme.},
  archive      = {J_NEUCOM},
  author       = {M. Hernandez-Gonzalez and M.V. Basin and E.A. Hernandez-Vargas},
  doi          = {10.1016/j.neucom.2019.12.005},
  journal      = {Neurocomputing},
  pages        = {172-178},
  shortjournal = {Neurocomputing},
  title        = {Discrete-time high-order neural network identifier trained with high-order sliding mode observer and unscented kalman filter},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint offloading and scheduling decisions for DAG
applications in mobile edge computing. <em>NEUCOM</em>, <em>424</em>,
160–171. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.081">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mobile edge computing (MEC) is a promising technology to support computation-intensive tasks for mobile devices which are usually associated with limited resources. Many researches from both scientific and industrial field have put focuses on MEC. However, most of them assume that in a MEC environment, the offloaded tasks are independent or that there is only one server in the MEC center. Nevertheless, in reality, tasks with dependencies take the majority and in a MEC center, there are usually multiple servers. Under this circumstance, previous methods no longer take effects. In this work, we consider offloading with precedence constraints among tasks, and try to minimize makespan over a MEC center with multiple servers. This problem becomes more complex given that a task can not start unless its predecessors are completed. To solve the problem, we jointly involve front end task offloading order and back end scheduling to optimize makespan, and propose a corresponding algorithm called joint re-ordering and frequency scaling (JRFS). Extensive experiments have been conducted. The results show that compared with several other methods, JRFS can achieve better makespan.},
  archive      = {J_NEUCOM},
  author       = {Jie Liang and Kenli Li and Chubo Liu and Keqin Li},
  doi          = {10.1016/j.neucom.2019.11.081},
  journal      = {Neurocomputing},
  pages        = {160-171},
  shortjournal = {Neurocomputing},
  title        = {Joint offloading and scheduling decisions for DAG applications in mobile edge computing},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Boosting prior knowledge in streaming variational bayes.
<em>NEUCOM</em>, <em>424</em>, 143–159. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Exploiting prior/human knowledge is an effective way to enhance Bayesian models , especially in cases of sparse or noisy data, for which building an entirely new model is not always possible. There is a lack of studies on the effect of external prior knowledge in streaming environments, where the data come sequentially and infinitely. In this work, we show the problem of vanishing prior knowledge in streaming variational Bayes . This is a serious drawback in various applications. We then develop a simple framework to boost the external prior when learning a Bayesian model from data streams. By boosting, the prior knowledge can be maintained and efficiently exploited through each minibatch of streaming data. We evaluate the performance of our framework in four scenarios: streaming in synthetic data, streaming sentiment analysis , streaming learning for latent Dirichlet allocation , and streaming text classification , in comparison with the methods that do not keep priors. From extensive experiments, we find that when provided good external knowledge, our framework can improve the performance of a Bayesian model, often by a significant margin for noisy and short text streams.},
  archive      = {J_NEUCOM},
  author       = {Duc Anh Nguyen and Van Linh Ngo and Kim Anh Nguyen and Canh Hao Nguyen and Khoat Than},
  doi          = {10.1016/j.neucom.2020.10.026},
  journal      = {Neurocomputing},
  pages        = {143-159},
  shortjournal = {Neurocomputing},
  title        = {Boosting prior knowledge in streaming variational bayes},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). No-reference stereoscopic image quality assessment based on
global and local content characteristics. <em>NEUCOM</em>, <em>424</em>,
132–142. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {No-reference stereoscopic images quality assessment (NR-SIQA) via deep learning has gained increasing attention. In this paper, we propose a no-reference stereoscopic image quality assessment method based on global and local content characteristics. The proposed method simulates the perception route of human visual system , and derives features from the fused view and single view through the global feature fusion sub-network and local feature enhancement sub-network. As for the fused view, a cross-fusion strategy is applied to model the process in the V1 visual cortex , and the multi-scales pooling (MSP) is utilized to integrate context information under different sub-regions for effective global feature extraction. As for the single view, the asymmetric convolution block (ACB) is introduced to strengthen the local information description. By jointly considering the fused view and single view, the proposed network can efficiently extract the features for quality assessment. Finally, a weighted average strategy is applied to estimate the visual quality of stereoscopic image. Experimental results on 3D quality databases demonstrate that the proposed network is superior to the state-of-the-art metrics, and achieves an excellent performance.},
  archive      = {J_NEUCOM},
  author       = {Lili Shen and Xiongfei Chen and Zhaoqing Pan and Kefeng Fan and Fei Li and Jianjun Lei},
  doi          = {10.1016/j.neucom.2020.10.024},
  journal      = {Neurocomputing},
  pages        = {132-142},
  shortjournal = {Neurocomputing},
  title        = {No-reference stereoscopic image quality assessment based on global and local content characteristics},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Formation-containment control for multi-agent systems with
sampled data and time delays. <em>NEUCOM</em>, <em>424</em>, 125–131.
(<a href="https://doi.org/10.1016/j.neucom.2019.11.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the formation containment control under sampling and with time delays for multi-agent systems (MASs). First, a novel sampling control protocol for the MASs to achieve formation containment is proposed, where the communication among agents is only occurred at the sampling instance. Then the communication load and the waste of energy can be decreased significantly. In addition, time delays are considered in this paper. Second, by establishing an appropriate Lyapunov function , sufficient conditions for MASs with sampled data and time delays reaching formation containment are obtained by handling the established Lyapunov function. Finally, the obtained results are demonstrated by a simulation example.},
  archive      = {J_NEUCOM},
  author       = {Jinxin Zhang and Housheng Su},
  doi          = {10.1016/j.neucom.2019.11.030},
  journal      = {Neurocomputing},
  pages        = {125-131},
  shortjournal = {Neurocomputing},
  title        = {Formation-containment control for multi-agent systems with sampled data and time delays},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Instance search based on weakly supervised feature learning.
<em>NEUCOM</em>, <em>424</em>, 117–124. (<a
href="https://doi.org/10.1016/j.neucom.2019.11.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Instance search has been conventionally addressed as an image retrieval issue. In the existing solutions, traditional hand-crafted features and global deep features have been widely adopted. Unfortunately, since the features are not directly derived from the exact area of an instance in an image, satisfactory performance from most of them is undesirable. In this paper, a compact instance level feature representation is proposed. The scheme basically consists of two convolutional neural network (CNN) pipelines. One is designed for localizing potential instances from an image, while another is trained to learn object-aware weights to produce distinctive features. The sensitivity to the unknown categories, the distinctiveness to different instances, and most importantly, the capability of localizing an instance in an image are all carefully considered in the feature design. Moreover, both pipelines only require image level annotations, which makes the framework feasible for large-scale image collections with variety of instances. To the best of our knowledge, this is the first piece of work that builds the instance level representation based on weakly supervised object detection.},
  archive      = {J_NEUCOM},
  author       = {Jie Lin and Yu Zhan and Wan-Lei Zhao},
  doi          = {10.1016/j.neucom.2019.11.029},
  journal      = {Neurocomputing},
  pages        = {117-124},
  shortjournal = {Neurocomputing},
  title        = {Instance search based on weakly supervised feature learning},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A new discrete-time neural network for quadratic programming
with general linear constraints. <em>NEUCOM</em>, <em>424</em>, 107–116.
(<a href="https://doi.org/10.1016/j.neucom.2019.11.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a discrete-time neurodynamic model to solve linear and quadratic programming with respect to linear equality and inequality constraints . The new model is obtained by using an auxiliary variable, and can be seen as the generalization of a neural model for bound constraints in the literature in the sense that bound constraints limit a linear function of the desired variable. The proposed neural solution is proved to be stable in the sense of Lyapunov and converges globally to the optimal solution of the given minimization by proper adjustment of a parameter. The model is further simplified for the case that the equality constraints entails a full row-rank linear mapping. The proposed neural solution is comparable with the state-of-the-art in terms of both the number of operations in each iteration and the required components for its circuit implementation. The experiments confirm the reasonable performance of the proposed neu a ral network.},
  archive      = {J_NEUCOM},
  author       = {Majid Mohammadi},
  doi          = {10.1016/j.neucom.2019.11.028},
  journal      = {Neurocomputing},
  pages        = {107-116},
  shortjournal = {Neurocomputing},
  title        = {A new discrete-time neural network for quadratic programming with general linear constraints},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The generalization error of graph convolutional networks may
enlarge with more layers. <em>NEUCOM</em>, <em>424</em>, 97–106. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph Neural Networks(GNNs) are powerful methods to analyze the non-Euclidean data. As a dominant type of GNN, Graph Convolutional Networks(GCNs) have wide applications. However, the analysis of the generalization error for GCNs with multilayer is limited. Based on the review of single-layer GCNs, this paper analyzes the generalization error of two-layers GCNs and extends the conclusion to the general GCNs models. Firstly, this paper examines two-layers GCNs and obtains the stability of the GCNs algorithm. And then, based on this algorithmic stability, the generalization stability of multilayer GCNs is obtained. This paper shows that the algorithmic stability of GCNs depends upon the graph filters and its product with node features as well as the training procedure. Furthermore, the generalization error gap of GCNs tends to be enlarged with more layers, which can interpret why GCNs with deeper layers have relatively poorer performance in test datasets.},
  archive      = {J_NEUCOM},
  author       = {Xianchen Zhou and Hongxia Wang},
  doi          = {10.1016/j.neucom.2020.10.109},
  journal      = {Neurocomputing},
  pages        = {97-106},
  shortjournal = {Neurocomputing},
  title        = {The generalization error of graph convolutional networks may enlarge with more layers},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Noise-tolerant neural algorithm for online solving
yang-baxter-type matrix equation in the presence of noises: A
control-based method. <em>NEUCOM</em>, <em>424</em>, 84–96. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-invariant/varying Yang-Baxter-type matrix equation problems in the presence of noises often arise in the fields of scientific computation and engineering implementation. Noises are ubiquitous and unavoidable in real systems but most existing models carry out the time-invariant/varying Yang-Baxter-type matrix equation problem with an indispensable precondition that the solving process is free of noises. In this paper, a noise-tolerant zeroing neural network model (NTZNNM) is first proposed, analyzed and verified by feat of a classical zeroing neural network model (ZNNM) from a control-theoretic viewpoint, and note that NTZNNM behaves efficiently in online solving the time-invariant/varying Yang-Baxter-type matrix equation problem with different measurement noises. Moreover, a general noise-tolerant zeroing neural network model (GNTZNNM) derived from a general noise-tolerant zeroing neural dynamic model (GNTZNDM) is developed and utilized to accelerating the convergent rate and enhancing the robustness. Then, theoretical results further demonstrate that the presented NTZNNM owns the ability to globally/exponentially converge with different measurement noises. Furthermore, the global convergence of GNTZNDM with different monotonically-increasing odd activation functions is also investigated and analyzed in detail. Besides, numerical results are provided to substantiate the efficiency, availability and superiority of the developed NTZNNM and GNTZNNM for time-invariant/varying Yang-Baxter-type matrix equation problems with inherent tolerance to noises.},
  archive      = {J_NEUCOM},
  author       = {Tian Shi and Yantao Tian and Zhongbo Sun and Keping Liu and Long Jin and Junzhi Yu},
  doi          = {10.1016/j.neucom.2020.10.110},
  journal      = {Neurocomputing},
  pages        = {84-96},
  shortjournal = {Neurocomputing},
  title        = {Noise-tolerant neural algorithm for online solving yang-baxter-type matrix equation in the presence of noises: A control-based method},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Minor class-based status detection for pipeline network
using enhanced generative adversarial networks. <em>NEUCOM</em>,
<em>424</em>, 71–83. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For the operational status detection of a pipeline network, it is essential to obtain enough samples of each class during the network operation. However, the phenomenon of few actual leak samples give rise to the imbalanced dataset problem. To address this issue, this paper proposes a minor class-based status detection method using enhanced generative adversarial networks (enhanced-GANs). First, a generative model with a U-net structure is established to generate the required samples with the modified normal samples, and the L1 loss and L2 loss functions are utilized to update the network parameters. Then, output results and extracted features regarding different layers of discriminative network are added in the generative network loss function to improve the quality of the generated samples. Furthermore, based on the hidden features extracted by the trained discriminative network, an enhanced dual judgment scheme is proposed to improve the status detection performance. Finally, extensive experiments are carried out to evaluate the proposed method with the dataset collected from a practical pipeline network. The experiment results show that the proposed method can not only provide enough leak samples but also effectively improves the status detection accuracy for a pipeline network.},
  archive      = {J_NEUCOM},
  author       = {Xuguang Hu and Huaguang Zhang and Dazhong Ma and Rui Wang and Jun Zheng},
  doi          = {10.1016/j.neucom.2020.11.009},
  journal      = {Neurocomputing},
  pages        = {71-83},
  shortjournal = {Neurocomputing},
  title        = {Minor class-based status detection for pipeline network using enhanced generative adversarial networks},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Light fixed-time control for cluster synchronization of
complex networks. <em>NEUCOM</em>, <em>424</em>, 63–70. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.111">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fixed-time control allows complex systems to be stable in a settling time independent of initial conditions, which receives extensive attentions in the field of control and engineering. However, the application to complex systems suffers from the issues of chattering effects and multi-parameters. To address these issues, a light fixed-time controller is proposed with a compact formulation by revisiting continuous control paradigm. Sufficient conditions are then obtained by Lyapunov stability theorem to guarantee the nodes in each cluster to desired states in a settling time. At last, numerical examples are given to verify the effectiveness of our proposed control strategy.},
  archive      = {J_NEUCOM},
  author       = {Shengqin Jiang and Yuankai Qi and Shuiming Cai and Xiaobo Lu},
  doi          = {10.1016/j.neucom.2020.10.111},
  journal      = {Neurocomputing},
  pages        = {63-70},
  shortjournal = {Neurocomputing},
  title        = {Light fixed-time control for cluster synchronization of complex networks},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of impulsive controllers and impulsive control
strategy for the mittag-leffler stability behavior of fractional gene
regulatory networks. <em>NEUCOM</em>, <em>424</em>, 54–62. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we consider fractional-order gene regulatory networks . The impulsive effects on their Mittag-Leffler stability properties are investigated and new criteria are proposed. The main results are proved by using the fractional Lyapunov method. Examples are given to demonstrate the efficiency of the proposed impulsive control strategy. Our results are the first step in the development of the theory of impulsive control fractional-order gene regulatory networks .},
  archive      = {J_NEUCOM},
  author       = {Trayan Stamov and Ivanka Stamova},
  doi          = {10.1016/j.neucom.2020.10.112},
  journal      = {Neurocomputing},
  pages        = {54-62},
  shortjournal = {Neurocomputing},
  title        = {Design of impulsive controllers and impulsive control strategy for the mittag-leffler stability behavior of fractional gene regulatory networks},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MOGPTK: The multi-output gaussian process toolkit.
<em>NEUCOM</em>, <em>424</em>, 49–53. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We present MOGPTK, a Python package for multi-channel data modelling using Gaussian processes (GP). The aim of this toolkit is to make multi-output GP (MOGP) models accessible to researchers, data scientists, and practitioners alike. MOGPTK uses a Python front-end and relies on the PyTorch suite, thus enabling GPU-accelerated training. The toolkit facilitates implementing the entire pipeline of GP modelling, including data loading, parameter initialization, model learning, parameter interpretation, up to data imputation and extrapolation. MOGPTK implements the main multi-output covariance kernels from literature, as well as spectral-based parameter initialization strategies. The source code, tutorials and examples in the form of Jupyter notebooks, together with the API documentation, can be found in this GitHub repository: https://github.com/GAMES-UChile/mogptk .},
  archive      = {J_NEUCOM},
  author       = {Taco de Wolff and Alejandro Cuevas and Felipe Tobar},
  doi          = {10.1016/j.neucom.2020.09.085},
  journal      = {Neurocomputing},
  pages        = {49-53},
  shortjournal = {Neurocomputing},
  title        = {MOGPTK: The multi-output gaussian process toolkit},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integrated deep learning method for workload and resource
prediction in cloud systems. <em>NEUCOM</em>, <em>424</em>, 35–48. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cloud computing providers face several challenges in precisely forecasting large-scale workload and resource time series. Such prediction can help them to achieve intelligent resource allocation for guaranteeing that users’ performance needs are strictly met with no waste of computing, network and storage resources. This work applies a logarithmic operation to reduce the standard deviation before smoothing workload and resource sequences. Then, noise interference and extreme points are removed via a powerful filter. A Min–Max scaler is adopted to standardize the data. An integrated method of deep learning for prediction of time series is designed. It incorporates network models including both bi-directional and grid long short-term memory network to achieve high-quality prediction of workload and resource time series. The experimental comparison demonstrates that the prediction accuracy of the proposed method is better than several widely adopted approaches by using datasets of Google cluster trace.},
  archive      = {J_NEUCOM},
  author       = {Jing Bi and Shuang Li and Haitao Yuan and MengChu Zhou},
  doi          = {10.1016/j.neucom.2020.11.011},
  journal      = {Neurocomputing},
  pages        = {35-48},
  shortjournal = {Neurocomputing},
  title        = {Integrated deep learning method for workload and resource prediction in cloud systems},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A partial policy iteration ADP algorithm for nonlinear
neuro-optimal control with discounted total reward. <em>NEUCOM</em>,
<em>424</em>, 23–34. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper constructs a partial policy iteration adaptive dynamic programming (ADP) algorithm to solve the optimal control problem of nonlinear systems with discounted total reward. Compared with traditional policy iteration ADP algorithm, the approach updates the iterative control law only in a local region of the global system state space. With the benefit of this feature, the overall computational burden at each iteration for processing units can be significantly reduced. Hence, this feature enables our algorithm to be successfully executed on low-performance devices such as smartphones, smartwatches and the Internet of Things (IoT) objects. We provide the convergency analysis to show that the generated sequence of value functions is monotonically nonincreasing and can finally reach a local optimum. In addition, the corresponding local policy space is developed theoretically for the first time. Besides, when the sequence of the local system state spaces is chosen properly, we prove that the developed algorithm is capable of finding the global optimal performance index function for the nonlinear systems . Finally, we present a numerical simulation to demonstrate the effectiveness of the proposed algorithm.},
  archive      = {J_NEUCOM},
  author       = {Mingming Liang and Qinglai Wei},
  doi          = {10.1016/j.neucom.2020.11.014},
  journal      = {Neurocomputing},
  pages        = {23-34},
  shortjournal = {Neurocomputing},
  title        = {A partial policy iteration ADP algorithm for nonlinear neuro-optimal control with discounted total reward},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised anomaly segmentation via deep feature
reconstruction. <em>NEUCOM</em>, <em>424</em>, 9–22. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic detecting anomalous regions in images of objects or textures without priors of the anomalies is challenging, especially when the anomalies appear in very small areas of the images, making difficult-to-detect visual variations, such as defects on manufacturing products. This paper proposes an effective unsupervised anomaly segmentation approach that can detect and segment out the anomalies in small and confined regions of images. Concretely, we develop a multi-scale regional feature generator which can generate multiple spatial context-aware representations from pre-trained deep convolutional networks for every subregion of an image. The regional representations not only describe the local characteristics of corresponding regions but also encode their multiple spatial context information, making them discriminative and very beneficial for anomaly detection . Leveraging these descriptive regional features, we then design a deep yet efficient convolutional autoencoder and detect anomalous regions within images via fast feature reconstruction. Our method is simple yet effective and efficient. It advances the state-of-the-art performances on several benchmark datasets and shows great potential for real applications.},
  archive      = {J_NEUCOM},
  author       = {Yong Shi and Jie Yang and Zhiquan Qi},
  doi          = {10.1016/j.neucom.2020.11.018},
  journal      = {Neurocomputing},
  pages        = {9-22},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised anomaly segmentation via deep feature reconstruction},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-paced active learning for deep CNNs via effective loss
function. <em>NEUCOM</em>, <em>424</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks have achieved great success on computer vision tasks , but the lack of labeled samples hinders the application of it in the real world. Active learning is one of the effective methods to address large volumes of unlabeled data . It interactively selects a few samples based on a certain criterion and queries their labels from annotators. In order to reduce the labor of annotation, we propose a novel framework “self-paced multi-criteria active learning” on the image classification task . Unlike previous work, we treat each iteration of active learning as the step of self-paced learning which considers the model should gradually proceed from simplicity to complexity in training. In the stage of selecting samples, we combine clustering with a multiple criteria selection method to reduce the negative effects of hard samples. In the training phase, we design a similarity classification loss function to mitigate the impact of the deficiency of labeled data. Experiments on multiple datasets demonstrate that our proposed method can achieve higher performance than current approaches.},
  archive      = {J_NEUCOM},
  author       = {Tianxiang Yin and Ningzhong Liu and Han Sun},
  doi          = {10.1016/j.neucom.2020.11.019},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {Self-paced active learning for deep CNNs via effective loss function},
  volume       = {424},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HaemoKBS: A knowledge-based system for real-time, continuous
categorisation of adverse reactions in blood recipients.
<em>NEUCOM</em>, <em>423</em>, 756–767. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work introduces HaemoKBS, a novel Haemovigilance decision support system for adverse reactions in blood recipients. Machine learning inference and rule-based reasoning were applied to build the underlying decision support models, namely to automatically extract evidence from different types of data included in hospital notifications and incorporate a priori expert knowledge. The ultimate aim is to dynamically learn and improve the reasoning abilities of the system and thus, be able to provide educated recommendations to hospital notifiers along with understandable explanations on the acquired knowledge. Experiments over the records of the Portuguese National Haemovigilance System from the last 10 years demonstrate the practical usefulness of HaemoKBS, which will contribute to a better depiction of the adverse reactions and to flag any incomplete notification enforcing data quality.},
  archive      = {J_NEUCOM},
  author       = {Augusto Ramoa and Jorge Condeço and Florentino Fdez-Riverola and Anália Lourenço},
  doi          = {10.1016/j.neucom.2020.04.101},
  journal      = {Neurocomputing},
  pages        = {756-767},
  shortjournal = {Neurocomputing},
  title        = {HaemoKBS: A knowledge-based system for real-time, continuous categorisation of adverse reactions in blood recipients},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ensemble learning for electricity consumption forecasting in
office buildings. <em>NEUCOM</em>, <em>423</em>, 747–755. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents three ensemble learning models for short term load forecasting. Machine learning has evolved quickly in recent years, leading to novel and advanced models that are improving the forecasting results in multiple fields. However, in highly dynamic fields such as power and energy systems, dealing with the fast acquisition of large amounts of data from multiple data sources and taking advantage from the correlation between the multiple available variables is a challenging task, for which current models are not prepared. Ensemble learning is bringing promising results in this sense, as, by combining the results and use of multiple learners, is able to find new ways for current learning models to be used and optimized. In this paper three ensemble learning models are developed and the respective results compared: gradient boosted regression trees, random forests and an adaptation of Adaboost. Results for electricity consumption forecasting in hour-ahead are presented using a case-study based on real data from an office building. Results show that the adapted Adaboost model outperforms the reference models for hour-ahead load forecasting.},
  archive      = {J_NEUCOM},
  author       = {Tiago Pinto and Isabel Praça and Zita Vale and Jose Silva},
  doi          = {10.1016/j.neucom.2020.02.124},
  journal      = {Neurocomputing},
  pages        = {747-755},
  shortjournal = {Neurocomputing},
  title        = {Ensemble learning for electricity consumption forecasting in office buildings},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group decision support systems for current times: Overcoming
the challenges of dispersed group decision-making. <em>NEUCOM</em>,
<em>423</em>, 735–746. (<a
href="https://doi.org/10.1016/j.neucom.2020.04.100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We are living a change of paradigm regarding decision-making. On the one hand, there is a growing need to make decisions in group at both professional and personal levels, on the other hand, it is increasingly difficult for decision-makers to meet at the same place and at the same time. The Web-based Group Decision Support Systems intend to overcome this limitation, allowing decision-makers to contribute to the decision process anytime and anywhere. However, they have been defined inadequately which has been compromising its success. This work discusses the current Group Decision Support Systems limitations in terms of challenges and possible impediments for their acceptance by the organizations and propose a conceptual definition of a Web-based Group Decision Support System that intends to overcome the existing limitations and help them to affirm as a reliable and useful tool. In addition, some crucial topics are addressed, such as communication and perception, that are essential and sometimes forgotten in the support of dispersed decision-makers. We concluded that there are still some limitations, mostly in terms of models and applications, that prevent the design of higher quality systems.},
  archive      = {J_NEUCOM},
  author       = {João Carneiro and Patrícia Alves and Goreti Marreiros and Paulo Novais},
  doi          = {10.1016/j.neucom.2020.04.100},
  journal      = {Neurocomputing},
  pages        = {735-746},
  shortjournal = {Neurocomputing},
  title        = {Group decision support systems for current times: Overcoming the challenges of dispersed group decision-making},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep neural networks approaches for detecting and
classifying colorectal polyps. <em>NEUCOM</em>, <em>423</em>, 721–734.
(<a href="https://doi.org/10.1016/j.neucom.2020.02.123">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep Learning (DL) has attracted a lot of attention in the field of medical image analysis because of its higher performance in image classification when compared to previous state-of-the-art techniques. In addition, a recent meta-analysis found that the diagnostic performance of DL models is equivalent to that of health-care professionals. In this scenario, a lot of research using DL for polyp detection and classification have been published showing promising results in the last five years. Our work aims to review the most relevant studies from a technical point of view, focusing on the low-level details for the implementation of the DL models. To do so, this review analyzes the published research covering aspects like DL architectures, training strategies, data augmentation , transfer learning , or the features of the datasets used and their impact on the performance of the models. Additionally, comparative tables summarizing the main aspects analyzed in this review are publicly available at https://github.com/sing-group/deep-learning-colonoscopy .},
  archive      = {J_NEUCOM},
  author       = {Alba Nogueira-Rodríguez and Rubén Domínguez-Carbajales and Hugo López-Fernández and Águeda Iglesias and Joaquín Cubiella and Florentino Fdez-Riverola and Miguel Reboiro-Jato and Daniel Glez-Peña},
  doi          = {10.1016/j.neucom.2020.02.123},
  journal      = {Neurocomputing},
  pages        = {721-734},
  shortjournal = {Neurocomputing},
  title        = {Deep neural networks approaches for detecting and classifying colorectal polyps},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial neural network analysis of the academic
performance of students in virtual learning environments.
<em>NEUCOM</em>, <em>423</em>, 713–720. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Educational institutions continually strive to improve the services they offer, their aim is to have the best possible teaching staff, increase the quality of teaching and the academic performance of their students. A knowledge of the factors that affect student learning could help universities and study centres adjust their curricula and teaching methods to the needs of their students. One of the first measures employed by teaching institutions was to create Virtual Learning Environments (VLEs). This type of environment makes it possible to attract a larger number of students because it enables them to study from wherever they are in the world, meaning that the student’s location is no longer a constraint. Moreover, VLEs facilitate access to teaching resources, they make it easier to monitor the activity of the teaching staff and of the interactions between students and teachers. Thus, online environments make it possible to assess the factors that cause the students’ academic performance to increase or decrease. To understand the factors that influence the university learning process, this paper applies a series of automatic learning techniques to a public dataset, including tree-based models and different types of Artificial Neural Networks (ANNs). Having applied these techniques to the dataset, the number of times students have accessed the resources made available on VLE platforms has been identified as a key factor affecting student performance. This factor has been analysed by conducting a real case study which has involved 120 students doing a masters degree over a VLE platform. Concretely, the case study participants were masters degree students in areas related to computer engineering at the University of Salamanca.},
  archive      = {J_NEUCOM},
  author       = {Alberto Rivas and Alfonso González-Briones and Guillermo Hernández and Javier Prieto and Pablo Chamoso},
  doi          = {10.1016/j.neucom.2020.02.125},
  journal      = {Neurocomputing},
  pages        = {713-720},
  shortjournal = {Neurocomputing},
  title        = {Artificial neural network analysis of the academic performance of students in virtual learning environments},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A neural blockchain for a tokenizable e-participation model.
<em>NEUCOM</em>, <em>423</em>, 703–712. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, Distributed Ledger Technologies (DLTs) and, especially, Blockchain technology represent a great opportunity for public institutions to improve citizen participation and foster democratic innovation. These technologies facilitate the simplification of processes and provide secure management of recorded data, guaranteeing the transmission and public transparency of information. Based on the combination of a Blockchain as a Service (BaaS) platform and G-Cloud solutions, our proposal consists of the design of an e-Participation model that uses a tokenizable system of the actions and processes undertaken by citizens in participatory processes providing incentives to promote greater participation in public affairs. In order to develop a sustainable, scalable and resilient e-Participation system, a new blockchain concept, which organizes the blocks as a neural system, is combined with the implementation of a virtual token to reward participants. Furthermore, this virtual token is deployed through a smart contract that the block itself produces, containing information about the transaction and all the documents involved in the process. Finally, our Neural Distributed Ledger (NDL) framework facilitates the interconnection of blockchain networks in a transparent, certified, secure, auditable, scalable and traceable way.},
  archive      = {J_NEUCOM},
  author       = {Francisco Luis Benítez-Martínez and María Visitación Hurtado-Torres and Esteban Romero-Frías},
  doi          = {10.1016/j.neucom.2020.03.116},
  journal      = {Neurocomputing},
  pages        = {703-712},
  shortjournal = {Neurocomputing},
  title        = {A neural blockchain for a tokenizable e-participation model},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Continuous authentication with a focus on explainability.
<em>NEUCOM</em>, <em>423</em>, 697–702. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.122">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional explicit authentication mechanisms, in which the device remains unlocked after the introduction of some kind of password, are slowly being complemented with the so-called implicit or continuous authentication mechanisms . In the latter, the user is constantly monitored in one or more ways, in search for signs of unauthorized access, which may happen if a third party has access to the phone after it has been unlocked. There are some different forms of continuous authentication , some of which based on Machine Learning . These are generally black box models, that provide a decision but not an explanation. In this paper we propose an approach for continuous authentication based on behavioral biometrics , machine learning, and that includes domain-dependent aspects for the user to interpret the actions and decisions of the system. It is non-intrusive, does not require any additional hardware, and can be used continuously to monitor user identity.},
  archive      = {J_NEUCOM},
  author       = {Rodrigo Rocha and Davide Carneiro and Paulo Novais},
  doi          = {10.1016/j.neucom.2020.02.122},
  journal      = {Neurocomputing},
  pages        = {697-702},
  shortjournal = {Neurocomputing},
  title        = {Continuous authentication with a focus on explainability},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advanced malware propagation on random complex networks.
<em>NEUCOM</em>, <em>423</em>, 689–696. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work a novel model to simulate advanced malware spreading is introduced and analyzed. It is an individual-based model such that the dynamics of the malware outbreak is governed by means of a cellular automaton . The network topologies considered are complex random networks and each device is endowed at every step of time with one of the following possible states: susceptible, infected, attacked and recovered. A study analyzing the influence of topology variability and the structural characteristics of initially infected devices is done.},
  archive      = {J_NEUCOM},
  author       = {A. Martín del Rey and G. Hernández and A. Bustos Tabernero and A. Queiruga Dios},
  doi          = {10.1016/j.neucom.2020.03.115},
  journal      = {Neurocomputing},
  pages        = {689-696},
  shortjournal = {Neurocomputing},
  title        = {Advanced malware propagation on random complex networks},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An agent-based simulation framework for the study of urban
delivery. <em>NEUCOM</em>, <em>423</em>, 679–688. (<a
href="https://doi.org/10.1016/j.neucom.2020.03.117">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, cities and especially urban mobility have undergone remarkable changes. Significant advances in technology have been translated into new mobility services for both goods and people. One evident change has been the transformation of traditional vehicle fleets into more open fleets, in the sense that their members can proactively decide whether or not they are part of a certain fleet and whether or not they perform certain services. Fleets of this type make the decision-making process to be highly distributed, and rule out some of the typically centralized decisions. The management and control of this type of open fleets is severely more complex and, for this reason, the availability of simulation tools that allow for their analysis can be very useful. In accordance with this, the main contribution of this work is the development of an agent-based simulation tool specifically designed for the simulation of new urban mobility models . In this way, the tool can simulate any type of fleet in different urban scenarios, including a solution of the Last Mile Delivery problem, which is also included as a proof of concept in this paper.},
  archive      = {J_NEUCOM},
  author       = {J. Palanca and A. Terrasa and S. Rodriguez and C. Carrascosa and V. Julian},
  doi          = {10.1016/j.neucom.2020.03.117},
  journal      = {Neurocomputing},
  pages        = {679-688},
  shortjournal = {Neurocomputing},
  title        = {An agent-based simulation framework for the study of urban delivery},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimization of capacitated vehicle routing problem with
alternative delivery, pick-up and time windows: A modified hybrid
approach. <em>NEUCOM</em>, <em>423</em>, 670–678. (<a
href="https://doi.org/10.1016/j.neucom.2020.02.126">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the optimization of Capacitated Vehicle Routing Problem with Alternative Delivery, Pick-up and Time windows is considered. The development of this problem was motivated by analysis of postal and courier delivery issues. In some generalization, the problem examined can be classified as a combination of many variants of the classical VRP (Vehicle Routing Problem), such as CVRP (Capacitated Vehicle Routing Problem), VRPPD (Vehicle Routing Problem with Pickup and Delivery), VRPTW (Vehicle Routing Problem with Time Windows), etc. What distinguishes the presented problem from known variants of VRPs is the introduction of alternative delivery points and parcel lockers incorporated into the distribution network and the ability to take into account logical constraints. The problem model was formulated in the form of BIP (Binary Integer Programming). Moreover, the original hybrid approach integrating CP (Constraint Programming), GA (Genetic Algorithm) and MP (Mathematical Programming) was proposed for the model implementation and optimization. Numerous computational experiments verifying the correctness of the model and the effectiveness of the hybrid approach were also presented.},
  archive      = {J_NEUCOM},
  author       = {Paweł Sitek and Jarosław Wikarek and Katarzyna Rutczyńska-Wdowiak and Grzegorz Bocewicz and Zbigniew Banaszak},
  doi          = {10.1016/j.neucom.2020.02.126},
  journal      = {Neurocomputing},
  pages        = {670-678},
  shortjournal = {Neurocomputing},
  title        = {Optimization of capacitated vehicle routing problem with alternative delivery, pick-up and time windows: A modified hybrid approach},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural networks and learning systems in distributed
computing and artificial intelligence. <em>NEUCOM</em>, <em>423</em>,
668–669. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Fernando De la Prieta and Juan M. Corchado Rodríguez},
  doi          = {10.1016/j.neucom.2020.05.001},
  journal      = {Neurocomputing},
  pages        = {668-669},
  shortjournal = {Neurocomputing},
  title        = {Neural networks and learning systems in distributed computing and artificial intelligence},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Defense against neural trojan attacks: A survey.
<em>NEUCOM</em>, <em>423</em>, 651–667. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.133">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning techniques have become significantly prevalent in many real-world problems including a variety of detection, recognition, and classification tasks . To obtain high-performance neural networks , an enormous amount of training datasets, memory, and time-consuming computations are required which has increased the demands for outsource training among users. As a result, the machine-learning-as-a-service(MLaaS) providers or a third party can gain an opportunity to put the model’s security at risk by training the model with malicious inputs . The malicious functionality inserted into the neural network by the adversary will be activated in the presence of specific inputs. These kinds of attacks to neural networks , called trojan or backdoor attacks, are very stealthy and hard to detect because they do not affect the network performance on clean datasets. In this paper, we refer to two important threat models and we focus on the detection and mitigation techniques against these types of attacks on neural networks which has been proposed recently. We summarize, discuss, and compare the defense methods and their corresponding results.},
  archive      = {J_NEUCOM},
  author       = {Sara Kaviani and Insoo Sohn},
  doi          = {10.1016/j.neucom.2020.07.133},
  journal      = {Neurocomputing},
  pages        = {651-667},
  shortjournal = {Neurocomputing},
  title        = {Defense against neural trojan attacks: A survey},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Graph classification based on structural features of
significant nodes and spatial convolutional neural networks.
<em>NEUCOM</em>, <em>423</em>, 639–650. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.060">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Many real-world problems can be abstracted into graph classification problems. Recently, graph convolutional networks have achieved great success in the task of node classification and link prediction. However, when using graph convolution network to process the task of graph classification, either global topology information or local information is ignored. Therefore, designing graph convolutional networks to improve the accuracy of graph classification has attracted more and more attention. Inspired by the use of convolutional neural networks to process graph-structured data, we put forward a new spatial convolutional neural network architecture for graph classification. To be specific, we first design a comprehensive weighting method to measure the significance of vertices in the graph based on multiple indicators to choose the central node sequence. Then, the normalization process of the graph is realized by constructing the same size neighborhood graphs for the central vertices. After that, the structural characteristics of the graph are extracted from both local and global aspects. Finally, the tensors obtained after the above steps are respectively input into the following two spatial convolutional neural network architectures to perform classification, one is a simple CNN structure, which has only two convolution layers , one dense layer and one softmax layer. The other is to modify the architecture of CNN, and the channel concatenation layer is introduced to determine the classification result of the entire graph according to the category of the neighborhood graphs . Experimental results on two kinds of real-world datasets, bioinformatics and social network datasets, indicate that our approach obtains competitive results and is superior to some classic kernels and similar deep learning-based algorithms on 6 out of 8 benchmark data sets.},
  archive      = {J_NEUCOM},
  author       = {Tinghuai Ma and Hongmei Wang and Lejun Zhang and Yuan Tian and Najla Al-Nabhan},
  doi          = {10.1016/j.neucom.2020.10.060},
  journal      = {Neurocomputing},
  pages        = {639-650},
  shortjournal = {Neurocomputing},
  title        = {Graph classification based on structural features of significant nodes and spatial convolutional neural networks},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prior guided conditional generative adversarial network for
single image dehazing. <em>NEUCOM</em>, <em>423</em>, 620–638. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single image dehazing is an important problem as the existence of haze degrades the quality of the image and hinders most high-level computer vision tasks . Previous methods solve this problem using various low-level statistics priors or learning on synthetic data sets with CNN. In practice, the low-level priors are not always held in various scenes. And many CNN based methods directly estimate the transmission maps and atmospheric lights from huge synthetic data. However, without the guidance or constraints of priors may lead to over-dehazed or under-dehazed results. To address these issues, we propose a prior guided conditional generative adversarial network , an end-to-end model that generates realistic clean images using hazy image input and dehazed image based on the traditional prior-based method. The proposed generator extracted the feature with a parameters-shared encoder, and the clear image is recovered by decoding multi-scale features, which are fused and enhanced by the proposed attention-based feature aggregation block. And two-scale discriminators are adopted to supervise the generator to recover more image details with a combination of perceptual loss and adversarial loss. Our algorithm can efficiently combine the prior-based and CNN based image dehazing method and remove the weakness of each other. Experimental results on synthetic datasets and real-world images demonstrate our model can generate more perceptually appealing dehazing results, and provide superior performance compared with the state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yan Zhao Su and Zhi Gao Cui and Chuan He and Ai Hua Li and Tao Wang and Kun Cheng},
  doi          = {10.1016/j.neucom.2020.10.061},
  journal      = {Neurocomputing},
  pages        = {620-638},
  shortjournal = {Neurocomputing},
  title        = {Prior guided conditional generative adversarial network for single image dehazing},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interaction-transformation symbolic regression with extreme
learning machine. <em>NEUCOM</em>, <em>423</em>, 609–619. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Symbolic Regression searches for a mathematical expression that fits the input data set by minimizing the approximation error. The search space explored by this technique is composed of any mathematical function representable as an expression tree. This provides more flexibility for fitting the data but it also makes the task more challenging. The search space induced by this representation becomes filled with redundancy and ruggedness, sometimes requiring a higher computational budget in order to achieve good results. Recently, a new representation for Symbolic Regression was proposed, called Interaction-Transformation, which can represent function forms as a composition of interactions between predictors and the application of a single transformation function. In this work, we show how this representation can be modeled as a multi-layer neural network with the weights adjusted following the Extreme Learning Machine procedure. The results show that this approach is capable of finding equally good or better results than the current state-of-the-art with a smaller computational cost.},
  archive      = {J_NEUCOM},
  author       = {Fabricio Olivetti de Franca and Maira Zabuscha de Lima},
  doi          = {10.1016/j.neucom.2020.10.062},
  journal      = {Neurocomputing},
  pages        = {609-619},
  shortjournal = {Neurocomputing},
  title        = {Interaction-transformation symbolic regression with extreme learning machine},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Extended dissipativity of semi-markov jump neural networks
with partly unknown transition rates. <em>NEUCOM</em>, <em>423</em>,
601–608. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.063">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the synchronization problem is addressed for semi-Markov jump master–slave neural networks (SMJNN) with extended ( X , Y , Z ) (X,Y,Z) -dissipativity performance and partly unknown transition rates (TR). Comparing with constant TR in Markovian jump neural networks , the TR of SMJNN depend on the sojourn time (ST) of semi-Markov process. First, some sufficient stability and extended ( X , Y , Z ) (X,Y,Z) -dissipativity criteria are established for the error system with partly unknown TR. Then, ST-dependent dissipativity criterion is transformed to feasible condition by the upper and lower bounds of TR. Furthermore, the state feedback controller is also designed to ensure the synchronization of SMJNN. Finally, a numerical example is provided to verify the admissibility and effectiveness of the acquired results.},
  archive      = {J_NEUCOM},
  author       = {Weizhong Chen and Ming-Zhe Dai and Chaoxu Guan and Zhongyang Fei},
  doi          = {10.1016/j.neucom.2020.10.063},
  journal      = {Neurocomputing},
  pages        = {601-608},
  shortjournal = {Neurocomputing},
  title        = {Extended dissipativity of semi-markov jump neural networks with partly unknown transition rates},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A practical generative adversarial network architecture for
restoring damaged character photographs. <em>NEUCOM</em>, <em>423</em>,
590–600. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning has been applied to many image restoration tasks. In this work, we focus on studying an efficient deep learning architecture to restore damaged character photographs (DCPs) which are spoiled by natural or human factors including creases, spots, cracks, light, etc. A large amount of work has focused on image restoration such as super-resolution, image inpainting, image deblurring, and image denoising. However, few studies focus on restoring DCPs based on deep learning since DCPs are varied and complex, along with the difficulty of getting paired training dataset. In this work, we propose a new generative adversarial network (GAN) architecture to restore DCPs. Specifically, a residual U-Net (ResU-Net) GAN (RUGAN) is firstly constructed to generate fake DCPs by employing real DCPs, clear character photographs (CCPs), and dirty masks. Then, a ResU-Net conditional GAN (RUCGAN) is built to restore DCPs by exploiting paired CCPs and fake DCPs. To further improve the quality of restored character photographs, a weighted multi-features loss function is adopted in RUCGAN. Finally, numerical results show that our approach can restore spots, creases, cracks, and other spoiled manners in DCPs.},
  archive      = {J_NEUCOM},
  author       = {Hufei Yu and Yifeng Liu and Shiwen He and Pei Jiang and Jiang Xin and Jingxi Wen},
  doi          = {10.1016/j.neucom.2020.10.065},
  journal      = {Neurocomputing},
  pages        = {590-600},
  shortjournal = {Neurocomputing},
  title        = {A practical generative adversarial network architecture for restoring damaged character photographs},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Long- and short-term self-attention network for sequential
recommendation. <em>NEUCOM</em>, <em>423</em>, 580–589. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.066">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With great value in real applications, sequential recommendation aims to recommend users the personalized sequential actions. To achieve better performance, it is essential to consider both long-term preferences and sequential patterns ( i . e i.e ., short-term dynamics). Compared to widely used Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN), Self-Attention Network (SAN) obtains a surge of interest due to fewer parameters, highly parallelizable computation, and flexibility in modeling dependencies. However, existing SAN-based models are inadequate in characterizing and distinguishing users’ long-term preferences and short-term demands since they do not emphasize the importance of the current interest and temporal order information of sequences. In this paper, we propose a novel multi-layer long- and short-term self-attention network (LSSA) for sequential recommendation. Specifically, we first split the entire sequence of a user into multiple sub-sequences according to the timespan. Then the first self-attention layer learns the user’s short-term dynamics based on the last sub-sequence, while the second one captures the user’s long-term preferences through the previous sub-sequences and the last one. Finally, we integrate the long- and short-term representations together to form the user’s final hybrid representation. We evaluate the proposed model on three real-world datasets, and our experimental results show that LSSA outperforms state-of-the-art methods with a wide margin.},
  archive      = {J_NEUCOM},
  author       = {Chengfeng Xu and Jian Feng and Pengpeng Zhao and Fuzhen Zhuang and Deqing Wang and Yanchi Liu and Victor S. Sheng},
  doi          = {10.1016/j.neucom.2020.10.066},
  journal      = {Neurocomputing},
  pages        = {580-589},
  shortjournal = {Neurocomputing},
  title        = {Long- and short-term self-attention network for sequential recommendation},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient neural network using pointwise convolution kernels
with linear phase constraint. <em>NEUCOM</em>, <em>423</em>, 572–579.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In current efficient convolutional neural networks , 1 × 1 convolution is widely used. However, the amount of computation and the number of parameters of 1 × 1 convolution layers account for a large part of these neural network models. In this paper, we propose to use linear-phase pointwise convolution kernels (LPPC kernels) to reduce the computational complexities and storage costs of these neural networks . We design four types of LPPC kernels based on the parity of the number of input channels and symmetry of the weights of the pointwise convolution kernel. Experimental results show that Type-I LPPC kernels can compress some popular networks better with a small reduction in accuracy than the other types of LPPC kernels. The LPPC kernels can be used as new 1 × 1 convolution kernels to design efficient neural network architectures in the future. Moreover, the LPPC kernels are friendly to low-power hardware accelerator design to achieve lower memory access cost and smaller model size.},
  archive      = {J_NEUCOM},
  author       = {Feng Liang and Zhichao Tian and Ming Dong and Shuting Cheng and Li Sun and Hai Li and Yiran Chen and Guohe Zhang},
  doi          = {10.1016/j.neucom.2020.10.067},
  journal      = {Neurocomputing},
  pages        = {572-579},
  shortjournal = {Neurocomputing},
  title        = {Efficient neural network using pointwise convolution kernels with linear phase constraint},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Combining pretrained CNN feature extractors to enhance
clustering of complex natural images. <em>NEUCOM</em>, <em>423</em>,
551–571. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a common starting point for solving complex unsupervised image classification tasks is to use generic features, extracted with deep Convolutional Neural Networks (CNN) pretrained on a large and versatile dataset (ImageNet). However, in most research, the CNN architecture for feature extraction is chosen arbitrarily, without justification. This paper aims at providing insight on the use of pretrained CNN features for image clustering (IC). First, extensive experiments are conducted and show that, for a given dataset, the choice of the CNN architecture for feature extraction has a huge impact on the final clustering . These experiments also demonstrate that proper extractor selection for a given IC task is difficult. To solve this issue, we propose to rephrase the IC problem as a multi-view clustering (MVC) problem that considers features extracted from different architectures as different “views” of the same data. This approach is based on the assumption that information contained in the different CNN may be complementary, even when pretrained on the same data. We then propose a multi-input neural network architecture that is trained end-to-end to solve the MVC problem effectively. This approach is tested on nine natural image datasets, and produces state-of-the-art results for IC.},
  archive      = {J_NEUCOM},
  author       = {Joris Guérin and Stéphane Thiery and Eric Nyiri and Olivier Gibaru and Byron Boots},
  doi          = {10.1016/j.neucom.2020.10.068},
  journal      = {Neurocomputing},
  pages        = {551-571},
  shortjournal = {Neurocomputing},
  title        = {Combining pretrained CNN feature extractors to enhance clustering of complex natural images},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-stage hybrid embedding fusion network for visual
question answering. <em>NEUCOM</em>, <em>423</em>, 541–550. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multimodal fusion is a crucial component of Visual Question Answering (VQA), which involves joint understanding and semantic integration between visual and textual information. Existing VQA learning frameworks focus mainly on Latent Embedding Fusion (LEF) method, by projecting visual and textual features into a common latent space, and fusing them with element-wise multiplication. In this paper, we intend to achieve multiple and fine-grained multimodal interactions for enhancing fusion performance. To this end, we propose a Multi-stage Hybrid Embedding Fusion (MHEF) network to fulfill our improvements in two folds: First, we introduce a Dual Embedding Fusion (DEF) approach that transforms one modal input into the reciprocal embedding space before integration, and the DEF is further incorporated with the LEF to form a novel Hybrid Embedding Fusion (HEF). Second, we design a Multi-stage Fusion Structure (MFS) for the HEF to form the MHEF network, so as to obtain diverse and better fusion features for answer prediction. By jointly training the multi-stage framework, we can not only improve the performance in each single stage, but also obtain additional accuracy improvements by integrating all prediction results from each stage. Extensive experiments verify both our proposed HEF and MFS are beneficial to multi-modal fusion. The full MHEF model outperforms the baseline LEF model with 2\% accuracy improvements, and achieves promising performance on the VQA-v1 and VQA-v2 datasets.},
  archive      = {J_NEUCOM},
  author       = {Mingrui Lao and Yanming Guo and Nan Pu and Wei Chen and Yu Liu and Michael S. Lew},
  doi          = {10.1016/j.neucom.2020.10.071},
  journal      = {Neurocomputing},
  pages        = {541-550},
  shortjournal = {Neurocomputing},
  title        = {Multi-stage hybrid embedding fusion network for visual question answering},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Complex-valued hopfield neural networks with real weights
in synchronous mode. <em>NEUCOM</em>, <em>423</em>, 535–540. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex-valued Hopfield neural network with a multistate activation function converges in asynchronous mode , whereas it converges or is trapped at a cycle of length two in synchronous mode . For parallel processing , convergence in synchronous mode is necessary. In particular, a complex-valued Hopfield neural network (CHNN) is the most widely used multistate Hopfield model, and it is desirable that a CHNN converges in synchronous mode. In this work, a real-weight CHNN (RWCHNN) is proposed. An RWCHNN restricts the weights of a CHNN to real numbers and has half weight parameters of a CHNN. We provide the stability conditions of an RWCHNN in synchronous mode and prove that the projection rule satisfies them. The RWCHNN is the first model such that it converges in synchronous mode and has half weight parameters of a CHNN. Computer simulations show that the average update count until convergence is far less than those of the hypercomplex-valued Hopfield neural networks with the same number of weight parameters of an RWCHNN.},
  archive      = {J_NEUCOM},
  author       = {Masaki Kobayashi},
  doi          = {10.1016/j.neucom.2020.10.072},
  journal      = {Neurocomputing},
  pages        = {535-540},
  shortjournal = {Neurocomputing},
  title        = {Complex-valued hopfield neural networks with real weights in synchronous mode},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Phase synchronization between a light-dependent neuron and a
thermosensitive neuron. <em>NEUCOM</em>, <em>423</em>, 518–534. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.083">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The nervous system is made up of various functional neurons, e.g. some neurons can percept external optical signal while other neurons can detect the fluctuation of temperature, and these physical signals can be transmitted into bioelectric signals. The collective behaviors of neurons are dependent on the cooperation between neurons with different biophysical functions. In this paper, electronical synapse connection between the light-dependent neuron and thermosensitive neuron is activated to detect possible occurrence of phase synchronization. The light-dependent neuron is obtained from a neural circuit driven by photocurrent generated from the phototube, which external optical signal can be captured. The thermosensitive neuron is mapped from a neural circuit in which a thermistor is connected to percept the changes of temperature. When the two functional neurons are activated, it is found that phase synchronization/lock can be obtained by changing the intensity in the coupling channel. In addition, phase synchronization can be enhanced even in the presence of noise. The Hamilton energy is also calculated, and it is confirmed that two neurons are out of energy balance under phase synchronization. Finally, noise is applied for the coupled neurons, it is found that the involvement of noise can enhance the phase synchronization, and neurons in phase lock keep robustness to external noise. It indicates that neurons in different functional regions can keep pace with each other in the presence of phase synchronization, in this way, target gaits can be reached under the cooperation between different functional neurons stimulated by signals from different input channels. It provides possible guidance to design and regulate the synchronous behaviors of artificial neurons.},
  archive      = {J_NEUCOM},
  author       = {Zhao Yao and Ping Zhou and Zhigang Zhu and Jun Ma},
  doi          = {10.1016/j.neucom.2020.09.083},
  journal      = {Neurocomputing},
  pages        = {518-534},
  shortjournal = {Neurocomputing},
  title        = {Phase synchronization between a light-dependent neuron and a thermosensitive neuron},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based adaptive fixed-time formation control for
multi-agent systems with unknown uncertainties. <em>NEUCOM</em>,
<em>423</em>, 506–517. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the fixed-time formation tracking control problem for multi-agent systems with model uncertainties and in absence of leader’s velocity measurements. For each follower, a novel fixed-time cascaded leader state observer (FTCLSO) without velocity measurements is first designed to reconstruct the states of the leader. Then, radial basis function neural networks (RBFNNs) are adopted to approximate the model uncertainties online. Based on the proposed FTCLSO and RBFNNs, a novel fixed-time formation control scheme is constructed to address the time-varying formation tracking problem by utilizing fixed-time nonsmooth backstepping technique. The fixed-time convergence of the formation tracking error is guaranteed through Lyapunov stability analysis. Finally, simulation results demonstrate the effectiveness of the proposed formation tracking control scheme.},
  archive      = {J_NEUCOM},
  author       = {Tianyi Xiong and Zhou Gu},
  doi          = {10.1016/j.neucom.2020.10.074},
  journal      = {Neurocomputing},
  pages        = {506-517},
  shortjournal = {Neurocomputing},
  title        = {Observer-based adaptive fixed-time formation control for multi-agent systems with unknown uncertainties},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CentroidNetV2: A hybrid deep neural network for small-object
segmentation and counting. <em>NEUCOM</em>, <em>423</em>, 490–505. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.075">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents CentroidNetV2, a novel hybrid Convolutional Neural Network (CNN) that has been specifically designed to segment and count many small and connected object instances. This complete redesign of the original CentroidNet uses a CNN backbone to regress a field of centroid-voting vectors and border-voting vectors. The segmentation masks of the individual object instances are produced by decoding centroid votes and border votes. A loss function that combines cross-entropy loss and Euclidean-distance loss achieves high quality centroids and borders of object instances. Several backbones and loss functions are tested on three different datasets ranging from precision agriculture to microbiology and pathology. CentroidNetV2 is compared to the state-of-the art networks You Only Look Once Version 3 (YOLOv3) and Mask Recurrent Convolutional Neural Network (MRCNN). On two out of three datasets CentroidNetV2 achieves the highest F1 score and on all three datasets CentroidNetV2 achieves the highest recall. CentroidNetV2 demonstrates the best ability to detect small objects although the best segmentation masks for larger objects are produced by MRCNN.},
  archive      = {J_NEUCOM},
  author       = {Klaas Dijkstra and Jaap van de Loosdrecht and Waatze A. Atsma and Lambert R.B. Schomaker and Marco A. Wiering},
  doi          = {10.1016/j.neucom.2020.10.075},
  journal      = {Neurocomputing},
  pages        = {490-505},
  shortjournal = {Neurocomputing},
  title        = {CentroidNetV2: A hybrid deep neural network for small-object segmentation and counting},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Predictive visual control framework of mobile robot for
solving occlusion. <em>NEUCOM</em>, <em>423</em>, 474–489. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.076">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human-following mobile robots have been widely used in industry and daily life. However, during the tracking procedure, the human body is usually blocked by various moving or fixed occlusions. Although researchers have proposed some methods, they usually cannot restore human movement. In order to address this issue, we present a novel predictive visual control framework based on image generation . It includes visual tracking module, visual servo control module and occlusion solution module. In the occlusion solution module, we propose a convolutional attention-based differential LSTM (CAD-LSTM) Network to learn and predict the human motion state. The network focuses on how to predict for a long time from the difference between the previous frame and the next frame, which makes the robot tracking more robust. To show the effectiveness of our framework and CAD-LSTM Network, we apply them to image generation and conduct experiments in datasets and simulation environments. Our experimental results demonstrate that the proposed method outperforms than other methods.},
  archive      = {J_NEUCOM},
  author       = {Juncheng Zou},
  doi          = {10.1016/j.neucom.2020.10.076},
  journal      = {Neurocomputing},
  pages        = {474-489},
  shortjournal = {Neurocomputing},
  title        = {Predictive visual control framework of mobile robot for solving occlusion},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Rethinking feature aggregation for deep RGB-d salient
object detection. <em>NEUCOM</em>, <em>423</em>, 463–473. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.079">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Two-stream UNet based architectures are widely used in deep RGB-D salient object detection (SOD) models. However, UNet only adopts a top-down decoder network to progressively aggregate high-level features with low-level ones. In this paper, we propose to enrich feature aggregation via holistic aggregation paths and an extra bottom-up decoder network. The former aggregates multi-level features holistically to learn abundant feature interactions while the latter aggregates improved low-level features with high-level features, thus promoting their representation ability. Aiming at the two-stream architecture, we propose another early aggregation scheme to aggregate and propagate multi-modal encoder features at each level, thereby improving the encoder capability. We also propose a factorized attention module to efficiently modulate the feature aggregation action for each feature node with multiple learned attention factors. Experimental results demonstrate that all of the proposed components can gradually improve RGB-D SOD results. Consequently, our final SOD model performs favorably against other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yuan-fang Zhang and Jiangbin Zheng and Long Li and Nian Liu and Wenjing Jia and Xiaochen Fan and Chengpei Xu and Xiangjian He},
  doi          = {10.1016/j.neucom.2020.10.079},
  journal      = {Neurocomputing},
  pages        = {463-473},
  shortjournal = {Neurocomputing},
  title        = {Rethinking feature aggregation for deep RGB-D salient object detection},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust unsupervised anomaly detection via multi-time scale
DCGANs with forgetting mechanism for industrial multivariate time
series. <em>NEUCOM</em>, <em>423</em>, 444–462. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting anomalies in time series is a vital technique in a wide variety of industrial application in which sensors monitor expensive machinery. The complexity of this task increases when heterogeneous sensors provide information of different attributes, scales and characteristics from the same machine. Actually, the challenges of anomaly detection for industrial time series are to design effective pre-processing, feature extraction and overcome the lack of abnormal samples. Recent deep learning models have shown prominent abilities on raw multivariate time series , alleviating these previous works. In this work, a novel framework named multi-time scale deep convolutional generative adversarial network (MTS-DCGAN) is proposed to deal with anomaly detection of industrial time series. Firstly, multivariate time series are transformed into the multi-channel signature matrices via sliding window based cross-correlation computation, and therein forgetting mechanism is introduced to effectively avoid false alarms due to excessive influence of old sequences. Then the framework conducts an unsupervised adversarial training of multi-channel signature matrices and capture their hidden features via deep convolution structure. Besides, a novel threshold setting strategy is proposed to optimize anomaly detection performance under imbalance of normal and abnormal data. Finally, the proposed framework is assessed against the experiments on four datasets. Within this study, experimental results show our framework outperforms the comparison algorithms in terms of model performance and robustness, providing an effective anomaly detection method for industrial multivariate time series.},
  archive      = {J_NEUCOM},
  author       = {Haoran Liang and Lei Song and Jianxing Wang and Lili Guo and Xuzhi Li and Ji Liang},
  doi          = {10.1016/j.neucom.2020.10.084},
  journal      = {Neurocomputing},
  pages        = {444-462},
  shortjournal = {Neurocomputing},
  title        = {Robust unsupervised anomaly detection via multi-time scale DCGANs with forgetting mechanism for industrial multivariate time series},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuroadaptive observer-based discrete-time command filtered
fault-tolerant control for induction motors with load disturbances.
<em>NEUCOM</em>, <em>423</em>, 435–443. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a neuroadaptive observer-based discrete-time command filtered fault-tolerant control method is proposed for induction motors (IMs) with possible actuator faults and load disturbances. Firstly, the problem of “complexity of computation” and noncausal problem result from the traditional backstepping method are solved using the command filtered technique. Secondly, fault-tolerant control considering possible actuator faults is realized by adaptive neural control. In addition, a neuroadaptive observer is utilized to estimate the rotor position, angular velocity , and settle unknown load disturbances of IMs. The results of simulation demonstrate that the new design scheme can get rid of the effect of actuator faults and guarantee satisfactory position tracking performance.},
  archive      = {J_NEUCOM},
  author       = {Qixin Lei and Yumei Ma and Jiapeng Liu and Jinpeng Yu},
  doi          = {10.1016/j.neucom.2020.10.085},
  journal      = {Neurocomputing},
  pages        = {435-443},
  shortjournal = {Neurocomputing},
  title        = {Neuroadaptive observer-based discrete-time command filtered fault-tolerant control for induction motors with load disturbances},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Alpha-divergence minimization with mixed variational
posterior for bayesian neural networks and its robustness against
adversarial examples. <em>NEUCOM</em>, <em>423</em>, 427–434. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the approximate inference of Bayesian neural networks (BNNs), the variational posterior distribution is often taken an exponential family form (such as Gaussian). We propose to make the mixtures of exponential family distributions instead to get a more flexible approximation posterior. A novel reparameterization trick is introduced in this paper, in order to apply the reparameterization trick to mixed density distributions in Alpha divergence minimization. Our method is extendable to various neural architectures such as fully-connected neural networks and convolutional neural networks. The analysis on time complexity demonstrates that our method has less computation-consuming than normalizing flows. It also outperforms some related state-of-the-art techniques in the experiments of uncertainty estimation and robustness against adversarial examples.},
  archive      = {J_NEUCOM},
  author       = {Xiao Liu and Shiliang Sun},
  doi          = {10.1016/j.neucom.2020.10.087},
  journal      = {Neurocomputing},
  pages        = {427-434},
  shortjournal = {Neurocomputing},
  title        = {Alpha-divergence minimization with mixed variational posterior for bayesian neural networks and its robustness against adversarial examples},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-varying delay-dependent finite-time boundedness with h∞
performance for markovian jump neural networks with state and input
constraints. <em>NEUCOM</em>, <em>423</em>, 419–426. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work focuses on time-varying delay-dependent finite-time boundedness with H ∞ H∞ performance for Markovian jump neural networks with state and input constraints. This is the first try to study finite-time boundedness with H ∞ H∞ performance for Markovian jump neural networks with state and input constraints. There are disturbance input and system state with bounded peaks in the nonlinear system . In contrast to the existing study results, the studied system can be applied to a wider range. The purpose is to obtain less conservative conditions on finite-time H ∞ H∞ performance for Markovian jump neural networks with time-varying delay. Sufficient conditions of finite-time boundedness with H ∞ H∞ performance are collected by stochastic Lyapunov function . Linear matrix inequalities are utilized to obtain analysis results. Eventually, an example is provided to illustrate the validity of the addressed method.},
  archive      = {J_NEUCOM},
  author       = {Shaoxin Sun and Huaguang Zhang and Weihua Li and Yingchun Wang},
  doi          = {10.1016/j.neucom.2020.10.088},
  journal      = {Neurocomputing},
  pages        = {419-426},
  shortjournal = {Neurocomputing},
  title        = {Time-varying delay-dependent finite-time boundedness with h∞ performance for markovian jump neural networks with state and input constraints},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning pose-invariant 3D object reconstruction from
single-view images. <em>NEUCOM</em>, <em>423</em>, 407–418. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to reconstruct 3D shapes using 2D images is an active research topic, with benefits of not requiring expensive 3D data. However, most work in this direction requires multi-view images for each object instance as training supervision, which oftentimes does not apply in practice. In this paper, we relax the common multi-view assumption and explore a more challenging yet more realistic setup of learning 3D shape from only single-view images. The major difficulty lies in insufficient constraints that can be provided by single view images, which leads to the problem of pose entanglement in learned shape space. As a result, reconstructed shapes vary along input pose and have poor accuracy. We address this problem by taking a novel domain adaptation perspective, and propose an effective adversarial domain confusion method to learn pose-disentangled compact shape space. Experiments on single-view reconstruction show effectiveness in solving pose entanglement, and the proposed method achieves on-par reconstruction accuracy with state-of-the-art with higher efficiency.},
  archive      = {J_NEUCOM},
  author       = {Bo Peng and Wei Wang and Jing Dong and Tieniu Tan},
  doi          = {10.1016/j.neucom.2020.10.089},
  journal      = {Neurocomputing},
  pages        = {407-418},
  shortjournal = {Neurocomputing},
  title        = {Learning pose-invariant 3D object reconstruction from single-view images},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SA-CapsGAN: Using capsule networks with embedded
self-attention for generative adversarial network. <em>NEUCOM</em>,
<em>423</em>, 399–406. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative Adversarial Network (GAN) based on Convolutional Neural Network (CNN) has been the focus of research in recent years, but CNN is only suitable for detecting objects in images and cannot indicate the position of one part relative to another, losing the spatial feature relationships. In order to solve the above problems, we propose Self-Attention Generative Adversarial Capsule Network (SA-CapsGAN), using Capsule Networks (CapsNets) with an embedded Self-Attention mechanism as the Discriminator . This mechanism can make reasonable and comprehensive use of the information such as features and spatial location . Compared with CNN-based GAN, it effectively solves the lossy compression and long-range dependence of features. It can learn the target data manifold more quickly and has higher stability. Through some comparative experiments and analysis, it demonstrates the superior performance of SA-CapsGAN on MNIST and CelebA datasets, both quantitatively and qualitatively. Additionally, Fashion-MNIST and Rotated-MNIST datasets are used as a supplement to verify its performance.},
  archive      = {J_NEUCOM},
  author       = {Guangcong Sun and Shifei Ding and Tongfeng Sun and Chenglong Zhang},
  doi          = {10.1016/j.neucom.2020.10.092},
  journal      = {Neurocomputing},
  pages        = {399-406},
  shortjournal = {Neurocomputing},
  title        = {SA-CapsGAN: Using capsule networks with embedded self-attention for generative adversarial network},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Skeleton-based action recognition using sparse
spatio-temporal GCN with edge effective resistance. <em>NEUCOM</em>,
<em>423</em>, 389–398. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph convolutional neural networks have established significant success in solving various machine learning and computer vision problems. For skeleton-based action recognition, graph convolutional neural networks are the most suitable choice since human skeleton resembles to a graph. Stacking body skeletons over the length of video sequence results in a very complex spatio-temporal graph of many nodes and edges. Modeling the graph convolutional network directly with such a complex graph curtails the performance due to the redundancy of insignificant nodes and edges in the graph. Also for skeleton-based action recognition, the long-term contextual information is of central importance and many current architectures may fail to capture such contextual information. Therefore in order to alleviate these problems, we propose graph sparsification technique using edge effective resistance to better model the global context information and to eliminate redundant nodes and edges in the graph. Furthermore, we incorporate self-attention graph pooling to retain local properties and graph structures while pooling operation. To the best of our knowledge, we are the first to apply graph sparsification using edge effective resistance for skeleton-based action recognition and our proposed method is confirmed to be effective on action recognition, which achieves state-of-the-art results on publicly available datasets: UTD-MHAD, J-HMDB, NTU-RGB + D-60, NTU-RGB + D-120 and Kinetics dataset.},
  archive      = {J_NEUCOM},
  author       = {Tasweer Ahmad and Lianwen Jin and Luojun Lin and GuoZhi Tang},
  doi          = {10.1016/j.neucom.2020.10.096},
  journal      = {Neurocomputing},
  pages        = {389-398},
  shortjournal = {Neurocomputing},
  title        = {Skeleton-based action recognition using sparse spatio-temporal GCN with edge effective resistance},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A CORDIC based real-time implementation and analysis of a
respiratory central pattern generator. <em>NEUCOM</em>, <em>423</em>,
373–388. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.101">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Central pattern generators (CPGs) are dedicated neural circuits which can generate rhythmic motor patterns even in absence of sensory input with extraordinary robustness and flexibility. In this paper, a biologically realistic model of a respiratory CPG with four neurons is implemented on a reconfigurable Field-Programmable Gate Array (FPGA) system. Considering the limitations of hardware resources, we first propose a modified respiratory CPG model with Coordinate Rotation Digital Computer (CORDIC) algorithm to save limited resources and reduce complexity. And then, all the multipliers are replaced with a method which is appropriate and effective for hardware implementation to avoid the use of the area-intensive multipliers. The implementation results show that rhythmic oscillations are successfully generated by the respiratory CPG network and the resource utilization is greatly reduced, which shows the potential for building large-scale spiking neural networks . The proposed high-performance and real-time implementation of the respiratory CPG network on the FPGA system can speed up the process to gain new insights into the respiratory network and can also be developed into applications for respiratory rhythm generation and modulation.},
  archive      = {J_NEUCOM},
  author       = {Xinyu Hao and Shuangming Yang and Bin Deng and Jiang Wang and Xile Wei and Yanqiu Che},
  doi          = {10.1016/j.neucom.2020.10.101},
  journal      = {Neurocomputing},
  pages        = {373-388},
  shortjournal = {Neurocomputing},
  title        = {A CORDIC based real-time implementation and analysis of a respiratory central pattern generator},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Activity recognition and anomaly detection in smart homes.
<em>NEUCOM</em>, <em>423</em>, 362–372. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical and cognitive impairments decline the ability of elderly in execution of daily activities, such as eating, sleeping or taking medication. The proposed approach recognizes the activities performed in a smart home, and separates the normal from the anomalous activities. Moreover, we identify the anomalous days based on the number of activities performed in a day. We perform activity recognition by applying probabilistic neural network on the pre-segmented activity-data obtained from the sensors deployed at different locations in a smart home. We use H2O autoencoder to identify the anomalous from the normal instances of activities. We further categorize the anomalies based on the criteria such as missing or extra subevents, and unusual duration of activity. Since the ground truth of the anomalies is unavailable, we generate the ground truth using the boxplots of the duration, and the number of subevents in an activity. We provide the quantified results of activity recognition and anomaly detection that can be further used by the research community. A comprehensive evaluation of the proposed approach on two publicly available CASAS smart home datasets demonstrates its ability in the activity recognition and the correct identification of anomalies.},
  archive      = {J_NEUCOM},
  author       = {Labiba Gillani Fahad and Syed Fahad Tahir},
  doi          = {10.1016/j.neucom.2020.10.102},
  journal      = {Neurocomputing},
  pages        = {362-372},
  shortjournal = {Neurocomputing},
  title        = {Activity recognition and anomaly detection in smart homes},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ALGeNet: Adaptive log-euclidean gaussian embedding network
for time series forecasting. <em>NEUCOM</em>, <em>423</em>, 353–361. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series prediction has attracted much attention as various issues can be formulated as such a task. It is one of the critical challenges to extract the intrinsic information for estimating future trends from historical data. Long Short-Term Memory Network (LSTM) shows excellent performance in this assignment. Probabilistic information extraction, which is demonstrated effective in object recognition in recent years, has not been introduced in time series prediction. To our knowledge, there has not been any work on plugging trainable probability distributions into LSTM as feature representation in an end-to-end manner. In this work we put forward an Adaptive Log-Euclidean Gaussian embedding Network (ALGeNet) to take one step further on solving this problem. The core of the network is capturing statistical information through the Gaussian Distribution with LSTM for end-to-end learning. As the space of Gaussian Distribution is a manifold, we try to embed Gaussian layer into LSTM through mapping Gaussian space into a linear space based on the Lie group and logarithm operation. We introduce four descriptors of Gaussian, two descriptors performing direct logarithm and the others performing indirect logarithm. All of them can extract first-order and second-order statistical features while utilizing the structures of geometry and smooth group of Gaussians. Furthermore, our adaptive mechanism merges the advantages of each descriptor and works well. Experimental results on a real-world wind speed dataset and a system-level electricity load dataset show that the proposed adaptive network outperforms some state-of-the-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Zongxia Xie and Hui Hu and Qilong Wang and Renhui Li},
  doi          = {10.1016/j.neucom.2020.11.001},
  journal      = {Neurocomputing},
  pages        = {353-361},
  shortjournal = {Neurocomputing},
  title        = {ALGeNet: Adaptive log-euclidean gaussian embedding network for time series forecasting},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Attention based multilayer feature fusion convolutional
neural network for unsupervised monocular depth estimation.
<em>NEUCOM</em>, <em>423</em>, 343–352. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting depth from an image is an essential problem in the area of scene understanding and deep learning shows great potential in this area. Unsupervised methods regard image reconstruction loss as the supervised information which shows a great potential of application. Most methods face the problem that their depth estimation results are not accurate enough for detailed autopilot scenarios, which will limit its application. These methods are often based on the fully convolutional neural network , which is the most commonly used network in the image-to-image field. In this paper, aiming at optimizing the depth estimation network architecture , we propose two networks that fuse the features of different encoding layers for monocular depth estimation, a multilayer information fusion U-Net (FU-Net) and a more lightweight one (LFU-Net). In order to improve the efficiency of feature fusion , we propose a hybrid attention mechanism to optimize our network and named it as AgFU-Net. We compare our networks with other improvements of U-Net, and the result shows that our networks are more efficient. Also, the loss function is fine-tuned for the unsupervised depth estimation algorithm . Our improvements achieve results that are comparable with state-of-the-art unsupervised monocular depth prediction methods on the KITTI benchmarks.},
  archive      = {J_NEUCOM},
  author       = {Zeyu Lei and Yan Wang and Zijian Li and Junyao Yang},
  doi          = {10.1016/j.neucom.2020.11.002},
  journal      = {Neurocomputing},
  pages        = {343-352},
  shortjournal = {Neurocomputing},
  title        = {Attention based multilayer feature fusion convolutional neural network for unsupervised monocular depth estimation},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An memristor-based synapse implementation using BCM
learning rule. <em>NEUCOM</em>, <em>423</em>, 336–342. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.106">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A novel memristive synapse model based on the HP memristor is proposed in this paper, which can address the problem of synaptic weight infinite modulations. The sliding threshold mechanism of the Bienenstock-Cooper-Munro rule (BCM) is used to redefine the memristance (i.e. synaptic weight) adjustment process of the memristive synapse model. Based on the proposed memristor-based synapse and Leaky Integrate-and-Fire neurons, a spiking neural network (SNN) hardware fragment is constructed, where spike trains with different frequencies are used to evaluate the stability performance of the proposed SNN hardware. Results show that compared to other approaches, the network is stable under different stimuli due to the characteristics of the memristor-based synapse model, and prove that the proposed synapse model is able to mimic biological synaptic behaviour and the problem of synaptic weight infinite modulations is addressed.},
  archive      = {J_NEUCOM},
  author       = {Yongchuang Huang and Junxiu Liu and Jim Harkin and Liam McDaid and Yuling Luo},
  doi          = {10.1016/j.neucom.2020.10.106},
  journal      = {Neurocomputing},
  pages        = {336-342},
  shortjournal = {Neurocomputing},
  title        = {An memristor-based synapse implementation using BCM learning rule},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DSPNet: A low computational-cost network for human pose
estimation. <em>NEUCOM</em>, <em>423</em>, 327–335. (<a
href="https://doi.org/10.1016/j.neucom.2020.11.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing human pose estimation methods usually have a high computational load, which is very unfavorable for resource-limited equipment. To address this issue, we propose a low computational-cost deep supervision pyramid network called DSPNet. Firstly, we design a lightweight up-sampling unit instead of transposed convolution as a decoder for the network. In the case of decreased computation, it has brought an increase in prediction accuracy. Secondly, we present a novel deep supervision pyramid architecture to improve the multi-scale obtaining ability of MSRA SimpleBaseline while not bringing any increase in the number of parameters. The experimental results on both MPII and COCO pose estimation benchmarks illustrate that DSPNet achieves almost equivalent state-of-the-art results with a low computational load. Especially, the computational cost of DSPNet is 12.7\% of SimpleBaseline and the estimation accuracy is improved by 0.9 points when both methods use the same backbone network (EfficientNet) on MPII validation set. The code of the proposed method is availabe at https://github.com/sumaliqinghua/DSPNet .},
  archive      = {J_NEUCOM},
  author       = {Fujin Zhong and Mingyang Li and Kun Zhang and Jun Hu and Li Liu},
  doi          = {10.1016/j.neucom.2020.11.003},
  journal      = {Neurocomputing},
  pages        = {327-335},
  shortjournal = {Neurocomputing},
  title        = {DSPNet: A low computational-cost network for human pose estimation},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). State estimation of CPSs with deception attacks: Stability
analysis and approximate computation. <em>NEUCOM</em>, <em>423</em>,
318–326. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the state estimation problems of cyber-physical systems (CPSs) under unobservable deception attacks. First, the optimal state estimator is provided based on the derived state probability density function, which consists of an exponentially increasing number of linear Gaussian hypotheses. The exponentially growing number of components will lead to high computational cost. Therefore, a suboptimal state estimator based on the IMM algorithm is proposed, which is computationally more efficient than the optimal estimator. Finally, numerical results are given to verify the effectiveness and superiority of the proposed suboptimal estimator, rendering an efficient and stable state estimation when the privacy of sensor measurements is attacked.},
  archive      = {J_NEUCOM},
  author       = {Chang Zhao and James Lam and Hong Lin},
  doi          = {10.1016/j.neucom.2020.10.055},
  journal      = {Neurocomputing},
  pages        = {318-326},
  shortjournal = {Neurocomputing},
  title        = {State estimation of CPSs with deception attacks: Stability analysis and approximate computation},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Approximate optimal control for an uncertain robot based on
adaptive dynamic programming. <em>NEUCOM</em>, <em>423</em>, 308–317.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An approximate optimal scheme is proposed for an uncertain n -link robot subject to saturation non-linearity. A remarkable feature is that compared with the previous results, the model uncertainty in robotic dynamic is taken into account in the paper. Under the frame of adaptive dynamic programming (ADP), an optimal control is designed for the nominal robotic system and proved to be an approximate optimal control of the unknown robotic system, and it not only stabilizes the unknown system, but also decreases the control cost. Furthermore, the saturation non-linearity is also solved with generalized non-quadratic functional. According to the Lyapunov theory , all the error signals can be proved to be uniformly ultimately bounded (UUB). Simulation examples are implemented to validate the effectiveness of the designed method.},
  archive      = {J_NEUCOM},
  author       = {Linghuan Kong and Shuang Zhang and Xinbo Yu},
  doi          = {10.1016/j.neucom.2020.10.012},
  journal      = {Neurocomputing},
  pages        = {308-317},
  shortjournal = {Neurocomputing},
  title        = {Approximate optimal control for an uncertain robot based on adaptive dynamic programming},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning features from enhanced function call graphs for
android malware detection. <em>NEUCOM</em>, <em>423</em>, 301–307. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Analyzing the runtime behaviors of Android apps is crucial for malware detection . In this paper, we attempt to learn the behavior level features of an app from function calls. The challenges of this task are twofold. First, the absence of function attributes hinders the understanding of app behaviors . Second, the graphical representation of function calls cannot be directly processed by classical machine learning algorithms . In this paper, we develop two methods to overcome these challenges. Based on function embedding, we first propose the concept of enhanced function call graphs (E-FCGs) to characterize app runtime behaviors. We then develop a Graph Convolutional Network (GCN) based algorithm to obtain vector representations of E-FCGs. Extensive experiments show that the features learned by our method can achieve surprisingly high detection performance on a variety of classifiers (e.g., LR , DT , SVM , KNN, RF , MLP and CNN), significantly outperforming the traditional static features.},
  archive      = {J_NEUCOM},
  author       = {Minghui Cai and Yuan Jiang and Cuiying Gao and Heng Li and Wei Yuan},
  doi          = {10.1016/j.neucom.2020.10.054},
  journal      = {Neurocomputing},
  pages        = {301-307},
  shortjournal = {Neurocomputing},
  title        = {Learning features from enhanced function call graphs for android malware detection},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integration of regularized l1 tracking and instance
segmentation for video object tracking. <em>NEUCOM</em>, <em>423</em>,
284–300. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We introduce a tracking-by-detection method that integrates a deep object detector with a particle filter tracker under the regularization framework where the tracked object is represented by a sparse dictionary. A novel observation model which establishes consensus between the detector and tracker is formulated that enables us to update the dictionary with the guidance of the deep detector. This yields an efficient representation of the object appearance through the video sequence hence improves robustness to occlusion and pose changes. The proposed tracker employs a 7D affine state vector formulated to output deformed object bounding boxes that significantly increases robustness to scale changes. Performance evaluation has been carried out on a subset of challenging VOT2016 and VOT2018 benchmarking video sequences for 80 object classes of COCO. Numerical results demonstrate that the introduced tracker, L1DPF-M, achieves comparable robustness while it outperforms state-of-the-art trackers in success rate where the improvement achieved at IoU-th = 0.5 on the used VOT2016 and VOT2018 sequences is 11\% and 9\%, respectively.},
  archive      = {J_NEUCOM},
  author       = {Filiz Gurkan and Bilge Gunsel},
  doi          = {10.1016/j.neucom.2020.09.072},
  journal      = {Neurocomputing},
  pages        = {284-300},
  shortjournal = {Neurocomputing},
  title        = {Integration of regularized l1 tracking and instance segmentation for video object tracking},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-granularity feature learning network for deep hashing.
<em>NEUCOM</em>, <em>423</em>, 274–283. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the ever-increasing growth of massive high-dimensional data, deep learning to hash technology has been widely used for approximate nearest neighbor search on large-scale datasets, due to its remarkable efficiency and retrieval performance . In this paper, we propose a novel supervised deep hashing method , named Multi-granularity Feature Learning Hashing (MFLH), to learn compact binary descriptors. Specifically, we design an end-to-end trainable network to jointly learn feature representations and hash codes, in which a global stream and a local stream are responsible for learning feature representations with different granularities, and a hashing stream is devoted to encoding multi-granularity features into binary codes. In the local stream, a Cyclic Shift Mechanism (CSM) strategy is developed to assist mining more discriminative local fine information. In the meantime, an approximate sign activation function , which can be used for continuous optimization , is introduced to reduce quantization error . Furthermore, an improved variant of the triplet loss is presented to enhance the representation of pair-wise similarity for hash codes. Extensive experiments demonstrate that our proposed method significantly outperforms state-of-the-art hashing methods on the benchmark datasets, thereby verifying the effectiveness of our approach. Source code is provided for reproducibility.},
  archive      = {J_NEUCOM},
  author       = {Hao Feng and Nian Wang and Jun Tang and Jie Chen and Feng Chen},
  doi          = {10.1016/j.neucom.2020.10.028},
  journal      = {Neurocomputing},
  pages        = {274-283},
  shortjournal = {Neurocomputing},
  title        = {Multi-granularity feature learning network for deep hashing},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Video anomaly detection with multi-scale feature and
temporal information fusion. <em>NEUCOM</em>, <em>423</em>, 264–273. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video anomaly detection is a challenging task because of the uncertainty of abnormal events. The current method based on predictive frames has obtained better detection results compared with the previous reconstruction or hand-crafted methods. In current prediction methods, the characteristics considered previously are only of a single scale, and the time constraint information is not fully used. In our work, we proposed a new framework structure to achieve better abnormality detection rate. To address the objects of different scales in each video frame, we considered extracting the characteristics of different receptive fields to encode more spatial information. At the same time, we added temporal constraints to the network instead of using time-consuming optical flow information, and we completed the memory of temporal features through a ConvGRU module. Furthermore, while distinguishing abnormal events, we also considered temporal information and spatial information so that our framework could fully combine spatio-temporal information to correctly distinguish abnormal events from normal events. We obtained excellent results on three datasets, thus demonstrating the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Yiheng Cai and Jiaqi Liu and Yajun Guo and Shaobin Hu and Shinan Lang},
  doi          = {10.1016/j.neucom.2020.10.044},
  journal      = {Neurocomputing},
  pages        = {264-273},
  shortjournal = {Neurocomputing},
  title        = {Video anomaly detection with multi-scale feature and temporal information fusion},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Salient points driven pedestrian group retrieval with
fine-grained representation. <em>NEUCOM</em>, <em>423</em>, 255–263. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {People often take part in various social activities in the form of groups in public area. As the primary constituent units of crowd, groups retrieval has become one of the urgent issues for the security departments. In this paper, collection of stable individuals with some social relationship, called group, is selected as the research object, and a novel task of pedestrian group retrieval is introduced. Different from the individual person matching, groups often show high aggregation due to their inherent characteristics, occlusions in group individuals therefore are more serious. As a result, the performance of individual person based detection and matching will be affected. Meanwhile, group matching also needs to address the problems like variations in the shape or configuration. Therefore, we suggest that the group entirety may be disassembled into fine-grained representation and then design a salient points driven framework for pedestrian group retrieval. The work focuses on the problems of overall appearance characteristics extraction of a deformable pedestrian collection and matching of groups at varying scales. Experiments on Pedestrian-Groups2 dataset and Road Group dataset demonstrate the effectiveness of our proposed framework for Pedestrian Group retrieval.},
  archive      = {J_NEUCOM},
  author       = {Xiao-Han Chen and Jian-Huang Lai},
  doi          = {10.1016/j.neucom.2020.09.054},
  journal      = {Neurocomputing},
  pages        = {255-263},
  shortjournal = {Neurocomputing},
  title        = {Salient points driven pedestrian group retrieval with fine-grained representation},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An augmented delays-dependent region partitioning approach
for recurrent neural networks with multiple time-varying delays.
<em>NEUCOM</em>, <em>423</em>, 248–254. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the global asymptotic stability problem of recurrent neural networks with multiple time-varying delays. First, to make full use of the relationship between all delayed states x ( t - τ i ) ( i = 1 , … , N ) x(t-τi)(i=1,…,N) and current state x ( t ) x(t) , an augmented delays-dependent region partitioning (ADRP) approach is proposed. Then combining Wirtinger-based integral inequality and the reciprocally convex approach, two delay-dependent stability criteria with less conservatism are developed. Finally, two numerical simulations are shown to verify the effectiveness and the feasibility.},
  archive      = {J_NEUCOM},
  author       = {ChangChun Hua and YunFei Qiu and YiBo Wang and XinPing Guan},
  doi          = {10.1016/j.neucom.2020.10.047},
  journal      = {Neurocomputing},
  pages        = {248-254},
  shortjournal = {Neurocomputing},
  title        = {An augmented delays-dependent region partitioning approach for recurrent neural networks with multiple time-varying delays},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning from multiple inconsistent and dependent annotators
to support classification tasks. <em>NEUCOM</em>, <em>423</em>, 236–247.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Training a supervised learning model requires a labeled dataset, where the labeling process is usually carried out by an expert to provide the ground truth/gold standard for each sample. However, in many applications, such a gold standard is not available. Instead, several real-world scenarios give us access to annotations provided by crowds, holding different and unknown levels of expertise. Thus, Learning from crowds is a subject undergoing intense study, and its main aim is to manage various machine learning paradigms in the presence of multiple annotators. Most of the state-of-the-art approaches reside on two key assumptions: i) the labeler’s performance does not depend on the input feature space, and ii) independence among the annotators is imposed. Here, we introduce a localized kernel alignment-based annotator relevance analysis (LKAAR) to code each labeler’s expertise as the matching between the feature and label spaces. Namely, LKAAR takes into account inter-annotators dependencies and models labelers’ knowledge as a function of the input feature space. Experimental results devoted to classification, show that LKAAR achieves suitable performances from inconsistent labelers, even if the gold standard is not available.},
  archive      = {J_NEUCOM},
  author       = {J. Gil-Gonzalez and A. Orozco-Gutierrez and A. Alvarez-Meza},
  doi          = {10.1016/j.neucom.2020.10.045},
  journal      = {Neurocomputing},
  pages        = {236-247},
  shortjournal = {Neurocomputing},
  title        = {Learning from multiple inconsistent and dependent annotators to support classification tasks},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HITS centrality based on inter-layer similarity for
multilayer temporal networks. <em>NEUCOM</em>, <em>423</em>, 220–235.
(<a href="https://doi.org/10.1016/j.neucom.2020.10.040">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a novel HITS centrality based on inter-layer similarity for multilayer temporal networks, referred to as the MT-HITS centrality. We firstly introduce a sixth-order tensor to represent multilayer temporal networks and define an inter-layer similarity index to measure the strength of the interactions between different layers. Then, based on the established tensor, we construct a set of tensor equations to define centrality vectors of nodes, layers, and time stamps, respectively. These centrality vectors can be regarded as a Perron eigenvector of a multi-homogeneous map. Under some reasonable conditions, the existence and uniqueness of our proposed centrality measure are guaranteed by existing results. To demonstrate the effectiveness and superiority of our proposed method, we test it on three networks, and then we apply it for link prediction in temporal networks.},
  archive      = {J_NEUCOM},
  author       = {Laishui Lv and Kun Zhang and Dalal Bardou and Xun Li and Ting Zhang and Wei Xue},
  doi          = {10.1016/j.neucom.2020.10.040},
  journal      = {Neurocomputing},
  pages        = {220-235},
  shortjournal = {Neurocomputing},
  title        = {HITS centrality based on inter-layer similarity for multilayer temporal networks},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Causality extraction based on self-attentive BiLSTM-CRF with
transferred embeddings. <em>NEUCOM</em>, <em>423</em>, 207–219. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causality extraction from natural language texts is a challenging open problem in artificial intelligence. Existing methods utilize patterns, constraints, and machine learning techniques to extract causality, heavily depending on domain knowledge and requiring considerable human effort and time for feature engineering. In this paper, we formulate causality extraction as a sequence labeling problem based on a novel causality tagging scheme. On this basis, we propose a neural causality extractor with the BiLSTM-CRF model as the backbone, named SCITE ( S elf-attentive BiLSTM- C RF w I th T ransferred E mbeddings), which can directly extract cause and effect without extracting candidate causal pairs and identifying their relations separately. To address the problem of data insufficiency, we transfer contextual string embeddings, also known as Flair embeddings, which are trained on a large corpus in our task. In addition, to improve the performance of causality extraction, we introduce a multihead self-attention mechanism into SCITE to learn the dependencies between causal words. We evaluate our method on a public dataset, and experimental results demonstrate that our method achieves significant and consistent improvement compared to baselines.},
  archive      = {J_NEUCOM},
  author       = {Zhaoning Li and Qi Li and Xiaotian Zou and Jiangtao Ren},
  doi          = {10.1016/j.neucom.2020.08.078},
  journal      = {Neurocomputing},
  pages        = {207-219},
  shortjournal = {Neurocomputing},
  title        = {Causality extraction based on self-attentive BiLSTM-CRF with transferred embeddings},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Hypergraph network model for nested entity mention
recognition. <em>NEUCOM</em>, <em>423</em>, 200–206. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a hypergraph network (HGN) model to recognize the nested entity mentions in texts. This model can learn the representations for the sequence structures of natural languages and the representations for the hypergraph structures of nested entity mentions. Mainstream methods recognize an entity mention by separately tagging the words or the gaps between words, which may complicate the problem and not be favorable for capturing the overall features of the mention. To solve these issues, the HGN model treats each entity mention as a whole and tags it with one label. We represent each sentence as a hypergraph, in which nodes represent words and hyperedges represent entity mentions. Thus, entity mention recognition (EMR) is transformed into a task of classifying the hyperedges. The HGN model firstly uses encoders to extract the features and learn a hypergraph representation, and then recognizes entity mentions by tagging every hyperedge. The experiments on three standard datasets demonstrate our model outperforms the previous models for nested EMR. We openly release the source code at https://github.com/nlplab-ie/HGN.},
  archive      = {J_NEUCOM},
  author       = {Heyan Huang and Ming Lei and Chong Feng},
  doi          = {10.1016/j.neucom.2020.09.077},
  journal      = {Neurocomputing},
  pages        = {200-206},
  shortjournal = {Neurocomputing},
  title        = {Hypergraph network model for nested entity mention recognition},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Private and common feature learning with adversarial network
for RGBD object classification. <em>NEUCOM</em>, <em>423</em>, 190–199.
(<a href="https://doi.org/10.1016/j.neucom.2020.07.129">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key issue in RGBD classification is how to fuse the RGB and depth modalities. A popular way is to extract the private features of unimodality and the common features between the two modalities. Most of them use low order algebraic metrics to find the common part of the RGB and depth signals. In this paper, adversarial network is used to learn the common features between the RGB and depth modalities. A modality discriminator is designed to compete with the feature encoder so as to generate the modality-invariant information, which can be regarded as the common features. With this concept, we present a M ulti- M odal F eature L earning algorithm with A dversarial N etwork (MMFLAN) to decouple the RGBD signals and obtain the fused features. Comprehensive experiments based on three datasets are used to evaluate the effectiveness and robustness of our MMFLAN.},
  archive      = {J_NEUCOM},
  author       = {Lingfeng Qiao and Zhongliang Jing and Han Pan and Henry Leung and Wuji Liu},
  doi          = {10.1016/j.neucom.2020.07.129},
  journal      = {Neurocomputing},
  pages        = {190-199},
  shortjournal = {Neurocomputing},
  title        = {Private and common feature learning with adversarial network for RGBD object classification},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Robust local metric learning via least square regression
regularization for scene recognition. <em>NEUCOM</em>, <em>423</em>,
179–189. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.077">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Metric learning plays an important role in various machine learning tasks. Particularly, local metric learning is prevailing since it can learn more flexible metrics on complex datasets. However it may not be robust for scene recognition because of intra-class diversity and inter-class similarity in the scene images. To address this issue, we propose a novel method, called robust local metric learning via least square regression regularization (RLML-LSR), to learn a more robust distance metric for scene recognition. We first formulate a local discriminative metric function , aimed to pull same class neighbors closer and push different classes ones farther away simultaneously. Then taking advantage of the least square regression , we minimize the regression errors of same class neighbors, such that the local geometry structure can be preserved as much as possible. Finally, the local discriminative metric function and least square regression regularization are integrated into a unified framework, which jointly promotes the robustness of local metric learning and enhances the recognition performance of scene images. Extensive experiments on both natural scene and remote sensing scene datasets demonstrate the effectiveness and robustness of the proposed RLML-LSR method for scene recognition.},
  archive      = {J_NEUCOM},
  author       = {Chen Wang and Guohua Peng and Wei Lin},
  doi          = {10.1016/j.neucom.2020.08.077},
  journal      = {Neurocomputing},
  pages        = {179-189},
  shortjournal = {Neurocomputing},
  title        = {Robust local metric learning via least square regression regularization for scene recognition},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quality assessment of DIBR-synthesized views: An overview.
<em>NEUCOM</em>, <em>423</em>, 158–178. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Depth-Image-Based-Rendering (DIBR) is one of the main fundamental technique to generate new views in 3D video applications, such as Multi-View Videos (MVV), Free-Viewpoint Videos (FVV) and Virtual Reality (VR). However, the quality assessment of DIBR-synthesized views is quite different from the traditional 2D images/videos. In recent years, several efforts have been made towards this topic, but there is a lack of detailed survey in the literature. In this paper, we provide a comprehensive survey on various current approaches for DIBR-synthesized views. The current accessible datasets of DIBR-synthesized views are firstly reviewed, followed by a summary analysis of the representative state-of-the-art objective metrics. Then, the performances of different objective metrics are evaluated and discussed on all available datasets. Finally, we discuss the potential challenges and suggest possible directions for future research.},
  archive      = {J_NEUCOM},
  author       = {Shishun Tian and Lu Zhang and Wenbin Zou and Xia Li and Ting Su and Luce Morin and Olivier Déforges},
  doi          = {10.1016/j.neucom.2020.09.062},
  journal      = {Neurocomputing},
  pages        = {158-178},
  shortjournal = {Neurocomputing},
  title        = {Quality assessment of DIBR-synthesized views: An overview},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Gated PE-NL-MA: A multi-modal attention based network for
video understanding. <em>NEUCOM</em>, <em>423</em>, 148–157. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.112">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-modal learning tasks such as video understanding, the most important operations are feature extraction, feature enhancement for single modality and feature aggregation between modalities. In this paper, we present two attention based algorithms, the Position-embedding Non-local (PE-NL) Network and the Multi-modal Attention (MA) feature aggregation method. Inspired by Non-local Neural Networks and Transformers, our PE-NL is a self-attention liked feature enhancement operation and it can capture long-range dependencies and model relative positions. The MA aggregation method merges visual and audio modals while reduces feature dimension and the number of parameters without losing too much accuracy. Both of PE-NL and MA blocks can be plugged into many multi-modal learning architectures. Our Gated PE-NL-MA network achieves competitive results on Youtube-8M dataset.},
  archive      = {J_NEUCOM},
  author       = {Chengyang Xie and Xiaoping Wang},
  doi          = {10.1016/j.neucom.2020.05.112},
  journal      = {Neurocomputing},
  pages        = {148-157},
  shortjournal = {Neurocomputing},
  title        = {Gated PE-NL-MA: A multi-modal attention based network for video understanding},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep spatio-temporal graph convolutional network for traffic
accident prediction. <em>NEUCOM</em>, <em>423</em>, 135–147. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic accidents usually lead to severe human casualties and huge economic losses in real-world scenarios. Timely accurate prediction of traffic accidents has great potential to protect public safety and reduce economic losses. However, it is challenging to predict traffic accidents due to the complex causality of traffic accidents with multiple factors, including spatial correlations , temporal dynamic interactions and external influences in traffic-relevant heterogeneous data . To overcome the above issues, this paper proposes a novel Deep Spatio-Temporal Graph Convolutional Network , namely DSTGCN, to predict traffic accidents. The proposed model is composed of three components: the first component is the spatial learning layer which performs graph convolutional operations on spatial information to learn the correlations in space. The second component is the spatio-temporal learning layer which utilizes graph and standard convolutions to capture the dynamic variations in both spatial and temporal perspective. The third component is the embedding layer which aims to obtain meaningful and semantic representations of external information. To evaluate the proposed model, we collect large-scale real-world data, including accident records, citi-wide vehicle speeds, road networks, meteorological conditions, and Point-of-Interest distributions. Experimental results on real-world datasets demonstrate that DSTGCN outperforms both classical and state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Le Yu and Bowen Du and Xiao Hu and Leilei Sun and Liangzhe Han and Weifeng Lv},
  doi          = {10.1016/j.neucom.2020.09.043},
  journal      = {Neurocomputing},
  pages        = {135-147},
  shortjournal = {Neurocomputing},
  title        = {Deep spatio-temporal graph convolutional network for traffic accident prediction},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Audio description from image by modal translation network.
<em>NEUCOM</em>, <em>423</em>, 124–134. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Audio is the main form for the visually impaired to obtain information. In reality, all kinds of visual data always exist, but audio data does not exist in many cases. In order to help the visually impaired people to better perceive the information around them, an image-to-audio-description (I2AD) task is proposed to generate audio descriptions from images in this paper. To complete this totally new task, a modal translation network (MT-Net) from visual to auditory sense is proposed. The proposed MT-Net includes three progressive sub-networks: 1) feature learning , 2) cross-modal mapping, and 3) audio generation. First, the feature learning sub-network aims to learn semantic features from image and audio, including image feature learning and audio feature learning. Second, the cross-modal mapping sub-network transforms the image feature into a cross-modal representation with the same semantic concept as the audio feature. In this way, the correlation of inter-modal data is effectively mined for easing the heterogeneous gap between image and audio. Finally, the audio generation sub-network is designed to generate the audio waveform from the cross-modal representation. The generated audio waveform is interpolated to obtain the corresponding audio file according to the sample frequency. Being the first attempt to explore the I2AD task, three large-scale datasets with plenty of manual audio descriptions are built. Experiments on the datasets verify the feasibility of generating intelligible audio from an image directly and the effectiveness of proposed method.},
  archive      = {J_NEUCOM},
  author       = {Hailong Ning and Xiangtao Zheng and Yuan Yuan and Xiaoqiang Lu},
  doi          = {10.1016/j.neucom.2020.10.053},
  journal      = {Neurocomputing},
  pages        = {124-134},
  shortjournal = {Neurocomputing},
  title        = {Audio description from image by modal translation network},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finger vein recognition based on zone-based minutia
matching. <em>NEUCOM</em>, <em>423</em>, 110–123. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.029">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finger vein is universally regarded as a secure and convenient biometric pattern. Consequently, it has received considerable attention from researchers and is widely used in real world applications. However, the undesirable image quality and deformation problem have limited the improvement of its recognition accuracy. In the literature, minutia-based finger vein recognition is generally acknowledged as deformation-tolerant, but problems still remain: 1) the minutiae extracted in some finger vein images are small in amount; 2) one minutia is compared with all the minutiae from other images during matching, which is time-consuming and prones to false pairings. In this paper, a zone-based minutia matching technique, which combines minutia matching with traditional region-of-interest (ROI) based method, is designed to deal with these problems. First, we extract minutiae from each segmented image block to ensure the amount of the extracted minutiae. Second, minutiae in a rational neighborhood zone are selected for matching, which discards unnecessary matchings and avoids false pairings to some extent. Compared to traditional methods, the designed matching procedure is also parameter-free and more stable when conducting minutia matching. Extensive experiments demonstrate the robustness and efficiency of the proposed method. The results also show the superiority of our method over other similar works.},
  archive      = {J_NEUCOM},
  author       = {Xianjing Meng and Jinwen Zheng and Xiaoming Xi and Qing Zhang and Yilong Yin},
  doi          = {10.1016/j.neucom.2020.10.029},
  journal      = {Neurocomputing},
  pages        = {110-123},
  shortjournal = {Neurocomputing},
  title        = {Finger vein recognition based on zone-based minutia matching},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image super-resolution based on dense convolutional
auto-encoder blocks. <em>NEUCOM</em>, <em>423</em>, 98–109. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.049">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (DCNNs) have recently boosted the performance of image super-resolution (SR) by learning deep non-linear mappings from low-resolution images to their high-resolution counterparts. In general, these methods learn the mapping relationship in image space of a single scale. In this paper, we consider that features across different scales can provide various types of information for SR. Thus, we propose a novel network that extracts features of different spatial resolutions for image super-resolution. We successfully build a model to learn non-linear mappings across feature spaces of various spatial resolutions. Specifically, we propose a dense convolutional auto-encoder block (DCAE), which includes several auto-encoder (AE) units and a squeeze unit, as the basic component of our model. The AE units exploit features of different resolutions through paired encoding and decoding layers. Further, we employ skip connections to combine features of the same spatial scale in one AE unit and dense connections across successive AE units in one DCAE block to establish a temporal feature reuse mechanism. The squeeze units combine features in a DCAE block and the previous DCAE block to achieve long-term temporal feature reuse. Furthermore, we extend our work by performing multi-scale supervised training to build a single framework for SR of all scale factors. Comprehensive experiments show that the proposed method outperforms state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Yuan Zhou and Yeda Zhang and Xukai Xie and Sun-Yuan Kung},
  doi          = {10.1016/j.neucom.2020.09.049},
  journal      = {Neurocomputing},
  pages        = {98-109},
  shortjournal = {Neurocomputing},
  title        = {Image super-resolution based on dense convolutional auto-encoder blocks},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multistability of delayed neural networks with monotonically
nondecreasing linear activation function. <em>NEUCOM</em>, <em>423</em>,
89–97. (<a href="https://doi.org/10.1016/j.neucom.2020.10.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the multistability on a class of delayed neural networks with monotonically nondecreasing linear activation function . For n state neurons with 2 m + 1 2m+1 piecewise linear activation function , we prove the neural networks have ( 2 m + 1 ) n (2m+1)n equilibrium points, ( m + 1 ) n (m+1)n of which are locally exponentially stable. Different from the traditional multistability analysis method such as fixed point theory, this paper only uses the character of activation functions, and can also handle the neural networks with disturbance term. The research results of this paper generalize the previous related research works and are easy to test. A numerical example is given to shown the effectiveness of our theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Yuanchu Shen and Song Zhu},
  doi          = {10.1016/j.neucom.2020.10.011},
  journal      = {Neurocomputing},
  pages        = {89-97},
  shortjournal = {Neurocomputing},
  title        = {Multistability of delayed neural networks with monotonically nondecreasing linear activation function},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). Synthesis of complex- and hyperbolic-valued hopfield neural
networks. <em>NEUCOM</em>, <em>423</em>, 80–88. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A complex-valued Hopfield neural network (CHNN), a multistate Hopfield model, is useful for processing multilevel data, such as image data. Several alternatives of CHNN have been proposed. A hyperbolic-valued Hopfield neural network (HHNN) improves the noise tolerance of CHNN. In this work, we propose a synthetic Hopfield neural network (SHNN), a combination of a CHNN and an HHNN. An SHNN is the first combination of Hopfield models using different algebras. Since a CHNN and an HHNN have different operators, such as addition and multiplication, they are represented by matrices and vectors to compose an SHNN. A CHNN and an HHNN have different global minima. Only the common global minima are the global minima of SHNN. Thus, an SHNN is expected to improve the noise tolerance. In fact, computer simulations support our expectation.},
  archive      = {J_NEUCOM},
  author       = {Masaki Kobayashi},
  doi          = {10.1016/j.neucom.2020.10.002},
  journal      = {Neurocomputing},
  pages        = {80-88},
  shortjournal = {Neurocomputing},
  title        = {Synthesis of complex- and hyperbolic-valued hopfield neural networks},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Biased ReLU neural networks. <em>NEUCOM</em>, <em>423</em>,
71–79. (<a href="https://doi.org/10.1016/j.neucom.2020.09.050">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural networks (NN) with rectified linear units (ReLU) have been widely implemented since 2012. In this paper, we describe an activation function called the biased ReLU neuron (BReLU), which is similar to the ReLU. Based on this activation function , we propose the BReLU NN (BRNN). The structure of the BRNN is similar to that of the ReLU network. However, the difference between the two is that the BReLU introduces several biases for each input variable. This allows the BRNN to divide the input space into a greater number of linear regions and improve network flexibility. The BRNN parameters to be estimated are the weight matrices and the bias parameters of the BReLU neurons. The weights are obtained using the backpropagation method. Moreover, we propose a method to compute the bias parameters of the BReLU neurons. In this method, batch normalization is applied to the BRNN, and the variance and mean of the input variables are obtained. Based on these two parameters, the bias parameters are estimated. In addition, we investigate the flexibility of the BRNN. Specifically, we study the number of linear regions and provide the upper bound for the maximum number of linear regions. The results indicate that for the same input dimension, the BRNN divides the input space into a greater number of linear regions than the ReLU network. This explains to a certain extent why the BRNN has the superior approximation ability. Experiments are carried out using five datasets, and the results verify the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {XingLong Liang and Jun Xu},
  doi          = {10.1016/j.neucom.2020.09.050},
  journal      = {Neurocomputing},
  pages        = {71-79},
  shortjournal = {Neurocomputing},
  title        = {Biased ReLU neural networks},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). PrGCN: Probability prediction with graph convolutional
network for person re-identification. <em>NEUCOM</em>, <em>423</em>,
57–70. (<a href="https://doi.org/10.1016/j.neucom.2020.10.019">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robust similarity measurement is an important issue for person re-identification (ReID). Most existing ReID models estimate the similarity between query and gallery images by computing their Euclidean distances while ignoring the rich context information contained in the image space. In this paper, we propose a graph convolutional network (GCN) based method to improve the similarity measurement in ReID, which regards the ReID task as a prediction problem of the link probability between node pairs. Our method is named as PrGCN (Probability GCN), in which each person is regarded as an instance node. Firstly, an Instance Centered Sub-graphs (ICS) is constructed for each instance node to depict its rich local context information. Secondly, the constructed ICS is input to a GCN to infer and predict the link probability of node pairs, followed by a similarity ranking between the query and gallery images according to the predicted probabilities. Extensive experiments show that the proposed method improves the mAP and Top-1 accuracy of ReID significantly, yielding better or comparable results to the state-of-the-art methods on various benchmarks (Market1501, DukeMTMC-ReID and CUHK03). In addition, we validate that the proposed PrGCN can be easily embedded into other deep learning architectures to replace Euclidean distance metric and achieve significant performance improvements.},
  archive      = {J_NEUCOM},
  author       = {Hongmin Liu and Zhenzhen Xiao and Bin Fan and Hui Zeng and Yifan Zhang and Guoquan Jiang},
  doi          = {10.1016/j.neucom.2020.10.019},
  journal      = {Neurocomputing},
  pages        = {57-70},
  shortjournal = {Neurocomputing},
  title        = {PrGCN: Probability prediction with graph convolutional network for person re-identification},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A multi-scale and multi-level feature aggregation network
for crowd counting. <em>NEUCOM</em>, <em>423</em>, 46–56. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, crowd counting has drawn widespread attention in computer vision, but it is extremely challenging because of the varying scales and densities. Many existing methods focus on improving the multi-scale representation by utilizing multi-column or multi-branch architectures with different kernel sizes. However, such networks cannot extract the feature maps with large receptive fields due to limitation of depth. In addition, the importance of utilizing the multi-level feature information in a deep network is ignored. In this paper, we propose a multi-scale and multi-level features aggregation network (MFANet) for accurate and efficient crowd counting, and it can be trained by end-to-end. A vital component of the network is the scale and level aggregation module (SLAM), which can extract multi-scale features and make full use of multi-level feature information for more accurate estimation. When six SLAMs are stacked together and applied to our network, our method can achieve the best performance. Furthermore, we introduce a new loss function called normalized Euclidean loss (NEL) to balance the contribution of all samples to network training. To demonstrate the performance of the proposed method, extensive experiments are conducted on four benchmark crowd counting datasets, including ShanghaiTec Part A/B, UCF-CC-50, Mall, and UCF-QNRF. Experimental results show that our MFANet achieves state-of-the-art performance in crowd counting and crowd localization.},
  archive      = {J_NEUCOM},
  author       = {Fushun Zhu and Hua Yan and Xinyue Chen and Tong Li and Zhengyu Zhang},
  doi          = {10.1016/j.neucom.2020.09.059},
  journal      = {Neurocomputing},
  pages        = {46-56},
  shortjournal = {Neurocomputing},
  title        = {A multi-scale and multi-level feature aggregation network for crowd counting},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Segmentation of the multimodal brain tumor image used the
multi-pathway architecture method based on 3D FCN. <em>NEUCOM</em>,
<em>423</em>, 34–45. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Segmentation of multimodal brain tissues from 3D medical images is of great significance for brain diagnosis. It is required to create an automated and accurate segmentation based on deep-learning network due to the manual segmentation is time-consuming. However, how to segment medical images accurately and how to build neural network effectively with very limited computing resource, is still challenging task. To address these problems, we propose a novel model based on 3D fully convolutional network . More specifically, we apply multi-pathway architecture to feature extraction so as to effectively extract features from multi-modal MRI images. Different receptive field of feature have been extracted by adopting 3D dilated convolution in each pathway. By evaluating one-pathway model and key components of our model with a set of effective training schemes, we analyzed how these alternative methods affect the performance of experiments. Our proposed model was evaluated in the Brain Tumor Segmentation 2019 dataset (BraTS 2019), making an effective segmentation for the complete, core and enhancing tumor regions in Dice Similarity Coefficient metric (0.89, 0.78, 0.76) for the dataset. Also, we made a practice on BraTS 2018 using the same method with the Dice Similarity Coefficient metric of 0.90, 0.79, and 0.77 for the complete, core and enhancing tumor regions. Our method is inherently general and is a powerful tool to studies of medical images of brain tumors. Our code is available at https://github.com/JalexDooo/BrainstormTS .},
  archive      = {J_NEUCOM},
  author       = {Jindong Sun and Yanjun Peng and Yanfei Guo and Dapeng Li},
  doi          = {10.1016/j.neucom.2020.10.031},
  journal      = {Neurocomputing},
  pages        = {34-45},
  shortjournal = {Neurocomputing},
  title        = {Segmentation of the multimodal brain tumor image used the multi-pathway architecture method based on 3D FCN},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multinomial bayesian extreme learning machine for sparse and
accurate classification model. <em>NEUCOM</em>, <em>423</em>, 24–33. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse Bayesian extreme learning machine (SBELM) is a probabilistic model with three-layer neural network, which is superior to extreme learning machine (ELM) in model generalization, sparsity and execution time. In SBELM, Bernoulli distribution is employed for binary classification, and then extended to multi-class classification using pairwise coupling. However, pairwise coupling suffers from three significant drawbacks for multi-class classification: 1) classification ambiguity and uncovered class regions; 2) large model size; 3) insufficient uncertainty representation for label prediction in probabilities. To alleviate these drawbacks, multinomial Bayesian extreme learning machine (MBELM) is proposed that employs multinomial distribution, which is proposed for multi-class classification. For the sake of various concerns between sparsity and accuracy, two sparse mechanisms namely automatic relevance determination (ARD) and L 1 L1 penalty are respectively integrated with MBELM. The experimental results show that, compared to SBELM, the proposed MBELM improves the test accuracy and the model size respectively up to 5\% better, and 94 times smaller for multi-class classification.},
  archive      = {J_NEUCOM},
  author       = {Jiahua Luo and Chi-Man Wong and Chi-Man Vong},
  doi          = {10.1016/j.neucom.2020.09.061},
  journal      = {Neurocomputing},
  pages        = {24-33},
  shortjournal = {Neurocomputing},
  title        = {Multinomial bayesian extreme learning machine for sparse and accurate classification model},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reweighting and information-guidance networks for few-shot
learning. <em>NEUCOM</em>, <em>423</em>, 13–23. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.128">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-Shot Learning (FSL) aims at recognizing new categories from a few available samples. In this paper, we propose two strategies on the basis of Prototypical Networks [1] to improve the discriminativeness and representativeness of the visual prototypes for few-shot learning task. Firstly, we propose a reweighting mechanism to distribute different weights for accesses the instance representativeness to the class. Secondly, we propose an information-guidance mechanism to encode discriminative knowledge into the class prototypes to compensate for more information across classes. Extensive experimental results on two benchmark datasets empirically show that both the proposed strategies improve the Prototypical Networks and achieve the state-of-the-art performances. Besides, the information-guidance mechanism could be seamlessly combined into some existing approaches to substantially improve their performances on few-shot classification.},
  archive      = {J_NEUCOM},
  author       = {Zhong Ji and Xingliang Chai and Yunlong Yu and Zhongfei Zhang},
  doi          = {10.1016/j.neucom.2020.07.128},
  journal      = {Neurocomputing},
  pages        = {13-23},
  shortjournal = {Neurocomputing},
  title        = {Reweighting and information-guidance networks for few-shot learning},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Skeleton edge motion networks for human action recognition.
<em>NEUCOM</em>, <em>423</em>, 1–12. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human skeleton is receiving increasing attention from the community of human action recognition due to its robustness to complex image backgrounds. Previous methods usually utilize body joint-based representation, i.e., joint locations, while leaving edge-based movement poorly investigated. In this paper, we propose a new human action recognition method, skeleton edge motion networks (SEMN), to further explore the motion information of human body parts. Specifically, we address the movement of skeleton edge by using the angle changes of skeleton edge and the movement of the corresponding body joints. We then devise the proposed skeleton edge motion networks by stacking multiple spatial-temporal blocks to learn a robust deep representation from skeleton sequences. Furthermore, we propose a new progressive ranking loss to help the proposed skeleton edge motion networks maintain temporal order information in a self-supervised manner. Experimental results on five popular human action recognition datasets, PennAction, UTD-MHAD, NTU RGB+D, NTU RGB+D 120, and CSL, demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Haoran Wang and Baosheng Yu and Kun Xia and Jiaqi Li and Xin Zuo},
  doi          = {10.1016/j.neucom.2020.10.037},
  journal      = {Neurocomputing},
  pages        = {1-12},
  shortjournal = {Neurocomputing},
  title        = {Skeleton edge motion networks for human action recognition},
  volume       = {423},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Probability-based mask r-CNN for pulmonary embolism
detection. <em>NEUCOM</em>, <em>422</em>, 345–353. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pulmonary embolism (PE), a blockage of the lung artery, is common and sometimes fatal. Early diagnosis and treatment of PE can reduce the risk of associated morbidity and mortality. However, it is a huge challenge to accurately detect PE, particularly for the case of small segmental and subsegmental emboli. In this paper, a flexible probability-based Mask R-CNN model, namely P-Mask RCNN, is proposed for PE detection. Specifically, the feature map is firstly upsampled to enrich the local details of the small objects and to extract anchors at a higher density. Then, a candidate area is constructed based on the probability of the appearance of PE. Finally, we extract the anchors in the candidate area of the enlarged feature map for subsequent detection. Extracting anchors in the candidate area instead of the entire image can not only reduce both time and space consumption caused by the enlarging feature maps but also improve the detection performance by eliminating most invalid anchors. Compared with Mask R-CNN, the anchors extracted by the proposed P-Mask RCNN is closer to the ground truth. Extensive experimental results demonstrate the effectiveness and efficiency of the proposed approach. The source code of our method is available at https://github.com/longkun-uestc/P_Mask_RCNN .},
  archive      = {J_NEUCOM},
  author       = {Kun Long and Lei Tang and Xiaorong Pu and Yazhou Ren and Mingxiu Zheng and Li Gao and Chunjiang Song and Su Han and Min Zhou and Fengbin Deng},
  doi          = {10.1016/j.neucom.2020.10.022},
  journal      = {Neurocomputing},
  pages        = {345-353},
  shortjournal = {Neurocomputing},
  title        = {Probability-based mask R-CNN for pulmonary embolism detection},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Event-triggered adaptive fixed-time NN control for
constrained nonstrict-feedback nonlinear systems with prescribed
performance. <em>NEUCOM</em>, <em>422</em>, 332–344. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, an observer-based adaptive fixed-time control strategy is put forward for uncertain nonstrict-feedback nonlinear systems subject to prescribed performance, full-state constraints and event-triggered mechanism. The difficulty of control design is to use the state observer to estimate unmeasurable states for nonstrict-feedback form in the fixed-time convergence setting. Neural networks are implemented to model the unknown nonlinearities of system. Via introducing fixed-time theory and asymmetric barrier Lyapunov function (ABLF), the fixed-time control problem of the full-state contrained nonlinear system with prescribed performance is solved. Meanwhile, the problem of “explosion of complexity” caused by backstepping technique is averted by utilizing the dynamic surface control technique. Furthermore, an event-triggered controller is devised, which can significantly save communication resources. Moreover, it is concluded that all signals involved are bounded, full-state constraints are not transgressed, tracking error remains within a prescribed domain and Zeno phenomenon is completely circumvented. Finally, the effectiveness of the proposed algorithm is verified by some simulation results.},
  archive      = {J_NEUCOM},
  author       = {Wen Yang and Yingnan Pan and Hongjing Liang},
  doi          = {10.1016/j.neucom.2020.09.051},
  journal      = {Neurocomputing},
  pages        = {332-344},
  shortjournal = {Neurocomputing},
  title        = {Event-triggered adaptive fixed-time NN control for constrained nonstrict-feedback nonlinear systems with prescribed performance},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Data-based output tracking formation control for
heterogeneous MIMO multiagent systems under switching topologies.
<em>NEUCOM</em>, <em>422</em>, 322–331. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A data-based output tracking formation control strategy for nonlinear MIMO multiagent systems (MASs) is provided in this paper, where the dynamic of each agent is disparate. The novel linearization method is used to construct the agent models dynamically, and only one linearization parameter needs to be estimated via I/O data. Then, the data-driven formation control protocol is presented for heterogeneous MIMO MASs under switching topologies . The convergence analysis using contraction mapping principle shows that the output tracking errors of the group of agents are uniformly ultimately bounded. We also prove that the presented formation control protocol can be extended to the MASs with time-variable geometry formation. The combination of data-driven method, heterogeneous MASs, MIMO agent, switching topologies and time-varying formation control makes the presented control strategy more general and practical. In the end, two simulation experiments are given to elucidate the effectiveness of this formation control protocol of MASs.},
  archive      = {J_NEUCOM},
  author       = {Weizhao Song and Jian Feng and Shaoxin Sun},
  doi          = {10.1016/j.neucom.2020.10.017},
  journal      = {Neurocomputing},
  pages        = {322-331},
  shortjournal = {Neurocomputing},
  title        = {Data-based output tracking formation control for heterogeneous MIMO multiagent systems under switching topologies},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Style transfer for unsupervised domain-adaptive person
re-identification. <em>NEUCOM</em>, <em>422</em>, 314–321. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) is aimed to identify the same person under different cameras with disjoint views. With the development of deep learning , supervised Re-ID has made great progress. However, most methods fail to be generalized to new domains due to the potential image distinctions between different domains, making it difficult to be applied in practical use. We propose an unsupervised domain-adaptive person re-identification method based on style transfer (STReID) to improve model cross-domain capability. In this work, a novel style transfer framework is proposed for Re-ID, which allows us to change the style of images while retaining content information. Specifically, STReID mainly includes two steps: first, each image in the source domain is converted into the target domain style and the identity (ID) information remains unchanged. Then the source domain images and style transferred images are combined to train a style-independent Re-ID model. Experiments show that our method achieves higher performance of unsupervised cross-domain person Re-ID.},
  archive      = {J_NEUCOM},
  author       = {Yanwen Chong and Chengwei Peng and Jingjing Zhang and Shaoming Pan},
  doi          = {10.1016/j.neucom.2020.10.005},
  journal      = {Neurocomputing},
  pages        = {314-321},
  shortjournal = {Neurocomputing},
  title        = {Style transfer for unsupervised domain-adaptive person re-identification},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fixed-time synchronization analysis for discontinuous fuzzy
inertial neural networks with parameter uncertainties. <em>NEUCOM</em>,
<em>422</em>, 295–313. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to investigate the fixed-time synchronization analysis for discontinuous fuzzy inertial neural networks in the presence of parameter uncertainties. By using a new variable transformation and differential inclusions theory, we first establish two kinds of drive-response differential inclusion systems. By designing some novel discontinuous control inputs and using Lyapunov-Krasovskii functional approach, some sufficient criteria are derived for achieving fixed-time synchronization, and the corresponding setting times are estimated. The established results provide a new framework to deal with the inertial neural networks with fuzzy logics and discontinuous activation functions . Some previous works in the literature are extended and complement. Finally, two topical simulation examples are given to show the effectiveness of the developed main control schemes.},
  archive      = {J_NEUCOM},
  author       = {Fanchao Kong and Quanxin Zhu and Rathinasamy Sakthivel and Ardashir Mohammadzadeh},
  doi          = {10.1016/j.neucom.2020.09.014},
  journal      = {Neurocomputing},
  pages        = {295-313},
  shortjournal = {Neurocomputing},
  title        = {Fixed-time synchronization analysis for discontinuous fuzzy inertial neural networks with parameter uncertainties},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Augmented two-side-looped lyapunov functional for
sampled-data-based synchronization of chaotic neural networks with
actuator saturation. <em>NEUCOM</em>, <em>422</em>, 287–294. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper further investigated the synchronization problem of the chaotic neural networks by utilizing the sampled-data control with actuator saturation. Firstly, an augmented two-side-looped Lyapunov functional including both the states of the error system and their derivative is constructed. Then the Wirtinger-based integral inequality in combination with the improved reciprocally convex matrix inequality is applied to estimate the derivative of the presented Lyapunov functional and improved synchronization criteria are derived. As a result, a state feedback controller based on sampled-data is designed, making the drive system synchronize with the response system. Finally, through the results of the numerical example, the validity and superiority of the proposed methods have been confirmed.},
  archive      = {J_NEUCOM},
  author       = {Ying Zhang and Yong He and Fei Long},
  doi          = {10.1016/j.neucom.2020.09.018},
  journal      = {Neurocomputing},
  pages        = {287-294},
  shortjournal = {Neurocomputing},
  title        = {Augmented two-side-looped lyapunov functional for sampled-data-based synchronization of chaotic neural networks with actuator saturation},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The variant d-path laplacian based consensus protocols for
networked harmonic oscillators. <em>NEUCOM</em>, <em>422</em>, 277–286.
(<a href="https://doi.org/10.1016/j.neucom.2020.09.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the consensus protocol design problem of the networked harmonic oscillators interacting through a directed graph with peer pressure from the perspective of the output information, in which the peer pressure is in the expression of the variant d -path Laplacian. For networked harmonic oscillators without time delay , sufficient conditions in terms of coupling strength are given, while for networked harmonic oscillators with time delay , sufficient conditions in the term of coupling strength and the upper bound on the time delay are proposed. Finally, simulation examples are provided to verify the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Rong Fang and Xiaoling Wang and Housheng Su and Min Xiao},
  doi          = {10.1016/j.neucom.2020.09.053},
  journal      = {Neurocomputing},
  pages        = {277-286},
  shortjournal = {Neurocomputing},
  title        = {The variant d-path laplacian based consensus protocols for networked harmonic oscillators},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Payment-guard: Detecting fraudulent in-app purchases in iOS
system. <em>NEUCOM</em>, <em>422</em>, 263–276. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a successful business model, “in-app purchase” has been adopted by massive applications (Apps) gradually. Users can purchase various virtual goods in different kinds of Apps, such as the license to download movies or songs. In-app purchase helps App operators gain huge income, and meanwhile provides users with flexibility in using Apps. Recently, iOS Apps have suffered the attack of fraudulent purchase. Attackers leverage the vulnerabilities in iOS payment system to purchase virtual goods at zero or low cost. More seriously, unscrupulous attackers solicit customers publicly and provide purchasing services, which has caused huge financial loss to business entities. It becomes of great importance to detect the fraudulent in-app purchases in iOS Apps, and then take measures such as confiscating goods to minimize profit loss. In this paper, we propose a system called Payment-Guard to achieve this objective, which designs various features to characterize a purchase from four perspectives including App account behavior , device behavior, IP behavior and union behavior of (App account, device, IP), then conducts detection based on the features. We perform comprehensive experiments based on data collected from “Honor of Kings” App, which is one of the most famous MOBA games in China and allows players to recharge App accounts for virtual currency. Experimental results demonstrated that Payment-Guard can detect 92.2\% malicious in-app purchases and with only 2\% false positive rate.},
  archive      = {J_NEUCOM},
  author       = {Yadong Zhou and Tianyi Yue and Xiaoming Liu and Chao Shen and Lingling Tong and Zhihao Ding},
  doi          = {10.1016/j.neucom.2020.10.007},
  journal      = {Neurocomputing},
  pages        = {263-276},
  shortjournal = {Neurocomputing},
  title        = {Payment-guard: Detecting fraudulent in-app purchases in iOS system},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient approach for privacy preserving decentralized
deep learning models based on secure multi-party computation.
<em>NEUCOM</em>, <em>422</em>, 245–262. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to develop a new efficient framework named Secure Decentralized Training Framework (SDTF) for Privacy Preserving Deep Learning models . The main feature of the proposed framework is its capable of working on a decentralized network setting that does not need a trusted third-party server while simultaneously ensuring the privacy of local data with a low cost of communication bandwidth . Particularly, we first propose a so-called Efficient Secure Sum Protocol (ESSP) that enables a large group of parties to jointly calculate a sum of private inputs. ESSP can work not only with integer number but also with floating point number without any data conversion. We then propose a Secure Model Sharing Protocol that enables a group of parties securely train and share the local models to be aggregated into a global model. Secure Model Sharing Protocol exploits randomization techniques and ESSP to protect local models from any honest-but-curious party even n - 2 n-2 of n parties colluding. Eventually, these protocols are employed for collaborative training decentralized deep learning models. We conduct theoretical evaluation of privacy and communication cost as well as empirical experiments on balance class image datasets (MNIST) and an unbalance class text dataset (UCI SMS Spam). These experiments demonstrate the proposed approach can obtain high accuracy (i.e. 97\% baseline accuracy in only 10 training rounds with MNIST, 100 training rounds with SMS Spam) and robust to the heterogeneity decentralized network, with non-IID and unbalance data distributions. We also show a reduction in required rounds of training to achieve the accuracy baseline by 5 × × as compared to Downpour SGD . It is shown that the proposed approach can achieve both the privacy at the level of cryptographic approaches and efficiency at the level of randomization techniques, while it also retains higher model’s utility than differential privacy approaches.},
  archive      = {J_NEUCOM},
  author       = {Anh-Tu Tran and The-Dung Luong and Jessada Karnjana and Van-Nam Huynh},
  doi          = {10.1016/j.neucom.2020.10.014},
  journal      = {Neurocomputing},
  pages        = {245-262},
  shortjournal = {Neurocomputing},
  title        = {An efficient approach for privacy preserving decentralized deep learning models based on secure multi-party computation},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Region of interest selection for functional features.
<em>NEUCOM</em>, <em>422</em>, 235–244. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is a critical component in supervised learning to improve model performance. Searching for the optimal feature candidates can be NP-hard. With limited data, cross-validation is widely used to alleviate overfitting, which unfortunately suffers from high computational cost. We propose a highly innovative strategy in feature selection to reduce the overfitting risk but without cross-validation. Our method selects the optimal sub-interval, i.e., region of interest (ROI), of a functional feature for functional linear regression where the response is a scalar and the predictor is a function. For each candidate sub-interval, we evaluate the overfitting risk by calculating a necessary sample size to achieve a pre-specified statistical power. Combining with a model accuracy measure, we rank these sub-intervals and select the ROI. The proposed method has been compared with other state-of-the-art feature selection methods on several reference datasets. The results show that our proposed method achieves an excellent performance in prediction accuracy and reduces computational cost substantially.},
  archive      = {J_NEUCOM},
  author       = {Qiyue Wang and Yao Lu and Xiaoke Zhang and James Hahn},
  doi          = {10.1016/j.neucom.2020.10.009},
  journal      = {Neurocomputing},
  pages        = {235-244},
  shortjournal = {Neurocomputing},
  title        = {Region of interest selection for functional features},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Synchronization and metabolic energy consumption in
stochastic hodgkin-huxley neurons: Patch size and drug blockers.
<em>NEUCOM</em>, <em>422</em>, 222–234. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, a stochastic Langevin approach is adopted to coupled Hodgkin-Huxley neuron system to elucidate the role of channel noise in the kinetics and energetics of spiking of action potential and the synchronization between neurons. The size of patch plays a pivotal role in synchronization and metabolic energy consumption. The behavior of postsynaptic neuron is explored by taking three different patch size ranges from noise enhanced phase to dead range state before reaching a deterministic limit. We also discuss the effect of sodium and potassium channel blockers on kinetic and energetic characteristics of synchronization and metabolic energy consumption rate.},
  archive      = {J_NEUCOM},
  author       = {Krishnendu Pal and Dibakar Ghosh and Gautam Gangopadhyay},
  doi          = {10.1016/j.neucom.2020.10.006},
  journal      = {Neurocomputing},
  pages        = {222-234},
  shortjournal = {Neurocomputing},
  title        = {Synchronization and metabolic energy consumption in stochastic hodgkin-huxley neurons: Patch size and drug blockers},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A convolutional neural network using dinucleotide one-hot
encoder for identifying DNA n6-methyladenine sites in the rice genome.
<em>NEUCOM</em>, <em>422</em>, 214–221. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {N6-methyladenine (m 6 A) is one of the crucial epigenetic modifications and is related to the control of various DNA processes. Carrying out a genome-wide m 6 A analysis via wet experiments is fundamental but takes a long time. As complementary methods, computing tools, especially those based on machine learning , are urgently needed. A new protocol, iRicem6A-CNN, for identifying m 6 A sites in the rice genome was developed. This protocol was designed to use dinucleotide one-hot encoding to generate input tensors for predictions by convolutional neutral networks, and achieved five-fold cross-validation and independent testing accuracy values of 93.82\% and 96.19\%, respectively, performing better than those of other available predictors. The experiment results demonstrates that only the ability of iRicem6A-CNN based on 2-mer one-hot encoding is to display high performance but also to perform more stably and robustly than models using 1-mer one-hot encoding. A webserver is accessible at http://iRicem6A-CNN.aibiochem.net},
  archive      = {J_NEUCOM},
  author       = {Zhibin Lv and Hui Ding and Lei Wang and Quan Zou},
  doi          = {10.1016/j.neucom.2020.09.056},
  journal      = {Neurocomputing},
  pages        = {214-221},
  shortjournal = {Neurocomputing},
  title        = {A convolutional neural network using dinucleotide one-hot encoder for identifying DNA n6-methyladenine sites in the rice genome},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Local distribution-based adaptive minority oversampling for
imbalanced data classification. <em>NEUCOM</em>, <em>422</em>, 200–213.
(<a href="https://doi.org/10.1016/j.neucom.2020.05.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Imbalanced data classification, as a challenging task, has drawn a significant interest in numerous scientific areas. One popular strategy to balance the instance quantities between two classes is oversampling via generating synthetic instances. However, it still suffers from two key issues: where and how many synthetic instances should be generated. In this paper, we propose a L ocal distribution-based A daptive M inority O versampling method (LAMO) to deal with the imbalance classification problem. LAMO first identifies the informative borderline minority instances as sampling seeds according to their neighbors and the corresponding class distribution. Then, LAMO captures the local distribution of each seed according to its Euclidean distances from the nearest majority instance and nearest minority instance.Finally, LAMO generates synthetic instances around seeds via a Gaussian Mixture Model (GMM). For each component of GMM, the mixing coefficient and bandwidth are adaptively set with the aid of seeds’ local distribution. Extensive experiments have been conducted on both simulated and real data sets under varying the imbalance ratio and data size. By comparing with the state-of-the-art oversampling methods, the proposed LAMO obtains promising results in terms of several widely used evaluation metrics .},
  archive      = {J_NEUCOM},
  author       = {Xinyue Wang and Jian Xu and Tieyong Zeng and Liping Jing},
  doi          = {10.1016/j.neucom.2020.05.030},
  journal      = {Neurocomputing},
  pages        = {200-213},
  shortjournal = {Neurocomputing},
  title        = {Local distribution-based adaptive minority oversampling for imbalanced data classification},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Cycle label-consistent networks for unsupervised domain
adaptation. <em>NEUCOM</em>, <em>422</em>, 186–199. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.124">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Domain adaptation aims to leverage a labeled source domain to learn a classifier for the unlabeled target domain with a different distribution. Previous methods mostly match the distribution between two domains by global or class alignment. However, global alignment methods cannot achieve a fine-grained class-to-class overlap; class alignment methods supervised by pseudo-labels cannot guarantee their reliability. In this paper, we propose a simple yet efficient domain adaptation method, i.e. Cycle Label-Consistent Network (CLCN), by exploiting the cycle consistency of classification label, which applies dual cross-domain nearest centroid classification procedures to generate a reliable self-supervised signal for the discrimination in the target domain. The cycle label-consistent loss reinforces the consistency between ground-truth labels and pseudo-labels of source samples leading to statistically similar latent representations between source and target domains. This new loss can easily be added to any existing classification network with almost no computational overhead. We demonstrate the effectiveness of our approach on MNIST-USPS-SVHN, Office-31, Office-Home and Image CLEF-DA benchmarks. Results validate that the proposed method can alleviate the negative influence of falsely-labeled samples and learn more discriminative features , leading to the absolute improvement over source-only model by 9.4\% on Office-31 and 6.3\% on Image CLEF-DA.},
  archive      = {J_NEUCOM},
  author       = {Mei Wang and Weihong Deng},
  doi          = {10.1016/j.neucom.2020.07.124},
  journal      = {Neurocomputing},
  pages        = {186-199},
  shortjournal = {Neurocomputing},
  title        = {Cycle label-consistent networks for unsupervised domain adaptation},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021g). A neural collaborative filtering method for identifying
miRNA-disease associations. <em>NEUCOM</em>, <em>422</em>, 176–185. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The identification of disease-associated miRNAs can help people better understand the pathogenesis of diseases from a genetic perspective. Therefore, the prediction of miRNA-disease associations has received increasing attention. In this paper, we propose a new computational method NCFM (Neural network-based Collaborative Filtering Method) to predict miRNA-disease associations based on deep neural network. Firstly, high-dimensional sparse vectors of diseases and miRNAs are mapped into low-dimensional dense vectors in implicit semantic space via embedding layer, which called disease embedding and miRNA embedding, respectively. Secondly, the neural collaborative filter layers model the latent feature interactions between miRNAs and diseases. Then, different from other methods using square error loss function, we propose a new pairwise loss function to optimizes our model from a ranking perspective. Finally, experiments show that our proposed method can effectively prioritize disease-related miRNAs with the highest AUC of 0.912 and 0.921 compared with other recent methods in 5-fold cross validation and LOOCV framework. In addition, we implement two types of case studies, including four diseases. For a disease, more than 90\% of predicted miRNAs are validated by another official dataset, which further illustrates the effectiveness of NCFM.},
  archive      = {J_NEUCOM},
  author       = {Yue Liu and Shu-Lin Wang and Jun-Feng Zhang and Wei Zhang and Wen Li},
  doi          = {10.1016/j.neucom.2020.09.032},
  journal      = {Neurocomputing},
  pages        = {176-185},
  shortjournal = {Neurocomputing},
  title        = {A neural collaborative filtering method for identifying miRNA-disease associations},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic depression recognition using CNN with attention
mechanism from videos. <em>NEUCOM</em>, <em>422</em>, 165–175. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has incorporated various automatic systems and frameworks to diagnose the severity of depression using hand-crafted features. However, process of feature selection needs domain knowledge and is still time-consuming and subjective. Deep learning technology has been successfully adopted for depression recognition. Most previous works pre-train the deep models on large databases followed by fine-tuning with depression databases (i.e., AVEC2013, AVEC2014). In the present paper we propose an integrated framework – Deep Local Global Attention Convolutional Neural Network (DLGA-CNN) for depression recognition, which adopts CNN with attention mechanism as well as weighted spatial pyramid pooling (WSPP) to learn a deep and global representation. Two branches are introduced: Local Attention based CNN (LA-CNN) focuses on the local patches, while Global Attention based CNN (GA-CNN) learns the global patterns from the entire facial region. To capture the complementary information between the two branches, Local–Global Attention-based CNN (LGA-CNN) is proposed. After feature aggregation, WSPP is used to learn the depression patterns. Comprehensive experiments on AVEC2013 and AVEC2014 depression databases have demonstrated that the proposed method is capable of mining the underlying depression patterns of facial videos and outperforms the most of the state-of-the-art video-based depression recognition approaches.},
  archive      = {J_NEUCOM},
  author       = {Lang He and Jonathan Cheung-Wai Chan and Zhongmin Wang},
  doi          = {10.1016/j.neucom.2020.10.015},
  journal      = {Neurocomputing},
  pages        = {165-175},
  shortjournal = {Neurocomputing},
  title        = {Automatic depression recognition using CNN with attention mechanism from videos},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A fire-controlled MSPCNN and its applications for image
processing. <em>NEUCOM</em>, <em>422</em>, 150–164. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-term research goal of pulse-coupled neural network (PCNN) is to control neuronal firing states at each iteration. Recently, we propose a fire-controlled MSPCNN model (FC-MSPCNN) and provide a parameter setting method to control firing and fired neurons within an effective pulse cycle. We firstly design the proposed model according to previous prevalent PCNN models. Secondly, the setting methods of the adaptive parameters α , β, V , and R n are given to control neuronal firing time more effectively. Thirdly, a predetermined parameter P will determine the total iteration times of all the neurons. Fourthly, we also propose a color image quantization method and a gallbladder image location method based on the FC-MSPCNN. The evaluation experiments achieve good image processing performances compared to prevalent PCNN models and prove the effectiveness and robustness of the proposed methods.},
  archive      = {J_NEUCOM},
  author       = {Jing Lian and Zhen Yang and Wenhao Sun and Li Zheng and Yunliang Qi and Bin Shi and Yide Ma},
  doi          = {10.1016/j.neucom.2020.10.020},
  journal      = {Neurocomputing},
  pages        = {150-164},
  shortjournal = {Neurocomputing},
  title        = {A fire-controlled MSPCNN and its applications for image processing},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Associations between MSE and SSIM as cost functions in
linear decomposition with application to bit allocation for sparse
coding. <em>NEUCOM</em>, <em>422</em>, 139–149. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The traditional image quality assessments , such as the mean squared error (MSE), the signal-to-noise ratio (SNR), and the Peak signal-to-noise ratio (PSNR), are all based on the absolute error of images. Structural similarity (SSIM) index is another important image quality assessment which has been shown to be more effective in the human vision system (HVS). Although there are many essential differences between MSE and SSIM, some important associations exist between them. In this paper, the associations between MSE and SSIM as cost functions in linear decomposition are investigated. Based on the associations, a bit-allocation algorithm for sparse coding is proposed by considering both the reconstructed image quality and the reconstructed image contrast. In the proposed algorithm, the space occupied by a linear coefficient of a basis in sparse coding is reduced to only 9 to 10 bits, in which 1 bit is used to save the sign of linear coefficient, 3 bits are used to save the number of powers of 10 in scientific notation, and only 5 to 6 bits are used to save the significance digits. The experimental results show that the proposed bit-allocation algorithm for sparse coding can maintain both the image quality and the image contrast well.},
  archive      = {J_NEUCOM},
  author       = {Jianji Wang and Pei Chen and Nanning Zheng and Badong Chen and Jose C. Principe and Fei-Yue Wang},
  doi          = {10.1016/j.neucom.2020.10.018},
  journal      = {Neurocomputing},
  pages        = {139-149},
  shortjournal = {Neurocomputing},
  title        = {Associations between MSE and SSIM as cost functions in linear decomposition with application to bit allocation for sparse coding},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Pseudo-LiDAR point cloud magnification. <em>NEUCOM</em>,
<em>422</em>, 129–138. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the pseudo-LiDAR gains increasing attention since it provides the probability of replacing the expensive LiDAR with the camera in autonomous driving . However, due to the fixed field of view of the camera, the pseudo-LiDAR point cloud suffers from the limited spatial range. In this paper, we present a novel pseudo-LiDAR point cloud magnification algorithm, aiming to extrapolate the narrow baseline and further bridge the gap between LiDAR and camera. To achieve this goal, we design a complete pipeline consisting of the hybrid view synthesis module, stereo depth estimation module, image-depth associated stitching module, and magnified pseudo-LiDAR point cloud transformation module. Considering the artifacts existed in generated views, we propose a region-aware restoration approach to obtain more realistic synthesized results. To the best of our knowledge, this is the first work for the pseudo-LiDAR point cloud magnification, which shows appealing and meaningful applications in 3D spatial perception systems only equipped with cameras. Experimental results on KITTI benchmark demonstrate that our algorithm can effectively magnify pseudo-LiDAR point cloud with a wider field of view, note that we only use two images captured by stereo cameras .},
  archive      = {J_NEUCOM},
  author       = {Chunlan Zhang and Kang Liao and Chunyu Lin and Yao Zhao},
  doi          = {10.1016/j.neucom.2020.09.048},
  journal      = {Neurocomputing},
  pages        = {129-138},
  shortjournal = {Neurocomputing},
  title        = {Pseudo-LiDAR point cloud magnification},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Syntax grounded graph convolutional network for joint
entity and event extraction. <em>NEUCOM</em>, <em>422</em>, 118–128. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.044">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Event extraction aims to determine entity mentions, event triggers and argument roles in text, such as news articles. For this task, dependency syntax has been recognized as a valuable source of information. Previous work integrates dependency trees by using one-best results from a parser, where potential incorrect dependencies may impact the event extraction performance. We propose to use syntax features in an implicit approach, by adopting Soft Head Vectors (SHV) drawn from a well-trained parser as an adjacency matrix , densely connecting all words with the probabilistic head scores. SHV can be also regarded as dependency forests where multiple possible structures can be taken into account. A two-phase graph neural network is adopted to represent the forests, automatically differentiating the salient syntactic information from noisy parsers. Experiments on the two public datasets show that our model outperforms various baselines including graph-based one-best tree as well as recent transition-based decoding, giving the state-of-the-art results in the literature.},
  archive      = {J_NEUCOM},
  author       = {Junchi Zhang and Qi He and Yue Zhang},
  doi          = {10.1016/j.neucom.2020.09.044},
  journal      = {Neurocomputing},
  pages        = {118-128},
  shortjournal = {Neurocomputing},
  title        = {Syntax grounded graph convolutional network for joint entity and event extraction},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast-UAP: An algorithm for expediting universal adversarial
perturbation generation using the orientations of perturbation vectors.
<em>NEUCOM</em>, <em>422</em>, 109–117. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs), which are popular machine-learning tools, are being applied in various tasks. However, CNN models are vulnerable to universal perturbations, which despite being usually quasi-imperceptible to the human eye can cause natural images to be misclassified with high probability. The original algorithm of generating universal perturbations (the algorithm is called UAP for brevity) only aggregates minimal perturbations in each iteration without considering the orientations of perturbation vectors; consequently, the magnitude of the universal perturbation cannot efficiently increase at each iteration, thereby resulting in slow universal perturbation generation. Hence, we propose an optimized algorithm to enhance the performance of generating universal perturbations based on the orientations of perturbation vectors. At each iteration, rather than choosing the minimal perturbation vector, we choose the perturbation whose orientation is similar to that of the current universal perturbation; therefore, the magnitude of the aggregation of both the perturbations will be maximized. The experimental results show that compared with UAP, we could generate universal perturbations in a shorter time using a smaller number of training images. Furthermore, we empirically observed that compared with the universal perturbations generated using UAP, the ones generated using our proposed algorithm achieved an average fooling-rate increment of 9\%\% in white-box and black-box attacks.},
  archive      = {J_NEUCOM},
  author       = {Jiazhu Dai and Le Shu},
  doi          = {10.1016/j.neucom.2020.09.052},
  journal      = {Neurocomputing},
  pages        = {109-117},
  shortjournal = {Neurocomputing},
  title        = {Fast-UAP: An algorithm for expediting universal adversarial perturbation generation using the orientations of perturbation vectors},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DK-CNNs: Dynamic kernel convolutional neural networks.
<em>NEUCOM</em>, <em>422</em>, 95–108. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper introduces dynamic kernel convolutional neural networks (DK-CNNs), an enhanced type of CNN, by performing line-by-line scanning regular convolution to generate a latent dimension of kernel weights. The proposed DK-CNN applies regular convolution to the DK weights, which rely on a latent variable, and discretizes the space of the latent variable to extend a new dimension; this process is named “DK convolution”. DK convolution increases the expressive capacity of the convolution operation without increasing the number of parameters by searching for useful patterns within the new extended dimension. In contrast to conventional convolution, which applies a fixed kernel to analyse the changed features, DK convolution employs a DK to analyse fixed features. In addition, DK convolution can replace a standard convolution layer in any CNN network structure. The proposed DK-CNNs were compared with different network structures with and without a latent dimension on the CIFAR and FashionMNIST datasets. The experimental results show that DK-CNNs can achieve better performance than regular CNNs.},
  archive      = {J_NEUCOM},
  author       = {Jialin Liu and Fei Chao and Chih-Min Lin and Changle Zhou and Changjing Shang},
  doi          = {10.1016/j.neucom.2020.09.005},
  journal      = {Neurocomputing},
  pages        = {95-108},
  shortjournal = {Neurocomputing},
  title        = {DK-CNNs: Dynamic kernel convolutional neural networks},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast training of deep LSTM networks with guaranteed
stability for nonlinear system modeling. <em>NEUCOM</em>, <em>422</em>,
85–94. (<a href="https://doi.org/10.1016/j.neucom.2020.09.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep recurrent neural networks (RNN), such as LSTM , have many advantages over forward networks for nonlinear system modeling. However, the most used training method, backward propagation through time (BPTT), is very slow. In this paper, by separating the LSTM cell into forward and recurrent models, we give a faster training method than BPTT. The deep LSTM is modified by combining the deep RNN with the multilayer perceptrons (MLP). The backpropagation-like training methods are proposed for the deep RNN and MLP trainings. The stability of these algorithms are demonstrated. The simulation results show that our fast training methods for LSTM are better than the conventional approaches.},
  archive      = {J_NEUCOM},
  author       = {Wen Yu and Jesus Gonzalez and Xiaoou Li},
  doi          = {10.1016/j.neucom.2020.09.030},
  journal      = {Neurocomputing},
  pages        = {85-94},
  shortjournal = {Neurocomputing},
  title        = {Fast training of deep LSTM networks with guaranteed stability for nonlinear system modeling},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Joint image fusion and super-resolution for enhanced
visualization via semi-coupled discriminative dictionary learning and
advantage embedding. <em>NEUCOM</em>, <em>422</em>, 62–84. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, image fusion has attracted more and more attention, and many excellent methods have emerged. However, only a few studies on joint image fusion and super-resolution have been carried out, and the performance of existing methods is far from that of simple image fusion. To tackle such problem, we propose a novel joint fusion and super-resolution framework based on discriminative dictionary learning. Specifically, we first jointly learn two pairs of low-rank and sparse dictionaries (LRSD) and a conversion dictionary. One pair is used to represent the low-rank and sparse components of low-resolution input images, and the other is used to reconstruct high-resolution fused result; the conversion dictionary is used to establish the relationship between coding coefficients of low-resolution image and high-resolution image. To compensate for the loss of details, structure information compensation dictionary (SICD) is also learned, and the lost information is compensated by SICD and thus visualization of final results is enhanced. To integrate advantages of excellent image fusion methods into the fused and reconstructed results, we propose a deconvolution-based advantage embedding scheme. The experimental results verify the effectiveness and advantages of our method over other competitive ones.},
  archive      = {J_NEUCOM},
  author       = {Huafeng Li and Moyuan Yang and Zhengtao Yu},
  doi          = {10.1016/j.neucom.2020.09.024},
  journal      = {Neurocomputing},
  pages        = {62-84},
  shortjournal = {Neurocomputing},
  title        = {Joint image fusion and super-resolution for enhanced visualization via semi-coupled discriminative dictionary learning and advantage embedding},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient structurally-strengthened generative adversarial
network for MRI reconstruction. <em>NEUCOM</em>, <em>422</em>, 51–61.
(<a href="https://doi.org/10.1016/j.neucom.2020.09.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compressed sensing based magnetic resonance imaging (CS-MRI) methods greatly shorten the scanning time while ensuring the quality of image reconstruction in an efficient way. Recently deep learning has been introduced into MRI reconstruction to further improve the image quality and shorten reconstruction time. In this paper, we propose an efficient structurally-strengthened Generative Adversarial Network , termed as ESSGAN, for reconstructing MR images from highly under-sampled k -space data. ESSGAN consists of a structurally-strengthened generator (termed as SG) and a discriminator . In SG, we introduce strengthened connections to enhance feature propagation and reuse between the concatenated strengthened convolutional autoencoders (termed as SCAEs), where each SCAE is a variant of a typical convolutional autoencoder. In addition, we creatively introduce the residual in residual blocks (termed as RIRBs) to SG. The RIRBs can effectively enhance the expression ability of the proposed SG. To further preserve more image details, we introduce an enhanced structural loss to SG. The experimental results demonstrate that ESSGAN can provide higher image quality with fewer model parameters than the state-of-the-art deep learning-based methods at different undersampling rates under different types of undersampling patterns.},
  archive      = {J_NEUCOM},
  author       = {Wenzhong Zhou and Huiqian Du and Wenbo Mei and Liping Fang},
  doi          = {10.1016/j.neucom.2020.09.008},
  journal      = {Neurocomputing},
  pages        = {51-61},
  shortjournal = {Neurocomputing},
  title        = {Efficient structurally-strengthened generative adversarial network for MRI reconstruction},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Automatic zipper tape defect detection using two-stage
multi-scale convolutional networks. <em>NEUCOM</em>, <em>422</em>,
34–50. (<a href="https://doi.org/10.1016/j.neucom.2020.09.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defects inevitably occur during the manufacturing process of the zipper, significantly affecting its value. Zipper inspection is of significant importance in ensuring the quality of the zipper products. Traditional zipper inspection requires skilled inspectors and is labor-intensive, inefficient, and inaccurate. Currently, automated zipper defects inspection with high precision and high efficiency is still very challenging. In this paper, we propose a novel zipper tape defect detection framework based on fully convolutional networks in a two-stage coarse-to-fine cascade manner. For our special application, the zipper tape defects have multi-scale characteristics. Most of the existing deep learning methods have great advantages in detecting the large-scale defects with prominent features, but are prone to fail in detecting the small-scale ones due to their less remarkable features as well as their general location in a large background area. Thus, we propose to detect first the large local context regions containing the small-scale defects using a multi-scale detection architecture with high efficiency, which integrates a new detection branch by fusing the features in the shallow layer into the high-level layer to boost the detection performance of the context regions. Then we finely detect the small-scale defects from the local context regions detected in the first stage, which can be regarded as large-scale objects that are more easily detected. Extensive comparative experiments demonstrate that the proposed method offers a high detection accuracy while still having high detection efficiency compared with the state-of-the-art methods, coupled with good robustness in some complex cases.},
  archive      = {J_NEUCOM},
  author       = {Houzhang Fang and Mingjiang Xia and Hehui Liu and Yi Chang and Liming Wang and Xiyang Liu},
  doi          = {10.1016/j.neucom.2020.09.046},
  journal      = {Neurocomputing},
  pages        = {34-50},
  shortjournal = {Neurocomputing},
  title        = {Automatic zipper tape defect detection using two-stage multi-scale convolutional networks},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MAFNet: Multi-style attention fusion network for salient
object detection. <em>NEUCOM</em>, <em>422</em>, 22–33. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.033">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Salient object detection based on deep learning has become one of the research hotspots in computer vision. How to effectively extract useful information is a key issue for saliency detection . Most of the existing methods integrate features extracted from convolutional neural networks indiscriminately. However, the features of different layers have different characteristics, not all of them are useful for saliency detection and some even cause interferences. To solve above problem, we propose a Multi-style Attention Fusion Network (MAFNet). Specifically, MAFNet is mainly consists of dual-cues spatial attention module (DSA), dual attention intermediate representation module (DAIR), high-level channel attention module (HCA) and multi-level feature fusion module (MLFF). Among them, DSA aims to refine low-level features and filter background noise. DAIR uses two branches to adaptively integrate the spatial and semantic information of middle-level features. HCA obtains the semantic features of high-level blocks through two different channel-wise operations. Besides, MLFF effectively integrates the above multi-level features in a learnable manner. Finally, different from cross-entropy, cross-IOU loss guides the network to pay more attention to local details. Experimental results on six public datasets demonstrate that MAFNet’s outperformance is competitive in saliency detection and performs well on small object detection.},
  archive      = {J_NEUCOM},
  author       = {Yanhua Liang and Guihe Qin and Minghui Sun and Jie Yan and Huiming Jiang},
  doi          = {10.1016/j.neucom.2020.09.033},
  journal      = {Neurocomputing},
  pages        = {22-33},
  shortjournal = {Neurocomputing},
  title        = {MAFNet: Multi-style attention fusion network for salient object detection},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Safety robustness of reinforcement learning policies: A view
from robust control. <em>NEUCOM</em>, <em>422</em>, 12–21. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For a reinforcement learning (RL) problem without a specified reward function, one may specify different reward functions to better guide an agent to learn. With different reward functions, the agent can learn different policies that generally have different robustness. Both the achieved reward and the success rate have been commonly used to evaluate the robustness of policies. Safety is a concern when using RL to solve problems in many safety–critical applications (e.g., robotic manipulation). However, evaluating the robustness of policies from the perspective of safety has not been discussed in the literature. The major contributions of this paper are the proposal of a novel concept of safety robustness to evaluate the robustness of policies from the perspective of safety and an algorithm to approximate the safety robustness of policies. To demonstrate how to implement the proposed algorithm, illustrative experiments are conducted and the safety robustness of three policies for controlling the manipulation of a cable-driven parallel robot is analyzed. Experiment results show that the proposed algorithm can approximate the safety robustness of policies using the ratio of the number of safe episodes to the number of total episodes and identify the best policy from multiple policies in terms of the safety of policies.},
  archive      = {J_NEUCOM},
  author       = {Hao Xiong and Xiumin Diao},
  doi          = {10.1016/j.neucom.2020.09.055},
  journal      = {Neurocomputing},
  pages        = {12-21},
  shortjournal = {Neurocomputing},
  title        = {Safety robustness of reinforcement learning policies: A view from robust control},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A coarse-to-fine user preferences prediction method for
point-of-interest recommendation. <em>NEUCOM</em>, <em>422</em>, 1–11.
(<a href="https://doi.org/10.1016/j.neucom.2020.09.034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-of-interests (POIs) recommendations aim at recommending locations to users on social platforms by analyzing their histories or combining other information. At present, the different granularity of factors (i.e. time, geography and sociability) are not thoroughly studied in existing works. To deal with this problem, we propose a two-stage coarse-to-fine POI recommendation algorithm based on tensor factorization and weighted distance kernel density estimation (KDE). At first stage, we take account of not only long-term preferences with sequential context, but also the crowd’s preferences to estimate the coarse user-category interest. And then a specific-designed weighted KDE with consideration of spatial distance is employed to determine the fine-grained user-location interest. To evaluate the proposed method, experiments are conducted on two real benchmark location-based social network (LBSN) datasets. And the results show that the proposed method outperforms the state-of-the-art methods and produces better POI recommendation.},
  archive      = {J_NEUCOM},
  author       = {Liangqi Cai and Wen Wen and Biao Wu and Xiaowei Yang},
  doi          = {10.1016/j.neucom.2020.09.034},
  journal      = {Neurocomputing},
  pages        = {1-11},
  shortjournal = {Neurocomputing},
  title        = {A coarse-to-fine user preferences prediction method for point-of-interest recommendation},
  volume       = {422},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). New criteria for finite-time stability of fractional order
memristor-based neural networks with time delays. <em>NEUCOM</em>,
<em>421</em>, 349–359. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.039">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, the finite-time stability (FTS) problems for a class of fractional order memristor-based neural network (FOMNN) with time delays are investigated. Based on the method of steps, set-valued mapping, the theory of differential inclusion and fractional order Gronwall inequality, a new delay dependent criterion for the FTS of FOMNN with time delays and the fractional order 0 0&amp;lt;μ&amp;lt;1 is derived, which is less conservative than the existing criteria. Furthermore, a sufficient condition to ensure the FTS of FOMNN with the fractional-order 1 1&amp;lt;μ&amp;lt;2 is proposed. Finally, two examples are given to illustrate the validity of the proposed results.},
  archive      = {J_NEUCOM},
  author       = {Feifei Du and Jun-Guo Lu},
  doi          = {10.1016/j.neucom.2020.09.039},
  journal      = {Neurocomputing},
  pages        = {349-359},
  shortjournal = {Neurocomputing},
  title        = {New criteria for finite-time stability of fractional order memristor-based neural networks with time delays},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised monocular depth estimation with direct
methods. <em>NEUCOM</em>, <em>421</em>, 340–348. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Depth estimation is crucial to understanding the geometry of a scene in robotics and computer vision. Traditionally, depth estimators can be trained with various forms of self-supervised stereo data or supervised ground-truth data. In comparison to the methods that utilize stereo depth perception or ground-truth data from laser scans, determining depth relation using an unlabeled monocular camera proves considerably more challenging. Recent work has shown that CNN-based depth estimators can be learned using unlabeled monocular video. Without needing the stereo data or ground-truth depth data, learning with monocular self-supervised strategies can utilize much larger and more varied image datasets. Inspired by recent advances in depth estimation, in this paper, we propose a novel objective that replaces the use of explicit ground-truth depth or binocular stereo depth with unlabeled monocular video sequence data. No assumptions about scene geometry or pre-trained information are used in the proposed architecture. To enable a better pose prediction, we propose the use of an improved differentiable direct visual odometry (DDVO), which is fused with an appearance-matching loss. The auto-masking approach is introduced in the DDVO depth predictor to filter out the low-texture area or occlusion area, which can easily reduce matching error, from one frame to the subsequent frame in the monocular sequence. Additionally, we introduce a self-supervised loss function to fuse the auto-masking segment and the depth-prediction segment accordingly. Our method produces state-of-the-art results for monocular depth estimation on the KITTI driving dataset, even outperforming some supervised methods that have been trained with ground-truth depth.},
  archive      = {J_NEUCOM},
  author       = {Haixia Wang and Yehao Sun and Q.M. Jonathan Wu and Xiao Lu and Xiuling Wang and Zhiguo Zhang},
  doi          = {10.1016/j.neucom.2020.10.025},
  journal      = {Neurocomputing},
  pages        = {340-348},
  shortjournal = {Neurocomputing},
  title        = {Self-supervised monocular depth estimation with direct methods},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyperbolic node embedding for signed networks.
<em>NEUCOM</em>, <em>421</em>, 329–339. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Signed network embedding methods aim to learn vector representations of nodes in signed networks. However, existing algorithms only managed to embed networks into low-dimensional Euclidean spaces whereas many intrinsic features of signed networks are reported more suitable for non-Euclidean spaces. For instance, previous works did not consider the hierarchical structures of networks, which is widely witnessed in real-world networks. In this work, we answer an open question that whether the hyperbolic space is a good choice to accommodate signed networks and learn embeddings that can preserve the corresponding special characteristics. We also propose a non-Euclidean signed network embedding method based on structural balance theory and Riemannian optimization, which embeds signed networks into a Poincaré ball in a hyperbolic space . This space enables our approach to capture underlying hierarchy of nodes in signed networks because it can be seen as a continuous tree. We empirically compare our method against six Euclidean-based baselines in three tasks on seven real-world datasets, and the results show the effectiveness of our method.},
  archive      = {J_NEUCOM},
  author       = {Wenzhuo Song and Hongxu Chen and Xueyan Liu and Hongzhe Jiang and Shengsheng Wang},
  doi          = {10.1016/j.neucom.2020.10.008},
  journal      = {Neurocomputing},
  pages        = {329-339},
  shortjournal = {Neurocomputing},
  title        = {Hyperbolic node embedding for signed networks},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hyper-parameter-evolutionary latent factor analysis for
high-dimensional and sparse data from recommender systems.
<em>NEUCOM</em>, <em>421</em>, 316–328. (<a
href="https://doi.org/10.1016/j.neucom.2020.10.030">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {High-dimensional and Sparse (HiDS) data generated by recommender systems (RSs) contain rich knowledge regarding users’ potential preferences. A Latent factor analysis (LFA) model enables efficient extraction of essential features from such data. However, an LFA model relies heavily on its hyper-parameters like learning rate and regularization coefficient, which must be chosen with care. However, traditional grid-search-based manual tuning is extremely time-consuming and computationally expensive. To address this issue, this study proposes a hyper-parameter-evolutionary latent factor analysis (HLFA) model. Its main idea is to build a swarm by taking the hyper-parameters of every single LFA-based model as particles, and then apply particle swarm optimization (PSO) to make its both hyper-parameters, i.e., the learning rate and regularization coefficient, self-adaptive according to a pre-defined fitness function. Experimental results on six HiDS matrices from real RSs indicate that an HLFA model outperforms several state-of-the-art LF models in terms of computational efficiency, and most importantly, without loss of prediction accuracy for missing data of an HiDS matrix.},
  archive      = {J_NEUCOM},
  author       = {Jiufang Chen and Ye Yuan and Tao Ruan and Jia Chen and Xin Luo},
  doi          = {10.1016/j.neucom.2020.10.030},
  journal      = {Neurocomputing},
  pages        = {316-328},
  shortjournal = {Neurocomputing},
  title        = {Hyper-parameter-evolutionary latent factor analysis for high-dimensional and sparse data from recommender systems},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive prognostics method for fusing CDBN and diffusion
process: Application to bearing data. <em>NEUCOM</em>, <em>421</em>,
303–315. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the coming era of big data, many advances and attempts have been witnessed in deep learning based remaining useful life (RUL) prediction methods which can construct the mapping relation between the massive information and the RUL. Existing studies leverage advanced deep networks for RUL prediction mainly generating the point estimates for the RUL while the prognostic uncertainty quantification is often difficult. However, it is well admitted that such prognostic uncertainty quantification is important and cannot be neglected for health management of degrading products. The purpose of this paper is to develop an adaptive prognostic method towards both the massive data and prognostics uncertainty by leveraging the advantages of deep learning methods in processing massive data and stochastic methods in the uncertainty representation. To do so, a continuous deep belief network (CDBN) is first utilized to extract the deep hidden features behind the massive information, and then, we determine the health index via the self-organizing map (SOM) neural network based on the extracted features. Next, the diffusion process is applied to construct the health index evolving model. The parameters in the diffusion process are estimated online by combining Bayesian method and Expectation Maximization (EM) algorithm. Consequently, the probability density function (PDF) of the RUL can be obtained and updated adaptively. Finally, a practical case study for bearings is provided to substantiate the effectiveness and superiority of the proposed method. Experimental results indicate that the proposed method can provide more accurate RUL predictions.},
  archive      = {J_NEUCOM},
  author       = {Hong Pei and Xiao-Sheng Si and Chang-Hua Hu and Jian-Fei Zheng and Tian-Mei Li and Jian-Xun Zhang and Zhe-Nan Pang},
  doi          = {10.1016/j.neucom.2020.09.021},
  journal      = {Neurocomputing},
  pages        = {303-315},
  shortjournal = {Neurocomputing},
  title        = {An adaptive prognostics method for fusing CDBN and diffusion process: Application to bearing data},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021g). Differential evolution algorithm with multi-population
cooperation and multi-strategy integration. <em>NEUCOM</em>,
<em>421</em>, 285–302. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential evolution with a multi-population based ensemble of mutation strategies (MPEDE) has been considered among the most efficient Evolutionary Algorithms for global optimization. Our research results reveal that the performance of MPEDE may be improved by adding an information sharing mechanism and modifying the grouping mechanism . In MPEDE, the entire population is divided into four subpopulations, and most computing resources are allocated to the best strategy, but a better strategy has the same computing resources as the worst strategy. In order to rationally distribute computational resources, a differential evolution variant with multi-population cooperation and multi-strategy integration (MPMSDE) is proposed in this paper. MPMSDE develops a new grouping method instead of the grouping method in MPEDE, and the new grouping method utilizes the ranking of strategies to assign computational resources to different strategies. Also, an information sharing mechanism is introduced in the largest sub-population to avoid falling into local optimum. In MPMSDE, a new mutation strategy, “DE/pbad-to-pbest-to-gbest/1” , is used to replace the mutation strategy “DE/rand/1” in MPEDE. The new strategy not only uses personal history optimal solution and the worst solution but also uses the global best solution to update individuals. The new strategy can not only balance exploration and exploitation but also can accelerate the convergence of the algorithm. The performance of MPMSDE is compared with MPEDE and other state-of-the-art evolutionary algorithms on CEC2005 and CEC2014 benchmark functions . The experimental results show that the performance of the MPMSDE algorithm is very competitive in calculation accuracy and convergence speed.},
  archive      = {J_NEUCOM},
  author       = {Xiaoyu Li and Lei Wang and Qiaoyong Jiang and Ning Li},
  doi          = {10.1016/j.neucom.2020.09.007},
  journal      = {Neurocomputing},
  pages        = {285-302},
  shortjournal = {Neurocomputing},
  title        = {Differential evolution algorithm with multi-population cooperation and multi-strategy integration},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust feature matching via advanced neighborhood topology
consensus. <em>NEUCOM</em>, <em>421</em>, 273–284. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature matching is one of the key techniques in many vision-based tasks, which aims to establish reliable correspondences between two sets of features. In this paper, we present a new feature matching method, which formulates the matching of two feature sets as a mathematical model based on two common consistency constraints. We first propose an advanced consensus of neighborhood topology, which can better exploit the consensus of topological structures to identify inliers. In order to have reliable neighborhood information for the feature points, a subset with high percentage inliers obtained by a guided matching strategy from the putative matches for the neighborhood construction is used. We demonstrate the advantages of our proposed method on various real image pairs. The results demonstrate that the proposed method is superior to the state-of-the-art feature matching methods.},
  archive      = {J_NEUCOM},
  author       = {Yizhang Liu and Yanping Li and Luanyuan Dai and Changcai Yang and Lifang Wei and Taotao Lai and Riqing Chen},
  doi          = {10.1016/j.neucom.2020.09.047},
  journal      = {Neurocomputing},
  pages        = {273-284},
  shortjournal = {Neurocomputing},
  title        = {Robust feature matching via advanced neighborhood topology consensus},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Alzheimer’s disease classification using features extracted
from nonsubsampled contourlet subband-based individual networks.
<em>NEUCOM</em>, <em>421</em>, 260–272. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.012">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Morphological networks constructed with structural magnetic resonance imaging (sMRI) images have been widely investigated by exploring interregional alterations of different brain regions of interest (ROI) in the spatial domain for Alzheimer’s disease (AD) classification. However, few attentions are attracted to construct a subband-based individual network with the sMRI image in the frequency domain. In order to verify the feasibility of constructing individual networks with subbands and extract features from the subband-based individual network for AD classification, in this study, we propose a novel method to capture correlations of the abnormal energy distribution patterns related to AD by constructing nonsubsampled contourlet subband-based individual networks (NCSINs) in the frequency domain. Specifically, a 2-dimensional representation of the preprocessed sMRI image is firstly reshaped by downsampling and reconstruction steps. Then, the nonsubsampled contourlet transform is performed on the 2-dimensional representation to obtain directional subbands, and each directional subband at one scale is described by a column energy feature vector (CV) regarded as a node of the NCSIN. Subsequently, edge between any two nodes is weighted with connection strength (CS). Finally, the concatenation of node and edge features of the NCSINs at different scales is used as a network feature of the sMRI image for AD classification. Meanwhile, the support vector machine (SVM) classifier with a radial basis function (RBF) kernel is applied for categorizing 680 subjects from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database. Experimental results demonstrate that it is feasible to construct the subband-based individual network in the frequency domain and also show that our NCSIN method outperforms five other state-of-the-art approaches.},
  archive      = {J_NEUCOM},
  author       = {Jinwang Feng and Shao-Wu Zhang and Luonan Chen and Jie Xia and for the Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.neucom.2020.09.012},
  journal      = {Neurocomputing},
  pages        = {260-272},
  shortjournal = {Neurocomputing},
  title        = {Alzheimer’s disease classification using features extracted from nonsubsampled contourlet subband-based individual networks},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A diversified shared latent variable model for efficient
image characteristics extraction and modelling. <em>NEUCOM</em>,
<em>421</em>, 244–259. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.035">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An object can be consisting of various attributes, such as illuminance, appearance, shape, orientation, etc. Separately extract these attributes has enormous value in visual effects modeling, attribute-specific retrieval and recognition. Essentially, these attributes can be fairly abstract and thus need labels to extract. However, sometimes the labels of these attributes may not be available with training data. A solution to this problem is projecting the observed data into a lower dimension latent subspace, such that each observed data can be represented by a latent variable. After that, the dimensions of a latent variable can be segmented into different parts by weighting the kernel automatic relevance determination (ARD) parameters. Consequently, the latent variable is segmented into different parts each of which corresponds to the main attribute. In real life scenery, the attributes of an object may vary significantly from case to case. For instance, a single face can probably be under different illuminance conditions. Taking into account the diversity of these attribute variations, we propose the Diversified Shared Latent Variable Model (DSLVM) to extract and manipulate object attributes in an unsupervised way. More specifically, we initially set up two views that share the same latent variables. Then, two Diversity Encouraging (DE) priors are applied to the inducing points of each model view. Here, the inducing points are a small representative dataset that explains the observed data in its entirety. Meanwhile, the exploited diversity encouraging priors are able to cover more diverse characteristics of the attributes. The defined objective function is computed by variational inference. Extensive experiments on different datasets demonstrate that our method can accurately deal with various object.},
  archive      = {J_NEUCOM},
  author       = {Hao Xiong and Yuan Yan Tang and Fionn Murtagh and Leszek Rutkowski and Shlomo Berkovsky},
  doi          = {10.1016/j.neucom.2020.09.035},
  journal      = {Neurocomputing},
  pages        = {244-259},
  shortjournal = {Neurocomputing},
  title        = {A diversified shared latent variable model for efficient image characteristics extraction and modelling},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tri-domain pattern preserving sign prediction for signed
networks. <em>NEUCOM</em>, <em>421</em>, 234–243. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.004">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sign prediction in signed networks is one of the essential parts in signed networks data mining area. However, in most cases, sign information of links in signed networks is insufficient, so transfer learning is necessary to be an efficient tool to help us relieve this challenge. Many methods cannot leverage the knowledge in source domain adequately. Besides, they can hardly overcome the interference of noisy instances or unrelated instances which called negative transfer phenomenon. To decrease the negative transfer phenomenon in existing methods, a s ign p rediction model by T ri- D omain R elationship P attern (SP-TDRP) is proposed. TDRP selects an intermediate domain to be the bridge to transfer knowledge from source domains to the target domain. Then TDRP selects the interference instances and eliminates them to make the transferable knowledge more complete and purer. Thus, the sign classifier can be trained via transferable knowledge and predict the signs in the target domain. The considerable efficiency of SP-TDRP is evaluated on some realistic signed networks when compared with other state-of-the-art models.},
  archive      = {J_NEUCOM},
  author       = {Jiali Pang and Weiwei Yuan and Donghai Guan},
  doi          = {10.1016/j.neucom.2020.08.004},
  journal      = {Neurocomputing},
  pages        = {234-243},
  shortjournal = {Neurocomputing},
  title        = {Tri-domain pattern preserving sign prediction for signed networks},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Residual attention-based multi-scale script identification
in scene text images. <em>NEUCOM</em>, <em>421</em>, 222–233. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Script identification is an essential step in the text extraction pipeline for multi-lingual application. This paper presents an effective approach to identify scripts in scene text images. Due to the complicated background, various text styles, character similarity of different languages, script identification has not been solved yet. Under the general classification framework of script identification, we investigate two important components: feature extraction and classification layer. In the feature extraction, we utilize a hierarchical feature fusion block to extract the multi-scale features. Furthermore, we adopt an attention mechanism to obtain the local discriminative parts of feature maps. In the classification layer, we utilize a fully convolutional classifier to generate channel-level classifications which are then processed by a global pooling layer to improve classification efficiency. We evaluated the proposed approach on benchmark datasets of RRC-MLT2017, SIW-13, CVSI-2015 and MLe2e, and the experimental results show the effectiveness of each elaborate designed component. Finally, we achieve better performances than those competitive models, where the correct rates are 89.66\%, 96.11\%, 98.78\% and 97.20\% on PRC-MLT2017, SIW-13, CVSI-2015 and MLe2e, respectively.},
  archive      = {J_NEUCOM},
  author       = {Mengkai Ma and Qiu-Feng Wang and Shan Huang and Shen Huang and Yannis Goulermas and Kaizhu Huang},
  doi          = {10.1016/j.neucom.2020.09.015},
  journal      = {Neurocomputing},
  pages        = {222-233},
  shortjournal = {Neurocomputing},
  title        = {Residual attention-based multi-scale script identification in scene text images},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exploiting dependency information to improve biomedical
event detection via gated polar attention mechanism. <em>NEUCOM</em>,
<em>421</em>, 210–221. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper tackles the task of biomedical event detection, which includes identifying and categorizing biomedical event triggers. We find that the current biomedical event detection models driven by dependency fail to benefit more distinct improvement from the existing manual dependency embeddings. Here an interpretable hypothesis for the problem above is, that the model using manual dependency embeddings may suffer from low dependency information density (named as dependency weakness ) and diffusion of noises from sparse dependency items (called as sparsity diffusion ). We argue that dependency representation learning is more effective than the existing manual dependency embeddings, which can reduce dependency weakness and sparsity diffusion . In this work, we first confirm the hypothesis above and then propose to explicitly apply dependency representation learning and triple context representation learning for the biomedical event detection task via gated polar attention mechanism . In specific, we systematically investigate our model under the gated polar attention mechanism . Experimental results demonstrate that our approach outperforms the recent state-of-the-art methods and achieves the best F-score on the biomedical benchmark MLEE dataset.},
  archive      = {J_NEUCOM},
  author       = {Lishuang Li and Beibei Zhang},
  doi          = {10.1016/j.neucom.2020.09.020},
  journal      = {Neurocomputing},
  pages        = {210-221},
  shortjournal = {Neurocomputing},
  title        = {Exploiting dependency information to improve biomedical event detection via gated polar attention mechanism},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain tumor segmentation of multi-modality MR images via
triple intersecting u-nets. <em>NEUCOM</em>, <em>421</em>, 195–209. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a triple intersecting U-Nets (TIU-Nets) for brain glioma segmentation. First, the proposed TIU-Nets is composed of binary-class segmentation U-Net (BU-Net) and multi-class segmentation U-Net (MU-Net), in which MU-Net reuses multi-resolution features from BU-Net. Second, we introduce a segmentation soft-mask predicted by BU-Net, that is, candidate glioma region is generated by removing most of non-glioma backgrounds, which guides multi-category segmentation of MU-Net in a weighted manner. Third, an edge branch in MU-Net is leveraged to enhance boundary information of glioma substructure, which facilitates to locate glioma true boundaries and improve segmentation accuracy . Finally, we propose a sigmoid-evolution based polarized cross-entropy loss (S-CE) to resolve class unbalance problem, and apply S-CE loss to soft-mask prediction loss in BU-Net, multi-class segmentation loss in MU-Net and edge prediction loss in edge branch. Experimental results have demonstrated that the proposed 2D/3D TIU-Nets achieves a higher segmentation accuracy than corresponding 2D/3D state-of-the-art segmentation methods including FCN, U-Net, SegNet, CRDN, IVD-Net, FCDenseNet, DeepMedic, DMFNet, etc, evaluating on publicly available brain tumor segmentation challenge 2015 (BRATS2015) datasets. To show the universality of the proposed method, we also give a comparison of segmentation performance on BrainWeb dataset.},
  archive      = {J_NEUCOM},
  author       = {Jinjing Zhang and Jianchao Zeng and Pinle Qin and Lijun Zhao},
  doi          = {10.1016/j.neucom.2020.09.016},
  journal      = {Neurocomputing},
  pages        = {195-209},
  shortjournal = {Neurocomputing},
  title        = {Brain tumor segmentation of multi-modality MR images via triple intersecting U-nets},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal stealthy switching location attacks against remote
estimation in cyber-physical systems. <em>NEUCOM</em>, <em>421</em>,
183–194. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the design of the optimal stealthy switching location attacks in cyber-physical systems with multi-channels. By introducing the Kullback–Leibler divergence to characterize the stealthiness, an attack strategy with the energy constraint is proposed, which is only able to modify a part of the channels at each time step. Under the proposed attacks, the terminal estimation error is analyzed by utilizing the statistical characteristics of the innovations. And then, different from the DoS attack scheduling problems in the related works, the optimal attack strategy is derived by solving a constrained optimization problem and a 0–1 programming problem, which maximizes the remote estimation error and keeps deceptive simultaneously. Finally, the results are illustrated via the simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Yi-Gang Li and Guang-Hong Yang},
  doi          = {10.1016/j.neucom.2020.08.007},
  journal      = {Neurocomputing},
  pages        = {183-194},
  shortjournal = {Neurocomputing},
  title        = {Optimal stealthy switching location attacks against remote estimation in cyber-physical systems},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). An empirical study of multi-scale object detection in high
resolution UAV images. <em>NEUCOM</em>, <em>421</em>, 173–182. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Object detection in images collected by Unmanned Aerial Vehicles (UAVs) constitutes a challenging task in computer vision, due to difficulties of learning a well-trained object detection model for handling instances in UAV images with arbitrary orientations, variation in different scales, irregular shapes, etc. In order to facilitate object detection research and extend its applications in natural scenarios by using UAVs, this paper presents a large-scale benchmark dataset, MOHR, aiming at performing multi-scale object detection in UAV images with high resolution. A total of 90,014 object instances with labels and bounding boxes were annotated. In order to build a baseline for object detection on the MOHR dataset, we performed an empirical study by evaluating six state-of-the-art deep learning-based object detection models trained on our proposed dataset. Experimental results show promising detection performance, but also demonstrate that the dataset is quite challenging for adopting natural image-based object detection models for UAV images.},
  archive      = {J_NEUCOM},
  author       = {Haijun Zhang and Mingshan Sun and Qun Li and Linlin Liu and Ming Liu and Yuzhu Ji},
  doi          = {10.1016/j.neucom.2020.08.074},
  journal      = {Neurocomputing},
  pages        = {173-182},
  shortjournal = {Neurocomputing},
  title        = {An empirical study of multi-scale object detection in high resolution UAV images},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive NN control for nonlinear systems with uncertainty
based on dynamic surface control. <em>NEUCOM</em>, <em>421</em>,
161–172. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of adaptive neural network (NN) control and the dynamic surface control (DSC) method for a series of nonlinear systems with uncertainty is discussed in this paper. Unknown smooth functions can be approximated by radial basis function-neural networks (RBF-NNs) with arbitrary accuracy in nonlinear systems . The DSC scheme is introduced for nonlinear systems with uncertainty to overcome the “explosion of complexity” compared with the conventional backstepping approach. Meanwhile, the global asymptotic stability of nonlinear systems is manifested via the Lyapunov stability theory , which indicates the uniform boundedness of all closed-loop signals is ensured and dynamic surface errors are arbitrarily small in the compact set by selecting proper parameters. Finally, the effectiveness of the proposed control technique is validated by two simulation examples.},
  archive      = {J_NEUCOM},
  author       = {Zhiyong Zhou and Dongbing Tong and Qiaoyu Chen and Wuneng Zhou and Yuhua Xu},
  doi          = {10.1016/j.neucom.2020.09.026},
  journal      = {Neurocomputing},
  pages        = {161-172},
  shortjournal = {Neurocomputing},
  title        = {Adaptive NN control for nonlinear systems with uncertainty based on dynamic surface control},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Learning efficient multi-task stereo matching network with
richer feature information. <em>NEUCOM</em>, <em>421</em>, 151–160. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate depth estimation is a research hotspot in the field of stereo vision . The accuracy of stereo matching algorithm directly determines the quality of depth map. Recent researches have transformed stereo matching methods into a supervised learning task. However, the previous methods may have mismatches in the regions of non-textures, boundaries and tiny details. In this paper, we propose a multi-task attention stereo network (MASNet) to integrate the feature information from a stereo image pairs for disparity estimation. Firstly, a segmentation attention head module (SAH) is proposed, which adds semantic segmentation clues for disparity estimation, uses global receptive field to guide network feature extraction learning refined features, and alleviates the negative impact of depth addition of the network. Secondly, we construct a multiple cost volume (MCV) to make full use of the aggregation ability of 3D convolution and provide a better similarity measures for disparity estimation. Thirdly, we embed Top-k pooling layer into the 3D CNN module to obtain the reduced aggregation feature. The feature is fed into the proposed shallow merging network and fused with the intermediate feature to obtain richer low-level features and make up for the comprehensiveness of network neck feature. The results of experiment on Scene Flow, KITTI 2012, and KITTI 2015 datasets show that our proposed network has a significant superiority over state-of-art stereo matching methods.},
  archive      = {J_NEUCOM},
  author       = {Jie Wang and Sunjie Zhang and Yongxiong Wang and Zhengyu Zhu},
  doi          = {10.1016/j.neucom.2020.08.010},
  journal      = {Neurocomputing},
  pages        = {151-160},
  shortjournal = {Neurocomputing},
  title        = {Learning efficient multi-task stereo matching network with richer feature information},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MGRL: Graph neural network based inference in a markov
network with reinforcement learning for visual navigation.
<em>NEUCOM</em>, <em>421</em>, 140–150. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.091">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual navigation is an essential task for indoor robots and usually uses the map as assistance to providing global information for the agent. Because the traditional maps match the environments, the map-based and map-building-based navigation methods are limited in the new environments for obtaining maps. Although the deep reinforcement learning navigation method, utilizing the non-map-based navigation technique, achieves satisfactory performance, it lacks the interpretability and the global view of the environment. Therefore, we propose a novel abstract map for the deep reinforcement learning navigation method with better global relative position information and more reasonable interpretability . The abstract map is modeled as a Markov network which is used for explicitly representing the regularity of objects arrangement, influenced by people activities in different environments. Besides, a knowledge graph is utilized to initialize the structure of the Markov network , as providing the prior structure for the model and reducing the difficulty of model learning. Then, a graph neural network is adopted for probability inference in the Markov network. Furthermore, the update of the abstract map, including the knowledge graph structure and the parameters of the graph neural network , are combined into an end-to-end learning process trained by a reinforcement learning method. Finally, experiments in the AI2THOR framework and the physical environment indicate that our algorithm greatly improves the success rate of navigation in case of new environments, thus confirming the good generalization.},
  archive      = {J_NEUCOM},
  author       = {Yi Lu and Yaran Chen and Dongbin Zhao and Dong Li},
  doi          = {10.1016/j.neucom.2020.07.091},
  journal      = {Neurocomputing},
  pages        = {140-150},
  shortjournal = {Neurocomputing},
  title        = {MGRL: Graph neural network based inference in a markov network with reinforcement learning for visual navigation},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MLDH-fold: Protein fold recognition based on multi-view
low-rank modeling. <em>NEUCOM</em>, <em>421</em>, 127–139. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Protein fold recognition is critical for understanding the molecular functions of proteins and drug design. Computational predictors have been proposed to identify protein into one of the known folds based only on the protein sequence information. However, how to combine different features to improve predictive performance remains a challenging problem. In this study, two novel methods (MVLR and MLDH-Fold) were proposed for protein fold recognition. We proposed a novel multi-view learning framework to combine the different views of protein sequences. Each view represents the similarity scores between the target sequences and template sequences calculated by the threading method. The proposed method extracts the low-rank principal features to precisely represent the similarity scores of each view and constructs the latent subspace with the common information of different views to predict the target proteins. Furthermore, we proposed an ensemble method called MLDH-Fold to combine the MVLR with the template-based methods. Predictive results on the two widely used datasets (LE and YK) show that the proposed computational methods outperform other computational predictors, indicating that the MVLR and MLDH-Fold are useful tools for protein fold recognition.},
  archive      = {J_NEUCOM},
  author       = {Ke Yan and Jie Wen and Yong Xu and Bin Liu},
  doi          = {10.1016/j.neucom.2020.09.028},
  journal      = {Neurocomputing},
  pages        = {127-139},
  shortjournal = {Neurocomputing},
  title        = {MLDH-fold: Protein fold recognition based on multi-view low-rank modeling},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Atrous convolutional feature network for weakly supervised
semantic segmentation. <em>NEUCOM</em>, <em>421</em>, 115–126. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Weakly supervised semantic segmentation has been attracting increasing attention as it can alleviate the need for expensive pixel-level annotations through the use of image-level labels. Relevant methods mainly rely on the implicit object localization ability of convolutional neural networks (CNNs). However, generated object attention maps remain mostly small and incomplete. In this paper, we propose an Atrous Convolutional Feature Network (ACFN) to generate dense object attention maps. This is achieved by enhancing the context representation of image classification CNNs. More specifically, cascaded atrous convolutions are used in the middle layers to retain sufficient spatial details , and pyramidal atrous convolutions are used in the last convolutional layers to provide multi-scale context information for the extraction of object attention maps. Moreover, we propose an attentive fusion strategy to adaptively fuse the multi-scale features. Our method shows improvements over existing methods on both the PASCAL VOC 2012 and MS COCO datasets, achieving state-of-the-art performance.},
  archive      = {J_NEUCOM},
  author       = {Lian Xu and Hao Xue and Mohammed Bennamoun and Farid Boussaid and Ferdous Sohel},
  doi          = {10.1016/j.neucom.2020.09.045},
  journal      = {Neurocomputing},
  pages        = {115-126},
  shortjournal = {Neurocomputing},
  title        = {Atrous convolutional feature network for weakly supervised semantic segmentation},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AIRec: Attentive intersection model for tag-aware
recommendation. <em>NEUCOM</em>, <em>421</em>, 105–114. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.018">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tag-aware recommender systems (TRS) utilize rich tagging information to better depict user portraits and item features. Recently, many efforts have been done to improve TRS with neural networks . However, existing methods construct user representations through either explicit tagging behaviors or implicit interacted items, which is inadequate to capture multi-aspect user preferences. Besides, there are still lacks of investigation about the intersection between user and item tags, which is crucial for better recommendation. In this paper, we propose AIRec, an attentive intersection model for TRS, to address the above issues. More precisely, we first project the sparse tag vectors into a latent space through multi-layer perceptron (MLP). Then, the user representations are constructed with a hierarchical attention network , where the item-level attention differentiates the contributions of interacted items and the preference-level attention discriminates the saliencies between explicit and implicit preferences. After that, the intersection between user and item tags is exploited to enhance the learning of conjunct features. Finally, the user and item representations are concatenated and fed to factorization machines (FM) for score prediction. We conduct extensive experiments on two real-world datasets, demonstrating significant improvements of AIRec over state-of-the-art methods for tag-aware top-n recommendation.},
  archive      = {J_NEUCOM},
  author       = {Bo Chen and Yue Ding and Xin Xin and Yunzhe Li and Yule Wang and Dong Wang},
  doi          = {10.1016/j.neucom.2020.08.018},
  journal      = {Neurocomputing},
  pages        = {105-114},
  shortjournal = {Neurocomputing},
  title        = {AIRec: Attentive intersection model for tag-aware recommendation},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic event-triggered h∞ state estimation for delayed
complex networks with randomly occurring nonlinearities.
<em>NEUCOM</em>, <em>421</em>, 97–104. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.048">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper aims to iron out the dynamic event-triggered (ET) H ∞ H∞ state estimation issue for a class of discrete time-delay complex networks (CNs) with randomly occurring nonlinearities (RONs). In the signal transmission among the nodes, the effect of time-varying delays is examined. The RONs under consideration is modelled by a series of random variables obeying Bernoulli distribution . In the design of state estimators , a dynamic ET scheme is utilized with the hope of improving the energy utilization efficiency. A sufficient condition is first derived to ensure the exponential mean-square (EMS) stability and H ∞ H∞ performance index of the estimation error systems. Then, by using the matrix inequality technology, the desired state estimators are designed. Lastly, a numerical simulation example is given to show the usefulness of the proposed estimator design algorithm .},
  archive      = {J_NEUCOM},
  author       = {Nan Li and Qi Li and Jinghui Suo},
  doi          = {10.1016/j.neucom.2020.08.048},
  journal      = {Neurocomputing},
  pages        = {97-104},
  shortjournal = {Neurocomputing},
  title        = {Dynamic event-triggered h∞ state estimation for delayed complex networks with randomly occurring nonlinearities},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interacting t-s fuzzy semantic model estimation for
maneuvering target tracking. <em>NEUCOM</em>, <em>421</em>, 84–96. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes an interacting Takagi–Sugeno(T-S) fuzzy semantic model estimator (ITS-FSM) for maneuvering target tracking, and constructs a framework for a generic interacting T-S fuzzy semantic model to incorporate semantic information concerning the target. To adaptively calculate the transition probability matrix of the models, a probabilistic switching model based on semantic fuzzy sets is derived by using the degree of intersection between fuzzy sets, which enables switching from one semantic fuzzy set to another. We also propose an efficient kernel maximum entropy fuzzy clustering method to identify the premise parameters of the model. This enables the proposed algorithm to recursively estimate the premise parameters in case of a limited number of samples. Moreover, a modified extended forgetting factor recursive least squares (MEFRLS) estimator is used to identify the parameters of the T-S fuzzy semantic model. The results of experiments on three simulation datasets show that the proposed ITS-FSM algorithm is efficient, and is excellent at handling non-Gaussian noise.},
  archive      = {J_NEUCOM},
  author       = {Liang-Qun Li and Xi-yang Zhan and Wei-Xin Xie and Zong-Xiang Liu},
  doi          = {10.1016/j.neucom.2020.08.067},
  journal      = {Neurocomputing},
  pages        = {84-96},
  shortjournal = {Neurocomputing},
  title        = {Interacting T-S fuzzy semantic model estimation for maneuvering target tracking},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Autonomous cognition development with lifelong learning: A
self-organizing and reflecting cognitive network. <em>NEUCOM</em>,
<em>421</em>, 66–83. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lifelong learning is still a great challenge for cognitive robots since the continuous streaming data they encounter is usually enormous and no-stationary. Traditional cognitive methods suffer from large storage and computation consumption in this situation. Therefore, we propose a self-organizing and reflecting cognitive network (SORCN) to realize robotic lifelong cognitive development through incremental learning and regular reflecting. The network integrates a self-organizing incremental neural network (SOINN) with a modified CFS clustering algorithm . SOINN develops concise object concepts to alleviate storage consumption. Moreover, we modify SOINN by an efficient competitive method based on reflection results to reduce the learning computation. The modified CFS clustering algorithm is designed for reflecting knowledge learned by SOINN periodically. It improves the traditional CFS as a three-step clustering method including clustering, merging and splitting. Specifically, an autonomous center selection strategy is employed for CFS to cater to online learning. Moreover, a series of cluster merging and splitting strategies are proposed to enable CFS to cluster data incrementally and improve its clustering effect. Additionally, the reflection results are utilized to adjust the topological structure of SOINN and guide the future learning. Experimental results demonstrate that SORCN can achieve better learning effectiveness and efficiency over several state-of-art algorithms.},
  archive      = {J_NEUCOM},
  author       = {Ke Huang and Xin Ma and Rui Song and Xuewen Rong and Yibin Li},
  doi          = {10.1016/j.neucom.2020.09.027},
  journal      = {Neurocomputing},
  pages        = {66-83},
  shortjournal = {Neurocomputing},
  title        = {Autonomous cognition development with lifelong learning: A self-organizing and reflecting cognitive network},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Multi-scale and single-scale fully convolutional networks
for sound event detection. <em>NEUCOM</em>, <em>421</em>, 51–65. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.038">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among various Sound Event Detection (SED) systems, Recurrent Neural Networks (RNN), such as long short-term memory unit and gated recurrent unit , is used to capture temporal dependencies, but it is confined in its length of temporal dependencies, resulting in a failure to model sound events with long duration. What’s more, RNN is incapable to process datasets in parallel, leading to low efficiency and low industrial value. Given these shortcomings, we propose to use dilated convolution (and causal dilated convolution) to capture temporal dependencies, as its great ability to ensure high time resolution and obtain longer temporal dependencies under the filter size and the network depth unchanged. In addition, dilated convolution can be parallelized, so it has higher efficiency and industrial value. Based on this, we propose Single-Scale Fully Convolutional Networks (SS-FCN) composed of convolutional neural networks and dilated convolutional networks, with the former to provide frequency invariance and the later to capture temporal dependencies. With the help of dilated convolution to control the length of temporal dependencies, we observe SS-FCN modeling a single length of temporal dependencies achieves superior detection performance for finite kinds of events. For better performance, we propose Multi-Scale Fully Convolutional Networks (MS-FCN), in which the feature fusion module is introduced to capture long short-term dependencies by fusing features with different length of temporal dependencies. The proposed methods achieve competitive performance on three main datasets with higher efficiency. The results show that SED systems based on Fully Convolutional Networks have further research value and potential.},
  archive      = {J_NEUCOM},
  author       = {Yingbin Wang and Guanghui Zhao and Kai Xiong and Guangming Shi and Yumeng Zhang},
  doi          = {10.1016/j.neucom.2020.09.038},
  journal      = {Neurocomputing},
  pages        = {51-65},
  shortjournal = {Neurocomputing},
  title        = {Multi-scale and single-scale fully convolutional networks for sound event detection},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Zero-watermarking method for resisting rotation attacks in
3D models. <em>NEUCOM</em>, <em>421</em>, 39–50. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is challenging to relocate the embedded positions of the watermark when 3D models are subjected to rotation attacks, because the vertex data of 3D models has no implicit order. This paper proposes a zero-watermarking scheme for 3D models, using the Beamlet transform method. First, the area of the 1-ring neighbourhood of each vertex is calculated. Then, the 1-ring neighbourhoods of the vertices with moderate areas are projected onto the tangent planes; the X- axis of each tangent plane corresponds to the mesh line with the maximum curvature in the 1-ring neighbourhood. The Beamlet dictionary is constructed by recording the line segments on both sides of the X -axis; thus, a zero-watermarking image which protects the copyright of the model is produced. Simulations and experiments show that the proposed watermarking scheme exhibits a robust resistance to common signal-processing attacks, especially rotation attacks, and can protect the copyrights of 3D models reliably without distorting the content in any manner.},
  archive      = {J_NEUCOM},
  author       = {Gang Liu and Quan Wang and Lianqin Wu and Rong Pan and Bo Wan and Yumin Tian},
  doi          = {10.1016/j.neucom.2020.09.013},
  journal      = {Neurocomputing},
  pages        = {39-50},
  shortjournal = {Neurocomputing},
  title        = {Zero-watermarking method for resisting rotation attacks in 3D models},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021c). Deep unsupervised multi-modal fusion network for detecting
driver distraction. <em>NEUCOM</em>, <em>421</em>, 26–38. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The risk of incurring a road traffic crash has increased year by year. Studies show that lack of attention during driving is one of the major causes of traffic accidents. In this work, in order to detect driver distraction, e.g., phone conversation, eating, texting, we introduce a deep unsupervised multi-modal fusion network, termed UMMFN. It is an end-to-end model composing of three main modules: multi-modal representation learning, multi-scale feature fusion and unsupervised driver distraction detection. The first module is to learn low-dimensional representation of multiple heterogeneous sensors using embedding subnetworks . The goal of multi-scale feature fusion is to learn both the temporal dependency for each modality and spatio dependencies from different modalities. The last module utilizes a ConvLSTM Encoder-Decoder model to perform an unsupervised classification task that is not affected by new types of driver behaviors. During the detection phase, a fine-grained detection decision can be made through calculating reconstruction error of UMMFN as a score for each captured testing data. We empirically compare the proposed approach with several state-of-the-art methods on our own multi-modal dataset for distracted driving behavior. Experimental results show that UMMFN has superior performance over the existing approaches.},
  archive      = {J_NEUCOM},
  author       = {Yuxin Zhang and Yiqiang Chen and Chenlong Gao},
  doi          = {10.1016/j.neucom.2020.09.023},
  journal      = {Neurocomputing},
  pages        = {26-38},
  shortjournal = {Neurocomputing},
  title        = {Deep unsupervised multi-modal fusion network for detecting driver distraction},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Weakly and semi supervised detection in medical imaging via
deep dual branch net. <em>NEUCOM</em>, <em>421</em>, 15–25. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.037">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study presents a novel deep learning architecture for multi-class classification and localization of abnormalities in medical imaging illustrated through experiments on mammograms. The proposed network combines two learning branches. One branch is for region classification with a newly added normal-region class. Second branch is region detection branch for ranking regions relative to one another. Our method enables detection of abnormalities at full mammogram resolution for both weakly and semi-supervised settings. A novel objective function allows for the incorporation of local annotations into the model. We present the impact of our schemes on several performance measures for classification and localization, to evaluate the cost effectiveness of the lesion annotation effort. Our evaluation was primarily conducted over a large multi-center mammography dataset of ~ ~ 3,000 mammograms with various findings. The results for weakly supervised learning showed significant improvement compared to previous approaches. We show that the time consuming local annotations involved in supervised learning can be addressed by a weakly supervised method that can leverage a subset of locally annotated data. Weakly and semi-supervised methods coupled with detection can produce a cost effective and explainable model to be adopted by radiologists in the field.},
  archive      = {J_NEUCOM},
  author       = {Ran Bakalo and Jacob Goldberger and Rami Ben-Ari},
  doi          = {10.1016/j.neucom.2020.09.037},
  journal      = {Neurocomputing},
  pages        = {15-25},
  shortjournal = {Neurocomputing},
  title        = {Weakly and semi supervised detection in medical imaging via deep dual branch net},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A review on transfer learning in EEG signal analysis.
<em>NEUCOM</em>, <em>421</em>, 1–14. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electroencephalogram (EEG) signal analysis, which is widely used for human-computer interaction and neurological disease diagnosis, requires a large amount of labeled data for training. However, the collection of substantial EEG data could be difficult owing to its randomness and non-stationary. Moreover, there is notable individual difference in EEG data, which affects the reusability and generalization of models. For mitigating the adverse effects from the above factors, transfer learning is applied in this field to transfer the knowledge learnt in one domain into a different but related domain. Transfer learning adjusts models with small-scale data of the task, and also maintains the learning ability with individual difference. This paper describes four main methods of transfer learning and explores their practical applications in EEG signal analysis in recent years. Finally, we discuss challenges and opportunities of transfer learning and suggest areas for further study.},
  archive      = {J_NEUCOM},
  author       = {Zitong Wan and Rui Yang and Mengjie Huang and Nianyin Zeng and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2020.09.017},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {A review on transfer learning in EEG signal analysis},
  volume       = {421},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Finite-time synchronization of stochastic complex networks
with random coupling delay via quantized aperiodically intermittent
control. <em>NEUCOM</em>, <em>420</em>, 337–348. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.103">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper studies the finite-time synchronization issue of stochastic complex networks (SCNs) with random coupling delay and nonlinear coupling function. Internal delay, perturbation delay are also considered into this model. Meanwhile, a quantized aperiodically intermittent control strategy is proposed to realize finite-time synchronization of SCNs. By means of Lyapunov stability theory and graph theory, two types of sufficient conditions are derived to ensure finite-time synchronization of SCNs. The obtained results are closely related to the maximum proportion of rest width and the topological structure of considered networks. Moreover, the theoretical results is applied to study finite-time synchronization of stochastic coupled oscillators. Finally, a numerical example is presented to demonstrate the effectiveness and feasibility of the obtained results.},
  archive      = {J_NEUCOM},
  author       = {Yue Ren and Haijun Jiang and Jiarong Li and Binglong Lu},
  doi          = {10.1016/j.neucom.2020.05.103},
  journal      = {Neurocomputing},
  pages        = {337-348},
  shortjournal = {Neurocomputing},
  title        = {Finite-time synchronization of stochastic complex networks with random coupling delay via quantized aperiodically intermittent control},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Lag quasi-synchronization for periodic neural networks with
unreliable redundant communication channels. <em>NEUCOM</em>,
<em>420</em>, 329–336. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work studies lag quasi-synchronization (LQS) for discrete-time master–slave (MS) periodic neural networks (NNs) with the communication channel (CC) constraint. A logarithmic quantizer is used to overcome the CC constraint, and a redundant CC is introduced to transmit more information to improve the system performance. Two independent bernoulli processes are considered to model the packet dropouts of the main and the redundant CCs, respectively. A sufficient condition, ensuring LQS of MS NNs, is achieved, which also gives the boundary of the LQS error. Finally, a controller is designed on the basis of the obtained sufficient condition and the derived result is proved by a numerical example.},
  archive      = {J_NEUCOM},
  author       = {Hongxia Rao and Hui Chen and Zebing Huang and Zenghong Huang and Yuru Guo},
  doi          = {10.1016/j.neucom.2020.07.097},
  journal      = {Neurocomputing},
  pages        = {329-336},
  shortjournal = {Neurocomputing},
  title        = {Lag quasi-synchronization for periodic neural networks with unreliable redundant communication channels},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Dual-CNN based multi-modal sleep scoring with temporal
correlation driven fine-tuning. <em>NEUCOM</em>, <em>420</em>, 317–328.
(<a href="https://doi.org/10.1016/j.neucom.2020.08.020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Examination of dysfunctional brain dynamics often needs to tackle the difficulties of analyzing neural data of multiple modalities as recordings from a single source (such as EEG) do not always suffice in characterizing the brain states of interest. A typical example is sleep scoring from Polysomnography (PSG) for evaluation of sleep disorder, which has long been an onerous task and constantly results in unstable performance. Despite numerous successes achieved by the deep learning technologies recently booming along this direction, a grand challenge still remains: how to enable a stable solution to characterize the sleep stages (brain states) with temporal correlations embedded in the multi-modal recordings mainly from the brain activities without the support of sufficient a priori knowledge of the subjects. Aiming at the challenge, this study develops a deep learning framework for multi-modal sleep scoring. The framework uses a “dual-CNN” to simultaneously process inputs of two forms, i.e., temporal or time–frequency. The inputs of each branch may either consist of organized epochs of multiple modalities or their time–frequency representations. The fused deep features of the original multi-modal dataset will then be derived. The correlation of the original consecutive epochs embedded in the deep features can be reinforced through an RNN layer to aid classification with the final results fine-tuned by a customized Markov chain model, which considers the temporal correlations embedded in the deep features to amortize the potential bias resulted from the imbalance of brain states represented by the features. A case study of sleep scoring has been performed against a public Sleep-EDF dataset. Experimental results indicate that 1) the multi-modal features generated by the dual-CNN model help in significantly improve the accuracy of neural data classification; 2) the overall framework outperforms the state-of-the-art counterparts with an accuracy of 84.9\% achieved in sleep scoring.},
  archive      = {J_NEUCOM},
  author       = {Lei Zhang and Dan Chen and Peilu Chen and Weiguang Li and Xiaoli Li},
  doi          = {10.1016/j.neucom.2020.08.020},
  journal      = {Neurocomputing},
  pages        = {317-328},
  shortjournal = {Neurocomputing},
  title        = {Dual-CNN based multi-modal sleep scoring with temporal correlation driven fine-tuning},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distributed learning machines for solving forward and
inverse problems in partial differential equations. <em>NEUCOM</em>,
<em>420</em>, 299–316. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.006">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We conceptualize Distributed Learning Machines (DLMs) – a novel machine learning approach that integrates existing machine learning algorithms with traditional mesh-based numerical methods for solving forward and inverse problems in nonlinear partial differential equations (PDEs). In conventional numerical methods such as finite element method (FEM), the discretization of the computational domain is a standard technique to reduce the representation load of basis functions. Along the same lines, we propose a distributed neural network architecture that facilitates the simultaneous deployment of several localized neural networks to solve PDEs in a unified manner. The most critical requirement of the DLMs is the synchronization of the distributed neural networks. For this, we introduce a new physics-based interface regularization term to the cost function of the existing learning machines like the Physics Informed Neural Network (PINN) and the Physics Informed Extreme Learning Machine (PIELM). To evaluate the efficacy of this approach, we develop three distinct variants of DLM namely, time-marching Distributed PIELM (DPIELM), Distributed PINN (DPINN) and time-marching DPINN. We show that ideas of linearization and time-marching allow DPIELM to be able to solve nonlinear PDEs to some extent. Next, we show that DPINNs have potential advantages over existing PINNs to solve the inverse problems in heterogeneous media. Finally, we propose a rapid, time-marching version of DPINN which leverages the ideas of transfer learning to accelerate the training. Collectively, this framework leads towards the promise of hybrid Neural Network-FVM or Neural Network-FEM schemes in the future.},
  archive      = {J_NEUCOM},
  author       = {Vikas Dwivedi and Nishant Parashar and Balaji Srinivasan},
  doi          = {10.1016/j.neucom.2020.09.006},
  journal      = {Neurocomputing},
  pages        = {299-316},
  shortjournal = {Neurocomputing},
  title        = {Distributed learning machines for solving forward and inverse problems in partial differential equations},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Global exponential synchronization of interval neural
networks with mixed delays via delayed impulsive control.
<em>NEUCOM</em>, <em>420</em>, 290–298. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.010">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the synchronization problem of interval neural networks with both time-varying and unbounded distributed delays under delayed impulsive control. A new impulsive differential inequality which considers the effect of time delays in impulses is proposed. Based on the inequality, several synchronization criteria for interval neural networks are derived by employing impulsive control theory and inequality techniques. Finally, a numerical example with simulation results is provided to show the validity of the conclusions.},
  archive      = {J_NEUCOM},
  author       = {Yao Wang and Yujuan Tian and Xiaodi Li},
  doi          = {10.1016/j.neucom.2020.09.010},
  journal      = {Neurocomputing},
  pages        = {290-298},
  shortjournal = {Neurocomputing},
  title        = {Global exponential synchronization of interval neural networks with mixed delays via delayed impulsive control},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Domanial and dimensional adversarial learning for emotion
regression. <em>NEUCOM</em>, <em>420</em>, 281–289. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address cross-domain multi-dimensional emotion regression through adversarial learning. This is done via a proper conduction of both dimensional and domanial adversarial learning. On the one hand, we conduct adversarial learning between emotion dimensions via a dimensional discriminator to achieve dimension-specific features through the attention mechanism for better determining dimensional emotion scores. On the other hand, we conduct adversarial learning between the target domain and multiple source domains via a domanial discriminator for better leveraging texts from source domains for regression model training in the target domain. Empirical evaluation on the EMOBANK corpus shows that our proposed approach achieves notable improvements in r -values in the cross-domain multi-dimensional emotion regression task over the state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Suyang Zhu and Shoushan Li and Guodong Zhou},
  doi          = {10.1016/j.neucom.2020.09.036},
  journal      = {Neurocomputing},
  pages        = {281-289},
  shortjournal = {Neurocomputing},
  title        = {Domanial and dimensional adversarial learning for emotion regression},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). MonuMAI: Dataset, deep learning pipeline and citizen science
based app for monumental heritage taxonomy and classification.
<em>NEUCOM</em>, <em>420</em>, 266–280. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.041">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important part of art history can be discovered through the visual information in monument facades. However, the analysis of this visual information, i.e, morphology and architectural elements , requires high expert knowledge. An automatic system for identifying the architectural style or detecting the architectural elements of a monument based on one image will certainly help improving our knowledge in art and history. Building such tool is challenging as some styles share architectural elements, the bad conservation state of some monuments and the noise included in the image itself. The aim of this paper is to introduce MonuMAI (Monument with Mathematics and Artificial Intelligence) framework. In particular, (i) we designed MonuMAI dataset rich with expert knowledge considering the proposed architectural styles taxonomy and key elements relationship, which allows addressing several tasks, e.g., monument style classification and architectural elements detection, (ii) we developed MonuMAI deep learning pipeline based on lightweight MonuNet architecture for monument style classification and MonuMAI Key Elements Detection (MonuMAI-KED) model, and (iii) we built citizen science based MonuMAI mobile app that uses the proposed MonuMAI deep learning pipeline trained on MonuMAI dataset for performing in real life conditions. Our experiments show that both MonuNet architecture and the detection model achieve very good results under real life conditions.},
  archive      = {J_NEUCOM},
  author       = {Alberto Lamas and Siham Tabik and Policarpo Cruz and Rosana Montes and Álvaro Martínez-Sevilla and Teresa Cruz and Francisco Herrera},
  doi          = {10.1016/j.neucom.2020.09.041},
  journal      = {Neurocomputing},
  pages        = {266-280},
  shortjournal = {Neurocomputing},
  title        = {MonuMAI: Dataset, deep learning pipeline and citizen science based app for monumental heritage taxonomy and classification},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Research on historical phase division of terrorism: An
analysis method by time series complex network. <em>NEUCOM</em>,
<em>420</em>, 246–265. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.125">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anti-terrorism research is an important academic topic in current societies. The crucial features of attacked incidents can be obtained effectively by identifying phase division of terrorism history. To handle time-series issues, complex networks theories are efficient and reliable analysis solutions. Therefore, we propose an original community detection method for complex time-series networks. Especially, we consider the improved local density operator and bi-directional neighbor retrieval (ILD-BNR). First, complex networks of threatened countries are established by incidents feature and time-series principles. Then, cores of networks are selected by improved density operator. After that, attributes of unstable nodes are revised iteratively until initialization is finished. The optimal classification results are obtained by retrieval pattern of bi-directional neighbor. Finally, on the basis of clustering consequences, historical phases are divided ultimately. The mechanism of each phase is discussed simultaneously. The experiments demonstrate some important conclusions: a) The accuracy of proposed method is better than other evaluated algorithms on real time-series networks; b) The historical phase number is reduced reasonably, which is beneficial to analysis of information; and c) Classification consequences can reflect the historical tendency of terrorism.},
  archive      = {J_NEUCOM},
  author       = {Hong-Hai Qiao and Zheng-Hong Deng and Hui-Jia Li and Jun Hu and Qun Song and Li Gao},
  doi          = {10.1016/j.neucom.2020.07.125},
  journal      = {Neurocomputing},
  pages        = {246-265},
  shortjournal = {Neurocomputing},
  title        = {Research on historical phase division of terrorism: An analysis method by time series complex network},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Unsupervised learning based coordinated multi-task
allocation for unmanned surface vehicles. <em>NEUCOM</em>, <em>420</em>,
227–245. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent decades, unmanned surface vehicles (USVs) are attracting increasing attention due to their underlying capability in autonomously undertaking complex maritime tasks in constrained environments. However, the autonomy level of USVs is still limited, especially when being deployed to conduct multiple tasks simultaneously. This paper, therefore, aims to improve USVs autonomy level by investigating and developing an effective and efficient task management algorithm for multi-USV systems. To better deal with challenging requirements such as allocating vast tasks in cluttered environments, the task management has been de-composed into two submissions, i.e., task allocation and task execution. More specifically, unsupervised learning strategies have been used with an improved K-means algorithm proposed to first assign different tasks for a multi-USV system then a self-organising map (SOM) been implemented to deal with the task execution problem based upon the assigned tasks for each USV. Differing to other work, the communication problem that is crucial for USVs in a constrained environment has been specifically resolved by designing a new competition strategy for K-means algorithm. Key factors that will influence the communication capability in practical applications have been taken into account. A holistic task management architecture has been designed by integrating both the task allocation and task execution algorithms, and a number of simulations in both simulated and practical maritime environments have been carried out to validate the effectiveness of the proposed algorithms.},
  archive      = {J_NEUCOM},
  author       = {Song Ma and Weihong Guo and Rui Song and Yuanchang Liu},
  doi          = {10.1016/j.neucom.2020.09.031},
  journal      = {Neurocomputing},
  pages        = {227-245},
  shortjournal = {Neurocomputing},
  title        = {Unsupervised learning based coordinated multi-task allocation for unmanned surface vehicles},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural coupled central pattern generator based smooth gait
transition of a biomimetic hexapod robot. <em>NEUCOM</em>, <em>420</em>,
210–226. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.114">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a novel Central Pattern Generator (CPG) network topology based locomotion control strategy for a smooth gait transition of a biomimetic hexapod robot is proposed. Some preliminaries and correlations have been discussed to provide more suitable CPG network topology for both gait patterns that adapt to different environments, both in terms of transient state time and amplitude overshoot. The design network structure is developed with bidirectional diffusive coupling topologies to obtain robustness and efficient gait transitions. The stability of the proposed network is proved using coupling analyses. In contrast to conventional methods in the CPG network, the proposed method provides remarkable results that could generate four typical hexapod gaits transitions under rapid transient-state and steady-state conditions depending on the frequency, amplitude, and phase relationships among neurons. In order to govern the swing and stance phases according to the proposed network, the leg trajectory generator is designed and an inverse kinematics module is added to compute the link angles of the legs. By applying the proposed locomotion control strategy, the hexapod robot is capable of performing stable and rapid walking gaits. The simulation and experimental results show the effectiveness of the proposed method. High motion ability with the proposed network topology is provided considering walking frequency, forward speed, gait transition time, transient-state time, and steady-state comparisons with the literature.},
  archive      = {J_NEUCOM},
  author       = {Cafer Bal},
  doi          = {10.1016/j.neucom.2020.07.114},
  journal      = {Neurocomputing},
  pages        = {210-226},
  shortjournal = {Neurocomputing},
  title        = {Neural coupled central pattern generator based smooth gait transition of a biomimetic hexapod robot},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sub-optimal tracking in switched systems with fixed final
time and fixed mode sequence using reinforcement learning.
<em>NEUCOM</em>, <em>420</em>, 197–209. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximate dynamic programming is used to solve optimal tracking problems in switched systems with controlled subsystems and fixed mode sequence. Two feedback control solutions are generated such that the system tracks a desired reference signal, and the optimal switching instants are sought. Simulation results are provided to illustrate the effectiveness of the solutions.},
  archive      = {J_NEUCOM},
  author       = {Tohid Sardarmehni and Xingyong Song},
  doi          = {10.1016/j.neucom.2020.09.011},
  journal      = {Neurocomputing},
  pages        = {197-209},
  shortjournal = {Neurocomputing},
  title        = {Sub-optimal tracking in switched systems with fixed final time and fixed mode sequence using reinforcement learning},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interactive POS-aware network for aspect-level sentiment
classification. <em>NEUCOM</em>, <em>420</em>, 181–196. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.013">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing aspect-level sentiment-classification models completely rely on the learning from given datasets. However, these are easily misled by biased samples, resulting in learning some ill-suited rules that limit their potential. The information of some specific part-of-speech (POS) categories often indicates the word sentiment polarity, which can be introduced as prior knowledge to facilitate prediction of the model. Accordingly, we propose an interactive POS-aware network (IPAN) that explicitly introduces the POS information as reliable guidance to assist the model in accurately predicting sentiment polarity. We distinguish the information of different POS categories using a POS-filter gate and reinforce the features extracted from adjectives, adverbs, and verbs via a POS-highlighting attention mechanism . This enables the model to concentrate on the words that contain significant sentiment orientations and to obtain the most practical learning experience . To emphasize the target information, we construct a target-context gate that enables the interaction of the target information with contexts; consequently, the model considerably focuses on target-related sentiment features. The experiments on SemEval2014 and Twitter datasets verify that our IPAN consistently outperforms the current state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Kai Shuang and Mengyu Gu and Rui Li and Jonathan Loo and Sen Su},
  doi          = {10.1016/j.neucom.2020.08.013},
  journal      = {Neurocomputing},
  pages        = {181-196},
  shortjournal = {Neurocomputing},
  title        = {Interactive POS-aware network for aspect-level sentiment classification},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An intelligent diagnosis framework for roller bearing fault
under speed fluctuation condition. <em>NEUCOM</em>, <em>420</em>,
171–180. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Rotating speed fluctuation is a key problem that affects the fault diagnosis performance of mechanical equipment. Deep learning theory can use deep neural networks to realize automatic feature extraction and classification, but the existing methods always have defects in computational efficiency and diagnosis error on dealing with this problem. In this paper, combined with the advantages of deep learning, an intelligent fault diagnosis method is proposed to deal with the speed fluctuation problem. Firstly, sparse filtering is employed as a basic framework to construct the deep neural networks for feature extraction. Then, batch normalization is added to each layer to solve the frequency shift and amplitude variation properties of speed fluctuation signals. Finally, softmax regression is used as a classifier in the last layer of the deep neural networks. Two specially designed roller bearing experiments under speed fluctuation condition are adopted to verify the effectiveness of the proposed batch normalized deep sparse filtering method. The results show that the proposed method can completely ignore the influence of speed fluctuation and achieve accurate identification of different fault types, and obtain a higher accuracy than other methods.},
  archive      = {J_NEUCOM},
  author       = {Baokun Han and Shanshan Ji and Jinrui Wang and Huaiqian Bao and Xingxing Jiang},
  doi          = {10.1016/j.neucom.2020.09.022},
  journal      = {Neurocomputing},
  pages        = {171-180},
  shortjournal = {Neurocomputing},
  title        = {An intelligent diagnosis framework for roller bearing fault under speed fluctuation condition},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Graph-based reasoning model for multiple relation
extraction. <em>NEUCOM</em>, <em>420</em>, 162–170. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linguistic knowledge is useful for various NLP tasks, but the difficulty lies in the representation and application. We consider that linguistic knowledge is implied in a large-scale corpus, while classification knowledge, the knowledge related to the definitions of entity and relation types, is implied in the labeled training data. Therefore, a corpus subgraph is proposed to mine more linguistic knowledge from the easily accessible unlabeled data , and sentence subgraphs are used to acquire classification knowledge. They jointly constitute a relation knowledge graph (RKG) to extract relations from sentences in this paper. On RKG, entity recognition can be regarded as a property value filling problem and relation classification can be regarded as a link prediction problem. Thus, the multiple relation extraction can be treated as a reasoning process for knowledge completion. We combine statistical reasoning and neural network reasoning to segment sentences into entity chunks and non-entity chunks, then propose a novel Chunk Graph LSTM network to learn the representations of entity chunks and infer the relations among them. The experiments on two standard datasets demonstrate our model outperforms the previous models for multiple relation extraction.},
  archive      = {J_NEUCOM},
  author       = {Heyan Huang and Ming Lei and Chong Feng},
  doi          = {10.1016/j.neucom.2020.09.025},
  journal      = {Neurocomputing},
  pages        = {162-170},
  shortjournal = {Neurocomputing},
  title        = {Graph-based reasoning model for multiple relation extraction},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Revisiting paraphrase question generator using pairwise
discriminator. <em>NEUCOM</em>, <em>420</em>, 149–161. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose a method for obtaining sentence-level embeddings. While the problem of obtaining word-level embeddings is very well studied, we propose a novel method for obtaining sentence-level embeddings. This is obtained by a simple method in the context of solving the paraphrase generation task. If we use a sequential encoder-decoder model for generating paraphrase, we would like the generated paraphrase to be semantically close to the original sentence. One way to ensure this is by adding constraints for true paraphrase embeddings to be close and unrelated paraphrase candidate sentence embeddings to be far. This is ensured by using a sequential pair-wise discriminator that shares weights with the encoder. This discriminator is trained with a suitable loss function. Our loss function penalizes paraphrase sentence embedding distances from being too large. This loss is used in combination with a sequential encoder-decoder network. We also validate our method by evaluating the obtained embeddings for a sentiment analysis task. The proposed method results in semantic embeddings and provide competitive results on the paraphrase generation and sentiment analysis task on standard dataset. These results are also shown to be statistically significant.},
  archive      = {J_NEUCOM},
  author       = {Badri N. Patro and Dev Chauhan and Vinod K. Kurmi and Vinay P. Namboodiri},
  doi          = {10.1016/j.neucom.2020.08.022},
  journal      = {Neurocomputing},
  pages        = {149-161},
  shortjournal = {Neurocomputing},
  title        = {Revisiting paraphrase question generator using pairwise discriminator},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Infrared small target detection via self-regularized
weighted sparse model. <em>NEUCOM</em>, <em>420</em>, 124–148. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Infrared search and track (IRST) system is widely used in many fields, however, it’s still a challenging task to detect infrared small targets in complex background. This paper proposed a novel detection method called self-regularized weighted sparse (SRWS) model. The algorithm is designed for the hypothesis that data may come from multi-subspaces. And the overlapping edge information (OEI), which can detect the background structure information, is applied to constrain the sparse item and enhance the accuracy. Furthermore, the self-regularization item is applied to mine the potential information in background, and extract clutter from multi-subspaces. Therefore, the infrared small target detection problem is transformed into an optimization problem . By combining the optimization function with alternating direction method of multipliers (ADMM), we explained the solution method of SRWS and optimized its iterative convergence condition. A series of experimental results show that the proposed method outperforms state-of-the-art baselines.},
  archive      = {J_NEUCOM},
  author       = {Tianfang Zhang and Zhenming Peng and Hao Wu and Yanmin He and Chaohai Li and Chunping Yang},
  doi          = {10.1016/j.neucom.2020.08.065},
  journal      = {Neurocomputing},
  pages        = {124-148},
  shortjournal = {Neurocomputing},
  title        = {Infrared small target detection via self-regularized weighted sparse model},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Observer-based distributed consensus for multi-agent systems
with directed networks and input saturation. <em>NEUCOM</em>,
<em>420</em>, 111–123. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we devise a distributed protocol to study the consensus of multi-agent systems (MASs) with input saturation over directed networks. Firstly, a low-gain feedback control method is applied to overcome the saturation constraints, and an observation system without saturation constraints is designed. The semiglobal consensus condition over directed strongly connected networks is developed by using Ricatti equation. Secondly, a novel of tree-type error scheme is proposed to solve the consensus of MASs with general directed spanning tree networks. Combination with inequality techniques and Lyapunov stability theory , some criteria for achieving semiglobal consensus are obtained. In addition, the semiglobal consensus of MASs with directed switching networks is further considered, in which the network topologies only need to contain a directed spanning tree in some time intervals. Some related conditions are derived to ensure the consensus. Finally, some numerical simulations are given to demonstrate the validity of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Shuzhen Yu and Zhiyong Yu and Haijun Jiang and Xuehui Mei},
  doi          = {10.1016/j.neucom.2020.09.003},
  journal      = {Neurocomputing},
  pages        = {111-123},
  shortjournal = {Neurocomputing},
  title        = {Observer-based distributed consensus for multi-agent systems with directed networks and input saturation},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). A new method of data missing estimation with FNN-based
tensor heterogeneous ensemble learning for internet of vehicle.
<em>NEUCOM</em>, <em>420</em>, 98–110. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.042">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Vehicles (IoV) can obtain traffic information through a large number of data collected by sensors. However, the lack of data, abnormal data, and other low-quality problems have seriously restricted the development and application of the IoV. To solve the problem of missing data in a large-scale road network, the previous research achievements show that tensor decomposition method has the advantages in solving multi-dimensional data imputation problems, so we adopt this tensor mode to model traffic velocity data. A new method of data missing estimation with tensor heterogeneous ensemble learning based on FNN (Fuzzy Neural Network) named FNNTEL is proposed in this paper. The performance of this method is evaluated by our experiments and analysis. The proposed method is applied to be tested by the real data captured in Guangzhou and Tianjin of China respectively. A large number of experimental tests show that the performance of the new method is better than other commonly used technologies and different missing data generation models.},
  archive      = {J_NEUCOM},
  author       = {Ting Zhang and De-gan Zhang and Hao-ran Yan and Jian-ning Qiu and Jin-xin Gao},
  doi          = {10.1016/j.neucom.2020.09.042},
  journal      = {Neurocomputing},
  pages        = {98-110},
  shortjournal = {Neurocomputing},
  title        = {A new method of data missing estimation with FNN-based tensor heterogeneous ensemble learning for internet of vehicle},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neuroadaptive fault-tolerant control of state constrained
pure-feedback systems: A collective backstepping design.
<em>NEUCOM</em>, <em>420</em>, 90–97. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we present a neuroadaptive and fault-tolerant tracking control scheme for uncertain nonlinear pure-feedback systems in the presence of time-varying and asymmetric full state constraints and unanticipated actuation failures. Instead of using multi-step recursive backstepping design, we employ a one-step approach for control development. By introducing a nonlinear coordinate transformation, we convert the original nonlinear system with asymmetrical state constraints into a new augmented one free from state constraints, which allows for the complete obviation of the feasibility conditions in the strategy. Furthermore, by making use of the feature from skew symmetric matrix in the augmented system, we develop the neural adaptive control algorithms collectively without the need for repetitive design procedure, in which only one Lyapunov function and one step derivation are involved, leading to a design approach whose synthesis complexity does not increase with the order of the system.},
  archive      = {J_NEUCOM},
  author       = {Shuyan Zhou and Yongduan Song},
  doi          = {10.1016/j.neucom.2020.07.096},
  journal      = {Neurocomputing},
  pages        = {90-97},
  shortjournal = {Neurocomputing},
  title        = {Neuroadaptive fault-tolerant control of state constrained pure-feedback systems: A collective backstepping design},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Flounder-net: An efficient CNN for crowd counting by aerial
photography. <em>NEUCOM</em>, <em>420</em>, 82–89. (<a
href="https://doi.org/10.1016/j.neucom.2020.09.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd counting on aerial images using the embedded system is a challenging task, due to high-definition images, low computing power, and limited memory. To tackle this task, we propose an efficient deep learning model named Flounder-Net structured like a flounder. In the Flounder-Net, a novel interleaved group convolution is proposed to eliminate the redundancy of network, and a rapid shrink of feature maps is employed to tackle the high-resolution problem. Since we would like to investigate the case of online aerial surveillance, we use the embedded system of a drone to run our algorithm. We also use the vision system of this drone to collect a set of high-definition aerial photographs as a benchmark. Extensive experiments on existing datasets and our aerial dataset show that Flounder-Net achieves FCN-level accuracy with three types of photograph devices: handheld cameras, surveillance cameras, and drone-based cameras. Additionally, Flounder-Net has 17 × × fewer parameters and 20 × × faster speed than FCN and allows an input image with arbitrary sizes.},
  archive      = {J_NEUCOM},
  author       = {Jingyu Chen and Shengjie Xiu and Xiang Chen and Hao Guo and Xiaohua Xie},
  doi          = {10.1016/j.neucom.2020.09.001},
  journal      = {Neurocomputing},
  pages        = {82-89},
  shortjournal = {Neurocomputing},
  title        = {Flounder-net: An efficient CNN for crowd counting by aerial photography},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust stability of fractional-order quaternion-valued
neural networks with neutral delays and parameter uncertainties.
<em>NEUCOM</em>, <em>420</em>, 70–81. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.059">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the robust stability analysis of fractional-order quaternion-valued neural networks (FOQVNNs) with neutral delay and parameter uncertainties. Without transforming the FOQVNNs into equivalent two complex-valued systems or four real-valued systems, based on homeomorphism principle, matrix inequality technique and Lyapunov method, both delay-independent and delay-dependent criteria to guarantee the existence, uniqueness and global stability of equilibrium point for the considered FOQVNNs are derived in the form of linear matrix inequality (LMI). Two examples with simulations are provided to manifest the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Qiankun Song and Yanxi Chen and Zhenjiang Zhao and Yurong Liu and Fuad E. Alsaadi},
  doi          = {10.1016/j.neucom.2020.08.059},
  journal      = {Neurocomputing},
  pages        = {70-81},
  shortjournal = {Neurocomputing},
  title        = {Robust stability of fractional-order quaternion-valued neural networks with neutral delays and parameter uncertainties},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Image restoration using overlapping group sparsity on
hyper-laplacian prior of image gradient. <em>NEUCOM</em>, <em>420</em>,
57–69. (<a href="https://doi.org/10.1016/j.neucom.2020.08.053">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the ill-posed nature of image restoration, seeking a meaningful image prior is still a great challenge in the field of image processing . The total variation with overlapping group sparsity (OGS-TV) has been successfully applied for image denoising/deblurring. In this paper, we further study the overlapping group sparsity of the image gradient. The sparsity is measured by the ℓ q ℓq quasi-norm ( 0 0&amp;lt;q&amp;lt;1 ). The proposed regularizer comes down to the well-known hyper-Laplacian prior if the overlapping group size is 1. Although it seems to be a simple extensive study compared with the previous works, its regularization capability and corresponding mathematical problems are still in demand for imaging science. To solve the non-convex and non-smooth minimization problem , we use the alternating direction method of multipliers as the main algorithm framework. The difficult inner subproblem is tackled by the majorization-minimization method with the sophisticatedly derived majorizer. We carry out some numerical experiments to demonstrate the effectiveness of the proposed regularizer in terms of PSNR and SSIM values.},
  archive      = {J_NEUCOM},
  author       = {Kyongson Jon and Ying Sun and Qixin Li and Jun Liu and Xiaofei Wang and Wensheng Zhu},
  doi          = {10.1016/j.neucom.2020.08.053},
  journal      = {Neurocomputing},
  pages        = {57-69},
  shortjournal = {Neurocomputing},
  title        = {Image restoration using overlapping group sparsity on hyper-laplacian prior of image gradient},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PALO bounds for reinforcement learning in partially
observable stochastic games. <em>NEUCOM</em>, <em>420</em>, 36–56. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.054">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A partially observable stochastic game (POSG) is a general model for multiagent decision making under uncertainty. Perkins’ Monte Carlo exploring starts for partially observable Markov decision process (POMDP) (MCES-P) integrates Monte Carlo exploring starts (MCES) into a local search of the policy space to offer an elegant template for model-free reinforcement learning in POSGs. However, multiagent reinforcement learning in POSGs is tremendously more complex than in single agent settings due to the heterogeneity of agents and discrepancy of their goals. In this article, we generalize reinforcement learning under partial observability to self-interested and cooperative multiagent settings under the POSG umbrella. We present three new templates for multiagent reinforcement learning in POSGs. MCES for interactive POMDP (MCESIP) extends MCES-P by maintaining predictions of the other agent’s actions based on dynamic beliefs over models. MCES for multiagent POMDP (MCES-MP) generalizes MCES-P to the canonical multiagent POMDP framework, with a single policy mapping joint observations of all agents to joint actions. Finally, MCES for factored-reward multiagent POMDP (MCES-FMP) has each agent individually mapping joint observations to their own action. We use probabilistic approximate locally optimal (PALO) bounds to analyze sample complexity, thereby instantiating these templates to PALO learning. We promote sample efficiency by including a policy space pruning technique and evaluate the approaches on six benchmark domains as well as compare with the state-of-the-art techniques, which demonstrates that MCES-IP and MCES-FMP yield improved policies with fewer samples compared to the previous baselines.},
  archive      = {J_NEUCOM},
  author       = {Roi Ceren and Keyang He and Prashant Doshi and Bikramjit Banerjee},
  doi          = {10.1016/j.neucom.2020.08.054},
  journal      = {Neurocomputing},
  pages        = {36-56},
  shortjournal = {Neurocomputing},
  title        = {PALO bounds for reinforcement learning in partially observable stochastic games},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning from class-imbalance and heterogeneous data for
30-day hospital readmission. <em>NEUCOM</em>, <em>420</em>, 27–35. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Predicting 30-day hospital readmission is a core research task in the development of personalized healthcare. However, the imbalanced class distribution and the heterogeneity of electronic health records are the major challenges to establish an effective machine learning model for this task. To overcome these issues, we propose a new 30-day readmission prediction algorithm to improve the performance. First, we solve the problem of class-imbalance readmission prediction by learning sample weights based on hypothesis margin loss. At the same time, we consider the character of data heterogeneity , and learn the weights of heterogeneous data sources to improve the generalization ability . Based on this, we construct an optimization framework, which involves two variables, i.e., sample weights and source weights. By iterative optimization, we obtain the prediction result for readmission. Finally, we conduct experiments on three real-world readmission datasets to verify the effectiveness of the proposed method. The experimental results show that the proposed algorithm has the advantages to deal with the task of 30-day hospital readmission prediction.},
  archive      = {J_NEUCOM},
  author       = {Guodong Du and Jia Zhang and Shaozi Li and Candong Li},
  doi          = {10.1016/j.neucom.2020.08.064},
  journal      = {Neurocomputing},
  pages        = {27-35},
  shortjournal = {Neurocomputing},
  title        = {Learning from class-imbalance and heterogeneous data for 30-day hospital readmission},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving neural machine translation with sentence alignment
learning. <em>NEUCOM</em>, <em>420</em>, 15–26. (<a
href="https://doi.org/10.1016/j.neucom.2020.05.104">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural machine translation (NMT) optimized by maximum likelihood estimation (MLE) usually lacks the guarantee of translation adequacy. To alleviate this problem, we propose an NMT approach that heightens the adequacy in machine translation by transferring the semantic knowledge from bilingual sentence alignment learning. Specifically, we first design a discriminator that learns to estimate sentence aligning score over translation candidates. The discriminator is constructed by gated self-attention based sentence encoders and trained with an N -pair loss for better capturing lexical evidences from bilingual sentence pairs. Then we propose an adversarial training framework as well as a sentence alignment-aware decoding method for NMT to transfer the discriminator’s learned semantic knowledge to NMT models . We conduct our experiments on Chinese → → English, Uyghur → → Chinese and English → → German translation tasks. Experimental results show that our proposed methods outperform baseline NMT models on all these three translation tasks. Further analysis also indicates the characteristics of our approaches and details the semantic knowledge that transfered from the discriminator to the NMT model.},
  archive      = {J_NEUCOM},
  author       = {Xuewen Shi and Heyan Huang and Ping Jian and Yi-Kun Tang},
  doi          = {10.1016/j.neucom.2020.05.104},
  journal      = {Neurocomputing},
  pages        = {15-26},
  shortjournal = {Neurocomputing},
  title        = {Improving neural machine translation with sentence alignment learning},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neural network-based hybrid force/position control of
constrained reconfigurable manipulators. <em>NEUCOM</em>, <em>420</em>,
1–14. (<a href="https://doi.org/10.1016/j.neucom.2020.09.009">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This manuscript addresses the neural network-based hybrid force/position control scheme for the force and position control problem of constrained reconfigurable manipulators. The uncertainties in the dynamical model of the system are inevitable; therefore the model-based control approach is inadequate to handle these systems. Motivated by this, the authors have proposed a new hybrid control scheme for constrained reconfigurable manipulators by utilizing the available partial information about system dynamics together with the model-free approach. The inefficiency of the model-based control scheme is enhanced by using the approximation capability of the neural network. Radial basis function neural network estimates the unknown dynamics of the system. To overcome the aftereffects of neural network reconstruction error as well as the effects of friction terms and external disturbances, an adaptive compensator is added to the part of the controller. The online adaptive laws for the neural network weights and the parameter vector are used in the Lyapunov function to guarantee the system to be stable. As a result, position and force tracking errors boundedness are achieved and tracking error of the joints in all the directions converge to zero asymptotically. Finally, numerical simulation results are produced over a 2-DOF constrained reconfigurable manipulator to show the supremacy and robustness of the proposed approach in a comparative manner.},
  archive      = {J_NEUCOM},
  author       = {Naveen Kumar and Manju Rani},
  doi          = {10.1016/j.neucom.2020.09.009},
  journal      = {Neurocomputing},
  pages        = {1-14},
  shortjournal = {Neurocomputing},
  title        = {Neural network-based hybrid force/position control of constrained reconfigurable manipulators},
  volume       = {420},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The correlation-based tucker decomposition for hyperspectral
image compression. <em>NEUCOM</em>, <em>419</em>, 357–370. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.073">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tucker decomposition (TD) is widely used in hyperspectral image (HSI) processing. Generally, the performance of TD-based method depends on the core tensor and factor matrices, while the construction of core tensor and factor matrices is still a research topic. We give the detailed discussion about the correlation and performance of TD-based methods in this paper. Since TD is solved by singular value decomposition (SVD), the construction of core tensor and factor matrices should be determined by the distribution of singular energy of each mode-n matricization. Depending on the discussion, we propose a correlation-based Tucker decomposition (CBTD) method to construct the core tensor and factor matrices. As a general method, this proposed CBTD can be employed in any TD-based method of N th Nth -order tensor. The analysis on real HSI data verifies our conclusion about correlation and good performance of CBTD. Besides, the proposed CBTD method has better ability to improve the performance of HSI compression than other state-of-the-art methods.},
  archive      = {J_NEUCOM},
  author       = {Rui Li and Zhibin Pan and Yang Wang and Ping Wang},
  doi          = {10.1016/j.neucom.2020.08.073},
  journal      = {Neurocomputing},
  pages        = {357-370},
  shortjournal = {Neurocomputing},
  title        = {The correlation-based tucker decomposition for hyperspectral image compression},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). A multi-task learning model for chinese-oriented aspect
polarity classification and aspect term extraction. <em>NEUCOM</em>,
<em>419</em>, 344–356. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-based sentiment analysis (ABSA) task is a fine-grained task of natural language processing and consists of two subtasks: aspect term extraction (ATE) and aspect polarity classification (APC). Most of the related works merely focus on the subtask of Chinese aspect term polarity inferring and fail to emphasize the research of Chinese-oriented ABSA multi-task learning. Based on the local context focus (LCF) mechanism, this paper firstly proposes a multi-task learning model for Chinese-oriented aspect-based sentiment analysis, namely LCF-ATEPC. Compared with other models, this model equips the capability of extracting aspect term and inferring aspect term polarity synchronously. The experimental results on four Chinese review datasets outperform state-of-the-art performance on the ATE and APC subtask. And by integrating the domain-adapted BERT model, LCF-ATEPC achieves the state-of-the-art performance of ATE and APC in the most commonly used SemEval-2014 task4 Restaurant and Laptop datasets. Moreover, this model is effective to analyze both Chinese and English reviews collaboratively and the experimental results on a multilingual mixed dataset prove its effectiveness.},
  archive      = {J_NEUCOM},
  author       = {Heng Yang and Biqing Zeng and Jianhao Yang and Youwei Song and Ruyang Xu},
  doi          = {10.1016/j.neucom.2020.08.001},
  journal      = {Neurocomputing},
  pages        = {344-356},
  shortjournal = {Neurocomputing},
  title        = {A multi-task learning model for chinese-oriented aspect polarity classification and aspect term extraction},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). DEGAN: Decentralized generative adversarial networks.
<em>NEUCOM</em>, <em>419</em>, 335–343. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose a distributed and decentralized Generative Adversarial Networks (GANs) framework without the exchange of the training data. Each node contains local dataset, a discriminator and a generator, from which only the generator gradients are shared with other nodes. In this paper, we introduce a novel, distributed technique in which workers communicate directly with each other, having no central nodes. Our experimental results on the benchmark datasets demonstrate almost the same performance and accuracy compared with existing centralized GAN frameworks. The proposed framework addresses the lack of decentralized learning for GANs.},
  archive      = {J_NEUCOM},
  author       = {Mohammad Hashem Faezi and Shahriar Bijani and Ardeshir Dolati},
  doi          = {10.1016/j.neucom.2020.07.089},
  journal      = {Neurocomputing},
  pages        = {335-343},
  shortjournal = {Neurocomputing},
  title        = {DEGAN: Decentralized generative adversarial networks},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). RGSR: A two-step lossy JPG image super-resolution based on
noise reduction. <em>NEUCOM</em>, <em>419</em>, 322–334. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.056">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Single Image Super-Resolution (SISR) is a fundamental and important low-level computer vision (CV) task, yet its performance on real-world applications is not always satisfactory. Different from the previous SISR research, we focus on a specific but realistic SR issue: How can we obtain satisfied SR results from compressed JPG (C-JPG) images, which is a ubiquitous image format to greatly release storage space while missing fine details. the JPG SR task is deeply analyzed to discover the connotation. Then, we propose an effective two-step model structure named RGSR, involving two specifically designed components, i.e., JPG recovering and SR generation, instead of the perspective of noise elimination in traditional SR approaches. Besides, we further integrate the cycle loss to build a hybrid objective across scales for better SR generation. Experimental results on both of the standard test data sets and real images show that our approach achieves outstanding results and succeed in applying to practical C-JPG SR tasks.},
  archive      = {J_NEUCOM},
  author       = {Biao Li and Yong Shi and Bo Wang and Zhiquan Qi and Jiabin Liu},
  doi          = {10.1016/j.neucom.2020.08.056},
  journal      = {Neurocomputing},
  pages        = {322-334},
  shortjournal = {Neurocomputing},
  title        = {RGSR: A two-step lossy JPG image super-resolution based on noise reduction},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An adaptive locally connected neuron model: Focusing neuron.
<em>NEUCOM</em>, <em>419</em>, 306–321. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.008">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a new artificial neuron model capable of learning its receptive field in the topological domain of inputs. The experiments include tests of focusing neuron networks of one or two hidden layers on synthetic and well-known image recognition data sets. The results demonstrated that the focusing neurons can move their receptive fields towards more informative inputs. In the simple two-hidden layer networks, the focusing layers outperformed the dense layers in the classification of the 2D spatial data sets. Moreover, the focusing networks performed better than the dense networks even when 70\%\% of the weights were pruned. The tests on convolutional networks revealed that using focusing layers instead of dense layers for the classification of convolutional features may work better in some data sets.},
  archive      = {J_NEUCOM},
  author       = {F. Boray Tek},
  doi          = {10.1016/j.neucom.2020.08.008},
  journal      = {Neurocomputing},
  pages        = {306-321},
  shortjournal = {Neurocomputing},
  title        = {An adaptive locally connected neuron model: Focusing neuron},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Bipartite consensus for multi-agent systems with noises over
markovian switching topologies. <em>NEUCOM</em>, <em>419</em>, 295–305.
(<a href="https://doi.org/10.1016/j.neucom.2020.08.005">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we investigate the distributed control problem for multi-agent systems (MASs) subject to multiplicative and additive noises over switching networks, where both cooperative and antagonistic interactions coexist. The communication topology is governed by a continuous-time Markovian chain. A stochastic approximation technique is utilized to handle stochastic bipartite consensus with communication noises. The major challenge, due to the fact that the intensity of the multiplicative noise is nonlinearly coupled with the distance between agents, is that the coexistence of antagonistic information and multiplicative noise makes the multiplicative noise term impossible to be converted into an error form. This leads to the inapplicability of the Lyapunov-based method. To cope with this, we first show the boundedness of agents’ states where the second moment approach is employed. Based on it, the mean square and almost surely bipartite consensus are achieved under some mild requirements. The efficiency of the proposed method is supported by an example.},
  archive      = {J_NEUCOM},
  author       = {Yingxue Du and Yijing Wang and Zhiqiang Zuo},
  doi          = {10.1016/j.neucom.2020.08.005},
  journal      = {Neurocomputing},
  pages        = {295-305},
  shortjournal = {Neurocomputing},
  title        = {Bipartite consensus for multi-agent systems with noises over markovian switching topologies},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An optimally weighted user- and item-based collaborative
filtering approach to predicting baseline data for friedreich’s ataxia
patients. <em>NEUCOM</em>, <em>419</em>, 287–294. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a modified collaborative filtering (MCF) algorithm with improved performance is developed for recommendation systems with application in predicting baseline data of Friedreich’s Ataxia (FRDA) patients. The proposed MCF algorithm combines the individual merits of both the user-based collaborative filtering (UBCF) method and the item-based collaborative filtering (IBCF) method, where both the positively and negatively correlated neighbors are taken into account. The weighting parameters are introduced to quantify the degrees of utilizations of the UBCF and IBCF methods in the rating prediction, and the particle swarm optimization algorithm is applied to optimize the weighting parameters in order to achieve an adequate tradeoff between the positively and negatively correlated neighbors in terms of predicting the rating values. To demonstrate the prediction performance of the proposed MCF algorithm, the developed MCF algorithm is employed to assist with the baseline data collection for the FRDA patients. The effectiveness of the proposed MCF algorithm is confirmed by extensive experiments and, furthermore, it is shown that our algorithm outperforms some conventional approaches.},
  archive      = {J_NEUCOM},
  author       = {Wenbin Yue and Zidong Wang and Weibo Liu and Bo Tian and Stanislao Lauria and Xiaohui Liu},
  doi          = {10.1016/j.neucom.2020.08.031},
  journal      = {Neurocomputing},
  pages        = {287-294},
  shortjournal = {Neurocomputing},
  title        = {An optimally weighted user- and item-based collaborative filtering approach to predicting baseline data for friedreich’s ataxia patients},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021e). MemoryPath: A deep reinforcement learning framework for
incorporating memory component into knowledge graph reasoning.
<em>NEUCOM</em>, <em>419</em>, 273–286. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.032">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Knowledge Graph (KG) is identified as a major area in artificial intelligence , which is used for many real-world applications. The task of knowledge graph reasoning has been widely used and proven to be effective, which aims to find these reasonable paths for various relations to solve the issue of incompleteness in KGs. However, many previous works on KG reasoning, such as path-based or reinforcement learning-based methods, are too reliant on the pre-training , where the paths from the head entity and the target entity must be given to pre-train the model, which would easily lead the model to overfit on the given paths seen in the pre-training. To address this issue, we propose a novel reasoning model named MemoryPath with a deep reinforcement learning framework, which incorporates Long Short Term Memory (LSTM) and graph attention mechanism to form the memory component. The well-designed memory component can get rid of the pre-training so that the model doesn’t depend on the given target entity for training. A tailored mechanism of reinforcement learning is presented in this proposed deep reinforcement framework to optimize the training procedure, where two metrics, Mean Selection Rate (MSR) and Mean Alternative Rate (MAR), are defined to quantitatively measure the complexities of the query relations. Meanwhile, three different training mechanisms, Action Dropout, Reward Shaping and Force Forward, are proposed to optimize the training process of the proposed MemoryPath. The proposed MemoryPath is validated on two datasets from FB15K-237 and NELL-995 on different tasks including fact prediction, link prediction and success rate in finding paths. The experimental results demonstrate that the tailored mechanism of reinforcement learning make the MemoryPath achieves state-of-the-art performance comparing with the other models. Also, the qualitative analysis indicates that the MemoryPath can store the learning process and automatically find the promising paths for a reasoning task during the training, and shows the effectiveness of the memory component.},
  archive      = {J_NEUCOM},
  author       = {Shuangyin Li and Heng Wang and Rong Pan and Mingzhi Mao},
  doi          = {10.1016/j.neucom.2020.08.032},
  journal      = {Neurocomputing},
  pages        = {273-286},
  shortjournal = {Neurocomputing},
  title        = {MemoryPath: A deep reinforcement learning framework for incorporating memory component into knowledge graph reasoning},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Delay-dependent criteria for periodicity and exponential
stability of inertial neural networks with time-varying delays.
<em>NEUCOM</em>, <em>419</em>, 261–272. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.046">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper mainly studies the periodicity and exponential stability for a class of inertial neural networks (INNs) with time-varying delays. Without utilizing standard reduced-order transformation, by using the continuation theorem and Cauchy–Schwarz inequality, delay-dependent criteria shown by some algebraic inequalities are derived to ensure the existence of periodic solutions. Furthermore, by means of the fundamental inequality and constructing a modified delay-dependent Lyapunov functional, global exponential stability analysis is obtained based on the derived delay-dependent criteria. In comparison with the reduced order approach applied to the INNs and delay-independent criteria provided for the INNs in the existed literatures, the results obtained in this paper are new. Finally, numerical simulations are carried out to verify the main results.},
  archive      = {J_NEUCOM},
  author       = {Fanchao Kong and Yong Ren and Rathinasamy Sakthivel},
  doi          = {10.1016/j.neucom.2020.08.046},
  journal      = {Neurocomputing},
  pages        = {261-272},
  shortjournal = {Neurocomputing},
  title        = {Delay-dependent criteria for periodicity and exponential stability of inertial neural networks with time-varying delays},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Neurocomputing guest editorial for the special issue:
Advances in deep and shallow machine learning approaches for handling
data irregularities. <em>NEUCOM</em>, <em>419</em>, 259–260. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.082">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_NEUCOM},
  author       = {Swagatam Das and Salvador Garcia and Isaac Triguero},
  doi          = {10.1016/j.neucom.2020.07.082},
  journal      = {Neurocomputing},
  pages        = {259-260},
  shortjournal = {Neurocomputing},
  title        = {Neurocomputing guest editorial for the special issue: Advances in deep and shallow machine learning approaches for handling data irregularities},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Time-varying schur decomposition via zhang neural dynamics.
<em>NEUCOM</em>, <em>419</em>, 251–258. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {By applying Zhang neural dynamics method, this study proposed, analyzed, and investigated a continuous-time model for solving the time-varying Schur decomposition (SD) problem. The proposed model is an explicit dynamics model that utilizes the time derivative information. The theoretical analysis of the proposed model is presented to verify its convergence and efficiency in solving the time-varying SD problem. Furthermore, the proposed model is used to perform the SD of three time-varying matrices with different dimensions. Results confirm the effectiveness of the proposed model.},
  archive      = {J_NEUCOM},
  author       = {Yunong Zhang and Liangjie Ming and Huanchang Huang and Jianrong Chen and Zhonghua Li},
  doi          = {10.1016/j.neucom.2020.07.115},
  journal      = {Neurocomputing},
  pages        = {251-258},
  shortjournal = {Neurocomputing},
  title        = {Time-varying schur decomposition via zhang neural dynamics},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Exponential stability and synchronization of memristor-based
fractional-order fuzzy cellular neural networks with multiple delays.
<em>NEUCOM</em>, <em>419</em>, 239–250. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.057">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The stability and synchronization problems are addressed in this study for the memristor-based fractional-order fuzzy cellular neural networks with multiple delays. By using the Laplace transform method, fractional-order calculus approach and the method of complex function, three exponential stability criteria are derived. Compared with the existing results of the above system, the novel exponentially stable and synchronization conditions are first proposed. The obtained results can be applied not only to fractional-order systems, but also to integer-order systems. A two-dimension example and a three-dimension example and a practical example are given to illustrate the validity and merits.},
  archive      = {J_NEUCOM},
  author       = {Xueqi Yao and Xinzhi Liu and Shouming Zhong},
  doi          = {10.1016/j.neucom.2020.08.057},
  journal      = {Neurocomputing},
  pages        = {239-250},
  shortjournal = {Neurocomputing},
  title        = {Exponential stability and synchronization of memristor-based fractional-order fuzzy cellular neural networks with multiple delays},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rain streaks removal from single image based on texture
constraint of background scene. <em>NEUCOM</em>, <em>419</em>, 224–238.
(<a href="https://doi.org/10.1016/j.neucom.2020.08.025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Removing rain streaks from single image is mathematically ill-defined and the known strategies tend to over-smooth the background and remove image details. To tackle this problem, this paper proposes a novel two-stage system. Firstly, in view of the frequency and direction of rain streaks, Gabor filter is first used to suppress rain streaks. Based on the bases extracted from natural images, several Gabor filtered images extracted from the input rain image are fused by a new proposed method, and the fused result provides a texture constraint for the non-rain part. Secondly, a low-rank model is adopted to describe rain streaks as they take on similar and repeated patterns in an imaging scene. By combining the texture constraint and the low-rank model, a global cost function is constructed. Finally, an optimization strategy is proposed based on the split Bregman technique, which solves the function with high performance. A large number of experimental results show the competitive performance and efficiency of the proposed method in comparison with the state-of-the-art methods, making it more applicable in real practices.},
  archive      = {J_NEUCOM},
  author       = {Shuangli Du and Yiguang Liu and Mao Ye and Minghua Zhao and Zheng Li},
  doi          = {10.1016/j.neucom.2020.08.025},
  journal      = {Neurocomputing},
  pages        = {224-238},
  shortjournal = {Neurocomputing},
  title        = {Rain streaks removal from single image based on texture constraint of background scene},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Master–slave synchronization of neural networks via
event-triggered dynamic controller. <em>NEUCOM</em>, <em>419</em>,
215–223. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.062">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates the event-triggered dynamic feedback control for master–slave synchronization of neural networks with actuator saturation. Firstly, a novel event-triggered mechanism with an exponentially decaying term is proposed. It reduces the value of measure function, which corresponds to decrease the event-triggered frequency. Secondly, a dynamic feedback controller is designed to synchronize the neural networks . In this way, the control input is described as a specific time-varying signal between two consecutive event-triggered instants. Thirdly, by constructing Lyapunov functional and utilizing the generalized sector condition, some sufficient synchronization criteria are established via linear matrix inequalities. Whereafter, the co-designed problem of control gains and triggering parameters is discussed. The rigorous mathematical analysis is provided to show that the presented event-triggered mechanism can eliminate the Zeno behavior . Finally, a numerical example is employed to illustrate the effectiveness of the proposed approach.},
  archive      = {J_NEUCOM},
  author       = {Yong Wang and Sanbo Ding and Ruoxia Li},
  doi          = {10.1016/j.neucom.2020.08.062},
  journal      = {Neurocomputing},
  pages        = {215-223},
  shortjournal = {Neurocomputing},
  title        = {Master–slave synchronization of neural networks via event-triggered dynamic controller},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mobile behavior trusted certification based on multivariate
behavior sequences. <em>NEUCOM</em>, <em>419</em>, 203–214. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {When authenticating illegal users, the existing account/password matching mechanism is only used to validate passwords. Therefore, it can not identify the web behavior of malicious users, such as identity fraud. In the case of fingerprint and face recognition mechanisms, which are prone to fraud, these mechanisms are still ineffective in preventing identity fraud. Recent years, behavioral analysis has been widely studied in view of the fraud-resistant characteristics of user behavior data and the personalized information contained therein. Among them, mobile terminal behavior is one of the main types of web user behavior. Aiming at these mobile terminal behaviors, a method of subspace dimension reduction is proposed to transform the multi-variable real-valued time series into univariable. It is realized by forming each sliding window of multivariate time series into a matrix. By this it generates a matrix sequence. Then we compare the angle difference between two adjacent matrices and transform the matrix sequence into a univariate time series, and then we propose the Gaussian-processes based authentication method to verify a user’s web behavior. The whole process is called Subspace-based dimension Reduction Gaussian-process Authentication ( SRGA ) (SRGA) method. Finally, the effectiveness of proposed method is verified by a series of experiments.},
  archive      = {J_NEUCOM},
  author       = {Peihai Zhao and Mimi Wang},
  doi          = {10.1016/j.neucom.2020.08.003},
  journal      = {Neurocomputing},
  pages        = {203-214},
  shortjournal = {Neurocomputing},
  title        = {Mobile behavior trusted certification based on multivariate behavior sequences},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhancing session-based social recommendation through item
graph embedding and contextual friendship modeling. <em>NEUCOM</em>,
<em>419</em>, 190–202. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommender systems are designed to help users find matching items from plenty of candidates in online platforms. In many online platforms, such as Yelp and Epinions, users’ behaviors are constantly recorded over time, and the users also can build connections with others and share their interests. Previous recommendation methods have either modeled the dynamic interests or the dynamic social influences. A few studies have focused on the modeling of both factors, but they still have several limitations: 1) they fail to consider the complex items transitions among all session sequences, which can be used as a local factor to boost the performance of recommendation methods, and 2) they ignore that a user and their friends only share the same preferences in certain sessions, by keeping the friend vector unchanged for all target users at time t , and 3) they do not consider that a user’s long-term preference may change with the evolution of interests. To overcome the above issues, in this paper, we propose an approach to incorporate item graph embedding and contextual friendship modeling into the recommendation task. Specifically, 1) we construct a directed item graph based on all historical session sequences and utilize a graph neural network to capture the rich local dependency between items, and 2) take a session-level attention mechanism to get each friend’s representation according to the target user’s current interests, and 3) apply max-pooling on the target user’s historical session interests to learn the dynamics of his/her long-term interests. Extensive experiments on two real-world datasets show that our proposed model outperforms state-of-the-art methods consistently on various evaluation metrics .},
  archive      = {J_NEUCOM},
  author       = {Pan Gu and Yuqiang Han and Wei Gao and Guandong Xu and Jian Wu},
  doi          = {10.1016/j.neucom.2020.08.023},
  journal      = {Neurocomputing},
  pages        = {190-202},
  shortjournal = {Neurocomputing},
  title        = {Enhancing session-based social recommendation through item graph embedding and contextual friendship modeling},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AdaDB: An adaptive gradient method with data-dependent
bound. <em>NEUCOM</em>, <em>419</em>, 183–189. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.070">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adaptive gradient learning methods such as Adam, RMSProp, and AdaGrad play an essential role in training a very deep neural network . The learning rates of these optimizers are adaptively changed to accelerate the training process. And the convergence speed is much faster than SGD in many deep learning tasks such as classification and NLP tasks. However, recent works have pointed out that adaptive learning methods can not converge to a critical point under some situations and suffer poor generalization in many deep learning tasks. In our study, we propose AdaDB, an adaptive learning optimizer with data-dependent bound on the learning rate. Every element in the learning rate vector is constrained between a dynamic upper bound and a constant lower bound. And the upper bound is dependent on the data. We also give a theoretical proof of the convergence of AdaDB in the non-convex setting. Our experiments show that AdaDB is capable of eliminating the generalization gap between Adam and SGD . Experiments also reveal the convergence speed of AdaDB is much faster than Adam.},
  archive      = {J_NEUCOM},
  author       = {Liu Yang and Deng Cai},
  doi          = {10.1016/j.neucom.2020.07.070},
  journal      = {Neurocomputing},
  pages        = {183-189},
  shortjournal = {Neurocomputing},
  title        = {AdaDB: An adaptive gradient method with data-dependent bound},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Explaining the black-box model: A survey of local
interpretation methods for deep neural networks. <em>NEUCOM</em>,
<em>419</em>, 168–182. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.011">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, a significant amount of research has been investigated on interpretation of deep neural networks (DNNs) which are normally processed as black box models. Among the methods that have been developed, local interpretation methods stand out which have the features of clear expression in interpretation and low computation complexity. Different from existing surveys which cover a broad range of methods on interpretation of DNNs, this survey focuses on local interpretation methods with an in-depth analysis of the representative works including the newly proposed approaches. From the perspective of principles, we first divide local interpretation methods into two main categories: model-driven methods and data-driven methods. Then we make a fine-grained distinction between the two types of these methods, and highlight the latest ideas and principles. We further demonstrate the effects of a number of interpretation methods by reproducing the results through open source software plugins. Finally, we point out research directions in this rapidly evolving field.},
  archive      = {J_NEUCOM},
  author       = {Yu Liang and Siguang Li and Chungang Yan and Maozhen Li and Changjun Jiang},
  doi          = {10.1016/j.neucom.2020.08.011},
  journal      = {Neurocomputing},
  pages        = {168-182},
  shortjournal = {Neurocomputing},
  title        = {Explaining the black-box model: A survey of local interpretation methods for deep neural networks},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). Adaptive neural network finite-time tracking control for a
class of high-order nonlinear multi-agent systems with powers of
positive odd rational numbers and prescribed performance.
<em>NEUCOM</em>, <em>419</em>, 157–167. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.051">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the adaptive finite-time consensus tracking problem for high-order nonlinear multi-agent systems (MASs) with powers of positive odd rational numbers under prescribed performance. Since the virtual and actual control parts of the dynamics of each follower agent are power functions containing positive odd rational numbers, the method of adding a power integrator is used to overcome the controller design difficulties caused by the power functions. With the aid of a finite-time performance function (FTPF) and neural networks (NNs), a distributed adaptive finite-time consensus tracking controller with prescribed tracking performance is properly designed by the backstepping process. It is shown that the proposed control strategy can guarantee that the consensus tracking error converges to an arbitrarily small neighborhood around zero at any settling time, while all signals of the closed-loop system are semi-globally practical finite-time stable (SGPF-stable). Finally, a simulation example is presented to demonstrate the effectiveness of the proposed method.},
  archive      = {J_NEUCOM},
  author       = {Jiehan Liu and Chaoli Wang and Xuan Cai},
  doi          = {10.1016/j.neucom.2020.08.051},
  journal      = {Neurocomputing},
  pages        = {157-167},
  shortjournal = {Neurocomputing},
  title        = {Adaptive neural network finite-time tracking control for a class of high-order nonlinear multi-agent systems with powers of positive odd rational numbers and prescribed performance},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dropout regularization in hierarchical mixture of experts.
<em>NEUCOM</em>, <em>419</em>, 148–156. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.052">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Dropout is a very effective method in preventing overfitting and has become the go-to regularizer for multi-layer neural networks in recent years. Hierarchical mixture of experts is a hierarchically gated model that defines a soft decision tree where leaves correspond to experts and decision nodes correspond to gating models that softly choose between its children, and as such, the model defines a soft hierarchical partitioning of the input space. In this work, we propose a variant of dropout for hierarchical mixture of experts that is faithful to the tree hierarchy defined by the model, as opposed to having a flat, unitwise independent application of dropout as one has with multi-layer perceptrons . We show that on a synthetic regression data and on MNIST, CIFAR-10, and SSTB datasets, our proposed dropout mechanism prevents overfitting on trees with many levels improving generalization and providing smoother fits.},
  archive      = {J_NEUCOM},
  author       = {Ozan İrsoy and Ethem Alpaydın},
  doi          = {10.1016/j.neucom.2020.08.052},
  journal      = {Neurocomputing},
  pages        = {148-156},
  shortjournal = {Neurocomputing},
  title        = {Dropout regularization in hierarchical mixture of experts},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Prescribed-time cluster synchronization of uncertain complex
dynamical networks with switching via pinning control. <em>NEUCOM</em>,
<em>419</em>, 136–147. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper focuses on the cluster synchronization problem in the prescribed-time of a class of uncertain complex dynamical networks with switching signal which is characterized by average dwell-time constraint. Different from traditional complex dynamical networks, uncertainties, switching signals and nonlinear coupled properties have been introduced to the networks. By applying switched system theory and matrix decomposition method , conditions have been established to ensure that such complex dynamical networks can achieve the desired performance in finite time which is given in advance. Additionally, the methods and results about prescribed-time stable issue of switched systems can be employed to other more general systems. Finally, one numerical example is presented to show the effectiveness of the theoretical results.},
  archive      = {J_NEUCOM},
  author       = {Ling Liu and Xiangwu Ding and Wuneng Zhou},
  doi          = {10.1016/j.neucom.2020.08.043},
  journal      = {Neurocomputing},
  pages        = {136-147},
  shortjournal = {Neurocomputing},
  title        = {Prescribed-time cluster synchronization of uncertain complex dynamical networks with switching via pinning control},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Brain MR image classification for alzheimer’s disease
diagnosis using structural hippocampal asymmetrical attributes from
directional 3-d log-gabor filter responses. <em>NEUCOM</em>,
<em>419</em>, 126–135. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.102">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Alzheimer’s disease (AD) is a progressive and irreversible neurodegenerative condition whose development is characterized by lateralized brain atrophies. In AD, the hippocampus is the first brain structure to present atrophy, which, although to a lesser extent, is also a precursor to the broader asymmetrical development of the human brain. Structural magnetic resonance (MR) imaging is capable of detecting the disease-induced anatomical changes in the brain, thus aiding the diagnosis of AD. MR image attributes extracted from the hippocampal regions are commonly used for the AD classification task. However, most of the published methods do not explore hippocampal asymmetries for image classification. In this study, we propose a new technique for performing the classification of MR images for AD using only hippocampal asymmetrical attributes. By using the new proposed asymmetry index ( AI ), we assessed the attributes and the ones that passed the analysis of variance test, i.e., showing statistically mean differences among the classes (CN, MCI, and AD), were selected for classification. As a result of our study, the statistical analysis of our AI has shown a significant increase in hippocampal asymmetry as disease progress (CN &lt; MCI &lt; AD). Moreover, for the classification using clinical MR images, we obtained accuracy values of 69.44\% and 82.59\%; and AUC values of 0.76 and 0.9 for CN × MCI and CN × AD, respectively. Last, we found the results of our asymmetry analysis consistent with other statistical assessments and our classification results, using only asymmetry attributes comparable to (or even higher than) existing hippocampus studies.},
  archive      = {J_NEUCOM},
  author       = {Katia M. Poloni and Italo A. Duarte de Oliveira and Roger Tam and Ricardo J. Ferrari and for the Alzheimer’s Disease Neuroimaging Initiative},
  doi          = {10.1016/j.neucom.2020.07.102},
  journal      = {Neurocomputing},
  pages        = {126-135},
  shortjournal = {Neurocomputing},
  title        = {Brain MR image classification for alzheimer’s disease diagnosis using structural hippocampal asymmetrical attributes from directional 3-D log-gabor filter responses},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accurate and automatic tooth image segmentation model with
deep convolutional neural networks and level set method.
<em>NEUCOM</em>, <em>419</em>, 108–125. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In oral surgery, accurate segmentation of the teeth has critical significance for the orthodontic treatment and research. However, in the cone beam computed tomography (CBCT) images, the boundaries of the teeth are blurred and some tissues around the teeth have similar intensities to the teeth, which makes the tooth segmentation more difficult and challenging. In this paper, an accurate and automatic active contour model is proposed for the tooth segmentation. First, we apply deep convolutional neural networks to automatically detect the approximate position of each dental pulp. Then, we take the barycenter point of the pixels in the marked area as the center of the tooth. Based on this, we design the shape prior information by a series of mathematical methods to describe the shape, size and position of the tooth, which is achieved by further detecting the direction and length of the tooth. To make full use of the shape prior information, we define the prior constraint term to limit the segmentation curve to evolve around the shape prior information, while making the segmentation contour as close as possible to the shape prior information. Last, combining the image data term, the length term, the regularization term and the prior constraint term, we give the level set formulation of the energy functional and minimize it by the steepest descent method. To test the feasibility and effectiveness of the proposed model, we apply the proposed model to segment the tooth images in different slices. Experimental results show that the proposed model can accurately segment the tooth images. Qualitative comparison results demonstrate the proposed model is superior to the CV model, the RSF model, the LGIF model, the LIC model and the U-Net model in terms of the segmentation accuracy. In addition, the sensitivity test verifies that the proposed model is insensitive to the initial contours and deep network outputs.},
  archive      = {J_NEUCOM},
  author       = {Yunyun Yang and Ruicheng Xie and Wenjing Jia and Zhaoyang Chen and Yunna Yang and Lipeng Xie and BenXiang Jiang},
  doi          = {10.1016/j.neucom.2020.07.110},
  journal      = {Neurocomputing},
  pages        = {108-125},
  shortjournal = {Neurocomputing},
  title        = {Accurate and automatic tooth image segmentation model with deep convolutional neural networks and level set method},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classifier ensemble methods in feature selection.
<em>NEUCOM</em>, <em>419</em>, 97–107. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection has become an indispensable preprocessing step in an expert system. Improving the feature selection performance could guide such a system to make better decisions. Classifier ensembles are known to improve performance when compared to the use of a single classifier. In this study, we aim to perform a formal comparison of different classifier ensemble methods on the feature selection domain. For this purpose, we compare the performances of six classifier ensemble methods: a greedy approach, two average-based approaches, two majority voting approaches, and a meta-classifier approach. In our study, the classifier ensemble involves five machine learning techniques: Logistic Regression, Support Vector Machines, Extreme Learning Machine, Naïve Bayes, and Decision Tree. Experiments are carried on 12 well-known datasets, and results with statistical tests are provided. The results indicate that ensemble methods perform better than single classifiers, yet, they require a longer execution time. Moreover, they can minimize the number of features better than existing ensemble algorithms, namely Random Forest, AdaBoost, and Gradient Boosting, in a less amount of time. Among ensemble methods, the greedy based method performs well in terms of both classification accuracy and execution time.},
  archive      = {J_NEUCOM},
  author       = {Hakan Ezgi Kiziloz},
  doi          = {10.1016/j.neucom.2020.07.113},
  journal      = {Neurocomputing},
  pages        = {97-107},
  shortjournal = {Neurocomputing},
  title        = {Classifier ensemble methods in feature selection},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cooperative hybrid evolutionary algorithm for large scale
multi-stage multi-product batch plants scheduling problem.
<em>NEUCOM</em>, <em>419</em>, 80–96. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an important part of batch chemical industry scheduling problems, the multi-stage multi-product batch plant scheduling problem (MMSP) has been widely studied for decades. This problem is characterized by multiple stages with non-identical parallel units and operate based on customer orders. In this paper, we focus on the large scale MMSP and treat the minimization of make-span as the objective function. An efficient cooperative hybrid evolutionary algorithm is proposed based on the framework of cooperative co-evolution. First, a novel two-line encoding scheme is developed to represent the unit assignment and sequencing for orders respectively. Second, modified estimation of distribution algorithm (EDA) and differential evolutionary (DE) operations are proposed according to the feature of MMSP. EDA operation with a novel population-based incremental learning strategy is applied to handle the unit assignment variables. And novel DE operation based on a novel encoding method is adopted to deal with sequence variables. Then, two selection strategies are applied to preserve optimal and sub-optimal solutions for the proposed algorithm. The critical path based local search algorithm is adopted to further improve the efficiency of local optimization. The proposed algorithm has been tested by several instances with different sizes and characteristics. The numerical results and comparisons show that the proposed work is very competitive in solving large scale MMSP.},
  archive      = {J_NEUCOM},
  author       = {Yuxin Han and Xingsheng Gu},
  doi          = {10.1016/j.neucom.2020.07.094},
  journal      = {Neurocomputing},
  pages        = {80-96},
  shortjournal = {Neurocomputing},
  title        = {Cooperative hybrid evolutionary algorithm for large scale multi-stage multi-product batch plants scheduling problem},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Detection of heterogeneous parallel steganography for low
bit-rate VoIP speech streams. <em>NEUCOM</em>, <em>419</em>, 70–79. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.002">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers a new task of detecting heterogeneous parallel steganography (HPS) on streaming media. This task is to detect the existence of the confidential messages hidden in the frames of streaming media with multiple kinds of orthogonal steganographic methods. We target on detecting HPS in this work for low bit-rate Voice over Internet Protocol (VoIP) speech streams, which is a widely-used streaming medium. Specifically, two steganographic methods, i.e. , Quantization Index Modulation and Pitch Modulation Steganography, are utilized to form the HPS. Detecting HPS on low bit-rate VoIP speech streams is challenging for existing steganalysis methods. To accomplish the target, we propose a novel deep model named as Steganalysis Feature Fusion Network (SFFN). SFFN consists of three sub-networks, i.e. , a feature learning network, a feature fusion network and a classification network. With the three sub-networks, SFFN can effectively extract steganalysis features for the steganographic methods used in HPS and can fuse the features to make credible prediction. The experimental results demonstrate that our method is superior to the state-of-the-art steganalysis methods when detecting HPS. Besides, our method meets the requirement of real-time detection.},
  archive      = {J_NEUCOM},
  author       = {Yuting Hu and Yihua Huang and Zhongliang Yang and Yongfeng Huang},
  doi          = {10.1016/j.neucom.2020.08.002},
  journal      = {Neurocomputing},
  pages        = {70-79},
  shortjournal = {Neurocomputing},
  title        = {Detection of heterogeneous parallel steganography for low bit-rate VoIP speech streams},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-label learning with label-specific features via
weighting and label entropy guided clustering ensemble. <em>NEUCOM</em>,
<em>419</em>, 59–69. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-label learning has attracted more and more researchers’ attention. It deals with the problem where each instance is associated with multiple labels simultaneously. Some methods improve the performance by constructing label-specific features. Specifically, the LIFTACE method constructs label-specific features by clustering ensemble techniques, which ignores the importance of label vectors and does not explore label correlations when constructing the classification model . In this paper, we propose a multi-label learning method called LF-LELC, which considers the importance of label vectors and constructs the classification model by considering label correlations. Firstly, it performs clustering on the positive instances and negative instances respectively. The number of clusters is set by the information contained in the label vectors. After that, it employs clustering ensemble techniques that consider label correlations to make the clustering results more stable and effective. Then, it constructs label-specific features for each label. Finally, it builds the classification model by exploring label correlations. The label set for each test example is predicted by the classification model. Experiments show that LF-LELC can achieve better performance by considering the importance of label vectors and the correlations among labels.},
  archive      = {J_NEUCOM},
  author       = {Chunyu Zhang and Zhanshan Li},
  doi          = {10.1016/j.neucom.2020.07.107},
  journal      = {Neurocomputing},
  pages        = {59-69},
  shortjournal = {Neurocomputing},
  title        = {Multi-label learning with label-specific features via weighting and label entropy guided clustering ensemble},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An ensemble unsupervised spiking neural network for
objective recognition. <em>NEUCOM</em>, <em>419</em>, 47–58. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is now known that the spiking neuron is a basic unit of spiking neural networks (SNNs). Spiking neurons modulate the nervous cells via receiving external incentives, generation of action potential and firing spikes. The SNNs usually used for pattern recognition tasks or complex computation depending on the brain-like characteristic. Although the SNNs have no advantages comparing with the deep neural networks in terms of classification accuracy , the SNNs have more characteristics of biological neurons. In this paper, a hierarchical SNN, comprising convolutional and pooling layers, is designed. The proposed SNN consists of excitatory and inhibitory neurons based on the mechanism of the primate brain. A temporal coding (rank order) manner is used to encode the input patterns. It depends on the rank of the spike arrival on post synapses to establish the priority of input spikes for a particular pattern. The spike-timing-dependent plasticity (STDP) learning rule is used in convolutional layers to extract visual features in an unsupervised learning manner. During the classification stage, a lateral inhibition mechanism is used to prevent the non-firing neurons and produce distinguishable results. In order to improve the performance of our SNN, an ensemble SNN architecture using the voting method is proposed, and transfer learning is used to avoid re-training the SNN when solving the different tasks. The hand-written digits classification task on MNIST, CIFAR-10, and BreaKHis databases are used to verify the performance of the proposed SNN. Experimental results show that by using the ensemble architecture and transfer learning , the classification accuracy of 99.27\% for the MNIST database, overall accuracy is 93\% for the CIFAR-10 database, and overall accuracy is 96.97\% for BreaKHis database. In the meantime, this work achieves a better performance than the benchmarking approaches . Taken together, the results of our work suggest that the ensemble SNN architecture with transfer learning is key to improving the performance of the SNN.},
  archive      = {J_NEUCOM},
  author       = {Qiang Fu and Hongbin Dong},
  doi          = {10.1016/j.neucom.2020.07.109},
  journal      = {Neurocomputing},
  pages        = {47-58},
  shortjournal = {Neurocomputing},
  title        = {An ensemble unsupervised spiking neural network for objective recognition},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Impulsive quasi-containment control in heterogeneous
multiplex networks. <em>NEUCOM</em>, <em>419</em>, 37–46. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.045">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The quasi-containment control problems of heterogeneous multiplex networks are investigated in this paper. By applying the impulsive control to the followers in the networks, and proposing the jointly directed spanning tree, all the followers converge to a convex hull which is expended by multiple leaders. Based on the Lyapunov method and comparison principle of impulsive systems, sufficient criteria are derived to guarantee that the multiplex networks can achieve quasi-containment control. It is found that the upper bound of the errors is closely related to the topology of the multiplex networks, the coupling strength, and the maximal impulsive interval. In addition, the multiplex networks with time delays are further discussed. It is shown that the followers also can achieve quasi-containment control for the multiplex networks with time delays. Finally, the effectiveness of the theoretical results is verified by a two-layers network.},
  archive      = {J_NEUCOM},
  author       = {Xin Jin and Zhengxin Wang and Yuanzhen Feng and Yanling Lu and Chengdai Huang and Cong Zheng},
  doi          = {10.1016/j.neucom.2020.08.045},
  journal      = {Neurocomputing},
  pages        = {37-46},
  shortjournal = {Neurocomputing},
  title        = {Impulsive quasi-containment control in heterogeneous multiplex networks},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Stochasticity and robustness in spiking neural networks.
<em>NEUCOM</em>, <em>419</em>, 23–36. (<a
href="https://doi.org/10.1016/j.neucom.2020.07.105">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite drawing inspiration from biological systems which are inherently noisy and variable, artificial neural networks have been shown to require precise weights to carry out the task which they are trained to accomplish. This creates a challenge when adapting these artificial networks to specialized execution platforms which may encode weights in a manner which restricts their accuracy and/or precision. Reflecting back on the non-idealities which are observed in biological systems, we investigated the effect these properties have on the robustness of spiking neural networks under perturbations to weights. First, we examined techniques extant in conventional neural networks which resemble noisy processes, and postulated they may produce similar beneficial effects in spiking neural networks. Second, we evolved a set of spiking neural networks utilizing biological non-idealities to solve a pole-balancing task, and estimated their robustness. We showed it is higher in networks using noisy neurons, and demonstrated that one of these networks can perform well under the variance expected when a hafnium-oxide based resistive memory is used to encode synaptic weights . Lastly, we trained a series of networks using a surrogate gradient method on the MNIST classification task . We confirmed that these networks demonstrate similar trends in robustness to the evolved networks. We discuss these results and argue that they display empirical evidence supporting the role of noise as a regularizer which can increase network robustness.},
  archive      = {J_NEUCOM},
  author       = {Wilkie Olin-Ammentorp and Karsten Beckmann and Catherine D. Schuman and James S. Plank and Nathaniel C. Cady},
  doi          = {10.1016/j.neucom.2020.07.105},
  journal      = {Neurocomputing},
  pages        = {23-36},
  shortjournal = {Neurocomputing},
  title        = {Stochasticity and robustness in spiking neural networks},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). CASINet: Content-adaptive scale interaction networks for
scene parsing. <em>NEUCOM</em>, <em>419</em>, 9–22. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Objects at different spatial positions in an image exhibit different scales. Adaptive receptive fields are expected to capture suitable ranges of context for accurate pixel level semantic prediction. Recently, atrous convolution with different dilation rates has been used to generate features of multi-scales through several branches which are then fused for prediction. However, there is a lack of explicit interaction among the branches of different scales to adaptively make full use of the contexts. In this paper, we propose a Content-Adaptive Scale Interaction Network (CASINet) to exploit the multi-scale features for scene parsing . We build CASINet based on the classic Atrous Spatial Pyramid Pooling (ASPP) module, followed by a proposed contextual scale interaction (CSI) module, and a scale adaptation (SA) module. Specifically, in the CSI module, for each spatial position of some scale, instead of being limited by a fixed set of convolutional filters that are shared across different spatial positions for feature learning , we promote the adaptivity of the convolutional filters to spatial positions. We achieve this by the context interaction among the features of different scales. The SA module explicitly and softly selects the suitable scale for each spatial position and each channel. Ablation studies demonstrate the effectiveness of the proposed modules. We achieve state-of-the-art performance on three scene parsing benchmarks Cityscapes, ADE20K and LIP.},
  archive      = {J_NEUCOM},
  author       = {Xin Jin and Cuiling Lan and Wenjun Zeng and Zhizheng Zhang and Zhibo Chen},
  doi          = {10.1016/j.neucom.2020.08.014},
  journal      = {Neurocomputing},
  pages        = {9-22},
  shortjournal = {Neurocomputing},
  title        = {CASINet: Content-adaptive scale interaction networks for scene parsing},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The effect of coefficients on the continuous attractors in
coupled highway neural networks. <em>NEUCOM</em>, <em>419</em>, 1–8. (<a
href="https://doi.org/10.1016/j.neucom.2020.08.036">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the recurrent highway networks, we study the coupled networks as a modular behavior of the networks, which can better improve the performance of the system. For a neural network , the non-zero continuous attractors play an important role to decode the information. The emphasis of this paper is to study the conditions for the generation of non-zero continuous attractors in the coupled new system theoretically. By exploring the relationship between network parameters, the conditions for generating non-zero continuous attractors in the new model are successfully determined. In order to verify the correctness and validity of the proposed conclusions, the results of this paper are further verified by simulation.},
  archive      = {J_NEUCOM},
  author       = {Wenshuang Chen and Jiali Yu and Zhang Yi and Hong Qu},
  doi          = {10.1016/j.neucom.2020.08.036},
  journal      = {Neurocomputing},
  pages        = {1-8},
  shortjournal = {Neurocomputing},
  title        = {The effect of coefficients on the continuous attractors in coupled highway neural networks},
  volume       = {419},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
