<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>COIN_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="coin---91">COIN - 91</h2>
<ul>
<li><details>
<summary>
(2021). NIC: An innovative supervised machine learning computational
framework having network-based interactional connections. <em>COIN</em>,
<em>37</em>(4), 1916–1943. (<a
href="https://doi.org/10.1111/coin.12472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Models based on computational intelligence have many applications in various problems. Such systems are generally set up and designed based on a collection of data and information. In some real problems, the implementation of experimental studies or doing tests are costly and time-consuming. Therefore, a model which requires fewer data than the existing soft computing methods can be useful and applicable. In this article, a network-based interactional connection system is proposed as a new supervised machine learning computational framework for problems with small data. This model, which is inspired by the connections between neurons of the brain, utilizes the series and parallel structures with interactional connections to determine the best estimation. The proposed approach uses less unknown parameters than existing models and gives a suitable response in a few steps. The learning process starts with one generation and continues until an acceptable prediction is found, and the coefficients are determined. However, it may have more generations in a sequential format for better prediction and providing more accurate answers. To evaluate the performance of the proposed computational system, three engineering problems were investigated as a numerical study. The results also compared with the predicted values of four well-known techniques.},
  archive      = {J_COIN},
  author       = {Alireza Mirrashid and Ali-Asghar Beheshti Shirazi},
  doi          = {10.1111/coin.12472},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1916-1943},
  shortjournal = {Comput. Intell.},
  title        = {NIC: An innovative supervised machine learning computational framework having network-based interactional connections},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advanced extreme learning machine-based ensemble
classification scheme with enhanced data perturbation for human DNA
sequences. <em>COIN</em>, <em>37</em>(4), 1890–1915. (<a
href="https://doi.org/10.1111/coin.12471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The dramatic growth in machine learning has brought in significant features and quantified non-linear associations in the data derived from sensitive medical datasets. The data should be preserved without influencing the associated classifications by applying a robust, effective and reliable data perturbation technique before enforcing ensemble classification. In this paper, an Integrated Condensation Scheme imposed Privacy Preserving Rotation-based Data Perturbation and Ensemble Classification (ICS-PPR-DPEC) is proposed for ensuring privacy of such sensitive data. Condensation Algorithm-based Data Perturbation is used for constructing homogenous groups determined from the distance between tuples. It also generates a rotation matrix for conducting perturbation that ensures higher data sensitivity protection before it is sent for classification. Advanced Extreme Learning Machine-based Ensemble Classification Scheme includes kernel, norm-optimized and regularized Extreme Learning Machine (ELM)-based classifiers for attaining predominant classification accuracy in identifying human DNA sequences. This approach facilitates classification by constructing ensembles which are trained through randomly resampled ELM classifiers. It includes an objective function that systematically improves the accuracy and diversity among resulting ensembles. The experimental results of the proposed ICS-PPR-DPEC are found to be excellent in terms of classification Accuracy, Precision, Recall, and Kappa statistic when compared to the benchmarked techniques.},
  archive      = {J_COIN},
  author       = {Sengathir Janakiraman and Maruthakutty Deva Priya},
  doi          = {10.1111/coin.12471},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1890-1915},
  shortjournal = {Comput. Intell.},
  title        = {Advanced extreme learning machine-based ensemble classification scheme with enhanced data perturbation for human DNA sequences},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel dissimilarity metric based on feature-to-feature
scatter frequencies for clustering-based feature selection in biomedical
data. <em>COIN</em>, <em>37</em>(4), 1865–1889. (<a
href="https://doi.org/10.1111/coin.12470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Filter feature selection methods have been extensively used for dimensionality reduction in biomedical data analysis. In this article, a novel dissimilarity metric based on feature-to-feature (F2F) scatter frequencies is proposed for clustering-based filter feature selection. The proposed metric is computed by obtaining the feature-level ranks of samples and identifying the features which assign close ranks to each sample. The order of ranking is determined for each feature by class labels. Samples are represented as a set of affinity sets containing features having rank differences less than a predefined proximity window size. The F2F dissimilarity of a pair of features is computed using the frequency of their appearance in different affinity sets. Features are then clustered into distinct groups using F2F dissimilarity metric. From each cluster, the feature having the highest relevance score is selected. The experiments conducted on ten biomedical datasets confirmed the effectiveness of the proposed method in improving classification performance. Notably, the proposed method outperforms the widely used schemes in terms of both classification under ROC curve and stability.},
  archive      = {J_COIN},
  author       = {Ghazaal Sheikhi and Hakan Altınçay},
  doi          = {10.1111/coin.12470},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1865-1889},
  shortjournal = {Comput. Intell.},
  title        = {A novel dissimilarity metric based on feature-to-feature scatter frequencies for clustering-based feature selection in biomedical data},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel embedded system design for the detection and
classification of cardiac disorders. <em>COIN</em>, <em>37</em>(4),
1844–1864. (<a href="https://doi.org/10.1111/coin.12469">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Phonocardiogram (PCG) signals hold significant prognostic and diagnostic information about cardiac health. Numerous PCG or heart sound based automated detection algorithms were previously proposed to assist the disease diagnosis process. Most of the previous studies only focused on algorithmic development. This study presents an intelligent, portable, and low-cost embedded system for the classification of cardiac disorders associated with heart murmurs. Different stages corresponding to the developed embedded system implementation are summarized as follows: The first stage consists of the acquisition of PCG signals of both normal and patients from various hospitals with a customized and low-cost stethoscope. The second stage describes the preprocessing, localization of S1 and S2 heart sounds, and the extraction of systole and diastole from a heart signal with an empirical mode decomposition integrated with the self-developed algorithm. In the third stage, discriminant features are extracted to represent various cardiac classes of PCG signals in a compact manner. In the final stage of the algorithm, the k-nearest neighbors classifier is trained and tested to distinguish between normal and four cardiac disorders. The proposed algorithm achieved 94% mean accuracy through comprehensive experimentation. The cardiac disorders classification algorithm is implemented on a RP-based embedded system. Software application with an interactive graphical interface is also designed to assist users. The developed intelligent system is portable, low-cost, and it enables regular patient-monitoring. The proposed system has the potential to be employed at remote locations where the availability of doctors remains challenging.},
  archive      = {J_COIN},
  author       = {Umair Riaz and Sumair Aziz and Muhammad Umar Khan and Syed Azhar Ali Zaidi and Muhammad Ukasha and Aamir Rashid},
  doi          = {10.1111/coin.12469},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1844-1864},
  shortjournal = {Comput. Intell.},
  title        = {A novel embedded system design for the detection and classification of cardiac disorders},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Novel principal component analysis-based feature selection
mechanism for classroom sound classification. <em>COIN</em>,
<em>37</em>(4), 1827–1843. (<a
href="https://doi.org/10.1111/coin.12468">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning algorithms for sound classification can be supported by multiple temporal, spectral, and perceptual features extracted from the sound signal. The number of features affects the classification accuracy but also the computational resources requested, so the number of features has to be carefully selected. In this work, we propose a methodology for feature selection based on the principal component analysis. The case study has been the classification of classroom sounds during face-to-face module delivery and six sound types have been defined. The proposed method is applied upon a set of 143 sound features to produce feature ranking. The ranking results are compared with those provided by the Relief-F. Then the selected features are used by five classification algorithms, Linear Discriminant Analysis (LDA), Quadratic Support Vector Machine (QSVM), k Nearest Neighbors, Boosted Trees, and Random Forest. The algorithms are executed with increasing number of features, from 1 to 143, considering both feature rankings, creating 1430 models. The performance of the classification algorithms increases rapidly with the number of features with LDA, QSVM, and Boosted Trees outperforming other methods and surpassing the accuracy ratio of 90% with 25 features.},
  archive      = {J_COIN},
  author       = {Eleni Tsalera and Andreas Papadakis and Maria Samarakou},
  doi          = {10.1111/coin.12468},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1827-1843},
  shortjournal = {Comput. Intell.},
  title        = {Novel principal component analysis-based feature selection mechanism for classroom sound classification},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-lingual text detection and identification using agile
convolutional neural network. <em>COIN</em>, <em>37</em>(4), 1803–1826.
(<a href="https://doi.org/10.1111/coin.12467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-lingual scene text detection and identification is a challenging task in today&#39;s world due to the prevalence of many digitized multi-lingual documents, images, and videos. A valuable method for detecting multi-lingual text from natural scene images is proposed which uses the convolutional neural network, namely, You Only Look Once (YOLOv3) as the backbone. The proposed system is more agile than YOLOv3 with the introduction of atrous separable convolution (ASC). The multi-scale prediction in YOLOv3 emphasizes the integration of global features of multi-scale convolutional layers while it overlooks the blend of the multi-scale local region features on the same convolutional layer. To overcome this, ASC is applied to efficiently compute dense local region feature maps, thereby reducing computation complexity substantially. Complete IoU loss, which is an accumulation of overlap area, distance, and aspect ratio, is introduced for enhanced accuracy in bounding box regression, wherein IoU designates the measure of overlap between the predicted and the ground truth bounding boxes. The experimental results show that the proposed system is efficacious in detecting multi-lingual as well as English text from natural scene images.},
  archive      = {J_COIN},
  author       = {Aparna Yegnaraman and S. Valli},
  doi          = {10.1111/coin.12467},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1803-1826},
  shortjournal = {Comput. Intell.},
  title        = {Multi-lingual text detection and identification using agile convolutional neural network},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). FAIMCS: A fast and accurate influence maximization algorithm
in social networks based on community structures. <em>COIN</em>,
<em>37</em>(4), 1779–1802. (<a
href="https://doi.org/10.1111/coin.12466">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Finding a number of nodes that are able to maximize the spread of influence through the social network and are called influence maximization has numerous applications in marketing. One such application is to find influential members for promoting a product across a large network. Even though numerous algorithms have been proposed, challenges such as scalability, time constraints, and low accuracy have motivated the researchers for better solutions. Some of the newly proposed algorithms are scalable, but fail to provide adequate accuracy. On the other hand, some greedy algorithms provide a good level of accuracy but are very time consuming for large networks. In this paper, an algorithm is proposed called FAIMCS that can quickly find influential nodes across large networks with high accuracy. FAIMCS, reduces computational overhead considerably by eliminating major portions of the social network graph which have little influence. FAIMCS uses community detection algorithm to determine each community&#39;s quota of influential nodes based on the structure of that community. Finally, it obtains influential nodes from the candidate nodes. Experiment results show FAIMCS is faster than current algorithms and provides a high level of accuracy for large social networks.},
  archive      = {J_COIN},
  author       = {Esmaeil Bagheri and Gholamhossein Dastghaibyfard and Ali Hamzeh},
  doi          = {10.1111/coin.12466},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1779-1802},
  shortjournal = {Comput. Intell.},
  title        = {FAIMCS: A fast and accurate influence maximization algorithm in social networks based on community structures},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A recent survey on the applications of genetic programming
in image processing. <em>COIN</em>, <em>37</em>(4), 1745–1778. (<a
href="https://doi.org/10.1111/coin.12459">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Genetic programming (GP) has been primarily used to tackle optimization, classification, and feature selection related tasks. The widespread use of GP is due to its flexible and comprehensible tree-type structure. Similarly, research is also gaining momentum in the field of image processing, because of its promising results over vast areas of applications ranging from medical image processing to multispectral imaging. Image processing is mainly involved in applications such as computer vision, pattern recognition, image compression, storage, and medical diagnostics. This universal nature of images and their associated algorithm, that is, complexities, gave an impetus to the exploration of GP. GP has thus been used in different ways for image processing since its inception. Many interesting GP techniques have been developed and employed in the field of image processing, and consequently, we aim to provide the research community an extensive view of these techniques. This survey thus presents the diverse applications of GP in image processing and provides useful resources for further research. In addition, the comparison of different parameters used in different applications of image processing is summarized in tabular form. Moreover, analysis of the different parameters used in image processing related tasks is carried-out to save the time needed in the future for evaluating the parameters of GP. As more advancement is made in GP methodologies, its success in solving complex tasks, not only in image processing but also in other fields, may increase. In addition, guidelines are provided for applying GP in image processing related tasks, the pros and cons of GP techniques are discussed, and some future directions are also set.},
  archive      = {J_COIN},
  author       = {Asifullah Khan and Aqsa Saeed Qureshi and Noorul Wahab and Mutawarra Hussain and Muhammad Yousaf Hamza},
  doi          = {10.1111/coin.12459},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1745-1778},
  shortjournal = {Comput. Intell.},
  title        = {A recent survey on the applications of genetic programming in image processing},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving stochastic local search for uniform k-SAT by
generating appropriate initial assignment. <em>COIN</em>,
<em>37</em>(4), 1706–1744. (<a
href="https://doi.org/10.1111/coin.12438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stochastic local search (SLS) algorithms are well known for their ability to efficiently find models of random instances of the SAT problem, especially for uniform random k -SAT instances. Two processes affect most SLS solvers—the initial assignment of the variables and the heuristics that select which variable to flip. In the last few years, the work on generating the appropriate initial assignment has not been paid much attention or seen much progress, while most SLS solvers focused on the heuristic algorithm. The present work aims to improve SLS algorithms on uniform random k -SAT instances by developing effective methods for generating the initial assignment of variables in a controlled way. First, the allocation strategy introduced recently for 3-SAT instances is extended to initialize the initial assignment on random k -SAT instances. Then a concept of an initial probability distribution of the clause-to-variable ratio of the instance is introduced to determine the parameters of the allocation strategy. This combined method is added to the beginning of six state-of-the-art SLS algorithms in order to generate initial assignments of variables in a controlled way instead of generating them randomly, resulting in six extended SLS algorithms named WalkSATlm_E, DCCASat_E, Score 2 SAT_E, CSCCSat_E, Probsat_E, and Sparrow_E, respectively. They are then evaluated in terms of their capabilities and efficiency on uniform random k -SAT instance from the random track of SAT Competitions in 2016, 2017, and 2018. Experimental results show that these improved SLS solvers outperform their original performance, especially WalkSAT_E, Score 2 SAT_E, and CSCCSat_E outperform the winner of the random track of SAT competition in 2017. In addition, based on the initial probability distribution method, the present work proposes a parameter tuning and analysis of random 3-SAT instances and provides an additional comparative analysis with the state-of-the-art random SLS solvers based on large-scale experiments.},
  archive      = {J_COIN},
  author       = {Huimin Fu and Wuyang Zhang and Guanfeng Wu and Yang Xu and Jun Liu},
  doi          = {10.1111/coin.12438},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1706-1744},
  shortjournal = {Comput. Intell.},
  title        = {Improving stochastic local search for uniform k-SAT by generating appropriate initial assignment},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Static localization for underwater acoustics sensor networks
using nelder–mead algorithm for smart cities. <em>COIN</em>,
<em>37</em>(4), 1691–1705. (<a
href="https://doi.org/10.1111/coin.12431">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization is considered as an important research concept for underwater acoustic sensor networks (UASNs). It performs significant role in diverse routing methods, estimating the node position and node recovery. In UASNs, localization methods have different characteristics compared with the terrestrial networks. The challenges involved in UASNs are varying water temperature and pressure, time synchronization of beacon nodes, complicated ocean currents, and positioning of nodes. To overcome these challenges, a virtual node is deployed using the Nelder–Mead algorithm with the static localization method. In this study, two types of localization methods namely static and dynamic methods are considered and a virtual node is deployed in a static localization manner. Since anchor nodes cannot communicate to the entire network for localization additionally, virtual nodes are deployed to measure the received signal strength indicator and error ratio for effective transmission. In addition “GPS node” is equipped with a ship for easy deployment without communication overhead. The simulation result justifies that static localization for an autonomous underwater sensor networks perform with better coverage rate without time synchronization and acoustic transmission overhead.},
  archive      = {J_COIN},
  author       = {Madhumitha Kulandaivel and Arulanand Natarajan and Bharathi Priya Chandrasekaran and Anandamurugan Selvaraj},
  doi          = {10.1111/coin.12431},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1691-1705},
  shortjournal = {Comput. Intell.},
  title        = {Static localization for underwater acoustics sensor networks using Nelder–Mead algorithm for smart cities},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimal sizing and placement of multiple renewable
distribution generation and DSTATCOM in radial distribution systems
using hybrid lightning search algorithm-simplex method optimization
algorithm. <em>COIN</em>, <em>37</em>(4), 1673–1690. (<a
href="https://doi.org/10.1111/coin.12402">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this literature, the simultaneous placement of both the Renewable Distribution Generation (DG) and Distribution STATCOM (DSTATCOM) in the Radial Distribution System (RDS) for Power Loss Minimization (PLM) is discussed. Loss Sensitivity Factor (LSF) is initially applied to discover the candidate location of DG and DSTATCOM in RDS. The effective Hybrid Lightning Search Algorithm-Simplex Method (LSA-SM) is used to compute the optimal sizing of DG and D-STATCOM. The performance of the proposed method is tested separately on both IEEE33 and IEEE69 RDS test systems. The improvement in system Voltage Profile and operational stability before and after the allocation of DG and DSTATCOM is discussed. The improved system Voltage Stability Index values for different cases are plotted. The performance of the proposed method is compared with similar existing methods.},
  archive      = {J_COIN},
  author       = {Sakthi Gokul Rajan Chinnaraj and Ravi Kuppan},
  doi          = {10.1111/coin.12402},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1673-1690},
  shortjournal = {Comput. Intell.},
  title        = {Optimal sizing and placement of multiple renewable distribution generation and DSTATCOM in radial distribution systems using hybrid lightning search algorithm-simplex method optimization algorithm},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Light chain consensus reinforcement machine learning: An
effective blockchain model for internet of things using for its
advancement and challenges. <em>COIN</em>, <em>37</em>(4), 1651–1672.
(<a href="https://doi.org/10.1111/coin.12395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, blockchain intersected the Internet of Things (IoT) has come up with an integrated opportunity for different applications such as industries, medical diagnosis, and the education sector. Several conflicts have risen during the intersection, where the purpose of addressing the enormous resource utilization of blockchain, efficiency, and security issues of massive IoT has not been tackled in the present scenario. Presently, Ruff-chain, blockchain consortium basis, mobile cloud blockchain (MCBC), probed IoT, and proof of work deployed to overcome the drawback of blockchain intersected IoT demands high resource utilization and power consumption. To address this issue, a light chain consensus reinforcement machine learning (LCC-RML) method has been developed to optimize the blockchain effectively intersected IoT system and it assists in providing a learning methodology from the aspects of resource utilization, data security decentralization, scalability, and latency. In LCC-RML, without affecting the decentralization system, security, and latency, scalability has been improved with the underlying blockchain approach. Here, a lighter model is designed especially for the blockchain intersected IoT platform, which contains optimized learning procedures, reduced block size, lightweight consensus data structure, and related effective block interval to streamline the data processing. The experimental analysis has been evaluated in the learning framework to improve the performance of the blockchain intersected IoT system with a computational speed of 84.89% and resource utilization reduction of 85.88%. Further in the power consumption has been reduced up to 57.55% with the computation cost of 29.55% with the scalability ratio of 86.88%.},
  archive      = {J_COIN},
  author       = {K. Priyadharshini and R. Aroul Canessane},
  doi          = {10.1111/coin.12395},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1651-1672},
  shortjournal = {Comput. Intell.},
  title        = {Light chain consensus reinforcement machine learning: An effective blockchain model for internet of things using for its advancement and challenges},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpretability in healthcare: A comparative study of local
machine learning interpretability techniques. <em>COIN</em>,
<em>37</em>(4), 1633–1650. (<a
href="https://doi.org/10.1111/coin.12410">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although complex machine learning models (eg, random forest, neural networks) are commonly outperforming the traditional and simple interpretable models (eg, linear regression, decision tree), in the healthcare domain, clinicians find it hard to understand and trust these complex models due to the lack of intuition and explanation of their predictions. With the new general data protection regulation (GDPR), the importance for plausibility and verifiability of the predictions made by machine learning models has become essential. Hence, interpretability techniques for machine learning models are an area focus of research. In general, the main aim of these interpretability techniques is to shed light and provide insights into the prediction process of the machine learning models and to be able to explain how the results from the prediction was generated. A major problem in this context is that both the quality of the interpretability techniques and trust of the machine learning model predictions are challenging to measure. In this article, we propose four fundamental quantitative measures for assessing the quality of interpretability techniques— similarity , bias detection , execution time , and trust . We present a comprehensive experimental evaluation of six recent and popular local model agnostic interpretability techniques, namely, LIME , SHAP , Anchors , LORE , ILIME “ and MAPLE on different types of real-world healthcare data. Building on previous work, our experimental evaluation covers different aspects for its comparison including identity , stability , separability , similarity , execution time , bias detection , and trust . The results of our experiments show that MAPLE achieves the highest performance for the identity across all data sets included in this study, while LIME achieves the lowest performance for the identity metric. LIME achieves the highest performance for the separability metric across all data sets. On average, SHAP has the smallest average time to output explanation across all data sets included in this study. For detecting the bias, SHAP and MAPLE enable the participants to better detect the bias. For the trust metric, Anchors achieves the highest performance on all data sets included in this work.},
  archive      = {J_COIN},
  author       = {Radwa ElShawi and Youssef Sherif and Mouaz Al-Mallah and Sherif Sakr},
  doi          = {10.1111/coin.12410},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1633-1650},
  shortjournal = {Comput. Intell.},
  title        = {Interpretability in healthcare: A comparative study of local machine learning interpretability techniques},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A clinical support system for classification and prediction
of depression using machine learning methods. <em>COIN</em>,
<em>37</em>(4), 1619–1632. (<a
href="https://doi.org/10.1111/coin.12377">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The health sector collects a very large amount of data, hence the diagnostic process processes a very large and varied amount of data type which makes the process of analyzing these data very complicated, specifically the healthcare sector, mental health is very composed and varied by various data criteria. However, the forecast of health in modern life becomes very important. To this end, the proposed work aims to analyze patient data based on their represented symptoms, in order to help clinicians and mental health practitioners classify and refine the type of depression disorder “characterized” in patients intelligently, in order to make a relevant decision. In this context, the proposed system called CP-DDC is based on machine learning algorithms supervised more precisely by the random-forest algorithm. The dataset used in the case study contains 150 instances and 11 attributes, which define the different patient criteria, obtained from the Mohammed VI University Hospital Center of Marrakech “CHU.” The results of the experiment show that the proposed system offers the highest performance.},
  archive      = {J_COIN},
  author       = {Chaymae Benfares and Ouidad Akhrif and Younès El Bouzekri El Idrissi and Karim Hamid},
  doi          = {10.1111/coin.12377},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1619-1632},
  shortjournal = {Comput. Intell.},
  title        = {A clinical support system for classification and prediction of depression using machine learning methods},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Toward classifying small lung nodules with hyperparameter
optimization of convolutional neural networks. <em>COIN</em>,
<em>37</em>(4), 1599–1618. (<a
href="https://doi.org/10.1111/coin.12350">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among all cancer-related deaths, lung cancer leads all indicators, accounting for approximately 20% of all types. Patients diagnosed in the early stages have a 1-year survival rate of 81% to 85%, while in an advanced stage have 15% to 19% chances of survival. The primary manifestation of this cancer is through pulmonary nodule on computed tomography images. In the early stages, it is a complex task even for experienced specialists and presents some challenges to classify these nodules in benign or malignant. So, to assist specialists, computer-aided diagnosis systems have been used to improve the accuracy in the diagnosis. In this article, we explored and compared the use of random search, simulating annealing, and Tree-of-Parzen-estimators algorithms of hyperparameter tuning to find the best architecture of a convolutional neural network to classify small pulmonary nodules in benign or malignant with a diameter of 5 to 10 mm. Our best model used result was the model using the simulating annealing algorithm and yielded an area under the receiver operating characteristic curve of 0.95, the sensitivity of 82%, the specificity of 94%, and accuracy of 88% using a balanced data set of nodules. Therefore, our model is capable of classifying early lung nodules, where the patients have bigger chances of survival.},
  archive      = {J_COIN},
  author       = {Lucas L. Lima and José R. Ferreira Junior and Marcelo C. Oliveira},
  doi          = {10.1111/coin.12350},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1599-1618},
  shortjournal = {Comput. Intell.},
  title        = {Toward classifying small lung nodules with hyperparameter optimization of convolutional neural networks},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feature selection inspired by human intelligence for
improving classification accuracy of cancer types. <em>COIN</em>,
<em>37</em>(4), 1571–1598. (<a
href="https://doi.org/10.1111/coin.12341">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection is an essential task to predict clinical risk and biomarkers from the gene expression data. For practical matters, to choose the significant genes, researchers have been addressed several classical feature selection problems over the past decades for subsequent classification of genomics datasets with large ambient dimensionality but a small number of observations. To overcome high dimensionality and overfitting issues, in this paper, we developed a new gene selection technique by combination of minimum redundancy maximum relevance (mRMR) and teaching learning-based optimization for accurate cancer prediction. Firstly, in the proposed approach, mRMR is applied to find the most discriminative genes from the original feature sets, and then a precise teaching learning-based optimization with opposition-based learning approach further refines the reduced feature set that can contribute to identifying the type of cancers. In addition, a new activation function is also investigated for effective gene selection, which is applied to convert continuous to binary search space. Support vector machine (SVM) is used as a fitness function in the proposed method to select relevant features that can help to estimate the predictive accuracy and classify cancer accurately. Attempts have made to increase the performance of SVM classifier by tuning penalty factor, kernel parameter, and tube size parameter with the help of proposed method. In order to testify computational efficiency of proposed algorithm, we have collected six gene expression datasets. Experimental results demonstrated that proposed method by utilizing SVM with Radial Basis Function kernel function is able to significantly reduce the irrelevant genes and outperform the conventional wrapper methods in terms of accuracy and model interpretation.},
  archive      = {J_COIN},
  author       = {Alok Kumar Shukla},
  doi          = {10.1111/coin.12341},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1571-1598},
  shortjournal = {Comput. Intell.},
  title        = {Feature selection inspired by human intelligence for improving classification accuracy of cancer types},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A semantically enriched text mining system for clinical
decision support. <em>COIN</em>, <em>37</em>(4), 1545–1570. (<a
href="https://doi.org/10.1111/coin.12322">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing systems to support decision-taking process based on textual information of clinical reports are insufficient. Currently, there are few systems that unify different subtasks in a single and user-friendly framework, easing therefore the clinical work by automating complex and arduous tasks such as the detection of clinical alerts as well as clinical information coding. To address this issue, MiNerDoc is proposed as a new text mining (TM) system whose main objective is to support clinical decision-taking processes by analyzing textual clinical reports in a unified framework. MiNerDoc is a really alluring TM system that includes two relevant tasks in the medical field, that is, detection of risk factors according to five medical entities (disease, pharmacologic, region/part body, procedure/test, and finding/sign) and automatic prediction of standardized diagnostic codes (MeSH descriptors associated with diseases). MiNerDoc integrates a combination of techniques from the TM discipline along with the terminological and semantic enrichment provided by the MetaMap tool and UMLS metathesaurus. Some study cases as well as a wide experimental analysis on real clinical reports have been carried out to demonstrate the effectiveness and promising performance of MiNerDoc on two different tasks, that is, medical entities recognition (FMeasure 81.54%) and diagnostic classification (FMeasure mic 81.04%).},
  archive      = {J_COIN},
  author       = {Carmen Luque and José M. Luna and Sebastián Ventura},
  doi          = {10.1111/coin.12322},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1545-1570},
  shortjournal = {Comput. Intell.},
  title        = {A semantically enriched text mining system for clinical decision support},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards an approach using grammars for automatic
classification of masses in mammograms. <em>COIN</em>, <em>37</em>(4),
1515–1544. (<a href="https://doi.org/10.1111/coin.12320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximately 15% of all cancer deaths among women worldwide is due to breast cancer. Mammography is one of the most useful methods for the early detection of this disease. Over the last decade, several papers were published reporting the usage of different computer-aided diagnosis systems using pattern recognition techniques as a second opinion to obtain a more accurate diagnosis. However, the theory of formal languages has not been explored in this field. In this context, the main contribution of this study is to present the usage of a new syntactic approach that is able to classify breast masses found in mammograms as benign or malignant. The experimental tests were performed using a dataset that contains 111 images from different sources. The grammar-based classifiers achieved accuracy values ranging from 89% to 100% depending on the features and the model employed. Furthermore, to achieve a feature dimension reduction, a feature selection technique based on the Gini importance of each feature was employed. Additionally, we compared the obtained results with the grammar-based classifiers to the more traditional classifiers used in this research area, such as artificial neural networks, support vector machines, k-nearest neighbors, and random forest. The best result achieved by the grammar-based classifiers was approximately 10% higher, in terms of accuracy, than the best results produced by the traditional classifiers, showing the strength of this grammatical approach.},
  archive      = {J_COIN},
  author       = {Ricardo Wandré Dias Pedro and Ariane Machado-Lima and Fátima L. S. Nunes},
  doi          = {10.1111/coin.12320},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1515-1544},
  shortjournal = {Comput. Intell.},
  title        = {Towards an approach using grammars for automatic classification of masses in mammograms},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Co-occurrence patterns in diagnostic data. <em>COIN</em>,
<em>37</em>(4), 1499–1514. (<a
href="https://doi.org/10.1111/coin.12317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We demonstrate how graph decomposition techniques can be employed for the visualization of hierarchical co-occurrence patterns between medical data items. Our research is based on Gaifman graphs (a mathematical concept introduced in Logic), on specific variants of this concept, and on existing graph decomposition notions, specifically, graph modules and the clan decomposition of so-called 2-structures. The construction of the Gaifman graphs from a dataset is based on co-occurrence, or lack of it, of items in the dataset. We may select a discretization on the edge labels to aim at one among several Gaifman graph variants. Then, the decomposition of the graph may provide us with visual information about the data co-occurrences, after which one can proceed to more traditional statistical analysis.},
  archive      = {J_COIN},
  author       = {Marie Ely Piceno and Laura Rodríguez-Navas and José Luis Balcázar},
  doi          = {10.1111/coin.12317},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1499-1514},
  shortjournal = {Comput. Intell.},
  title        = {Co-occurrence patterns in diagnostic data},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Opening the black box: Personalizing type 2 diabetes
patients based on their latent phenotype and temporal associated
complication rules. <em>COIN</em>, <em>37</em>(4), 1460–1498. (<a
href="https://doi.org/10.1111/coin.12313">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {It is widely considered that approximately 10% of the population suffers from type 2 diabetes. Unfortunately, the impact of this disease is underestimated. Patient&#39;s mortality often occurs due to complications caused by the disease and not the disease itself. Many techniques utilized in modeling diseases are often in the form of a “black box” where the internal workings and complexities are extremely difficult to understand, both from practitioners&#39; and patients&#39; perspective. In this work, we address this issue and present an informative model/pattern, known as a “latent phenotype,” with an aim to capture the complexities of the associated complications&#39; over time. We further extend this idea by using a combination of temporal association rule mining and unsupervised learning in order to find explainable subgroups of patients with more personalized prediction. Our extensive findings show how uncovering the latent phenotype aids in distinguishing the disparities among subgroups of patients based on their complications patterns. We gain insight into how best to enhance the prediction performance and reduce bias in the models applied using uncertainty in the patients&#39; data.},
  archive      = {J_COIN},
  author       = {Leila Yousefi and Stephen Swift and Mahir Arzoky and Lucia Saachi and Luca Chiovato and Allan Tucker},
  doi          = {10.1111/coin.12313},
  journal      = {Computational Intelligence},
  month        = {11},
  number       = {4},
  pages        = {1460-1498},
  shortjournal = {Comput. Intell.},
  title        = {Opening the black box: Personalizing type 2 diabetes patients based on their latent phenotype and temporal associated complication rules},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Smart contract for distributed energy trading in virtual
power plants based on blockchain. <em>COIN</em>, <em>37</em>(3),
1445–1455. (<a href="https://doi.org/10.1111/coin.12388">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The energy system is evolving from smart grid to energy Internet. Virtual power plant (VPP), as an important part of the energy Internet, plays an important role in the distributed energy generation and trading. In this article, a blockchain-based VPP transaction model is established for the future energy Internet driven by real-time electricity price. Then the smart contracts for distributed energy trading in VPPs using blockchain technology are proposed, and the key technological difficulties are analyzed and the solutions are given. Experiments show that the proposed model can reflect the supply and demand information in real time, so that two-way selection can be carried out under the condition of information symmetry when distributed energy is connected to the grid. If our method is applied, we can help distributed energy suppliers set electricity prices, reduce the trust cost and improve the energy trading efficiency. Also, we can help the distributed energy voluntarily participate in VPPs and joint maintain the system, then solve the problem of VPP&#39;s coordinated control and scheduling of distributed energy resources.},
  archive      = {J_COIN},
  author       = {Jing Lu and Shihong Wu and Hanlei Cheng and Zhiyu Xiang},
  doi          = {10.1111/coin.12388},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1445-1455},
  shortjournal = {Comput. Intell.},
  title        = {Smart contract for distributed energy trading in virtual power plants based on blockchain},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). IoT cloud platform for information processing in smart city.
<em>COIN</em>, <em>37</em>(3), 1428–1444. (<a
href="https://doi.org/10.1111/coin.12387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The construction of a sustainable transport network for people or goods will gain and harm mobility depending on their nature and implementation, using new technology and business models. The regular mobile handoff and replacement of connections allow the efficient mobility management of asynchronous wireless transfer mode (ATM) networks. Hence, the design of the broad spectrum usability network architecture for public ATM systems has been given considerable attention in the literature. Since it has been done on the critical subject of estimating user mobility and the prediction, which aims to improve communication efficiency and the bandwidth efficiency of the underlying system architecture, this article addresses the problem by developing the impact of hierarchical framework of service on transportation and traffic pattern (HFSTTP). The growth in mobile Internet and the use of mobile devices over the last decade allowed for omnipresent information on traffic. With the growing use of unique mobile apps, the number of routing users has evolved to be sufficiently large to interrupt the traffic flow pattern. Modern carriage systems and urban logistics improve the efficiency of the transport of goods and slow down the use of road infrastructure. Numerical examples of vehicle traffic include proof of ties between the network traffic and the routing decision-making layer. The partnership between a cooperative control layer and a lower control layer to optimize freight transport is a second example. The congestion price in all over the world shows how to incorporate the social plan layer in future mobility services.},
  archive      = {J_COIN},
  author       = {Xiangcong Chen and Shuqing Zhang and Xiaohui Ding and Seifedine Nimer Kadry and Ching-Hsien Hsu},
  doi          = {10.1111/coin.12387},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1428-1444},
  shortjournal = {Comput. Intell.},
  title        = {IoT cloud platform for information processing in smart city},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Implementation analysis of pixel-level image processing
based on multiscale transforms. <em>COIN</em>, <em>37</em>(3),
1415–1427. (<a href="https://doi.org/10.1111/coin.12384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image processing covers a wide range of processing techniques. Image Fusion is one of those technique which plays a vital role with medical images since different imaging methods provide different set of clinical information for diagnosis. Advances in technology provide us with plenty of imaging modalities. Image fusion is essential for a joint analysis of these multimodality images since each of these modalities provide unique and complementary characterization of the underlying anatomy and tissue microstructure. This paper analyzes the image fusion methods based on multiscale transforms and implements using wavelet, contourlet, curvelet, and shearlet transform. The results are compared.},
  archive      = {J_COIN},
  author       = {Ancy Mergin Albert Jesuwaram and Godwin Premi Maria Sebastin},
  doi          = {10.1111/coin.12384},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1415-1427},
  shortjournal = {Comput. Intell.},
  title        = {Implementation analysis of pixel-level image processing based on multiscale transforms},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Digitized droop control of a high gain primitive
converter—general performance analysis for smart city lighting
application. <em>COIN</em>, <em>37</em>(3), 1405–1414. (<a
href="https://doi.org/10.1111/coin.12381">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents the detailed behavioral analysis of the reduced equation DC droop controller being adapted to the primitive high gain converter designed for DC loads. The article discusses the operation in its open and closed loop modes, voltage, and current control modes as part of the simulation study. The converter mode of operation is continuous in all. Graphical portrayals of statistical results describe the effectiveness of the controller against a standard proportional integral (PI) controller in time and frequency domain. The results substantiate that the DC droop control is superior in terms of efficiency, line regulation, dynamism, and current sharing and stability.},
  archive      = {J_COIN},
  author       = {Subha Sharmini Kannan and Vijayakumar Krishnasamy},
  doi          = {10.1111/coin.12381},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1405-1414},
  shortjournal = {Comput. Intell.},
  title        = {Digitized droop control of a high gain primitive converter—General performance analysis for smart city lighting application},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Relationship quality and supply chain quality performance:
The effect of supply chain integration in hotel industry. <em>COIN</em>,
<em>37</em>(3), 1388–1404. (<a
href="https://doi.org/10.1111/coin.12379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study investigates the relationship between relationship quality and supply chain quality performance in hotel supply chain, through the mediating effect of supply chain integration. A questionnaire survey is used to collect data relating to the research hypotheses. Structural equation model technique is suited for our research goals, and the SmartPLS software is implemented to test the conceptual model. The results show that relationship quality has a direct and positive impact on supply chain quality performance; but after introducing mediating variable—supply chain integration, relationship quality indirectly affects supply chain quality performance through supply chain integration. This means that a good relationship quality can promote supply chain integration and ultimately improve supply chain quality performance.},
  archive      = {J_COIN},
  author       = {Shanghong Le and Jinlin Wu and Jianlan Zhong},
  doi          = {10.1111/coin.12379},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1388-1404},
  shortjournal = {Comput. Intell.},
  title        = {Relationship quality and supply chain quality performance: The effect of supply chain integration in hotel industry},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advanced metameric dimension framework for heterogeneous
industrial internet of things. <em>COIN</em>, <em>37</em>(3), 1367–1387.
(<a href="https://doi.org/10.1111/coin.12378">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The heterogeneous industrial Internet of things (HetIoT) is a recent area of research that can change both our perception of fundamental informatics and the effectiveness of future machines. The HetIoT is rapidly used in a variety of industries, including healthcare smart cities, smart mobility, smart transportation, and advanced manufacturing. In industrial settings, outdated machines consume an inordinate amount of energy and time to produce effective output. The efficient functioning of the HetIoT machines plays a vital role in the industrial management. To demonstrate efficiency of the functioning, the continuous monitoring of machines becomes mandatory. To describe the efficiency of updated HetIoT machines, this article introduces the concept of advanced machine-metameric dimension (A m D) to analyze efficacy, efficiency, and effectiveness. This article proposes a HetIoT framework to identify the real-time resembling of continuous monitoring of a metameric dimension of the machines. This demonstration of the concept is attempted through the analysis of machine efficiency, efficacy, effectiveness, and so on. The proposed A m D with a HetIoT has achieved higher precision, recall, F1-Score, and higher purity.},
  archive      = {J_COIN},
  author       = {Mohammad Ayoub Khan and Khaled Ali Abuhasel},
  doi          = {10.1111/coin.12378},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1367-1387},
  shortjournal = {Comput. Intell.},
  title        = {Advanced metameric dimension framework for heterogeneous industrial internet of things},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Strength prediction of paste filling material based on
convolutional neural network. <em>COIN</em>, <em>37</em>(3), 1355–1366.
(<a href="https://doi.org/10.1111/coin.12373">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The common backfill mining technology in the green mining industry can be used for the secondary utilization of construction waste in smart cities. This measure has the advantages of low cost, fast results, and less environmental pollution. Over the past few decades, with the continuous advancement of global urbanization, the effective and environmentally friendly construction waste disposal and emission are very important for the development of urban green construction. Construction waste can be prepared as paste filling material, as one of the raw materials for backfill mining. This paper proposes a new method that can quickly and accurately predict the strength of paste filling materials with different compositions. A deep connected convolutional neural network (CNN) that can extract input parameters is used to build a prediction model. The coarse aggregate, fine aggregate, and cementing material are employed as the input variables of the CNN model, and five indicators which are generally used to evaluate the strength of filling material are selected as the output results. The experimental results show that the proposed prediction approach can obtain robust prediction results and high prediction accuracy and speed.},
  archive      = {J_COIN},
  author       = {Haigen Cheng and Junjian Hu and Chen Hu and Fangming Deng},
  doi          = {10.1111/coin.12373},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1355-1366},
  shortjournal = {Comput. Intell.},
  title        = {Strength prediction of paste filling material based on convolutional neural network},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence-based novel scheme for location area
planning in cellular networks. <em>COIN</em>, <em>37</em>(3), 1338–1354.
(<a href="https://doi.org/10.1111/coin.12371">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Planning of location area (LA) in cellular networks plays a vital role in utilizing the resources efficiently and economically. Location update and paging costs directly affect the cost to the service provider. When the size of the Mobile Switching Centre (MSC) is large, the paging cost becomes maximum. Though, no location update is required for this case. On the contrary, paging cost shoots high if each cell forms individual LA, but in this case, location update cost shoots to the maximum value. Therefore, deducing the network to the optimal amount of LA&#39;s is an intractable combinatorial optimization problem. In this paper, we intend to optimize the partitions of the MSC service area into an optimal number of LA, to curtail the total location management cost. We propose a novel scheme bearing in mind cell attributes of the network to deduce an optimum number of location areas, leading to minimum cost per call. It is revealed by the results of this work, attained after simulating the scenario on MATLAB 2018a that Cell Attributes Based Algorithm is a very promising scheme for cellular networks, and it outperforms the existing algorithms in a practical scenario.},
  archive      = {J_COIN},
  author       = {Vrince Vimal and Teekam Singh and Shamimul Qamar and Bhaskar Nautiyal and Kamred Udham Singh and Abhishek Kumar},
  doi          = {10.1111/coin.12371},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1338-1354},
  shortjournal = {Comput. Intell.},
  title        = {Artificial intelligence-based novel scheme for location area planning in cellular networks},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Internet of things assisted radio frequency identification
based mine safety management platform. <em>COIN</em>, <em>37</em>(3),
1322–1337. (<a href="https://doi.org/10.1111/coin.12369">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The production of any mine depends heavily on the secure relation between human and mining equipment. Protecting and optimizing the use of these tools and workers from potential accidents by real-time monitoring and control will greatly improve mine safety and productivity. As an emerging technology, the Internet of Things (IoT) and radio frequency identification (RFID) provides a new strategy for underground production of mine security and safety. The main technologies of the Internet of Things are introduced in line with the required of mine safety production. The innovation used in this process is RFID technology, sensor technology for the conceiving of things, intelligent technology for thinking about things, and inherent security technology. In this article, the adaptive heuristic mathematical model based on IoT and RFID real-time monitoring systems has been proposed for the production of mine safety and analysis. This system allows for real-time tracking, detecting suspicious incidents, and verification of the position of a miner within the harsh underground mining environment. The major involvement of this research is the cost-efficient framework to efficiently promote the protection of underground coalmines. This system helps solve serviceability, accessibility, flexibility, and interoperability problems in coal mines.},
  archive      = {J_COIN},
  author       = {Xionghui Xie and Rongping Lin and Bo Yu and Wenfu Wen and Fahui Gu and C.B. Sivaparthipan and Thanjai Vadivel},
  doi          = {10.1111/coin.12369},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1322-1337},
  shortjournal = {Comput. Intell.},
  title        = {Internet of things assisted radio frequency identification based mine safety management platform},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning approach for power consumption model based
on monsoon data for smart cities applications. <em>COIN</em>,
<em>37</em>(3), 1309–1321. (<a
href="https://doi.org/10.1111/coin.12368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this modern world, electricity plays a vital role. It is essential for human life and also affects normal behavior of environment resulting in global warming. Recent developments in artificial intelligence (AI), in particular machine learning (ML), have been significantly advancing smart city applications. Smart infrastructure, which is an essential component of smart cities, is equipped with power systems designed for optimizing smart devices. In this article, real domestic consumption data of 500 consumers from TANGEDCO are analyzed and clustered based on different seasons (consumption rate varies upon different weather conditions) for smart city applications. An efficient clustering algorithm k-means integrates big data set for a period of 10 years and converts it into clustering graph with three seasons. By analyzing this data, the amount of consumption of electricity by humans in particular area (Pasupathikovil) of Papanasam taluk of Thanjavur district will be predicted. This article would be more useful for predicting changes in usage of electricity and take proper steps for analyzing the consumption accordingly and it will be more useful in smart city development. It gives an idea of which season needs more consumption and which needs less.},
  archive      = {J_COIN},
  author       = {S. Sheik Mohideen Shah and S. Meganathan},
  doi          = {10.1111/coin.12368},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1309-1321},
  shortjournal = {Comput. Intell.},
  title        = {Machine learning approach for power consumption model based on monsoon data for smart cities applications},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Performance enhancement of safety message communication via
designing dynamic power control mechanisms in vehicular ad hoc networks.
<em>COIN</em>, <em>37</em>(3), 1286–1308. (<a
href="https://doi.org/10.1111/coin.12367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In vehicular ad hoc networks (VANETs), transmission power is a key factor in several performance measures, such as throughput, delay, and energy efficiency. Vehicle mobility in VANETs creates a highly dynamic topology that leads to a nontrivial task of maintaining connectivity due to rapid topology changes. Therefore, using fixed transmission power adversely affects VANET connectivity and leads to network performance degradation. New cross-layer power control algorithms called (BL-TPC 802.11MAC and DTPC 802.11 MAC) are designed, modeled, and evaluated in this paper. The designed algorithms can be deployed in smart cities, highway, and urban city roads. The designed algorithms improve VANET performance by adapting transmission power dynamically to improve network connectivity. The power adaptation is based on inspecting some network parameters, such as node density, network load, and media access control (MAC) queue state, and then deciding on the required power level. Obtained results indicate that the designed power control algorithm outperforms the traditional 802.11p MAC considering the number of received safety messages, network connectivity, network throughput, and the number of dropped safety messages. Consequently, improving network performance means enhancing the safety of vehicle drivers in smart cities, highway, and urban city.},
  archive      = {J_COIN},
  author       = {Amjed Razzaq Alabbas and Layth A. Hassnawi and Muhammad Ilyas and Haris Pervaiz and Qammer H. Abbasi and Oguz Bayat},
  doi          = {10.1111/coin.12367},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1286-1308},
  shortjournal = {Comput. Intell.},
  title        = {Performance enhancement of safety message communication via designing dynamic power control mechanisms in vehicular ad hoc networks},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sustainable achievement efficiency of transport energy
consumption based on indicator analysis. <em>COIN</em>, <em>37</em>(3),
1268–1285. (<a href="https://doi.org/10.1111/coin.12366">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Energy issue is one of the crucial problems in the corresponding research of sustainability because it is strongly related to the environmental dimension and economic dimension. For evaluating the transport sustainability level for sustainability for regions, the concept of sustainable achievement efficiency in transport energy consumption is initially suggested in this article. And then, on the quantitative analysis to calculate the transport energy achievement efficiency of the regions, the indicators that can represent the achievement of transport energy consumption are convincingly found out by indicator theory. Next, concentration is focused on the transport related indicators and proper indicators are picked up from the candidate indicators, which were the affecting factors to this issue. After that, using the selected indicators, we introduce the method of data envelopment analysis to do quantitative analysis, which helps to get the sustainable achievement efficiency of transport energy among cities all over the world. The analysis result shows the efficient regions and the inefficient regions respectively. Furthermore, the detailed efficiency value of each region is also laid out clearly. Consequently, the achievement efficiency in transport sector can be discussed quantitatively and further policy implications can be suggested for improvement for the inefficient regions to reach high level sustainability.},
  archive      = {J_COIN},
  author       = {Jian Jiang},
  doi          = {10.1111/coin.12366},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1268-1285},
  shortjournal = {Comput. Intell.},
  title        = {Sustainable achievement efficiency of transport energy consumption based on indicator analysis},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Research on the integration of heterogeneous information
resources in university management informatization based on data mining
algorithms. <em>COIN</em>, <em>37</em>(3), 1254–1267. (<a
href="https://doi.org/10.1111/coin.12365">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As far as the current higher education is concerned, the information system used in teaching and management is becoming more and more abundant, and the construction of its informatization is more and more rapid. However, the construction of university informatization project is too long, and there is no unified planning and other reasons, resulting in the difficulty of information and information management cannot be shared across departments. With the deepening of informationization and inaccurate information resources, how to use data mining technology to obtain valuable information is an important issue in the research of heterogeneous information in university management informationization. Based on the analysis of the information island problem in the informatization construction of colleges and universities, taking the student management work as a pilot, a heterogeneous information resource integration platform based on distributed query is proposed. Based on the platform, the information can be effectively applied globally. By analyzing its application in student information management, it shows that data mining is an effective technology to improve the management ability and scientific research level of colleges and universities in the construction of information technology.},
  archive      = {J_COIN},
  author       = {Hongqin Zhang and Min Fang},
  doi          = {10.1111/coin.12365},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1254-1267},
  shortjournal = {Comput. Intell.},
  title        = {Research on the integration of heterogeneous information resources in university management informatization based on data mining algorithms},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Service quality evaluation of satellite data distribution
system based on BP-IPA. <em>COIN</em>, <em>37</em>(3), 1236–1253. (<a
href="https://doi.org/10.1111/coin.12364">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the remarkable advances in remote sensing technology, remote sensing data collected by satellites play an important role in many application domains, in particular the smart city. The service quality of satellite data distribution systems (SDDS) is vital for both administrators and end users. Therefore, it is of practical significance to fully understand the factors that affect the satellite data distribution service. Based on prior studies of e-service quality evaluation and the characteristics of the satellite data, a multidimensional and multi-level service quality evaluation model of the SDDS is proposed. A questionnaire was designed based on the proposed model to collect users&#39; evaluation data. Backpropagation neural network was employed to examine whether and how factors in the proposed model affect the overall service quality. The results were interpreted using importance and performance analysis to assess the relationship between the keys of service quality of the SDDS and the overall service quality. Findings have important managerial implications for the quality management of the SDDS.},
  archive      = {J_COIN},
  author       = {Jiahua Jin and Lu Lu and Xiangbin Yan},
  doi          = {10.1111/coin.12364},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1236-1253},
  shortjournal = {Comput. Intell.},
  title        = {Service quality evaluation of satellite data distribution system based on BP-IPA},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cycling environment investigation and optimization of urban
central road in qingdao. <em>COIN</em>, <em>37</em>(3), 1217–1235. (<a
href="https://doi.org/10.1111/coin.12363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the context of the current construction of smart cities, cycling activities have grown rapidly, and the optimization of road cycling environments has become increasingly important. In order to explore the role of the optimization of cycling environment in improving the health of cyclists and shaping the overall sustainable environment of the city, this article takes the coastal road of Qingdao as the research object to consult the relevant literature and current environment investigation. The IPA analysis method is used to analyze and evaluate the safety, continuity, convenience, interest, and comfort of the cycling environment, to plan and construct the bicycle lanes to ensure the personal safety of cyclists, and to improve the original road facilities. In order to make suggestions for the optimization of the cycling environment in Qingdao, five aspects of developing the characteristic cycling route of coastal tourism are put forward. That is to ensure smooth cycling activities, to add bicycles parking facilities to maintain a good appearance of the city, to increase bicycles related services facilities, to make rational use of the vertical slope of the road, and to make use of the advantages of natural landscape resources.},
  archive      = {J_COIN},
  author       = {Kai Xue and Yue Deng and Hang Zhang and Sanjeevi Pandiyan and Adhiyaman Manickam},
  doi          = {10.1111/coin.12363},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1217-1235},
  shortjournal = {Comput. Intell.},
  title        = {Cycling environment investigation and optimization of urban central road in qingdao},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improved fuzzy-assisted hierarchical neural network system
for design of computer-aided english teaching system. <em>COIN</em>,
<em>37</em>(3), 1199–1216. (<a
href="https://doi.org/10.1111/coin.12362">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The world has enhanced the development of education with the rapid development of information technology in modern society to facilitate the information process. Educational technology has gained experience through the advancement of digital information network technology, from modern teaching technology to computer technology and communication technology. In this paper, an English learning system has been developed based on an improved fuzzy-assisted hierarchical neural network system (IF-HNNS). Improving the standard of English education is particularly important in improving intelligent education, especially the efficiency of classroom teaching. The development of an interactive educational system has changed the conventional way of teaching and facilitated individual independent learning. This English teaching system is a network updating computer-aided learning platform. The computer-aided system has the following advantages: (i) Easy-to-actualize computer-aided learning media will provide more teaching content and teach satisfaction. (ii) The interaction of computer-aided learning will raise interest in learning. (iii) Computer helped learners are rich in educational resources and are easy to set teaching goals. (iv) It will improve the monitoring of the education and teaching cycle using a computer-aided learning with human-computer interaction method.},
  archive      = {J_COIN},
  author       = {Hui Li},
  doi          = {10.1111/coin.12362},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1199-1216},
  shortjournal = {Comput. Intell.},
  title        = {Improved fuzzy-assisted hierarchical neural network system for design of computer-aided english teaching system},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Application of computer information technology in college
physical education using fuzzy evaluation theory. <em>COIN</em>,
<em>37</em>(3), 1181–1198. (<a
href="https://doi.org/10.1111/coin.12352">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The educational sector faces a new dimension that is dominated by lifelong learning and is affected by the technical, social, and cultural changes. This pattern represents the need to improve the teaching methods for physical education and sports science. The use of computers and other information technology to increase the effectiveness of the teaching process is a modern method. This paper aims to illustrate the use of information and communication technologies (ICT) in physical education and sports. In our field, the gradual computerization results can be summed up in the following aspects: education software, design, and planning activities, recording outcomes, motion monitoring, video analysis, comparison of performance and synchronizing, measurements at distance and time and the evaluation of the activity. Although physical education and sports are practical activities, specialists can make use of modern teaching technologies. In this paper, the system of curriculum assessment for physical education has been analyzed and researched in computer assessment. The first section introduced the method of assessment of the physical education program. The second phase of the paper represents a teaching model of the physical education mathematical model utilizing the Comprehensive Adaptive Fuzzy Evaluation Theory has been proposed. A new level is the modernization of physics education with the artificial intelligence computer education system built in this paper. The experimental results have high performance in detecting the physical activity of college students.},
  archive      = {J_COIN},
  author       = {Shan-an Yu},
  doi          = {10.1111/coin.12352},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1181-1198},
  shortjournal = {Comput. Intell.},
  title        = {Application of computer information technology in college physical education using fuzzy evaluation theory},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of online intelligent english teaching platform based
on artificial intelligence techniques. <em>COIN</em>, <em>37</em>(3),
1166–1180. (<a href="https://doi.org/10.1111/coin.12351">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence education (AIEd) is defined in the field of education as the utilization of artificial intelligence. There are currently many AIEd-driven applications in schools and universities. This paper applies an artificial intelligence module combined with the knowledge recommendation to the system and develops an online English teaching system in comparison with the common teaching auxiliary system. The method of English teaching is useful in investigating the potential internal connections between evaluation outcomes and various factors. This article develops deep learning-assisted online intelligent English teaching system that utilizes to create a modern tool platform to help students improve their English language teaching efficiency in line with their mastery of knowledge and personality. The decision tree algorithm and neural networks have been used and to generate an English teaching assessment implementation model based on decision tree technologies. It provides valuable data from extensive information, summarizes rules and data, and helps teachers to improve their education and the English scores of students. This system reflects the thinking of the artificial intelligence expert system. Test application demonstrates that the system can help students improve their learning efficiency and will make learning content more relevant. Besides, the system provides an example model with similar methods and has a referential definition.},
  archive      = {J_COIN},
  author       = {Zhuomin Sun and M. Anbarasan and D. Praveen Kumar},
  doi          = {10.1111/coin.12351},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1166-1180},
  shortjournal = {Comput. Intell.},
  title        = {Design of online intelligent english teaching platform based on artificial intelligence techniques},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of area efficient VLSI architecture for carry select
adder using logic optimization technique. <em>COIN</em>, <em>37</em>(3),
1155–1165. (<a href="https://doi.org/10.1111/coin.12347">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Square Root Carry Select Adder (SQRT-CSLA) is accomplishing the noteworthy attention in the arena of VLSI (Very-Large-Scale Integration) systems as it can process the computations with high speed. Though the current trending SQRT-CSLA adder designing techniques are effective in various performance metrics, there is a possibility to improve the design addressing various performance metrics. This article proposes CSLA architecture by employing Zero Finding Logic using the Logic optimization technique (ZFCLOT). CSLA using ZFCLOT is designed, simulated, and synthesized using 90 nm cadence tools. CSLA using ZFCLOT achieves an area efficiency of 46.127% and a power efficiency of 48.4% as against to SQRT-CSLA.},
  archive      = {J_COIN},
  author       = {Bala Sindhuri Kandula and Padma Vasavi Kalluru and Santi Prabha Inty},
  doi          = {10.1111/coin.12347},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1155-1165},
  shortjournal = {Comput. Intell.},
  title        = {Design of area efficient VLSI architecture for carry select adder using logic optimization technique},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Efficient signal selection using supervised learning model
for enhanced state restoration. <em>COIN</em>, <em>37</em>(3),
1141–1154. (<a href="https://doi.org/10.1111/coin.12344">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The post-silicon validation and debug is the most important task in the contemporary integrated circuit design methodology. The vital problem prevailing in this system is that it has limited observability and controllability due to the minimum number of storage space in the trace buffer. This tends to select the signals prudently in order to maximize state reconstruction. In the reported works, to select and to restore the signals efficiently it is categorized into two types like low simulation with high-quality technique and high simulation with low-quality technique. In this work, a node-based combinational gate signal selection algorithm is proposed based on machine learning method that maximizes the state restoration capability. A significant improvement (80%) has made to achieve adequate simulation time with the high-quality associated with the state-of-the-art of supplementary methods.},
  archive      = {J_COIN},
  author       = {Agalya Rajendran and Muthaiah Rajappa},
  doi          = {10.1111/coin.12344},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1141-1154},
  shortjournal = {Comput. Intell.},
  title        = {Efficient signal selection using supervised learning model for enhanced state restoration},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Physical education teaching for saving energy in basketball
sports athletics using hidden markov and motion model. <em>COIN</em>,
<em>37</em>(3), 1125–1140. (<a
href="https://doi.org/10.1111/coin.12343">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A new trend of schooling is characterized by long-term learning and driven by technological, social, and cultural developments. This trend means that physical education (PE) and sports science must be strengthened. Although PE and sports are practical activities, specialists can make use of modern teaching technologies. Basketball is intended to develop the skills and understanding of movement and protection and its ability to take use of an active and healthy lifestyle in a variety of activities. Therefore, a survey suggested that, energy is valuable part in PE, especially more energy is increased by playing basketball. Hence this study concentrates on Hidden Markov hybridised with Motion Model (HM-HMM), to save energy through the habit of playing basketball. The secret of HM-HMM is computer evaluation system, particularly useful for the calculation of mastery of the academic knowledge of a collection of information points in pathways in PE in colleges to approximate and infer difficulties and unknown properties according to the observed variables. This article introduces a motion model which is more practical based on studies for player movement to save energy.},
  archive      = {J_COIN},
  author       = {Ning Zhang and Yubin Han and Rubén G. Crespo and Oscar S. Martínez},
  doi          = {10.1111/coin.12343},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1125-1140},
  shortjournal = {Comput. Intell.},
  title        = {Physical education teaching for saving energy in basketball sports athletics using hidden markov and motion model},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An empirical model in intrusion detection systems using
principal component analysis and deep learning models. <em>COIN</em>,
<em>37</em>(3), 1111–1124. (<a
href="https://doi.org/10.1111/coin.12342">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data are a main resource of a computer system, which can be transmitted over network from source to destination. While transmitting, it faces lot of security issues such as virus, malware, infection, error, and data loss. The security issues are the attacks that have to be detected and eliminated in efficient way to guarantee the secure transmission. The attack detection rates of existing Intrusion Detection Systems (IDS) are low, because the number of unknown attacks are high when compared to the known attacks in the network. Thus, recent researchers focus more on evaluation of known attacks attributes, that will help in identification of the attacks. But the difficulty here is the nature of the IDS datasets. The difficulty in any IDS dataset is to, too many attributes, irrelevant and unstructured in nature. So analyzing such attributes leads to a time consuming process and that produces an inefficient result. This article presents a combined approach Principle Component Analysis and Deep learning (PCA-DL) model to address above issues. The proposed PCA-DL method has achieved the accuracy 92.6% on detecting the attacks correctly.},
  archive      = {J_COIN},
  author       = {Hariharan Rajadurai and Usha Devi Gandhi},
  doi          = {10.1111/coin.12342},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1111-1124},
  shortjournal = {Comput. Intell.},
  title        = {An empirical model in intrusion detection systems using principal component analysis and deep learning models},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning approach to handle data-driven model for
simulation and forecasting of the cone crusher output in the stone
crushing plant. <em>COIN</em>, <em>37</em>(3), 1098–1110. (<a
href="https://doi.org/10.1111/coin.12338">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Grinding and crushing of stones and other particles are associated with various significant applications. Different sectors have continuously evolved in this area. In the crushing industry, plants function under strict conditions, many of which involve grinding materials. Therefore, various factors are responsible for how the crushers perform. This research investigated the ability of the adaptive neuro fuzzy inference system (ANFIS) to simulate the effects of throw, eccentric speed, closed side setting, and the size of the particle on crusher output. The developed simulation model was adjusted and authenticated alongside the experimental data of the investigated parameters. The model &#39; s performance was computed by the use of several prediction criteria skills. The results of the study indicated that the developed ANFIS model could simulate the Cone crusher output and give a dependable forecast of the cumulative weight fraction. The researchers resolved that the model fostered was a suitable instrument for the onsite cone crusher assessment.},
  archive      = {J_COIN},
  author       = {Khaled Ali Abuhasel},
  doi          = {10.1111/coin.12338},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1098-1110},
  shortjournal = {Comput. Intell.},
  title        = {Machine learning approach to handle data-driven model for simulation and forecasting of the cone crusher output in the stone crushing plant},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Analysis of real-time heartbeat monitoring using wearable
device internet of things system in sports environment. <em>COIN</em>,
<em>37</em>(3), 1080–1097. (<a
href="https://doi.org/10.1111/coin.12337">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Technology in the field of Internet of Things (IoT) with smartphones is enormously growing at a rapid pace for assisting people with their health conditions. Wearable sensors can provide real time data in the field of sports for monitoring the heartbeat of the athletes which can assist in physical activities. Heartbeat rate of the players change during different positions while playing sports and heartbeat monitoring will help the players to know the health condition thus improving the health of an individual. In this research, we propose a new method of wearable sensor device for collecting real time data of athletes using IoT-based system for monitoring electrocardiogram (ECG) patterns along with acceleration of body using smart phone and classify the obtained data using Radial-basis Function Network and Levenberg-Marquardt with Probabilistic Neural Network. The experimental setup of the proposed model performed using 100 persons and effectively classifies the data and predicts the heart rate with the precision of validation and training sample being 73.58% and 73.45 respectively. Thus the proposed IoT-based prediction system can be used to monitor health data of the athletes in real time as an alternate solution for monitoring physical health of the athletes.},
  archive      = {J_COIN},
  author       = {Zhonghua Wang and Zhonghe Gao},
  doi          = {10.1111/coin.12337},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1080-1097},
  shortjournal = {Comput. Intell.},
  title        = {Analysis of real-time heartbeat monitoring using wearable device internet of things system in sports environment},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integration of AI with reduced order generalized integrator
controller for power system harmonic reduction. <em>COIN</em>,
<em>37</em>(3), 1068–1079. (<a
href="https://doi.org/10.1111/coin.12335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increased use of electronics for control and use of nonlinear type loads by consumers in the present power system network are injecting harmonics into the power signal, due to which the power quality issue has become more challenge for the present researchers. In this work, the reduced order generalized integrator (ROGI) and fuzzy logic control (FLC) are collectively used to reduce the current harmonics in the power system. FLC-SVM technique is used to maintain the process of SAF—Shunt active filter with fixed switching frequency. This proposed control technique consists of control loop for current to have fast and effective control. The Proportional Resonant controller is used to have control on voltage for a slow and effective control process which is also used to compensate reactive power. The shunt active filter is designed with the help of ROGI by integrating PI controller for fuzzy-based SVM to reduce the current harmonics on the load side. The results are achieved in MATLAB/SIMULINK software.},
  archive      = {J_COIN},
  author       = {Srihari Mandava and Praveen Kumar Medarametla and Abhishek Gudipalli and M Saravanan and P Sudheer},
  doi          = {10.1111/coin.12335},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1068-1079},
  shortjournal = {Comput. Intell.},
  title        = {Integration of AI with reduced order generalized integrator controller for power system harmonic reduction},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). High-speed and area-efficient sobel edge detector on
field-programmable gate array for artificial intelligence and machine
learning applications. <em>COIN</em>, <em>37</em>(3), 1056–1067. (<a
href="https://doi.org/10.1111/coin.12334">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sobel edge detector is an algorithm commonly used in image processing and computer vision to extract edges from input images using derivative of image pixels in x and y directions against surrounding pixels. Most artificial intelligence and machine learning applications require image processing algorithms running in real time on hardware systems like field-programmable gate array (FPGAs). They typically require high throughput to match real-time speeds and since they run alongside other processing algorithms, they are required to be area efficient as well. This article proposes a high-speed and low-area implementation of the Sobel edge detection algorithm. We created the design using a novel high-level synthesis (HLS) design method based on application specific bit widths for intermediate data nodes. Register transfer level code was generated using MATLAB hardware description language (HDL) coder for HLS. The generated HDL code was implemented on Xilinx Kintex 7 field programmable gate array (FPGA) using Xilinx Vivado software. Our implementation results are superior to those obtained for similar implementations using the vendor library block sets as well as those obtained by other researchers using similar implementations in the recent past in terms of area and speed. We tested our algorithm on Kintex 7 using real-time input video with a frame resolution of 1920 × 1080. We also verified the functional simulation results with a golden MATLAB implementation using FPGA in the loop feature of HDL Verifier. In addition, we propose a generic area, speed, and power improvement methodology for different HLS tools and application designs.},
  archive      = {J_COIN},
  author       = {Prateek Sikka and Abhijit R Asati and Chandra Shekhar},
  doi          = {10.1111/coin.12334},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1056-1067},
  shortjournal = {Comput. Intell.},
  title        = {High-speed and area-efficient sobel edge detector on field-programmable gate array for artificial intelligence and machine learning applications},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning-based charge scheduling of electric
vehicles with minimum waiting time. <em>COIN</em>, <em>37</em>(3),
1047–1055. (<a href="https://doi.org/10.1111/coin.12333">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In order to reduce the greenhouse gas emission and limit the rise in global temperature, the trend in automotive industry is changing rapidly and most of the manufacturers are moving towards the electrification of vehicles. Computational intelligence and machine learning play a very important role in the field of electric vehicles (EVs) due to the necessity of automatic control in battery charging and port accessibility. Due to the limited ranges of EVs, they have to be charged periodically during their travels and its charging will take more time. As the number of EVs increases, suitable charging infrastructure having many charging stations and co-ordination of scheduling the charging vehicles from charging stations are necessary. As charging stations have less number of fast charging ports, accessing these fast charging ports needs proper planning. The major challenge of an EV is to identify the charging station with a fast charging port which is on route to the destination with minimum waiting time. This article deals with the application of machine learning in selecting a charging station with available fast charging port and minimum waiting time.},
  archive      = {J_COIN},
  author       = {V. Vanitha and R. Resmi and Karri Naga Sai Vineela Reddy},
  doi          = {10.1111/coin.12333},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1047-1055},
  shortjournal = {Comput. Intell.},
  title        = {Machine learning-based charge scheduling of electric vehicles with minimum waiting time},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence-based wind forecasting using
variational mode decomposition. <em>COIN</em>, <em>37</em>(3),
1034–1046. (<a href="https://doi.org/10.1111/coin.12331">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intermittency in wind offers the major challenge in accomplishing the wind energy as a dependable sustainable energy resource in power grid. Fluctuations in wind speed occur seasonally over a year and if this seasonality is considered, the prediction of the speed of wind can be made more accurate. In this paper, an attempt is made to apply a signal decomposition technique called Variational Mode Decomposition (VMD), which decomposes series of wind speed data into several intrinsic mode functions (IMFs) to make the data more regular thereby enhancing the accuracy of the wind speed forecast model. Then, artificial intelligence technique, Adaptive neuro fuzzy inference system (ANFIS) is applied for the wind speed prediction by combining the obtained modes from VMD. Here, wind data of two sites in India, Jogimatti and Lamba are taken for the study. Each site data is grouped into high and low wind speed months and later, this series is decomposed into regular modes using VMD. Later, ANFIS is applied for training and predicting the wind speed for different time horizons.},
  archive      = {J_COIN},
  author       = {Vanitha V and Sophia J. G and Resmi R and Delna Raphel},
  doi          = {10.1111/coin.12331},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1034-1046},
  shortjournal = {Comput. Intell.},
  title        = {Artificial intelligence-based wind forecasting using variational mode decomposition},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Enhanced constrained application protocol for secured
medical data transmission model for internet of things. <em>COIN</em>,
<em>37</em>(3), 1014–1033. (<a
href="https://doi.org/10.1111/coin.12321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The medical data produced from various sensors of sensitive information so there is a need to secure them through security solutions. At present, many security solutions are available in the market to secure the medical data. Transport layer security (TLS) is designed to transfer the client from the client to the server in a more secure manner. The major advantage of using TLS is it will not lose any data while transferring the message from client to server. Datagram transport layer security (DTLS) is designed specifically to use in constrained networks. The DTLS protocol consists of major components like base protocol, record layer, and handshake protocol. The main disadvantage of DTLS is the attacker can send multiple Hello messages to the server. This can cause an attack against the server and this attack encourages a new connection between the client and server and also it increases required bandwidth and resources for every message. The main objective of the proposed work is to use the constrained application protocol (CoAP) with DTLS in place of user datagram protocol (UDP) for the secure transmission of data. To evaluate the efficiency of the system, the packet loss ratio, data transmission time, and handshake time are calculated.},
  archive      = {J_COIN},
  author       = {Kamalam Gobichettipalayam Krishnasamy and Anandamurugan Selvaraj},
  doi          = {10.1111/coin.12321},
  journal      = {Computational Intelligence},
  month        = {8},
  number       = {3},
  pages        = {1014-1033},
  shortjournal = {Comput. Intell.},
  title        = {Enhanced constrained application protocol for secured medical data transmission model for internet of things},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A truss-based approach for densest homogeneous subgraph
mining in node-attributed graphs. <em>COIN</em>, <em>37</em>(2),
995–1010. (<a href="https://doi.org/10.1111/coin.12448">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In a wide range of graph analysis tasks such as community detection and event detection, densest subgraph mining is important and primitive. With the development of social network, densest subgraph mining not only need to consider the structural data but also the attributes information, which descripts the features of nodes or edges. However, there are few researches on densest subgraph mining with attribute description. In this article, we only focus on the node-attributed graph. According to the properties of structure and attribute in node-attributed graphs, we define a novel dense subgraph pattern, called hybridized k -truss in attribute-augmented graph. A hybridized k -truss is a subgraph that consists of structural nodes and attribute nodes, of which there are at least ( k − 2) common neighbors between any two connected nodes. We introduce the densest hybridized truss problem, and the densest hybridized truss mapping to a densely connected subgraph with homogenous attributes in the original graph. We propose a densest hybridized truss extraction (DHTE) algorithm for node-attributed graphs, to automatically find the densest subgraph with high density and homogenous attributes at the same time. Extensive experimental results of 21 real world datasets demonstrate the effectiveness and efficiency of DHTE over state-of-the-art methods, through comparison about structural cohesiveness and attributive homogeneity.},
  archive      = {J_COIN},
  author       = {Heli Sun and Yawei Zhang and Xiaolin Jia and Pei Wang and Ruodan Huang and Jianbin Huang and Liang He and Zhongbin Sun},
  doi          = {10.1111/coin.12448},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {995-1010},
  shortjournal = {Comput. Intell.},
  title        = {A truss-based approach for densest homogeneous subgraph mining in node-attributed graphs},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixed pixel removal in north tamil nadu region for accurate
area measurement. <em>COIN</em>, <em>37</em>(2), 975–994. (<a
href="https://doi.org/10.1111/coin.12447">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In remote sensing, vegetation and water areas delineation from satellite image plays a vital role for urban and rural planning. Delineation of vegetation and water area is a challenging task due to mixed pixels and geometric distortion over the boundary region. Geometric distortion arises due to change in velocity and speed of satellite during image acquisition, and mixed pixels arises due to different surfaces in a particular area. Traditional methods apply classifier algorithms such as support vector machine, neural network, and fuzzy for vegetation and water area delineation. The traditional methods require more training dataset and consume more interpretation time for delineation. In this article, we propose transverse dyadic wavelet transform (TDyWT) to delineate vegetation and water area from Landsat 8 images. The TDyWT method enhances the boundary and curvature area of satellite image for accurate delineation. From the experimental results, the proposed TDyWT approach delineates the area of subclass for vegetation and water areas with 95% of accuracy with respect to the ground truth.},
  archive      = {J_COIN},
  author       = {Prabu Mani and Shanker Rajendiran Nagalingam and Celine Kavida Aruldoss and Ganesh Elanchezhian},
  doi          = {10.1111/coin.12447},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {975-994},
  shortjournal = {Comput. Intell.},
  title        = {Mixed pixel removal in north tamil nadu region for accurate area measurement},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A systematic review on machine learning for fall detection
system. <em>COIN</em>, <em>37</em>(2), 951–974. (<a
href="https://doi.org/10.1111/coin.12441">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fall is a major threat to the health and life of the elders. A Fall Detection System (FDS) assist the elders by identifying the fall and save their life. Machine Learning- (ML) based FDS has turned into a major research area due to its capability to assist the elders automatically. The efficiency of a FDS depends on its strength to identify the fall from nonfall accurately. The initial fall detection scheme depends on the threshold-based classification to classify the fall from the Activity of Daily Living (ADL) but this classification method has failed to reduce the false alarm rate, which raises a question on the efficiency of the technique. This review work identifies the problems in threshold-based classification from existing works and finds the need for an efficient ML-based classification technique to accurately identify the fall. Then, presents a comprehensive literature review on various ML-based classification in fall detection. Moreover, the scrutiny investigates the shortcomings associated with the ML-based techniques for future research. This study finds that present ML-based FDS has not addressed problems like data preprocessing and data dimensionality reduction techniques even though ML-based techniques are far superior to threshold-based techniques. The study concludes that Self-Adaptive-based FDS, as well as the complexity reduction of ML-based models, should be concentrated in future research.},
  archive      = {J_COIN},
  author       = {Shikha Rastogi and Jaspreet Singh},
  doi          = {10.1111/coin.12441},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {951-974},
  shortjournal = {Comput. Intell.},
  title        = {A systematic review on machine learning for fall detection system},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Review prognosis system to predict employees job
satisfaction using deep neural network. <em>COIN</em>, <em>37</em>(2),
924–950. (<a href="https://doi.org/10.1111/coin.12440">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the multitude of companies that flourish today, job seekers want to join companies with highly satisfied employees. So, job satisfaction prediction is an important task that helps companies in sustaining or redesigning employee policies. Such predictions not only help in reducing employee attrition but also affect the goodwill and reputation of a company. The higher satisfaction level of current employees attracts potential new employees and confirms the positive policies of a company toward its employees. Job satisfaction prediction can be performed using employee reviews either manually or via automated machine learning algorithms. This study first evaluates four widely used machine learning algorithms, that is, random forest, logistic regression, support vector classifier, and gradient boosting, and then proposes a deep learning model to predict employee job satisfaction level. Experiments are carried out on a dataset that contains text reviews from the employees of Google, Facebook, Amazon, Microsoft, and Apple. Three feature extraction methods are analyzed as well including term frequency-inverse document frequency (TF-IDF), bag-of-words (BOW), and global vector for word representation (GloVe). Performance is evaluated using accuracy, precision, recall, F1 score, as well as, macro average precision, and weighted average. The performance of the proposed model is compared with state-of-the-art deep learning models. Results demonstrate that the proposed model performs better than both the machine learning and state-of-the-art approaches.},
  archive      = {J_COIN},
  author       = {Furqan Rustam and Imran Ashraf and Rahman Shafique and Arif Mehmood and Saleem Ullah and Gyu Sang Choi},
  doi          = {10.1111/coin.12440},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {924-950},
  shortjournal = {Comput. Intell.},
  title        = {Review prognosis system to predict employees job satisfaction using deep neural network},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Ant colony optimization–evolutionary hybrid optimization
with translation of problem representation. <em>COIN</em>,
<em>37</em>(2), 891–923. (<a
href="https://doi.org/10.1111/coin.12439">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Different hybrid optimization metaheuristics (see the works of Talbi for classification) either assume the embedding of one algorithm (usually a metaheuristic) in another (for instance, a local search inside an evolutionary algorithm—a memetic algorithm) or creating a chain of algorithms. In this paper, such a chain combination of two algorithms (namely, the Ant Colony Optimization and Evolutionary Algorithm) is presented. However, because of the intrinsic differences between the two algorithms (a vector of labels and a pheromone table when solving the traveling salesman problem, for example), several dedicated algorithms for translating the solutions between these two representations of the problem are proposed. The hybrid algorithm constructed with the application of the translation methods turns out to be significantly better in solving the TSP compared to non-hybrid versions (relevant experimental results are presented and discussed). This paves the way for new possibilities of constructing hybrid metaheuristics by putting together completely different ones (using different representations); the impact of the presented research is aimed far beyond the hybridization of only ant colony optimization and evolutionary algorithm.},
  archive      = {J_COIN},
  author       = {Wojciech Polnik and Jacek Stobiecki and Aleksander Byrski and Marek Kisiel-Dorohinicki},
  doi          = {10.1111/coin.12439},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {891-923},
  shortjournal = {Comput. Intell.},
  title        = {Ant colony optimization–evolutionary hybrid optimization with translation of problem representation},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Variable population-sized particle swarm optimization for
highly imbalanced dataset classification. <em>COIN</em>, <em>37</em>(2),
873–890. (<a href="https://doi.org/10.1111/coin.12436">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world datasets used for classification often face many challenges when they are imbalanced in nature which is unavoidable and need to be handled by analysts. Many researchers have proposed methods for handling imbalanced datasets and they mostly concentrated on handling binary classification with only two class labels. Only very few research works have been carried out for treating highly imbalanced datasets and fail to handle multiclass datasets. To address imbalance problem in multiclass datasets, this paper proposes a Variable Population sized Particle Swarm Optimization (VPPSO) which is a modified version of Particle Swarm Optimization (PSO) which works based on clustering. PSO usually has fixed population size and has high computational complexity. In order to reduce this, the population size is varied over generations and the particles are loaded into the population iteratively by retaining the balance nature of solutions. PSO optimizes the selection of training and testing samples from each class label in imbalanced datasets for improved classification results. From the implementation results, it is evident that using VPPSO, highly imbalanced datasets with multiclass attributes are classified more efficiently than state-of-the-art algorithms. The statistical results also prove the superior performance of VPPSO.},
  archive      = {J_COIN},
  author       = {Devi Priya Rangasamy and Sivaraj Rajappan and Anitha Natarajan and Rajadevi Ramasamy and Devisurya Vijayakumar},
  doi          = {10.1111/coin.12436},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {873-890},
  shortjournal = {Comput. Intell.},
  title        = {Variable population-sized particle swarm optimization for highly imbalanced dataset classification},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Solution of intuitionistic fuzzy linear programming problem
by dual simplex algorithm and sensitivity analysis. <em>COIN</em>,
<em>37</em>(2), 852–872. (<a
href="https://doi.org/10.1111/coin.12435">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensitivity analysis is designed to study the effect on the optimal solution of changes in model parameters. This analysis is known to be an integral part of any real-life problem solving. This gives a system a dynamic function that enables a researcher to analyze the behavior of the optimal solution as a result of changing the parameters of the model. In this article, postoptimality analysis for changes in objective functions and constraints is presented with suitable numerical illustrations by dual simplex method using magnitude based ranking of triangular intuitionistic fuzzy numbers. The sensitivity range is determined within which the parameters that exist in intuitionistic fuzzy linear programming problem can vary without affecting the optimality of the solution.},
  archive      = {J_COIN},
  author       = {Suresh Mohan and Arun Prakash Kannusamy and Sukhpreet Kaur Sidhu},
  doi          = {10.1111/coin.12435},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {852-872},
  shortjournal = {Comput. Intell.},
  title        = {Solution of intuitionistic fuzzy linear programming problem by dual simplex algorithm and sensitivity analysis},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generating and evaluating cross-sectional synthetic
electronic healthcare data: Preserving data utility and patient privacy.
<em>COIN</em>, <em>37</em>(2), 819–851. (<a
href="https://doi.org/10.1111/coin.12427">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Electronic healthcare record data have been used to study risk factors of disease, treatment effectiveness and safety, and to inform healthcare service planning. There has been increasing interest in utilizing these data for new purposes such as for machine learning to develop predictive algorithms to aid diagnostic and treatment decisions. Synthetic data could potentially be an alternative to real-world data for these purposes as well as reveal any biases in the data used for algorithm development. This article discusses the key requirements of synthetic data for multiple purposes and proposes an approach to generate and evaluate synthetic data focused on, but not limited to, cross-sectional healthcare data. To our knowledge, this is the first article to propose a framework to generate and evaluate synthetic healthcare data with the aim of simultaneously preserving the complexities of ground truth data in the synthetic data while also ensuring privacy. We include findings and new insights from synthetic datasets modeled on both the Indian liver patient dataset and UK primary care dataset to demonstrate the application of this framework under different scenarios.},
  archive      = {J_COIN},
  author       = {Zhenchen Wang and Puja Myles and Allan Tucker},
  doi          = {10.1111/coin.12427},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {819-851},
  shortjournal = {Comput. Intell.},
  title        = {Generating and evaluating cross-sectional synthetic electronic healthcare data: Preserving data utility and patient privacy},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Simulation and performance analysis of 15 nm FinFET based
carry skip adder. <em>COIN</em>, <em>37</em>(2), 799–818. (<a
href="https://doi.org/10.1111/coin.12417">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Various changes in the advanced semiconductor industry, designing adder with higher performance is a major concern. These proposed works constrain the major area in FinFET designing at the range of 15-nm FinFET technology at 25°C. By designing the FinFET technology with the range of 15 nm is the rising transistor technology with the lesser delay and the management in the power tradeoff. FinFET technology makes the evolutionary step in the semiconductor field because various adders have various complications in scaling at the range of 15 nm. The speed reinforcement is used based on various schemes to improve the efficiency of the conventional carry skip adder (Conv-CSKA) structure. By taking into account multiplexer logic, the proposed designing structure made in the account of AND-OR-Invert (AOI) and OR-AND-Invert (OAI) compound gates which are used as the skip logic. The simulation is carried out using HSPICE and Tanner. In various research works, it is concluded that the FinFET based adders are implemented in the semiconductor devices which are the advanced part of the computerized technique with the advancement in the designing circuits. The proposed designing structure includes the 8 T adders which reduce the power consumption with different datapath. The modified designing increases the slack time and decreases the input voltage. This article implements the comparison of FinFET designing based on their speed, power, and energy with the other adder circuits using 15-nm FinFET technology.},
  archive      = {J_COIN},
  author       = {N. Duraivel and B. Paulchamy},
  doi          = {10.1111/coin.12417},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {799-818},
  shortjournal = {Comput. Intell.},
  title        = {Simulation and performance analysis of 15 nm FinFET based carry skip adder},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sentiment classification with adversarial learning and
attention mechanism. <em>COIN</em>, <em>37</em>(2), 774–798. (<a
href="https://doi.org/10.1111/coin.12329">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment classification is a key task in sentiment analysis, reviews mining, and other text mining applications. Various models have been proposed to build sentiment classifiers, but the classification performances of some existing methods are not good enough. Meanwhile, as a subproblem of sentiment classification, positive and unlabeled learning (PU learning) problem widely exists in real-world cases, but it has not been given enough attention. In this article, we aim to solve the two problems in one framework. We first build a model for traditional sentiment classification based on adversarial learning, attention mechanism, and long short-term memory (LSTM) network. We further propose an enhanced adversarial learning method to tackle PU learning problem. We conducted extensive experiments in three real-world datasets. The experimental results demonstrate that our models outperform the compared methods in both traditional sentiment classification problem and PU learning problem. Furthermore, we study the effect of our models on word embedding. Finally, we report and discuss the sensitivity of our models to parameters.},
  archive      = {J_COIN},
  author       = {Yueshen Xu and Lei Li and Honghao Gao and Lei Hei and Rui Li and Yihao Wang},
  doi          = {10.1111/coin.12329},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {774-798},
  shortjournal = {Comput. Intell.},
  title        = {Sentiment classification with adversarial learning and attention mechanism},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Intention classification in multiturn dialogue systems with
key sentences mining. <em>COIN</em>, <em>37</em>(2), 758–773. (<a
href="https://doi.org/10.1111/coin.12345">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multiturn dialogue system has been prevalently used in e-commerce websites and modern information systems, which significantly improves the efficiency of problem solving and further promotes the service quality. In a multiturn dialogue system, the problem of intention classification is a core task, as the intention of a customer is the basis of subsequent problems handling. However, traditional related methods are unsuitable for the classification of multiturn dialogues. Because traditional methods do not distinguish the importance of each sentence and concatenate all sentences in the text, which is likely to generate a model with low prediction accuracy. In this paper, we propose a method of multiturn dialogue classification based on key sentences mining. We design a keywords extraction algorithm, mining key sentences from the dialogue text. We propose an algorithm finishing the computation of the weights of each sentence. According to the sentence weight and the sentence vector, the dialogue text is transformed to a dialogue vector. The dialogue text is classified by a classifier, and the input is the dialogue vector. We conducted sufficient experiments on a real-world dataset, evaluating the performance of the proposed method. The experimental results show that our method outperforms the related methods on a series of evaluation metrics.},
  archive      = {J_COIN},
  author       = {Bin Cao and Kui Ma and Yuqi Liu and Yueshen Xu and Linan Zhu},
  doi          = {10.1111/coin.12345},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {758-773},
  shortjournal = {Comput. Intell.},
  title        = {Intention classification in multiturn dialogue systems with key sentences mining},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid convolutional bidirectional recurrent neural network
based sentiment analysis on movie reviews. <em>COIN</em>,
<em>37</em>(2), 735–757. (<a
href="https://doi.org/10.1111/coin.12400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis is the process of extracting the opinions of customers from online reviews. In general, customers express their reviews in natural language. It becomes a complex task when applying sentiment analysis on those reviews. In earlier stages, word-level features with various feature weighting methods such as Bag of Words, TF-IDF, and Word2Vec were applied for sentiment analysis and deep learning networks are not explored much. We considered phrase level and sentence level features instead of applying word-level features for sentiment analysis and also enhanced by applying various deep learning techniques. In this article, we have proposed a hybrid convolutional bidirectional recurrent neural network model (CBRNN) by combining two-layer convolutional neural network (CNN) with a bidirectional gated recurrent unit (BGRU). In the proposed CBRNN model, the CNN layer extracts the rich set of phrase-level features and BGRU captures the chronological features through long term dependency in a multi-layered sentence. The proposed approach was evaluated on two benchmark datasets and compared with various baselines. The experimental results show that the proposed hybrid model provides better results than any other models with an F 1 score of 87.62% and 77.4% on IMDB and Polarity datasets,respectively. Our CBRNN model outperforms the state of the art by 2%-4% on these two datasets. It is also observed that, the time taken for training is slightly higher than the existing approaches with the substantial improvement in the performance.},
  archive      = {J_COIN},
  author       = {Sivakumar Soubraylu and Ratnavel Rajalakshmi},
  doi          = {10.1111/coin.12400},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {735-757},
  shortjournal = {Comput. Intell.},
  title        = {Hybrid convolutional bidirectional recurrent neural network based sentiment analysis on movie reviews},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Estimating uncertainty in deep learning for reporting
confidence to clinicians in medical image segmentation and diseases
detection. <em>COIN</em>, <em>37</em>(2), 701–734. (<a
href="https://doi.org/10.1111/coin.12411">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL), which involves powerful black box predictors, has achieved a remarkable performance in medical image analysis, such as segmentation and classification for diagnosis. However, in spite of these successes, these methods focus exclusively on improving the accuracy of point predictions without assessing the quality of their outputs. Knowing how much confidence there is in a prediction is essential for gaining clinicians&#39; trust in the technology. In this article, we propose an uncertainty estimation framework, called MC-DropWeights, to approximate Bayesian inference in DL by imposing a Bernoulli distribution on the incoming or outgoing weights of the model, including neurones. We demonstrate that by decomposing predictive probabilities into two main types of uncertainty, aleatoric and epistemic, using the Bayesian Residual U-Net (BRUNet) in image segmentation. Approximation methods in Bayesian DL suffer from the “mode collapse” phenomenon in variational inference. To address this problem, we propose a model which Ensembles of Monte-Carlo DropWeights by varying the DropWeights rate. In segmentation, we introduce a predictive uncertainty estimator, which takes the mean of the standard deviations of the class probabilities associated with every class. However, in classification, we need an alternative approach since the predictive probabilities from a forward pass through the model does not capture uncertainty. The entropy of the predictive distribution is a measure of uncertainty, but its exponential depends on sample size. The plug-in estimate in mutual information is subject to sampling bias. We propose Jackknife resampling, to correct for sample bias, which improves estimating uncertainty quality in image classification. We demonstrate that our deep ensemble MC-DropWeights method, using the bias-corrected estimator produces an equally good or better result in both quantified uncertainty estimation and quality of uncertainty estimates than approximate Bayesian neural networks in practice.},
  archive      = {J_COIN},
  author       = {Biraja Ghoshal and Allan Tucker and Bal Sanghera and Wai Lup Wong},
  doi          = {10.1111/coin.12411},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {701-734},
  shortjournal = {Comput. Intell.},
  title        = {Estimating uncertainty in deep learning for reporting confidence to clinicians in medical image segmentation and diseases detection},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Distance dynamics based overlapping semantic community
detection for node-attributed networks. <em>COIN</em>, <em>37</em>(2),
678–700. (<a href="https://doi.org/10.1111/coin.12324">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, due to the rise of social, biological, and other rich content graphs, several novel community detection methods using structure and node attributes have been proposed. Moreover, nodes in a network are naturally characterized by multiple community memberships and there is growing interest in overlapping community detection algorithms. In this paper, we design a weighted vertex interaction model based on distance dynamics to divide the network, furthermore, we propose a distance Dynamics-based Overlapping Semantic Community detection algorithm(DOSC) for node-attribute networks. The method is divided into three phases: Firstly, we detect local single-attribute subcommunities in each attribute-induced graph based on the weighted vertex interaction model. Then, a hypergraph is constructed by using the subcommunities obtained in the previous step. Finally, the weighted vertex interaction model is used in the hypergraph to get global semantic communities. Experimental results in real-world networks demonstrate that DOSC is a more effective semantic community detection method compared with state-of-the-art methods.},
  archive      = {J_COIN},
  author       = {Heli Sun and Xiaolin Jia and Ruodan Huang and Pei Wang and Chenyu Wang and Jianbin Huang},
  doi          = {10.1111/coin.12324},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {678-700},
  shortjournal = {Comput. Intell.},
  title        = {Distance dynamics based overlapping semantic community detection for node-attributed networks},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Supervised shift k-means based machine learning approach for
link prediction using inherent structural properties of large online
social network. <em>COIN</em>, <em>37</em>(2), 660–677. (<a
href="https://doi.org/10.1111/coin.12372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social network analysis can be used to address the challenges of link prediction in a social network through the measuring and processing of the inherent structural properties of the network. By developing relationships between the anonymous types on networks such as Facebook and Twitter, social network analysis can determine the prediction of future and missing links among the nodes, as well as assist in developing a predictive system. Various techniques have been discussed with proposals for network link prediction methodologies. The scaling of social networks, differences in local and global features, and efficient and precise prediction of links are issues for further study. We propose a collaborative model for link prediction that offers the benefit of structural-based and machine learning techniques. The model produces meaningful results for the prediction of strong and weak links. In this study, we consider node-based feature parameters for the clustering of the social network.},
  archive      = {J_COIN},
  author       = {Praveen Kumar Bhanodia and Aditya Khamparia and Babita Pandey},
  doi          = {10.1111/coin.12372},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {660-677},
  shortjournal = {Comput. Intell.},
  title        = {Supervised shift k-means based machine learning approach for link prediction using inherent structural properties of large online social network},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on computational intelligence for social media
data mining and knowledge discovery. <em>COIN</em>, <em>37</em>(2),
658–659. (<a href="https://doi.org/10.1111/coin.12457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_COIN},
  author       = {Ying Li and R. K. Shyamasundar and Xinheng Wang},
  doi          = {10.1111/coin.12457},
  journal      = {Computational Intelligence},
  month        = {5},
  number       = {2},
  pages        = {658-659},
  shortjournal = {Comput. Intell.},
  title        = {Special issue on computational intelligence for social media data mining and knowledge discovery},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Incremental learning framework for real-world fraud
detection environment. <em>COIN</em>, <em>37</em>(1), 635–656. (<a
href="https://doi.org/10.1111/coin.12434">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For detecting malicious bidding activities in e-auctions, this study develops a chunk-based incremental learning framework that can operate in real-world auction settings. The self-adaptive framework first classifies incoming bidder chunks to counter fraud in each auction and take necessary actions. The fraud classifier is then adjusted with confident bidders&#39; labels validated via bidder verification and one-class classification. Based on real fraud data produced from commercial auctions, we conduct an extensive experimental study wherein the classifier is adapted incrementally using only relevant bidding data while evaluating the subsequent adjusted models&#39; detection and misclassification rates. We also compare our classifier with static learning and learning without data relevancy.},
  archive      = {J_COIN},
  author       = {Farzana Anowar and Samira Sadaoui},
  doi          = {10.1111/coin.12434},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {635-656},
  shortjournal = {Comput. Intell.},
  title        = {Incremental learning framework for real-world fraud detection environment},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiobjective optimization on adhesive bonding of
aluminum-carbon fiber laminate. <em>COIN</em>, <em>37</em>(1), 621–634.
(<a href="https://doi.org/10.1111/coin.12432">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This work presents a multi-objective optimization methodology to find compromise adhesive bonding schemes that possess a great shear load and a low percentage of remaining fiber in the bonding. The joining overlap, adhesive type, and prior surface finishing are considered. The Pareto front of the multi-objective response surface model is found with an Nondominated Sorting Genetic algorithm. The adhesive bonding factors are the adhesive (MP55420, Betamate 120, and DC-80), the surface finishing (acetone cleaned and atmospheric plasma), and the overlapping distance of the test coupons.},
  archive      = {J_COIN},
  author       = {Eduardo Valdés and J. D Mosquera-Artamonov and Celso Cruz-Gonzalez and Jose Jaime Taha-Tijerina},
  doi          = {10.1111/coin.12432},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {621-634},
  shortjournal = {Comput. Intell.},
  title        = {Multiobjective optimization on adhesive bonding of aluminum-carbon fiber laminate},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Mixture-based clustering for count data using approximated
fisher scoring and minorization–maximization approaches. <em>COIN</em>,
<em>37</em>(1), 596–620. (<a
href="https://doi.org/10.1111/coin.12429">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The multinomial distribution has been widely used to model count data. To increase clustering efficiency, we use an approximation to the Fisher scoring algorithm, which is more robust regarding the choice of initial parameter values. Then, we use a novel approach to estimate the optimal number of components, based on minimum message length criterion. Moreover, we consider a generalization of the multinomial model obtained by introducing the Dirichlet as prior, yielding the Dirichlet Compound Multinomial (DCM). Even though DCM can address the burstiness phenomenon of count data, the presence of Gamma function in its density function usually leads to undesired complications. In this article, we use two alternative representations of DCM distribution to perform clustering based on finite mixture models, where the mixture parameters are estimated using the minorization–maximization framework. To evaluate and compare the performance of our proposed models, we have considered three challenging real-world applications that involve high-dimensional count vectors, namely, sentiment analysis, facial expression recognition, and human action recognition. The results show that the proposed algorithms increase the clustering efficiency of their respective models remarkably, and the best results are achieved by the second parametrization of DCM, which can accommodate over-dispersed count data.},
  archive      = {J_COIN},
  author       = {Ornela Bregu and Nuha Zamzami and Nizar Bouguila},
  doi          = {10.1111/coin.12429},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {596-620},
  shortjournal = {Comput. Intell.},
  title        = {Mixture-based clustering for count data using approximated fisher scoring and Minorization–Maximization approaches},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for vision-based fall detection system:
Enhanced optical dynamic flow. <em>COIN</em>, <em>37</em>(1), 578–595.
(<a href="https://doi.org/10.1111/coin.12428">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate fall detection for the assistance of older people is crucial to reduce incidents of deaths or injuries due to falls. Meanwhile, vision-based fall detection system has shown some significant results to detect falls. Still, numerous challenges need to be resolved. The impact of deep learning has changed the landscape of the vision-based system, such as action recognition. The deep learning technique has not been successfully implemented in vision-based fall detection system due to the requirement of a large amount of computation power and requirement of a large amount of sample training data. This research aims to propose a vision-based fall detection system that improves the accuracy of fall detection in some complex environments such as the change of light condition in the room. Also, this research aims to increase the performance of the pre-processing of video images. The proposed system consists of Enhanced Dynamic Optical Flow technique that encodes the temporal data of optical flow videos by the method of rank pooling, which thereby improves the processing time of fall detection and improves the classification accuracy in dynamic lighting condition. The experimental results showed that the classification accuracy of the fall detection improved by around 3% and the processing time by 40–50 ms. The proposed system concentrates on decreasing the processing time of fall detection and improving the classification accuracy. Meanwhile, it provides a mechanism for summarizing a video into a single image by using dynamic optical flow technique, which helps to increase the performance of image preprocessing steps.},
  archive      = {J_COIN},
  author       = {Sagar Chhetri and Abeer Alsadoon and Thair Al-Dala&#39;in and P. W. C. Prasad and Tarik A. Rashid and Angelika Maag},
  doi          = {10.1111/coin.12428},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {578-595},
  shortjournal = {Comput. Intell.},
  title        = {Deep learning for vision-based fall detection system: Enhanced optical dynamic flow},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fuzzy local ternary pattern and skin texture properties
based countermeasure against face spoofing in biometric systems.
<em>COIN</em>, <em>37</em>(1), 559–577. (<a
href="https://doi.org/10.1111/coin.12426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of facial skin texture properties is very demanding and noticeable due to its optimum resource constraint along with reduced processing expenditure. Traditionally, the local binary pattern (LBP) and the variations are accepted for analyzing the skin for liveness detection. LBP descriptor, which is the most dominant algorithm, has its own limitations of not working excellent on images with noise. Texture properties contain variations in skin features like wrinkles. LBP organizes the feature extraction for specified texture to extract the variation between normal and abnormal. In applications such as surveillance, the images are captured by remote cameras and transmitted to control room. The images shall be affected by transmission noises. Transmission noises are varied under the transmission of texture features quality, contrast based pixel coordinates. Thus, in the proposed work, the effectiveness of fuzzy local ternary pattern (FLTP) as a substitute LBP and LTP is presented. It is used to find uncertainty principles of texture image, which are trained from the local databases. Moreover, FLTP embraces Weber&#39;s law that fuses the features to wipe out the predetermined threshold setting in LTP. The proposed approach was analyzed on various publicly available databases pertaining to this domain. Furthermore the proposed system was tested with University Putra Malaysia (UPM) face spoof database. The outcomes obtained from the projected FLTP texture descriptor achieved most proper exactness and outflanked the LBP and LTP surface descriptors.},
  archive      = {J_COIN},
  author       = {P. Kavitha and K. Vijaya},
  doi          = {10.1111/coin.12426},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {559-577},
  shortjournal = {Comput. Intell.},
  title        = {Fuzzy local ternary pattern and skin texture properties based countermeasure against face spoofing in biometric systems},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Traffic video-based intelligent traffic control system for
smart cities using modified ant colony optimizer. <em>COIN</em>,
<em>37</em>(1), 538–558. (<a
href="https://doi.org/10.1111/coin.12424">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Road traffic congestion is a serious problem in today&#39;s world and it happens because of urbanization and population growth. The traffic reduces the transport efficiency in the city, increases the waiting time and travel time, and also increases the usage of fuel and air pollution. To overcome these issues this papers propose an intelligent traffic control system using the Internet of Vehicles (IoV). The vehicles or nodes present in the IoV can communicate between themselves. This technique helps in determining the traffic intensity and the best route to reach the destination. The area of study used in this paper is Vellore city in Tamilnadu, India. The city map is separated into many segments of equal size and Ant Colony Algorithm (AOC) is applied to the separated maps to find the optimal route to reach the destination. Further, Support Vector Machine (SVM) is used to calculate the traffic density and to model the heavy traffic. The proposed algorithm performs better in finding the optimal route when compared to that of the existing path selection algorithms. From the results, it is evident that the proposed IoV-based route selection method provides better performance.},
  archive      = {J_COIN},
  author       = {Krishnasamy Ragavan and Krishnan Venkatalakshmi and Kandasamy Vijayalakshmi},
  doi          = {10.1111/coin.12424},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {538-558},
  shortjournal = {Comput. Intell.},
  title        = {Traffic video-based intelligent traffic control system for smart cities using modified ant colony optimizer},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Classifying and clustering malicious advertisement uniform
resource locators using deep learning. <em>COIN</em>, <em>37</em>(1),
511–537. (<a href="https://doi.org/10.1111/coin.12422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Malicious online advertisement detection has attracted increasing attention in recent years in both academia and industry. The existing advertising blocking systems are vulnerable to the evolution of new attacks and can cause time latency issues by analyzing web content or querying remote servers. This article proposes a lightweight detection system for advertisement Uniform resource locators (URLs) detection, depending only on lexical-based features. Deep learning algorithms are used for online advertising classification. After optimizing the deep neural network architecture, our proposed approach can achieve satisfactory results with false negative rate as low as 1.31%. We also design a novel unsupervised method for data clustering. With the implementation of AutoEncoder for feature preprocessing and t-distributed stochastic neighbor embedding for clustering and visualization, our model outperforms other dimensionality reduction algorithms by generating clear clusterings for different URL families.},
  archive      = {J_COIN},
  author       = {Xichen Zhang and Arash Habibi Lashkari and Ali A. Ghorbani},
  doi          = {10.1111/coin.12422},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {511-537},
  shortjournal = {Comput. Intell.},
  title        = {Classifying and clustering malicious advertisement uniform resource locators using deep learning},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). LPX: Overlapping community detection based on x-means and
label propagation algorithm in attributed networks. <em>COIN</em>,
<em>37</em>(1), 484–510. (<a
href="https://doi.org/10.1111/coin.12420">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional community detection methods in attributed networks (eg, social network) usually disregard abundant node attribute information and only focus on structural information of a graph. Existing community detection methods in attributed networks are mostly applied in the detection of nonoverlapping communities and cannot be directly used to detect the overlapping structures. This article proposes an overlapping community detection algorithm in attributed networks. First, we employ the modified X-means algorithm to cluster attributes to form different themes. Second, we employ the label propagation algorithm (LPA), which is based on neighborhood network conductance for priority and the rule of theme weight, to detect communities in each theme. Finally, we perform redundant processing to form the final community division. The proposed algorithm improves the X-means algorithm to avoid the effects of outliers. Problems of LPA such as instability of division and adjacent communities being easily merged can be corrected by prioritizing the node neighborhood network conductance. As the community is detected in the attribute subspace, the algorithm can find overlapping communities. Experimental results on real-attributed and synthetic-attributed networks show that the performance of the proposed algorithm is excellent with multiple evaluation metrics.},
  archive      = {J_COIN},
  author       = {Jinhuan Ge and Heli Sun and Chenhao Xue and Liang He and Xiaolin Jia and Hui He and Jiyin Chen},
  doi          = {10.1111/coin.12420},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {484-510},
  shortjournal = {Comput. Intell.},
  title        = {LPX: Overlapping community detection based on X-means and label propagation algorithm in attributed networks},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multiperson interaction recognition in images: A body
keypoint based feature image analysis. <em>COIN</em>, <em>37</em>(1),
461–483. (<a href="https://doi.org/10.1111/coin.12419">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most interaction recognition approaches have been limited to single-person action classification in videos. However, for still images where motion information is not available, the task becomes more complex. Aiming to this point, we propose an approach for multiperson human interaction recognition in images with keypoint-based feature image analysis. Proposed method is a three-stage framework. In the first stage, we propose feature-based neural network (FCNN) for action recognition trained with feature images. Feature images are body features, that is, effective distances between a set of body part pairs and angular relation between body part triplets, rearranged in 2D gray-scale image to learn effective representation of complex actions. In the later stage, we propose a voting-based method for direction encoding to anticipate probable motion in steady images. Finally, our multiperson interaction recognition algorithm identifies which human pairs are interacting with each other using an interaction parameter. We evaluate our approach on two real-world data sets, that is, UT-interaction and SBU kinect interaction. The empirical experiments show that results are better than the state-of-the-art methods with recognition accuracy of 95.83% on UT-I set 1, 92.5% on UT-I set 2, and 94.28% on SBU clean data set.},
  archive      = {J_COIN},
  author       = {Amit Verma and Toshanlal Meenpal and Bibhudendra Acharya},
  doi          = {10.1111/coin.12419},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {461-483},
  shortjournal = {Comput. Intell.},
  title        = {Multiperson interaction recognition in images: A body keypoint based feature image analysis},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An integrated methodology to control the risk of
cardiovascular disease in patients with hypertension and type 1
diabetes. <em>COIN</em>, <em>37</em>(1), 435–460. (<a
href="https://doi.org/10.1111/coin.12418">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, air pollution, smoking, use of fatty acids and ready-made foods, and so on, have exacerbated heart disease. Therefore, controlling the risk of such diseases can prevent or reduce their incidence. The present study aimed at developing an integrated methodology including Markov decision processes (MDP) and genetic algorithm (GA) to control the risk of cardiovascular disease in patients with hypertension and type 1 diabetes. First, the efficiency of GA is evaluated against Grey Wolf optimization (GWO) algorithm, and then, the superiority of GA is revealed. Next, the MDP is employed to estimate the risk of cardiovascular disease. For this purpose, model inputs are first determined using a validated micro-simulation model for screening cardiovascular disease developed at Tehran University of Medical Sciences, Iran by GA. The model input factors are then defined accordingly and using these inputs, three risk estimation models are identified. The results of these models support WHO guidelines that provide medicine with a high discount to patients with high expected LYs. To develop the MDP methodology, policies should be adopted that work well despite the difference between the risk model and the actual risk. Finally, a sensitivity analysis is conducted to study the behavior of the total medication cost against the changes of parameters.},
  archive      = {J_COIN},
  author       = {Samar Shetaban and Mir Mehdi Seyyed Esfahani and Abbas Saghaei and Abbas Ahmadi},
  doi          = {10.1111/coin.12418},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {435-460},
  shortjournal = {Comput. Intell.},
  title        = {An integrated methodology to control the risk of cardiovascular disease in patients with hypertension and type 1 diabetes},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sentiment analysis of tweets using a unified convolutional
neural network-long short-term memory network model. <em>COIN</em>,
<em>37</em>(1), 409–434. (<a
href="https://doi.org/10.1111/coin.12415">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sentiment analysis focuses on identifying and classifying the sentiments expressed in text messages and reviews. Social networks like Twitter, Facebook, and Instagram generate heaps of data filled with sentiments, and the analysis of such data is very fruitful when trying to improve the quality of both products and services alike. Classic machine learning techniques have a limited capability to efficiently analyze such large amounts of data and produce precise results; they are thus supported by deep learning models to achieve higher accuracy. This study proposes a combination of convolutional neural network and long short-term memory (CNN-LSTM) deep network for performing sentiment analysis on Twitter datasets. The performance of the proposed model is analyzed with machine learning classifiers, including the support vector classifier, random forest (RF), stochastic gradient descent (SGD), logistic regression, a voting classifier (VC) of RF and SGD, and state-of-the-art classifier models. Furthermore, two feature extraction methods (term frequency-inverse document frequency and word2vec) are also investigated to determine their impact on prediction accuracy. Three datasets (US airline sentiments, women&#39;s e-commerce clothing reviews, and hate speech) are utilized to evaluate the performance of the proposed model. Experiment results demonstrate that the CNN-LSTM achieves higher accuracy than those of other classifiers.},
  archive      = {J_COIN},
  author       = {Muhammad Umer and Imran Ashraf and Arif Mehmood and Saru Kumari and Saleem Ullah and Gyu Sang Choi},
  doi          = {10.1111/coin.12415},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {409-434},
  shortjournal = {Comput. Intell.},
  title        = {Sentiment analysis of tweets using a unified convolutional neural network-long short-term memory network model},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to rank by using multivariate adaptive regression
splines and conic multivariate adaptive regression splines.
<em>COIN</em>, <em>37</em>(1), 371–408. (<a
href="https://doi.org/10.1111/coin.12413">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning to rank is a supervised learning problem that aims to construct a ranking model for the given data. The most common application of learning to rank is to rank a set of documents against a query. In this work, we focus on point-wise learning to rank , where the model learns the ranking values. Multivariate adaptive regression splines (MARS) and conic multivariate adaptive regression splines (CMARS) are supervised learning techniques that have been proven to provide successful results on various prediction problems. In this article, we investigate the effectiveness of MARS and CMARS for point-wise learning to rank problem. The prediction performance is analyzed in comparison to three well-known supervised learning methods, artificial neural network (ANN), support vector machine, and random forest for two datasets under a variety of metrics including accuracy, stability, and robustness. The experimental results show that MARS and ANN are effective methods for learning to rank problem and provide promising results.},
  archive      = {J_COIN},
  author       = {Gulsah Altinok and Pinar Karagoz and Inci Batmaz},
  doi          = {10.1111/coin.12413},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {371-408},
  shortjournal = {Comput. Intell.},
  title        = {Learning to rank by using multivariate adaptive regression splines and conic multivariate adaptive regression splines},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Integration of recurrent convolutional neural network and
optimal encryption scheme for intrusion detection with secure data
storage in the cloud. <em>COIN</em>, <em>37</em>(1), 344–370. (<a
href="https://doi.org/10.1111/coin.12408">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data communication security is growing day after day with the proliferation of cloud computing. It is primarily because of the few security constraints and challenges occurring in the cloud environment during data transmission. Existing research has shown that the intrusion detection system (IDS) centered on the cloud is more complicated. In this article, we address the above issues by proposing an attention-based recurrent convolutional neural network (RCNN). This proposed RCNN is used to detect whether the text data are intrusion or nonintrusion. The nonintrusion text information is then used for further processing and encrypted using a two-way encryption scheme. We introduce the elliptical curve cryptography (ECC) approach to increase the security-level performance of nonintrusion data. Moreover, the integration of ECC with the modified flower pollination algorithm (MFP-ECC) creates the two-way encryption scheme, and it is used to produce an optimal private key. The encrypted data are then stored in a cloud environment by steganography and the data with the sensitive information are replaced by some other text, thus providing security to the data at rest. The proposed MFP-ECC approach shows maximum breaking time results and can also withstand different classical attacks when compared with other methods. As a result, the proposed intrusion detection and secure data storage mechanism is highly secured and it is never affected by any kinds of conspiracy attacks.},
  archive      = {J_COIN},
  author       = {Varun Prabhakaran and Ashokkumar Kulandasamy},
  doi          = {10.1111/coin.12408},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {344-370},
  shortjournal = {Comput. Intell.},
  title        = {Integration of recurrent convolutional neural network and optimal encryption scheme for intrusion detection with secure data storage in the cloud},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hybrid recurrent neural network-logistic chaos-based whale
optimization framework for heart disease prediction with electronic
health records. <em>COIN</em>, <em>37</em>(1), 315–343. (<a
href="https://doi.org/10.1111/coin.12405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heart disease, known interchangeably as “Cardio Vascular Disease,” blocks the blood vessels in the heart and causes heart attack, chest pain, and stroke. Heart disease is one of the leading causes of morbidity and mortality worldwide and it is one of the major causes of morbidity and mortality globally and a trending topic in clinical data analysis. Assessing risk factors related to heart disease is considered as an important step in diagnosing the disease at an early stage. Clinical data present in the form of electronic health records (EHR) can be extracted with the aid of machine learning (ML) algorithms to provide valuable decisions and predictions. ML approaches also play a vital role in early diagnosis and therapeutic monitoring of heart disease. Several research works have been carried out recently to predict heart disease. To this end, we propose a novel hybrid recurrent neural network (RNN)-logistic chaos-based whale optimization (LCBWO) structured hybrid framework for predicting heart disease within 5 years using EHR data. Meanwhile, in the hybrid model established multilayer bidirectional LSTM is used for feature selection, LCBWO algorithm for structural improvement and fast convergence, and LSTM for disease prediction. This research used 10 cross-validations to obtain generalized accuracy and error values. The findings and observations provided here are focused on the knowledge obtained from the EHR report. The results show that the proposed novel hybrid RNN-LCBWO framework achieves a higher accuracy of 98%, a specificity of 99%, precision of 96%, Mathews correlation coefficient of 91%, F-measure of 0.9892, an area under the curve value of 98%, and a prediction time of 9.23 seconds. The accurate predictions obtained from the comparative analysis shows the significant performance of our proposed framework.},
  archive      = {J_COIN},
  author       = {P. Priyanga and Veena V. Pattankar and S. Sridevi},
  doi          = {10.1111/coin.12405},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {315-343},
  shortjournal = {Comput. Intell.},
  title        = {A hybrid recurrent neural network-logistic chaos-based whale optimization framework for heart disease prediction with electronic health records},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A machine learning approach for optimizing heuristic
decision-making in web ontology language reasoners. <em>COIN</em>,
<em>37</em>(1), 273–314. (<a
href="https://doi.org/10.1111/coin.12404">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Description logics (DLs) are formalisms for representing knowledge bases of application domains. The Web Ontology Language (OWL) is a syntactic variant of a very expressive DL. OWL reasoners can infer implied information from OWL ontologies. The performance of OWL reasoners can be severely affected by situations that require decision-making over many alternatives. Such a nondeterministic behavior is often controlled by heuristics that are based on insufficient information. This article proposes a novel OWL reasoning approach that applies machine learning (ML) to implement pragmatic and optimal decision-making strategies in such situations. Disjunctions occurring in ontologies are one source of nondeterministic actions in reasoners. We propose two ML-based approaches to reduce the nondeterminism caused by dealing with disjunctions. The first approach is restricted to propositional DL while the second one can deal with standard DL. Both approaches speed up our ML-based reasoner by up to two orders of magnitude in comparison to the non-ML reasoner. Another source of nondeterministic actions is the order in which tableau rules should be applied. On average, our ML-based approach achieves a speedup of two orders of magnitude when compared to the most expensive rule ordering of the non-ML reasoner.},
  archive      = {J_COIN},
  author       = {Razieh Mehri and Volker Haarslev and Hamidreza Chinaei},
  doi          = {10.1111/coin.12404},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {273-314},
  shortjournal = {Comput. Intell.},
  title        = {A machine learning approach for optimizing heuristic decision-making in web ontology language reasoners},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An improved vertical fragmentation, allocation and
replication for enhancing e-learning in distributed database
environment. <em>COIN</em>, <em>37</em>(1), 253–272. (<a
href="https://doi.org/10.1111/coin.12401">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {E-learning is the indispensable technique to educate huge number of people and students in short period of time with optimized usage of different kind of required resources. It is employed as a crucial teaching approach by almost all kind of educational institutions all around the world. Since e-learning involves significant amount of resource utilization and cost, it requires some essential methodology to enhance the current system of e-learning more efficient. The mere publication of the educational content in websites is not enough. It is very clear that, without applying suitable strategic models and concepts and establishing appropriate communication channels between contributors of e-learning system, the educational goals cannot be achieved as we desired. Distributed database involves greater contribution in the field of cloud based e-learning process. Basically, data replication is crucial decision of companies as database distribution can be achieved effectively by the method of database replication which generates the same copies of information called replicas. In this article, we analyze the supremacy of synergetic learning and concentrates on data replication&#39;s significance in cloud based learning system. Here we propose an excellent mechanism for data replication and enhancing the performance in terms optimized access and update of data by the determination of exact location of data through dynamic programming. The efficiency of proposed mechanism is clearly illustrated by experimental results.},
  archive      = {J_COIN},
  author       = {P. Sathishkumar and M. Gunasekaran},
  doi          = {10.1111/coin.12401},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {253-272},
  shortjournal = {Comput. Intell.},
  title        = {An improved vertical fragmentation, allocation and replication for enhancing e-learning in distributed database environment},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Accuracy improvement in air-quality forecasting using
regressor combination with missing data imputation. <em>COIN</em>,
<em>37</em>(1), 226–252. (<a
href="https://doi.org/10.1111/coin.12399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a hybrid model based on regressor combination to improve the accuracy of air-quality forecasting. The expectation-maximization algorithm was used to impute the missing values of the dataset. The optimal hyperparameter values for the regressors were found by the grid search approach, depending on the mean absolute error (MAE), in the training session. The regressors having the minimum MAE were then globally combined for prediction. The output of the regressor with the minimum absolute error between the actual and predicted values was chosen as the prediction result of the hybrid model. The performance of the proposed model was compared with that of sequential deep learning methods, namely long short-term memory and gated recurrent unit, in terms of MAE, mean relative error (MRE), and squared correlation coefficient (SCC) metrics. The imputed dataset was divided into training and testing subsets of different durations. According to the experimental results, our hybrid model performed better than the deep learning methods in terms of MAE, MRE, and SCC metrics, irrespective of the training data length. Furthermore, the Akaike&#39;s information criterion and the Bayesian information criterion values suggested that the quality of the hybrid model was better than that of the deep learning models.},
  archive      = {J_COIN},
  author       = {Ali Ozturk},
  doi          = {10.1111/coin.12399},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {226-252},
  shortjournal = {Comput. Intell.},
  title        = {Accuracy improvement in air-quality forecasting using regressor combination with missing data imputation},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Group recommendation with noisy subjective preferences.
<em>COIN</em>, <em>37</em>(1), 210–225. (<a
href="https://doi.org/10.1111/coin.12398">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social choice theory provides a principled framework for the aggregation of individuals&#39; preferences in support of group decision-making and recommendation. Much of this work, however, either assumes that individuals&#39; subjective preferences (and thus, their votes) are correctly specified by the individuals themselves, or alternatively that the votes of individuals are noisy estimates of some underlying ground truth over rankings of alternatives. We argue that neither model appropriately addresses some of the issues which arise in the context of group-recommendation domains where individuals have subjective preferences but for some reason (eg, the high cognitive burden, concerns about privacy, etc.) may instead vote using a noisy estimate of their subjective preference rankings. In this paper, we propose a general probabilistic framework for modeling noisy subjective preferences, and explore the accuracy and reliability of four well-studied voting rules under various noise models. Our results demonstrate that there is no single reliable method amongst the examined methods. Specifically, we observe the change in noise distribution can flip one method from being the most reliable to the least.},
  archive      = {J_COIN},
  author       = {Amirali Salehi-Abari and Kate Larson},
  doi          = {10.1111/coin.12398},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {210-225},
  shortjournal = {Comput. Intell.},
  title        = {Group recommendation with noisy subjective preferences},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A novel hybrid whale optimization algorithm with flower
pollination algorithm for feature selection: Case study email spam
detection. <em>COIN</em>, <em>37</em>(1), 176–209. (<a
href="https://doi.org/10.1111/coin.12397">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) in data mining is one of the most challenging and most important activities in pattern recognition. In this article, a new hybrid model of whale optimization algorithm (WOA) and flower pollination algorithm (FPA) is presented for the problem of FS based on the concept of opposition-based learning (OBL) which name is HWOAFPA. The procedure is that the WOA is run first and at the same time during the run, the WOA population is changed by the OBL. And, to increase the accuracy and speed of convergence, it is used as the initial population of FPA. To evaluate the performance of the proposed method, experiments were carried out in two steps. The experiments were performed on 10 datasets from the UCI data repository and Email spam detection datasets. The results obtained from the first step showed that the proposed method was more successful in terms of the average size of selection and classification accuracy than other basic metaheuristic algorithms. In addition, the results from the second step showed that the proposed method which was a run on the Email spam dataset performed much more accurately than other similar algorithms in terms of accuracy of Email spam detection.},
  archive      = {J_COIN},
  author       = {Hekmat Mohammadzadeh and Farhad Soleimanian Gharehchopogh},
  doi          = {10.1111/coin.12397},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {176-209},
  shortjournal = {Comput. Intell.},
  title        = {A novel hybrid whale optimization algorithm with flower pollination algorithm for feature selection: Case study email spam detection},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Blood glucose level prediction for diabetes based on
modified fuzzy time series and particle swarm optimization.
<em>COIN</em>, <em>37</em>(1), 155–175. (<a
href="https://doi.org/10.1111/coin.12396">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blood glucose control is an essential goal for the patients who have Type-1 diabetes (T1D). The prediction of the blood glucose levels for the next 30-minute is crucial. If the predicted blood glucose level is in the critical ranges, and these predictions can be known in advance, then the patients can take the necessary cautions to prevent from it. In this article, we propose a modified fuzzy particle swarm optimization algorithm for the prediction of blood glucose levels of 30-minute after the last measurement. We form the average and patient-specific models to predict the blood glucose level of the patients. Both models are tested on two different datasets which contain patients with T1D. The experimental results are evaluated in terms of root mean squared error and Clarke error grid analysis metrics. The results indicate that our proposed modified algorithm is feasible to be applied to the prediction of blood glucose levels. In addition, this approach can assist patients with T1D for their blood glucose control.},
  archive      = {J_COIN},
  author       = {Hatice Nizam Ozogur and Gokhan Ozogur and Zeynep Orman},
  doi          = {10.1111/coin.12396},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {155-175},
  shortjournal = {Comput. Intell.},
  title        = {Blood glucose level prediction for diabetes based on modified fuzzy time series and particle swarm optimization},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Defending against child death: Deep learning-based diagnosis
method for abnormal identification of fetus ultrasound images.
<em>COIN</em>, <em>37</em>(1), 128–154. (<a
href="https://doi.org/10.1111/coin.12394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the most important industries which protect human from various diseases is the medical industry. Child death is a crucial concern that needs to concentrate on “save the children.” Abnormality of a child can be obtained by diagnosing the prenatal by ultrasound system within a specific period for providing better treatment to do “save the children.”. This article aimed to diagnose the (prenatal) ultrasound-images by design and implement a novel framework named Defending Against Child Death (DACD). The existing method is a semiautomatic method where it used convolutional neural network (CNN) algorithm for classifying ultrasound images. Real-time medical industry requires a fully automatic method for classifying the ultrasound images to save the human. Hence this article, includes deep learning by implementing five convolutional neural network architectures in an order where it learns, estimate, and confirms the fetus parameters. All the layers in the convolutional neural network extract and classify the different number of features in the ultrasound images automatically and provide a result. The increased number of hidden layers in the CNN can extract even the hidden features of the images. The extracted features are classified automatically and improve the accuracy of disease detection. To segment the fetus abdomen, U-Net architecture is included in the CNN with Hough transformation. The experiment is carried out using the CNN toolbox in MATLAB and the outcomes are verified. The performance of the DACD is assessed by comparing the results with the earlier researches. From the experimental results, it is obtained that the accuracy of DACD is 99.7%, which is higher than the results obtained from the existing machine learning approach.},
  archive      = {J_COIN},
  author       = {P. Deepika and R.M. Suresh and P. Pabitha},
  doi          = {10.1111/coin.12394},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {128-154},
  shortjournal = {Comput. Intell.},
  title        = {Defending against child death: Deep learning-based diagnosis method for abnormal identification of fetus ultrasound images},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A dictionary for translation from natural to formal data
model language. <em>COIN</em>, <em>37</em>(1), 87–127. (<a
href="https://doi.org/10.1111/coin.12393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper describes our current research activities and results related to developing knowledge-based systems to support the creation of entity-relationship (ER) models. The authors based obtaining an ER model in textual form on translation from one language into another, that is, from an English controlled natural language into the formalized language of an ER data model. Our translation method consisted of creating translation rules of sentential form parts into ER model constructs based on the textual and character patterns detected in the business descriptions. To enable the computer analyses necessary for creating translation mechanisms, we created a linguistic corpus that contains lists of the business descriptions and the texts of other business materials. From the corpus, we then created a specific dictionary and linguistic rules to automate the business descriptions&#39; translation into the ER data model language. Before that, however, the corpus was enriched by adding annotations to the words related to ER data model constructs. In this paper, we also present the main issues uncovered during the translation process and offer a possible solution with utility evaluation: applying information-extraction performance measures to a set of sentences from the corpus.},
  archive      = {J_COIN},
  author       = {Sabrina Šuman and Alen Jakupović and Mladen Marinac},
  doi          = {10.1111/coin.12393},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {87-127},
  shortjournal = {Comput. Intell.},
  title        = {A dictionary for translation from natural to formal data model language},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Handwritten meitei mayek recognition using three-channel
convolution neural network of gradients and gray. <em>COIN</em>,
<em>37</em>(1), 70–86. (<a
href="https://doi.org/10.1111/coin.12392">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The problem of searching a similar pattern is an exciting and challenging research field of pattern recognition. The intelligence of humans for vision to read is a crucial phenomenon for machine simulation and has been carried out for a few decades. Therefore, in this article, a recognition system of handwritten Meitei Mayek (Manipuri script) is introduced using a convolutional neural network. Generally, character recognition is performed using the gray scale of the image of characters. However, we have additionally considered the corresponding gradient direction and gradient magnitude images to create three-channels image for every character so that supplementary information from gradient images can be obtained for efficient recognition. Experiments are conducted on 14 700 sample images collected from various individuals of different age groups and educational backgrounds. A recognition rate of 98.70% is obtained, which is compared with the existing methods, and it is found to be superior performance than other neural network methods on Meitei Mayek.},
  archive      = {J_COIN},
  author       = {Sanasam Inunganbi and Prakash Choudhary and Khumanthem Manglem},
  doi          = {10.1111/coin.12392},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {70-86},
  shortjournal = {Comput. Intell.},
  title        = {Handwritten meitei mayek recognition using three-channel convolution neural network of gradients and gray},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Development of intuitionistic fuzzy special embedded
convolutional neural network for mammography enhancement. <em>COIN</em>,
<em>37</em>(1), 47–69. (<a
href="https://doi.org/10.1111/coin.12391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel mammogram enhancement approach using adaptive intuitionistic fuzzy special set (IFSS) with deep convolutional neural network (called MECNNIFS) for visual interpretation of mammography lesions, lumps, and abnormal cells in low-dose X-ray images. The proposed MECNNIFS scheme utilizes the membership grade modification by IFSS on low-dose X-ray images (mammography). The suggested model attempts to increase the underexposed and abnormal structural regions such as breast lesions, lumps, and nodules on the mammogram. The proposed algorithm initially separates mammograms using convolutional neural networks (CNNs) into foreground and background areas and then fuzzifies the image by intuitionistic fuzzy set theory. Low-level features of a mammogram of the adjacent part are integrated with CNN in pixel classification during the separation task stage to improve the performance. Hyperbolic regularization and hesitant score have been applied on fuzzy plane to quantify the uncertainty and fuzziness in spatial domain for the proposed contrast enhancement. Finally, an enhanced mammogram is acquired through the process of defuzzification. The results show better quality and performance for improvement of contrast and visual quality in mammograms compared with other state-of-the-art methods.},
  archive      = {J_COIN},
  author       = {Swarup Kr Ghosh and Biswajit Biswas and Anupam Ghosh},
  doi          = {10.1111/coin.12391},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {47-69},
  shortjournal = {Comput. Intell.},
  title        = {Development of intuitionistic fuzzy special embedded convolutional neural network for mammography enhancement},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Faults diagnosis of a centrifugal pump using multilayer
perceptron genetic algorithm back propagation and support vector machine
with discrete wavelet transform-based feature extraction. <em>COIN</em>,
<em>37</em>(1), 21–46. (<a
href="https://doi.org/10.1111/coin.12390">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a comparative study of two artificial intelligent systems, namely; Multilayer Perceptron (MLP) and support vector machine (SVM), to classify six fault conditions and the normal (nonfaulty) condition of a centrifugal pump. A hybrid training method for MLP is proposed for this work based on the combination of Back Propagation (BP) and Genetic Algorithm (GA). The two training algorithms are tested and compared separately as well. Features are extracted using Discrete Wavelet Transform (DWT), both approximations, details, and two mother wavelets were used to investigate their effectiveness on feature extraction. GA is also used to optimize the number of hidden layers and neurons of MLP. In this study, the feature extraction, GA-based hidden layers, neurons selection, training algorithm, and classification performance, based on the strengths and weaknesses of each method, are discussed. From the results obtained, it is observed that the DWT with both MLP-BP and SVM produces better classification rates and performances.},
  archive      = {J_COIN},
  author       = {Maamar Al Tobi and Geraint Bevan and Peter Wallace and David Harrison and Kenneth Eloghene Okedu},
  doi          = {10.1111/coin.12390},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {21-46},
  shortjournal = {Comput. Intell.},
  title        = {Faults diagnosis of a centrifugal pump using multilayer perceptron genetic algorithm back propagation and support vector machine with discrete wavelet transform-based feature extraction},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Evolutionary fuzzy-based gravitational search algorithm for
query optimization in crowdsourcing system to minimize cost and latency.
<em>COIN</em>, <em>37</em>(1), 2–20. (<a
href="https://doi.org/10.1111/coin.12382">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowdsourcing is an environment where a group of users collaborates together to exchange information and to find answers for complex problems (queries). Query optimization is the task of selecting the best query strategy with less cost associated with it. The crowdsourcing cost can be determined by selecting the best plan from the set of options available and the best plan considerably reduce the cost for the inquiry configuration. As one of the center tasks in information recovery, the investigation of top-k queries with crowdsourcing, to be specific group empowered top k inquiries is depicted. This issue is defined with three key variables, latency, money related expense, and nature of answers. The fundamental point is to plan a novel system that limits financial cost when the latency is compelled. In this article, we used a heuristic search algorithm named as Evolutionary Fuzzy-based Gravitational Search algorithm (EFGSA) that produces an optimal query feature selection results with minimizing cost and latency. EFGSA-based crowdsourcing framework gives a better balance between latency and cost while generating query plans. The performance analysis of proposed EFSGA for optimal query plan is evaluated in terms of running time, accuracy, monetary cost, and so on. From the experimental results, the proposed method achieved better results than other methods in our cost and latency model.},
  archive      = {J_COIN},
  author       = {N. Bhaskar and P. Mohan Kumar and J. Arokia Renjit},
  doi          = {10.1111/coin.12382},
  journal      = {Computational Intelligence},
  month        = {2},
  number       = {1},
  pages        = {2-20},
  shortjournal = {Comput. Intell.},
  title        = {Evolutionary fuzzy-based gravitational search algorithm for query optimization in crowdsourcing system to minimize cost and latency},
  volume       = {37},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
