<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>AIM_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="aim---41">AIM - 41</h2>
<ul>
<li><details>
<summary>
(2021). Looking back, looking ahead: Symbolic versus connectionist
AI. <em>AIM</em>, <em>42</em>(4), 83–85. (<a
href="https://doi.org/10.1609/aaai.12026">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The ongoing debate between symbolic and connectionist AI attends to some of the most fundamental issues in the field. In this column, I briefly review the evolution of the unfolding discussion. I also point out that there is a lot more to intelligence than the symbolic and connectionist views of AI.},
  archive      = {J_AIM},
  author       = {Ashok K. Goel},
  doi          = {10.1609/aaai.12026},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {83-85},
  shortjournal = {AI Mag.},
  title        = {Looking back, looking ahead: Symbolic versus connectionist AI},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Agents of exploration and discovery. <em>AIM</em>,
<em>42</em>(4), 72–82. (<a
href="https://doi.org/10.1609/aaai.12021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents have many applications in familiar situations, but they also have great potential to help us understand novel settings. In this paper, I propose a new challenge for the AI research community: developing embodied systems that not only explore new environments but also characterize them in scientific terms. Illustrative examples include autonomous rovers on planetary surfaces and unmanned vehicles on undersea missions. I review two relevant paradigms: robotic agents that explore unknown areas and computational systems that discover scientific models. In each case, I specify the problem, identify component functions, describe current abilities, and note remaining limitations. Finally, I discuss obstacles that the community must overcome before it can develop integrated agents of exploration and discovery.},
  archive      = {J_AIM},
  author       = {Pat Langley},
  doi          = {10.1609/aaai.12021},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {72-82},
  shortjournal = {AI Mag.},
  title        = {Agents of exploration and discovery},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Avoiding negative side effects due to incomplete knowledge
of AI systems. <em>AIM</em>, <em>42</em>(4), 62–71. (<a
href="https://doi.org/10.1609/aaai.12028">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Autonomous agents acting in the real-world often operate based on models that ignore certain aspects of the environment. The incompleteness of any given model – handcrafted or machine acquired – is inevitable due to practical limitations of any modeling technique for complex real-world settings. Due to the limited fidelity of its model, an agent&#39;s actions may have unexpected, undesirable consequences during execution. Learning to recognize and avoid such negative side effects (NSEs) of an agent&#39;s actions is critical to improve the safety and reliability of autonomous systems. Mitigating NSEs is an emerging research topic that is attracting increased attention due to the rapid growth in the deployment of AI systems and their broad societal impacts. This article provides a comprehensive overview of different forms of NSEs and the recent research efforts to address them. We identify key characteristics of NSEs, highlight the challenges in avoiding NSEs, and discuss recently developed approaches, contrasting their benefits and limitations. The article concludes with a discussion of open questions and suggestions for future research directions.},
  archive      = {J_AIM},
  author       = {Sandhya Saisubramanian and Shlomo Zilberstein and Ece Kamar},
  doi          = {10.1609/aaai.12028},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {62-71},
  shortjournal = {AI Mag.},
  title        = {Avoiding negative side effects due to incomplete knowledge of AI systems},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Do we need a hippocratic oath for artificial intelligence
scientists? <em>AIM</em>, <em>42</em>(4), 57–61. (<a
href="https://doi.org/10.1609/aaai.12022">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence (AI) has been beneficial for humanity, improving many human activities. However, there are now significant dangers that may increase when AI reaches a human level of intelligence or superintelligence. It is paramount to focus on ensuring that AI is designed in a manner that is robustly beneficial for humans. The ethics and personal responsibilities of AI scientists could play an important role in continuing the constructive use of AI in the future. Lessons can be learnt from the long and successful history of medical ethics. Therefore, a Hippocratic Oath for AI scientists may increase awareness of the potential lethal threats of AI, enhance efforts to develop safe and beneficial AI to prevent corrupt practices and manipulations and invigorate ethical codes. The Hippocratic Oath in medicine, using simple universal principles, is a basis of human ethics, and in an analogous way, the proposed oath for AI scientists could enhance morality beyond biological consciousness and spread ethics across the universe.},
  archive      = {J_AIM},
  author       = {Nikolaos M. Siafakas},
  doi          = {10.1609/aaai.12022},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {57-61},
  shortjournal = {AI Mag.},
  title        = {Do we need a hippocratic oath for artificial intelligence scientists?},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Feedback-based self-learning in large-scale conversational
AI agents. <em>AIM</em>, <em>42</em>(4), 43–56. (<a
href="https://doi.org/10.1609/aaai.12025">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Today, most of the large-scale conversational AI agents such as Alexa, Siri, or Google Assistant are built using manually annotated data to train the different components of the system including automatic speech recognition (ASR), natural language understanding (NLU), and entity resolution (ER). Typically, the accuracy of the machine learning models in these components are improved by manually transcribing and annotating data. As the scope of these systems increase to cover more scenarios and domains, manual annotation to improve the accuracy of these components becomes prohibitively costly and time consuming. In this paper, we propose a system that leverages customer/system interaction feedback signals to automate learning without any manual annotation. Users of these systems tend to modify a previous query in hopes of fixing an error in the previous turn to get the right results. These reformulations, which are often preceded by defective experiences caused by either errors in ASR, NLU, ER, or the application. In some cases, users may not properly formulate their requests (e.g., providing partial title of a song), but gleaning across a wider pool of users and sessions reveals the underlying recurrent patterns. Our proposed self-learning system automatically detects the errors, generates reformulations, and deploys fixes to the runtime system to correct different types of errors occurring in different components of the system. In particular, we propose leveraging an absorbing Markov Chain model as a collaborative filtering mechanism in a novel attempt to mine these patterns, and coupling it with a guardrail rewrite selection mechanism that reactively evaluates these fixes using feedback friction data. We show that our approach is highly scalable, and able to learn reformulations that reduce Alexa-user errors by pooling anonymized data across millions of customers. The proposed self-learning system achieves a win-loss ratio of 11.8 and effectively reduces the defect rate by more than 30 percent on utterance level reformulations in our production A/B tests. To the best of our knowledge, this is the first self-learning large-scale conversational AI system in production.},
  archive      = {J_AIM},
  author       = {Pragaash Ponnusamy and Alireza Roshan Ghias and Yi Yi and Benjamin Yao and Chenlei Guo and Ruhi Sarikaya},
  doi          = {10.1609/aaai.12025},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {43-56},
  shortjournal = {AI Mag.},
  title        = {Feedback-based self-learning in large-scale conversational AI agents},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the care and feeding of virtual assistants: Automating
conversation review with AI. <em>AIM</em>, <em>42</em>(4), 29–42. (<a
href="https://doi.org/10.1609/aaai.12024">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rise of intelligent virtual assistants (IVAs), there is a necessary rise in human effort to identify conversations containing misunderstood user inputs. These conversations uncover error in natural language understanding and help prioritize improvements to the IVA. As human analysis is time consuming and expensive, prioritizing the conversations where misunderstanding has likely occurred reduces costs and speeds IVA improvement. In addition, less conversations reviewed by humans mean less user data are exposed, increasing privacy. We describe Trace AI, a scalable system for automated conversation review based on the detection of conversational features that can identify potential mis-communications. Trace AI provides IVA designers with suggested actions to correct understanding errors, prioritizes areas of language model repair, and can automate the review of conversations. We discuss the system design and report its performance at identifying errors in IVA understanding compared to that of human reviewers. Trace AI has been commercially deployed for over 4 years and is responsible for significant savings in human annotation costs as well as accelerating the refinement cycle of deployed enterprise IVAs.},
  archive      = {J_AIM},
  author       = {Ian Beaver and Abdullah Mueen},
  doi          = {10.1609/aaai.12024},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {29-42},
  shortjournal = {AI Mag.},
  title        = {On the care and feeding of virtual assistants: Automating conversation review with AI},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Large scale multilingual sticker recommendation in messaging
apps. <em>AIM</em>, <em>42</em>(4), 16–28. (<a
href="https://doi.org/10.1609/aaai.12023">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stickers are popularly used while messaging to visually express nuanced thoughts. We describe a real-time sticker recommendation (SR) system. We decompose SR into two steps: predict the message that is likely to be sent, and substitute that message with an appropriate sticker. To address the challenges caused by transliteration of message from users&#39; native language to the Roman script, we learn message embeddings by employing character-level CNN in an unsupervised manner. We use them to cluster semantically similar messages. Next, we predict the message cluster instead of the message. Except for validation, our system does not require human labeled data, leading to a fully automatic tuning pipeline. We propose a hybrid message prediction model, which can easily run on low-end phones. We discuss message cluster to sticker mapping, addressing the multilingual needs of our users, automated tuning of the system and also propose a novel application of community detection algorithm. As of November 2020, our system contains 100k+ stickers, has been deployed for 15+ months, and is being used by millions of users.},
  archive      = {J_AIM},
  author       = {Abhishek Laddha and Mohamed Hanoosh and Debdoot Mukherjee and Parth Patwa and Ankur Narang},
  doi          = {10.1609/aaai.12023},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {16-28},
  shortjournal = {AI Mag.},
  title        = {Large scale multilingual sticker recommendation in messaging apps},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Will AI write scientific papers in the future? <em>AIM</em>,
<em>42</em>(4), 3–15. (<a
href="https://doi.org/10.1609/aaai.12027">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this presidential address, I would like to start with a personal reflection on the field and then share with you the research directions I am pursuing and my excitement about the future of AI. In my personal research to advance AI while advancing scientific discoveries, one question that I have been pondering for some years now is whether AI will write scientific papers in the future. I want to reflect on this question, and look back at the many accomplishments in our field that can make us very hopeful that the answer will be yes, and that it may happen sooner than we might expect.},
  archive      = {J_AIM},
  author       = {Yolanda Gil},
  doi          = {10.1609/aaai.12027},
  journal      = {AI Magazine},
  month        = {12},
  number       = {4},
  pages        = {3-15},
  shortjournal = {AI Mag.},
  title        = {Will AI write scientific papers in the future?},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Letter from the editors: AI magazine in the new era of AI.
<em>AIM</em>, <em>42</em>(3), 79–80. (<a
href="https://doi.org/10.1609/aimag.v42i3.18600">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  author       = {K. Brent Venable and Odd Erik Gundersen},
  doi          = {10.1609/aimag.v42i3.18600},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {79-80},
  shortjournal = {AI Mag.},
  title        = {Letter from the editors: AI magazine in the new era of AI},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Engagement during pandemic teaching: Report of the EAAI-21
panel on teaching online and blended AI courses. <em>AIM</em>,
<em>42</em>(3), 77–78. (<a
href="https://doi.org/10.1609/aimag.v42i3.15092">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three panelists, Ashok Goel, Ansaf Salleb-Aouissi and Mehran Sahami explain some of the tools and techniques they used to keep their students engaged during virtual instruction. The techniques include the desire to take one&#39;s passion for the learning materials to the virtual classroom, to ensure teacher presence, provide for cognitive engagement with the subject and facilitate social interactions. Finally, we learn about tools used to manage a large online course so as to move the many active learning exercises to the virtual classroom.},
  archive      = {J_AIM},
  author       = {Michael Wollowski},
  doi          = {10.1609/aimag.v42i3.15092},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {77-78},
  shortjournal = {AI Mag.},
  title        = {Engagement during pandemic teaching: Report of the EAAI-21 panel on teaching online and blended AI courses},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Betting on bets. <em>AIM</em>, <em>42</em>(3), 74–76. (<a
href="https://doi.org/10.1609/aimag.v42i3.15108">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The AI Bookie column documents highlights from AI Bets, an online forum for the creation of adjudicatable predictions about the future of AI. Since the column&#39;s inception 3 years ago, only a few scientific bets have been collected, despite universal approval around the idea of scientific betting. We hope to widen our reach with an additional first batch of seed bets that are of broad interest to the research community including AI bias, fifth sentence prediction, emotion regulation, big models, and fake news. For detailed guidelines and to place bets, visit sciencebets.org .},
  archive      = {J_AIM},
  author       = {Chris Welty and Praveen Paritosh and Kurt Bollacker},
  doi          = {10.1609/aimag.v42i3.15108},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {74-76},
  shortjournal = {AI Mag.},
  title        = {Betting on bets},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Summary report for the third international competition on
computational models of argumentation. <em>AIM</em>, <em>42</em>(3),
70–73. (<a href="https://doi.org/10.1609/aimag.v42i3.15109">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Third International Competition on Computational Models of Argumentation (ICCMA&#39;19) focused on reasoning tasks in abstract argumentation frameworks. Submitted solvers were tested on a selected collection of benchmark instances, including artificially generated argumentation frameworks and some frameworks formalizing real-world problems. This competition introduced two main novelties over the two previous editions: the first one is the use of the Docker platform for packaging the participating solvers into virtual “light” containers; the second novelty consists of a new track for dynamic frameworks.},
  archive      = {J_AIM},
  author       = {Stefano Bistarelli and Lars Kotthof and Francesco Santini and Carlo Taticchi},
  doi          = {10.1609/aimag.v42i3.15109},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {70-73},
  shortjournal = {AI Mag.},
  title        = {Summary report for the third international competition on computational models of argumentation},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recommending news in traditional media companies.
<em>AIM</em>, <em>42</em>(3), 55–69. (<a
href="https://doi.org/10.1609/aimag.v42i3.18146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of recommender systems in online news personalization has made it possible to tailor the news stream to the individual interests of each reader. Previous research on commercial recommender systems has emphasized their use in large-scale media houses and technology companies, and real-world experiments indicate substantial improvements of click rates and user satisfaction. It is less understood how smaller media houses are coping with this new technology, how the technology affects their business models, their editorial processes, and their news production in general. Here we report on the experiences from numerous Scandinavian media houses that have experimented with various recommender strategies and streamlined their news production to provide personalized news experiences. In addition to influencing the content and style of news stories and the working environment of journalists, the news recommender systems have been part of a profound digital transformation of the whole media industry. Interestingly, many media houses have found it undesirable to automate the entire recommendation process and look for approaches that combine automatic recommendations with editorial choices.},
  archive      = {J_AIM},
  author       = {Jon Atle Gulla and Rolf Dyrnes Svendsen and Lemei Zhang and Agnes Stenbom and Jørgen Frøland},
  doi          = {10.1609/aimag.v42i3.18146},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {55-69},
  shortjournal = {AI Mag.},
  title        = {Recommending news in traditional media companies},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Progress in recommender systems research: Crisis? What
crisis? <em>AIM</em>, <em>42</em>(3), 43–54. (<a
href="https://doi.org/10.1609/aimag.v42i3.18145">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Scholars in algorithmic recommender systems research have developed a largely standardized scientific method, where progress is claimed by showing that a new algorithm outperforms existing ones on or more accuracy measures. In theory, reproducing and thereby verifying such improvements is easy, as it merely involves the execution of the experiment code on the same data. However, as recent work shows, the reported progress is often only virtual, because of a number of issues related to (i) a lack of reproducibility, (ii) technical and theoretical flaws, and (iii) scholarship practices that are strongly prone to researcher biases. As a result, several recent works could show that the latest published algorithms actually do not outperform existing methods when evaluated independently. Despite these issues, we currently see no signs of a crisis, where researchers re-think their scientific method, but rather a situation of stagnation, where researchers continue to focus on the same topics. In this paper, we discuss these issues, analyze their potential underlying reasons, and outline a set of guidelines to ensure progress in recommender systems research.},
  archive      = {J_AIM},
  author       = {Paolo Cremonesi and Dietmar Jannach},
  doi          = {10.1609/aimag.v42i3.18145},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {43-54},
  shortjournal = {AI Mag.},
  title        = {Progress in recommender systems research: Crisis? what crisis?},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Human-centered recommender systems: Origins, advances,
challenges, and opportunities. <em>AIM</em>, <em>42</em>(3), 31–42. (<a
href="https://doi.org/10.1609/aimag.v42i3.18142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {From the earliest days of the field, Recommender Systems research and practice has struggled to balance and integrate approaches that focus on recommendation as a machine learning or missing-value problem with ones that focus on machine learning as a discovery tool and perhaps persuasion platform. In this article, we review 25 years of recommender systems research from a human-centered perspective, looking at the interface and algorithm studies that advanced our understanding of how system designs can be tailored to users objectives and needs. At the same time, we show how external factors, including commercialization and technology developments, have shaped research on human-centered recommender systems. We show how several unifying frameworks have helped developers and researchers alike incorporate thinking about user experience and human decision-making into their designs. We then review the challenges, and the opportunities, in today&#39;s recommenders, looking at how deep learning and optimization techniques can integrate with both interface designs and human performance statistics to improve recommender effectiveness and usefulness},
  archive      = {J_AIM},
  author       = {Joseph A. Konstan and Loren G. Terveen},
  doi          = {10.1609/aimag.v42i3.18142},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {31-42},
  shortjournal = {AI Mag.},
  title        = {Human-centered recommender systems: Origins, advances, challenges, and opportunities},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recommendations as treatments. <em>AIM</em>, <em>42</em>(3),
19–30. (<a href="https://doi.org/10.1609/aimag.v42i3.18141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, a new line of research has taken an interventional view of recommender systems, where recommendations are viewed as actions that the system takes to have a desired effect. This interventional view has led to the development of counterfactual inference techniques for evaluating and optimizing recommendation policies. This article explains how these techniques enable unbiased offline evaluation and learning despite biased data, and how they can inform considerations of fairness and equity in recommender systems.},
  archive      = {J_AIM},
  author       = {Thorsten Joachims and Ben London and Yi Su and Adith Swaminathan and Lequn Wang},
  doi          = {10.1609/aimag.v42i3.18141},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {19-30},
  shortjournal = {AI Mag.},
  title        = {Recommendations as treatments},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deep learning for recommender systems: A netflix case study.
<em>AIM</em>, <em>42</em>(3), 7–18. (<a
href="https://doi.org/10.1609/aimag.v42i3.18140">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning has profoundly impacted many areas of machine learning. However, it took a while for its impact to be felt in the field of recommender systems. In this article, we outline some of the challenges encountered and lessons learned in using deep learning for recommender systems at Netflix. We first provide an overview of the various recommendation tasks on the Netflix service. We found that different model architectures excel at different tasks. Even though many deep-learning models can be understood as extensions of existing (simple) recommendation algorithms, we initially did not observe significant improvements in performance over well-tuned non-deep-learning approaches. Only when we added numerous features of heterogeneous types to the input data, deep-learning models did start to shine in our setting. We also observed that deep-learning methods can exacerbate the problem of offline–online metric (mis-)alignment. After addressing these challenges, deep learning has ultimately resulted in large improvements to our recommendations as measured by both offline and online metrics. On the practical side, integrating deep-learning toolboxes in our system has made it faster and easier to implement and experiment with both deep-learning and non-deep-learning approaches for various recommendation tasks. We conclude this article by summarizing our take-aways that may generalize to other applications beyond Netflix.},
  archive      = {J_AIM},
  author       = {Harald Steck and Linas Baltrunas and Ehtsham Elahi and Dawen Liang and Yves Raimond and Justin Basilico},
  doi          = {10.1609/aimag.v42i3.18140},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {7-18},
  shortjournal = {AI Mag.},
  title        = {Deep learning for recommender systems: A netflix case study},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Recommender systems: Past, present, future. <em>AIM</em>,
<em>42</em>(3), 3–6. (<a
href="https://doi.org/10.1609/aimag.v42i3.18139">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The origins of modern recommender systems date back to the early 1990s when they were mainly applied experimentally to personal email and information filtering. Today, 30 years later, personalized recommendations are ubiquitous and research in this highly successful application area of AI is flourishing more than ever. Much of the research in the last decades was fueled by advances in machine learning technology. However, building a successful recommender system requires more than a clever general-purpose algorithm. It requires an in-depth understanding of the specifics of the application environment and the expected effects of the system on its users. Ultimately, making recommendations is a human-computer interaction problem, where a computerized system supports users in information search or decision-making contexts. This special issue contains a selection of papers reflecting this multi-faceted nature of the problem and puts open research challenges in recommender systems to the forefront. It features articles on the latest learning technology, reflects on the human-computer interaction aspects, reports on the use of recommender systems in practice, and it finally critically discusses our research methodology.},
  archive      = {J_AIM},
  author       = {Dietmar Jannach and Pearl Pu and Francesco Ricci and Markus Zanker},
  doi          = {10.1609/aimag.v42i3.18139},
  journal      = {AI Magazine},
  month        = {9},
  number       = {3},
  pages        = {3-6},
  shortjournal = {AI Mag.},
  title        = {Recommender systems: Past, present, future},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021a). Rethinking AI magazine again. <em>AIM</em>, <em>42</em>(2),
87–88. (<a href="https://doi.org/10.1609/aimag.v42i2.15110">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  author       = {Ashok Goel},
  doi          = {10.1609/aimag.v42i2.15110},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {87-88},
  shortjournal = {AI Mag.},
  title        = {Rethinking AI magazine again},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Considerations on creating conversational agents for
multiple environments and users. <em>AIM</em>, <em>42</em>(2), 71–86.
(<a href="https://doi.org/10.1609/aimag.v42i2.7484">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Advances in artificial intelligence algorithms and expansion of straightforward cloud-based platforms have enabled the adoption of conversational assistants by both, medium and large companies, to facilitate interaction between clients and employees. The interactions are possible through the use of ubiquitous devices (e.g., Amazon Echo, Apple HomePod, Google Nest), virtual assistants (e.g., Apple Siri, Google Assistant, Samsung Bixby, or Microsoft Cortana), chat windows on the corporate website, or social network applications (e.g. Facebook Messenger, Telegram, Slack, WeChat). Creating a useful, personalized conversational agent that is also robust and popular is nonetheless challenging work. It requires picking the right algorithm, framework, and/or communication channel, but perhaps more importantly, consideration of the specific task, user needs, environment, available training data, budget, and a thoughtful design. In this paper, we will consider the elements necessary to create a conversational agent for different types of users, environments, and tasks. The elements will account for the limited amount of data available for specific tasks within a company and for non-English languages. We are confident that we can provide a useful resource for the new practitioner developing an agent. We can point out novice problems/traps to avoid, create consciousness that the development of the technology is achievable despite comprehensive and significant challenges, and raise awareness about different ethical issues that may be associated with this technology. We have compiled our experience with deploying conversational systems for daily use in multicultural, multilingual, and intergenerational settings. Additionally, we will give insight on how to scale the proposed solutions.},
  archive      = {J_AIM},
  author       = {Javier Cebrián and Ramón Martínez and Natalia Rodríguez and Luis Fernando D&#39;Haro},
  doi          = {10.1609/aimag.v42i2.7484},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {71-86},
  shortjournal = {AI Mag.},
  title        = {Considerations on creating conversational agents for multiple environments and users},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Clarity 2.0: Improved assessment of product competitiveness
from online content. <em>AIM</em>, <em>42</em>(2), 59–70. (<a
href="https://doi.org/10.1609/aimag.v42i2.15100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Competitive analysis is a critical part of any business. Product managers, sellers, and marketers spend time and resources scouring through an immense amount of online and offline content, aiming to discover what their competitors are doing in the marketplace to understand what type of threat they pose to their business&#39; financial well-being. Currently, this process is time and labor-intensive, slow and costly. This paper presents Clarity , a data-driven unsupervised system for assessment of products, which is currently in deployment in the global technology company, IBM. Clarity has been running for more than a year and is used by over 4,500 people to perform over 200 competitive analyses involving over 1000 products. The system considers multiple factors from a collection of online content: numeric ratings by online users, sentiment of user generated online content for key product performance dimensions, content volume, and topic analysis of content. The results and explanations of factors leading to the results are visualized in an interactive dashboard that allows users to track their product&#39;s performance as well as understand main contributing factors. Its efficacy has been tested in a series of cases across IBM&#39;s portfolio which spans software, hardware, and services. After initial release and first year of use, improvements to the methodology were implemented to ensure it was relevant to and served the highest impact needs of target users. Moreover, new use cases leveraging the initial ideas and approaches continue to be explored.},
  archive      = {J_AIM},
  author       = {Yufeng Huang and Mariana Bernagozzi and Michelle Morales and Sheema Usmani and Biplav Srivastava and Michelle Mullins},
  doi          = {10.1609/aimag.v42i2.15100},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {59-70},
  shortjournal = {AI Mag.},
  title        = {Clarity 2.0: Improved assessment of product competitiveness from online content},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Improving search engine efficiency through contextual factor
selection. <em>AIM</em>, <em>42</em>(2), 50–58. (<a
href="https://doi.org/10.1609/aimag.v42i2.15099">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  author       = {Anxiang Zeng and Han Yu and Qing Da and Yusen Zhan and Yang Yu and Jingren Zhou and Chunyan Miao},
  doi          = {10.1609/aimag.v42i2.15099},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {50-58},
  shortjournal = {AI Mag.},
  title        = {Improving search engine efficiency through contextual factor selection},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Day-ahead forecasting of losses in the distribution network.
<em>AIM</em>, <em>42</em>(2), 38–49. (<a
href="https://doi.org/10.1609/aimag.v42i2.15097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Utility companies in the Nordics have to nominate how much electricity is expected to be lost in their power grid the next day. We present a commercially deployed machine learning system that automates this day-ahead nomination of the expected grid loss. It meets several practical constraints and issues related to, among other things, delayed, missing and incorrect data and a small data set. The system incorporates a total of 24 different models that performs forecasts for three sub-grids. Each day one model is selected for making the hourly day-ahead forecasts for each sub-grid. The deployed system reduced the mean average percentage error (MAPE) with 40% from 12.17 to 7.26 per hour from mid-July to mid-October, 2019. It is robust, flexible and reduces manual work. Recently, the system was deployed to forecast and nominate grid losses for two new grids belonging to a new customer. As the presented system is modular and adaptive, the integration was quick and needed minimal work. We have shared the grid loss data-set on Kaggle.},
  archive      = {J_AIM},
  author       = {Nisha Dalal and Martin Mølnå and Mette Herrem and Magne Røen and Odd Erik Gundersen},
  doi          = {10.1609/aimag.v42i2.15097},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {38-49},
  shortjournal = {AI Mag.},
  title        = {Day-ahead forecasting of losses in the distribution network},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Optimizing smart grid operations from the demand side.
<em>AIM</em>, <em>42</em>(2), 28–37. (<a
href="https://doi.org/10.1609/aimag.v42i2.15096">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As demand for electricity grows in China, the existing power grid is coming under increasing pressure. Expansion of power generation and delivery capacities across the country requires years of planning and construction. In the meantime, to ensure safe operation of the power grid, it is important to coordinate and optimize the demand side usage. In this paper, we report on our experience deploying an artificial intelligence (AI)–empowered demand-side management platform – the Power Intelligent Decision Support (PIDS) platform – in Shandong Province, China. It consists of three main components: 1) short-term power consumption gap prediction, 2) fine-grained Demand Response (DR) with optimal power adjustment planning, and 3) Orderly Power Utilization (OPU) recommendations to ensure stable operation while minimizing power disruptions and improving fair treatment of participating companies. PIDS has been deployed since August 2018. It is helping over 400 companies optimize their power usage through DR, while dynamically managing the OPU process for around 10,000 companies. Compared to the previous system, power outage under PIDS due to forced shutdown has been reduced from 16% to 0.56%.},
  archive      = {J_AIM},
  author       = {Yongqing Zheng and Han Yu and Yuliang Shi and Kun Zhang and Shuai Zhen and Lizhen Cui and Cyril Leung and Chunyan Miao},
  doi          = {10.1609/aimag.v42i2.15096},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {28-37},
  shortjournal = {AI Mag.},
  title        = {Optimizing smart grid operations from the demand side},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Federated learning-powered visual object detection for
safety monitoring. <em>AIM</em>, <em>42</em>(2), 19–27. (<a
href="https://doi.org/10.1609/aimag.v42i2.15095">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Visual object detection is an important artificial intelligence (AI) technique for safety monitoring applications. Current approaches for building visual object detection models require large and well-labeled dataset stored by a centralized entity. This not only poses privacy concerns under the General Data Protection Regulation (GDPR), but also incurs large transmission and storage overhead. Federated learning (FL) is a promising machine learning paradigm to address these challenges. In this paper, we report on FedVision —a machine learning engineering platform to support the development of federated learning powered computer vision applications—to bridge this important gap. The platform has been deployed through collaboration between WeBank and Extreme Vision to help customers develop computer vision-based safety monitoring solutions in smart city applications. Through actual usage, it has demonstrated significant efficiency improvement and cost reduction while fulfilling privacy-preservation requirements (e.g., reducing communication overhead for one company by 50 fold and saving close to 40,000RMB of network cost per annum). To the best of our knowledge, this is the first practical application of FL in computer vision-based tasks.},
  archive      = {J_AIM},
  author       = {Yang Liu and Anbu Huang and Yun Luo and He Huang and Youzhi Liu and Yuanyuan Chen and Lican Feng and Tianjian Chen and Han Yu and Qiang Yang},
  doi          = {10.1609/aimag.v42i2.15095},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {19-27},
  shortjournal = {AI Mag.},
  title        = {Federated learning-powered visual object detection for safety monitoring},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Deploying an artificial intelligence-based defect finder for
manufacturing quality management. <em>AIM</em>, <em>42</em>(2), 5–18.
(<a href="https://doi.org/10.1609/aimag.v42i2.15094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper describes how the Big Data Research Center of Kyung Hee University and Benple Inc. developed and deployed an artificial intelligence system to automate the quality management process for Frontec, an SME company that manufactures automobile parts. Various constraints, such as response time requirements and the limited computing resources available, needed to be considered in this project. Defect finders using large-scale images are expected to classify weld nuts within 0.2 s with an accuracy rate of over 95%. Our system uses Circular Hough Transform for preprocessing as well as an adjusted VGG (Visual Geometry Group) model. Our convolutional neural network (CNN) system shows an accuracy of over 99% and a response time of about 0.14 s. To embed the CNN model into the factory, we reimplemented the preprocessing modules using LabVIEW and had the classification model server communicate with an existing vision inspector. We share our lessons from this experience by explaining the procedure and real-world issues developing and embedding a deep learning framework in an existing manufacturing environment without implementing any hardware changes.},
  archive      = {J_AIM},
  author       = {Kyoung Jun Lee and Jun Woo Kwon and Soohong Min and Jungho Yoon},
  doi          = {10.1609/aimag.v42i2.15094},
  journal      = {AI Magazine},
  month        = {6},
  number       = {2},
  pages        = {5-18},
  shortjournal = {AI Mag.},
  title        = {Deploying an artificial intelligence-based defect finder for manufacturing quality management},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AAAI news: Spring news from the association for the
advancement of artificial intelligence. <em>AIM</em>, <em>42</em>(1),
101–107. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00019.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_AIM},
  doi          = {10.1002/j.2371-9621.2021.tb00019.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {101-107},
  shortjournal = {AI Mag.},
  title        = {AAAI news: Spring news from the association for the advancement of artificial intelligence},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021b). The association for the advancement of artificial
intelligence’s new award for the societal benefits of artificial
intelligence — an interview with richard tong. <em>AIM</em>,
<em>42</em>(1), 95–100. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00018.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this interview, conducted in early 2020 by Ashok Goel, Richard Tong, the chief architect and general manager of Squirrel AI Learning&#39;s US operations, discusses adaptive learning, challenges facing AI in education, and the Squirrel AI Award for Artificial Intelligence to Benefit Humanity.},
  archive      = {J_AIM},
  author       = {Ashok Goel},
  doi          = {10.1002/j.2371-9621.2021.tb00018.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {95-100},
  shortjournal = {AI Mag.},
  title        = {The association for the advancement of artificial intelligence&#39;s new award for the societal benefits of artificial intelligence — an interview with richard tong},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The role of open-source software in artificial intelligence.
<em>AIM</em>, <em>42</em>(1), 93–94. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00017.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With this publication, we launch a new column for AI Magazine on the role of open-source software in artificial intelligence. As the column editor, I would like to extend my welcome and invite AI Magazine readers to send short articles for future columns, which may appear in the traditional print version of AI Magazine, or on the AI Magazine interactive site currently under development. This introductory column serves to highlight my interests in open-source software and to propose a few topics for future columns.},
  archive      = {J_AIM},
  author       = {Jim Spohrer},
  doi          = {10.1002/j.2371-9621.2021.tb00017.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {93-94},
  shortjournal = {AI Mag.},
  title        = {The role of open-source software in artificial intelligence},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The case against registered reports. <em>AIM</em>,
<em>42</em>(1), 88–92. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00016.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Registered reports have been proposed as a way to move from eye-catching and surprising results and toward methodologically sound practices and interesting research questions. However, none of the top-twenty artificial intelligence journals support registered reports, and no traces of registered reports can be found in the field of artificial intelligence. Is this because they do not provide value for the type of research that is conducted in the field of artificial intelligence?},
  archive      = {J_AIM},
  author       = {Odd Erik Gundersen},
  doi          = {10.1002/j.2371-9621.2021.tb00016.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {88-92},
  shortjournal = {AI Mag.},
  title        = {The case against registered reports},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Advances in theory and applications of artificial
intelligence. <em>AIM</em>, <em>42</em>(1), 86–87. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00015.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 33rd International Conference on Industrial, Engineering, and Other Applications of Applied Intelligent Systems was held in Kitakyushu, Japan on 22 to 25 September 2020. This report provides an overview and summary of the conference.},
  archive      = {J_AIM},
  author       = {Hamido Fujita and Philippe Foumier-Viger and Jun Sasaki and Moonis Ali},
  doi          = {10.1002/j.2371-9621.2021.tb00015.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {86-87},
  shortjournal = {AI Mag.},
  title        = {Advances in theory and applications of artificial intelligence},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Report on the first and second workshops on hierarchical
planning held at the international conference on automated planning and
scheduling. <em>AIM</em>, <em>42</em>(1), 83–85. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00014.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical planning has attracted renewed interest in the last few years. Consequently, the time was right to establish a workshop devoted entirely to hierarchical planning — an insight shared by many supporters. In this article, we report on the first International Conference on Automated Planning and Scheduling workshop on hierarchical planning held in Delft, The Netherlands, in 2018 as well as on the second workshop held in Berkeley, CA, USA, in 2019.},
  archive      = {J_AIM},
  author       = {Pascal Bercher and Daniel Höller and Gregor Behnke and Susanne Biundo and Vikas Shivashankar and Ron Alford},
  doi          = {10.1002/j.2371-9621.2021.tb00014.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {83-85},
  shortjournal = {AI Mag.},
  title        = {Report on the first and second workshops on hierarchical planning held at the international conference on automated planning and scheduling},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Organizing a successful artificial intelligence online
conference: Lessons from the 13th symposium on combinatorial search.
<em>AIM</em>, <em>42</em>(1), 76–82. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00013.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The 13th Symposium on Combinatorial Search (SoCS) was held May 26 to 28, 2020. Originally scheduled to take place in Vienna, Austria, the symposium pivoted toward a fully online technical program in early March. As an in-person event, SoCS offers participants a diverse array of scholarly activities including technical talks (long and short), poster sessions, plenary sessions, a community meeting and, new for 2020, a Master Class tutorial program. This article describes challenges, approaches, and opportunities associated with adapting these many different activities to the online setting. We consider issues such as scheduling, dissemination, attendee interaction, and community engagement before, during, and after the event. In each case, we report on the approaches taken by SoCS, then give a post hoc analysis of their effectiveness and discuss how these decisions continue to impact the SoCS community in the days after SoCS 2020. This work will be of interest to organizers of similar conferences who may be considering the switch to an online format.},
  archive      = {J_AIM},
  author       = {Daniel Harabor and Mauro Vallati},
  doi          = {10.1002/j.2371-9621.2021.tb00013.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {76-82},
  shortjournal = {AI Mag.},
  title        = {Organizing a successful artificial intelligence online conference: Lessons from the 13th symposium on combinatorial search},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence’s grand challenges: Past, present,
and future. <em>AIM</em>, <em>42</em>(1), 61–75. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00012.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Innovative, bold initiatives that capture the imagination of researchers and system builders are often required to spur a field of science or technology forward. A vision for the future of artificial intelligence was laid out by Turing Award winner Raj Reddy in his 1988 Presidential address to the Association for the Advancement of Artificial Intelligence. It is time to provide an accounting of the progress that has been made in the field, over the last three decades, toward the challenge goals. While some tasks such as the world-champion chess machine were accomplished in short order, many others, such as self-replicating systems, require more focus and breakthroughs for completion. A new set of challenges for the current decade is also proposed, spanning the health, wealth, and wisdom spheres.},
  archive      = {J_AIM},
  author       = {Ganesh Mani},
  doi          = {10.1002/j.2371-9621.2021.tb00012.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {61-75},
  shortjournal = {AI Mag.},
  title        = {Artificial intelligence&#39;s grand challenges: Past, present, and future},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Using a machine learning tool to support high-stakes
decisions in child protection. <em>AIM</em>, <em>42</em>(1), 53–60. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00011.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine learning decision support tools have become popular in a range of social domains including healthcare, criminal justice, and child welfare. But the design of these tools often fails to consider the potentially complex interactions that happen between the tools and humans. This lack of human-centered design is one reason that so few tools are actually deployed, and even if they are, struggle to achieve impact. In this article we present the example of the Allegheny Family Screening Tool, a machine learning model used since 2016 to support hotline screening of child maltreatment referrals. We describe aspects of human-centered design that contributed to the successful deployment of this tool, including agency leadership and ownership, transparency by design, ethical oversight, community engagement, and social license. Finally, we identify potential next-steps to encourage greater integration of human-centered design into the development and implementation of machine learning decision support tools.},
  archive      = {J_AIM},
  author       = {Rhema Vaithianathan and Diana Benavides-Prado and Erin Dalton and Alexandra Chouldechova and Emily Putnam-Hornstein},
  doi          = {10.1002/j.2371-9621.2021.tb00011.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {53-60},
  shortjournal = {AI Mag.},
  title        = {Using a machine learning tool to support high-stakes decisions in child protection},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Machine learning techniques for accountability.
<em>AIM</em>, <em>42</em>(1), 47–52. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00010.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence systems have provided us with many everyday conveniences. We can easily search for information across millions of web-pages via text and voice. Paperwork processing is increasingly automated. Artificial intelligence systems flag potentially fraudulent credit-card transactions and filter our e-mail. Yet these artificial intelligence systems have also experienced significant failings. Across a range of applications, including loan approvals, disease severity scores, hiring algorithms, and face recognition, artificial-intelligence-based scoring systems have exhibited gender and racial bias. Self-driving cars have had serious accidents. As these systems become more prevalent, it is increasingly important that we identify the best ways to keep them accountable.},
  archive      = {J_AIM},
  author       = {Been Kim and Finale Doshi-Velez},
  doi          = {10.1002/j.2371-9621.2021.tb00010.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {47-52},
  shortjournal = {AI Mag.},
  title        = {Machine learning techniques for accountability},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial and human intelligence in mental health.
<em>AIM</em>, <em>42</em>(1), 39–46. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00009.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {While technology has dramatically changed medical practice, various aspects of mental health practice and diagnosis remain almost unchanged across decades. Here we argue that artificial intelligence — with its capacity to learn and infer from data the workings of the human mind — may rapidly change this scenario. However, this process will not happen without friction and will promote an explicit reflection of the overarching goals and foundational aspects of mental health. We suggest that the converse relation is also very likely to happen. The application of artificial intelligence to a field that relates to the foundations of what makes us human — our volition, our thoughts, our pains and pleasures — may shift artificial intelligence back to its earliest days, when it was mostly conceived of as a laboratory to explore the limits and possibilities of human intelligence.},
  archive      = {J_AIM},
  author       = {Mariano Sigman and Diego Fernandez Slezak and Lucas Drucaroff and Sidarta Ribeiro and Facundo Carrillo},
  doi          = {10.1002/j.2371-9621.2021.tb00009.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {39-46},
  shortjournal = {AI Mag.},
  title        = {Artificial and human intelligence in mental health},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Procedural democracy and electronic agents. <em>AIM</em>,
<em>42</em>(1), 30–38. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00008.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, firms offering political campaigning and fundraising services have claimed that artificial intelligence is used to maximize their clients&#39; interests. Numerous news reports suggest that artificial intelligence capacities have influenced high-profile voting events; publications decrying the threat posed to democratic procedures are proliferating. This article takes a skeptical view of such claims, with an argument in six sections. First, the received principles of procedural democracy in relation to voting events are outlined. Second, the kind of services in question are considered. Third, to what extent these services actually involve artificial intelligence is pondered. Fourth, how such technological capacities may bear upon the tenets of procedural democracy are raised. Fifth, it is argued that it is unlikely that those tenets are indeed significantly undermined in practice. And sixth, this article concludes by considering the implications of it being proven that such technological capacities do play a decisive role in voting events.},
  archive      = {J_AIM},
  author       = {Suman Gupta},
  doi          = {10.1002/j.2371-9621.2021.tb00008.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {30-38},
  shortjournal = {AI Mag.},
  title        = {Procedural democracy and electronic agents},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence community and self. <em>AIM</em>,
<em>42</em>(1), 25–29. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00007.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The means by which artificial intelligence systems will both interact and influence individuals and community are considered, with a description of current capabilities such as video analytics, agency, natural language processing, and online data analysis. Open research questions such as the roles of analogies, associative memory, and the grounding problem are discussed, with speculation presented regarding the possible ramification of this research agenda. Such topics will include how artificial intelligence and humanity might co-evolve; artificial creativity; and life without work.},
  archive      = {J_AIM},
  author       = {Peter Tu},
  doi          = {10.1002/j.2371-9621.2021.tb00007.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {25-29},
  shortjournal = {AI Mag.},
  title        = {Artificial intelligence community and self},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Artificial intelligence and the future of work: A proactive
strategy. <em>AIM</em>, <em>42</em>(1), 16–24. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00006.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One of the greatest challenges and opportunities of our time lies in harnessing the innovative potential of emerging technologies to help achieve a more prosperous and just society. Discussions of how to do so are at the center of debates over how artificial intelligence, machine learning, and associated tools might affect the future of work. In this article, I will outline a proactive strategy for addressing these issues.},
  archive      = {J_AIM},
  author       = {Thomas A. Kochan},
  doi          = {10.1002/j.2371-9621.2021.tb00006.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {16-24},
  shortjournal = {AI Mag.},
  title        = {Artificial intelligence and the future of work: A proactive strategy},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Rethinking the maturity of artificial intelligence in
safety-critical settings. <em>AIM</em>, <em>42</em>(1), 6–15. (<a
href="https://doi.org/10.1002/j.2371-9621.2021.tb00005.x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Artificial intelligence, in the form of machine learning, has the potential to transform many safety-critical applications such as those in transportation and healthcare. However, despite significant investment and impressive demonstrations, such technologies have struggled to live up to their promises. To this end, this article illustrates that machine learning fundamentally lacks the ability to leverage top-down reasoning, a critical element in safety-critical systems. This is especially important in situations where uncertainty can grow very quickly, requiring adaption to unknowns. This fundamental lack of contextual reasoning, combined with a lack of understanding of what constitutes maturity in artificial intelligence-embedded systems, has significantly contributed to the failures of these systems. Demonstrations where safety-critical artificial intelligence-enabled systems function as if they were almost operational should not be a substitute for testing. Instead, companies and regulatory agencies need to work together to develop clear criteria and certification protocols before such technologies are made publicly available.},
  archive      = {J_AIM},
  author       = {Mary L. Cummings},
  doi          = {10.1002/j.2371-9621.2021.tb00005.x},
  journal      = {AI Magazine},
  month        = {3},
  number       = {1},
  pages        = {6-15},
  shortjournal = {AI Mag.},
  title        = {Rethinking the maturity of artificial intelligence in safety-critical settings},
  volume       = {42},
  year         = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
