<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>IJRR_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="ijrr---78">IJRR - 78</h2>
<ul>
<li><details>
<summary>
(2021). Frequency modulation of body waves to improve performance of
sidewinding robots. <em>The International Journal of Robotics
Research</em>, <em>40</em>(12-14), 1547–1562. (<a
href="https://doi.org/10.1177/02783649211037715">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Sidewinding is a form of locomotion executed by certain snakes and has been reconstructed in limbless robots; the gait is beneficial because it is effective in diverse terrestrial environments. Sidewinding gaits are generated by coordination of horizontal and vertical traveling waves of body undulation: the horizontal wave largely sets the direction of sidewinding with respect to the body frame while the vertical traveling wave largely determines the contact pattern between the body and the environment. When the locomotor’s center of mass leaves the supporting polygon formed by the contact pattern, undesirable locomotor behaviors (such as unwanted turning or unstable oscillation of the body) can occur. In this article, we develop an approach to generate desired translation and turning by modulating the vertical wave. These modulations alter the distribution of body–environment contact patches and can stabilize configurations that were previously statically unstable. The approach first identifies the spatial frequency of the vertical wave that statically stabilizes the locomotor for a given horizontal wave. Then, using geometric mechanics tools, we design the coordination between body waves that produces the desired translation or rotation. We demonstrate the effectiveness of our technique in numerical simulations and on experiments with a 16-joint limbless robot locomoting on flat hard ground. Our scheme broadens the range of movements and behaviors accessible to sidewinding locomotors at low speeds, which can lead to limbless systems capable of traversing diverse terrain stably and/or rapidly.},
  archive  = {J},
  author   = {Baxi Chong and Tianyu Wang and Jennifer M. Rieser and Bo Lin and Abdul Kaba and Grigoriy Blekherman and Howie Choset and Daniel I. Goldman},
  doi      = {10.1177/02783649211037715},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1547-1562},
  title    = {Frequency modulation of body waves to improve performance of sidewinding robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Kimera: From SLAM to spatial perception with 3D dynamic
scene graphs. <em>The International Journal of Robotics Research</em>,
<em>40</em>(12-14), 1510–1546. (<a
href="https://doi.org/10.1177/02783649211056674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Humans are able to form a complex mental model of the environment they move in. This mental model captures geometric and semantic aspects of the scene, describes the environment at multiple levels of abstractions (e.g., objects, rooms, buildings), includes static and dynamic entities and their relations (e.g., a person is in a room at a given time). In contrast, current robots’ internal representations still provide a partial and fragmented understanding of the environment, either in the form of a sparse or dense set of geometric primitives (e.g., points, lines, planes, and voxels), or as a collection of objects. This article attempts to reduce the gap between robot and human perception by introducing a novel representation, a 3D dynamic scene graph (DSG), that seamlessly captures metric and semantic aspects of a dynamic environment. A DSG is a layered graph where nodes represent spatial concepts at different levels of abstraction, and edges represent spatiotemporal relations among nodes. Our second contribution is Kimera , the first fully automatic method to build a DSG from visual–inertial data. Kimera includes accurate algorithms for visual–inertial simultaneous localization and mapping (SLAM), metric–semantic 3D reconstruction, object localization, human pose and shape estimation, and scene parsing. Our third contribution is a comprehensive evaluation of Kimera in real-life datasets and photo-realistic simulations, including a newly released dataset, uHumans2 , which simulates a collection of crowded indoor and outdoor scenes. Our evaluation shows that Kimera achieves competitive performance in visual–inertial SLAM, estimates an accurate 3D metric–semantic mesh model in real-time, and builds a DSG of a complex indoor environment with tens of objects and humans in minutes. Our final contribution is to showcase how to use a DSG for real-time hierarchical semantic path-planning. The core modules in Kimera have been released open source.},
  archive  = {J},
  author   = {Antoni Rosinol and Andrew Violette and Marcus Abate and Nathan Hughes and Yun Chang and Jingnan Shi and Arjun Gupta and Luca Carlone},
  doi      = {10.1177/02783649211056674},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1510-1546},
  title    = {Kimera: From SLAM to spatial perception with 3D dynamic scene graphs},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Self-supervised learning for using overhead imagery as maps
in outdoor range sensor localization. <em>The International Journal of
Robotics Research</em>, <em>40</em>(12-14), 1488–1509. (<a
href="https://doi.org/10.1177/02783649211045736">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Traditional approaches to outdoor vehicle localization assume a reliable, prior map is available, typically built using the same sensor suite as the on-board sensors used during localization. This work makes a different assumption. It assumes that an overhead image of the workspace is available and utilizes that as a map for use for range-based sensor localization by a vehicle. Here, range-based sensors are radars and lidars. Our motivation is simple, off-the-shelf, publicly available overhead imagery such as Google satellite images can be a ubiquitous, cheap, and powerful tool for vehicle localization when a usable prior sensor map is unavailable, inconvenient, or expensive. The challenge to be addressed is that overhead images are clearly not directly comparable to data from ground range sensors because of their starkly different modalities. We present a learned metric localization method that not only handles the modality difference, but is also cheap to train, learning in a self-supervised fashion without requiring metrically accurate ground truth. By evaluating across multiple real-world datasets, we demonstrate the robustness and versatility of our method for various sensor configurations in cross-modality localization, achieving localization errors on-par with a prior supervised approach while requiring no pixel-wise aligned ground truth for supervision at training. We pay particular attention to the use of millimeter-wave radar, which, owing to its complex interaction with the scene and its immunity to weather and lighting conditions, makes for a compelling and valuable use case.},
  archive  = {J},
  author   = {Tim Y. Tang and Daniele De Martini and Shangzhe Wu and Paul Newman},
  doi      = {10.1177/02783649211045736},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1488-1509},
  title    = {Self-supervised learning for using overhead imagery as maps in outdoor range sensor localization},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Interpreting and predicting tactile signals for the SynTouch
BioTac. <em>The International Journal of Robotics Research</em>,
<em>40</em>(12-14), 1467–1487. (<a
href="https://doi.org/10.1177/02783649211047634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the human hand, high-density contact information provided by afferent neurons is essential for many human grasping and manipulation capabilities. In contrast, robotic tactile sensors, including the state-of-the-art SynTouch BioTac, are typically used to provide low-density contact information, such as contact location, center of pressure, and net force. Although useful, these data do not convey or leverage the rich information content that some tactile sensors naturally measure. This research extends robotic tactile sensing beyond reduced-order models through (1) the automated creation of a precise experimental tactile dataset for the BioTac over a diverse range of physical interactions, (2) a 3D finite-element (FE) model of the BioTac, which complements the experimental dataset with high-density, distributed contact data, (3) neural-network-based mappings from raw BioTac signals to not only low-dimensional experimental data, but also high-density FE deformation fields, and (4) mappings from the FE deformation fields to the raw signals themselves. The high-density data streams can provide a far greater quantity of interpretable information for grasping and manipulation algorithms than previously accessible. Datasets, CAD files for the experimental testbed, FE model files, and videos are available at https://sites.google.com/nvidia.com/tactiledata .},
  archive  = {J},
  author   = {Yashraj S. Narang and Balakumar Sundaralingam and Karl Van Wyk and Arsalan Mousavian and Dieter Fox},
  doi      = {10.1177/02783649211047634},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1467-1487},
  title    = {Interpreting and predicting tactile signals for the SynTouch BioTac},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning to solve sequential physical reasoning problems
from a scene image. <em>The International Journal of Robotics
Research</em>, <em>40</em>(12-14), 1435–1466. (<a
href="https://doi.org/10.1177/02783649211056967">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this article, we propose deep visual reasoning, which is a convolutional recurrent neural network that predicts discrete action sequences from an initial scene image for sequential manipulation problems that arise, for example, in task and motion planning (TAMP). Typical TAMP problems are formalized by combining reasoning on a symbolic, discrete level (e.g., first-order logic) with continuous motion planning such as nonlinear trajectory optimization. The action sequences represent the discrete decisions on a symbolic level, which, in turn, parameterize a nonlinear trajectory optimization problem. Owing to the great combinatorial complexity of possible discrete action sequences, a large number of optimization/motion planning problems have to be solved to find a solution, which limits the scalability of these approaches. To circumvent this combinatorial complexity, we introduce deep visual reasoning: based on a segmented initial image of the scene, a neural network directly predicts promising discrete action sequences such that ideally only one motion planning problem has to be solved to find a solution to the overall TAMP problem. Our method generalizes to scenes with many and varying numbers of objects, although being trained on only two objects at a time. This is possible by encoding the objects of the scene and the goal in (segmented) images as input to the neural network, instead of a fixed feature vector. We show that the framework can not only handle kinematic problems such as pick-and-place (as typical in TAMP), but also tool-use scenarios for planar pushing under quasi-static dynamic models. Here, the image-based representation enables generalization to other shapes than during training. Results show runtime improvements of several orders of magnitudes by, in many cases, removing the need to search over the discrete action sequences.},
  archive  = {J},
  author   = {Danny Driess and Jung-Su Ha and Marc Toussaint},
  doi      = {10.1177/02783649211056967},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1435-1466},
  title    = {Learning to solve sequential physical reasoning problems from a scene image},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Concept2Robot: Learning manipulation concepts from
instructions and human demonstrations. <em>The International Journal of
Robotics Research</em>, <em>40</em>(12-14), 1419–1434. (<a
href="https://doi.org/10.1177/02783649211046285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We aim to endow a robot with the ability to learn manipulation concepts that link natural language instructions to motor skills. Our goal is to learn a single multi-task policy that takes as input a natural language instruction and an image of the initial scene and outputs a robot motion trajectory to achieve the specified task. This policy has to generalize over different instructions and environments. Our insight is that we can approach this problem through learning from demonstration by leveraging large-scale video datasets of humans performing manipulation actions. Thereby, we avoid more time-consuming processes such as teleoperation or kinesthetic teaching. We also avoid having to manually design task-specific rewards. We propose a two-stage learning process where we first learn single-task policies through reinforcement learning. The reward is provided by scoring how well the robot visually appears to perform the task. This score is given by a video-based action classifier trained on a large-scale human activity dataset. In the second stage, we train a multi-task policy through imitation learning to imitate all the single-task policies. In extensive simulation experiments, we show that the multi-task policy learns to perform a large percentage of the 78 different manipulation tasks on which it was trained. The tasks are of greater variety and complexity than previously considered robot manipulation tasks. We show that the policy generalizes over variations of the environment. We also show examples of successful generalization over novel but similar instructions.},
  archive  = {J},
  author   = {Lin Shao and Toki Migimatsu and Qiang Zhang and Karen Yang and Jeannette Bohg},
  doi      = {10.1177/02783649211046285},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1419-1434},
  title    = {Concept2Robot: Learning manipulation concepts from instructions and human demonstrations},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Systematic object-invariant in-hand manipulation via
reconfigurable underactuation: Introducing the RUTH gripper. <em>The
International Journal of Robotics Research</em>, <em>40</em>(12-14),
1402–1418. (<a href="https://doi.org/10.1177/02783649211048929">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We introduce a reconfigurable underactuated robot hand able to perform systematic prehensile in-hand manipulations regardless of object size or shape. The hand utilizes a two-degree-of-freedom five-bar linkage as the palm of the gripper, with three three-phalanx underactuated fingers, jointly controlled by a single actuator, connected to the mobile revolute joints of the palm. Three actuators are used in the robot hand system in total, one for controlling the force exerted on objects by the fingers through an underactuated tendon system, and two for changing the configuration of the palm and, thus, the positioning of the fingers. This novel layout allows decoupling grasping and manipulation, facilitating the planning and execution of in-hand manipulation operations. The reconfigurable palm provides the hand with a large grasping versatility, and allows easy computation of a map between task space and joint space for manipulation based on distance-based linkage kinematics. The motion of objects of different sizes and shapes from one pose to another is then straightforward and systematic, provided the objects are kept grasped. This is guaranteed independently and passively by the underactuated fingers using a custom tendon routing method, which allows no tendon length variation when the relative finger base positions change with palm reconfigurations. We analyze the theoretical grasping workspace and grasping and manipulation capability of the hand, present algorithms for computing the manipulation map and in-hand manipulation planning, and evaluate all these experimentally. Numerical and empirical results of several manipulation trajectories with objects of different size and shape clearly demonstrate the viability of the proposed concept.},
  archive  = {J},
  author   = {Qiujie Lu and Nicholas Baron and Angus B. Clark and Nicolas Rojas},
  doi      = {10.1177/02783649211048929},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1402-1418},
  title    = {Systematic object-invariant in-hand manipulation via reconfigurable underactuation: Introducing the RUTH gripper},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Cable manipulation with a tactile-reactive gripper. <em>The
International Journal of Robotics Research</em>, <em>40</em>(12-14),
1385–1401. (<a href="https://doi.org/10.1177/02783649211027233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Cables are complex, high-dimensional, and dynamic objects. Standard approaches to manipulate them often rely on conservative strategies that involve long series of very slow and incremental deformations, or various mechanical fixtures such as clamps, pins, or rings. We are interested in manipulating freely moving cables, in real time, with a pair of robotic grippers, and with no added mechanical constraints. The main contribution of this paper is a perception and control framework that moves in that direction, and uses real-time tactile feedback to accomplish the task of following a dangling cable. The approach relies on a vision-based tactile sensor, GelSight, that estimates the pose of the cable in the grip, and the friction forces during cable sliding. We achieve the behavior by combining two tactile-based controllers: (1) cable grip controller, where a PD controller combined with a leaky integrator regulates the gripping force to maintain the frictional sliding forces close to a suitable value; and (2) cable pose controller, where an linear–quadratic regulator controller based on a learned linear model of the cable sliding dynamics keeps the cable centered and aligned on the fingertips to prevent the cable from falling from the grip. This behavior is possible with the use of reactive gripper fitted with GelSight-based high-resolution tactile sensors. The robot can follow 1 m of cable in random configurations within two to three hand regrasps, adapting to cables of different materials and thicknesses. We demonstrate a robot grasping a headphone cable, sliding the fingers to the jack connector, and inserting it. To the best of the authors’ knowledge, this is the first implementation of real-time cable following without the aid of mechanical fixtures. Videos are available at http://gelsight.csail.mit.edu/cable/},
  archive  = {J},
  author   = {Yu She and Shaoxiong Wang and Siyuan Dong and Neha Sunil and Alberto Rodriguez and Edward Adelson},
  doi      = {10.1177/02783649211027233},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1385-1401},
  title    = {Cable manipulation with a tactile-reactive gripper},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Provably constant-time planning and replanning for real-time
grasping objects off a conveyor belt. <em>The International Journal of
Robotics Research</em>, <em>40</em>(12-14), 1370–1384. (<a
href="https://doi.org/10.1177/02783649211027194">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In warehouse and manufacturing environments, manipulation platforms are frequently deployed at conveyor belts to perform pick-and-place tasks. Because objects on the conveyor belts are moving, robots have limited time to pick them up. This brings the requirement for fast and reliable motion planners that could provide provable real-time planning guarantees, which the existing algorithms do not provide. In addition to the planning efficiency, the success of manipulation tasks relies heavily on the accuracy of the perception system which is often noisy, especially if the target objects are perceived from a distance. For fast-moving conveyor belts, the robot cannot wait for a perfect estimate before it starts executing its motion. In order to be able to reach the object in time, it must start moving early on (relying on the initial noisy estimates) and adjust its motion on-the-fly in response to the pose updates from perception. We propose a planning framework that meets these requirements by providing provable constant-time planning and replanning guarantees. To this end, we first introduce and formalize a new class of algorithms called constant-time motion planning (CTMP) algorithms that guarantee to plan in constant time and within a user-defined time bound. We then present our planning framework for grasping objects off a conveyor belt as an instance of the CTMP class of algorithms. We present it, provide its analytical properties, and perform an experimental analysis both in simulation and on a real robot.},
  archive  = {J},
  author   = {Fahad Islam and Oren Salzman and Aditya Agarwal and Maxim Likhachev},
  doi      = {10.1177/02783649211027194},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1370-1384},
  title    = {Provably constant-time planning and replanning for real-time grasping objects off a conveyor belt},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Multi-fidelity black-box optimization for time-optimal
quadrotor maneuvers. <em>The International Journal of Robotics
Research</em>, <em>40</em>(12-14), 1352–1369. (<a
href="https://doi.org/10.1177/02783649211033317">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We consider the problem of generating a time-optimal quadrotor trajectory for highly maneuverable vehicles, such as quadrotor aircraft. The problem is challenging because the optimal trajectory is located on the boundary of the set of dynamically feasible trajectories. This boundary is hard to model as it involves limitations of the entire system, including complex aerodynamic and electromechanical phenomena, in agile high-speed flight. In this work, we propose a multi-fidelity Bayesian optimization framework that models the feasibility constraints based on analytical approximation, numerical simulation, and real-world flight experiments. By combining evaluations at different fidelities, trajectory time is optimized while the number of costly flight experiments is kept to a minimum. The algorithm is thoroughly evaluated for the trajectory generation problem in two different scenarios: (1) connecting predetermined waypoints; (2) planning in obstacle-rich environments. For each scenario, we conduct both simulation and real-world flight experiments at speeds up to 11 m/s. Resulting trajectories were found to be significantly faster than those obtained through minimum-snap trajectory planning.},
  archive  = {J},
  author   = {Gilhyun Ryou and Ezra Tal and Sertac Karaman},
  doi      = {10.1177/02783649211033317},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1352-1369},
  title    = {Multi-fidelity black-box optimization for time-optimal quadrotor maneuvers},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Task space adaptation via the learning of gait controllers
of magnetic soft millirobots. <em>The International Journal of Robotics
Research</em>, <em>40</em>(12-14), 1331–1351. (<a
href="https://doi.org/10.1177/02783649211021869">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Untethered small-scale soft robots have promising applications in minimally invasive surgery, targeted drug delivery, and bioengineering applications as they can directly and non-invasively access confined and hard-to-reach spaces in the human body. For such potential biomedical applications, the adaptivity of the robot control is essential to ensure the continuity of the operations, as task environment conditions show dynamic variations that can alter the robot’s motion and task performance. The applicability of the conventional modeling and control methods is further limited for soft robots at the small-scale owing to their kinematics with virtually infinite degrees of freedom, inherent stochastic variability during fabrication, and changing dynamics during real-world interactions. To address the controller adaptation challenge to dynamically changing task environments, we propose using a probabilistic learning approach for a millimeter-scale magnetic walking soft robot using Bayesian optimization (BO) and Gaussian processes (GPs). Our approach provides a data-efficient learning scheme by finding the gait controller parameters while optimizing the stride length of the walking soft millirobot using a small number of physical experiments. To demonstrate the controller adaptation, we test the walking gait of the robot in task environments with different surface adhesion and roughness, and medium viscosity, which aims to represent the possible conditions for future robotic tasks inside the human body. We further utilize the transfer of the learned GP parameters among different task spaces and robots and compare their efficacy on the improvement of data-efficient controller learning.},
  archive  = {J},
  author   = {Sinan O. Demir and Utku Culha and Alp C. Karacakol and Abdon Pena-Francesch and Sebastian Trimpe and Metin Sitti},
  doi      = {10.1177/02783649211021869},
  journal  = {The International Journal of Robotics Research},
  month    = {12},
  number   = {12-14},
  pages    = {1331-1351},
  title    = {Task space adaptation via the learning of gait controllers of magnetic soft millirobots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robotics: Science and systems (RSS) 2020. <em>The
International Journal of Robotics Research</em>, <em>40</em>(12-14),
1329–1330. (<a href="https://doi.org/10.1177/02783649211052346">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Thrishantha Nanayakkara and Tim Barfoot and Thomas Howard},
  doi     = {10.1177/02783649211052346},
  journal = {The International Journal of Robotics Research},
  month   = {12},
  number  = {12-14},
  pages   = {1329-1330},
  title   = {Robotics: Science and systems (RSS) 2020},
  volume  = {40},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sequential robot imitation learning from observations.
<em>The International Journal of Robotics Research</em>,
<em>40</em>(10-11), 1306–1325. (<a
href="https://doi.org/10.1177/02783649211032721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents a framework to learn the sequential structure in the demonstrations for robot imitation learning. We first present a family of task-parameterized hidden semi-Markov models that extracts invariant segments (also called sub-goals or options) from demonstrated trajectories, and optimally follows the sampled sequence of states from the model with a linear quadratic tracking controller. We then extend the concept to learning invariant segments from visual observations that are sequenced together for robot imitation. We present Motion2Vec that learns a deep embedding space by minimizing a metric learning loss in a Siamese network: images from the same action segment are pulled together while being pushed away from randomly sampled images of other segments, and a time contrastive loss is used to preserve the temporal ordering of the images. The trained embeddings are segmented with a recurrent neural network, and subsequently used for decoding the end-effector pose of the robot. We first show its application to a pick-and-place task with the Baxter robot while avoiding a moving obstacle from four kinesthetic demonstrations only, followed by suturing task imitation from publicly available suturing videos of the JIGSAWS dataset with state-of-the-art 85 . 5 % segmentation accuracy and 0 . 94 cm error in position per observation on the test set.},
  archive  = {J},
  author   = {Ajay Kumar Tanwani and Andy Yan and Jonathan Lee and Sylvain Calinon and Ken Goldberg},
  doi      = {10.1177/02783649211032721},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1306-1325},
  title    = {Sequential robot imitation learning from observations},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Dynamic regret convergence analysis and an adaptive
regularization algorithm for on-policy robot imitation learning. <em>The
International Journal of Robotics Research</em>, <em>40</em>(10-11),
1284–1305. (<a href="https://doi.org/10.1177/0278364920985879">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {On-policy imitation learning algorithms such as DAgger evolve a robot control policy by executing it, measuring performance (loss), obtaining corrective feedback from a supervisor, and generating the next policy. As the loss between iterations can vary unpredictably, a fundamental question is under what conditions this process will eventually achieve a converged policy. If one assumes the underlying trajectory distribution is static (stationary), it is possible to prove convergence for DAgger. However, in more realistic models for robotics, the underlying trajectory distribution is dynamic because it is a function of the policy. Recent results show it is possible to prove convergence of DAgger when a regularity condition on the rate of change of the trajectory distributions is satisfied. In this article, we reframe this result using dynamic regret theory from the field of online optimization and show that dynamic regret can be applied to any on-policy algorithm to analyze its convergence and optimality. These results inspire a new algorithm, Adaptive On-Policy Regularization ( Aor ), that ensures the conditions for convergence. We present simulation results with cart–pole balancing and locomotion benchmarks that suggest Aor can significantly decrease dynamic regret and chattering as the robot learns. To the best of the authors’ knowledge, this is the first application of dynamic regret theory to imitation learning.},
  archive  = {J},
  author   = {Jonathan N. Lee and Michael Laskey and Ajay Kumar Tanwani and Anil Aswani and Ken Goldberg},
  doi      = {10.1177/0278364920985879},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1284-1305},
  title    = {Dynamic regret convergence analysis and an adaptive regularization algorithm for on-policy robot imitation learning},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning constraints from demonstrations with grid and
parametric representations. <em>The International Journal of Robotics
Research</em>, <em>40</em>(10-11), 1255–1283. (<a
href="https://doi.org/10.1177/02783649211035177">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We extend the learning from demonstration paradigm by providing a method for learning unknown constraints shared across tasks, using demonstrations of the tasks, their cost functions, and knowledge of the system dynamics and control constraints. Given safe demonstrations, our method uses hit-and-run sampling to obtain lower cost, and thus unsafe, trajectories. Both safe and unsafe trajectories are used to obtain a consistent representation of the unsafe set via solving an integer program. Our method generalizes across system dynamics and learns a guaranteed subset of the constraint. In addition, by leveraging a known parameterization of the constraint, we modify our method to learn parametric constraints in high dimensions. We also provide theoretical analysis on what subset of the constraint and safe set can be learnable from safe demonstrations. We demonstrate our method on linear and nonlinear system dynamics, show that it can be modified to work with suboptimal demonstrations, and that it can also be used to learn constraints in a feature space.},
  archive  = {J},
  author   = {Glen Chou and Dmitry Berenson and Necmiye Ozay},
  doi      = {10.1177/02783649211035177},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1255-1283},
  title    = {Learning constraints from demonstrations with grid and parametric representations},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hamiltonian coordination primitives for decentralized
multiagent navigation. <em>The International Journal of Robotics
Research</em>, <em>40</em>(10-11), 1234–1254. (<a
href="https://doi.org/10.1177/02783649211037731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We focus on decentralized navigation among multiple non-communicating agents in continuous domains without explicit traffic rules, such as sidewalks, hallways, or squares. Following collision-free motion in such domains requires effective mechanisms of multiagent behavior prediction. Although this prediction problem can be shown to be NP-hard, humans are often capable of solving it efficiently by leveraging sophisticated mechanisms of implicit coordination. Inspired by the human paradigm, we propose a novel topological formalism that explicitly models multiagent coordination. Our formalism features both geometric and algebraic descriptions enabling the use of standard gradient-based optimization techniques for trajectory generation but also symbolic inference over coordination strategies. In this article, we contribute (a) HCP (Hamiltonian Coordination Primitives), a novel multiagent trajectory-generation pipeline that accommodates spatiotemporal constraints formulated as symbolic topological specifications corresponding to a desired coordination strategy; (b) HCPnav, an online planning framework for decentralized collision avoidance that generates motion by following multiagent trajectory primitives corresponding to high-likelihood, low-cost coordination strategies. Through a series of challenging trajectory-generation experiments, we show that HCP outperforms a trajectory-optimization baseline in generating trajectories of desired topological specifications in terms of success rate and computational efficiency. Finally, through a variety of navigation experiments, we illustrate the efficacy of HCPnav in handling challenging multiagent navigation scenarios under homogeneous or heterogeneous agents across a series of environments of different geometry.},
  archive  = {J},
  author   = {Christoforos Mavrogiannis and Ross A. Knepper},
  doi      = {10.1177/02783649211037731},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1234-1254},
  title    = {Hamiltonian coordination primitives for decentralized multiagent navigation},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A resource-aware approach to collaborative loop-closure
detection with provable performance guarantees. <em>The International
Journal of Robotics Research</em>, <em>40</em>(10-11), 1212–1233. (<a
href="https://doi.org/10.1177/0278364920948594">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper presents resource-aware algorithms for distributed inter-robot loop-closure detection for applications such as collaborative simultaneous localization and mapping (CSLAM) and distributed image retrieval. In real-world scenarios, this process is resource-intensive as it involves exchanging many observations and geometrically verifying a large number of potential matches. This poses severe challenges for small-size and low-cost robots with various operational and resource constraints that limit, e.g., energy consumption, communication bandwidth, and computation capacity. This paper proposes a framework in which robots first exchange compact queries to identify a set of potential loop closures. We then seek to select a subset of potential inter-robot loop closures for geometric verification that maximizes a monotone submodular performance metric without exceeding budgets on computation (number of geometric verifications) and communication (amount of exchanged data for geometric verification). We demonstrate that this problem is, in general, NP-hard, and present efficient approximation algorithms with provable a priori performance guarantees. The proposed framework is extensively evaluated on real and synthetic datasets. A natural convex relaxation scheme is also presented to certify the near-optimal performance of the proposed framework a posteriori.},
  archive  = {J},
  author   = {Yulun Tian and Kasra Khosoussi and Jonathan P How},
  doi      = {10.1177/0278364920948594},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1212-1233},
  title    = {A resource-aware approach to collaborative loop-closure detection with provable performance guarantees},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A visibility-based approach to computing non-deterministic
bouncing strategies. <em>The International Journal of Robotics
Research</em>, <em>40</em>(10-11), 1196–1211. (<a
href="https://doi.org/10.1177/0278364921992788">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Inspired by motion patterns of some commercially available mobile robots, we investigate the power of robots that move forward in straight lines until colliding with an environment boundary, at which point they can rotate in place and move forward again; we visualize this as the robot “bouncing” off boundaries. We define bounce rules governing how the robot should reorient after reaching a boundary, such as reorienting relative to its heading prior to collision, or relative to the normal of the boundary. We then generate plans as sequences of rules, using the bounce visibility graph generated from a polygonal environment definition, while assuming we have unavoidable non-determinism in our actuation. Our planner can be queried to determine the feasibility of tasks such as reaching goal sets and patrolling (repeatedly visiting a sequence of goals). If the task is found feasible, the planner provides a sequence of non-deterministic interaction rules, which also provide information on how precisely the robot must execute the plan to succeed. We also show how to compute stable cyclic trajectories and use these to limit uncertainty in the robot’s position.},
  archive  = {J},
  author   = {Alexandra Q Nilles and Yingying Ren and Israel Becerra and Steven M LaValle},
  doi      = {10.1177/0278364921992788},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1196-1211},
  title    = {A visibility-based approach to computing non-deterministic bouncing strategies},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). SACBP: Belief space planning for continuous-time dynamical
systems via stochastic sequential action control. <em>The International
Journal of Robotics Research</em>, <em>40</em>(10-11), 1167–1195. (<a
href="https://doi.org/10.1177/02783649211037697">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose a novel belief space planning technique for continuous dynamics by viewing the belief system as a hybrid dynamical system with time-driven switching. Our approach is based on the perturbation theory of differential equations and extends sequential action control to stochastic dynamics. The resulting algorithm, which we name SACBP, does not require discretization of spaces or time and synthesizes control signals in near real-time. SACBP is an anytime algorithm that can handle general parametric Bayesian filters under certain assumptions. We demonstrate the effectiveness of our approach in an active sensing scenario and a model-based Bayesian reinforcement learning problem. In these challenging problems, we show that the algorithm significantly outperforms other existing solution techniques including approximate dynamic programming and local trajectory optimization.},
  archive  = {J},
  author   = {Haruki Nishimura and Mac Schwager},
  doi      = {10.1177/02783649211037697},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1167-1195},
  title    = {SACBP: Belief space planning for continuous-time dynamical systems via stochastic sequential action control},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hardness of motion planning with obstacle uncertainty in two
dimensions. <em>The International Journal of Robotics Research</em>,
<em>40</em>(10-11), 1151–1166. (<a
href="https://doi.org/10.1177/0278364921992787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We consider the problem of motion planning in the presence of uncertain obstacles, modeled as polytopes with Gaussian-distributed faces (PGDFs). A number of practical algorithms exist for motion planning in the presence of known obstacles by constructing a graph in configuration space, then efficiently searching the graph to find a collision-free path. We show that such an exact algorithm is unlikely to be practical in the domain with uncertain obstacles. In particular, we show that safe 2D motion planning among PGDF obstacles is NP -hard with respect to the number of obstacles, and remains NP -hard after being restricted to a graph. Our reduction is based on a path encoding of MAXQHORNSAT and uses the risk of collision with an obstacle to encode variable assignments and literal satisfactions. This implies that, unlike in the known case, planning under uncertainty is hard, even when given a graph containing the solution. We further show by reduction from 3 -SAT that both safe 3D motion planning among PGDF obstacles and the related minimum constraint removal problem remain NP -hard even when restricted to cases where each obstacle overlaps with at most a constant number of other obstacles.},
  archive  = {J},
  author   = {Luke Shimanuki and Brian Axelrod},
  doi      = {10.1177/0278364921992787},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1151-1166},
  title    = {Hardness of motion planning with obstacle uncertainty in two dimensions},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning stabilizable nonlinear dynamics with
contraction-based regularization. <em>The International Journal of
Robotics Research</em>, <em>40</em>(10-11), 1123–1150. (<a
href="https://doi.org/10.1177/0278364920949931">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose a novel framework for learning stabilizable nonlinear dynamical systems for continuous control tasks in robotics. The key contribution is a control-theoretic regularizer for dynamics fitting rooted in the notion of stabilizability, a constraint which guarantees the existence of robust tracking controllers for arbitrary open-loop trajectories generated with the learned system. Leveraging tools from contraction theory and statistical learning in reproducing kernel Hilbert spaces, we formulate stabilizable dynamics learning as a functional optimization with a convex objective and bi-convex functional constraints. Under a mild structural assumption and relaxation of the functional constraints to sampling-based constraints, we derive the optimal solution with a modified representer theorem. Finally, we utilize random matrix feature approximations to reduce the dimensionality of the search parameters and formulate an iterative convex optimization algorithm that jointly fits the dynamics functions and searches for a certificate of stabilizability. We validate the proposed algorithm in simulation for a planar quadrotor, and on a quadrotor hardware testbed emulating planar dynamics. We verify, both in simulation and on hardware, significantly improved trajectory generation and tracking performance with the control-theoretic regularized model over models learned using traditional regression techniques, especially when learning from small supervised datasets. The results support the conjecture that the use of stabilizability constraints as a form of regularization can help prune the hypothesis space in a manner that is tailored to the downstream task of trajectory generation and feedback control. This produces models that are not only dramatically better conditioned, but also data efficient.},
  archive  = {J},
  author   = {Sumeet Singh and Spencer M Richards and Vikas Sindhwani and Jean-Jacques E Slotine and Marco Pavone},
  doi      = {10.1177/0278364920949931},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1123-1150},
  title    = {Learning stabilizable nonlinear dynamics with contraction-based regularization},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Semi-infinite programming for trajectory optimization with
non-convex obstacles. <em>The International Journal of Robotics
Research</em>, <em>40</em>(10-11), 1106–1122. (<a
href="https://doi.org/10.1177/0278364920983353">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article presents a novel optimization method that handles collision constraints with complex, non-convex 3D geometries. The optimization problem is cast as a semi-infinite program in which each collision constraint is implicitly treated as an infinite number of numeric constraints. The approach progressively generates some of these constraints for inclusion in a finite nonlinear program. Constraint generation uses an oracle to detect points of deepest penetration, and this oracle is implemented efficiently via signed distance field (SDF) versus point cloud collision detection. This approach is applied to pose optimization and trajectory optimization for both free-flying rigid bodies and articulated robots. Experiments demonstrate performance improvements compared with optimizers that handle only convex polyhedra, and demonstrate efficient collision avoidance between non-convex CAD models and point clouds in a variety of pose and trajectory optimization settings.},
  archive  = {J},
  author   = {Kris Hauser},
  doi      = {10.1177/0278364920983353},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1106-1122},
  title    = {Semi-infinite programming for trajectory optimization with non-convex obstacles},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Robust and efficient forward, differential, and inverse
kinematics using dual quaternions. <em>The International Journal of
Robotics Research</em>, <em>40</em>(10-11), 1087–1105. (<a
href="https://doi.org/10.1177/0278364920931948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Modern approaches for robot kinematics employ the product of exponentials formulation, represented using homogeneous transformation matrices. Quaternions over dual numbers are an established alternative representation; however, their use presents certain challenges: the dual quaternion exponential and logarithm contain a zero-angle singularity, and many common operations are less efficient using dual quaternions than with matrices. We present a new derivation of the dual quaternion exponential and logarithm that removes the singularity, we show an implicit representation of dual quaternions offers analytical and empirical efficiency advantages compared with both matrices and explicit dual quaternions, and we derive efficient dual quaternion forms of differential and inverse position kinematics. Analytically, implicit dual quaternions are more compact and require fewer arithmetic instructions for common operations, including chaining and exponentials. Empirically, we demonstrate a 30–40% speedup on forward kinematics and a 300–500% speedup on inverse position kinematics. This work relates dual quaternions with modern exponential coordinates and demonstrates that dual quaternions are a robust and efficient representation for robot kinematics.},
  archive  = {J},
  author   = {Neil T Dantam},
  doi      = {10.1177/0278364920931948},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1087-1105},
  title    = {Robust and efficient forward, differential, and inverse kinematics using dual quaternions},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Fast deep swept volume estimator. <em>The International
Journal of Robotics Research</em>, <em>40</em>(10-11), 1068–1086. (<a
href="https://doi.org/10.1177/0278364920940781">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Despite decades of research on efficient swept volume computation for robotics, computing the exact swept volume is intractable and approximate swept volume algorithms have been computationally prohibitive for applications such as motion and task planning. In this work, we employ deep neural networks (DNNs) for fast swept volume estimation. Since swept volume is a property of robot kinematics, a DNN can be trained off-line once in a supervised manner and deployed in any environment. The trained DNN is fast during on-line swept volume geometry or size inferences. Results show that DNNs can accurately and rapidly estimate swept volumes caused by rotational, translational, and prismatic joint motions. Sampling-based planners using the learned distance are up to five times more efficient and identify paths with smaller swept volumes on simulated and physical robots. Results also show that swept volume geometry estimation with a DNN is over 98.9% accurate and 1,200 times faster than an octree-based swept volume algorithm.},
  archive  = {J},
  author   = {Hao-Tien Lewis Chiang and John EG Baxter and Satomi Sugaya and Mohammad R Yousefi and Aleksandra Faust and Lydia Tapia},
  doi      = {10.1177/0278364920940781},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1068-1086},
  title    = {Fast deep swept volume estimator},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Free space of rigid objects: Caging, path non-existence, and
narrow passage detection. <em>The International Journal of Robotics
Research</em>, <em>40</em>(10-11), 1049–1067. (<a
href="https://doi.org/10.1177/0278364920932996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this work, we propose algorithms to explicitly construct a conservative estimate of the configuration spaces of rigid objects in two and three dimensions. Our approach is able to detect compact path components and narrow passages in configuration space which are important for applications in robotic manipulation and path planning. Moreover, as we demonstrate, they are also applicable to identification of molecular cages in chemistry. Our algorithms are based on a decomposition of the resulting three- and six-dimensional configuration spaces into slices corresponding to a finite sample of fixed orientations in configuration space. We utilize dual diagrams of unions of balls and uniform grids of orientations to approximate the configuration space. Furthermore, we carry out experiments to evaluate the computational efficiency on a set of objects with different geometric features thus demonstrating that our approach is applicable to different object shapes. We investigate the performance of our algorithm by computing increasingly fine-grained approximations of the object’s configuration space. A multithreaded implementation of our approach is shown to result in significant speed improvements.},
  archive  = {J},
  author   = {Anastasiia Varava and J. Frederico Carvalho and Danica Kragic and Florian T. Pokorny},
  doi      = {10.1177/0278364920932996},
  journal  = {The International Journal of Robotics Research},
  month    = {9},
  number   = {10-11},
  pages    = {1049-1067},
  title    = {Free space of rigid objects: Caging, path non-existence, and narrow passage detection},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Special issue on the thirteenth workshop on the algorithmic
foundations of robotics (WAFR) 2018. <em>The International Journal of
Robotics Research</em>, <em>40</em>(10-11), 1047–1048. (<a
href="https://doi.org/10.1177/02783649211038146">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Marco Morales and Lydia Tapia and Gildardo Sánchez-Ante and Seth Hutchinson},
  doi     = {10.1177/02783649211038146},
  journal = {The International Journal of Robotics Research},
  month   = {9},
  number  = {10-11},
  pages   = {1047-1048},
  title   = {Special issue on the thirteenth workshop on the algorithmic foundations of robotics (WAFR) 2018},
  volume  = {40},
  year    = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of multirotor aerial vehicles: A taxonomy based on
input allocation. <em>The International Journal of Robotics
Research</em>, <em>40</em>(8-9), 1015–1044. (<a
href="https://doi.org/10.1177/02783649211025998">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This paper reviews the effect of multirotor aerial vehicle designs on their abilities in terms of tasks and system properties. We propose a general taxonomy to characterize and describe multirotor aerial vehicles and their designs, which we apply exhaustively on the vast literature available. Thanks to the systematic characterization of the designs, we exhibit groups of designs having the same abilities in terms of achievable tasks and system properties. In particular, we organize the literature review based on the number of atomic actuation units and we discuss global properties arising from their choice and spatial distribution in the mechanical designs. Finally, we provide a discussion on the common traits of the designs found in the literature and the main open and future problems.},
  archive  = {J},
  author   = {Mahmoud Hamandi and Federico Usai and Quentin Sablé and Nicolas Staub and Marco Tognon and Antonio Franchi},
  doi      = {10.1177/02783649211025998},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {8-9},
  pages    = {1015-1044},
  title    = {Design of multirotor aerial vehicles: A taxonomy based on input allocation},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Contact-initiated shared control strategies for four-arm
supernumerary manipulation with foot interfaces. <em>The International
Journal of Robotics Research</em>, <em>40</em>(8-9), 986–1014. (<a
href="https://doi.org/10.1177/02783649211017642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In industrial or surgical settings, to achieve many tasks successfully, at least two people are needed. To this end, robotic assistance could be used to enable a single person to perform such tasks alone, with the help of robots through direct, shared, or autonomous control. We are interested in four-arm manipulation scenarios, where both feet are used to control two robotic arms via bi-pedal haptic interfaces. The robotic arms complement the tasks of the biological arms, for instance, in supporting and moving an object while working on it (using both hands). To reduce fatigue, cognitive workload, and to ease the execution of the foot manipulation, we propose two types of assistance that can be enabled upon contact with the object (i.e., based on the interaction forces): autonomous-contact force generation and auto-coordination of the robotic arms. The latter relates to controlling both arms with a single foot, once the object is grasped. We designed four (shared) control strategies that are derived from the combinations (absence/presence) of both assistance modalities, and we compared them through a user study (with 12 participants) on a four-arm manipulation task. The results show that force assistance positively improves human–robot fluency in the four-arm task, the ease of use and usefulness; it also reduces the fatigue. Finally, to make the dual-assistance approach the preferred and most successful among the proposed control strategies, delegating the grasping force to the robotic arms is a crucial factor when controlling them both with a single foot.},
  archive  = {J},
  author   = {Walid Amanhoud and Jacob Hernandez Sanchez and Mohamed Bouri and Aude Billard},
  doi      = {10.1177/02783649211017642},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {8-9},
  pages    = {986-1014},
  title    = {Contact-initiated shared control strategies for four-arm supernumerary manipulation with foot interfaces},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy budgets for coordinate invariant robot control in
physical human–robot interaction. <em>The International Journal of
Robotics Research</em>, <em>40</em>(8-9), 968–985. (<a
href="https://doi.org/10.1177/02783649211011639">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In this work we consider the current certification process of applications with physical human–robot interaction (pHRI). Two major hazards are collisions and clamping scenarios. The implementation of safety measures in pHRI applications typically depends strongly on coordinates, e.g., to monitor the robot velocity or to predict external forces. We show that the current certification process does not, in general, guarantee a safe robot behavior. In particular, in unstructured environments it is not possible to predict all risks in advance. We therefore propose to control the energy of the robot, which is a coordinate invariant entity. For an impedance controlled robot, the total energy consists of potential energy and kinetic energy. The energy flow from task description to physical interaction follows a strict causality. We assign a safe energy budget for the robot. With this energy budget, the presented controller auto-tunes its parameters to limit the exchanged kinetic energy during a collision and the potential energy during clamping scenarios. In contact, the robot behaves compliantly and therefore eliminates clamping danger. After contact, the robot automatically continues to follow the desired trajectory. With this approach the number of safety-related parameters to be determined can be reduced to one energy value, which has the potential to significantly speed up the commissioning of pHRI applications. The proposed technique is validated by experiments.},
  archive  = {J},
  author   = {Johannes Lachner and Felix Allmendinger and Eddo Hobert and Neville Hogan and Stefano Stramigioli},
  doi      = {10.1177/02783649211011639},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {8-9},
  pages    = {968-985},
  title    = {Energy budgets for coordinate invariant robot control in physical human–robot interaction},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Towards 3D LiDAR-based semantic scene understanding of 3D
point cloud sequences: The SemanticKITTI dataset. <em>The International
Journal of Robotics Research</em>, <em>40</em>(8-9), 959–967. (<a
href="https://doi.org/10.1177/02783649211006735">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A holistic semantic scene understanding exploiting all available sensor modalities is a core capability to master self-driving in complex everyday traffic. To this end, we present the SemanticKITTI dataset that provides point-wise semantic annotations of Velodyne HDL-64E point clouds of the KITTI Odometry Benchmark. Together with the data, we also published three benchmark tasks for semantic scene understanding covering different aspects of semantic scene understanding: (1) semantic segmentation for point-wise classification using single or multiple point clouds as input; (2) semantic scene completion for predictive reasoning on the semantics and occluded regions; and (3) panoptic segmentation combining point-wise classification and assigning individual instance identities to separate objects of the same class. In this article, we provide details on our dataset showing an unprecedented number of fully annotated point cloud sequences, more information on our labeling process to efficiently annotate such a vast amount of point clouds, and lessons learned in this process. The dataset and resources are available at http://www.semantic-kitti.org .},
  archive  = {J},
  author   = {Jens Behley and Martin Garbade and Andres Milioto and Jan Quenzel and Sven Behnke and Jürgen Gall and Cyrill Stachniss},
  doi      = {10.1177/02783649211006735},
  journal  = {The International Journal of Robotics Research},
  month    = {8},
  number   = {8-9},
  pages    = {959-967},
  title    = {Towards 3D LiDAR-based semantic scene understanding of 3D point cloud sequences: The SemanticKITTI dataset},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Shape-induced obstacle attraction and repulsion during
dynamic locomotion. <em>The International Journal of Robotics
Research</em>, <em>40</em>(6-7), 939–955. (<a
href="https://doi.org/10.1177/0278364921989372">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Robots still struggle to dynamically traverse complex 3D terrain with many large obstacles, an ability required for many critical applications. Body–obstacle interaction is often inevitable and induces perturbation and uncertainty in motion that challenges closed-form dynamic modeling. Here, inspired by recent discovery of a terradynamic streamlined shape, we studied how two body shapes interacting with obstacles affect turning and pitching motions of an open-loop multi-legged robot and cockroaches during dynamic locomotion. With a common cuboidal body, the robot was attracted towards obstacles, resulting in pitching up and flipping-over. By contrast, with an elliptical body, the robot was repelled by obstacles and readily traversed. The animal displayed qualitatively similar turning and pitching motions induced by these two body shapes. However, unlike the cuboidal robot, the cuboidal animal was capable of escaping obstacle attraction and subsequent high pitching and flipping over, which inspired us to develop an empirical pitch-and-turn strategy for cuboidal robots. Considering the similarity of our self-propelled body–obstacle interaction with part–feeder interaction in robotic part manipulation, we developed a quasi-static potential energy landscape model to explain the dependence of dynamic locomotion on body shape. Our experimental and modeling results also demonstrated that obstacle attraction or repulsion is an inherent property of locomotor body shape and insensitive to obstacle geometry and size. Our study expands the concept and usefulness of terradynamic shapes for passive control of robot locomotion to traverse large obstacles using physical interaction. Our study is also a step in establishing an energy landscape approach to locomotor transitions.},
  archive  = {J},
  author   = {Yuanfeng Han and Ratan Othayoth and Yulong Wang and Chun-Cheng Hsu and Rafael de la Tijera Obert and Evains Francois and Chen Li},
  doi      = {10.1177/0278364921989372},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {6-7},
  pages    = {939-955},
  title    = {Shape-induced obstacle attraction and repulsion during dynamic locomotion},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Closed-loop control of soft continuum manipulators under tip
follower actuation. <em>The International Journal of Robotics
Research</em>, <em>40</em>(6-7), 923–938. (<a
href="https://doi.org/10.1177/0278364921997167">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Continuum manipulators, inspired by nature, have drawn significant interest within the robotics community. They can facilitate motion within complex environments where traditional rigid robots may be ineffective, while maintaining a reasonable degree of precision. Soft continuum manipulators have emerged as a growing subfield of continuum robotics, with promise for applications requiring high compliance, including certain medical procedures. This has driven demand for new control schemes designed to precisely control these highly flexible manipulators, whose kinematics may be sensitive to external loads, such as gravity. This article presents one such approach, utilizing a rapidly computed kinematic model based on Cosserat rod theory, coupled with sensor feedback to facilitate closed-loop control, for a soft continuum manipulator under tip follower actuation and external loading. This approach is suited to soft manipulators undergoing quasi-static deployment, where actuators apply a follower wrench (i.e., one that is in a constant body frame direction regardless of robot configuration) anywhere along the continuum structure, as can be done in water-jet propulsion. In this article we apply the framework specifically to a tip actuated soft continuum manipulator. The proposed control scheme employs both actuator feedback and pose feedback. The actuator feedback is utilized to both regulate the follower load and to compensate for non-linearities of the actuation system that can introduce kinematic model error. Pose feedback is required to maintain accurate path following. Experimental results demonstrate successful path following with the closed-loop control scheme, with significant performance improvements gained through the use of sensor feedback when compared with the open-loop case.},
  archive  = {J},
  author   = {Federico Campisano and Simone Caló and Andria A. Remirez and James H. Chandler and Keith L. Obstein and Robert J. Webster, III and Pietro Valdastri},
  doi      = {10.1177/0278364921997167},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {6-7},
  pages    = {923-938},
  title    = {Closed-loop control of soft continuum manipulators under tip follower actuation},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Biologically inspired electrostatic artificial muscles for
insect-sized robots. <em>The International Journal of Robotics
Research</em>, <em>40</em>(6-7), 895–922. (<a
href="https://doi.org/10.1177/02783649211002545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Millimeter-sized electrostatic film actuators, inspired by the efficient spatial arrangement of insect muscles, achieve a muscle-like power density (61 W kg −1 ) and enable robotic applications in which agility is needed in confined spaces. Like biological muscles, these actuators incorporate a hierarchical structure, in this case building from electrodes to arrays to laminates, and are composed primarily of flexible materials. So comprised, these actuators can be designed for a wide range of manipulation and locomotion tasks, similar to natural muscle, while being robust and compact. A typical actuator can achieve 85 mN of force with a 15 mm stroke, with a size of 28 × 5 . 7 × 0 . 3 mm 3 and mass of 92 mg. Two millimeter-sized robots, an ultra-thin earthworm-inspired robot and an intestinal-muscle-inspired endoscopic tool for tissue resection, demonstrate the utility of these actuators. The earthworm robot undertakes inspection tasks: the navigation of a 5 mm channel and a 19 mm square tube while carrying an on-board camera. The surgical tool, which conforms to the surface of the distal end of an endoscope, similar to the thin, smooth muscle that covers the intestine, completes tissue cutting and penetrating tasks. Beyond these devices, we anticipate widespread use of these actuators in soft robots, medical robots, wearable robots, and miniature autonomous systems.},
  archive  = {J},
  author   = {Hongqiang Wang and Peter York and Yufeng Chen and Sheila Russo and Tommaso Ranzani and Conor Walsh and Robert J. Wood},
  doi      = {10.1177/02783649211002545},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {6-7},
  pages    = {895-922},
  title    = {Biologically inspired electrostatic artificial muscles for insect-sized robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Learning compositional models of robot skills for task and
motion planning. <em>The International Journal of Robotics
Research</em>, <em>40</em>(6-7), 866–894. (<a
href="https://doi.org/10.1177/02783649211004615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The objective of this work is to augment the basic abilities of a robot by learning to use sensorimotor primitives to solve complex long-horizon manipulation problems. This requires flexible generative planning that can combine primitive abilities in novel combinations and, thus, generalize across a wide variety of problems. In order to plan with primitive actions, we must have models of the actions: under what circumstances will executing this primitive successfully achieve some particular effect in the world? We use, and develop novel improvements to, state-of-the-art methods for active learning and sampling. We use Gaussian process methods for learning the constraints on skill effectiveness from small numbers of expensive-to-collect training examples. In addition, we develop efficient adaptive sampling methods for generating a comprehensive and diverse sequence of continuous candidate control parameter values (such as pouring waypoints for a cup) during planning. These values become end-effector goals for traditional motion planners that then solve for a full robot motion that performs the skill. By using learning and planning methods in conjunction, we take advantage of the strengths of each and plan for a wide variety of complex dynamic manipulation tasks. We demonstrate our approach in an integrated system, combining traditional robotics primitives with our newly learned models using an efficient robot task and motion planner. We evaluate our approach both in simulation and in the real world through measuring the quality of the selected primitive actions. Finally, we apply our integrated system to a variety of long-horizon simulated and real-world manipulation problems.},
  archive  = {J},
  author   = {Zi Wang and Caelan Reed Garrett and Leslie Pack Kaelbling and Tomás Lozano-Pérez},
  doi      = {10.1177/02783649211004615},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {6-7},
  pages    = {866-894},
  title    = {Learning compositional models of robot skills for task and motion planning},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Inverse optimal control from incomplete trajectory
observations. <em>The International Journal of Robotics Research</em>,
<em>40</em>(6-7), 848–865. (<a
href="https://doi.org/10.1177/0278364921996384">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article develops a methodology that enables learning an objective function of an optimal control system from incomplete trajectory observations. The objective function is assumed to be a weighted sum of features (or basis functions) with unknown weights, and the observed data is a segment of a trajectory of system states and inputs. The proposed technique introduces the concept of the recovery matrix to establish the relationship between any available segment of the trajectory and the weights of given candidate features. The rank of the recovery matrix indicates whether a subset of relevant features can be found among the candidate features and the corresponding weights can be learned from the segment data. The recovery matrix can be obtained iteratively and its rank non-decreasing property shows that additional observations may contribute to the objective learning. Based on the recovery matrix, a method for using incomplete trajectory observations to learn the weights of selected features is established, and an incremental inverse optimal control algorithm is developed by automatically finding the minimal required observation. The effectiveness of the proposed method is demonstrated on a linear quadratic regulator system and a simulated robot manipulator.},
  archive  = {J},
  author   = {Wanxin Jin and Dana Kulić and Shaoshuai Mou and Sandra Hirche},
  doi      = {10.1177/0278364921996384},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {6-7},
  pages    = {848-865},
  title    = {Inverse optimal control from incomplete trajectory observations},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The UMA-SAR dataset: Multimodal data collection from a
ground vehicle during outdoor disaster response training exercises.
<em>The International Journal of Robotics Research</em>,
<em>40</em>(6-7), 835–847. (<a
href="https://doi.org/10.1177/02783649211004959">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article presents a collection of multimodal raw data captured from a manned all-terrain vehicle in the course of two realistic outdoor search and rescue (SAR) exercises for actual emergency responders conducted in Málaga (Spain) in 2018 and 2019: the UMA-SAR dataset. The sensor suite, applicable to unmanned ground vehicles (UGVs), consisted of overlapping visible light (RGB) and thermal infrared (TIR) forward-looking monocular cameras, a Velodyne HDL-32 three-dimensional (3D) lidar, as well as an inertial measurement unit (IMU) and two global positioning system (GPS) receivers as ground truth. Our mission was to collect a wide range of data from the SAR domain, including persons, vehicles, debris, and SAR activity on unstructured terrain. In particular, four data sequences were collected following closed-loop routes during the exercises, with a total path length of 5.2 km and a total time of 77 min. In addition, we provide three more sequences of the empty site for comparison purposes (an extra 4.9 km and 46 min). Furthermore, the data is offered both in human-readable format and as rosbag files, and two specific software tools are provided for extracting and adapting this dataset to the users’ preference. The review of previously published disaster robotics repositories indicates that this dataset can contribute to fill a gap regarding visual and thermal datasets and can serve as a research tool for cross-cutting areas such as multispectral image fusion, machine learning for scene understanding, person and object detection, and localization and mapping in unstructured environments. The full dataset is publicly available at: www.uma.es/robotics-and-mechatronics/sar-datasets .},
  archive  = {J},
  author   = {Jesús Morales and Ricardo Vázquez-Martín and Anthony Mandow and David Morilla-Cabello and Alfonso García-Cerezo},
  doi      = {10.1177/02783649211004959},
  journal  = {The International Journal of Robotics Research},
  month    = {6},
  number   = {6-7},
  pages    = {835-847},
  title    = {The UMA-SAR dataset: Multimodal data collection from a ground vehicle during outdoor disaster response training exercises},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A model predictive approach for online mobile manipulation
of non-holonomic objects using learned dynamics. <em>The International
Journal of Robotics Research</em>, <em>40</em>(4-5), 815–831. (<a
href="https://doi.org/10.1177/0278364921992793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Assistive robots designed for physical interaction with objects will play an important role in assisting with mobility and fall prevention in healthcare facilities. Autonomous mobile manipulation presents a hurdle prior to safely using robots in real-life applications. In this article, we introduce a mobile manipulation framework based on model predictive control using learned dynamics models of objects. We focus on the specific problem of manipulating legged objects such as those commonly found in healthcare environments and personal dwellings (e.g., walkers, tables, chairs). We describe a probabilistic method for autonomous learning of an approximate dynamics model for these objects. In this method, we learn dynamic parameters using a small dataset consisting of force and motion data from interactions between the robot and object. Moreover, we account for multiple manipulation strategies by formulating manipulation planning as a mixed-integer convex optimization. The proposed framework considers the hybrid control system composed of (i) choosing which leg to grasp and (ii) control of continuous applied forces for manipulation. We formalize our algorithm based on model predictive control to compensate for modeling errors and find an optimal path to manipulate the object from one configuration to another. We present results for several objects with various wheel configurations. Simulation and physical experiments show that the obtained dynamics models are sufficiently accurate for safe and collision-free manipulation. When combined with the proposed manipulation planning algorithm, the robot successfully moves the object to the desired pose while avoiding any collision.},
  archive  = {J},
  author   = {Roya Sabbagh Novin and Amir Yazdani and Andrew Merryweather and Tucker Hermans},
  doi      = {10.1177/0278364921992793},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {815-831},
  title    = {A model predictive approach for online mobile manipulation of non-holonomic objects using learned dynamics},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Sniffing out fugitive methane emissions: Autonomous remote
gas inspection with a mobile robot. <em>The International Journal of
Robotics Research</em>, <em>40</em>(4-5), 782–814. (<a
href="https://doi.org/10.1177/0278364920954907">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Air pollution causes millions of premature deaths every year, and fugitive emissions of, e.g., methane are major causes of global warming. Correspondingly, air pollution monitoring systems are urgently needed. Mobile, autonomous monitoring can provide adaptive and higher spatial resolution compared with traditional monitoring stations and allows fast deployment and operation in adverse environments. We present a mobile robot solution for autonomous gas detection and gas distribution mapping using remote gas sensing. Our “Autonomous Remote Methane Explorer” ( ARMEx ) is equipped with an actuated spectroscopy-based remote gas sensor, which collects integral gas measurements along up to 30 m long optical beams. State-of-the-art 3D mapping and robot localization allow the precise location of the optical beams to be determined, which then facilitates gas tomography (tomographic reconstruction of local gas distributions from sets of integral gas measurements). To autonomously obtain informative sampling strategies for gas tomography, we reduce the search space for gas inspection missions by defining a sweep of the remote gas sensor over a selectable field of view as a sensing configuration. We describe two different ways to find sequences of sensing configurations that optimize the criteria for gas detection and gas distribution mapping while minimizing the number of measurements and distance traveled. We evaluated an ARMEx prototype deployed in a large, challenging indoor environment with eight gas sources. In comparison with human experts teleoperating the platform from a distant building, the autonomous strategy produced better gas maps with a lower number of sensing configurations and a slightly longer route.},
  archive  = {J},
  author   = {Muhammad Asif Arain and Victor Hernandez Bennetts and Erik Schaffernicht and Achim J Lilienthal},
  doi      = {10.1177/0278364920954907},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {782-814},
  title    = {Sniffing out fugitive methane emissions: Autonomous remote gas inspection with a mobile robot},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Joint-level force sensing for indirect hybrid force/position
control of continuum robots with friction. <em>The International Journal
of Robotics Research</em>, <em>40</em>(4-5), 764–781. (<a
href="https://doi.org/10.1177/0278364920979721">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Continuum robots offer the dexterity and obstacle circumvention capabilities necessary to enable surgery in deep surgical sites. They also can enable joint-level ex situ force sensing (JEFS), which provides an estimate of end-effector wrenches given joint-level forces. Prior works on JEFS relied on a restrictive embodiment with minimal actuation line friction and captured model and frictional actuation transmission uncertainties using a configuration space formulation. In this work, we overcome these limitations. First, frictional losses are canceled using a feed-forward term based on support vector regression in joint space. Then, regression maps and their interpolation are used to account for actuation hysteresis. The residual joint-force error is then further minimized using a least-squares model parameter update. An indirect hybrid force/position controller using JEFS is presented with evaluation carried out on a realistic pre-clinically deployable insertable robotic effectors platform (IREP) for single-port access surgery. Automated mock force-controlled ablation, exploration, and knot tightening are evaluated. A user study involving the daVinci Research Kit surgeon console and the IREP as a surgical slave was carried out to compare the performance of users with and without force feedback based on JEFS for force-controlled ablation and knot tightening. Results in automated experiments and a user study of telemanipulated experiments suggest that intrinsic force-sensing can achieve levels of force uncertainty and force regulation errors of the order of 0.2 N. Using JEFS and automated task execution, repeatability, and force regulation accuracy is shown to be comparable to using a commercial force sensor for human-in-the-loop feedback.},
  archive  = {J},
  author   = {Rashid Yasin and Nabil Simaan},
  doi      = {10.1177/0278364920979721},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {764-781},
  title    = {Joint-level force sensing for indirect hybrid force/position control of continuum robots with friction},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Coordination of lateral body bending and leg movements for
sprawled posture quadrupedal locomotion. <em>The International Journal
of Robotics Research</em>, <em>40</em>(4-5), 747–763. (<a
href="https://doi.org/10.1177/0278364921991158">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Many animals generate propulsive forces by coordinating legs, which contact and push against the surroundings, with bending of the body, which can only indirectly influence these forces. Such body–leg coordination is not commonly employed in quadrupedal robotic systems. To elucidate the role of back bending during quadrupedal locomotion, we study a model system: the salamander, a sprawled-posture quadruped that uses lateral bending of the elongate back in conjunction with stepping of the limbs during locomotion. We develop a geometric approach that yields a low-dimensional representation of the body and limb contributions to the locomotor performance quantified by stride displacement. For systems where the damping forces dominate inertial forces, our approach offers insight into appropriate coordination patterns, and improves the computational efficiency of optimization techniques. In particular, we demonstrate effect of the lateral undulation coordinated with leg movement in the forward, rotational, and lateral directions of the robot motion. We validate the theoretical results using numerical simulations, and then successfully test these approaches using robophysical experiments on granular media, a model deformable, frictional substrate. Although our focus lies primarily on robotics, we also demonstrate that our tools can accurately predict optimal body bending of a living salamander Salamandra salamandra .},
  archive  = {J},
  author   = {Baxi Chong and Yasemin Ozkan Aydin and Chaohui Gong and Guillaume Sartoretti and Yunjin Wu and Jennifer M Rieser and Haosen Xing and Perrin E Schiebel and Jeffery W. Rankin and Krijn B Michel and Alfredo Nicieza and John R Hutchinson and Daniel I Goldman and Howie Choset},
  doi      = {10.1177/0278364921991158},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {747-763},
  title    = {Coordination of lateral body bending and leg movements for sprawled posture quadrupedal locomotion},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A hip–knee–ankle exoskeleton emulator for studying gait
assistance. <em>The International Journal of Robotics Research</em>,
<em>40</em>(4-5), 722–746. (<a
href="https://doi.org/10.1177/0278364920961452">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Lower-limb exoskeletons could improve the mobility of people with disabilities, older adults, workers, first responders, and military personnel. Despite recent advances, few products are commercially available and exoskeleton research is still often limited by hardware constraints. Many promising multi-joint assistance strategies, especially those with high-torque and high-power components, have yet to be tested because they are beyond the capabilities of current devices. To study these untested assistance strategies, we present a hip–knee–ankle exoskeleton emulator that can apply high torques and powers that match or exceed those observed in uphill running. The system has powerful off-board motors that actuate a 13.5 kg exoskeleton end effector worn by the user. It can apply up to 200 Nm of torque in hip flexion, hip extension, and ankle plantarflexion, 250 Nm of torque in knee extension, and 140 Nm of torque in knee flexion, with over 4.5 kW of power at each joint and a closed-loop torque bandwidth of at least 18 Hz in each direction of actuation. The exoskeleton is compliant in unactuated directions, adjustable for a wide range of users and comfortable during walking and running. When paired with human-in-the-loop optimization, we expect that this system will identify new assistance strategies to improve human mobility. A complete computer-aided design (CAD) model of the exoskeleton and a bill of materials are included and available for download.},
  archive  = {J},
  author   = {Gwendolyn M Bryan and Patrick W Franks and Stefan C Klein and Robert J Peuchen and Steven H Collins},
  doi      = {10.1177/0278364920961452},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {722-746},
  title    = {A hip–knee–ankle exoskeleton emulator for studying gait assistance},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). How to train your robot with deep reinforcement learning:
Lessons we have learned. <em>The International Journal of Robotics
Research</em>, <em>40</em>(4-5), 698–721. (<a
href="https://doi.org/10.1177/0278364920987859">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Deep reinforcement learning (RL) has emerged as a promising approach for autonomously acquiring complex behaviors from low-level sensor observations. Although a large portion of deep RL research has focused on applications in video games and simulated control, which does not connect with the constraints of learning in real environments, deep RL has also demonstrated promise in enabling physical robots to learn complex skills in the real world. At the same time, real-world robotics provides an appealing domain for evaluating such algorithms, as it connects directly to how humans learn: as an embodied agent in the real world. Learning to perceive and move in the real world presents numerous challenges, some of which are easier to address than others, and some of which are often not considered in RL research that focuses only on simulated domains. In this review article, we present a number of case studies involving robotic deep RL. Building off of these case studies, we discuss commonly perceived challenges in deep RL and how they have been addressed in these works. We also provide an overview of other outstanding challenges, many of which are unique to the real-world robotics setting and are not often the focus of mainstream RL research. Our goal is to provide a resource both for roboticists and machine learning researchers who are interested in furthering the progress of deep RL in the real world.},
  archive  = {J},
  author   = {Julian Ibarz and Jie Tan and Chelsea Finn and Mrinal Kalakrishnan and Peter Pastor and Sergey Levine},
  doi      = {10.1177/0278364920987859},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {698-721},
  title    = {How to train your robot with deep reinforcement learning: Lessons we have learned},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). AIR-Act2Act: Human–human interaction dataset for teaching
non-verbal social behaviors to robots. <em>The International Journal of
Robotics Research</em>, <em>40</em>(4-5), 691–697. (<a
href="https://doi.org/10.1177/0278364921990671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {To better interact with users, a social robot should understand the users’ behavior, infer the intention, and respond appropriately. Machine learning is one way of implementing robot intelligence. It provides the ability to automatically learn and improve from experience instead of explicitly telling the robot what to do. Social skills can also be learned through watching human–human interaction videos. However, human–human interaction datasets are relatively scarce to learn interactions that occur in various situations. Moreover, we aim to use service robots in the elderly care domain; however, there has been no interaction dataset collected for this domain. For this reason, we introduce a human–human interaction dataset for teaching non-verbal social behaviors to robots. It is the only interaction dataset that elderly people have participated in as performers. We recruited 100 elderly people and 2 college students to perform 10 interactions in an indoor environment. The entire dataset has 5,000 interaction samples, each of which contains depth maps, body indexes, and 3D skeletal data that are captured with three Microsoft Kinect v2 sensors. In addition, we provide the joint angles of a humanoid NAO robot which are converted from the human behavior that robots need to learn. The dataset and useful Python scripts are available for download at https://github.com/ai4r/AIR-Act2Act . It can be used to not only teach social skills to robots but also benchmark action recognition algorithms.},
  archive  = {J},
  author   = {Woo-Ri Ko and Minsu Jang and Jaeyeon Lee and Jaehong Kim},
  doi      = {10.1177/0278364921990671},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {691-697},
  title    = {AIR-Act2Act: Human–human interaction dataset for teaching non-verbal social behaviors to robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Canadian adverse driving conditions dataset. <em>The
International Journal of Robotics Research</em>, <em>40</em>(4-5),
681–690. (<a href="https://doi.org/10.1177/0278364920979368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The Canadian Adverse Driving Conditions (CADC) dataset was collected with the Autonomoose autonomous vehicle platform, based on a modified Lincoln MKZ. The dataset, collected during winter within the Region of Waterloo, Canada, is the first autonomous driving dataset that focuses on adverse driving conditions specifically. It contains 7,000 frames of annotated data from 8 cameras (Ximea MQ013CG-E2), lidar (VLP-32C), and a GNSS+INS system (Novatel OEM638), collected through a variety of winter weather conditions. The sensors are time synchronized and calibrated with the intrinsic and extrinsic calibrations included in the dataset. Lidar frame annotations that represent ground truth for 3D object detection and tracking have been provided by Scale AI.},
  archive  = {J},
  author   = {Matthew Pitropov and Danson Evan Garcia and Jason Rebello and Michael Smart and Carlos Wang and Krzysztof Czarnecki and Steven Waslander},
  doi      = {10.1177/0278364920979368},
  journal  = {The International Journal of Robotics Research},
  month    = {4},
  number   = {4-5},
  pages    = {681-690},
  title    = {Canadian adverse driving conditions dataset},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Generation of synchronized configuration space trajectories
with workspace path constraints for an ensemble of robots. <em>The
International Journal of Robotics Research</em>, <em>40</em>(2-3),
651–678. (<a href="https://doi.org/10.1177/0278364920988087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We present an approach to generate path-constrained synchronous motion for the coupled ensemble of robots. In this article, we refer to serial-link manipulators and mobile bases as robots. We assume that the relative motion constraints among the objects in the environment are given. We represent the motion constraints as path constraints and pose the problem of path-constrained synchronous trajectory generation as a non-linear optimization problem. Our approach generates configuration space trajectories for the robots to manipulate the objects such that the given motion constraints among the objects are satisfied. We present a method that formulates the problem as a discrete parameter optimization problem and solves it using successive constraint refinement techniques. The method adaptively selects the parametric representation of the configuration variables for a given scenario. It also generates an approximate solution as the starting point for the successive constraint refinement stages to reduce the computation time. We discuss in detail why successive constraint refinement strategies are useful for solving this class of problems. We demonstrate the effectiveness of the proposed method on challenging test cases in simulation and physical environments with high-degree-of-freedom robotic systems.},
  archive  = {J},
  author   = {Ariyan M Kabir and Shantanu Thakar and Rishi K Malhan and Aniruddha V Shembekar and Brual C Shah and Satyandra K Gupta},
  doi      = {10.1177/0278364920988087},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {651-678},
  title    = {Generation of synchronized configuration space trajectories with workspace path constraints for an ensemble of robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Geometry-aware manipulability learning, tracking, and
transfer. <em>The International Journal of Robotics Research</em>,
<em>40</em>(2-3), 624–650. (<a
href="https://doi.org/10.1177/0278364920946815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Body posture influences human and robot performance in manipulation tasks, as appropriate poses facilitate motion or the exertion of force along different axes. In robotics, manipulability ellipsoids arise as a powerful descriptor to analyze, control, and design the robot dexterity as a function of the articulatory joint configuration. This descriptor can be designed according to different task requirements, such as tracking a desired position or applying a specific force. In this context, this article presents a novel manipulability transfer framework, a method that allows robots to learn and reproduce manipulability ellipsoids from expert demonstrations. The proposed learning scheme is built on a tensor-based formulation of a Gaussian mixture model that takes into account that manipulability ellipsoids lie on the manifold of symmetric positive-definite matrices. Learning is coupled with a geometry-aware tracking controller allowing robots to follow a desired profile of manipulability ellipsoids. Extensive evaluations in simulation with redundant manipulators, a robotic hand and humanoids agents, as well as an experiment with two real dual-arm systems validate the feasibility of the approach.},
  archive  = {J},
  author   = {Noémie Jaquier and Leonel Rozo and Darwin G Caldwell and Sylvain Calinon},
  doi      = {10.1177/0278364920946815},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {624-650},
  title    = {Geometry-aware manipulability learning, tracking, and transfer},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hybrid conditional planning for robotic applications.
<em>The International Journal of Robotics Research</em>,
<em>40</em>(2-3), 594–623. (<a
href="https://doi.org/10.1177/0278364920963783">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Robots who have partial observability of and incomplete knowledge about their environments may have to consider contingencies while planning, and thus necessitate cognitive abilities beyond classical planning. Moreover, during planning, they need to consider continuous feasibility checks for executability of the plans in the real world. Conditional planning is concerned with reaching goals from an initial state, in the presence of incomplete knowledge and partial observability, by considering all contingencies and by utilizing sensing actions to gather relevant knowledge when needed. A conditional plan is essentially a tree of actions where each branch of the tree represents a possible execution of actuation actions and sensing actions to reach a goal state. Hybrid conditional planning extends conditional planning by integrating feasibility checks into executability conditions of actions. We introduce a parallel offline algorithm, called HCP lan , for computing hybrid conditional plans. HCP lan relies on modeling deterministic effects of actuation actions and non-deterministic effects of sensing actions in the causality-based action language C + . Branches of a hybrid conditional plan are computed in parallel using a SAT solver, where continuous feasibility checks are performed as needed. We develop a comprehensive benchmark suite and introduce new evaluation metrics for hybrid conditional planning. We evaluate HCP lan with extensive experiments in terms of computational efficiency and plan quality. We perform experiments to compare HCP lan with other related conditional planners and approaches to deal with contingencies due to incomplete knowledge. We further demonstrate the applicability and usefulness of HCP lan in service robotics applications, through dynamic simulations and physical implementations.},
  archive  = {J},
  author   = {Ahmed Nouman and Volkan Patoglu and Esra Erdem},
  doi      = {10.1177/0278364920963783},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {594-623},
  title    = {Hybrid conditional planning for robotic applications},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). PAC-bayes control: Learning policies that provably
generalize to novel environments. <em>The International Journal of
Robotics Research</em>, <em>40</em>(2-3), 574–593. (<a
href="https://doi.org/10.1177/0278364920959444">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Our goal is to learn control policies for robots that provably generalize well to novel environments given a dataset of example environments. The key technical idea behind our approach is to leverage tools from generalization theory in machine learning by exploiting a precise analogy (which we present in the form of a reduction) between generalization of control policies to novel environments and generalization of hypotheses in the supervised learning setting. In particular, we utilize the probably approximately correct (PAC)-Bayes framework, which allows us to obtain upper bounds that hold with high probability on the expected cost of (stochastic) control policies across novel environments. We propose policy learning algorithms that explicitly seek to minimize this upper bound. The corresponding optimization problem can be solved using convex optimization (relative entropy programming in particular) in the setting where we are optimizing over a finite policy space. In the more general setting of continuously parameterized policies (e.g., neural network policies), we minimize this upper bound using stochastic gradient descent. We present simulated results of our approach applied to learning (1) reactive obstacle avoidance policies and (2) neural network-based grasping policies. We also present hardware results for the Parrot Swing drone navigating through different obstacle environments. Our examples demonstrate the potential of our approach to provide strong generalization guarantees for robotic systems with continuous state and action spaces, complicated (e.g., nonlinear) dynamics, rich sensory inputs (e.g., depth images), and neural network-based policies.},
  archive  = {J},
  author   = {Anirudha Majumdar and Alec Farid and Anoopkumar Sonar},
  doi      = {10.1177/0278364920959444},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {574-593},
  title    = {PAC-bayes control: Learning policies that provably generalize to novel environments},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). HyP-DESPOT: A hybrid parallel algorithm for online planning
under uncertainty. <em>The International Journal of Robotics
Research</em>, <em>40</em>(2-3), 558–573. (<a
href="https://doi.org/10.1177/0278364920937074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Robust planning under uncertainty is critical for robots in uncertain, dynamic environments, but incurs high computational cost. State-of-the-art online search algorithms, such as DESPOT, have vastly improved the computational efficiency of planning under uncertainty and made it a valuable tool for robotics in practice. This work takes one step further by leveraging both CPU and GPU parallelization in order to achieve real-time online planning performance for complex tasks with large state, action, and observation spaces. Specifically, Hybrid Parallel DESPOT (HyP-DESPOT) is a massively parallel online planning algorithm that integrates CPU and GPU parallelism in a multi-level scheme. It performs parallel DESPOT tree search by simultaneously traversing multiple independent paths using multi-core CPUs; it performs parallel Monte Carlo simulations at the leaf nodes of the search tree using GPUs. HyP-DESPOT provably converges in finite time under moderate conditions and guarantees near-optimality of the solution. Experimental results show that HyP-DESPOT speeds up online planning by up to a factor of several hundred in several challenging robotic tasks in simulation, compared with the original DESPOT algorithm. It also exhibits real-time performance on a robot vehicle navigating among many pedestrians.},
  archive  = {J},
  author   = {Panpan Cai and Yuanfu Luo and David Hsu and Wee Sun Lee},
  doi      = {10.1177/0278364920937074},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {558-573},
  title    = {HyP-DESPOT: A hybrid parallel algorithm for online planning under uncertainty},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A learning-based harmonic mapping: Framework, assessment,
and case study of human-to-robot hand pose mapping. <em>The
International Journal of Robotics Research</em>, <em>40</em>(2-3),
534–557. (<a href="https://doi.org/10.1177/0278364920962205">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Harmonic mapping provides a natural way of mapping two manifolds by minimizing distortion induced by the mapping. However, most applications are limited to mapping between 2D and/or 3D spaces owing to the high computational cost. We propose a novel approach, the harmonic autoencoder (HAE), by approximating a harmonic mapping in a data-driven way. The HAE learns a mapping from an input domain to a target domain that minimizes distortion and requires only a small number of input–target reference pairs. The HAE can be applied to high-dimensional applications, such as human-to-robot hand pose mapping. Our method can map from the input to the target domain while minimizing distortion over the input samples, covering the target domain, and satisfying the reference pairs. This is achieved by extending an existing neural network method called the contractive autoencoder. Starting from a contractive autoencoder, the HAE takes into account a distance function between point clouds within the input and target domains, in addition to a penalty for estimation error on reference points. For efficiently selecting a set of input–target reference pairs during the training process, we introduce an adaptive optimization criterion. We demonstrate that pairs selected in this way yield a higher-performance mapping than pairs selected randomly, and the mapping is comparable to that from pairs selected heuristically by the experimenter. Our experimental results with synthetic data and human-to-robot hand pose data demonstrate that our method can learn an effective mapping between the input and target domains.},
  archive  = {J},
  author   = {Eunsuk Chong and Lionel Zhang and Veronica J. Santos},
  doi      = {10.1177/0278364920962205},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {534-557},
  title    = {A learning-based harmonic mapping: Framework, assessment, and case study of human-to-robot hand pose mapping},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A modular, multi-arm concentric tube robot system with
application to transnasal surgery for orbital tumors. <em>The
International Journal of Robotics Research</em>, <em>40</em>(2-3),
521–533. (<a href="https://doi.org/10.1177/02783649211000074">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the development of telemanipulated surgical robots, a class of continuum robots known as concentric tube robots has drawn particular interest for clinical applications in which space is a major limitation. One such application is transnasal surgery, which is used to access surgical sites in the sinuses and at the skull base. Current techniques for performing these procedures require surgeons to maneuver multiple rigid tools through the narrow confines of the nasal passages, leaving them with limited dexterity at the surgical site. In this article, we present a complete robotic system for transnasal surgery featuring concentric tube manipulators. It illustrates a bagging concept for sterility, and intraoperatively interchangeable instruments that work in conjunction with it, which were developed with operating room workflow compatibility in mind. The system also includes a new modular, portable surgeon console, a variable view-angle endoscope to facilitate surgical field visualization, and custom motor control electronics. Furthermore, we demonstrate elastic instability avoidance for the first time on a physical prototype in a geometrically accurate surgical scenario, which facilitates use of higher curvature tubes than could otherwise be used safely in this application. From a surgical application perspective, this article presents the first robotic approach to removing tumors growing behind the eyes in the orbital apex region, which has not been attempted previously with a surgical robot.},
  archive  = {J},
  author   = {Trevor L. Bruns and Andria A. Remirez and Maxwell A. Emerson and Ray A. Lathrop and Arthur W. Mahoney and Hunter B. Gilbert and Cindy L. Liu and Paul T. Russell and Robert F. Labadie and Kyle D. Weaver and Robert J. Webster, III},
  doi      = {10.1177/02783649211000074},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {521-533},
  title    = {A modular, multi-arm concentric tube robot system with application to transnasal surgery for orbital tumors},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). ALFA: A dataset for UAV fault and anomaly detection. <em>The
International Journal of Robotics Research</em>, <em>40</em>(2-3),
515–520. (<a href="https://doi.org/10.1177/0278364920966642">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We present a dataset of several fault types in control surfaces of a fixed-wing unmanned aerial vehicle (UAV) for use in fault detection and isolation (FDI) and anomaly detection (AD) research. Currently, the dataset includes processed data for 47 autonomous flights with 23 sudden full engine failure scenarios and 24 scenarios for 7 other types of sudden control surface (actuator) faults, with a total of 66 minutes of flight under normal conditions and 13 minutes of post-fault flight time. It additionally includes many hours of raw data of fully autonomous, autopilot-assisted and manual flights with tens of fault scenarios. The ground truth of the time and type of faults is provided in each scenario to enable evaluation of the methods using the dataset. We have also provided the helper tools in several programming languages to load and work with the data and to help the evaluation of a detection method using the dataset. A set of metrics is proposed to help to compare different methods using the dataset. Most of the current fault detection methods are evaluated in simulation and, as far as we know, this dataset is the only one providing the real flight data with faults in such capacity. We hope it will help advance the state of the art in AD or FDI research for autonomous aerial vehicles and mobile robots to enhance the safety of autonomous and remote flight operations further. The dataset and the provided tools can be accessed from https://doi.org/10.1184/R1/12707963 .},
  archive  = {J},
  author   = {Azarakhsh Keipour and Mohammadreza Mousaei and Sebastian Scherer},
  doi      = {10.1177/0278364920966642},
  journal  = {The International Journal of Robotics Research},
  month    = {2},
  number   = {2-3},
  pages    = {515-520},
  title    = {ALFA: A dataset for UAV fault and anomaly detection},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Reliability analysis of a tendon-driven actuation for soft
robots. <em>The International Journal of Robotics Research</em>,
<em>40</em>(1), 494–511. (<a
href="https://doi.org/10.1177/0278364920907151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The reliability of soft robotic devices will be the bottleneck that slows their commercialization. In particular, fatigue failure issues are a major concern. Thus, reliability should be taken into account from the earliest stages of development. However, to date, there have been no attempts to analyze the reliability of soft robotic devices in a systematic manner. When soft robots are employed to force transmission applications, reliability is typically a dominant issue, since soft robotic structures are constructed with soft material components; these materials have highly nonlinear properties that arise due to the large distribution in the material properties. Furthermore, reliability should be analyzed from the robot’s system down to the components using domain knowledge about the system; this requires a systematic approach. This study presents a framework for reliability analysis of soft robotic devices taking into account a probability distribution that has not been considered before and examines a case study of a tendon-driven soft robot. This study focuses specifically on the (a) concept design process, (b) lifetime analysis process, and (c) design and optimization process. A life model that considers distribution is proposed using accelerated life testing based on analysis of the failure mechanism of the tendon-driven system. The tensile stress of the wire was varied during the experiment with different bend angles and output tension. The result was validated with different stress levels using a testbed to simulate an actual application. The proposed reliability analysis methodology could be applied to other soft robotic systems, such as pneumatic actuators, to improve the reliability-related properties during the robot design stage, and the life model can be used to estimate the device lifetime under various stress conditions.},
  archive  = {J},
  author   = {Useok Jeong and Keunsu Kim and Sang-Hun Kim and Hyunhee Choi and Byeng Dong Youn and Kyu-Jin Cho},
  doi      = {10.1177/0278364920907151},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {494-511},
  title    = {Reliability analysis of a tendon-driven actuation for soft robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparing model-based control methods for simultaneous
stiffness and position control of inflatable soft robots. <em>The
International Journal of Robotics Research</em>, <em>40</em>(1),
470–493. (<a href="https://doi.org/10.1177/0278364920911960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Inflatable robots are naturally lightweight and compliant, which may make them well suited for operating in unstructured environments or in close proximity to people. The inflatable joints used in this article consist of a strong fabric exterior that constrains two opposing compliant air bladders that generate torque (unlike McKibben actuators where pressure changes cause translation). This antagonistic structure allows the simultaneous control of position and stiffness. However, dynamic models of soft robots that allow variable stiffness control have not been well developed. In this work, a model that includes stiffness as a state variable is developed and validated. Using the stiffness model, a sliding mode controller and model predictive controller are developed to control stiffness and position simultaneously. For sliding mode control (SMC), the joint stiffness was controlled to within 0.07 Nm/rad of a 45 Nm/rad command. For model predictive control (MPC) the joint stiffness was controlled to within 0.045 Nm/rad of the same stiffness command. Both SMC and MPC were able to control to within 0.5° of a desired position at steady state. Stiffness control was extended to a multiple-degree-of-freedom soft robot using MPC. Controlling stiffness of a 4-DOF arm reduced the end-effector deflection by approximately 50% (from 17.9 to 12.2cm) with a 4 lb (1.8 kg) step input applied at the end effector when higher joint stiffness (40 Nm/rad) was used compared with low stiffness (30 Nm/rad). This work shows that the derived stiffness model can enable effective position and stiffness control.},
  archive  = {J},
  author   = {Charles M. Best and Levi Rupert and Marc D. Killpack},
  doi      = {10.1177/0278364920911960},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {470-493},
  title    = {Comparing model-based control methods for simultaneous stiffness and position control of inflatable soft robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A soft manipulator for efficient delicate grasping in
shallow water: Modeling, control, and real-world experiments. <em>The
International Journal of Robotics Research</em>, <em>40</em>(1),
449–469. (<a href="https://doi.org/10.1177/0278364920917203">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Collecting in shallow water (water depth: ~30 m) is an emerging field that requires robotics for replacing human divers. Soft robots have several promising features (e.g., safe interaction with the environments, lightweight, etc.) for performing such tasks. In this article, we developed an underwater robotic system with a three-degree-of-freedom (3-DoF) soft manipulator for spatial delicate grasping in shallow water. First, we present the design and fabrication of the soft manipulator with an opposite-bending-and-stretching structure (OBSS). Then, we proposed a simple and efficient kinematics method for controlling the spatial location and trajectory of the soft manipulator’s end effector. The inverse kinematics of the OBSS manipulator can be solved efficiently (computation time: 8.2 ms). According to this inverse kinematics method, we demonstrated that the OBSS soft manipulator could track complex two-dimensional and three-dimensional trajectories, including star, helix, etc. Further, we performed real-time closed-loop pick-and-place experiments of the manipulator with binocular and on-hand cameras in a lab aquarium. Hydrodynamic experiments showed that the OBSS soft manipulator produced little force (less than 0.459 N) and torque (less than 0.228 N·m), which suggested its low-inertia feature during the underwater operation. Finally, we demonstrated that the underwater robotic system with the OBSS soft manipulator successfully collected seafood animals at the bottom of the natural oceanic environment. The robot successfully collected eight sea echini and one sea cucumber within 20 minutes at a water depth of around 10 m.},
  archive  = {J},
  author   = {Zheyuan Gong and Xi Fang and Xingyu Chen and Jiahui Cheng and Zhexin Xie and Jiaqi Liu and Bohan Chen and Hui Yang and Shihan Kong and Yufei Hao and Tianmiao Wang and Junzhi Yu and Li Wen},
  doi      = {10.1177/0278364920917203},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {449-469},
  title    = {A soft manipulator for efficient delicate grasping in shallow water: Modeling, control, and real-world experiments},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Morphologically induced stability on an underwater legged
robot with a deformable body. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 435–448. (<a
href="https://doi.org/10.1177/0278364919840426">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {For robots to navigate successfully in the real world, unstructured environment adaptability is a prerequisite. Although this is typically implemented within the control layer, there have been recent proposals of adaptation through a morphing of the body. However, the successful demonstration of this approach has mostly been theoretical and in simulations thus far. In this work we present an underwater hopping robot that features a deformable body implemented as a deployable structure that is covered by a soft skin for which it is possible to manually change the body size without altering any other property (e.g. buoyancy or weight). For such a system, we show that it is possible to induce a stable hopping behavior instead of a fall, by just increasing the body size. We provide a mathematical model that describes the hopping behavior of the robot under the influence of shape-dependent underwater contributions (drag, buoyancy, and added mass) in order to analyze and compare the results obtained. Moreover, we show that for certain conditions, a stable hopping behavior can only be obtained through changing the morphology of the robot as the controller (i.e. actuator) would already be working at maximum capacity. The presented work demonstrates that, through the exploitation of shape-dependent forces, the dynamics of a system can be modified through altering the morphology of the body to induce a desirable behavior and, thus, a morphological change can be an effective alternative to the classic control.},
  archive  = {J},
  author   = {Giacomo Picardi and Helmut Hauser and Cecilia Laschi and Marcello Calisti},
  doi      = {10.1177/0278364919840426},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {435-448},
  title    = {Morphologically induced stability on an underwater legged robot with a deformable body},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Hierarchical control of soft manipulators towards
unstructured interactions. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 411–434. (<a
href="https://doi.org/10.1177/0278364920979367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Performing daily interaction tasks such as opening doors and pulling drawers in unstructured environments is a challenging problem for robots. The emergence of soft-bodied robots brings a new perspective to solving this problem. In this paper, inspired by humans performing interaction tasks through simple behaviors, we propose a hierarchical control system for soft arms, in which the low-level controller achieves motion control of the arm tip, the high-level controller controls the behaviors of the arm based on the low-level controller, and the top-level planner chooses what behaviors should be taken according to tasks. To realize the motion control of the soft arm in interacting with environments, we propose two control methods. The first is a feedback control method based on a simplified Jacobian model utilizing the motion laws of the soft arm that are not affected by environments during interaction. The second is a control method based on Q -learning, in which we present a novel method to increase training data by setting virtual goals. We implement the hierarchical control system on a platform with the Honeycomb Pneumatic Networks Arm (HPN Arm) and validate the effectiveness of this system on a series of typical daily interaction tasks, which demonstrates this proposed hierarchical control system could render the soft arms to perform interaction tasks as simply as humans, without force sensors or accurate models of the environments. This work provides a new direction for the application of soft-bodied arms and offers a new perspective for the physical interactions between robots and environments.},
  archive  = {J},
  author   = {Hao Jiang and Zhanchi Wang and Yusong Jin and Xiaotong Chen and Peijin Li and Yinghao Gan and Sen Lin and Xiaoping Chen},
  doi      = {10.1177/0278364920979367},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {411-434},
  title    = {Hierarchical control of soft manipulators towards unstructured interactions},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Design of physical user–robot interactions for model
identification of soft actuators on exoskeleton robots. <em>The
International Journal of Robotics Research</em>, <em>40</em>(1),
397–410. (<a href="https://doi.org/10.1177/0278364919853618">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recent breakthroughs in wearable robots, such as exoskeleton robots with soft actuators and soft exosuits, have enabled the use of safe and comfortable movement assistance. However, modeling and identification methods for soft actuators used in wearable robots have yet to be sufficiently explored. In this study, we propose a novel approach for obtaining accurate soft actuator models through the design of physical user–robot interactions for wearable robots, in which the user applies external forces to the robot. To obtain an accurate soft actuator model from the limited amount of data acquired through an interaction, we leverage an active learning framework based on Gaussian process regression. We conducted experiments using a two-degree-of-freedom upper-limb exoskeleton robot with four pneumatic artificial muscles (PAMs). Experimental results showed that physical interactions between the exoskeleton robot and the user were successfully designed to allow PAM models to be identified. Furthermore, we found that data acquired through an interaction could result in more accurate soft actuator models for the exoskeleton robots than data acquired without a physical interaction between the exoskeleton robot and the user.},
  archive  = {J},
  author   = {Masashi Hamaya and Takamitsu Matsubara and Tatsuya Teramae and Tomoyuki Noda and Jun Morimoto},
  doi      = {10.1177/0278364919853618},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {397-410},
  title    = {Design of physical user–robot interactions for model identification of soft actuators on exoskeleton robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Adaptive tensegrity locomotion: Controlling a compliant
icosahedron with symmetry-reduced reinforcement learning. <em>The
International Journal of Robotics Research</em>, <em>40</em>(1),
375–396. (<a href="https://doi.org/10.1177/0278364919859443">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Tensegrity robots, which are prototypical examples of hybrid soft–rigid robots, exhibit dynamical properties that provide ruggedness and adaptability. They also bring about, however, major challenges for locomotion control. Owing to high dimensionality and the complex evolution of contact states, data-driven approaches are appropriate for producing viable feedback policies for tensegrities. Guided policy search (GPS), a sample-efficient hybrid framework for optimization and reinforcement learning, has previously been applied to generate periodic, axis-constrained locomotion by an icosahedral tensegrity on flat ground. Varying environments and tasks, however, create a need for more adaptive and general locomotion control that actively utilizes an expanded space of robot states. This implies significantly higher needs in terms of sample data and setup effort. This work mitigates such requirements by proposing a new GPS -based reinforcement learning pipeline, which exploits the vehicle’s high degree of symmetry and appropriately learns contextual behaviors that are sustainable without periodicity. Newly achieved capabilities include axially unconstrained rolling, rough terrain traversal, and rough incline ascent. These tasks are evaluated for a small variety of key model parameters in simulation and tested on the NASA hardware prototype, SUPERball. Results confirm the utility of symmetry exploitation and the adaptability of the vehicle. They also shed light on numerous strengths and limitations of the GPS framework for policy design and transfer to real hybrid soft–rigid robots.},
  archive  = {J},
  author   = {David Surovik and Kun Wang and Massimo Vespignani and Jonathan Bruce and Kostas E Bekris},
  doi      = {10.1177/0278364919859443},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {375-396},
  title    = {Adaptive tensegrity locomotion: Controlling a compliant icosahedron with symmetry-reduced reinforcement learning},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). On the motion/stiffness decoupling property of articulated
soft robots with application to model-free torque iterative learning
control. <em>The International Journal of Robotics Research</em>,
<em>40</em>(1), 348–374. (<a
href="https://doi.org/10.1177/0278364920943275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article tackles the problem of controlling articulated soft robots (ASRs), i.e., robots with either fixed or variable elasticity lumped at the joints. Classic control schemes rely on high-authority feedback actions, which have the drawback of altering the desired robot softness. The problem of accurate control of ASRs, without altering their inherent stiffness, is particularly challenging because of their complex and hard-to-model nonlinear dynamics. Leveraging a learned anticipatory action, iterative learning control (ILC) strategies do not suffer from these issues. Recently, ILC was adopted to perform position control of ASRs. However, the limitation of position-based ILC in controlling variable stiffness robots is that whenever the robot stiffness profile is changed, a different input action has to be learned. Our first contribution is to identify a wide class of ASRs, whose motion and stiffness adjusting dynamics can be proved to be decoupled. This class is described by two properties that we define: strong elastic coupling, relative to motors and links of the system and their connections; and homogeneity, relative to the characteristics of the motors. Furthermore, we design a torque-based ILC scheme that, starting from a rough estimation of the system parameters, refines the torque needed for the joint positions tracking. The resulting control scheme requires minimum knowledge of the system. Experiments on variable stiffness robots prove that the method effectively generalizes the iterative procedure with respect to the desired stiffness profile and allows good tracking performance. Finally, potential restrictions of the method, e.g., caused by friction phenomena, are discussed.},
  archive  = {J},
  author   = {Riccardo Mengacci and Franco Angelini and Manuel G Catalano and Giorgio Grioli and Antonio Bicchi and Manolo Garabini},
  doi      = {10.1177/0278364920943275},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {348-374},
  title    = {On the motion/stiffness decoupling property of articulated soft robots with application to model-free torque iterative learning control},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). TMTDyn: A matlab package for modeling and control of hybrid
rigid–continuum robots based on discretized lumped systems and
reduced-order models. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 296–347. (<a
href="https://doi.org/10.1177/0278364919881685">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A reliable, accurate, and yet simple dynamic model is important to analyzing, designing, and controlling hybrid rigid–continuum robots. Such models should be fast, as simple as possible, and user-friendly to be widely accepted by the ever-growing robotics research community. In this study, we introduce two new modeling methods for continuum manipulators: a general reduced-order model (ROM) and a discretized model with absolute states and Euler–Bernoulli beam segments (EBA). In addition, a new formulation is presented for a recently introduced discretized model based on Euler–Bernoulli beam segments and relative states (EBR). We implement these models in a Matlab software package, named TMTDyn, to develop a modeling tool for hybrid rigid–continuum systems. The package features a new high-level language (HLL) text-based interface, a CAD-file import module, automatic formation of the system equation of motion (EOM) for different modeling and control tasks, implementing Matlab C-mex functionality for improved performance, and modules for static and linear modal analysis of a hybrid system. The underlying theory and software package are validated for modeling experimental results for (i) dynamics of a continuum appendage, and (ii) general deformation of a fabric sleeve worn by a rigid link pendulum. A comparison shows higher simulation accuracy (8–14% normalized error) and numerical robustness of the ROM model for a system with a small number of states, and computational efficiency of the EBA model with near real-time performances that makes it suitable for large systems. The challenges and necessary modules to further automate the design and analysis of hybrid systems with a large number of states are briefly discussed.},
  archive  = {J},
  author   = {S.M. Hadi Sadati and S. Elnaz Naghibi and Ali Shiva and Brendan Michael and Ludovic Renson and Matthew Howard and Caleb D. Rucker and Kaspar Althoefer and Thrishantha Nanayakkara and Steffen Zschaler and Christos Bergeles and Helmut Hauser and Ian D. Walker},
  doi      = {10.1177/0278364919881685},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {296-347},
  title    = {TMTDyn: A matlab package for modeling and control of hybrid rigid–continuum robots based on discretized lumped systems and reduced-order models},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Decoupled nonlinear adaptive control of position and
stiffness for pneumatic soft robots. <em>The International Journal of
Robotics Research</em>, <em>40</em>(1), 277–295. (<a
href="https://doi.org/10.1177/0278364920903787">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article addresses the problem of simultaneous and robust closed-loop control of joint stiffness and position, for a class of antagonistically actuated pneumatic soft robots with rigid links and compliant joints. By introducing a first-order dynamic equation for the stiffness variable and using the additional control degree of freedom, embedded in the null space of the pneumatic actuator matrix, an innovative control approach is introduced comprising an adaptive compensator and a dynamic decoupler. The proposed solution builds upon existing adaptive control theory and provides a technique for closing the loop on joint stiffness in pneumatic variable stiffness actuators. Under a very mild assumption involving the inertia and actuator matrices, the solution is able to cope with uncertainties of the model and, when the desired stiffness is constant or slowly varying, also of the pneumatic actuator. Position and stiffness decoupling is achieved by the introduction of a first-order differential equation for an internal state variable of the controller, which takes into account the time derivative of pressure in the stiffness dynamics. A formal proof of the stability of the position and stiffness tracking errors is provided. An appealing property of the approach is that it does not require higher derivatives of position or any derivatives of stiffness. The solution is validated with respect to several use-cases, first in simulation and then via a real pneumatic soft robot with McKibben muscles. A comparison with respect to existing techniques reveals a more robust position and stiffness tracking skill.},
  archive  = {J},
  author   = {Maja Trumić and Kosta Jovanović and Adriano Fagiolini},
  doi      = {10.1177/0278364920903787},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {277-295},
  title    = {Decoupled nonlinear adaptive control of position and stiffness for pneumatic soft robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Model-based online learning and adaptive control for a
“human-wearable soft robot” integrated system. <em>The International
Journal of Robotics Research</em>, <em>40</em>(1), 256–276. (<a
href="https://doi.org/10.1177/0278364919873379">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Soft robots are considered intrinsically safe with regard to human–robot interaction. This has motivated the development and investigation of soft medical robots, such as soft robotic gloves for stroke rehabilitation. However, the output force of conventional purely soft actuators is usually limited. This restricts their application in stroke rehabilitation, which requires a large force and bidirectional movement. In addition, accurate control of soft actuators is difficult owing to the nonlinearity of purely soft actuators. In this study, a soft robotic glove is designed based on a soft-elastic composite actuator (SECA) that integrates an elastic torque compensating layer to increase the output force as well as achieving bidirectional movement. Such a hybrid design also significantly reduces the degree of nonlinearity compared with a purely soft actuator. A model-based online learning and adaptive control algorithm is proposed for the wearable soft robotic glove, taking its interaction environment into account, namely, the human hand/finger. The designed hybrid controller enables the soft robotic glove to adapt to different hand conditions for reference tracking. Experimental results show that satisfactory tracking performance can be achieved on both healthy subjects and stroke subjects (with the tracking root mean square error (RMSE) &lt; 0.05 rad). Meanwhile, the controller can output an actuator–finger model for each individual subject (with the learning error RMSE &lt; 0.06 rad), which provides information on the condition of the finger and, thus, has further potential clinical application.},
  archive  = {J},
  author   = {Zhi Qiang Tang and Ho Lam Heung and Kai Yu Tong and Zheng Li},
  doi      = {10.1177/0278364919873379},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {256-276},
  title    = {Model-based online learning and adaptive control for a “human-wearable soft robot” integrated system},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Energy-shaping control of soft continuum manipulators with
in-plane disturbances. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 236–255. (<a
href="https://doi.org/10.1177/0278364920907679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Soft continuum manipulators offer levels of compliance and inherent safety that can render them a superior alternative to conventional rigid robots for a variety of tasks, such as medical interventions or human–robot interaction. However, the ability of soft continuum manipulators to compensate for external disturbances needs to be further enhanced to meet the stringent requirements of many practical applications. In this paper, we investigate the control problem for soft continuum manipulators that consist of one inextensible segment of constant section, which bends under the effect of the internal pressure and is subject to unknown disturbances acting in the plane of bending. A rigid-link model of the manipulator with a single input pressure is employed for control purposes and an energy-shaping approach is proposed to derive the control law. A method for the adaptive estimation of disturbances is detailed and a disturbance compensation strategy is proposed. Finally, the effectiveness of the controller is demonstrated with simulations and with experiments on an inextensible soft continuum manipulator that employs pneumatic actuation.},
  archive  = {J},
  author   = {Enrico Franco and Arnau Garriga-Casanovas},
  doi      = {10.1177/0278364920907679},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {236-255},
  title    = {Energy-shaping control of soft continuum manipulators with in-plane disturbances},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling biomechanical interaction between soft tissue and
soft robotic instruments: Importance of constitutive anisotropic
hyperelastic formulations. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 224–235. (<a
href="https://doi.org/10.1177/0278364920927476">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Cardiovascular diseases are the leading cause of death in the western countries. Robotic surgery recently emerged as a confirmed strategy in the cardiovascular field, especially thanks to the improvement of soft robotics. These techniques have demonstrated their potential in terms of speed of execution and precision. In this context, a deeper knowledge of the material properties of the blood vessels is required, especially for computational soft robotics applications. A constitutive model including the contribution of the collagen fibers families is needed to take hyperelasticity and anisotropy into account. For this purpose, four different models are presented: two fiber families with dispersion (2FFD), two fiber families without dispersion (2FF), four fiber families with dispersion (4FFD), and four fiber families without dispersion (4FF). A set of experimental biaxial data obtained from ex-vivo specimens was used to assess the model performances. Two fitting procedures were imposed: a procedure with no weighting of scores and a procedure with a weight set to enhance the model performances in the contact range. A finite element simulation of a contact procedure was developed to evaluate the effect on the contact pressures and forces according to the different model implementations. In particular, a minimally invasive aortic valve positioning process through a previously designed soft robot was simulated. The results confirmed the overall fitting procedure. The adoption of the weighting process for the fitting was successful, as it permitted an accurate prediction in the region of interest through models with less parameters.},
  archive  = {J},
  author   = {Emanuele Vignali and Emanuele Gasparotti and Katia Capellini and Benigno Marco Fanni and Luigi Landini and Vincenzo Positano and Simona Celi},
  doi      = {10.1177/0278364920927476},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {224-235},
  title    = {Modeling biomechanical interaction between soft tissue and soft robotic instruments: Importance of constitutive anisotropic hyperelastic formulations},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The softness distribution index: Towards the creation of
guidelines for the modeling of soft-bodied robots. <em>The International
Journal of Robotics Research</em>, <em>40</em>(1), 197–223. (<a
href="https://doi.org/10.1177/0278364919893451">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Modeling soft robots is not an easy task owing to their highly nonlinear mechanical behavior. So far, several researchers have tackled the problem using different approaches, each having advantages and drawbacks in terms of accuracy, ease of implementation, and computational burden. The soft robotics community is currently working to develop a unified framework for modeling. Our contribution in this direction consists of a novel dimensionless quantity that we call the softness distribution index (SDI). The SDI for a given soft body is computed based on the distribution of its structural properties. We show that the index can serve as a tool in the choice of a modeling technique among multiple approaches suggested in literature. At the moment, the investigation is limited to bodies performing planar bending. The aim of this work is twofold: (i) to highlight the importance of the distribution of the geometrical and material properties of a soft robotic link/body throughout its structure; and (ii) to demonstrate that a classification based on this distribution provides guidelines for the modeling.},
  archive  = {J},
  author   = {Giovanna A Naselli and Barbara Mazzolai},
  doi      = {10.1177/0278364919893451},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {197-223},
  title    = {The softness distribution index: Towards the creation of guidelines for the modeling of soft-bodied robots},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Controlling the deformation space of soft membranes using
fiber reinforcement. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 178–196. (<a
href="https://doi.org/10.1177/0278364919897134">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recent efforts in soft-body control have been hindered by the infinite dimensionality of soft bodies. Without restricting the deformation space of soft bodies to desired degrees of freedom, it is difficult, if not impossible, to guarantee that the soft body will remain constrained within a desired operating range. In this article, we present novel modeling and fabrication techniques for leveraging the reorientation of fiber arrays in soft bodies to restrict their deformation space to a critical case. Implementing this fiber reinforcement introduces unique challenges, especially in complex configurations. To address these challenges, we present a geometric technique for modeling fiber reinforcement on smooth elastomeric surfaces and a two-stage molding process to embed the fiber patterns dictated by that technique into elastomer membranes. The variable material properties afforded by fiber reinforcement are demonstrated with the canonical case of a soft, circular membrane reinforced with an embedded, intersecting fiber pattern such that it deforms into a prescribed hemispherical geometry when inflated. It remains constrained to that configuration, even with an additional increase in internal pressure. Furthermore, we show that the fiber-reinforced membrane is capable of maintaining its hemispherical shape under a load, and we present a practical application for the membrane by using it to control the buoyancy of a bioinspired autonomous underwater robot developed in our lab. An additional experiment on a circular membrane that inflates to a conical frustum is presented to provide additional validation of the versatility of the proposed model and fabrication techniques.},
  archive  = {J},
  author   = {Nick Sholl and Austin Moss and Mike Krieg and Kamran Mohseni},
  doi      = {10.1177/0278364919897134},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {178-196},
  title    = {Controlling the deformation space of soft membranes using fiber reinforcement},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). A generalizable equilibrium model for bending soft arms with
longitudinal actuators. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 148–177. (<a
href="https://doi.org/10.1177/0278364919880259">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Current models of bending in soft arms are formulated in terms of experimentally determined, arm-specific parameters, which cannot evaluate fundamental differences in soft robot arm design. Existing models are successful at improving control of individual arms but do not give insight into how the structure of the arm affects the arm’s capabilities. For example, omnidirectional soft robot arms most frequently have three parallel actuators, but may have four or more, while common biological arms, including octopuses, have tens of distinct longitudinal muscle bundles. This article presents a quasi-static analytical model of soft arms bent with longitudinal actuators, based on equilibrium principles and assuming an unknown neutral axis location. The model is presented as a generalizable framework and specifically implemented for an arm with N fluid-driven actuators, a subset of which are pressurized to induce a bend with a certain curvature and direction. The presented implementation is validated experimentally using planar (2D) and spatial (3D) bends. The planar model is used to initially estimate pressure for a closed-loop curvature control system and to bound the accessible configurations for a rapidly-exploring random trees (RRT) motion planner. A three-segment planar arm is demonstrated to navigate along a planned trajectory through a gap in a wall. Finally, the model is used to explore how the arm morphology affects maximum curvature and directional resolution. This research analytically connects soft arm structure and actuator behavior to unloaded arm performance, and the results may be used to methodically design soft robot arms.},
  archive  = {J},
  author   = {Gina Olson and Scott Chow and Austin Nicolai and Callie Branyan and Geoffrey Hollinger and Yiğit Mengüç},
  doi      = {10.1177/0278364919880259},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {148-177},
  title    = {A generalizable equilibrium model for bending soft arms with longitudinal actuators},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Modeling and analysis of hydraulic piston actuation of
McKibben fluidic artificial muscles for hand rehabilitation. <em>The
International Journal of Robotics Research</em>, <em>40</em>(1),
136–147. (<a href="https://doi.org/10.1177/0278364919872251">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Soft robotic actuators are well-suited for interactions with the human body, particularly in rehabilitation applications. The fluidic artificial muscle (FAM), specifically the McKibben FAM, is a type of soft robotic actuator that can be driven either pneumatically or hydraulically, and has potential for use in rehabilitation devices. The force applied by a FAM is well-described by a variety of models, the most common of which is based on the virtual work principle. However, the use of a piston assembly as a hydraulic power source for activation of FAMs has not previously been modeled in detail. This article presents a FAM designed to address the specific needs of a hand rehabilitation device. A syringe pump test bed is used to find and validate a novel volume–strain relationship. The volume–strain relationship remains constant with the coupled piston–FAM system, regardless of load. This confirms a bivariate approach to FAM control which is particularly beneficial in the exoskeleton application as the load varies throughout use. A novel, fixed-end cylindrical model is found to predict the strain of the FAM, given a volume input, regardless of load. For the FAMs tested in this work, the fixed-end cylindrical model improves strain prediction seven-fold when compared with traditional models.},
  archive  = {J},
  author   = {Anderson S Camp and Edward M Chapman and Paola Jaramillo Cienfuegos},
  doi      = {10.1177/0278364919872251},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {136-147},
  title    = {Modeling and analysis of hydraulic piston actuation of McKibben fluidic artificial muscles for hand rehabilitation},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Comparison and experimental validation of predictive models
for soft, fiber-reinforced actuators. <em>The International Journal of
Robotics Research</em>, <em>40</em>(1), 119–135. (<a
href="https://doi.org/10.1177/0278364919879493">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Successful soft robot modeling approaches appearing in the recent literature have been based on a variety of distinct theories, including traditional robotic theory, continuum mechanics, and machine learning. Though specific modeling techniques have been developed for and validated against already realized systems, their strengths and weaknesses have not been explicitly compared against each other. In this article, we show how three distinct model structures, a lumped-parameter model, a continuum mechanical model, and a neural network, compare in capturing the gross trends and specific features of the force generation of soft robotic actuators. In particular, we study models for fiber-reinforced elastomeric enclosures (FREEs), which are a popular choice of soft actuator and that are used in several soft articulated systems, including soft manipulators, exoskeletons, grippers, and locomoting soft robots. We generated benchmark data by testing eight FREE samples that spanned broad design and kinematic spaces and compared the models on their ability to predict the loading–deformation relationships of these samples. This comparison shows the predictive capabilities of each model on individual actuators and each model’s generalizability across the design space. While the neural net achieved the highest peak performance, the first principles-based models generalized best across all actuator design parameters tested. The results highlight the essential roles of mathematical structure and experimental parameter determination in building high-performing, generalizable soft actuator models with varying effort invested in system identification.},
  archive  = {J},
  author   = {Audrey Sedal and Alan Wineman and R. Brent Gillespie and C. David Remy},
  doi      = {10.1177/0278364919879493},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {119-135},
  title    = {Comparison and experimental validation of predictive models for soft, fiber-reinforced actuators},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Algebraic approach towards the exploitation of “softness”:
The input–output equation for morphological computation. <em>The
International Journal of Robotics Research</em>, <em>40</em>(1), 99–118.
(<a href="https://doi.org/10.1177/0278364920912298">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Recently, soft robots that consist of soft and deformable materials have received much attention for their adaptability to uncertain environments. Although these robots are difficult to control with a conventional control theory owing to their complex body dynamics, research from different perspectives attempts to actively exploit these body dynamics as an asset rather than a drawback. This approach is called morphological computation, in which the soft materials are used for computation that includes a new kind of control strategy. In this article, we propose a novel approach to analyze the computational properties of soft materials based on an algebraic method, called the input–output equation used in systems analysis, particularly in systems biology. We mainly focus on the two scenarios relevant to soft robotics, that is, analysis of the computational capabilities of soft materials and design of the input force to soft devices to generate the target behaviors. The input–output equation directly describes the relationship between inputs and outputs of a system, and hence by using this equation, important properties, such as the echo state property that guarantees reproducible responses against the same input stream, can be investigated for soft structures. Several application scenarios of our proposed method are demonstrated using typical soft robotic settings in detail, including linear/nonlinear models and hydrogels driven by chemical reactions.},
  archive  = {J},
  author   = {Mizuka Komatsu and Takaharu Yaguchi and Kohei Nakajima},
  doi      = {10.1177/0278364920912298},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {99-118},
  title    = {Algebraic approach towards the exploitation of “softness”: The input–output equation for morphological computation},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Quasi-static modeling of a novel growing soft-continuum
robot. <em>The International Journal of Robotics Research</em>,
<em>40</em>(1), 86–98. (<a
href="https://doi.org/10.1177/0278364919893438">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Soft-continuum robots attract researchers owing to their advantages over rigid-bodied robots such as adaptation of the flexible structure to tortuous environments, and compliant contact mechanics. The need for new modeling methods to attain precise control for such systems has emerged from the recent rapid progress in soft robotics. This article presents a quasi-static model for a growing soft-continuum robot that is propelled via thin-walled inflated tubes, and steered by the difference between tube lengths. Therefore, the robot shaft is modeled as a series of inflated beams under deformation. A quasi-static model coupled with a kinematic model is developed to accurately position the end effector while accounting for the inflated beam stiffness and end-effector loads. The proposed model calculates control parameters, namely tube lengths and tendon tensions required to maintain the end effector at a certain position. Tip deflection due to end-effector loading is calculated and kinematic model inputs are updated to correct positioning error caused by shaft deformation. The model is simulated for the soft-continuum robot moving on a path to show the change in model parameters for various end-effector positions. Results demonstrate the significance of including pressurized tube stiffness in the model for growing robots of similar type. Second, the need for tendons in addition to pneumatic actuation is emphasized for accurate positioning of the end effector under loading. The proposed model offers a potential method for simulation and control of similar growing soft-continuum robots presented in the literature.},
  archive  = {J},
  author   = {Cem Tutcu and Bora A. Baydere and Seref K. Talas and Evren Samur},
  doi      = {10.1177/0278364919893438},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {86-98},
  title    = {Quasi-static modeling of a novel growing soft-continuum robot},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Soft pneumatic actuator-driven origami-inspired modular
robotic “pneumagami.” <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 72–85. (<a
href="https://doi.org/10.1177/0278364920909905">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article presents a new modular robotic platform for enabling reconfigurable, actively controlled, high-degree-of-freedom (high-DoF) systems with compact form factor. The robotic modules exploit the advantages of origami-inspired construction methods and materials, and soft pneumatic actuators (SPAs) to achieve an actuator embedded, parallel kinematic mechanism with three independently controlled “waterbomb” base legs. The multi-material, layer-fabricated body of the modules features selectively compliant flexure hinge elements between rigid panels that define the module as a kinematic 6R spherical joint. The precision layer-fabrication technique is also used to form embedded distribution channels within the module base to connect actuators to onboard control hardware. A decentralized control architecture is applied by integrating each module with small-scale solenoid valves, communication electronics, and sensors. This design approach enables a single pneumatic supply line to be shared between modules, while still allowing independent control of each leg joint, driven by soft, inflatable pouch actuators. A passive pneumatic relay is also designed and incorporated in each module to leverage the coupled, inverted inflation, and exhaust states between antagonistic actuator pairs allowing both to be controlled by a single solenoid valve. A prototype module is presented as the first demonstration of integrated modular origami and SPA design, or pneumagami, which allows predefined kinematic structural mechanisms to locally prescribe specific motions by active effect, not just through passive compliance, to dictate task space and motion. The design strategy facilitates the composition of lightweight, high-strength robotic structures with many DoFs that will benefit various fields such as wearable robotics.},
  archive  = {J},
  author   = {Matthew A Robertson and Ozdemir Can Kara and Jamie Paik},
  doi      = {10.1177/0278364920909905},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {72-85},
  title    = {Soft pneumatic actuator-driven origami-inspired modular robotic “pneumagami”},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Compliant gripper design, prototyping, and modeling using
screw theory formulation. <em>The International Journal of Robotics
Research</em>, <em>40</em>(1), 55–71. (<a
href="https://doi.org/10.1177/0278364920947818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {This article investigates some aspects related to the design, modeling, prototyping, and testing of soft–rigid tendon-driven grippers. As a case study, we present the design and development of a two-finger soft gripper and exploit it as an example to demonstrate the application scenario of our mathematical model based on screw theory. A mathematical formulation based on screw theory is then presented to model gripper dynamics. The proposed formulation is the extension of a model previously introduced including the mechanical system dynamics. In this type of gripper, it is possible to achieve different behaviors, e.g., different fingertip trajectories, equivalent fingertip stiffness ellipsoids, etc., while keeping the same kinematic structure of the gripper and varying the properties of its passive deformable joints. These properties can be varied in the prototype by properly regulating some manufacturing parameters, such as percentage of printing infill density in a 3D printing process. We performed experiments with the prototype of the gripper and an optical tracking system to validate the proposed mathematical formulation, and to compare its results with other simplified formulations. We furthermore identified the main performance of the gripper in terms of payload and maximum horizontal resisted force, and verified the capabilities of the gripper to grasp objects with different shapes and weights.},
  archive  = {J},
  author   = {Irfan Hussain and Monica Malvezzi and Dongming Gan and Zubair Iqbal and Lakmal Seneviratne and Domenico Prattichizzo and Federico Renda},
  doi      = {10.1177/0278364920947818},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {55-71},
  title    = {Compliant gripper design, prototyping, and modeling using screw theory formulation},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). An efficient leg with series–parallel and biarticular
compliant actuation: Design optimization, modeling, and control of the
eLeg. <em>The International Journal of Robotics Research</em>,
<em>40</em>(1), 37–54. (<a
href="https://doi.org/10.1177/0278364919893762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We present the development, modeling, and control of a three-degree-of-freedom compliantly actuated leg called the eLeg , which employs both series- and parallel-elastic actuation as well as a bio-inspired biarticular tendon. The leg can be reconfigured to use three distinct actuation configurations, to directly compare with a state-of-the-art series-elastic actuation scheme. Critical actuation design parameters are derived through optimization. A rigorous modeling approach is presented using the concept of power flows, which are also used to demonstrate the ability to transfer mechanical power between ankle and knee joints using the biarticular tendon. The design principles and control strategies were verified both in simulation and experiment. Notably, the experimental data demonstrate significant improvements of 65–75% in electrical energy consumption compared with a state-of-the-art series-elastic actuator configuration.},
  archive  = {J},
  author   = {Wesley Roozing and Zeyu Ren and Nikos G Tsagarakis},
  doi      = {10.1177/0278364919893762},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {37-54},
  title    = {An efficient leg with series–parallel and biarticular compliant actuation: Design optimization, modeling, and control of the eLeg},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). The design and development of branch bot: A branch-crawling,
caterpillar-inspired, soft robot. <em>The International Journal of
Robotics Research</em>, <em>40</em>(1), 24–36. (<a
href="https://doi.org/10.1177/0278364919846358">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A soft climbing robot has the potential to access locations such as wiring ducts and tree canopies that are unreachable by humans and traditional rigid robots. In addition, a soft robot is robust and can fall without damaging itself or its environment. We present a soft, branch-crawling robot that is inspired by the passive gripping mechanisms used by caterpillars. The conformability of the robot’s soft body makes it uniquely suited to move in a complex 3D environment. A key innovation is that grip release is actively controlled and coordinated with propulsion generated by stored elastic energy. The robot is molded from silicone rubber and actuated using remote motor-tendons coupled to the structure through Bowden cables. Grip is achieved passively through an elastic flexure that pushes a compliant finger against the dowel. Experimental results show that the gripper is easily able to support the weight of the robot, and that the body structure allows the robot to crawl horizontally, vertically, and along branches. This robot demonstrates some key advantages of a soft robotic platform over traditional rigid robots.},
  archive  = {J},
  author   = {Shane Rozen-Levy and William Messner and Barry A Trimmer},
  doi      = {10.1177/0278364919846358},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {24-36},
  title    = {The design and development of branch bot: A branch-crawling, caterpillar-inspired, soft robot},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Tendon-driven continuum robots with extensible sections—a
model-based evaluation of path-following motions. <em>The International
Journal of Robotics Research</em>, <em>40</em>(1), 7–23. (<a
href="https://doi.org/10.1177/0278364919886047">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Continuum robots are highly miniaturizable, exhibit non-linear shapes with several curves, and are flexible and compliant. In particular, concentric-tube and tendon-driven continuum robots can be designed on a small scale with diameters of below 10 mm. A small diameter-to-length ratio enables insertion of these robots through small entry points in order to reach hardly accessible regions by avoiding obstacles. This scenario can often be found in minimally invasive surgery and technical inspections. However, to reach the target region, a deployment along a narrow tortuous path is often required. Common tendon-driven continuum robots are intrinsically incapable of such deployment and concentric-tube continuum robots require special path conditions and intensive parameter optimization. Other proposed robot types, such as hyper-redundant and pneumatically actuated robots, exhibit less favorable diameter-to-length ratios and are thus not suitable for those tasks. Since the limiting factors are found in the design of continuum robots, we propose a novel tendon-driven continuum robot design, which features an additional degree of freedom in each robot section. The backbone is composed of straight, concentrically arranged tubes, each of which composes a section and is used to adapt its length. We present a three-section continuum robot prototype with a diameter of 7 mm, determine its follow-the-leader capabilities theoretically, and validate the results experimentally using model-based control. For our 165 mm long robot prototype, the repeatability is below 2.38 mm. The model accuracy reaches a median of 3.16% over 25 configurations with respect to robot length. The path-following error over five curvilinear paths results in median errors of 2.59% with respect to robot length.},
  archive  = {J},
  author   = {Ernar Amanov and Thien-Dang Nguyen and Jessica Burgner-Kahrs},
  doi      = {10.1177/0278364919886047},
  journal  = {The International Journal of Robotics Research},
  month    = {1},
  number   = {1},
  pages    = {7-23},
  title    = {Tendon-driven continuum robots with extensible sections—A model-based evaluation of path-following motions},
  volume   = {40},
  year     = {2021},
}
</textarea>
</details></li>
<li><details>
<summary>
(2021). Editorial: Soft robotic modeling and control: Bringing
together articulated soft robots and soft-bodied robots. <em>The
International Journal of Robotics Research</em>, <em>40</em>(1), 3–6.
(<a href="https://doi.org/10.1177/0278364921998088">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive = {J},
  author  = {Cosimo Della Santina and Robert K. Katzschmann and Antonio Bicchi and Daniela Rus},
  doi     = {10.1177/0278364921998088},
  journal = {The International Journal of Robotics Research},
  month   = {1},
  number  = {1},
  pages   = {3-6},
  title   = {Editorial: soft robotic modeling and control: bringing together articulated soft robots and soft-bodied robots},
  volume  = {40},
  year    = {2021},
}
</textarea>
</details></li>
</ul>

</body>
</html>
