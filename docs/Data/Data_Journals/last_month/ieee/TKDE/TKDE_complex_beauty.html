<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TKDE_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tkde---32">TKDE - 32</h2>
<ul>
<li><details>
<summary>
(2025). Web-FTP: A feature transferring-based pre-trained model for
web attack detection. <em>TKDE</em>, <em>37</em>(3), 1495–1507. (<a
href="https://doi.org/10.1109/TKDE.2024.3512793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Web attack is a major threat to cyberspace security, so web attack detection models have become a critical task. Traditional supervised learning methods learn features of web attacks with large amounts of high-confidence labeled data, which are extremely expensive in the real world. Pre-trained models offer a novel solution with their ability to learn generic features on large unlabeled datasets. However, designing and deploying a pre-trained model for real-world web attack detection remains challenges. In this paper, we present a pre-trained model for web attack detection, including a pre-processing module, a pre-training module, and a deployment scheme. Our model significantly improves classification performance on several web attack detection datasets. Moreover, we deploy the model in real-world systems and show its potential for industrial applications.},
  archive      = {J_TKDE},
  author       = {Zhenyu Guo and Qinghua Shang and Xin Li and Chengyi Li and Zijian Zhang and Zhuo Zhang and Jingjing Hu and Jincheng An and Chuanming Huang and Yang Chen and Yuguang Cai},
  doi          = {10.1109/TKDE.2024.3512793},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1495-1507},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Web-FTP: A feature transferring-based pre-trained model for web attack detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UniTE: A survey and unified pipeline for pre-training
spatiotemporal trajectory embeddings. <em>TKDE</em>, <em>37</em>(3),
1475–1494. (<a href="https://doi.org/10.1109/TKDE.2024.3523996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spatiotemporal trajectories are sequences of timestamped locations, which enable a variety of analyses that in turn enable important real-world applications. It is common to map trajectories to vectors, called embeddings, before subsequent analyses. Thus, the qualities of embeddings are very important. Methods for pre-training embeddings, which leverage unlabeled trajectories for training universal embeddings, have shown promising applicability across different tasks, thus attracting considerable interest. However, research progress on this topic faces two key challenges: a lack of a comprehensive overview of existing methods, resulting in several related methods not being well-recognized, and the absence of a unified pipeline, complicating the development of new methods and the analysis of methods. We present UniTE, a survey and a unified pipeline for this domain. In doing so, we present a comprehensive list of existing methods for pre-training trajectory embeddings, which includes methods that either explicitly or implicitly employ pre-training techniques. Further, we present a unified and modular pipeline with publicly available underlying code, simplifying the process of constructing and evaluating methods for pre-training trajectory embeddings. Additionally, we contribute a selection of experimental results using the proposed pipeline on real-world datasets.},
  archive      = {J_TKDE},
  author       = {Yan Lin and Zeyu Zhou and Yicheng Liu and Haochen Lv and Haomin Wen and Tianyi Li and Yushuai Li and Christian S. Jensen and Shengnan Guo and Youfang Lin and Huaiyu Wan},
  doi          = {10.1109/TKDE.2024.3523996},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1475-1494},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {UniTE: A survey and unified pipeline for pre-training spatiotemporal trajectory embeddings},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). The expressive power of graph neural networks: A survey.
<em>TKDE</em>, <em>37</em>(3), 1455–1474. (<a
href="https://doi.org/10.1109/TKDE.2024.3523700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) are effective machine learning models for many graph-related applications. Despite their empirical success, many research efforts focus on the theoretical limitations of GNNs, i.e., the GNNs expressive power. Early works in this domain mainly focus on studying the graph isomorphism recognition ability of GNNs, and recent works try to leverage the properties such as subgraph counting and connectivity learning to characterize the expressive power of GNNs, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for models for enhancing expressive power under different forms of definition. Concretely, the models are reviewed based on three categories, i.e., Graph feature enhancement, Graph topology enhancement, and GNNs architecture enhancement.},
  archive      = {J_TKDE},
  author       = {Bingxu Zhang and Changjun Fan and Shixuan Liu and Kuihua Huang and Xiang Zhao and Jincai Huang and Zhong Liu},
  doi          = {10.1109/TKDE.2024.3523700},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1455-1474},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {The expressive power of graph neural networks: A survey},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-correcting clustering. <em>TKDE</em>, <em>37</em>(3),
1439–1454. (<a href="https://doi.org/10.1109/TKDE.2024.3523021">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The incorporation of target distribution significantly enhances the success of deep clustering. However, most of the related deep clustering methods suffer from two drawbacks: (1) manually-designed target distribution functions with uncertain performance and (2) cluster misassignment accumulation. To address these issues, a Self-Correcting Clustering (Self-CC) framework is proposed. In Self-CC, a robust target distribution solver (RTDS) is designed to automatically predict the target distribution and alleviate the adverse influence of misassignments. Specifically, RTDS divides the high confidence samples selected according to the cluster assignments predicted by a clustering module into labeled samples with correct pseudo labels and unlabeled samples of possible misassignments by modeling its training loss distribution. With the divided data, RTDS can be trained in a semi-supervised way. The critical hyperparameter which controls the semi-supervised training process can be set adaptively by estimating the distribution property of misassignments in the pseudo-label space with the support of a theoretical analysis. The target distribution can be predicted by the well-trained RTDS automatically, optimizing the clustering module and correcting misassignments in the cluster assignments. The clustering module and RTDS mutually promote each other forming a positive feedback loop. Extensive experiments on four benchmark datasets demonstrate the effectiveness of the proposed Self-CC.},
  archive      = {J_TKDE},
  author       = {Hanxuan Wang and Na Lu and Zixuan Wang and Yuxuan Yan and Gustavo Carneiro and Zhen Wang},
  doi          = {10.1109/TKDE.2024.3523021},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1439-1454},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Self-correcting clustering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Segmented sequence prediction using variable-order markov
model ensemble. <em>TKDE</em>, <em>37</em>(3), 1425–1438. (<a
href="https://doi.org/10.1109/TKDE.2024.3522975">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, sequence prediction, particularly in natural language processing tasks, has made significant progress due to advanced neural network architectures like Transformer and enhanced computing power. However, challenges persist in modeling and analyzing certain types of sequence data, such as human daily activities and competitive ball games. These segmented sequence data are characterized by short length, varying local dependencies, and coarse-grained unit states. These characteristics limit the effectiveness of conventional probabilistic graphical models and attention-based or recurrent neural networks in modeling and analyzing segmented sequence data. To address this gap, we introduce a novel generative model for segmented sequences, employing an ensemble of multiple variable-order Markov models (VOMMs) to flexibly represent state transition dependencies. Our approach integrates probabilistic graphical models with neural networks, surpassing the representation capabilities of single high-order or variable-order Markov models. Compared to end-to-end deep learning models, our method offers improved interpretability and reduces overfitting in short segments. We demonstrate the efficacy of our proposed method in two tasks: predicting tennis shot types and forecasting daily action sequences. These applications highlight the broad applicability of our segmented sequence modeling approach across diverse domains.},
  archive      = {J_TKDE},
  author       = {Weichao Yan and Hao Ma and Zaiyue Yang},
  doi          = {10.1109/TKDE.2024.3522975},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1425-1438},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Segmented sequence prediction using variable-order markov model ensemble},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust and communication-efficient federated domain
adaptation via random features. <em>TKDE</em>, <em>37</em>(3),
1411–1424. (<a href="https://doi.org/10.1109/TKDE.2024.3510296">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Modern machine learning (ML) models have grown to a scale where training them on a single machine becomes impractical. As a result, there is a growing trend to leverage federated learning (FL) techniques to train large ML models in a distributed and collaborative manner. These models, however, when deployed on new devices, might struggle to generalize well due to domain shifts. In this context, federated domain adaptation (FDA) emerges as a powerful approach to address this challenge. Most existing FDA approaches typically focus on aligning the distributions between source and target domains by minimizing their (e.g., MMD) distance. Such strategies, however, inevitably introduce high communication overheads and can be highly sensitive to network reliability. In this paper, we introduce RF-TCA, an enhancement to the standard Transfer Component Analysis approach that significantly accelerates computation without compromising theoretical and empirical performance. Leveraging the computational advantage of RF-TCA, we further extend it to FDA setting with FedRF-TCA. The proposed FedRF-TCA protocol boasts communication complexity that is independent of the sample size, while maintaining performance that is either comparable to or even surpasses state-of-the-art FDA methods. We present extensive experiments to showcase the superior performance and robustness (to network condition) of FedRF-TCA.},
  archive      = {J_TKDE},
  author       = {Zhanbo Feng and Yuanjie Wang and Jie Li and Fan Yang and Jiong Lou and Tiebin Mi and Robert Caiming Qiu and Zhenyu Liao},
  doi          = {10.1109/TKDE.2024.3510296},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1411-1424},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Robust and communication-efficient federated domain adaptation via random features},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RMD-graph: Adversarial attacks resisting malicious domain
detection based on dual denoising. <em>TKDE</em>, <em>37</em>(3),
1394–1410. (<a href="https://doi.org/10.1109/TKDE.2024.3520798">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Domain Name System (DNS) is a critical Internet service that translates domain names into IPs, but it is often targeted by attackers, posing a serious security risk. Graph-based models for detecting malicious domains have shown high performance but are vulnerable to adversarial attacks. To address this issue, we propose RMD-Graph, which is characterized by its ability to resist adversarial attacks and its low dependency on labeled data. A dual denoising module is specifically designed based on two autoencoders to generate the reconstructed graph, where SVD, TOP-k and reconstruction loss are introduced to enhance the denoising capability of autoencoders. Subsequently, residual connections are employed to generate an optimized graph that retains essential information from the original graph. The reconstructed graph and the optimized graph are then utilized as two views for graph contrastive learning, thereby achieving an self-supervised representation learning task without labels. In the downstream malicious domain detection, the denoised node representations are employed for machine learning classification. Extensive experiments are conducted on publicly available DNS datasets, and the results demonstrate that RMD-Graph significantly outperforms known baseline methods, especially in adversarial scenarios.},
  archive      = {J_TKDE},
  author       = {Sanfeng Zhang and Luyao Huang and Zheng Zhang and Wenduan Xu and Wang Yang and Linfeng Liu},
  doi          = {10.1109/TKDE.2024.3520798},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1394-1410},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {RMD-graph: Adversarial attacks resisting malicious domain detection based on dual denoising},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Nowhere to H2IDE: Fraud detection from multi-relation graphs
via disentangled homophily and heterophily identification.
<em>TKDE</em>, <em>37</em>(3), 1380–1393. (<a
href="https://doi.org/10.1109/TKDE.2024.3523107">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fraud detection has always been one of the primary concerns in social and economic activities and is becoming a decisive force in the booming digital economy. Graph structures formed by rich user interactions naturally serve as important clues for identifying fraudsters. While numerous graph neural network-based methods have been proposed, the diverse interactive connections within graphs and the heterophilic connections deliberately established by fraudsters to normal users as camouflage pose new research challenges. In this light, we propose H2IDE (Homophily and Heterophily Identification with Disentangled Embeddings) for accurate fraud detection in multi-relation graphs. H2IDE features in an independence-constrained disentangled representation learning scheme to capture various latent behavioral patterns in graphs, along with a supervised identification task to specifically model the factor-wise heterophilic connections, both of which are proven crucial to fraud detection. We also design a relation-aware attention mechanism for hierarchical and adaptive neighborhood aggregation in H2IDE. Extensive comparative experiments with state-of-the-art baseline methods on two real-world multi-relation graphs and two large-scale homogeneous graphs demonstrate the superiority and scalability of our proposed method and highlight the key role of disentangled representation learning with homophily and heterophily identification.},
  archive      = {J_TKDE},
  author       = {Chao Fu and Guannan Liu and Kun Yuan and Junjie Wu},
  doi          = {10.1109/TKDE.2024.3523107},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1380-1393},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Nowhere to H2IDE: Fraud detection from multi-relation graphs via disentangled homophily and heterophily identification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Next point-of-interest recommendation with adaptive graph
contrastive learning. <em>TKDE</em>, <em>37</em>(3), 1366–1379. (<a
href="https://doi.org/10.1109/TKDE.2024.3509480">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next point-of-interest (POI) recommendation predicts user’s next movement and facilitates location-based applications such as destination suggestion and travel planning. State-of-the-art (SOTA) methods learn an adaptive graph from user trajectories and compute POI representations using graph neural networks (GNNs). However, a single graph cannot capture the diverse dependencies among the POIs (e.g., geographical proximity and transition frequency). To tackle this limitation, we propose the Adaptive Graph Contrastive Learning (AGCL) framework. AGCL constructs multiple adaptive graphs, each modeling a kind of POI dependency and producing one POI representation; and the POI representations from different graphs are merged into a multi-facet representation that encodes comprehensive information. To train the POI representations, we tailor a graph-based contrastive learning, which encourages the representations of similar POIs to align and dissimilar POIs to differentiate. Moreover, to learn the sequential regularities of user trajectories, we design an attention mechanism to integrate spatial-temporal information into the POI representations. An explicit spatial-temporal bias is also employed to adjust the predictions for enhanced accuracy. We compare AGCL with 10 state-of-the-art baselines on 3 datasets. The results show that AGCL outperforms all baselines and achieves an improvement of 10.14% over the best performing baseline in average accuracy.},
  archive      = {J_TKDE},
  author       = {Xuan Rao and Renhe Jiang and Shuo Shang and Lisi Chen and Peng Han and Bin Yao and Panos Kalnis},
  doi          = {10.1109/TKDE.2024.3509480},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1366-1379},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Next point-of-interest recommendation with adaptive graph contrastive learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Network-to-network: Self-supervised network representation
learning via position prediction. <em>TKDE</em>, <em>37</em>(3),
1354–1365. (<a href="https://doi.org/10.1109/TKDE.2024.3493391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Network Representation Learning (NRL) has achieved remarkable success in learning low-dimensional representations for network nodes. However, most NRL methods, including Graph Neural Networks (GNNs) and their variants, face critical challenges. First, labeled network data, which are required for training most GNNs, are expensive to obtain. Second, existing methods are sub-optimal in preserving comprehensive topological information, including structural and positional information. Finally, most GNN approaches ignore the rich node content information. To address these challenges, we propose a self-supervised Network-to-Network framework (Net2Net) to learn semantically meaningful node representations. Our framework employs a pretext task of node position prediction (PosPredict) to effectively fuse the topological and content knowledge into low-dimensional embeddings for every node in a semi-supervised manner. Specifically, we regard a network as node content and position networks, where Net2Net aims to learn the mapping between them. We utilize a multi-layer recursively composable encoder to integrate the content and topological knowledge into the egocentric network node embeddings. Furthermore, we design a cross-modal decoder to map the egocentric node embeddings into their node position identities (PosIDs) in the node position network. Extensive experiments on eight diverse networks demonstrate the superiority of Net2Net over comparable methods.},
  archive      = {J_TKDE},
  author       = {Jie Liu and Chunhai Zhang and Zhicheng He and Wenzheng Zhang and Na Li},
  doi          = {10.1109/TKDE.2024.3493391},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1354-1365},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Network-to-network: Self-supervised network representation learning via position prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-grade revenue maximization for promotional and
competitive viral marketing in social networks. <em>TKDE</em>,
<em>37</em>(3), 1339–1353. (<a
href="https://doi.org/10.1109/TKDE.2024.3518359">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we address the problem of revenue maximization (RM) for multi-grade products in social networks by considering pricing, seed selection, and coupon distribution. Previous works on RM often focus on a single product and neglect the use of coupons for promotion. We propose a new optimization problem, Revenue Maximization of Multi-Grade Product(RMMGP), to simultaneously determine pricing, seed selection, and coupon distribution for multi-grade products with both promotional and competitive relationships between grades in order to maximize revenue through viral marketing. We prove the hardness and inapproximability of RMMGP and show that the revenue function is not monotone or submodular. To solve RMMGP, we design an approximation algorithm, namely Data-Dependent Revenue Maximization (DDRM), and propose the Pricing-Seeding-Coupon allocation (PriSCa) algorithm, which uses the concepts of Worth Receiving Probability, Pricing-Promotion Alternating Framework, and Independent/Holistic Customer-Grade Determinant sets. Our experiments on real social networks, using valuation distributions from Amazon.com, demonstrate that PriSCa and DDRM achieve on average 1.5 times higher revenue than state-of-the-art approaches. Additionally, PriSCa is efficient and scalable on large datasets.},
  archive      = {J_TKDE},
  author       = {Ya-Wen Teng and Yishuo Shi and De-Nian Yang and Chih-Hua Tai and Philip S. Yu and Ming-Syan Chen},
  doi          = {10.1109/TKDE.2024.3518359},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1339-1353},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-grade revenue maximization for promotional and competitive viral marketing in social networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-behavior hypergraph contrastive learning for
session-based recommendation. <em>TKDE</em>, <em>37</em>(3), 1325–1338.
(<a href="https://doi.org/10.1109/TKDE.2024.3523383">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most current session-based recommendations model session sequences solely based on the user&#39;s target behavior, ignoring the user&#39;s hidden preferences in auxiliary behaviors. Additionally, they use ordinary graphs to model one-to-one item correlations in the current session and fail to leverage other sessions to learn richer higher-order item correlations. To address these issues, a multi-behavior hypergraph contrastive learning model for session-based recommendations is proposed. This model represents all the sessions as global hypergraphs according to two types of behavior sequences. It employs contrastive learning to obtain global item embeddings, which are further aggregated to generate a global session representation that captures higher-order correlations of items from all session perspectives. A novel local heterogeneous hypergraph is designed for the current session to capture higher-order correlations between items with different behaviors in the current session, thus enhancing the local session representation. Additionally, a novel self-supervised signal is created by constructing a multi-behavior line graph, enhancing the global session representation. Finally, the local session representation, global session representation, and global item embedding are used to learn the predicted interaction probability of each item. Extensive experiments are conducted on three real datasets, and the results demonstrate that the proposed model significantly improves recommendation accuracy.},
  archive      = {J_TKDE},
  author       = {Liangmin Guo and Shiming Zhou and Haiyue Tang and Xiaoyao Zheng and Yonglong Luo},
  doi          = {10.1109/TKDE.2024.3523383},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1325-1338},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Multi-behavior hypergraph contrastive learning for session-based recommendation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MimoSketch: A framework for frequency-based mining tasks on
multiple nodes with sketches. <em>TKDE</em>, <em>37</em>(3), 1311–1324.
(<a href="https://doi.org/10.1109/TKDE.2024.3523034">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In distributed data stream mining, we abstract a MIMO scenario where a stream of multiple items is mined by multiple nodes. We design a framework named MimoSketch for the MIMO-specific scenario, which improves the fundamental mining tasks of item frequency estimation, item size distribution estimation, heavy hitter detection, heavy change detection, and entropy estimation. MimoSketch consists of an algorithm design and a policy to schedule items to nodes. MimoSketch&#39;s algorithm applies random counting to preserve a mathematically proven unbiasedness property, which makes it friendly to the aggregate query on multiple nodes; its memory layout is dynamically adaptive to the runtime item size distribution, which maximizes the estimation accuracy by storing more items. MimoSketch&#39;s scheduling policy balances items among nodes, avoiding nodes being overloaded or underloaded, which improves the overall mining accuracy. Our prototype and evaluation show that our algorithm can improve the accuracy of five typical mining tasks by an order of magnitude compared with the state-of-the-art solutions, and the scheduling policy further promotes the performance in MIMO scenarios.},
  archive      = {J_TKDE},
  author       = {Wenfei Wu and Yuchen Xu},
  doi          = {10.1109/TKDE.2024.3523034},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1311-1324},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {MimoSketch: A framework for frequency-based mining tasks on multiple nodes with sketches},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Maximizing influence query over indoor trajectories.
<em>TKDE</em>, <em>37</em>(3), 1294–1310. (<a
href="https://doi.org/10.1109/TKDE.2024.3514323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Maximizing Influence (Max-Inf) query is a fundamental operation in spatial data management. This query returns an optimal site from a candidate set to maximize its influence. Existing work commonly focuses on outdoor spaces. In practice, however, people spend up to 87% of their daily life inside indoor spaces. The outdoor techniques fall short in indoor spaces due to the complicated topology of indoor spaces. In this paper, we formulate two indoor Max-Inf queries: Top-$k$&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt; Probabilistic Influence Query (T$k$&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;PI) and Collective-$k$&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt; Probabilistic Influence Query (C$k$&lt;mml:math xmlns:mml=&quot;http://www.w3.org/1998/Math/MathML&quot;&gt;&lt;mml:mi&gt;k&lt;/mml:mi&gt;&lt;/mml:math&gt;PI) taking probability and mobility factors into consideration. We propose a novel spatial index, IT-tree, which utilizes the properties of indoor venues to facilitate the indoor distance computation, and then applies a trie to further organize the trajectories with similar check-in partitions together, based on their sketch information. This structure is simple but highly effective in pruning the trajectory search space. To process T$k$PI efficiently, we devise subtree pruning and progressive pruning techniques to delicately filter out unnecessary trajectories based on probability bounds and the monotonicity of influence probability. For C$k$PI queries, which is a submodular NP-hard problem, three approximation algorithms are provided with different strategies of computing marginal influence value during the search. Through extensive experiments on several real indoor venues, we demonstrate the efficiency and effectiveness of our proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Jian Chen and Hong Gao and Yuhong Shi and Junle Chen and Donghua Yang and Jianzhong Li},
  doi          = {10.1109/TKDE.2024.3514323},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1294-1310},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Maximizing influence query over indoor trajectories},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LDGI: Location-discriminative geo-indistinguishability for
location privacy. <em>TKDE</em>, <em>37</em>(3), 1282–1293. (<a
href="https://doi.org/10.1109/TKDE.2024.3522320">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Geo-Indistinguishability (GI) is a powerful privacy model that can effectively protect location information by limiting the ability of an attacker to infer a user&#39;s true location. In real life, locations usually have different sensitive levels in terms of privacy; for example, shopping malls might be low-sensitive while home addresses might be high-sensitive for users. But the GI model does not consider the various sensitive levels of locations, and implements the same perturbation on all locations to meet the highest privacy requirement. This would cause overprotection of low-sensitive locations and reduce data utility. To strike a good balance between privacy and utility, in this paper, we propose a novel privacy notion, termed Location-Discriminative Geo-Indistinguishability (LDGI), which takes into account different sensitive levels of location privacy. With LDGI model, we then develop a perturbation scheme called EM-LDGI based on the exponential mechanism, and an advance scheme MinQL to further enhance data utility. To improve the efficiency of the proposed schemes, we design a scheme MinQL-S with the assistance of the spanner graph, at the cost of a slight utility degradation. We theoretically analyze that the proposed schemes satisfy LDGI and evaluate their performance by extensive experiments on both synthetic and real datasets. The comparison with GI mechanisms demonstrates the advantages of the LDGI model.},
  archive      = {J_TKDE},
  author       = {Youwen Zhu and Yuanyuan Hong and Qiao Xue and Xiao Lan and Yushu Zhang and Yong Xiang},
  doi          = {10.1109/TKDE.2024.3522320},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1282-1293},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {LDGI: Location-discriminative geo-indistinguishability for location privacy},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label-aware causal feature selection. <em>TKDE</em>,
<em>37</em>(3), 1268–1281. (<a
href="https://doi.org/10.1109/TKDE.2024.3522580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Causal feature selection has recently received increasing attention in machine learning and data mining, especially in the era of Big Data. Existing causal feature selection algorithms select unique causal features of the single class label as the optimal feature subset. However, a single class label usually has multiple classes, and it is unreasonable to select the same causal features for different classes of a single class label. To address this problem, we employ the class-specific mutual information to evaluate the causal information carried by each class of the single class label, and theoretically analyze the unique relationship between each class and the causal features. Based on this, a Label-aware Causal Feature Selection algorithm (LaCFS) is proposed to identifies the causal features for each class of the class label. Specifically, LaCFS uses the pairwise comparisons of class-specific mutual information and the size of class-specific mutual information values from the perspective of each class, and follows a divide-and-conquer framework to find causal features. The correctness and application condition of LaCFS are theoretically proved, and extensive experiments are conducted to demonstrate the efficiency and superiority of LaCFS compared to the state-of-the-art approaches.},
  archive      = {J_TKDE},
  author       = {Zhaolong Ling and Jingxuan Wu and Yiwen Zhang and Peng Zhou and Xingyu Wu and Kui Yu and Xindong Wu},
  doi          = {10.1109/TKDE.2024.3522580},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1268-1281},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Label-aware causal feature selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperbolic graph contrastive learning for collaborative
filtering. <em>TKDE</em>, <em>37</em>(3), 1255–1267. (<a
href="https://doi.org/10.1109/TKDE.2024.3522960">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperbolic space based collaborative filtering has emerged as a popular topic in recommender systems. Compared to the euclidean space, hyperbolic space is more suitable to the tree-like structures in the user-item interactions and can achieve better recommender performance. Although some works have been devoted to this popular topic and made some progresses, they use tangent space as an approximation of hyperbolic space to implement model. Despite the effectiveness, such methods fail to fully exploit the advantages of hyperbolic space and still suffer from the data sparsity issue, which severely limits the recommender performance. To tackle these problems, we refer to the self-supervised learning technique and novelly propose a Hyperbolic Graph Contrastive Learning (HyperCL) framework. Specifically, our framework encodes the augmentation views from both the tangent space and the hyperbolic space, and construct the contrast pairs based on their corresponding learned node representations. Our model not only leverages the geometric advantages of both sides but also achieves seamless information transmission between the two spaces. Extensive experimental results on public benchmark datasets demonstrate that our model is highly competitive and outperforms leading baselines by considerable margins. Further experiments validate the robustness and the superiority of contrastive learning paradigm.},
  archive      = {J_TKDE},
  author       = {Zhida Qin and Wentao Cheng and Wenxing Ding and Gangyi Ding},
  doi          = {10.1109/TKDE.2024.3522960},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1255-1267},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hyperbolic graph contrastive learning for collaborative filtering},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hierarchical multi-agent meta-reinforcement learning for
cross-channel bidding. <em>TKDE</em>, <em>37</em>(3), 1241–1254. (<a
href="https://doi.org/10.1109/TKDE.2024.3523472">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time bidding (RTB) plays a pivotal role in online advertising ecosystems. Advertisers employ strategic bidding to optimize their advertising impact while adhering to various financial constraints, such as the return-on-investment (ROI) and cost-per-click (CPC). Primarily focusing on bidding with fixed budget constraints, traditional approaches cannot effectively manage the dynamic budget allocation problem where the goal is to achieve global optimization of bidding performance across multiple channels with a shared budget. In this paper, we propose a hierarchical multi-agent reinforcement learning framework for multi-channel bidding optimization. In this framework, the top-level strategy applies a CPC constrained diffusion model to dynamically allocate budgets among the channels according to their distinct features and complex interdependencies, while the bottom-level strategy adopts a state-action decoupled actor-critic method to address the problem of extrapolation errors in offline learning caused by out-of-distribution actions and a context-based meta-channel knowledge learning method to improve the state representation capability of the policy based on the shared knowledge among different channels. Comprehensive experiments conducted on a large scale real-world industrial dataset from the Meituan ad bidding platform demonstrate that our method achieves a state-of-the-art performance.},
  archive      = {J_TKDE},
  author       = {Shenghong He and Chao Yu and Qian Lin and Shangqin Mao and Bo Tang and Qianlong Xie and Xingxing Wang},
  doi          = {10.1109/TKDE.2024.3523472},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1241-1254},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Hierarchical multi-agent meta-reinforcement learning for cross-channel bidding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HidAttack: An effective and undetectable model poisoning
attack to federated recommenders. <em>TKDE</em>, <em>37</em>(3),
1227–1240. (<a href="https://doi.org/10.1109/TKDE.2024.3522763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy concerns in recommender systems are potentially addressed due to constitutional and commercial requirements. Centralized recommendation models are susceptible to poisoning attacks, which threaten their integrity. In this context, federated learning has emerged as an optimal solution to privacy concerns. However, recent investigations proved that Federated Recommender Systems (FedRS) are also vulnerable to model poisoning attacks. Existing attack possibilities highlighted in academic literature require a large fraction of Byzantine clients to effectively influence the training process, which is unrealistic for practical systems with millions of users. Additionally, most attack models neglected the role of the defense mechanism running at the aggregation server. To this end, we propose a novel undetectable hidden attack strategy (HidAttack) for FedRS, aiming to raise the exposure ratio of targeted items with minimum Byzantine clients. To achieve this goal, we construct a cluster of baseline attacks, on top of which a bandit model is designed that intelligently infers effective poisoned gradients. It ensures a diverse pattern of poisoned gradients and therefore, Byzantine clients cannot be distinguished from benign clients by the defense mechanism. Extensive experiments demonstrate that: 1) our attack model significantly increases the target item&#39;s exposure rate covertly without compromising the recommendation accuracy and 2) the current defenses are insufficient, emphasizing the need for better security improvements against our model poisoning attack to FedRS.},
  archive      = {J_TKDE},
  author       = {Waqar Ali and Khalid Umer and Xiangmin Zhou and Jie Shao},
  doi          = {10.1109/TKDE.2024.3522763},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1227-1240},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {HidAttack: An effective and undetectable model poisoning attack to federated recommenders},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GSM-EL: A generalizable symbol-manipulation approach for
entity linking. <em>TKDE</em>, <em>37</em>(3), 1213–1226. (<a
href="https://doi.org/10.1109/TKDE.2024.3523399">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Entity linking (EL) is a challenging task as it typically requires matching an ambiguous entity mention with its corresponding entity in a knowledge base (KB). The mainstream studies focus on learning and evaluating linking models on the same corpus and obtained significant performance achievement, however, they often overlook the generalization ability to out-of-domain corpus, which is more realistic yet much more challenging. To address this issue, we introduce a novel neural-symbolic model for entity linking, which is inspired by the symbol-manipulation mechanism in human brains. Specifically, we abstract diverse features into unified variables, then combine them using neural operators to capture diverse relevance requirements, and finally aggregate relevance scores through voting. We conduct experiments on eleven benchmark datasets with different types of text, and the results show that our method outperforms nearly all baselines. Notably, the best performance of our method on seven out-of-domain datasets highlights its generalization ability.},
  archive      = {J_TKDE},
  author       = {Xueqi Cheng and Yuanzheng Wang and Yixing Fan and Jiafeng Guo and Ruqing Zhang and Keping Bi},
  doi          = {10.1109/TKDE.2024.3523399},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1213-1226},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {GSM-EL: A generalizable symbol-manipulation approach for entity linking},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph percolation embeddings for efficient knowledge graph
inductive reasoning. <em>TKDE</em>, <em>37</em>(3), 1198–1212. (<a
href="https://doi.org/10.1109/TKDE.2024.3508064">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study Graph Neural Networks (GNNs)-based embedding techniques for knowledge graph (KG) reasoning. For the first time, we link the path redundancy issue in the state-of-the-art path encoding-based models to the transformation error in model training, which brings us new theoretical insights into KG reasoning, as well as high efficacy in practice. On the theoretical side, we analyze the entropy of transformation error in KG paths and point out query-specific redundant paths causing entropy increases. These findings guide us to maintain the shortest paths and remove redundant paths for minimized-entropy message passing. To achieve this goal, on the practical side, we propose an efficient Graph Percolation process motivated by the percolation phenomenon in Fluid Mechanics, and design a lightweight GNN-based KG reasoning framework called Graph Percolation Embeddings (GraPE)1. GraPE outperforms state-of-the-art methods in both transductive and inductive reasoning tasks, while requiring fewer training parameters and less inference time.},
  archive      = {J_TKDE},
  author       = {Kai Wang and Dan Lin and Siqiang Luo},
  doi          = {10.1109/TKDE.2024.3508064},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1198-1212},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Graph percolation embeddings for efficient knowledge graph inductive reasoning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy granule density-based outlier detection with
multi-scale granular balls. <em>TKDE</em>, <em>37</em>(3), 1182–1197.
(<a href="https://doi.org/10.1109/TKDE.2024.3525003">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection refers to the identification of anomalous samples that deviate significantly from the distribution of normal data and has been extensively studied and used in a variety of practical tasks. However, most unsupervised outlier detection methods are carefully designed to detect specified outliers, while real-world data may be entangled with different types of outliers. In this study, we propose a fuzzy rough sets-based multi-scale outlier detection method to identify various types of outliers. Specifically, a novel fuzzy rough sets-based method that integrates relative fuzzy granule density is first introduced to improve the capability of detecting local outliers. Then, a multi-scale view generation method based on granular-ball computing is proposed to collaboratively identify group outliers at different levels of granularity. Moreover, reliable outliers and inliers determined by the three-way decision are used to train a weighted support vector machine to further improve the performance of outlier detection. The proposed method innovatively transforms unsupervised outlier detection into a semi-supervised classification problem and for the first time explores the fuzzy rough sets-based outlier detection from the perspective of multi-scale granular balls, allowing for high adaptability to different types of outliers. Extensive experiments carried out on both artificial and UCI datasets demonstrate that the proposed outlier detection method significantly outperforms the state-of-the-art methods, improving the results by at least 8.48% in terms of the Area Under the ROC Curve (AUROC) index.},
  archive      = {J_TKDE},
  author       = {Can Gao and Xiaofeng Tan and Jie Zhou and Weiping Ding and Witold Pedrycz},
  doi          = {10.1109/TKDE.2024.3525003},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1182-1197},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Fuzzy granule density-based outlier detection with multi-scale granular balls},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FRAME: Feature rectification for class imbalance learning.
<em>TKDE</em>, <em>37</em>(3), 1167–1181. (<a
href="https://doi.org/10.1109/TKDE.2024.3523043">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Class imbalance learning is a challenging task in machine learning applications. To balance training data, traditional class imbalance learning approaches, such as class resampling or reweighting, are commonly applied in the literature. However, these methods can have significant limitations, particularly in the presence of noisy data, missing values, or when applied to advanced learning paradigms like semi-supervised or federated learning. To address these limitations, this paper proposes a novel and theoretically-ensured latent Feature Rectification method for clAss iMbalance lEarning (FRAME). The proposed FRAME can automatically learn multiple centroids for each class in the latent space and then perform class balancing. Unlike data-level methods, FRAME balances feature in the latent space rather than the original space. Compared to algorithm-level methods, FRAME can distinguish different classes based on distance without the need to adjust the learning algorithms. Through latent feature rectification, FRAME can effectively mitigate contaminated noises/missing values without worrying about structural variations in the data. In order to accommodate a wider range of applications, this paper extends FRAME to the following three main learning paradigms: fully-supervised learning, semi-supervised learning, and federated learning. Extensive experiments on 10 binary-class datasets demonstrate that our FRAME can achieve competitive performance than the state-of-the-art methods and its robustness to noises/missing values.},
  archive      = {J_TKDE},
  author       = {Xu Cheng and Fan Shi and Yao Zhang and Huan Li and Xiufeng Liu and Shengyong Chen},
  doi          = {10.1109/TKDE.2024.3523043},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1167-1181},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {FRAME: Feature rectification for class imbalance learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Early detection of malicious crypto addresses with asset
path tracing and selection. <em>TKDE</em>, <em>37</em>(3), 1154–1166.
(<a href="https://doi.org/10.1109/TKDE.2024.3522772">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In response to the burgeoning cryptocurrency sector and its associated financial risks, there is a growing focus on detecting fraudulent activities and malicious addresses. Traditional studies are limited by their reliance on comprehensive historical data and address-wise manipulation, which are not available for early malice detection and fail to identify addresses controlled by the same fraudulent entity. We thus introduce Evolve Path Tracer, a novel solution designed for early malice detection in cryptocurrency. This system innovatively incorporates Asset Transfer Paths and corresponding path graphs in an evolve model, which effectively characterize rapidly evolving transaction patterns. First, for the target address, the Clustering-based Path Selector weight each Asset Transfer Path by finding sibling addresses along the Asset Transfer Paths. Evolve Path Encoder LSTM and Evolve Path Graph GCN then encode the asset transfer path and path graph within a dynamic structure. Additionally, our Hierarchical Survival Predictor efficiently scales to predict the address labels, demonstrating high scalability and efficiency. We rigorously tested Evolve Path Tracer on three real-world datasets of malicious addresses, where it consistently outperformed existing state-of-the-art methods. Our extensive scalability tests further confirmed the model&#39;s robust adaptability in dynamic prediction environments, highlighting its potential as a significant tool in the realm of cryptocurrency security.},
  archive      = {J_TKDE},
  author       = {Ling Cheng and Feida Zhu and Qian Shao and Jiashu Pu and Fengzhu Zeng},
  doi          = {10.1109/TKDE.2024.3522772},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1154-1166},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Early detection of malicious crypto addresses with asset path tracing and selection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Delayed bottlenecking: Alleviating forgetting in pre-trained
graph neural networks. <em>TKDE</em>, <em>37</em>(3), 1140–1153. (<a
href="https://doi.org/10.1109/TKDE.2024.3516192">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Pre-training GNNs to extract transferable knowledge and apply it to downstream tasks has become the de facto standard of graph representation learning. Recent works focused on designing self-supervised pre-training tasks to extract useful and universal transferable knowledge from large-scale unlabeled data. However, they have to face an inevitable question: traditional pre-training strategies that aim at extracting useful information about pre-training tasks, may not extract all useful information about the downstream task. In this paper, we reexamine the pre-training process within traditional pre-training and fine-tuning frameworks from the perspective of Information Bottleneck (IB) and confirm that the forgetting phenomenon in pre-training phase may cause detrimental effects on downstream tasks. Therefore, we propose a novel Delayed Bottlenecking Pre-training (DBP) framework which maintains as much as possible mutual information between latent representations and training data during pre-training phase by suppressing the compression operation and delays the compression operation to fine-tuning phase to make sure the compression can be guided with labeled fine-tuning data and downstream tasks. To achieve this, we design two information control objectives that can be directly optimized and further integrate them into the actual model design. Extensive experiments on both chemistry and biology domains demonstrate the effectiveness of DBP.},
  archive      = {J_TKDE},
  author       = {Zhe Zhao and Pengkun Wang and Xu Wang and Haibin Wen and Xiaolong Xie and Zhengyang Zhou and Qingfu Zhang and Yang Wang},
  doi          = {10.1109/TKDE.2024.3516192},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1140-1153},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Delayed bottlenecking: Alleviating forgetting in pre-trained graph neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conversational recommendations with user entity focus and
multi-granularity latent variable enhancement. <em>TKDE</em>,
<em>37</em>(3), 1126–1139. (<a
href="https://doi.org/10.1109/TKDE.2024.3523283">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conversational recommendation is one system that can extract the user&#39;s preferences and recommend suitable items in a similar way to human-like responses. Existing methods often use the feature extraction combined with the Transformer model to extract user preferences and make recommendations. However, these methods have two limitations. First, they do not consider the order in which entities appear, thus affecting the extraction of user preferences. Second, the generated responses lack diversity that affects the users’ experience to the system. To this end, we propose a conversational recommendation model with User Entity focus and Multi-Granularity latent variable enhancement (UEMG). In UEMG, we design a novel neural network that utilizes Bi-GRU to capture the appearing orders of entities in dialogues, and leverages Transformer to capture the global dependencies of entities, and then combines them to extract user preferences. For the second issue, to improve the diversity of dialogue generation, we propose a multi-granularity latent variable mechanism, which can extract more entities from the context information and the knowledge graphs, respectively. We conducted extensive experiments on publicly available dialogue generation datasets. Experimental results demonstrate that compared to current state-of-the-art methods, UEMG achieves 9.7% improvements in recommendation performance and 23% improvements in dialogue generation.},
  archive      = {J_TKDE},
  author       = {Yunfei Yin and Yiming Pan and Xianjian Bao and Faliang Huang},
  doi          = {10.1109/TKDE.2024.3523283},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1126-1139},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Conversational recommendations with user entity focus and multi-granularity latent variable enhancement},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Colorful star motif counting: Concepts, algorithms and
applications. <em>TKDE</em>, <em>37</em>(3), 1105–1125. (<a
href="https://doi.org/10.1109/TKDE.2024.3514997">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A colorful star motif is a star-shaped graph where any two nodes have different colors. Counting the colorful star motif can help to analyze the structural properties of real-life colorful graphs, model higher-order clustering, and accelerate the mining of the densest subgraph exhibiting $h$-clique characteristics in graphs. In this manuscript, we introduce the concept of colorful $h$-star in a colored graph and proposes two higher-order cohesive subgraph models, namely colorful $h$-star core and colorful $h$-star truss. We show that the colorful $h$-stars can be counted and updated very efficiently using a novel dynamic programming (DP) algorithm. Based on the proposed DP algorithm, we develop a colorful $h$-star core decomposition algorithm which takes $O(h m)$ time, $O(h n+m)$ space; and a colorful $h$-star truss decomposition algorithm which takes $O(h m^{1.5})$ time, $O(hm)$ space, where $m$ and $n$ denote the number of edges and nodes of the graph respectively. Moreover, we also propose a graph reduction technique based on our colorful $h$-star core model to accelerate the computation of the approximation algorithm for $ h$-clique densest subgraph mining. The results of comprehensive experiments on 11 large real-world datasets demonstrate the efficiency, scalability and effectiveness of the proposed algorithms.},
  archive      = {J_TKDE},
  author       = {Hongchao Qin and Gao Sen and Rong-Hua Li and Hongzhi Chen and Ye Yuan and Guoren Wang},
  doi          = {10.1109/TKDE.2024.3514997},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1105-1125},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Colorful star motif counting: Concepts, algorithms and applications},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ATPF: An adaptive temporal perturbation framework for
adversarial attacks on temporal knowledge graph. <em>TKDE</em>,
<em>37</em>(3), 1091–1104. (<a
href="https://doi.org/10.1109/TKDE.2024.3510689">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Robustness is paramount for ensuring the reliability of knowledge graph models in safety-sensitive applications. While recent research has delved into adversarial attacks on static knowledge graph models, the exploration of more practical temporal knowledge graphs has been largely overlooked. To fill this gap, we present the Adaptive Temporal Perturbation Framework (ATPF), a novel adversarial attack framework aimed at probing the robustness of temporal knowledge graph (TKG) models. The general idea of ATPF is to inject perturbations into the victim model input to undermine the prediction. First, we propose the Temporal Perturbation Prioritization (TPP) algorithm, which identifies the optimal time sequence for perturbation injection before initiating attacks. Subsequently, we design the Rank-Based Edge Manipulation (RBEM) algorithm, enabling the generation of both edge addition and removal perturbations under black-box setting. With ATPF, we present two adversarial attack methods: the stringent ATPF-hard and the more lenient ATPF-soft, each imposing different perturbation constraints. Our experimental evaluations on the link prediction task for TKGs demonstrate the superior attack performance of our methods compared to baseline methods. Furthermore, we find that strategically placing a single perturbation often suffices to successfully compromise a target link.},
  archive      = {J_TKDE},
  author       = {Longquan Liao and Linjiang Zheng and Jiaxing Shang and Xu Li and Fengwen Chen},
  doi          = {10.1109/TKDE.2024.3510689},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1091-1104},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ATPF: An adaptive temporal perturbation framework for adversarial attacks on temporal knowledge graph},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor guided unsupervised domain adaptation. <em>TKDE</em>,
<em>37</em>(3), 1079–1090. (<a
href="https://doi.org/10.1109/TKDE.2024.3511714">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised domain adaptation aims to classify unlabeled data points in the target domain using labeled data points from the source domain, while the distributions of data points in two domains are different. To address this issue, we propose a novel method called the anchor guided unsupervised domain adaptation method (AGDA). We minimize distribution divergence in a latent feature subspace using the Maximum Mean Discrepancy (MMD) criterion. Unlike existing unsupervised domain adaptation methods, we introduce anchor points in the original space and impose domains data to the same anchor points rather than center points to further reduce the domain difference. We optimize the anchor-based graph in the subspace to obtain discriminative transformation matrices. This enables our model to perform better on non-Gaussian distribution than methods focusing on global structure. Furthermore, the sparse anchor-based graph reduces time complexity compared to the fully connected graph, enabling exploration of local structure. Experimental results demonstrate that our algorithm outperforms several state-of-the-art methods on various benchmark datasets.},
  archive      = {J_TKDE},
  author       = {Canyu Zhang and Feiping Nie and Rong Wang},
  doi          = {10.1109/TKDE.2024.3511714},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1079-1090},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {Anchor guided unsupervised domain adaptation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AEGK: Aligned entropic graph kernels through continuous-time
quantum walks. <em>TKDE</em>, <em>37</em>(3), 1064–1078. (<a
href="https://doi.org/10.1109/TKDE.2024.3512181">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we develop a family of Aligned Entropic Graph Kernels (AEGK) for graph classification. We commence by performing the Continuous-time Quantum Walk (CTQW) on each graph structure, and compute the Averaged Mixing Matrix (AMM) to describe how the CTQW visits all vertices from a starting vertex. More specifically, we show how this AMM matrix allows us to compute a quantum Shannon entropy of each vertex for either un-attributed or attributed graphs. For pairwise graphs, the proposed AEGK kernels are defined by computing the kernel-based similarity between the quantum Shannon entropies of their pairwise aligned vertices. The analysis of theoretical properties reveals that the proposed AEGK kernels cannot only address the shortcoming of neglecting the structural correspondence information between graphs arising in most existing R-convolution graph kernels, but also overcome the problems of neglecting the structural differences and vertex-attributed information arising in existing vertex-based matching kernels. Moreover, unlike most existing classical graph kernels that only focus on the global or local structural information of graphs, the proposed AEGK kernels can simultaneously capture both global and local structural characteristics through the quantum Shannon entropies, reflecting more precise kernel-based similarity measures between pairwise graphs. The above theoretical properties explain the effectiveness of the proposed AEGK kernels. Experimental evaluations demonstrate that the proposed kernels can outperform state-of-the-art graph kernels and deep learning models for graph classification.},
  archive      = {J_TKDE},
  author       = {Lu Bai and Lixin Cui and Ming Li and Peng Ren and Yue Wang and Lichi Zhang and Philip S. Yu and Edwin R. Hancock},
  doi          = {10.1109/TKDE.2024.3512181},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1064-1078},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {AEGK: Aligned entropic graph kernels through continuous-time quantum walks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ADMH-ER: Adaptive denoising multi-modal hybrid for entity
resolution. <em>TKDE</em>, <em>37</em>(3), 1049–1063. (<a
href="https://doi.org/10.1109/TKDE.2025.3526623">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-Modal Knowledge Graphs (MMKGs), comprising relational triples and related multi-modal data (e.g., text and images), usually suffer from the problems of low coverage and incompleteness. To mitigate this, existing studies introduce a fundamental MMKG fusion task, i.e., Multi-Modal Entity Alignment (MMEA) that identifies equivalent entities across multiple MMKGs. Despite MMEA’s significant advancements, effectively integrating MMKGs remains challenging, mainly stemming from two core limitations: 1) entity ambiguity, where real-world entities across different MMKGs may possess multiple corresponding counterparts or alternative identities; and 2) severe noise within multi-modal data. To tackle these limitations, a new task MMER (Multi-Modal Entity Resolution), which expands the scope of MMEA to encompass entity ambiguity, is introduced. To tackle this task effectively, we develop a novel model ADMH-ER (Adaptive Denoising Multi-modal Hybrid for Entity Resolution) that incorporates several crucial modules: 1) multi-modal knowledge encoders, which are crafted to obtain entity representations based on multi-modal data sources; 2) an adaptive denoising multi-modal hybrid module that is designed to tackle challenges including noise interference, multi-modal heterogeneity, and semantic irrelevance across modalities; and 3) a hierarchical multi-objective learning strategy, which is proposed to ensure diverse convergence capabilities among different learning objectives. Experimental results demonstrate that ADMH-ER outperforms state-of-the-art methods.},
  archive      = {J_TKDE},
  author       = {Qian Zhou and Wei Chen and Li Zhang and An Liu and Junhua Fang and Lei Zhao},
  doi          = {10.1109/TKDE.2025.3526623},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1049-1063},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {ADMH-ER: Adaptive denoising multi-modal hybrid for entity resolution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of change point detection in dynamic graphs.
<em>TKDE</em>, <em>37</em>(3), 1030–1048. (<a
href="https://doi.org/10.1109/TKDE.2024.3523857">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Change point detection is crucial for identifying state transitions and anomalies in dynamic systems, with applications in network security, health care, and social network analysis. Dynamic systems are represented by dynamic graphs with spatial and temporal dimensions. As objects and their relations in a dynamic graph change over time, detecting these changes is essential. Numerous methods for change point detection in dynamic graphs have been developed, but no systematic review exists. This paper addresses this gap by introducing change point detection tasks in dynamic graphs, discussing two tasks based on input data types: detection in graph snapshot series (focusing on graph topology changes) and time series on graphs (focusing on changes in graph entities with temporal dynamics). We then present related challenges and applications, provide a comprehensive taxonomy of surveyed methods, including datasets and evaluation metrics, and discuss promising research directions.},
  archive      = {J_TKDE},
  author       = {Yuxuan Zhou and Shang Gao and Dandan Guo and Xiaohui Wei and Jon Rokne and Hui Wang},
  doi          = {10.1109/TKDE.2024.3523857},
  journal      = {IEEE Transactions on Knowledge and Data Engineering},
  month        = {3},
  number       = {3},
  pages        = {1030-1048},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  title        = {A survey of change point detection in dynamic graphs},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
