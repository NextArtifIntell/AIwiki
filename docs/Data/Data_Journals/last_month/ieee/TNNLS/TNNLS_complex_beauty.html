<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TNNLS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tnnls---146">TNNLS - 146</h2>
<ul>
<li><details>
<summary>
(2025). Convergence analysis on trace ratio linear discriminant
analysis algorithms. <em>TNNLS</em>, <em>36</em>(2), 3878–3881. (<a
href="https://doi.org/10.1109/TNNLS.2024.3355422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Linear discriminant analysis (LDA) may yield an inexact solution by transforming a trace ratio problem into a corresponding ratio trace problem. Most recently, optimal dimensionality LDA (ODLDA) and trace ratio LDA (TRLDA) have been developed to overcome this problem. As one of the greatest contributions, the two methods design efficient iterative algorithms to derive an optimal solution. However, the theoretical evidence for the convergence of these algorithms has not yet been provided, which renders the theory of ODLDA and TRLDA incomplete. In this correspondence, we present some rigorously theoretical insight into the convergence of the iterative algorithms. To be specific, we first demonstrate the existence of lower bounds for the objective functions in both ODLDA and TRLDA, and then establish proofs that the objective functions are monotonically decreasing under the iterative frameworks. Based on the findings, we disclose the convergence of the iterative algorithms finally.},
  archive      = {J_TNNLS},
  author       = {Qiaolin Ye and Jie Yang and Hao Zheng and Liyong Fu},
  doi          = {10.1109/TNNLS.2024.3355422},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3878-3881},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Convergence analysis on trace ratio linear discriminant analysis algorithms},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-driven safe policy optimization for black-box dynamical
systems with temporal logic specifications. <em>TNNLS</em>,
<em>36</em>(2), 3870–3877. (<a
href="https://doi.org/10.1109/TNNLS.2023.3339885">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning-based policy optimization methods have shown great potential for building general-purpose control systems. However, existing methods still struggle to achieve complex task objectives while ensuring policy safety during learning and execution phases for black-box systems. To address these challenges, we develop data-driven safe policy optimization (D2SPO), a novel reinforcement learning (RL)-based policy improvement method that jointly learns a control barrier function (CBF) for system safety and a linear temporal logic (LTL) guided RL algorithm for complex task objectives. Unlike many existing works that assume known system dynamics, by carefully constructing the data sets and redesigning the loss functions of D2SPO, a provably safe CBF is learned for black-box dynamical systems, which continuously evolves for improved system safety as RL interacts with the environment. To deal with complex task objectives, we take advantage of the capability of LTL in representing the task progress and develop LTL-guided RL policy for efficient completion of various tasks with LTL objectives. Extensive numerical and experimental studies demonstrate that D2SPO outperforms most state-of-the-art (SOTA) baselines and can achieve over 95% safety rate and nearly 100% task completion rates. The experiment video is available at https://youtu.be/2RgaH-zcmkY.},
  archive      = {J_TNNLS},
  author       = {Chenlin Zhang and Shijun Lin and Hao Wang and Ziyang Chen and Shaochen Wang and Zhen Kan},
  doi          = {10.1109/TNNLS.2023.3339885},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3870-3877},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Data-driven safe policy optimization for black-box dynamical systems with temporal logic specifications},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning cross-domain features with dual-path signal
transformer. <em>TNNLS</em>, <em>36</em>(2), 3863–3869. (<a
href="https://doi.org/10.1109/TNNLS.2024.3350609">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The past decade has witnessed the rapid development of deep neural networks (DNNs) for automatic modulation classification (AMC). However, most of the available works learn signal features from only a single domain via DNNs, which is not reliable enough to work in uncertain and complex electromagnetic environments. In this brief, a new cross-domain signal transformer (CDSiT) is proposed for AMC, to explore the latent association between different domains of signals. By constructing a signal fusion bottleneck (SFB), CDSiT can implicitly fuse and classify signal features with complementary structures in different domains. Extensive experiments are performed on RadioML2016.10A and RadioML2018.01A, and the results show that CDSiT outperforms its counterparts, particularly for some modulation modes that are difficult to classify before. Through ablation experiences, we also verify the effectiveness of each module in CDSiT.},
  archive      = {J_TNNLS},
  author       = {Lei Zhai and Yitong Li and Zhixi Feng and Shuyuan Yang and Hao Tan},
  doi          = {10.1109/TNNLS.2024.3350609},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3863-3869},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning cross-domain features with dual-path signal transformer},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the size and width of the decoder of a boolean threshold
autoencoder. <em>TNNLS</em>, <em>36</em>(2), 3855–3862. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342818">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this brief paper, we study the size and width of autoencoders consisting of Boolean threshold functions, where an autoencoder is a layered neural network whose structure can be viewed as consisting of an encoder, which compresses an input vector to a lower dimensional vector, and a decoder which transforms the low-dimensional vector back to the original input vector exactly (or approximately). We focus on the decoder part and show that $\Omega ((Dn/d)^{1/2})$ and $O(\sqrt {Dn})$ nodes are required to transform $n$ vectors in $d$ -dimensional binary space to $D$ - dimensional binary space. We also show that the width can be reduced if we allow small errors, where the error is defined as the average of the Hamming distance between each vector input to the encoder part and the resulting vector output by the decoder.},
  archive      = {J_TNNLS},
  author       = {Tatsuya Akutsu and Avraham A. Melkman},
  doi          = {10.1109/TNNLS.2023.3342818},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3855-3862},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {On the size and width of the decoder of a boolean threshold autoencoder},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An end-to-end deep graph clustering via online mutual
learning. <em>TNNLS</em>, <em>36</em>(2), 3847–3854. (<a
href="https://doi.org/10.1109/TNNLS.2024.3353217">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clustering fields, the deep graph models generally utilize the graph neural network to extract the deep embeddings and aggregate them according to the data structure. The optimization procedure can be divided into two individual stages, optimizing the neural network with gradient descent and generating the aggregation with a machine learning-based algorithm. Hence, it means that clustering results cannot guide the optimization of graph neural networks. Besides, since the aggregating stage involves complicated matrix computation such as decomposition, it brings a high computational burden. To address these issues, a unified deep graph clustering (UDGC) model via online mutual learning is proposed in this brief. Specifically, it maps the data into the deep embedding subspace and extracts the deep graph representation to explore the latent topological knowledge of the nodes. In the deep subspace, the model aggregates the embeddings and generates the clustering assignments via the local preserving loss. More importantly, we train a neural layer to fit the clustering results and design an online mutual learning strategy to optimize the whole model, which can not only output the clustering assignments end-to-end but also reduce the computation complexity. Extensive experiments support the superiority of our model.},
  archive      = {J_TNNLS},
  author       = {Ziheng Jiao and Xuelong Li},
  doi          = {10.1109/TNNLS.2024.3353217},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3847-3854},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An end-to-end deep graph clustering via online mutual learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sign-based gradient descent with heterogeneous data:
Convergence and byzantine resilience. <em>TNNLS</em>, <em>36</em>(2),
3834–3846. (<a
href="https://doi.org/10.1109/TNNLS.2023.3345367">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Communication overhead has become one of the major bottlenecks in the distributed training of modern deep neural networks. With such consideration, various quantization-based stochastic gradient descent (SGD) solvers have been proposed and widely adopted, among which SignSGD with majority vote shows a promising direction because of its communication efficiency and robustness against Byzantine attackers. However, SignSGD fails to converge in the presence of data heterogeneity, which is commonly observed in the emerging federated learning (FL) paradigm. In this article, a sufficient condition for the convergence of the sign-based gradient descent method is derived, based on which a novel magnitude-driven stochastic-sign-based gradient compressor is proposed to address the non-convergence issue of SignSGD. The convergence of the proposed method is established in the presence of arbitrary data heterogeneity. The Byzantine resilience of sign-based gradient descent methods is quantified, and the error-feedback mechanism is further incorporated to boost the learning performance. Experimental results on the MNIST dataset, the CIFAR-10 dataset, and the Tiny-ImageNet dataset corroborate the effectiveness of the proposed methods.},
  archive      = {J_TNNLS},
  author       = {Richeng Jin and Yuding Liu and Yufan Huang and Xiaofan He and Tianfu Wu and Huaiyu Dai},
  doi          = {10.1109/TNNLS.2023.3345367},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3834-3846},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Sign-based gradient descent with heterogeneous data: Convergence and byzantine resilience},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive sparse memory networks for efficient and robust
video object segmentation. <em>TNNLS</em>, <em>36</em>(2), 3820–3833.
(<a href="https://doi.org/10.1109/TNNLS.2024.3357118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, memory-based networks have achieved promising performance for video object segmentation (VOS). However, existing methods still suffer from unsatisfactory segmentation accuracy and inferior efficiency. The reasons are mainly twofold: 1) during memory construction, the inflexible memory storage mechanism results in a weak discriminative ability for similar appearances in complex scenarios, leading to video-level temporal redundancy, and 2) during memory reading, matching robustness and memory retrieval accuracy decrease as the number of video frames increases. To address these challenges, we propose an adaptive sparse memory network (ASM) that efficiently and effectively performs VOS by sparsely leveraging previous guidance while attending to key information. Specifically, we design an adaptive sparse memory constructor (ASMC) to adaptively memorize informative past frames according to dynamic temporal changes in video frames. Furthermore, we introduce an attentive local memory reader (ALMR) to quickly retrieve relevant information using a subset of memory, thereby reducing frame-level redundant computation and noise in a simpler and more convenient manner. To prevent key features from being discarded by the subset of memory, we further propose a novel attentive local feature aggregation (ALFA) module, which preserves useful cues by selectively aggregating discriminative spatial dependence from adjacent frames, thereby effectively increasing the receptive field of each memory frame. Extensive experiments demonstrate that our model achieves state-of-the-art performance with real-time speed on six popular VOS benchmarks. Furthermore, our ASM can be applied to existing memory-based methods as generic plugins to achieve significant performance improvements. More importantly, our method exhibits robustness in handling sparse videos with low frame rates.},
  archive      = {J_TNNLS},
  author       = {Jisheng Dang and Huicheng Zheng and Xiaohao Xu and Longguang Wang and Qingyong Hu and Yulan Guo},
  doi          = {10.1109/TNNLS.2024.3357118},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3820-3833},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive sparse memory networks for efficient and robust video object segmentation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Shielded planning guided data-efficient and safe
reinforcement learning. <em>TNNLS</em>, <em>36</em>(2), 3808–3819. (<a
href="https://doi.org/10.1109/TNNLS.2024.3359031">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Safe reinforcement learning (RL) has shown great potential for building safe general-purpose robotic systems. While many existing works have focused on post-training policy safety, it remains an open problem to ensure safety during training as well as to improve exploration efficiency. Motivated to address these challenges, this work develops shielded planning guided policy optimization (SPPO), a new model-based safe RL method that augments policy optimization algorithms with path planning and shielding mechanism. In particular, SPPO is equipped with shielded planning for guided exploration and efficient data collection via model predictive path integral (MPPI), along with an advantage-based shielding rule to keep the above processes safe. Based on the collected safe data, a task-oriented parameter optimization (TOPO) method is used for policy improvement, as well as the observation-independent latent dynamics enhancement. In addition, SPPO provides explicit theoretical guarantees, i.e., clear theoretical bounds for training safety, deployment safety, and the learned policy performance. Experiments demonstrate that SPPO outperforms baselines in terms of policy performance, learning efficiency, and safety performance during training.},
  archive      = {J_TNNLS},
  author       = {Hao Wang and Jiahu Qin and Zhen Kan},
  doi          = {10.1109/TNNLS.2024.3359031},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3808-3819},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Shielded planning guided data-efficient and safe reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor-sharing and cluster-wise contrastive network for
multiview representation learning. <em>TNNLS</em>, <em>36</em>(2),
3797–3807. (<a
href="https://doi.org/10.1109/TNNLS.2024.3357087">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiview clustering (MVC) has gained significant attention as it enables the partitioning of samples into their respective categories through unsupervised learning. However, there are a few issues as follows: 1) many existing deep clustering methods use the same latent features to achieve the conflict objectives, namely, reconstruction and view consistency. The reconstruction objective aims to preserve view-specific features for each individual view, while the view-consistency objective strives to obtain common features across all views; 2) some deep embedded clustering (DEC) approaches adopt view-wise fusion to obtain consensus feature representation. However, these approaches overlook the correlation between samples, making it challenging to derive discriminative consensus representations; and 3) many methods use contrastive learning (CL) to align the view’s representations; however, they do not take into account cluster information during the construction of sample pairs, which can lead to the presence of false negative pairs. To address these issues, we propose a novel multiview representation learning network, called anchor-sharing and clusterwise CL (CwCL) network for multiview representation learning. Specifically, we separate view-specific learning and view-common learning into different network branches, which addresses the conflict between reconstruction and consistency. Second, we design an anchor-sharing feature aggregation (ASFA) module, which learns the sharing anchors from different batch data samples, establishes the bipartite relationship between anchors and samples, and further leverages it to improve the samples’ representations. This module enhances the discriminative power of the common representation from different samples. Third, we design CwCL module, which incorporates the learned transition probability into CL, allowing us to focus on minimizing the similarity between representations from negative pairs with a low transition probability. It alleviates the conflict in previous sample-level contrastive alignment. Experimental results demonstrate that our method outperforms the state-of-the-art performance.},
  archive      = {J_TNNLS},
  author       = {Weiqing Yan and Yuanyang Zhang and Chang Tang and Wujie Zhou and Weisi Lin},
  doi          = {10.1109/TNNLS.2024.3357087},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3797-3807},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Anchor-sharing and cluster-wise contrastive network for multiview representation learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Label distribution learning by partitioning label
distribution manifold. <em>TNNLS</em>, <em>36</em>(2), 3786–3796. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341807">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researchers have suggested leveraging label correlation to deal with the exponentially sized output space of label distribution learning (LDL). Among them, some have proposed to exploit local label correlation. They first partition the training set into different groups and then exploit local label correlation on each one. However, these works usually apply clustering algorithms, such as $K$ -means, to split the training set and obtain the clustering results independent of label correlation. The structures (e.g., low rank and manifold) learned on such clusters may not efficiently capture label correlation. To solve this problem, we put forward a novel LDL method called LDL by partitioning label distribution manifold (LDL-PLDM). First, it jointly bipartitions the training set and learns the label distribution manifold to model label correlation. Second, it recurses until the reconstruction error of learning the label distribution manifold cannot be reduced. LDL-PLDM achieves label-correlation-related partition results, on which the learned label distribution manifold can better capture label correlation. We conduct extensive experiments to justify that LDL-PLDM statistically outperforms state-of-the-art LDL methods.},
  archive      = {J_TNNLS},
  author       = {Jing Wang and Jianhui Lv and Xin Geng},
  doi          = {10.1109/TNNLS.2023.3341807},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3786-3796},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Label distribution learning by partitioning label distribution manifold},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fault-tolerant attitude tracking control driven by spiking
NNs for unmanned aerial vehicles. <em>TNNLS</em>, <em>36</em>(2),
3773–3785. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342078">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we proposed a novel fault-tolerant control scheme for quadrotor unmanned aerial vehicles (UAVs) based on spiking neural networks (SNNs), which leverages the inherent features of neural network computing to significantly enhance the reliability and robustness of UAV flight control. Traditional control methods are known to be inadequate in dealing with complex and real-time sensor data, which results in poor performance and reduced robustness in fault-tolerant control. In contrast, the temporal processing, parallelism, and nonlinear capacity of SNNs enable the fault-tolerant control scheme to process vast amounts of sensory data with the ability to accurately identify and respond to faults. Furthermore, SNNs can learn and adjust to new environments and fault conditions, providing effective and adaptive flight control. The proposed SNN-based fault-tolerant control scheme demonstrates significant improvements in control accuracy and robustness compared with conventional methods, indicating its potential applicability and suitability for a range of UAV flight control scenarios.},
  archive      = {J_TNNLS},
  author       = {Wei Yu and Ning Yang and Zhijiong Wang and Hung Chun Li and Anguo Zhang and Chaoxu Mu and Sio Hang Pun},
  doi          = {10.1109/TNNLS.2023.3342078},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3773-3785},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fault-tolerant attitude tracking control driven by spiking NNs for unmanned aerial vehicles},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Partial multilabel learning using noise-tolerant broad
learning system with label enhancement and dimensionality reduction.
<em>TNNLS</em>, <em>36</em>(2), 3758–3772. (<a
href="https://doi.org/10.1109/TNNLS.2024.3352285">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial multilabel learning (PML) addresses the issue of noisy supervision, which contains an overcomplete set of candidate labels for each instance with only a valid subset of training data. Using label enhancement techniques, researchers have computed the probability of a label being ground truth. However, enhancing labels in the noisy label space makes it impossible for the existing partial multilabel label enhancement methods to achieve satisfactory results. Besides, few methods simultaneously involve the ambiguity problem, the feature space’s redundancy, and the model’s efficiency in PML. To address these issues, this article presents a novel joint partial multilabel framework using broad learning systems (namely BLS-PML) with three innovative mechanisms: 1) a trustworthy label space is reconstructed through a novel label enhancement method to avoid the bias caused by noisy labels; 2) a low-dimensional feature space is obtained by a confidence-based dimensionality reduction method to reduce the effect of redundancy in the feature space; and 3) a noise-tolerant BLS is proposed by adding a dimensionality reduction layer and a trustworthy label layer to deal with PML problem. We evaluated it on six real-world and seven synthetic datasets, using eight state-of-the-art partial multilabel algorithms as baselines and six evaluation metrics. Out of 144 experimental scenarios, our method significantly outperforms the baselines by about 80%, demonstrating its robustness and effectiveness in handling partial multilabel tasks.},
  archive      = {J_TNNLS},
  author       = {Wenbin Qian and Yanqiang Tu and Jintao Huang and Wenhao Shu and Yiu-Ming Cheung},
  doi          = {10.1109/TNNLS.2024.3352285},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3758-3772},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Partial multilabel learning using noise-tolerant broad learning system with label enhancement and dimensionality reduction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EaLDL: Element-aware lifelong dictionary learning for
multimode process monitoring. <em>TNNLS</em>, <em>36</em>(2), 3744–3757.
(<a href="https://doi.org/10.1109/TNNLS.2023.3343937">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the rapid development of modern industry and the increasing prominence of artificial intelligence, data-driven process monitoring methods have gained significant popularity in industrial systems. Traditional static monitoring models struggle to represent the new modes that arise in industrial production processes due to changes in production environments and operating conditions. Retraining these models to address the changes often leads to high computational complexity. To address this issue, we propose a multimode process monitoring method based on element-aware lifelong dictionary learning (EaLDL). This method initially treats dictionary elements as fundamental units and measures the global importance of dictionary elements from the perspective of the multimode global learning process. Subsequently, to ensure that the dictionary can represent new modes without losing the representation capability of historical modes during the updating process, we construct a novel surrogate loss to impose constraints on the update of dictionary elements. This constraint enables the continuous updating of the dictionary learning (DL) method to accommodate new modes without compromising the representation of previous modes. Finally, to evaluate the effectiveness of the proposed method, we perform comprehensive experiments on numerical simulations as well as an industrial process. A comparison is made with several advanced process monitoring methods to assess its performance. Experimental results demonstrate that our proposed method achieves a favorable balance between learning new modes and retaining the memory of historical modes. Moreover, the proposed method exhibits insensitivity to initial points, delivering satisfactory results under various initial conditions.},
  archive      = {J_TNNLS},
  author       = {Keke Huang and Hengxing Zhu and Dehao Wu and Chunhua Yang and Weihua Gui},
  doi          = {10.1109/TNNLS.2023.3343937},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3744-3757},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {EaLDL: Element-aware lifelong dictionary learning for multimode process monitoring},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cognition-driven structural prior for instance-dependent
label transition matrix estimation. <em>TNNLS</em>, <em>36</em>(2),
3730–3743. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347633">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The label transition matrix has emerged as a widely accepted method for mitigating label noise in machine learning. In recent years, numerous studies have centered on leveraging deep neural networks to estimate the label transition matrix for individual instances within the context of instance-dependent noise. However, these methods suffer from low search efficiency due to the large space of feasible solutions. Behind this drawback, we have explored that the real murderer lies in the invalid class transitions, that is, the actual transition probability between certain classes is zero but is estimated to have a certain value. To mask the invalid class transitions, we introduced a human-cognition-assisted method with structural information from human cognition. Specifically, we introduce a structured transition matrix network (STMN) designed with an adversarial learning process to balance instance features and prior information from human cognition. The proposed method offers two advantages: 1) better estimation effectiveness is obtained by sparing the transition matrix and 2) better estimation accuracy is obtained with the assistance of human cognition. By exploiting these two advantages, our method parametrically estimates a sparse label transition matrix, effectively converting noisy labels into true labels. The efficiency and superiority of our proposed method are substantiated through comprehensive comparisons with state-of-the-art methods on three synthetic datasets and a real-world dataset. Our code will be available at https://github.com/WheatCao/STMN-Pytorch.},
  archive      = {J_TNNLS},
  author       = {Ruiheng Zhang and Zhe Cao and Shuo Yang and Lingyu Si and Haoyang Sun and Lixin Xu and Fuchun Sun},
  doi          = {10.1109/TNNLS.2023.3347633},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3730-3743},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Cognition-driven structural prior for instance-dependent label transition matrix estimation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight group transformer-based time series reduction
network for edge intelligence and its application in industrial RUL
prediction. <em>TNNLS</em>, <em>36</em>(2), 3720–3729. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347227">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, deep learning-based models such as transformer have achieved significant performance for industrial remaining useful life (RUL) prediction due to their strong representation ability. In many industrial practices, RUL prediction algorithms are deployed on edge devices for real-time response. However, the high computational cost of deep learning models makes it difficult to meet the requirements of edge intelligence. In this article, a lightweight group transformer with multihierarchy time-series reduction (GT-MRNet) is proposed to alleviate this problem. Different from most existing RUL methods computing all time series, GT-MRNet can adaptively select necessary time steps to compute the RUL. First, a lightweight group transformer is constructed to extract features by employing group linear transformation with significantly fewer parameters. Then, a time-series reduction strategy is proposed to adaptively filter out unimportant time steps at each layer. Finally, a multihierarchy learning mechanism is developed to further stabilize the performance of time-series reduction. Extensive experimental results on the real-world condition datasets demonstrate that the proposed method can significantly reduce up to 74.7% parameters and 91.8% computation cost without sacrificing accuracy.},
  archive      = {J_TNNLS},
  author       = {Lei Ren and Haiteng Wang and Tingyu Mo and Laurence T. Yang},
  doi          = {10.1109/TNNLS.2023.3347227},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3720-3729},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A lightweight group transformer-based time series reduction network for edge intelligence and its application in industrial RUL prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Anchor graph network for incomplete multiview clustering.
<em>TNNLS</em>, <em>36</em>(2), 3708–3719. (<a
href="https://doi.org/10.1109/TNNLS.2024.3349405">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Incomplete multiview clustering (IMVC) has received extensive attention in recent years. However, existing works still have several shortcomings: 1) some works ignore the correlation of sample pairs in the global structural distribution; 2) many methods are computational expensive, thus cannot be applicable to the large-scale incomplete data clustering tasks; and 3) some methods ignore the refinement of the bipartite graph structure. To address the above issues, we propose a novel anchor graph network for IMVC, which includes a generative model and a similarity metric network. Concretely, the method uses a generative model to construct bipartite graphs, which can mine latent global structure distributions of sample pairs. Later, we use graph convolution network (GCN) with the constructed bipartite graphs to learn the structural embeddings. Notably, the introduction of bipartite graphs can greatly reduce the computational complexity and thus enable our model to handle large-scale data. Unlike previous works based on bipartite graph, our method employs bipartite graphs to guide the learning process in GCNs. In addition, an innovative adaptive learning strategy that can construct robust bipartite graphs is incorporated into our method. Extensive experiments demonstrate that our method achieves the comparable or superior performance compared with the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Yulu Fu and Yuting Li and Qiong Huang and Jinrong Cui and Jie Wen},
  doi          = {10.1109/TNNLS.2024.3349405},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3708-3719},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Anchor graph network for incomplete multiview clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Controllability of n-duplication corona product networks
with laplacian dynamics. <em>TNNLS</em>, <em>36</em>(2), 3693–3707. (<a
href="https://doi.org/10.1109/TNNLS.2023.3336948">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the controllability of a new composite network generated by two smaller scale factor networks via the Corona product with Laplacian dynamics. First, the eigenvalues and corresponding eigenvectors of a new composite network—the $\mathcal {N}$ -duplication Corona product network—are derived by some properties of its factor networks. Second, a necessary and sufficient algebra-based criterion for the controllability of such network is established based on the Popov-Belevitch-Hautus (PBH) test. Furthermore, the weights on edges between the different factor networks are considered. Finally, several examples are presented to demonstrate the effectiveness of our results applied to the unmanned aerial vehicle (UAV) formation.},
  archive      = {J_TNNLS},
  author       = {Bo Liu and Xuan Li and Junjie Huang and Housheng Su},
  doi          = {10.1109/TNNLS.2023.3336948},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3693-3707},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Controllability of N-duplication corona product networks with laplacian dynamics},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convergence-rate-based event-triggered mechanisms for
quasi-synchronization of delayed nonlinear systems on time scales.
<em>TNNLS</em>, <em>36</em>(2), 3682–3692. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347615">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the existing event-triggered mechanisms (ETMs) were designed according to the difference between the quadratic form of measurement errors and the quadratic form of sampling states (or real-time states). In order to reduce the amount of data transmission and develop ETMs for continuous-time and discrete-time delayed nonlinear systems (NSs) simultaneously, this article investigates quasi-synchronization (QS) of NSs on time scales based on a novel ETM, which is designed according to the convergence rate instead of measurement errors of the addressed systems. First, a novel ETM is designed under known nonlinear dynamics, and it is demonstrated that QS with given convergence rate and error level can be achieved under matrix inequality criteria. Second, if the nonlinear functions are unknown, we adapt our ETM to handle this special case. Not only QS but also complete synchronization with given convergence rate can be achieved under the ETMs. If the constructed Lyapunov functions passes through 0, the designed ETM will keep it at the origin. In this case, finite-time synchronization is achieved. Third, under the designed ETMs, it is proved that Zeno behavior can be excluded. At last, four numerical simulations are presented to demonstrate the feasibility and the advantage of the designed ETMs in this article.},
  archive      = {J_TNNLS},
  author       = {Peng Wan and Zhigang Zeng},
  doi          = {10.1109/TNNLS.2023.3347615},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3682-3692},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Convergence-rate-based event-triggered mechanisms for quasi-synchronization of delayed nonlinear systems on time scales},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint state and unknown input estimation for a class of
artificial neural networks with sensor resolution: An encoding–decoding
mechanism. <em>TNNLS</em>, <em>36</em>(2), 3671–3681. (<a
href="https://doi.org/10.1109/TNNLS.2023.3348752">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article is concerned with the joint state and unknown input (SUI) estimation for a class of artificial neural networks (ANNs) with sensor resolution (SR) under the encoding–decoding mechanisms. The consideration of SR, which is an important specification of sensors in the real world, caters to engineering practice. Furthermore, the implementation of the encoding–decoding mechanism in the communication network aims to accommodate the limited bandwidth. The objective of this study is to propose a set-membership estimation algorithm that accurately estimates the state of the ANN without being influenced by the unknown input while accounting for the SR and the encoding–decoding mechanism. First, a sufficient condition is derived to ensure an ellipsoidal constraint on the estimation error. Then, by addressing an optimization problem, the design of the estimator gains is accomplished, and the minimal ellipsoidal constraint on the state estimation error is obtained. Finally, an example is provided to confirm the validity of the proposed joint SUI estimation scheme.},
  archive      = {J_TNNLS},
  author       = {Yuxuan Shen and Zidong Wang and Hongli Dong and Hongjian Liu and Xiaohui Liu},
  doi          = {10.1109/TNNLS.2023.3348752},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3671-3681},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Joint state and unknown input estimation for a class of artificial neural networks with sensor resolution: An Encoding–Decoding mechanism},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient predefined-time adaptive neural networks for
computing time-varying tensor moore–penrose inverse. <em>TNNLS</em>,
<em>36</em>(2), 3659–3670. (<a
href="https://doi.org/10.1109/TNNLS.2024.3354936">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes predefined-time adaptive neural network (PTANN) and event-triggered PTANN (ET-PTANN) models to efficiently compute the time-varying tensor Moore–Penrose (MP) inverse. The PTANN model incorporates a novel adaptive parameter and activation function, enabling it to achieve strongly predefined-time convergence. Unlike traditional time-varying parameters that increase over time, the adaptive parameter is proportional to the error norm, thereby better allocating computational resources and improving efficiency. To further enhance efficiency, the ET-PTANN model combines an event trigger with the evolution formula, resulting in the adjustment of step size and reduction of computation frequency compared to the PTANN model. By conducting mathematical derivations, the article derives the upper bound of convergence time for the proposed neural network models and determines the minimum execution interval for the event trigger. A simulation example demonstrates that the PTANN and ET-PTANN models outperform other related neural network models in terms of computational efficiency and convergence rate. Finally, the practicality of the PTANN and ET-PTANN models is demonstrated through their application for mobile sound source localization.},
  archive      = {J_TNNLS},
  author       = {Zhaohui Qi and Yingqiang Ning and Lin Xiao and Zidong Wang and Yongjun He},
  doi          = {10.1109/TNNLS.2024.3354936},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3659-3670},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Efficient predefined-time adaptive neural networks for computing time-varying tensor Moore–Penrose inverse},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep multiview clustering by pseudo-label guided contrastive
learning and dual correlation learning. <em>TNNLS</em>, <em>36</em>(2),
3646–3658. (<a
href="https://doi.org/10.1109/TNNLS.2024.3354731">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep multiview clustering (MVC) is to learn and utilize the rich relations across different views to enhance the clustering performance under a human-designed deep network. However, most existing deep MVCs meet two challenges. First, most current deep contrastive MVCs usually select the same instance across views as positive pairs and the remaining instances as negative pairs, which always leads to inaccurate contrastive learning (CL). Second, most deep MVCs only consider learning feature or cluster correlations across views, failing to explore the dual correlations. To tackle the above challenges, in this article, we propose a novel deep MVC framework by pseudo-label guided CL and dual correlation learning. Specifically, a novel pseudo-label guided CL mechanism is designed by using the pseudo-labels in each iteration to help removing false negative sample pairs, so that the CL for the feature distribution alignment can be more accurate, thus benefiting the discriminative feature learning. Different from most deep MVCs learning only one kind of correlation, we investigate both the feature and cluster correlations among views to discover the rich and comprehensive relations. Experiments on various datasets demonstrate the superiority of our method over many state-of-the-art compared deep MVCs. The source implementation code will be provided at https://github.com/ShizheHu/Deep-MVC-PGCL-DCL.},
  archive      = {J_TNNLS},
  author       = {Shizhe Hu and Chengkun Zhang and Guoliang Zou and Zhengzheng Lou and Yangdong Ye},
  doi          = {10.1109/TNNLS.2024.3354731},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3646-3658},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep multiview clustering by pseudo-label guided contrastive learning and dual correlation learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GT-HAD: Gated transformer for hyperspectral anomaly
detection. <em>TNNLS</em>, <em>36</em>(2), 3631–3645. (<a
href="https://doi.org/10.1109/TNNLS.2024.3355166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral anomaly detection (HAD) aims to distinguish between the background and anomalies in a scene, which has been widely adopted in various applications. Deep neural network (DNN)-based methods have emerged as the predominant solution, wherein the standard paradigm is to discern the background and anomalies based on the error of self-supervised hyperspectral image (HSI) reconstruction. However, current DNN-based methods cannot guarantee correspondence between the background, anomalies, and reconstruction error, which limits the performance of HAD. In this article, we propose a novel gated transformer network for HAD (GT-HAD). Our key observation is that the spatial–spectral similarity in HSI can effectively distinguish between the background and anomalies, which aligns with the fundamental definition of HAD. Consequently, we develop GT-HAD to exploit the spatial–spectral similarity during HSI reconstruction. GT-HAD consists of two distinct branches that model the features of the background and anomalies, respectively, with content similarity as constraints. Furthermore, we introduce an adaptive gating unit to regulate the activation states of these two branches based on a content-matching method (CMM). Extensive experimental results demonstrate the superior performance of GT-HAD. The original code is publicly available at https://github.com/jeline0110/ GT-HAD, along with a comprehensive benchmark of state-of-the-art HAD methods.},
  archive      = {J_TNNLS},
  author       = {Jie Lian and Lizhi Wang and He Sun and Hua Huang},
  doi          = {10.1109/TNNLS.2024.3355166},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3631-3645},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {GT-HAD: Gated transformer for hyperspectral anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memristor-based neural network circuit of associative memory
with overshadowing and emotion congruent effect. <em>TNNLS</em>,
<em>36</em>(2), 3618–3630. (<a
href="https://doi.org/10.1109/TNNLS.2023.3348553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most memristor-based neural network circuits consider only a single pattern of overshadowing or emotion, but the relationship between overshadowing and emotion is ignored. In this article, a memristor-based neural network circuit of associative memory with overshadowing and emotion congruent effect is designed, and overshadowing under multiple emotions is taken into account. The designed circuit mainly consists of an emotion module, a memory module, an inhibition module, and a feedback module. The generation and recovery of different emotions are realized by the emotion module. The functions of overshadowing under different emotions and recovery from overshadowing are achieved by the inhibition module and the memory module. Finally, the blocking caused by long-term overshadowing is implemented by the feedback module. The proposed circuit can be applied to bionic emotional robots and offers some references for brain-like systems.},
  archive      = {J_TNNLS},
  author       = {Junwei Sun and Yu Zhai and Peng Liu and Yanfeng Wang},
  doi          = {10.1109/TNNLS.2023.3348553},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3618-3630},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Memristor-based neural network circuit of associative memory with overshadowing and emotion congruent effect},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synchronization in coupled neural networks with hybrid
delayed impulses: Average impulsive delay-gain method. <em>TNNLS</em>,
<em>36</em>(2), 3608–3617. (<a
href="https://doi.org/10.1109/TNNLS.2024.3357515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we propose a new concept called average impulsive delay-gain (AIDG) for studying the synchronization of coupled neural networks (CNNs). Based on the viewpoints of impulsive control and impulsive perturbation, we establish some globally exponential synchronization criteria for CNNs. Our methods are well-suited for addressing the synchronization problems of systems subject to hybrid delayed impulses with time-varying impulsive delay and gain. Moreover, we prove that the AIDG has both positive and negative effects on synchronization. Compared to existing research, our conclusions are more applicable and less conservative as the considered hybrid delayed impulses involve more flexible cases. Finally, we validate the effectiveness of our proposed results by applying them to small-world and scale-free network models.},
  archive      = {J_TNNLS},
  author       = {Kangping Gao and Jianquan Lu and Wei Xing Zheng and Xiangyong Chen},
  doi          = {10.1109/TNNLS.2024.3357515},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3608-3617},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Synchronization in coupled neural networks with hybrid delayed impulses: Average impulsive delay-gain method},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fractional tensor recurrent unit (fTRU): A stable
forecasting model with long memory. <em>TNNLS</em>, <em>36</em>(2),
3598–3607. (<a
href="https://doi.org/10.1109/TNNLS.2023.3338696">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The tensor recurrent model is a family of nonlinear dynamical systems, of which the recurrence relation consists of a $p$ -fold (called degree- $p$ ) tensor product. Despite such models frequently appearing in advanced recurrent neural networks (RNNs), to this date, there are limited studies on their long memory properties and stability in sequence tasks. In this article, we propose a fractional tensor recurrent model, where the tensor degree $p$ is extended from the discrete domain to the continuous domain, so it is effectively learnable from various datasets. Theoretically, we prove that a large degree $p$ is essential to achieve the long memory effect in a tensor recurrent model, yet it could lead to unstable dynamical behaviors. Hence, our new model, named fractional tensor recurrent unit (fTRU), is expected to seek the saddle point between long memory property and model stability during the training. We experimentally show that the proposed model achieves competitive performance with a long memory and stable manners in several forecasting tasks compared to various advanced RNNs.},
  archive      = {J_TNNLS},
  author       = {Hejia Qiu and Chao Li and Ying Weng and Zhun Sun and Qibin Zhao},
  doi          = {10.1109/TNNLS.2023.3338696},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3598-3607},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fractional tensor recurrent unit (fTRU): A stable forecasting model with long memory},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SARF: Aliasing relation–assisted self-supervised learning
for few-shot relation reasoning. <em>TNNLS</em>, <em>36</em>(2),
3587–3597. (<a
href="https://doi.org/10.1109/TNNLS.2024.3355151">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot relation reasoning on knowledge graphs (FS-KGR) is an important and practical problem that aims to infer long-tail relations and has drawn increasing attention these years. Among all the proposed methods, self-supervised learning (SSL) methods, which effectively extract the hidden essential inductive patterns relying only on the support sets, have achieved promising performance. However, the existing SSL methods simply cut down connections between high-frequency and long-tail relations, which ignores the fact, i.e., the two kinds of information could be highly related to each other. Specifically, we observe that relations with similar contextual meanings, called aliasing relations (ARs), may have similar attributes. In other words, the ARs of the target long-tail relation could be in high-frequency, and leveraging such attributes can largely improve the reasoning performance. Based on the interesting observation above, we proposed a novel Self-supervised learning model by leveraging Aliasing Relations to assist FS-KGR, termed SARF. Specifically, we propose a graph neural network (GNN)-based AR-assist module to encode the ARs. Besides, we further provide two fusion strategies, i.e., simple summation and learnable fusion, to fuse the generated representations, which contain extra abundant information underlying the ARs, into the self-supervised reasoning backbone for performance enhancement. Extensive experiments on three few-shot benchmarks demonstrate that SARF achieves state-of-the-art (SOTA) performance compared with other methods in most cases.},
  archive      = {J_TNNLS},
  author       = {Lingyuan Meng and Ke Liang and Bin Xiao and Sihang Zhou and Yue Liu and Meng Liu and Xihong Yang and Xinwang Liu and Jinyan Li},
  doi          = {10.1109/TNNLS.2024.3355151},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3587-3597},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SARF: Aliasing Relation–Assisted self-supervised learning for few-shot relation reasoning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time adaptive dynamic programming for affine-form
nonlinear systems. <em>TNNLS</em>, <em>36</em>(2), 3573–3586. (<a
href="https://doi.org/10.1109/TNNLS.2023.3337387">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Inspired by the fusion of state optimization and finite-time convergence, the finite-time optimal control (FTOC) for the affine-form nonlinear systems is investigated in this article. To achieve optimal stability with finite response time, a novel finite-time adaptive dynamic programming (FTADP) is presented for the affine-form nonlinear systems. By mapping the value function into finite-time stability space with the transformation function, the Bellman equation with finite-time stability space is first obtained. Then, by solving the Hamilton–Jacobi–Bellman (HJB) equation, the new FTOC strategy is presented with the theoretical finite-time stability description. Furthermore, to solve the above optimal controller with nonlinearity characteristic, the novel adaptive dynamic programming (ADP) based on the finite-time critic-actor offline neural network (NN) approximation algorithm is implemented, and the corresponding finite-time convergence characteristic is illustrated theoretically. Eventually, the application analysis on the circuit systems shows that the proposed FTADP has superiority compared with general optimal control.},
  archive      = {J_TNNLS},
  author       = {Longjie Zhang and Yong Chen},
  doi          = {10.1109/TNNLS.2023.3337387},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3573-3586},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Finite-time adaptive dynamic programming for affine-form nonlinear systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge distillation guided interpretable brain subgraph
neural networks for brain disorder exploration. <em>TNNLS</em>,
<em>36</em>(2), 3559–3572. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain is a highly complex neurological system that has been the subject of continuous exploration by scientists. With the help of modern neuroimaging techniques, there has been significant progress made in brain disorder analysis. There is an increasing interest about utilizing artificial intelligence techniques to improve the efficiency of disorder diagnosis in recent years. However, these methods rely only on neuroimaging data for disorder diagnosis and do not explore the pathogenic mechanism behind the disorder or provide an interpretable result toward the diagnosis decision. Furthermore, the scarcity of medical data limits the performance of existing methods. As the hot application of graph neural networks (GNNs) in molecular graphs and drug discovery due to its strong graph-structured data learning ability, whether GNNs can also play a huge role in the field of brain disorder analysis. Thus, in this work, we innovatively model brain neuroimaging data into graph-structured data and propose knowledge distillation (KD) guided brain subgraph neural networks to extract discriminative subgraphs between patient and healthy brain graphs to explain which brain regions and abnormal functional connectivities cause the disorder. Specifically, we introduce the KD technique to transfer the knowledge of pretrained teacher model to guide brain subgraph neural networks training and alleviate the problem of insufficient training data. And these discriminative subgraphs are conducive to learn better brain graph-level representations for disorder prediction. We conduct abundant experiments on two functional magnetic resonance imaging datasets, i.e., Parkinson’s disease (PD) and attention-deficit/hyperactivity disorder (ADHD), and experimental results well demonstrate the superiority of our method over other brain graph analysis methods for disorder prediction accuracy. The interpretable experimental results given by our method are consistent with corresponding medical research, which is encouraging to provide a potential for deeper brain disorder study.},
  archive      = {J_TNNLS},
  author       = {Xuexiong Luo and Jia Wu and Jian Yang and Hongyang Chen and Zhao Li and Hao Peng and Chuan Zhou},
  doi          = {10.1109/TNNLS.2023.3341802},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3559-3572},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge distillation guided interpretable brain subgraph neural networks for brain disorder exploration},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised lie algebra representation learning via
optimal canonical metric. <em>TNNLS</em>, <em>36</em>(2), 3547–3558. (<a
href="https://doi.org/10.1109/TNNLS.2024.3355492">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning discriminative representation with limited training samples is emerging as an important yet challenging visual categorization task. While prior work has shown that incorporating self-supervised learning can improve performance, we found that the direct use of canonical metric in a Lie group is theoretically incorrect. In this article, we prove that a valid optimization measurement should be a canonical metric on Lie algebra. Based on the theoretical finding, this article introduces a novel self-supervised Lie algebra network (SLA-Net) representation learning framework. Via minimizing canonical metric distance between target and predicted Lie algebra representation within a computationally convenient vector space, SLA-Net avoids computing nontrivial geodesic (locally length-minimizing curve) metric on a manifold (curved space). By simultaneously optimizing a single set of parameters shared by self-supervised learning and supervised classification, the proposed SLA-Net gains improved generalization capability. Comprehensive evaluation results on eight public datasets show the effectiveness of SLA-Net for visual categorization with limited samples.},
  archive      = {J_TNNLS},
  author       = {Xiaohan Yu and Zicheng Pan and Yang Zhao and Yongsheng Gao},
  doi          = {10.1109/TNNLS.2024.3355492},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3547-3558},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Self-supervised lie algebra representation learning via optimal canonical metric},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Novel snap-layer MMPC scheme via neural dynamics equivalency
and solver for redundant robot arms with five-layer physical limits.
<em>TNNLS</em>, <em>36</em>(2), 3534–3546. (<a
href="https://doi.org/10.1109/TNNLS.2024.3351674">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To obtain smoother kinematic control of minimum motion, a novel snap-layer minimum motion scheme, otherwise known as the minimum motion planning and control (MMPC) scheme for redundant robot arms, is proposed for the first time in this study. With the primary task of tracking planned paths and the consideration of satisfying five-layer physical limits, the snap-layer MMPC problem is transformed into a quadratic programming (QP) problem. Five-layer physical limits include angle-layer, velocity-layer, acceleration-layer, jerk-layer, and snap-layer limits, which are all considered and then transformed into a unified-layer bounded constraint through Zhang neural dynamics (ZND) equivalency. Furthermore, the snap-layer performance index and equation constraint are derived by utilizing the ZND formula. Therefore, the proposed snap-layer MMPC scheme is formulated as a standard QP that can avoid the potential physical damage of redundant robot arms. The snap-layer projection neural dynamics (PND) solver is presented and used to acquire the neural solution of the QP. Simulation results on a 6-degrees-of-freedom (DOF) planar redundant robot arm are presented to substantiate the effectiveness and superiority of the proposed snap-layer MMPC scheme by comparing it with the jerk-layer MMPC scheme and the minimum snap norm (MSN) scheme.},
  archive      = {J_TNNLS},
  author       = {Zanyu Tang and Yunong Zhang and Liangjie Ming},
  doi          = {10.1109/TNNLS.2024.3351674},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3534-3546},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Novel snap-layer MMPC scheme via neural dynamics equivalency and solver for redundant robot arms with five-layer physical limits},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Redundancy is not what you need: An embedding fusion graph
auto-encoder for self-supervised graph representation learning.
<em>TNNLS</em>, <em>36</em>(2), 3519–3533. (<a
href="https://doi.org/10.1109/TNNLS.2024.3357080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute graphs are a crucial data structure for graph communities. However, the presence of redundancy and noise in the attribute graph can impair the aggregation effect of integrating two different heterogeneous distributions of attribute and structural features, resulting in inconsistent and distorted data that ultimately compromises the accuracy and reliability of attribute graph learning. For instance, redundant or irrelevant attributes can result in overfitting, while noisy attributes can lead to underfitting. Similarly, redundant or noisy structural features can affect the accuracy of graph representations, making it challenging to distinguish between different nodes or communities. To address these issues, we propose the embedded fusion graph auto-encoder framework for self-supervised learning (SSL), which leverages multitask learning to fuse node features across different tasks to reduce redundancy. The embedding fusion graph auto-encoder (EFGAE) framework comprises two phases: pretraining (PT) and downstream task learning (DTL). During the PT phase, EFGAE uses a graph auto-encoder (GAE) based on adversarial contrastive learning to learn structural and attribute embeddings separately and then fuses these embeddings to obtain a representation of the entire graph. During the DTL phase, we introduce an adaptive graph convolutional network (AGCN), which is applied to graph neural network (GNN) classifiers to enhance recognition for downstream tasks. The experimental results demonstrate that our approach outperforms state-of-the-art (SOTA) techniques in terms of accuracy, generalization ability, and robustness.},
  archive      = {J_TNNLS},
  author       = {Mengran Li and Yong Zhang and Shaofan Wang and Yongli Hu and Baocai Yin},
  doi          = {10.1109/TNNLS.2024.3357080},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3519-3533},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Redundancy is not what you need: An embedding fusion graph auto-encoder for self-supervised graph representation learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An off-policy reinforcement learning-based adaptive
optimization method for dynamic resource allocation problem.
<em>TNNLS</em>, <em>36</em>(2), 3504–3518. (<a
href="https://doi.org/10.1109/TNNLS.2023.3338237">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an adaptive optimization method is proposed for the dynamic resource allocation problem (RAP) with multiple objectives in the manufacturing industry. In the proposed method, a novel reinforcement learning method (DSAC-ERCE) is designed to adaptively set the weights for multiple objectives, and then the optimization method is adopted to generate the noninferior solutions in each time period. To ensure DSAC-ERCE’s performance in dynamic and complex resource allocation environments, we develop a state-encoding network with a proposed information entropy attention mechanism to encode the state. Then, we introduce a new reward function to escape from the local optima of the policy and further present a conditional entropy policy to enhance the policy network. In addition, we demonstrate the feasibility of improving the quality of actions and present a boundary method for high-quality actions. We also introduce an optimization model to automatically adjust the temperature parameter in DSAC-ERCE. Furthermore, we compare and analyze our approach with other state-of-the-art reinforcement learning methods. The experiments illustrate that DSAC-ERCE outperforms state-of-the-art reinforcement learning methods. Moreover, DSAC-ERCE can be generalized to solve optimization problems with two to five objectives, problems with linear, quadratic, cubic, logarithmic, or inverse objectives, and problems with diverse structures.},
  archive      = {J_TNNLS},
  author       = {Baiyang He and Ying Meng and Lixin Tang},
  doi          = {10.1109/TNNLS.2023.3338237},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3504-3518},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An off-policy reinforcement learning-based adaptive optimization method for dynamic resource allocation problem},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallel solution of nonlinear projection equations in a
multitask learning framework. <em>TNNLS</em>, <em>36</em>(2), 3490–3503.
(<a href="https://doi.org/10.1109/TNNLS.2024.3350335">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nonlinear projection equations (NPEs) provide a unified framework for addressing various constrained nonlinear optimization and engineering problems. However, when it comes to solving multiple NPEs, traditional numerical integration methods are not efficient enough. This is because traditional methods solve each NPE iteratively and independently. In this article, we propose a novel approach based on multitask learning (MTL) for solving multiple NPEs. The solution procedure is outlined as follows. First, we model each NPE as a system of ordinary differential equations (ODEs) using neurodynamic optimization. Second, for each ODE system, we use a physics-informed neural network (PINN) as the solution. Third, we use a multibranch MTL framework, where each branch corresponds to a PINN model. This allows us to solve multiple NPEs in parallel by training a single neural network model. Experimental results show that our approach has superior computational performance, especially when the number of NPEs to be solved is large.},
  archive      = {J_TNNLS},
  author       = {Dawen Wu and Abdel Lisser},
  doi          = {10.1109/TNNLS.2024.3350335},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3490-3503},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Parallel solution of nonlinear projection equations in a multitask learning framework},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synergetic learning neuro-control for unknown affine
nonlinear systems with asymptotic stability guarantees. <em>TNNLS</em>,
<em>36</em>(2), 3479–3489. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347663">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {For completely unknown affine nonlinear systems, in this article, a synergetic learning algorithm (SLA) is developed to learn an optimal control. Unlike the conventional Hamilton–Jacobi–Bellman equation (HJBE) with system dynamics, a model-free HJBE (MF-HJBE) is deduced by means of off-policy reinforcement learning (RL). Specifically, the equivalence between HJBE and MF-HJBE is first bridged from the perspective of the uniqueness of the solution of the HJBE. Furthermore, it is proven that once the solution of MF-HJBE exists, its corresponding control input renders the system asymptotically stable and optimizes the cost function. To solve the MF-HJBE, the two agents composing the synergetic learning (SL) system, the critic agent and the actor agent, can evolve in real-time using only the system state data. By building an experience reply (ER)-based learning rule, it is proven that when the critic agent evolves toward the optimal cost function, the actor agent not only evolves toward the optimal control, but also guarantees the asymptotic stability of the system. Finally, simulations of the F16 aircraft system and the Van der Pol oscillator are conducted and the results support the feasibility of the developed SLA.},
  archive      = {J_TNNLS},
  author       = {Liao Zhu and Qinglai Wei and Ping Guo},
  doi          = {10.1109/TNNLS.2023.3347663},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3479-3489},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Synergetic learning neuro-control for unknown affine nonlinear systems with asymptotic stability guarantees},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multilevel contrastive graph masked autoencoders for
unsupervised graph-structure learning. <em>TNNLS</em>, <em>36</em>(2),
3464–3478. (<a
href="https://doi.org/10.1109/TNNLS.2024.3358801">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised graph-structure learning (GSL) which aims to learn an effective graph structure applied to arbitrary downstream tasks by data itself without any labels’ guidance, has recently received increasing attention in various real applications. Although several existing unsupervised GSL has achieved superior performance in different graph analytical tasks, how to utilize the popular graph masked autoencoder to sufficiently acquire effective supervision information from the data itself for improving the effectiveness of learned graph structure has been not effectively explored so far. To tackle the above issue, we present a multilevel contrastive graph masked autoencoder (MCGMAE) for unsupervised GSL. Specifically, we first introduce a graph masked autoencoder with the dual feature masking strategy to reconstruct the same input graph-structured data under the original structure generated by the data itself and learned graph-structure scenarios, respectively. And then, the inter- and intra-class contrastive loss is introduced to maximize the mutual information in feature and graph-structure reconstruction levels simultaneously. More importantly, the above inter- and intra-class contrastive loss is also applied to the graph encoder module for further strengthening their agreement at the feature-encoder level. In comparison to the existing unsupervised GSL, our proposed MCGMAE can effectively improve the training robustness of the unsupervised GSL via different-level supervision information from the data itself. Extensive experiments on three graph analytical tasks and eight datasets validate the effectiveness of the proposed MCGMAE.},
  archive      = {J_TNNLS},
  author       = {Sichao Fu and Qinmu Peng and Yang He and Xiaorui Wang and Bin Zou and Duanquan Xu and Xiao-Yuan Jing and Xinge You},
  doi          = {10.1109/TNNLS.2024.3358801},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3464-3478},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multilevel contrastive graph masked autoencoders for unsupervised graph-structure learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Imbalance mitigation for continual learning via knowledge
decoupling and dual enhanced contrastive learning. <em>TNNLS</em>,
<em>36</em>(2), 3450–3463. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347477">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Continual learning (CL) aims at studying how to learn new knowledge continuously from data streams without catastrophically forgetting the previous knowledge. One of the key problems is catastrophic forgetting, that is, the performance of the model on previous tasks declines significantly after learning the subsequent task. Several studies addressed it by replaying samples stored in the buffer when training new tasks. However, the data imbalance between old and new task samples results in two serious problems: information suppression and weak feature discriminability. The former refers to the information in the sufficient new task samples suppressing that in the old task samples, which is harmful to maintaining the knowledge since the biased output worsens the consistency of the same sample’s output at different moments. The latter refers to the feature representation being biased to the new task, which lacks discrimination to distinguish both old and new tasks. To this end, we build an imbalance mitigation for CL (IMCL) framework that incorporates a decoupled knowledge distillation (DKD) approach and a dual enhanced contrastive learning (DECL) approach to tackle both problems. Specifically, the DKD approach alleviates the suppression of the new task on the old tasks by decoupling the model output probability during the replay stage, which better maintains the knowledge of old tasks. The DECL approach enhances both low- and high-level features and fuses the enhanced features to construct contrastive loss to effectively distinguish different tasks. Extensive experiments on three popular datasets show that our method achieves promising performance under task incremental learning (Task-IL), class incremental learning (Class-IL), and domain incremental learning (Domain-IL) settings.},
  archive      = {J_TNNLS},
  author       = {Zhong Ji and Zhanyu Jiao and Qiang Wang and Yanwei Pang and Jungong Han},
  doi          = {10.1109/TNNLS.2023.3347477},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3450-3463},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Imbalance mitigation for continual learning via knowledge decoupling and dual enhanced contrastive learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Boosting convolutional neural networks with middle spectrum
grouped convolution. <em>TNNLS</em>, <em>36</em>(2), 3436–3449. (<a
href="https://doi.org/10.1109/TNNLS.2024.3355489">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a novel module called middle spectrum grouped convolution (MSGC) for efficient deep convolutional neural networks (DCNNs) with the mechanism of grouped convolution. It explores the broad “middle spectrum” area between channel pruning and conventional grouped convolution. Compared with channel pruning, MSGC can retain most of the information from the input feature maps due to the group mechanism; compared with grouped convolution, MSGC benefits from the learnability, the core of channel pruning, for constructing its group topology, leading to better channel division. The middle spectrum area is unfolded along four dimensions: groupwise, layerwise, samplewise, and attentionwise, making it possible to reveal more powerful and interpretable structures. As a result, the proposed module acts as a booster that can reduce the computational cost of the host backbones for general image recognition with even improved predictive accuracy. For example, in the experiments on the ImageNet dataset for image classification, MSGC can reduce the multiply–accumulates (MACs) of ResNet-18 and ResNet-50 by half but still increase the Top-1 accuracy by more than 1%. With a 35% reduction of MACs, MSGC can also increase the Top-1 accuracy of the MobileNetV2 backbone. Results on the MS COCO dataset for object detection show similar observations. Our code and trained models are available at https://github.com/hellozhuo/msgc.},
  archive      = {J_TNNLS},
  author       = {Zhuo Su and Jiehua Zhang and Tianpeng Liu and Zhen Liu and Shuanghui Zhang and Matti Pietikäinen and Li Liu},
  doi          = {10.1109/TNNLS.2024.3355489},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3436-3449},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Boosting convolutional neural networks with middle spectrum grouped convolution},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convex dual theory analysis of two-layer convolutional
neural networks with soft-thresholding. <em>TNNLS</em>, <em>36</em>(2),
3423–3435. (<a
href="https://doi.org/10.1109/TNNLS.2024.3353795">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Soft-thresholding has been widely used in neural networks. Its basic network structure is a two-layer convolution neural network with soft-thresholding. Due to the network’s nature of nonlinear and nonconvex, the training process heavily depends on an appropriate initialization of network parameters, resulting in the difficulty of obtaining a globally optimal solution. To address this issue, a convex dual network is designed here. We theoretically analyze the network convexity and prove that the strong duality holds. Extensive results on both simulation and real-world datasets show that strong duality holds, the dual network does not depend on initialization and optimizer, and enables faster convergence than the state-of-the-art two-layer network. This work provides a new way to convexify soft-thresholding neural networks. Furthermore, the convex dual network model of a deep soft-thresholding network with a parallel structure is deduced.},
  archive      = {J_TNNLS},
  author       = {Chunyan Xiong and Chaoxing Zhang and Mengli Lu and Xiaotong Yu and Jian Cao and Zhong Chen and Di Guo and Xiaobo Qu},
  doi          = {10.1109/TNNLS.2024.3353795},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3423-3435},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Convex dual theory analysis of two-layer convolutional neural networks with soft-thresholding},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MCMC: Multi-constrained model compression via one-stage
envelope reinforcement learning. <em>TNNLS</em>, <em>36</em>(2),
3410–3422. (<a
href="https://doi.org/10.1109/TNNLS.2024.3353763">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model compression methods are being developed to bridge the gap between the massive scale of neural networks and the limited hardware resources on edge devices. Since most real-world applications deployed on resource-limited hardware platforms typically have multiple hardware constraints simultaneously, most existing model compression approaches that only consider optimizing one single hardware objective are ineffective. In this article, we propose an automated pruning method called multi-constrained model compression (MCMC) that allows for the optimization of multiple hardware targets, such as latency, floating point operations (FLOPs), and memory usage, while minimizing the impact on accuracy. Specifically, we propose an improved multi-objective reinforcement learning (MORL) algorithm, the one-stage envelope deep deterministic policy gradient (DDPG) algorithm, to determine the pruning strategy for neural networks. Our improved one-stage envelope DDPG algorithm reduces exploration time and offers greater flexibility in adjusting target priorities, enhancing its suitability for pruning tasks. For instance, on the visual geometry group (VGG)-16 network, our method achieved an 80% reduction in FLOPs, a $2.31\times $ reduction in memory usage, and a $1.92\times $ acceleration, with an accuracy improvement of 0.09% compared with the baseline. For larger datasets, such as ImageNet, we reduced FLOPs by 50% for MobileNet-V1, resulting in a $4.7\times $ faster speed and $1.48\times $ memory compression, while maintaining the same accuracy. When applied to edge devices, such as JETSON XAVIER NX, our method resulted in a 71% reduction in FLOPs for MobileNet-V1, leading to a $1.63\times $ faster speed, $1.64\times $ memory compression, and an accuracy improvement.},
  archive      = {J_TNNLS},
  author       = {Siqi Li and Jun Chen and Shanqi Liu and Chengrui Zhu and Guanzhong Tian and Yong Liu},
  doi          = {10.1109/TNNLS.2024.3353763},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3410-3422},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MCMC: Multi-constrained model compression via one-stage envelope reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust decoding of rich dynamical visual scenes with retinal
spikes. <em>TNNLS</em>, <em>36</em>(2), 3396–3409. (<a
href="https://doi.org/10.1109/TNNLS.2024.3351120">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sensory information transmitted to the brain activates neurons to create a series of coping behaviors. Understanding the mechanisms of neural computation and reverse engineering the brain to build intelligent machines requires establishing a robust relationship between stimuli and neural responses. Neural decoding aims to reconstruct the original stimuli that trigger neural responses. With the recent upsurge of artificial intelligence, neural decoding provides an insightful perspective for designing novel algorithms of brain–machine interface. For humans, vision is the dominant contributor to the interaction between the external environment and the brain. In this study, utilizing the retinal neural spike data collected over multi trials with visual stimuli of two movies with different levels of scene complexity, we used a neural network decoder to quantify the decoded visual stimuli with six different metrics for image quality assessment establishing comprehensive inspection of decoding. With the detailed and systematical study of the effect and single and multiple trials of data, different noise in spikes, and blurred images, our results provide an in-depth investigation of decoding dynamical visual scenes using retinal spikes. These results provide insights into the neural coding of visual scenes and services as a guideline for designing next-generation decoding algorithms of neuroprosthesis and other devices of brain–machine interface.},
  archive      = {J_TNNLS},
  author       = {Zhaofei Yu and Tong Bu and Yijun Zhang and Shanshan Jia and Tiejun Huang and Jian K. Liu},
  doi          = {10.1109/TNNLS.2024.3351120},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3396-3409},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust decoding of rich dynamical visual scenes with retinal spikes},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LR aerial photo categorization by cross-resolution
perceptual knowledge propagation. <em>TNNLS</em>, <em>36</em>(2),
3384–3395. (<a
href="https://doi.org/10.1109/TNNLS.2024.3349515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are hundreds of high- and low-altitude earth observation satellites that asynchronously capture massive-scale aerial photographs every day. Generally, high-altitude satellites take low-resolution (LR) aerial pictures, each covering a considerably large area. In contrast, low-altitude satellites capture high-resolution (HR) aerial photos, each depicting a relatively small area. Accurately discovering the semantics of LR aerial photos is an indispensable technique in computer vision. Nevertheless, it is also a challenging task due to: 1) the difficulty to characterize human hierarchical visual perception and 2) the intolerable human resources to label sufficient training data. To handle these problems, a novel cross-resolution perceptual knowledge propagation (CPKP) framework is proposed, focusing on adapting the visual perceptual experiences deeply learned from HR aerial photos to categorize LR ones. Specifically, by mimicking the human vision system, a novel low-rank model is designed to decompose each LR aerial photo into multiple visually/semantically salient foreground regions coupled with the background nonsalient regions. This model can: 1) produce a gaze-shifting path (GSP) simulating human gaze behavior and 2) engineer the deep feature for each GSP. Afterward, a kernel-induced feature selection (FS) algorithm is formulated to obtain a succinct set of deep GSP features discriminative across LR and HR aerial photos. Based on the selected features, the labels from LR and HR aerial photos are collaboratively utilized to train a linear classifier for categorizing LR ones. It is worth emphasizing that, such a CPKP mechanism can effectively optimize the linear classifier training, as labels of HR aerial photos are acquired more conveniently in practice. Comprehensive visualization results and comparative study have validated the superiority of our approach.},
  archive      = {J_TNNLS},
  author       = {Yi Li and Luming Zhang and Lin Shao},
  doi          = {10.1109/TNNLS.2024.3349515},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3384-3395},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {LR aerial photo categorization by cross-resolution perceptual knowledge propagation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DiffStyler: Controllable dual diffusion for text-driven
image stylization. <em>TNNLS</em>, <em>36</em>(2), 3370–3383. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342645">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the impressive results of arbitrary image-guided style transfer methods, text-driven image stylization has recently been proposed for transferring a natural image into a stylized one according to textual descriptions of the target style provided by the user. Unlike the previous image-to-image transfer approaches, text-guided stylization progress provides users with a more precise and intuitive way to express the desired style. However, the huge discrepancy between cross-modal inputs/outputs makes it challenging to conduct text-driven image stylization in a typical feed-forward CNN pipeline. In this article, we present DiffStyler, a dual diffusion processing architecture to control the balance between the content and style of the diffused results. The cross-modal style information can be easily integrated as guidance during the diffusion process step-by-step. Furthermore, we propose a content image-based learnable noise on which the reverse denoising process is based, enabling the stylization results to better preserve the structure information of the content image. We validate the proposed DiffStyler beyond the baseline methods through extensive qualitative and quantitative experiments. The code is available at https://github.com/haha-lisa/Diffstyler.},
  archive      = {J_TNNLS},
  author       = {Nisha Huang and Yuxin Zhang and Fan Tang and Chongyang Ma and Haibin Huang and Weiming Dong and Changsheng Xu},
  doi          = {10.1109/TNNLS.2023.3342645},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3370-3383},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DiffStyler: Controllable dual diffusion for text-driven image stylization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semantic consistency reasoning for 3-d object detection in
point clouds. <em>TNNLS</em>, <em>36</em>(2), 3356–3369. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341097">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point cloud-based 3-D object detection is a significant and critical issue in numerous applications. While most existing methods attempt to capitalize on the geometric characteristics of point clouds, they neglect the internal semantic properties of point and the consistency between the semantic and geometric clues. We introduce a semantic consistency (SC) mechanism for 3-D object detection in this article, by reasoning about the semantic relations between 3-D object boxes and its internal points. This mechanism is based on a natural principle: the semantic category of a 3-D bounding box should be consistent with the categories of all points within the box. Driven by the SC mechanism, we propose a novel SC network (SCNet) to detect 3-D objects from point clouds. Specifically, the SCNet is composed of a feature extraction module, a detection decision module, and a semantic segmentation module. In inference, the feature extraction and the detection decision modules are used to detect 3-D objects. In training, the semantic segmentation module is jointly trained with the other two modules to produce more robust and applicable model parameters. The performance is greatly boosted through reasoning about the relations between the output 3-D object boxes and segmented points. The proposed SC mechanism is model-agnostic and can be integrated into other base 3-D object detection models. We test the proposed model on three challenging indoor and outdoor benchmark datasets: ScanNetV2, SUN RGB-D, and KITTI. Furthermore, to validate the universality of the SC mechanism, we implement it in three different 3-D object detectors. The experiments show that the performance is impressively improved and the extensive ablation studies also demonstrate the effectiveness of the proposed model.},
  archive      = {J_TNNLS},
  author       = {Wenwen Wei and Ping Wei and Zhimin Liao and Jialu Qin and Xiang Cheng and Meiqin Liu and Nanning Zheng},
  doi          = {10.1109/TNNLS.2023.3341097},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3356-3369},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Semantic consistency reasoning for 3-D object detection in point clouds},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DSFedCon: Dynamic sparse federated contrastive learning for
data-driven intelligent systems. <em>TNNLS</em>, <em>36</em>(2),
3343–3355. (<a
href="https://doi.org/10.1109/TNNLS.2024.3349400">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) makes it possible for multiple clients to collaboratively train a machine-learning model through communicating models instead of data, reducing privacy risk. Thus, FL is more suitable for processing data security and privacy for intelligent systems and applications. Unfortunately, there are several challenges in FL, such as the low training accuracy for nonindependent and identically distributed (non-IID) data and the high cost of computation and communication. Considering these, we propose a novel FL framework named dynamic sparse federated contrastive learning (DSFedCon). DSFedCon combines FL with dynamic sparse (DSR) training of network pruning and contrastive learning to improve model performance and reduce computation costs and communication costs. We analyze DSFedCon from the perspective of accuracy, communication, and security, demonstrating it is communication-efficient and safe. To give a practical evaluation for non-IID data training, we perform experiments and comparisons on the MNIST, CIFAR-10, and CIFAR-100 datasets with different parameters of Dirichlet distribution. Results indicate that DSFedCon can get higher accuracy and better communication cost than other state-of-the-art methods in these two datasets. More precisely, we show that DSFedCon has a 4.67-time speedup of communication rounds in MNIST, a 7.5-time speedup of communication rounds in CIFAR-10, and an 18.33-time speedup of communication rounds in CIFAR-100 dataset while achieving the same training accuracy.},
  archive      = {J_TNNLS},
  author       = {Zhengming Li and Jiahui Chen and Peifeng Zhang and Huiwu Huang and Guanbin Li},
  doi          = {10.1109/TNNLS.2024.3349400},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3343-3355},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DSFedCon: Dynamic sparse federated contrastive learning for data-driven intelligent systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attentive learning facilitates generalization of neural
networks. <em>TNNLS</em>, <em>36</em>(2), 3329–3342. (<a
href="https://doi.org/10.1109/TNNLS.2024.3356310">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies the generalization of neural networks (NNs) by examining how a network changes when trained on a training sample with or without out-of-distribution (OoD) examples. If the network’s predictions are less influenced by fitting OoD examples, then the network learns attentively from the clean training set. A new notion, dataset-distraction stability, is proposed to measure the influence. Extensive CIFAR-10/100 experiments on the different VGG, ResNet, WideResNet, ViT architectures, and optimizers show a negative correlation between the dataset-distraction stability and generalizability. With the distraction stability, we decompose the learning process on the training set $\mathcal {S}$ into multiple learning processes on the subsets of $\mathcal {S}$ drawn from simpler distributions, i.e., distributions of smaller intrinsic dimensions (IDs), and furthermore, a tighter generalization bound is derived. Through attentive learning, miraculous generalization in deep learning can be explained and novel algorithms can also be designed.},
  archive      = {J_TNNLS},
  author       = {Shiye Lei and Fengxiang He and Haowen Chen and Dacheng Tao},
  doi          = {10.1109/TNNLS.2024.3356310},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3329-3342},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Attentive learning facilitates generalization of neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PAFormer: Anomaly detection of time series with
parallel-attention transformer. <em>TNNLS</em>, <em>36</em>(2),
3315–3328. (<a
href="https://doi.org/10.1109/TNNLS.2023.3337876">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time-series anomaly detection is a critical task with significant impact as it serves a pivotal role in the field of data mining and quality management. Current anomaly detection methods are typically based on reconstruction or forecasting algorithms, as these methods have the capability to learn compressed data representations and model time dependencies. However, most methods rely on learning normal distribution patterns, which can be difficult to achieve in real-world engineering applications. Furthermore, real-world time-series data is highly imbalanced, with a severe lack of representative samples for anomalous data, which can lead to model learning failure. In this article, we propose a novel end-to-end unsupervised framework called the parallel-attention transformer (PAFormer), which discriminates anomalies by modeling both the global characteristics and local patterns of time series. Specifically, we construct parallel-attention (PA), which includes two core modules: the global enhanced representation module (GERM) and the local perception module (LPM). GERM consists of two pattern units and a normalization module, with attention weights that indicate the relationship of each data point to the whole series (global). Due to the rarity of anomalous points, they have strong associations with adjacent data points. LPM is composed of a learnable Laplace kernel function that learns the neighborhood relevancies through the distributional properties of the kernel function (local). We employ the PA to learn the global-local distributional differences for each data point, which enables us to discriminate anomalies. Finally, we propose a two-stage adversarial loss to optimize the model. We conduct experiments on five public benchmark datasets (real-world datasets) and one synthetic dataset. The results show that PAFormer outperforms state-of-the-art baselines.},
  archive      = {J_TNNLS},
  author       = {Ningning Bai and Xiaofeng Wang and Ruidong Han and Qin Wang and Zinian Liu},
  doi          = {10.1109/TNNLS.2023.3337876},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3315-3328},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {PAFormer: Anomaly detection of time series with parallel-attention transformer},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tuned compositional feature replays for efficient stream
learning. <em>TNNLS</em>, <em>36</em>(2), 3300–3314. (<a
href="https://doi.org/10.1109/TNNLS.2023.3344085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Our brains extract durable, generalizable knowledge from transient experiences of the world. Artificial neural networks come nowhere close to this ability. When tasked with learning to classify objects by training on nonrepeating video frames in temporal order (online stream learning), models that learn well from shuffled datasets catastrophically forget old knowledge upon learning new stimuli. We propose a new continual learning algorithm, compositional replay using memory blocks (CRUMB), which mitigates forgetting by replaying feature maps reconstructed by combining generic parts. CRUMB concatenates trainable and reusable “memory block” vectors to compositionally reconstruct feature map tensors in convolutional neural networks (CNNs). Storing the indices of memory blocks used to reconstruct new stimuli enables memories of the stimuli to be replayed during later tasks. This reconstruction mechanism also primes the neural network to minimize catastrophic forgetting by biasing it toward attending to information about object shapes more than information about image textures and stabilizes the network during stream learning by providing a shared feature-level basis for all training examples. These properties allow CRUMB to outperform an otherwise identical algorithm that stores and replays raw images while occupying only 3.6% as much memory. We stress-tested CRUMB alongside 13 competing methods on seven challenging datasets. To address the limited number of existing online stream learning datasets, we introduce two new benchmarks by adapting existing datasets for stream learning. With only 3.7%–4.1% as much memory and 15%–43% as much runtime, CRUMB mitigates catastrophic forgetting more effectively than the state-of-the-art. Our code is available at https://github.com/MorganBDT/crumb.git},
  archive      = {J_TNNLS},
  author       = {Morgan B. Talbot and Rushikesh Zawar and Rohil Badkundri and Mengmi Zhang and Gabriel Kreiman},
  doi          = {10.1109/TNNLS.2023.3344085},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3300-3314},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Tuned compositional feature replays for efficient stream learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EVAE: Evolutionary variational autoencoder. <em>TNNLS</em>,
<em>36</em>(2), 3288–3299. (<a
href="https://doi.org/10.1109/TNNLS.2024.3359275">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Variational autoencoders (VAEs) are challenged by the imbalance between representation inference and task fitting caused by surrogate loss. To address this issue, existing methods adjust their balance by directly tuning their coefficients. However, these methods suffer from a tradeoff uncertainty, i.e., nondynamic regulation over iterations and inflexible hyperparameters for learning tasks. Accordingly, we make the first attempt to introduce an evolutionary VAE (eVAE), building on the variational information bottleneck (VIB) theory and integrative evolutionary neural learning. eVAE integrates a variational genetic algorithm (VGA) into VAE with variational evolutionary operators, including variational mutation (V-mutation), crossover, and evolution. Its training mechanism synergistically and dynamically addresses and updates the learning tradeoff uncertainty in the evidence lower bound (ELBO) without additional constraints and hyperparameter tuning. Furthermore, eVAE presents an evolutionary paradigm to tune critical factors of VAEs and addresses the premature convergence and random search problem in integrating evolutionary optimization into deep learning. Experiments show that eVAE addresses the KL-vanishing problem for text generation with low reconstruction loss, generates all the disentangled factors with sharp images, and improves image generation quality. eVAE achieves better disentanglement, generation performance, and generation–inference balance than its competitors. Code available at: https://github.com/amasawa/eVAE.},
  archive      = {J_TNNLS},
  author       = {Zhangkai Wu and Longbing Cao and Lei Qi},
  doi          = {10.1109/TNNLS.2024.3359275},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3288-3299},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {EVAE: Evolutionary variational autoencoder},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Active learning for handling missing data. <em>TNNLS</em>,
<em>36</em>(2), 3273–3287. (<a
href="https://doi.org/10.1109/TNNLS.2024.3352279">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the massive growth of IoT devices and Internet data, which are widely used in many applications, including industry and healthcare, has dramatically increased the amount of free unlabeled data collected. However, this unlabeled data is useless if we want to learn supervised machine learning models. The expensive and time-consuming cost of labeling makes the problem even more challenging. Here, the active learning (AL) technique provides a solution by labeling small but highly informative and representative data, which guarantees a high degree of generalizability over space and improves classification performance with data we have never seen before. The task is more difficult when the active learner has no predefined knowledge, such as initial training data, and when the obtained data is incomplete (i.e., contains missing values). In previous studies, the missing data should first be imputed. Then, the active learner selects from the available unlabeled data, regardless of whether the points were originally observed or imputed. However, selecting inaccurate imputed data points would negatively affect the active learner and prevent it from selecting informative and/or representative points, thus reducing the overall classification performance of the prediction models. This motivated us to introduce a novel query selection strategy that accounts for imputation uncertainty when querying new points. For this purpose, we first introduce a novel multiple imputation method that considers feature importance in selecting the most promising feature groups for missing value estimation. This multiple imputation method provides the ability to quantify the imputation uncertainty of each imputed data point. Furthermore, in each of the two phases of the proposed active learner (exploration and exploitation), imputation uncertainty is taken into account to reduce the probability of selecting points with high imputation uncertainty. We tested the effectiveness of the proposed active learner on different binary and multiclass datasets with different missing rates.},
  archive      = {J_TNNLS},
  author       = {Alaa Tharwat and Wolfram Schenck},
  doi          = {10.1109/TNNLS.2024.3352279},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3273-3287},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Active learning for handling missing data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DVSRNet: Deep video super-resolution based on progressive
deformable alignment and temporal-sparse enhancement. <em>TNNLS</em>,
<em>36</em>(2), 3258–3272. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347450">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video super-resolution (VSR) is used to compose high-resolution (HR) video from low-resolution video. Recently, the deformable alignment-based VSR methods are becoming increasingly popular. In these methods, the features extracted from video are aligned to eliminate the motion error targeting high super-resolution (SR) quality. However, these methods often suffer from misalignment and the lack of enough temporal information to compose HR frames, which accordingly induce artifacts in the SR result. In this article, we design a deep VSR network (DVSRNet) based on the proposed progressive deformable alignment (PDA) module and temporal-sparse enhancement (TSE) module. Specifically, the PDA module is designed to accurately align features and to eliminate artifacts via the bidirectional information propagation. The TSE module is constructed to further eliminate artifacts and to generate clear details for the HR frame. In addition, we construct a lightweight deep optical flow network (OFNet) to obtain the bidirectional optical flows for the implementation of the PDA module. Moreover, two new loss functions are designed for our proposed method. The first one is adopted in OFNet and the second one is constructed to guarantee the generation of sharp and clear details for the HR frames. The experimental results demonstrate that our method performs better than the state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Qiang Zhu and Feiyu Chen and Shuyuan Zhu and Yu Liu and Xue Zhou and Ruiqin Xiong and Bing Zeng},
  doi          = {10.1109/TNNLS.2023.3347450},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3258-3272},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {DVSRNet: Deep video super-resolution based on progressive deformable alignment and temporal-sparse enhancement},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revisiting initializing then refining: An incomplete and
missing graph imputation network. <em>TNNLS</em>, <em>36</em>(2),
3244–3257. (<a
href="https://doi.org/10.1109/TNNLS.2024.3349850">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the development of various applications, such as recommendation systems and social network analysis, graph data have been ubiquitous in the real world. However, graphs usually suffer from being absent during data collection due to copyright restrictions or privacy-protecting policies. The graph absence could be roughly grouped into attribute-incomplete and attribute-missing cases. Specifically, attribute-incomplete indicates that a portion of the attribute vectors of all nodes are incomplete, while attribute-missing indicates that all attribute vectors of partial nodes are missing. Although various graph imputation methods have been proposed, none of them is custom-designed for a common situation where both types of graph absence exist simultaneously. To fill this gap, we develop a novel graph imputation network termed revisiting initializing then refining (RITR), where both attribute-incomplete and attribute-missing samples are completed under the guidance of a novel initializing-then-refining imputation criterion. Specifically, to complete attribute-incomplete samples, we first initialize the incomplete attributes using Gaussian noise before network learning, and then introduce a structure-attribute consistency constraint to refine incomplete values by approximating a structure-attribute correlation matrix to a high-order structure matrix. To complete attribute-missing samples, we first adopt structure embeddings of attribute-missing samples as the embedding initialization, and then refine these initial values by adaptively aggregating the reliable information of attribute-incomplete samples according to a dynamic affinity structure. To the best of our knowledge, this newly designed method is the first end-to-end unsupervised framework dedicated to handling hybrid-absent graphs. Extensive experiments on six datasets have verified that our methods consistently outperform the existing state-of-the-art competitors. Our source code is available at https://github.com/WxTu/RITR.},
  archive      = {J_TNNLS},
  author       = {Wenxuan Tu and Bin Xiao and Xinwang Liu and Sihang Zhou and Zhiping Cai and Jieren Cheng},
  doi          = {10.1109/TNNLS.2024.3349850},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3244-3257},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Revisiting initializing then refining: An incomplete and missing graph imputation network},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A unified and biologically plausible relational graph
representation of vision transformers. <em>TNNLS</em>, <em>36</em>(2),
3231–3243. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Vision transformer (ViT) and its variants have achieved remarkable success in various tasks. The key characteristic of these ViT models is to adopt different aggregation strategies of spatial patch information within the artificial neural networks (ANNs). However, there is still a key lack of unified representation of different ViT architectures for systematic understanding and assessment of model representation performance. Moreover, how those well-performing ViT ANNs are similar to real biological neural networks (BNNs) is largely unexplored. To answer these fundamental questions, we, for the first time, propose a unified and biologically plausible relational graph representation of ViT models. Specifically, the proposed relational graph representation consists of two key subgraphs: an aggregation graph and an affine graph. The former considers ViT tokens as nodes and describes their spatial interaction, while the latter regards network channels as nodes and reflects the information communication between channels. Using this unified relational graph representation, we found that: 1) model performance was closely related to graph measures; 2) the proposed relational graph representation of ViT has high similarity with real BNNs; and 3) there was a further improvement in model performance when training with a superior model to constrain the aggregation graph.},
  archive      = {J_TNNLS},
  author       = {Yuzhong Chen and Zhenxiang Xiao and Yu Du and Lin Zhao and Lu Zhang and Zihao Wu and Dajiang Zhu and Tuo Zhang and Dezhong Yao and Xintao Hu and Tianming Liu and Xi Jiang},
  doi          = {10.1109/TNNLS.2023.3342810},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3231-3243},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A unified and biologically plausible relational graph representation of vision transformers},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Subgraph propagation and contrastive calibration for
incomplete multiview data clustering. <em>TNNLS</em>, <em>36</em>(2),
3218–3230. (<a
href="https://doi.org/10.1109/TNNLS.2024.3350671">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The success of multiview raw data mining relies on the integrity of attributes. However, each view faces various noises and collection failures, which leads to a condition that attributes are only partially available. To make matters worse, the attributes in multiview raw data are composed of multiple forms, which makes it more difficult to explore the structure of the data especially in multiview clustering task. Due to the missing data in some views, the clustering task on incomplete multiview data confronts the following challenges, namely: 1) mining the topology of missing data in multiview is an urgent problem to be solved; 2) most approaches do not calibrate the complemented representations with common information of multiple views; and 3) we discover that the cluster distributions obtained from incomplete views have a cluster distribution unaligned problem (CDUP) in the latent space. To solve the above issues, we propose a deep clustering framework based on subgraph propagation and contrastive calibration (SPCC) for incomplete multiview raw data. First, the global structural graph is reconstructed by propagating the subgraphs generated by the complete data of each view. Then, the missing views are completed and calibrated under the guidance of the global structural graph and contrast learning between views. In the latent space, we assume that different views have a common cluster representation in the same dimension. However, in the unsupervised condition, the fact that the cluster distributions of different views do not correspond affects the information completion process to use information from other views. Finally, the complemented cluster distributions for different views are aligned by contrastive learning (CL), thus solving the CDUP in the latent space. Our method achieves advanced performance on six benchmarks, which validates the effectiveness and superiority of our SPCC.},
  archive      = {J_TNNLS},
  author       = {Zhibin Dong and Jiaqi Jin and Yuyang Xiao and Bin Xiao and Siwei Wang and Xinwang Liu and En Zhu},
  doi          = {10.1109/TNNLS.2024.3350671},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3218-3230},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Subgraph propagation and contrastive calibration for incomplete multiview data clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated discriminative representation learning for image
classification. <em>TNNLS</em>, <em>36</em>(2), 3204–3217. (<a
href="https://doi.org/10.1109/TNNLS.2023.3336957">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Acquiring big-size datasets to raise the performance of deep models has become one of the most critical problems in representation learning (RL) techniques, which is the core potential of the emerging paradigm of federated learning (FL). However, most current FL models concentrate on seeking an identical model for isolated clients and thus fail to make full use of the data specificity between clients. To enhance the classification performance of each client, this study introduces the FDRL, a federated discriminative RL model, by partitioning the data features of each client into a global subspace and a local subspace. More specifically, FDRL learns the global representation for federated communication between those isolated clients, which is to capture common features from all protected datasets via model sharing, and local representations for personalization in each client, which is to preserve specific features of clients via model differentiating. Toward this goal, FDRL in each client trains a shared submodel for federated communication and, meanwhile, a not-shared submodel for locality preservation, in which the two models partition client-feature space by maximizing their differences, followed by a linear model fed with combined features for image classification. The proposed model is implemented with neural networks and optimized in an iterative manner between the server of computing the global model and the clients of learning the local classifiers. Thanks to the powerful capability of local feature preservation, FDRL leads to more discriminative data representations than the compared FL models. Experimental results on public datasets demonstrate that our FDRL benefits from the subspace partition and achieves better performance on federated image classification than the state-of-the-art FL models.},
  archive      = {J_TNNLS},
  author       = {Yupei Zhang and Yifei Wang and Yuxin Li and Yunan Xu and Shuangshuang Wei and Shuhui Liu and Xuequn Shang},
  doi          = {10.1109/TNNLS.2023.3336957},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3204-3217},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Federated discriminative representation learning for image classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward high-accuracy and low-latency spiking neural networks
with two-stage optimization. <em>TNNLS</em>, <em>36</em>(2), 3189–3203.
(<a href="https://doi.org/10.1109/TNNLS.2023.3337176">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) operating with asynchronous discrete events show higher energy efficiency with sparse computation. A popular approach for implementing deep SNNs is artificial neural network (ANN)–SNN conversion combining both efficient training of ANNs and efficient inference of SNNs. However, the accuracy loss is usually nonnegligible, especially under few time steps, which restricts the applications of SNN on latency-sensitive edge devices greatly. In this article, we first identify that such performance degradation stems from the misrepresentation of the negative or overflow residual membrane potential in SNNs. Inspired by this, we decompose the conversion error into three parts: quantization error, clipping error, and residual membrane potential representation error. With such insights, we propose a two-stage conversion algorithm to minimize those errors, respectively. In addition, we show that each stage achieves significant performance gains in a complementary manner. By evaluating on challenging datasets including CIFAR- 10, CIFAR- 100, and ImageNet, the proposed method demonstrates the state-of-the-art performance in terms of accuracy, latency, and energy preservation. Furthermore, our method is evaluated using a more challenging object detection task, revealing notable gains in regression performance under ultralow latency, when compared with existing spike-based detection algorithms. Codes will be available at: https://github.com/Windere/snn-cvt-dual-phase.},
  archive      = {J_TNNLS},
  author       = {Ziming Wang and Yuhao Zhang and Shuang Lian and Xiaoxin Cui and Rui Yan and Huajin Tang},
  doi          = {10.1109/TNNLS.2023.3337176},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3189-3203},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward high-accuracy and low-latency spiking neural networks with two-stage optimization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EM-trans: Edge-aware multimodal transformer for RGB-d
salient object detection. <em>TNNLS</em>, <em>36</em>(2), 3175–3188. (<a
href="https://doi.org/10.1109/TNNLS.2024.3358858">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {RGB-D salient object detection (SOD) has gained tremendous attention in recent years. In particular, transformer has been employed and shown great potential. However, existing transformer models usually overlook the vital edge information, which is a major issue restricting the further improvement of SOD accuracy. To this end, we propose a novel edge-aware RGB-D SOD transformer, called EM-Trans, which explicitly models the edge information in a dual-band decomposition framework. Specifically, we employ two parallel decoder networks to learn the high-frequency edge and low-frequency body features from the low- and high-level features extracted from a two-steam multimodal backbone network, respectively. Next, we propose a cross-attention complementarity exploration module to enrich the edge/body features by exploiting the multimodal complementarity information. The refined features are then fed into our proposed color-hint guided fusion module for enhancing the depth feature and fusing the multimodal features. Finally, the resulting features are fused using our deeply supervised progressive fusion module, which progressively integrates edge and body features for predicting saliency maps. Our model explicitly considers the edge information for accurate RGB-D SOD, overcoming the limitations of existing methods and effectively improving the performance. Extensive experiments on benchmark datasets demonstrate that EM-Trans is an effective RGB-D SOD framework that outperforms the current state-of-the-art models, both quantitatively and qualitatively. A further extension to RGB-T SOD demonstrates the promising potential of our model in various kinds of multimodal SOD tasks.},
  archive      = {J_TNNLS},
  author       = {Geng Chen and Qingyue Wang and Bo Dong and Ruitao Ma and Nian Liu and Huazhu Fu and Yong Xia},
  doi          = {10.1109/TNNLS.2024.3358858},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3175-3188},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {EM-trans: Edge-aware multimodal transformer for RGB-D salient object detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intralayer synchronization and interlayer
quasisynchronization in multiplex networks of nonidentical layers.
<em>TNNLS</em>, <em>36</em>(2), 3165–3174. (<a
href="https://doi.org/10.1109/TNNLS.2023.3326629">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we discuss synchronization in multiplex networks of different layers. Both the topologies and the uncoupled node dynamics in different layers are different. Novel sufficient criteria are derived for intralayer synchronization and interlayer quasisynchronization, in terms of the coupling matrices, the coupling strengths, and the intrinsic function of the uncoupled systems. We also investigate interlayer synchronization of multiplex networks with identical uncoupled node dynamics. Finally, we give some numerical examples to validate the effectiveness of these theoretical results.},
  archive      = {J_TNNLS},
  author       = {Yujuan Han and Wenlian Lu and Tianping Chen},
  doi          = {10.1109/TNNLS.2023.3326629},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3165-3174},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Intralayer synchronization and interlayer quasisynchronization in multiplex networks of nonidentical layers},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Factorization vision transformer: Modeling long-range
dependency with local window cost. <em>TNNLS</em>, <em>36</em>(2),
3151–3164. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342172">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transformers have astounding representational power but typically consume considerable computation which is quadratic with image resolution. The prevailing Swin transformer reduces computational costs through a local window strategy. However, this strategy inevitably causes two drawbacks: 1) the local window-based self-attention (WSA) hinders global dependency modeling capability and 2) recent studies point out that local windows impair robustness. To overcome these challenges, we pursue a preferable trade-off between computational cost and performance. Accordingly, we propose a novel factorization self-attention (FaSA) mechanism that enjoys both the advantages of local window cost and long-range dependency modeling capability. By factorizing the conventional attention matrix into sparse subattention matrices, FaSA captures long-range dependencies, while aggregating mixed-grained information at a computational cost equivalent to the local WSA. Leveraging FaSA, we present the factorization vision transformer (FaViT) with a hierarchical structure. FaViT achieves high performance and robustness, with linear computational complexity concerning input image spatial resolution. Extensive experiments have shown FaViT’s advanced performance in classification and downstream tasks. Furthermore, it also exhibits strong model robustness to corrupted and biased data and hence demonstrates benefits in favor of practical applications. In comparison to the baseline model Swin-T, our FaViT-B2 significantly improves classification accuracy by 1% and robustness by 7%, while reducing model parameters by 14%. Our code will soon be publicly available: at https://github.com/q2479036243/FaViT.},
  archive      = {J_TNNLS},
  author       = {Haolin Qin and Daquan Zhou and Tingfa Xu and Ziyang Bian and Jianan Li},
  doi          = {10.1109/TNNLS.2023.3342172},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3151-3164},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Factorization vision transformer: Modeling long-range dependency with local window cost},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hypernetwork-based physics-driven personalized federated
learning for CT imaging. <em>TNNLS</em>, <em>36</em>(2), 3136–3150. (<a
href="https://doi.org/10.1109/TNNLS.2023.3338867">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In clinical practice, computed tomography (CT) is an important noninvasive inspection technology to provide patients’ anatomical information. However, its potential radiation risk is an unavoidable problem that raises people’s concerns. Recently, deep learning (DL)-based methods have achieved promising results in CT reconstruction, but these methods usually require the centralized collection of large amounts of data for training from specific scanning protocols, which leads to serious domain shift and privacy concerns. To relieve these problems, in this article, we propose a hypernetwork-based physics-driven personalized federated learning method (HyperFed) for CT imaging. The basic assumption of the proposed HyperFed is that the optimization problem for each domain can be divided into two subproblems: local data adaption and global CT imaging problems, which are implemented by an institution-specific physics-driven hypernetwork and a global-sharing imaging network, respectively. Learning stable and effective invariant features from different data distributions is the main purpose of global-sharing imaging network. Inspired by the physical process of CT imaging, we carefully design physics-driven hypernetwork for each domain to obtain hyperparameters from specific physical scanning protocol to condition the global-sharing imaging network, so that we can achieve personalized local CT reconstruction. Experiments show that HyperFed achieves competitive performance in comparison with several other state-of-the-art methods. It is believed as a promising direction to improve CT imaging quality and personalize the needs of different institutions or scanners without data sharing. Related codes have been released at https://github.com/Zi-YuanYang/HyperFed.},
  archive      = {J_TNNLS},
  author       = {Ziyuan Yang and Wenjun Xia and Zexin Lu and Yingyu Chen and Xiaoxiao Li and Yi Zhang},
  doi          = {10.1109/TNNLS.2023.3338867},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3136-3150},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hypernetwork-based physics-driven personalized federated learning for CT imaging},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distributed adaptive flocking control for large-scale
multiagent systems. <em>TNNLS</em>, <em>36</em>(2), 3126–3135. (<a
href="https://doi.org/10.1109/TNNLS.2023.3343666">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel distributed flocking control method for large-scale multiagent systems (LS-MASs) operating in uncertain environments. When dealing with a massive number of flocking agents in uncertain environments, existing flocking methods encounter the problem of communication complexity and “Curse of dimensionality” caused by the exponential growth of agent interactions while solving PDE-based optimal flocking control for large-scale systems. The mean field game (MFG) method addresses this issue by transforming interactions among all agents into the interaction of each individual agent with average effects represented by a probability density function (pdf) of other agents. However, relying solely on a pdf term to consider other agents’ states can result in inefficient flocking performance due to the absence of a proficient coordination mechanism encompassing all agents involved in flocking. To overcome these difficulties and achieve the desired flocking performance for LS-MASs, the agents are decomposed into a finite number of subgroups. Each subgroup comprises a leader and followers, and a hybrid game theory is developed to manage both inter- and intragroup interactions. The method incorporates a cooperative game that links leaders from different groups to formulate distributed flocking control, a Stackelberg game that teams up leaders and followers within the same group to extend collective flocking behavior, and an MFG for followers to address the challenges of LS-MASs. Furthermore, to achieve distributed adaptive flocking using the hybrid game structure, we propose a hierarchical actor–critic-mass-based reinforcement learning technique. This approach incorporates a multiactor–critic method for leaders and an actor–critic-mass algorithm for followers, enabling adaptive flocking control in a distributed manner for large-scale agents. Finally, numerical simulation including comparison study and Lyapunov analysis demonstrates the effectiveness of the developed method.},
  archive      = {J_TNNLS},
  author       = {Shawon Dey and Hao Xu},
  doi          = {10.1109/TNNLS.2023.3343666},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3126-3135},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Distributed adaptive flocking control for large-scale multiagent systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MG-SIN: Multigraph sparse interaction network for multitask
stance detection. <em>TNNLS</em>, <em>36</em>(2), 3111–3125. (<a
href="https://doi.org/10.1109/TNNLS.2023.3328659">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stance detection on social media aims to identify if an individual is in support of or against a specific target. Most existing stance detection approaches primarily rely on modeling the contextual semantic information in sentences and neglect to explore the pragmatics dependency information of words, thus degrading performance. Although several single-task learning methods have been proposed to capture richer semantic representation information, they still suffer from semantic sparsity problems caused by short texts on social media. This article proposes a novel multigraph sparse interaction network (MG-SIN) by using multitask learning (MTL) to identify the stances and classify the sentiment polarities of tweets simultaneously. Our basic idea is to explore the pragmatics dependency relationship between tasks at the word level by constructing two types of heterogeneous graphs, including task-specific and task-related graphs (tr-graphs), to boost the learning of task-specific representations. A graph-aware module is proposed to adaptively facilitate information sharing between tasks via a novel sparse interaction mechanism among heterogeneous graphs. Through experiments on two real-world datasets, compared with the state-of-the-art baselines, the extensive results exhibit that MG-SIN achieves competitive improvements of up to 2.1% and 2.42% for the stance detection task, and 5.26% and 3.93% for the sentiment analysis task, respectively.},
  archive      = {J_TNNLS},
  author       = {Heyan Chai and Jinhao Cui and Siyu Tang and Ye Ding and Xinwang Liu and Binxing Fang and Qing Liao},
  doi          = {10.1109/TNNLS.2023.3328659},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3111-3125},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MG-SIN: Multigraph sparse interaction network for multitask stance detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CORE: CORrelation-guided feature enhancement for few-shot
image classification. <em>TNNLS</em>, <em>36</em>(2), 3098–3110. (<a
href="https://doi.org/10.1109/TNNLS.2024.3355774">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot classification aims to adapt classifiers trained on base classes to novel classes with a few shots. However, the limited amount of training data is often inadequate to represent the intraclass variations in novel classes. This can result in biased estimation of the feature distribution, which in turn results in inaccurate decision boundaries, especially when the support data are outliers. To address this issue, we propose a feature enhancement method called CORrelation-guided feature Enrichment that generates improved features for novel classes using weak supervision from the base classes. The proposed CORrelation-guided feature Enhancement (CORE) method utilizes an autoencoder (AE) architecture but incorporates classification information into its latent space. This design allows the CORE to generate more discriminative features while discarding irrelevant content information. After being trained on base classes, CORE’s generative ability can be transferred to novel classes that are similar to those in the base classes. By using these generative features, we can reduce the estimation bias of the class distribution, which makes few-shot learning (FSL) less sensitive to the selection of support data. Our method is generic and flexible and can be used with any feature extractor and classifier. It can be easily integrated into existing FSL approaches. Experiments with different backbones and classifiers show that our proposed method consistently outperforms existing methods on various widely used benchmarks.},
  archive      = {J_TNNLS},
  author       = {Jing Xu and Xinglin Pan and Jingquan Wang and Wenjie Pei and Qing Liao and Zenglin Xu},
  doi          = {10.1109/TNNLS.2024.3355774},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3098-3110},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CORE: CORrelation-guided feature enhancement for few-shot image classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-constructing chebyshev fuzzy neural complementary
sliding mode control and its application. <em>TNNLS</em>,
<em>36</em>(2), 3084–3097. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a complementary sliding mode (CSM) controller using a self-constructing Chebyshev fuzzy recurrent neural network (SCCFRNN) is proposed for harmonic suppression control of an active power filter (APF). The SCCFRNN whose structure can be automatically learned through the designed structure self-learning algorithm is introduced to approximate the unknown nonlinear term in the APF dynamic model, so as to improve modeling accuracy and reduce the burden of CSM control (CSMC). The SCCFRNN combines the advantages of a fuzzy neural network (FNN), recurrent neural network (RNN), and Chebyshev neural network (CNN), and all parameters can be adjusted according to the designed adaptive laws. Eventually, through detailed simulation, hardware experiments, and fair comparison, the feasibility and superiority of the proposed control algorithm were verified.},
  archive      = {J_TNNLS},
  author       = {Juntao Fei and Lei Zhang and Yunmei Fang},
  doi          = {10.1109/TNNLS.2023.3347767},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3084-3097},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Self-constructing chebyshev fuzzy neural complementary sliding mode control and its application},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SOSNet: Real-time small object segmentation via hierarchical
decoding and example mining. <em>TNNLS</em>, <em>36</em>(2), 3071–3083.
(<a href="https://doi.org/10.1109/TNNLS.2023.3338732">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-time semantic segmentation plays an important role in auto vehicles. However, most real-time small object segmentation methods fail to obtain satisfactory performance on small objects, such as cars and sign symbols, since the large objects usually tend to devote more to the segmentation result. To solve this issue, we propose an efficient and effective architecture, termed small objects segmentation network (SOSNet), to improve the segmentation performance of small objects. The SOSNet works from two perspectives: methodology and data. Specifically, with the former, we propose a dual-branch hierarchical decoder (DBHD) which is viewed as a small-object sensitive segmentation head. The DBHD consists of a top segmentation head that predicts whether the pixels belong to a small object class and a bottom one that estimates the pixel class. In this situation, the latent correlation among small objects can be fully explored. With the latter, we propose a small object example mining (SOEM) algorithm for balancing examples between small objects and large objects automatically. The core idea of the proposed SOEM is that most of the hard examples on small-object classes are reserved for training while most of the easy examples on large-object classes are banned. Experiments on three commonly used datasets show that the proposed SOSNet architecture greatly improves the accuracy compared to the existing real-time semantic segmentation methods while keeping efficiency. The code will be available at https://github.com/StuLiu/SOSNet.},
  archive      = {J_TNNLS},
  author       = {Wang Liu and Xudong Kang and Puhong Duan and Zhuojun Xie and Xiaohui Wei and Shutao Li},
  doi          = {10.1109/TNNLS.2023.3338732},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3071-3083},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SOSNet: Real-time small object segmentation via hierarchical decoding and example mining},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiprior learning via neural architecture search for blind
face restoration. <em>TNNLS</em>, <em>36</em>(2), 3057–3070. (<a
href="https://doi.org/10.1109/TNNLS.2023.3339614">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Blind face restoration (BFR) aims to recover high-quality (HQ) face images from low-quality (LQ) ones and usually resorts to facial priors for improving restoration performance. However, current methods still suffer from two major difficulties: 1) how to derive a powerful network architecture without extensive hand tuning and 2) how to capture complementary information from multiple facial priors in one network to improve restoration performance. To this end, we propose a face restoration searching network (FRSNet) to adaptively search the suitable feature extraction architecture within our specified search space, which can directly contribute to the restoration quality. On the basis of FRSNet, we further design our multiple facial prior searching network (MFPSNet) with a multiprior learning scheme. MFPSNet optimally extracts information from diverse facial priors and fuses the information into image features, ensuring that both external guidance and internal features are reserved. In this way, MFPSNet takes full advantage of semantic-level (parsing maps), geometric-level (facial heat maps), reference-level (facial dictionaries), and pixel-level (degraded images) information and, thus, generates faithful and realistic images. Quantitative and qualitative experiments show that the MFPSNet performs favorably on both synthetic and real-world datasets against the state-of-the-art (SOTA) BFR methods. The codes are publicly available at: https://github.com/YYJ1anG/MFPSNet.},
  archive      = {J_TNNLS},
  author       = {Yanjiang Yu and Puyang Zhang and Kaihao Zhang and Wenhan Luo and Changsheng Li},
  doi          = {10.1109/TNNLS.2023.3339614},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3057-3070},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiprior learning via neural architecture search for blind face restoration},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Allosteric feature collaboration for model-heterogeneous
federated learning. <em>TNNLS</em>, <em>36</em>(2), 3042–3056. (<a
href="https://doi.org/10.1109/TNNLS.2023.3344084">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Although federated learning (FL) has achieved outstanding results in privacy-preserved distributed learning, the setting of model homogeneity among clients restricts its wide application in practice. This article investigates a more general case, namely, model-heterogeneous FL (M-hete FL), where client models are independently designed and can be structurally heterogeneous. M-hete FL faces new challenges in collaborative learning because the parameters of heterogeneous models could not be directly aggregated. In this article, we propose a novel allosteric feature collaboration (AlFeCo) method, which interchanges knowledge across clients and collaboratively updates heterogeneous models on the server. Specifically, an allosteric feature generator is developed to reveal task-relevant information from multiple client models. The revealed information is stored in the client-shared and client-specific codes. We exchange client-specific codes across clients to facilitate knowledge interchange and generate allosteric features that are dimensionally variable for model updates. To promote information communication between different clients, a dual-path (model–model and model–prediction) communication mechanism is designed to supervise the collaborative model updates using the allosteric features. Client models are fully communicated through the knowledge interchange between models and between models and predictions. We further provide theoretical evidence and convergence analysis to support the effectiveness of AlFeCo in M-hete FL. The experimental results show that the proposed AlFeCo method not only performs well on classical FL benchmarks but also is effective in model-heterogeneous federated antispoofing. Our codes are publicly available at https://github.com/ybaoyao/AlFeCo.},
  archive      = {J_TNNLS},
  author       = {Baoyao Yang and Pong C. Yuen and Yiqun Zhang and An Zeng},
  doi          = {10.1109/TNNLS.2023.3344084},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3042-3056},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Allosteric feature collaboration for model-heterogeneous federated learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ViT-MVT: A unified vision transformer network for multiple
vision tasks. <em>TNNLS</em>, <em>36</em>(2), 3027–3041. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342141">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we seek to learn multiple mainstream vision tasks concurrently using a unified network, which is storage-efficient as numerous networks with task-shared parameters can be implanted into a single consolidated network. Our framework, vision transformer (ViT)-MVT, built on a plain and nonhierarchical ViT, incorporates numerous visual tasks into a modest supernet and optimizes them jointly across various dataset domains. For the design of ViT-MVT, we augment the ViT with a multihead self-attention (MHSE) to offer complementary cues in the channel and spatial dimension, as well as a local perception unit (LPU) and locality feed-forward network (locality FFN) for information exchange in the local region, thus endowing ViT-MVT with the ability to effectively optimize multiple tasks. Besides, we construct a search space comprising potential architectures with a broad spectrum of model sizes to offer various optimum candidates for diverse tasks. After that, we design a layer-adaptive sharing technique that automatically determines whether each layer of the transformer block is shared or not for all tasks, enabling ViT-MVT to obtain task-shared parameters for a reduction of storage and task-specific parameters to learn task-related features such that boosting performance. Finally, we introduce a joint-task evolutionary search algorithm to discover an optimal backbone for all tasks under total model size constraint, which challenges the conventional wisdom that visual tasks are typically supplied with backbone networks developed for image classification. Extensive experiments reveal that ViT-MVT delivers exceptional performances for multiple visual tasks over state-of-the-art methods while necessitating considerably fewer total storage costs. We further demonstrate that once ViT-MVT has been trained, ViT-MVT is capable of incremental learning when generalized to new tasks while retaining identical performances for trained tasks. The code is available at https://github.com/XT-1997/vitmvt.},
  archive      = {J_TNNLS},
  author       = {Tao Xie and Kun Dai and Zhiqiang Jiang and Ruifeng Li and Shouren Mao and Ke Wang and Lijun Zhao},
  doi          = {10.1109/TNNLS.2023.3342141},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3027-3041},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {ViT-MVT: A unified vision transformer network for multiple vision tasks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Masked spatial–spectral autoencoders are excellent
hyperspectral defenders. <em>TNNLS</em>, <em>36</em>(2), 3012–3026. (<a
href="https://doi.org/10.1109/TNNLS.2023.3345734">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) methodology contributes a lot to the development of hyperspectral image (HSI) analysis community. However, it also makes HSI analysis systems vulnerable to adversarial attacks. To this end, we propose a masked spatial–spectral autoencoder (MSSA) in this article under self-supervised learning theory, for enhancing the robustness of HSI analysis systems. First, a masked sequence attention learning (MSAL) module is conducted to promote the inherent robustness of HSI analysis systems along spectral channel. Then, we develop a graph convolutional network (GCN) with learnable graph structure to establish global pixel-wise combinations. In this way, the attack effect would be dispersed by all the related pixels among each combination, and a better defense performance is achievable in spatial aspect. Finally, to improve the defense transferability and address the problem of limited labeled samples, MSSA employs spectra reconstruction as a pretext task and fits the datasets in a self-supervised manner. Comprehensive experiments over three benchmarks verify the effectiveness of MSSA in comparison with the state-of-the-art hyperspectral classification methods and representative adversarial defense strategies.},
  archive      = {J_TNNLS},
  author       = {Jiahao Qi and Zhiqiang Gong and Xingyue Liu and Chen Chen and Ping Zhong},
  doi          = {10.1109/TNNLS.2023.3345734},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {3012-3026},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Masked Spatial–Spectral autoencoders are excellent hyperspectral defenders},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hyperspectral image super resolution with real unaligned RGB
guidance. <em>TNNLS</em>, <em>36</em>(2), 2999–3011. (<a
href="https://doi.org/10.1109/TNNLS.2023.3340561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fusion-based hyperspectral image (HSI) super-resolution has become increasingly prevalent for its capability to integrate high-frequency spatial information from the paired high-resolution (HR) RGB reference (Ref-RGB) image. However, most of the existing methods either heavily rely on the accurate alignment between low-resolution (LR) HSIs and RGB images or can only deal with simulated unaligned RGB images generated by rigid geometric transformations, which weakens their effectiveness for real scenes. In this article, we explore the fusion-based HSI super-resolution with real Ref-RGB images that have both rigid and nonrigid misalignments. To properly address the limitations of existing methods for unaligned reference images, we propose an HSI fusion network (HSIFN) with heterogeneous feature extractions, multistage feature alignments, and attentive feature fusion. Specifically, our network first transforms the input HSI and RGB images into two sets of multiscale features with an HSI encoder and an RGB encoder, respectively. The features of Ref-RGB images are then processed by a multistage alignment module to explicitly align the features of Ref-RGB with the LR HSI. Finally, the aligned features of Ref-RGB are further adjusted by an adaptive attention module to focus more on discriminative regions before sending them to the fusion decoder to generate the reconstructed HR HSI. Additionally, we collect a real-world HSI fusion dataset, consisting of paired HSI and unaligned Ref-RGB, to support the evaluation of the proposed model for real scenes. Extensive experiments are conducted on both simulated and our real-world datasets, and it shows that our method obtains a clear improvement over existing single-image and fusion-based super-resolution methods on quantitative assessment as well as visual comparison. The code and dataset are publicly available at https://zeqiang-lai.github.io/HSI-RefSR/.},
  archive      = {J_TNNLS},
  author       = {Zeqiang Lai and Ying Fu and Jun Zhang},
  doi          = {10.1109/TNNLS.2023.3340561},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2999-3011},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hyperspectral image super resolution with real unaligned RGB guidance},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving uncertainty quantification of variance networks by
tree-structured learning. <em>TNNLS</em>, <em>36</em>(2), 2984–2998. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342138">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To improve the uncertainty quantification of variance networks, we propose a novel tree-structured local neural network model that partitions the feature space into multiple regions based on uncertainty heterogeneity. A tree is built upon giving the training data, whose leaf nodes represent different regions where region-specific neural networks are trained to predict both the mean and the variance for quantifying uncertainty. The proposed uncertainty-splitting neural regression tree (USNRT) employs novel splitting criteria. At each node, a neural network is trained on the full data first, and a statistical test for the residuals is conducted to find the best split, corresponding to the two subregions with the most significant uncertainty heterogeneity between them. USNRT is computationally friendly, because very few leaf nodes are sufficient and pruning is unnecessary. Furthermore, an ensemble version can be easily constructed to estimate the total uncertainty, including the aleatory and epistemic. On extensive UCI datasets, USNRT or its ensemble shows superior performance compared to some recent popular methods for quantifying uncertainty with variances. Through comprehensive visualization and analysis, we uncover how USNRT works and show its merits, revealing that uncertainty heterogeneity does exist in many datasets and can be learned by USNRT.},
  archive      = {J_TNNLS},
  author       = {Wenxuan Ma and Xing Yan and Kun Zhang},
  doi          = {10.1109/TNNLS.2023.3342138},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2984-2998},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Improving uncertainty quantification of variance networks by tree-structured learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Conformal loss-controlling prediction. <em>TNNLS</em>,
<em>36</em>(2), 2973–2983. (<a
href="https://doi.org/10.1109/TNNLS.2024.3356512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conformal prediction (CP) is a learning framework controlling prediction coverage of prediction sets, which can be built on any learning algorithm for point prediction. This work proposes a learning framework named conformal loss-controlling prediction, which extends CP to the situation where the value of a loss function needs to be controlled. Different from existing works about risk-controlling prediction sets and conformal risk control with the purpose of controlling the expected values of loss functions, the proposed approach in this article focuses on the loss for any test object, which is an extension of CP from miscoverage loss to some general loss. The controlling guarantee is proved under the assumption of exchangeability of data in finite-sample cases and the framework is tested empirically for classification with a class-varying loss and statistical postprocessing of numerical weather forecasting applications, which are introduced as point-wise classification and point-wise regression problems. All theoretical analysis and experimental results confirm the effectiveness of our loss-controlling approach.},
  archive      = {J_TNNLS},
  author       = {Di Wang and Ping Wang and Zhong Ji and Xiaojun Yang and Hongyue Li},
  doi          = {10.1109/TNNLS.2024.3356512},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2973-2983},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Conformal loss-controlling prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Virtual classification: Modulating domain-specific knowledge
for multidomain crowd counting. <em>TNNLS</em>, <em>36</em>(2),
2958–2972. (<a
href="https://doi.org/10.1109/TNNLS.2024.3350363">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multidomain crowd counting aims to learn a general model for multiple diverse datasets. However, deep networks prefer modeling distributions of the dominant domains instead of all domains, which is known as domain bias. In this study, we propose a simple-yet-effective modulating domain-specific knowledge network (MDKNet) to handle the domain bias issue in multidomain crowd counting. MDKNet is achieved by employing the idea of “modulating,” enabling deep network balancing and modeling different distributions of diverse datasets with little bias. Specifically, we propose an instance-specific batch normalization (IsBN) module, which serves as a base modulator to refine the information flow to be adaptive to domain distributions. To precisely modulating the domain-specific information, the domain-guided virtual classifier (DVC) is then introduced to learn a domain-separable latent space. This space is employed as an input guidance for the IsBN modulator, such that the mixture distributions of multiple datasets can be well treated. Extensive experiments performed on popular benchmarks, including Shanghai-tech A/B, QNRF, and NWPU validate the superiority of MDKNet in tackling multidomain crowd counting and the effectiveness for multidomain learning. Code is available at https://github.com/csguomy/MDKNet.},
  archive      = {J_TNNLS},
  author       = {Mingyue Guo and Binghui Chen and Zhaoyi Yan and Yaowei Wang and Qixiang Ye},
  doi          = {10.1109/TNNLS.2024.3350363},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2958-2972},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Virtual classification: Modulating domain-specific knowledge for multidomain crowd counting},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extreme fuzzy broad learning system: Algorithm, frequency
principle, and applications in classification and regression.
<em>TNNLS</em>, <em>36</em>(2), 2946–2957. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347888">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an effective alternative to deep neural networks, broad learning system (BLS) has attracted more attention due to its efficient and outstanding performance and shorter training process in classification and regression tasks. Nevertheless, the performance of BLS will not continue to increase, but even decrease, as the number of nodes reaches the saturation point and continues to increase. In addition, the previous research on neural networks usually ignored the reason for the good generalization of neural networks. To solve these problems, this article first proposes the Extreme Fuzzy BLS (E-FBLS), a novel cascaded fuzzy BLS, in which multiple fuzzy BLS blocks are grouped or cascaded together. Moreover, the original data is input to each FBLS block rather than the previous blocks. In addition, we use residual learning to illustrate the effectiveness of E-FBLS. From the frequency domain perspective, we also discover the existence of the frequency principle in E-FBLS, which can provide good interpretability for the generalization of the neural network. Experimental results on classical classification and regression datasets show that the accuracy of the proposed E-FBLS is superior to traditional BLS in handling classification and regression tasks. The accuracy improves when the number of blocks increases to some extent. Moreover, we verify the frequency principle of E-FBLS that E-FBLS can obtain the low-frequency components quickly, while the high-frequency components are gradually adjusted as the number of FBLS blocks increases.},
  archive      = {J_TNNLS},
  author       = {Junwei Duan and Shiyi Yao and Jiantao Tan and Yang Liu and Long Chen and Zhen Zhang and C. L. Philip Chen},
  doi          = {10.1109/TNNLS.2023.3347888},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2946-2957},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Extreme fuzzy broad learning system: Algorithm, frequency principle, and applications in classification and regression},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Achieving sharp upper bounds on the expressive power of
neural networks via tropical polynomials. <em>TNNLS</em>,
<em>36</em>(2), 2931–2945. (<a
href="https://doi.org/10.1109/TNNLS.2024.3350786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The expressive power of neural networks describes the ability to represent or approximate complex functions. The number of linear regions is the standard and most natural measure of expressive power. However, a major challenge in utilizing the number of linear regions as a measure of expressive power is the exponential gap between the theoretical upper and lower bounds, which becomes more pronounced as the neural network capacity increases. In this article, we aim to derive a sharp upper bound on piecewise linear neural networks (PLNNs) to bridge this gap. Specifically, we first establish the relationship between tropical polynomials and PLNNs. In the unexpanded tropical polynomials form, we make the proposition that hyperplanes are not all in the general positions, thereby reducing the number of intersecting hyperplanes. We propose a rank-based approach and present the empirical analysis that this approach outperforms previous Zaslavsky’s theorem-based methods. In the expanded tropical polynomials form, accounting for limitations in weight initialization and model computational precision, we raise the concept that the values range of each term is bounded. We propose a precision-based approach that transforms the approximate exponential growth of the number of linear regions into polynomial growth with width, which is effective at larger layer widths. Finally, we compare the number of linear regions that can be represented by each hidden layer in both forms and derive a sharp upper bound for PLNNs. Empirical analysis and experimental results provide compelling evidence for the efficacy and feasibility of this sharp upper bound on both simulated experiments and real datasets.},
  archive      = {J_TNNLS},
  author       = {Zhiwei Li and Cheng Wang},
  doi          = {10.1109/TNNLS.2024.3350786},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2931-2945},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Achieving sharp upper bounds on the expressive power of neural networks via tropical polynomials},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep multiview module adaption transfer network for
subject-specific EEG recognition. <em>TNNLS</em>, <em>36</em>(2),
2917–2930. (<a
href="https://doi.org/10.1109/TNNLS.2024.3350085">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Transfer learning is one of the popular methods to solve the problem of insufficient data in subject-specific electroencephalogram (EEG) recognition tasks. However, most existing approaches ignore the difference between subjects and transfer the same feature representations from source domain to different target domains, resulting in poor transfer performance. To address this issue, we propose a novel subject-specific EEG recognition method named deep multiview module adaption transfer (DMV-MAT) network. First, we design a universal deep multiview (DMV) network to generate different types of discriminative features from multiple perspectives, which improves the generalization performance by extensive feature sets. Second, module adaption transfer (MAT) is designed to evaluate each module by the feature distributions of source and target samples, which can generate an optimal weight sharing strategy for each target subject and promote the model to learn domain-invariant and domain-specific features simultaneously. We conduct extensive experiments in two EEG recognition tasks, i.e., motor imagery (MI) and seizure prediction, on four datasets. Experimental results demonstrate that the proposed method achieves promising performance compared with the state-of-the-art methods, indicating a feasible solution for subject-specific EEG recognition tasks. Implementation codes are available at https://github.com/YangLibuaa/DMV-MAT.},
  archive      = {J_TNNLS},
  author       = {Weigang Cui and Yansong Xiang and Yifan Wang and Tao Yu and Xiao-Feng Liao and Bin Hu and Yang Li},
  doi          = {10.1109/TNNLS.2024.3350085},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2917-2930},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep multiview module adaption transfer network for subject-specific EEG recognition},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An information fusion system-driven deep neural networks
with application to cancer mortality risk estimate. <em>TNNLS</em>,
<em>36</em>(2), 2905–2916. (<a
href="https://doi.org/10.1109/TNNLS.2023.3342462">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Next-generation sequencing (NGS) genomic data offer valuable high-throughput genomic information for computational applications in medicine. Using genomic data to identify disease-associated genes to estimate cancer mortality risk remains challenging regarding to computational efficiency and risk integration. For determining mortality-related genes, we propose an information fusion system based on a fuzzy system to fuse the numerous deep-learning-based risk scores, consider the significance of features related to time-varying effects and risk stratifications, and interpret the directional relationship and interaction between outcome and predictors. Fuzzy rules were implemented to integrate the considerations mentioned above by merging all the risk score models to achieve advanced risk estimation. The genomic data of head and neck squamous cell carcinoma (HNSCC) were used to evaluate the performance of the proposed computational approach. The results indicated that the proposed computational approach exhibited optimal ability to identify mortality risk-related genes in HNSCC patients. The results also suggest that HNSCC mortality is associated with cancer inflammatory response, the interleukin-17A signaling pathway, stellate cell activation, and the extracellular-regulated protein kinase five signaling pathway, which might offer new therapeutic targets HNSCC through immunologic or antiangiogenic mechanisms. The proposed information fusion system can promote the determination of high-risk genes related to cancer mortality. This study contributes a valid cancer mortality risk estimate that can identify mortality-related genes.},
  archive      = {J_TNNLS},
  author       = {Cheng-Hong Yang and Sin-Hua Moi and Li-Yeh Chuang and Yu-Da Lin},
  doi          = {10.1109/TNNLS.2023.3342462},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2905-2916},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An information fusion system-driven deep neural networks with application to cancer mortality risk estimate},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid of generative and discriminative models based on
the gaussian-coupled softmax layer. <em>TNNLS</em>, <em>36</em>(2),
2894–2904. (<a
href="https://doi.org/10.1109/TNNLS.2024.3358113">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative models offer advantageous characteristics for classification tasks, such as the availability of unsupervised data and calibrated confidence. In contrast, discriminative models have advantages in terms of their potential to outperform their generative counterparts and the simplicity of their model structures and learning algorithms. In this article, we propose a method to train a hybrid of discriminative and generative models in a single neural network (NN), which exhibits the characteristics of both models. The key idea is the Gaussian-coupled softmax layer, which is a fully connected layer with a softmax activation function coupled with Gaussian distributions. This layer can be embedded into an NN-based classifier and allows the classifier to estimate both the class posterior distribution and the input data distribution. We demonstrate that the proposed hybrid model can be applied to semi-supervised learning and confidence calibration.},
  archive      = {J_TNNLS},
  author       = {Hideaki Hayashi},
  doi          = {10.1109/TNNLS.2024.3358113},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2894-2904},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A hybrid of generative and discriminative models based on the gaussian-coupled softmax layer},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fully spiking actor network with intralayer connections for
reinforcement learning. <em>TNNLS</em>, <em>36</em>(2), 2881–2893. (<a
href="https://doi.org/10.1109/TNNLS.2024.3352653">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the help of special neuromorphic hardware, spiking neural networks (SNNs) are expected to realize artificial intelligence (AI) with less energy consumption. It provides a promising energy-efficient way for realistic control tasks by combining SNNs with deep reinforcement learning (DRL). In this article, we focus on the task where the agent needs to learn multidimensional deterministic policies to control, which is very common in real scenarios. Recently, the surrogate gradient method has been utilized for training multilayer SNNs, which allows SNNs to achieve comparable performance with the corresponding deep networks in this task. Most existing spike-based reinforcement learning (RL) methods take the firing rate as the output of SNNs, and convert it to represent continuous action space (i.e., the deterministic policy) through a fully connected (FC) layer. However, the decimal characteristic of the firing rate brings the floating-point matrix operations to the FC layer, making the whole SNN unable to deploy on the neuromorphic hardware directly. To develop a fully spiking actor network (SAN) without any floating-point matrix operations, we draw inspiration from the nonspiking interneurons found in insects and employ the membrane voltage of the nonspiking neurons to represent the action. Before the nonspiking neurons, multiple population neurons are introduced to decode different dimensions of actions. Since each population is used to decode a dimension of action, we argue that the neurons in each population should be connected in time domain and space domain. Hence, the intralayer connections are used in output populations to enhance the representation capacity. This mechanism exists extensively in animals and has been demonstrated effectively. Finally, we propose a fully SAN with intralayer connections (ILC-SAN). Extensive experimental results demonstrate that the proposed method outperforms the state-of-the-art performance on continuous control tasks from OpenAI gym. Moreover, we estimate the theoretical energy consumption when deploying ILC-SAN on neuromorphic chips to illustrate its high energy efficiency.},
  archive      = {J_TNNLS},
  author       = {Ding Chen and Peixi Peng and Tiejun Huang and Yonghong Tian},
  doi          = {10.1109/TNNLS.2024.3352653},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2881-2893},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Fully spiking actor network with intralayer connections for reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning robust predictive control: A spatial–temporal game
theoretic approach. <em>TNNLS</em>, <em>36</em>(2), 2869–2880. (<a
href="https://doi.org/10.1109/TNNLS.2024.3357238">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article investigates robust predictive control problem for unknown dynamical systems. Since the dynamics unavailability restricts feasibility of model-driven methods, learning robust predictive control (LRPC) framework is developed from the aspect of time consistency. Under feedback-like control causality, the robust predictive control is then reconstructed as spatial–temporal games, and we guarantee stability through time-consistent Nash equilibrium. For gradation clarity, our framework is specified as four-follow contents. First, multistep feedback-like control causality is drawn from time series analysis, and Takens’ theorem provides theoretical support from steady-state property. Second, control problem is reconstructed as games, while performance and robustness partition the game into temporal nonzero-sum subgames and spatial zero-sum ones, respectively. Next, multistep reinforcement learning (RL) is designed to solve robust predictive control without system model. Convergence is proven through bounds analysis of oscillatory value functions, and properties of receding horizon are derived from time consistency. Finally, data-driven implementation is given with function approximation, and neural networks are chosen to approximate value functions and feedback-like causality. Weights are estimated with least squares errors. Numerical results verify the effectiveness.},
  archive      = {J_TNNLS},
  author       = {Xindi Yang and Hao Zhang and Zhuping Wang and Shun-Feng Su},
  doi          = {10.1109/TNNLS.2024.3357238},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2869-2880},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning robust predictive control: A Spatial–Temporal game theoretic approach},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward less constrained macro-neural architecture search.
<em>TNNLS</em>, <em>36</em>(2), 2854–2868. (<a
href="https://doi.org/10.1109/TNNLS.2023.3326648">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Networks found with neural architecture search (NAS) achieve the state-of-the-art performance in a variety of tasks, out-performing human-designed networks. However, most NAS methods heavily rely on human-defined assumptions that constrain the search: architecture’s outer skeletons, number of layers, parameter heuristics, and search spaces. In addition, common search spaces consist of repeatable modules (cells) instead of fully exploring the architecture’s search space by designing entire architectures (macro-search). Imposing such constraints requires deep human expertise and restricts the search to predefined settings. In this article, we propose less constrained macro-neural architecture search (LCMNAS), a method that pushes NAS to less constrained search spaces by performing macro-search without relying on predefined heuristics or bounded search spaces. LCMNAS introduces three components for the NAS pipeline: 1) a method that leverages information about well-known architectures to autonomously generate complex search spaces based on weighted directed graphs (WDGs) with hidden properties; 2) an evolutionary search strategy that generates complete architectures from scratch; and 3) a mixed-performance estimation approach that combines information about architectures at the initialization stage and lower fidelity estimates to infer their trainability and capacity to model complex functions. We present experiments in 14 different datasets showing that LCMNAS is capable of generating both cell and macro-based architectures with minimal GPU computation and state-of-the-art results. Moreover, we conduct extensive studies on the importance of different NAS components in both cell and macro-based settings. The code for reproducibility is publicly available at https://github.com/VascoLopes/LCMNAS.},
  archive      = {J_TNNLS},
  author       = {Vasco Lopes and Luís A. Alexandre},
  doi          = {10.1109/TNNLS.2023.3326648},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2854-2868},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward less constrained macro-neural architecture search},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dual accuracy-quality-driven neural network for prediction
interval generation. <em>TNNLS</em>, <em>36</em>(2), 2843–2853. (<a
href="https://doi.org/10.1109/TNNLS.2023.3339470">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate uncertainty quantification is necessary to enhance the reliability of deep learning (DL) models in real-world applications. In the case of regression tasks, prediction intervals (PIs) should be provided along with the deterministic predictions of DL models. Such PIs are useful or “high-quality (HQ)” as long as they are sufficiently narrow and capture most of the probability density. In this article, we present a method to learn PIs for regression-based neural networks (NNs) automatically in addition to the conventional target predictions. In particular, we train two companion NNs: one that uses one output, the target estimate, and another that uses two outputs, the upper and lower bounds of the corresponding PI. Our main contribution is the design of a novel loss function for the PI-generation network that takes into account the output of the target-estimation network and has two optimization objectives: minimizing the mean PI width and ensuring the PI integrity using constraints that maximize the PI probability coverage implicitly. Furthermore, we introduce a self-adaptive coefficient that balances both objectives within the loss function, which alleviates the task of fine-tuning. Experiments using a synthetic dataset, eight benchmark datasets, and a real-world crop yield prediction dataset showed that our method was able to maintain a nominal probability coverage and produce significantly narrower PIs without detriment to its target estimation accuracy when compared to those PIs generated by three state-of-the-art neural-network-based methods. In other words, our method was shown to produce higher quality PIs.},
  archive      = {J_TNNLS},
  author       = {Giorgio Morales and John W. Sheppard},
  doi          = {10.1109/TNNLS.2023.3339470},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2843-2853},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Dual accuracy-quality-driven neural network for prediction interval generation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust low-rank latent feature analysis for spatiotemporal
signal recovery. <em>TNNLS</em>, <em>36</em>(2), 2829–2842. (<a
href="https://doi.org/10.1109/TNNLS.2023.3339786">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Wireless sensor network (WSN) is an emerging and promising developing area in the intelligent sensing field. Due to various factors like sudden sensors breakdown or saving energy by deliberately shutting down partial nodes, there are always massive missing entries in the collected sensing data from WSNs. Low-rank matrix approximation (LRMA) is a typical and effective approach for pattern analysis and missing data recovery in WSNs. However, existing LRMA-based approaches ignore the adverse effects of outliers inevitably mixed with collected data, which may dramatically degrade their recovery accuracy. To address this issue, this article innovatively proposes a latent feature analysis (LFA) based spatiotemporal signal recovery (STSR) model, named LFA-STSR. Its main idea is twofold: 1) incorporating the spatiotemporal correlation into an LFA model as the regularization constraint to improve its recovery accuracy and 2) aggregating the $L_{1}$ -norm into the loss part of an LFA model to improve its robustness to outliers. As such, LFA-STSR can accurately recover missing data based on partially observed data mixed with outliers in WSNs. To evaluate the proposed LFA-STSR model, extensive experiments have been conducted on four real-world WSNs datasets. The results demonstrate that LFA-STSR significantly outperforms the related six state-of-the-art models in terms of both recovery accuracy and robustness to outliers.},
  archive      = {J_TNNLS},
  author       = {Di Wu and Zechao Li and Zhikai Yu and Yi He and Xin Luo},
  doi          = {10.1109/TNNLS.2023.3339786},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2829-2842},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust low-rank latent feature analysis for spatiotemporal signal recovery},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward balance deep semisupervised clustering.
<em>TNNLS</em>, <em>36</em>(2), 2816–2828. (<a
href="https://doi.org/10.1109/TNNLS.2023.3339680">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The goal of balanced clustering is partitioning data into distinct groups of equal size. Previous studies have attempted to address this problem by designing balanced regularizers or utilizing conventional clustering methods. However, these methods often rely solely on classic methods, which limits their performance and primarily focuses on low-dimensional data. Although neural networks exhibit effective performance on high-dimensional datasets, they struggle to effectively leverage prior knowledge for clustering with a balanced tendency. To overcome the above limitations, we propose deep semisupervised balanced clustering, which simultaneously learns clustering and generates balance-favorable representations. Our model is based on the autoencoder paradigm incorporating a semisupervised module. Specifically, we introduce a balance-oriented clustering loss and incorporate pairwise constraints into the penalty term as a pluggable module using the Lagrangian multiplier method. Theoretically, we ensure that the proposed model maintains a balanced orientation and provides a comprehensive optimization process. Empirically, we conducted extensive experiments on four datasets to demonstrate significant improvements in clustering performance and balanced measurements. Our code is available at https://github.com/DuannYu/BalancedSemi-TNNLS.},
  archive      = {J_TNNLS},
  author       = {Yu Duan and Zhoumin Lu and Rong Wang and Xuelong Li and Feiping Nie},
  doi          = {10.1109/TNNLS.2023.3339680},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2816-2828},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Toward balance deep semisupervised clustering},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Graph reasoning with supervised contrastive learning for
legal judgment prediction. <em>TNNLS</em>, <em>36</em>(2), 2801–2815.
(<a href="https://doi.org/10.1109/TNNLS.2023.3344634">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Given the fact descriptions of legal cases, the legal judgment prediction (LJP) problem aims to determine three judgment tasks of law articles, charges, and the term of penalty. Most existing studies have considered task dependencies while neglecting the prior dependencies of labels among different tasks. Therefore, how to make better use of the information on the relation dependencies among tasks and labels becomes a crucial issue. To this end, we transform the text classification problem into a node classification framework based on graph reasoning and supervised contrastive learning (SCL) techniques, named GraSCL. Specifically, we first design a graph reasoning network to model the potential dependency structures and facilitate relational learning under various graph topologies. Then, we introduce the SCL method for the LJP task to further leverage the label relation on the graph. To accommodate the node classification settings, we extend the traditional SCL method to novel variants for SCL at the node level, which allows the GraSCL framework to be trained efficiently even with small batches. Furthermore, to recognize the importance of hard negative samples in contrastive learning, we introduce a simple yet effective technique called online hard negative mining (OHNM) to enhance our SCL approach. This technique complements our SCL method and enables us to control the number and complexity of negative samples, leading to further improvements in the model’s performance. Finally, extensive experiments are conducted on two well-known benchmarks, demonstrating the effectiveness and rationality of our proposed SCL approach as compared to the state-of-the-art competitors.},
  archive      = {J_TNNLS},
  author       = {Jiawei Wang and Yuquan Le and Da Cao and Shaofei Lu and Zhe Quan and Meng Wang},
  doi          = {10.1109/TNNLS.2023.3344634},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2801-2815},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Graph reasoning with supervised contrastive learning for legal judgment prediction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KMT-PLL: K-means cross-attention transformer for partial
label learning. <em>TNNLS</em>, <em>36</em>(2), 2789–2800. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Partial label learning (PLL) studies the problem of learning instance classification with a set of candidate labels and only one is correct. While recent works have demonstrated that the Vision Transformer (ViT) has achieved good results when training from clean data, its applications to PLL remain limited and challenging. To address this issue, we rethink the relationship between instances and object queries to propose K-means cross-attention transformer for PLL (KMT-PLL), which can continuously learn cluster centers and be used for downstream disambiguation tasks. More specifically, K-means cross-attention as a clustering process can effectively learn the cluster centers to represent label classes. The purpose of this operation is to make the similarity between instances and labels measurable, which can effectively detect noise labels. Furthermore, we propose a new corrected cross entropy formulation, which can assign weights to candidate labels according to the instance-to-label relevance to guide the training of the instance classifier. As the training goes on, the ground-truth label is progressively identified, and the refined labels and cluster centers in turn help to improve the classifier. Simulation results demonstrate the advantage of the KMT-PLL and its suitability for PLL.},
  archive      = {J_TNNLS},
  author       = {Jinfu Fan and Linqing Huang and Chaoyu Gong and Yang You and Min Gan and Zhongjie Wang},
  doi          = {10.1109/TNNLS.2023.3347792},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2789-2800},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {KMT-PLL: K-means cross-attention transformer for partial label learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Security and safety-critical learning-based collaborative
control for multiagent systems. <em>TNNLS</em>, <em>36</em>(2),
2777–2788. (<a
href="https://doi.org/10.1109/TNNLS.2024.3350679">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article presents a novel learning-based collaborative control framework to ensure communication security and formation safety of nonlinear multiagent systems (MASs) subject to denial-of-service (DoS) attacks, model uncertainties, and barriers in environments. The framework has a distributed and decoupled design at the cyber-layer and the physical layer. A resilient control Lyapunov function-quadratic programming (RCLF-QP)-based observer is first proposed to achieve secure reference state estimation under DoS attacks at the cyber-layer. Based on deep reinforcement learning (RL) and control barrier function (CBF), a safety-critical formation controller is designed at the physical layer to ensure safe collaborations between uncertain agents in dynamic environments. The framework is applied to autonomous vehicles for area scanning formations with barriers in environments. The comparative experimental results demonstrate that the proposed framework can effectively improve the resilience and robustness of the system.},
  archive      = {J_TNNLS},
  author       = {Bing Yan and Peng Shi and Chee Peng Lim and Yuan Sun and Ramesh K. Agarwal},
  doi          = {10.1109/TNNLS.2024.3350679},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2777-2788},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Security and safety-critical learning-based collaborative control for multiagent systems},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An inexact sequential quadratic programming method for
learning and control of recurrent neural networks. <em>TNNLS</em>,
<em>36</em>(2), 2762–2776. (<a
href="https://doi.org/10.1109/TNNLS.2024.3354855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article considers the two-stage approach to solving a partially observable Markov decision process (POMDP): the identification stage and the (optimal) control stage. We present an inexact sequential quadratic programming framework for recurrent neural network learning (iSQPRL) for solving the identification stage of the POMDP, in which the true system is approximated by a recurrent neural network (RNN) with dynamically consistent overshooting (DCRNN). We formulate the learning problem as a constrained optimization problem and study the quadratic programming (QP) subproblem with a convergence analysis under a restarted Krylov-subspace iterative scheme that implicitly exploits the structure of the associated Karush–Kuhn–Tucker (KKT) subsystem. In the control stage, where a feedforward neural network (FNN) controller is designed on top of the RNN model, we adapt a generalized Gauss–Newton (GGN) algorithm that exploits useful approximations to the curvature terms of the training data and selects its mini-batch step size using a known property of some regularization function. Simulation results are provided to demonstrate the effectiveness of our approach.},
  archive      = {J_TNNLS},
  author       = {Adeyemi D. Adeoye and Alberto Bemporad},
  doi          = {10.1109/TNNLS.2024.3354855},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2762-2776},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {An inexact sequential quadratic programming method for learning and control of recurrent neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning for nash equilibrium of
differential games. <em>TNNLS</em>, <em>36</em>(2), 2747–2761. (<a
href="https://doi.org/10.1109/TNNLS.2024.3351631">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Nash equilibrium is a significant solution concept representing the optimal strategy in an uncooperative multiagent system. This study presents two deep reinforcement learning (DRL) algorithms for solving the Nash equilibrium of differential games. Both algorithms are built upon the distributed distributional deep deterministic policy gradient (D4PG) algorithm, which is a one-sided learning method. We modified it to a two-sided adversarial learning method. The first is D4PG for games (D4P2G), which directly applies an adversarial play framework based on the D4PG. A simultaneous policy gradient descent (SPGD) method is employed to optimize the policies of the players with conflicting objectives. The second is the distributional deep deterministic symplectic policy gradient (D4SPG) algorithm, which is our main contribution. More specifically, it newly designs a minimax learning framework that combines the critics of the two players and proposes a symplectic policy gradient adjustment method to find a better policy gradient. Simulations show that both algorithms converge to the Nash equilibrium in most cases, but D4SPG can learn the Nash equilibrium more accurately and efficiently, especially in Hamiltonian games. Moreover, it can handle games with complex dynamics, which is challenging for traditional methods.},
  archive      = {J_TNNLS},
  author       = {Zhenyu Li and Yazhong Luo},
  doi          = {10.1109/TNNLS.2024.3351631},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2747-2761},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep reinforcement learning for nash equilibrium of differential games},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Frequency domain-oriented complex graph neural networks for
graph classification. <em>TNNLS</em>, <em>36</em>(2), 2733–2746. (<a
href="https://doi.org/10.1109/TNNLS.2024.3351762">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNNs) could directly deal with the data of graph structure. Current GNNs are confined to the spatial domain and learn real low-dimensional embeddings in graph classification tasks. In this article, we explore frequency domain-oriented complex GNNs in which the node’s embedding in each layer is a complex vector. The difficulty lies in the design of graph pooling and we propose a mirror-connected design with two crucial problems: parameter reduction problem and complex gradient backpropagation problem. To deal with the former problem, we propose the notion of squared singular value pooling (SSVP) and prove that the representation power of SSVP followed by a fully connected layer with nonnegative weights is exactly equivalent to that of a mirror-connected layer. To resolve the latter problem, we provide an alternative feasible method to solve singular values of complex embeddings with a theoretical guarantee. Finally, we propose a mixture of pooling strategies in which first-order statistics information is employed to enrich the last low-dimensional representation. Experiments on benchmarks demonstrate the effectiveness of the complex GNNs with mirror-connected layers.},
  archive      = {J_TNNLS},
  author       = {Youfa Liu and Bo Du},
  doi          = {10.1109/TNNLS.2024.3351762},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2733-2746},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Frequency domain-oriented complex graph neural networks for graph classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Universality and approximation bounds for echo state
networks with random weights. <em>TNNLS</em>, <em>36</em>(2), 2720–2732.
(<a href="https://doi.org/10.1109/TNNLS.2023.3339512">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We study the uniform approximation of echo state networks (ESNs) with randomly generated internal weights. These models, in which only the readout weights are optimized during training, have made empirical success in learning dynamical systems. Recent results showed that ESNs with ReLU activation are universal. In this article, we give an alternative construction and prove that the universality holds for general activation functions. Specifically, our main result shows that, under certain condition on the activation function, there exists a sampling procedure for the internal weights so that the ESN can approximate any continuous casual time-invariant operators with high probability. In particular, for ReLU activation, we give explicit construction for these sampling procedures. We also quantify the approximation error of the constructed ReLU ESNs for sufficiently regular operators.},
  archive      = {J_TNNLS},
  author       = {Zhen Li and Yunfei Yang},
  doi          = {10.1109/TNNLS.2023.3339512},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2720-2732},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Universality and approximation bounds for echo state networks with random weights},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Goal-conditioned hierarchical reinforcement learning with
high-level model approximation. <em>TNNLS</em>, <em>36</em>(2),
2705–2719. (<a
href="https://doi.org/10.1109/TNNLS.2024.3354061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hierarchical reinforcement learning (HRL) exhibits remarkable potential in addressing large-scale and long-horizon complex tasks. However, a fundamental challenge, which arises from the inherently entangled nature of hierarchical policies, has not been understood well, consequently compromising the training stability and exploration efficiency of HRL. In this article, we propose a novel HRL algorithm, high-level model approximation (HLMA), presenting both theoretical foundations and practical implementations. In HLMA, a Planner constructs an innovative high-level dynamic model to predict the $k$ -step transition of the Controller in a subtask. This allows for the estimation of the evolving performance of the Controller. At low level, we leverage the initial state of each subtask, transforming absolute states into relative deviations by a designed operator as Controller input. This approach facilitates the reuse of subtask domain knowledge, enhancing data efficiency. With this designed structure, we establish the local convergence of each component within HLMA and subsequently derive regret bounds to ensure global convergence. Abundant experiments conducted on complex locomotion and navigation tasks demonstrate that HLMA surpasses other state-of-the-art single-level RL and HRL algorithms in terms of sample efficiency and asymptotic performance. In addition, thorough ablation studies validate the effectiveness of each component of HLMA.},
  archive      = {J_TNNLS},
  author       = {Yu Luo and Tianying Ji and Fuchun Sun and Huaping Liu and Jianwei Zhang and Mingxuan Jing and Wenbing Huang},
  doi          = {10.1109/TNNLS.2024.3354061},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2705-2719},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Goal-conditioned hierarchical reinforcement learning with high-level model approximation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CapMatch: Semi-supervised contrastive transformer capsule
with feature-based knowledge distillation for human activity
recognition. <em>TNNLS</em>, <em>36</em>(2), 2690–2704. (<a
href="https://doi.org/10.1109/TNNLS.2023.3344294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article proposes a semi-supervised contrastive capsule transformer method with feature-based knowledge distillation (KD) that simplifies the existing semisupervised learning (SSL) techniques for wearable human activity recognition (HAR), called CapMatch. CapMatch gracefully hybridizes supervised learning and unsupervised learning to extract rich representations from input data. In unsupervised learning, CapMatch leverages the pseudolabeling, contrastive learning (CL), and feature-based KD techniques to construct similarity learning on lower and higher level semantic information extracted from two augmentation versions of the data, “weak” and “timecut,” to recognize the relationships among the obtained features of classes in the unlabeled data. CapMatch combines the outputs of the weak- and timecut-augmented models to form pseudolabeling and thus CL. Meanwhile, CapMatch uses the feature-based KD to transfer knowledge from the intermediate layers of the weak-augmented model to those of the timecut-augmented model. To effectively capture both local and global patterns of HAR data, we design a capsule transformer network consisting of four capsule-based transformer blocks and one routing layer. Experimental results show that compared with a number of state-of-the-art semi-supervised and supervised algorithms, the proposed CapMatch achieves decent performance on three commonly used HAR datasets, namely, HAPT, WISDM, and UCI_HAR. With only 10% of data labeled, CapMatch achieves $F_{1}$ values of higher than 85.00% on these datasets, outperforming 14 semi-supervised algorithms. When the proportion of labeled data reaches 30%, CapMatch obtains $F_{1}$ values of no lower than 88.00% on the datasets above, which is better than several classical supervised algorithms, e.g., decision tree and $k$ -nearest neighbor (KNN).},
  archive      = {J_TNNLS},
  author       = {Zhiwen Xiao and Huagang Tong and Rong Qu and Huanlai Xing and Shouxi Luo and Zonghai Zhu and Fuhong Song and Li Feng},
  doi          = {10.1109/TNNLS.2023.3344294},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2690-2704},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CapMatch: Semi-supervised contrastive transformer capsule with feature-based knowledge distillation for human activity recognition},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-supervised random forest on transformed distribution
for anomaly detection. <em>TNNLS</em>, <em>36</em>(2), 2675–2689. (<a
href="https://doi.org/10.1109/TNNLS.2023.3348833">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anomaly detection, the task of differentiating abnormal data points from normal ones, presents a significant challenge in the realm of machine learning. Numerous strategies have been proposed to tackle this task, with classification-based methods, specifically those utilizing a self-supervised approach via random affine transformations (RATs), demonstrating remarkable performance on both image and non-image data. However, these methods encounter a notable bottleneck, the overlap of constructed labeled datasets across categories, which hampers the subsequent classifiers’ ability to detect anomalies. Consequently, the creation of an effective data distribution becomes the pivotal factor for success. In this article, we introduce a model called “self-supervised forest (sForest),” which leverages the random Fourier transform (RFT) and random orthogonal rotations to craft a controlled data distribution. Our model utilizes the RFT to map input data into a new feature space. With this transformed data, we create a self-labeled training dataset using random orthogonal rotations. We theoretically prove that the data distribution formulated by our methodology is more stable compared to one derived from RATs. We then use the self-labeled dataset in a random forest (RF) classifier to distinguish between normal and anomalous data points. Comprehensive experiments conducted on both real and artificial datasets illustrate that sForest outperforms other anomaly detection methods, including distance-based, kernel-based, forest-based, and network-based benchmarks.},
  archive      = {J_TNNLS},
  author       = {Jiabin Liu and Huadong Wang and Hanyuan Hang and Shumin Ma and Xin Shen and Yong Shi},
  doi          = {10.1109/TNNLS.2023.3348833},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2675-2689},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Self-supervised random forest on transformed distribution for anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tensor robust kernel PCA for multidimensional data.
<em>TNNLS</em>, <em>36</em>(2), 2662–2674. (<a
href="https://doi.org/10.1109/TNNLS.2024.3356228">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, the tensor nuclear norm (TNN)-based tensor robust principle component analysis (TRPCA) has achieved impressive performance in multidimensional data processing. The underlying assumption in TNN is the low-rankness of frontal slices of the tensor in the transformed domain (e.g., Fourier domain). However, the low-rankness assumption is usually violative for real-world multidimensional data (e.g., video and image) due to their intrinsically nonlinear structure. How to effectively and efficiently exploit the intrinsic structure of multidimensional data remains a challenge. In this article, we first suggest a kernelized TNN (KTNN) by leveraging the nonlinear kernel mapping in the transform domain, which faithfully captures the intrinsic structure (i.e., implicit low-rankness) of multidimensional data and is computed at a lower cost by introducing kernel trick. Armed with KTNN, we propose a tensor robust kernel PCA (TRKPCA) model for handling multidimensional data, which decomposes the observed tensor into an implicit low-rank component and a sparse component. To tackle the nonlinear and nonconvex model, we develop an efficient alternating direction method of multipliers (ADMM)-based algorithm. Extensive experiments on real-world applications collectively verify that TRKPCA achieves superiority over the state-of-the-art RPCA methods.},
  archive      = {J_TNNLS},
  author       = {Jie Lin and Ting-Zhu Huang and Xi-Le Zhao and Teng-Yu Ji and Qibin Zhao},
  doi          = {10.1109/TNNLS.2024.3356228},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2662-2674},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Tensor robust kernel PCA for multidimensional data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Capsule networks with residual pose routing. <em>TNNLS</em>,
<em>36</em>(2), 2648–2661. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347722">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capsule networks (CapsNets) have been known difficult to develop a deeper architecture, which is desirable for high performance in the deep learning era, due to the complex capsule routing algorithms. In this article, we present a simple yet effective capsule routing algorithm, which is presented by a residual pose routing. Specifically, the higher-layer capsule pose is achieved by an identity mapping on the adjacently lower-layer capsule pose. Such simple residual pose routing has two advantages: 1) reducing the routing computation complexity and 2) avoiding gradient vanishing due to its residual learning framework. On top of that, we explicitly reformulate the capsule layers by building a residual pose block. Stacking multiple such blocks results in a deep residual CapsNets (ResCaps) with a ResNet-like architecture. Results on MNIST, AffNIST, SmallNORB, and CIFAR-10/100 show the effectiveness of ResCaps for image classification. Furthermore, we successfully extend our residual pose routing to large-scale real-world applications, including 3-D object reconstruction and classification, and 2-D saliency dense prediction. The source code has been released on https://github.com/liuyi1989/ResCaps.},
  archive      = {J_TNNLS},
  author       = {Yi Liu and De Cheng and Dingwen Zhang and Shoukun Xu and Jungong Han},
  doi          = {10.1109/TNNLS.2023.3347722},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2648-2661},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Capsule networks with residual pose routing},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cycle-refined multidecision joint alignment network for
unsupervised domain adaptive hyperspectral change detection.
<em>TNNLS</em>, <em>36</em>(2), 2634–2647. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347301">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Hyperspectral change detection, which provides abundant information on land cover changes in the Earth’s surface, has become one of the most crucial tasks in remote sensing. Recently, deep-learning-based change detection methods have shown remarkable performance, but the acquirement of labeled data is extremely expensive and time-consuming. It is intuitive to learn changes from the scene with sufficient labeled data and adapting them into an unlabeled new scene. However, the nonnegligible domain shift between different scenes leads to inevitable performance degradation. In this article, a cycle-refined multidecision joint alignment network (CMJAN) is proposed for unsupervised domain adaptive hyperspectral change detection, which realizes progressive alignment of the data distributions between the source and target domains with cycle-refined high-confidence labeled samples. There are two key characteristics: 1) progressively mitigate the distribution discrepancy to learn domain-invariant difference feature representation and 2) update the high-confidence training samples of the target domain in a cycle manner. The benefit is that the domain shift between the source and target domains is progressively alleviated to promote change detection performance on the target domain in an unsupervised manner. Experimental results on different datasets demonstrate that the proposed method can achieve better performance than the state-of-the-art change detection methods.},
  archive      = {J_TNNLS},
  author       = {Jiahui Qu and Wenqian Dong and Yufei Yang and Tongzhen Zhang and Yunsong Li and Qian Du},
  doi          = {10.1109/TNNLS.2023.3347301},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2634-2647},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Cycle-refined multidecision joint alignment network for unsupervised domain adaptive hyperspectral change detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reconstruction of adaptive leaky integrate-and-fire neuron
to enhance the spiking neural networks performance by establishing
complex dynamics. <em>TNNLS</em>, <em>36</em>(2), 2619–2633. (<a
href="https://doi.org/10.1109/TNNLS.2023.3336690">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since digital spiking signals can carry rich information and propagate with low computational consumption, spiking neural networks (SNNs) have received great attention from neuroscientists and are regarded as the future development object of neural networks. However, generating the appropriate spiking signals remains challenging, which is related to the dynamics property of neurons. Most existing studies imitate the biological neurons based on the correlation of synaptic input and output, but these models have only one time constant, thus ignoring the structural differentiation and versatility in biological neurons. In this article, we propose the reconstruction of adaptive leaky integrate-and-fire (R-ALIF) neuron to perform complex behaviors similar to real neurons. First, a synaptic cleft time constant is introduced into the membrane voltage charging equation to distinguish the leakage degree between the neuron membrane and the synaptic cleft, which can expand the representation space of spiking neurons to facilitate SNNs to obtain better information expression way. Second, R-ALIF constructs a voltage threshold adjustment equation to balance the firing rate of output signals. Third, three time constants are transformed into learnable parameters, enabling the adaptive adjustment of dynamics equation and enhancing the information expression ability of SNNs. Fourth, the computational graph of R-ALIF is optimized to improve the performance of SNNs. Moreover, we adopt a temporal dropout (TemDrop) method to solve the overfitting problem in SNNs and propose a data augmentation method for neuromorphic datasets. Finally, we evaluate our method on CIFAR10-DVS, ASL-DVS, and CIFAR-100, and achieve top1 accuracy of 81.0%, 99.8%, and 67.83%, respectively, with few time steps. We believe that our method will further promote the development of SNNs trained by spatiotemporal backpropagation (STBP).},
  archive      = {J_TNNLS},
  author       = {Quan Liu and Mincheng Cai and Kun Chen and Qingsong Ai and Li Ma},
  doi          = {10.1109/TNNLS.2023.3336690},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2619-2633},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Reconstruction of adaptive leaky integrate-and-fire neuron to enhance the spiking neural networks performance by establishing complex dynamics},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep reinforcement learning-based multirestricted
dynamic-request transportation framework. <em>TNNLS</em>,
<em>36</em>(2), 2608–2618. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341471">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unmanned aerial vehicles (UAVs) are used in many areas where their usage is increasing constantly. Their popularity, therefore, maintains its importance in the technology world. Parallel to the development of technology, human standards, and surroundings should also improve equally. This study is developed based on the possibility of timely delivery of urgent medical requests in emergency situations. Using UAVs for delivering urgent medical requests will be very effective due to their flexible maneuverability and low costs. However, off-the-shelf UAVs suffer from limited payload capacity and battery constraints. In addition, urgent requests may be requested at an uncertain time, and delivering in a short time may be crucial. To address this issue, we proposed a novel framework that considers the limitations of the UAVs and dynamically requested packages. These previously unknown packages have source–destination pairs and delivery time intervals. Furthermore, we utilize deep reinforcement learning (DRL) algorithms, deep Q-network (DQN), proximal policy optimization (PPO), and advantage actor–critic (A2C) to overcome this unknown environment and requests. The comprehensive experimental results demonstrate that the PPO algorithm has a faster and more stable training performance than the other DRL algorithms in two different environmental setups. Also, we implemented an extension version of a Brute-force (BF) algorithm, assuming that all requests and environments are known in advance. The PPO algorithm performs very close to the success rate of the BF algorithm.},
  archive      = {J_TNNLS},
  author       = {Erdal Akin},
  doi          = {10.1109/TNNLS.2023.3341471},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2608-2618},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep reinforcement learning-based multirestricted dynamic-request transportation framework},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to predict gradients for semi-supervised continual
learning. <em>TNNLS</em>, <em>36</em>(2), 2593–2607. (<a
href="https://doi.org/10.1109/TNNLS.2024.3361375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A key challenge for machine intelligence is to learn new visual concepts without forgetting the previously acquired knowledge. Continual learning (CL) is aimed toward addressing this challenge. However, there still exists a gap between CL and human learning. In particular, humans are able to continually learn from the samples associated with known or unknown labels in their daily lives, whereas existing CL and semi-supervised CL (SSCL) methods assume that the training samples are associated with known labels. Specifically, we are interested in two questions: 1) how to utilize unrelated unlabeled data for the SSCL task and 2) how unlabeled data affect learning and catastrophic forgetting in the CL task. To explore these issues, we formulate a new SSCL method, which can be generically applied to existing CL models. Furthermore, we propose a novel gradient learner to learn from labeled data to predict gradients on unlabeled data. In this way, the unlabeled data can fit into the supervised CL framework. We extensively evaluate the proposed method on mainstream CL methods, adversarial CL (ACL), and semi-supervised learning (SSL) tasks. The proposed method achieves state-of-the-art performance on classification accuracy and backward transfer (BWT) in the CL setting while achieving the desired performance on classification accuracy in the SSL setting. This implies that the unlabeled images can enhance the generalizability of CL models on the predictive ability of unseen data and significantly alleviate catastrophic forgetting. The code is available at https://github.com/luoyan407/grad_prediction.git.},
  archive      = {J_TNNLS},
  author       = {Yan Luo and Yongkang Wong and Mohan Kankanhalli and Qi Zhao},
  doi          = {10.1109/TNNLS.2024.3361375},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2593-2607},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learning to predict gradients for semi-supervised continual learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FADngs: Federated learning for anomaly detection.
<em>TNNLS</em>, <em>36</em>(2), 2578–2592. (<a
href="https://doi.org/10.1109/TNNLS.2024.3350660">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing demand for data privacy, federated learning (FL) has gained popularity for various applications. Most existing FL works focus on the classification task, overlooking those scenarios where anomaly detection may also require privacy-preserving. Traditional anomaly detection algorithms cannot be directly applied to the FL setting due to false and missing detection issues. Moreover, with common aggregation methods used in FL (e.g., averaging model parameters), the global model cannot keep the capacities of local models in discriminating anomalies deviating from local distributions, which further degrades the performance. For the aforementioned challenges, we propose Federated Anomaly Detection with Noisy Global Density Estimation, and Self-supervised Ensemble Distillation (FADngs). Specifically, FADngs aligns the knowledge of data distributions from each client by sharing processed density functions. Besides, FADngs trains local models in an improved contrastive learning way that learns more discriminative representations specific for anomaly detection based on the shared density functions. Furthermore, FADngs aggregates capacities by ensemble distillation, which distills the knowledge learned from different distributions to the global model. Our experiments demonstrate that the proposed method significantly outperforms state-of-the-art federated anomaly detection methods. We also empirically show that the shared density function is privacy-preserving. The code for the proposed method is provided for research purposes https://github.com/kanade00/Federated_Anomaly_detection.},
  archive      = {J_TNNLS},
  author       = {Boyu Dong and Dong Chen and Yu Wu and Siliang Tang and Yueting Zhuang},
  doi          = {10.1109/TNNLS.2024.3350660},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2578-2592},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {FADngs: Federated learning for anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-instance nonparallel tube learning. <em>TNNLS</em>,
<em>36</em>(2), 2563–2577. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347449">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In multi-instance nonparallel plane learning (NPL), the training set is comprised of bags of instances and the nonparallel planes are trained to classify the bags. Most of the existing multi-instance NPL methods are proposed based on a twin support vector machine (TWSVM). Similar to TWSVM, they use only a single plane to generalize the data occurrence of one class and do not sufficiently consider the boundary information, which may lead to the limitation of their classification accuracy. In this article, we propose a multi-instance nonparallel tube learning (MINTL) method. Distinguished from the existing multi-instance NPL methods, MINTL embeds the boundary information into the classifier by learning a large-margin-based $\epsilon $ -tube for each class, such that the boundary information can be incorporated into refining the classifier and further improving the performance. Specifically, given a $K$ -class multi-instance dataset, MINTL seeks $K~\epsilon $ -tubes, one for each class. In multi-instance learning, each positive bag contains at least one positive instance. To build up the $\epsilon _{k}$ -tube of class $k$ , we require that each bag of class $k$ should have at least one instance included in the $\epsilon _{k}$ -tube. Moreover, except for one instance included in the $\epsilon _{k}$ -tube, the remaining instances in the positive bag may include positive instances or irrelevant instances, and their labels are unavailable. A large margin constraint is presented to assign the remaining instances either inside the $\epsilon _{k}$ -tube or outside the $\epsilon _{k}$ -tube with a large margin. Substantial experiments on real-world datasets have shown that MINTL obtains significantly better classification accuracy than the existing multi-instance NPL methods.},
  archive      = {J_TNNLS},
  author       = {Yanshan Xiao and Bo Liu and Zhifeng Hao},
  doi          = {10.1109/TNNLS.2023.3347449},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2563-2577},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multi-instance nonparallel tube learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Memory-dependent computation and learning in spiking neural
networks through hebbian plasticity. <em>TNNLS</em>, <em>36</em>(2),
2551–2562. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) are the basis for many energy-efficient neuromorphic hardware systems. While there has been substantial progress in SNN research, artificial SNNs still lack many capabilities of their biological counterparts. In biological neural systems, memory is a key component that enables the retention of information over a huge range of temporal scales, ranging from hundreds of milliseconds up to years. While Hebbian plasticity is believed to play a pivotal role in biological memory, it has so far been analyzed mostly in the context of pattern completion and unsupervised learning in artificial and SNNs. Here, we propose that Hebbian plasticity is fundamental for computations in biological and artificial spiking neural systems. We introduce a novel memory-augmented SNN architecture that is enriched by Hebbian synaptic plasticity. We show that Hebbian enrichment renders SNNs surprisingly versatile in terms of their computational as well as learning capabilities. It improves their abilities for out-of-distribution generalization, one-shot learning, cross-modal generative association, language processing, and reward-based learning. This suggests that powerful cognitive neuromorphic systems can be built based on this principle.},
  archive      = {J_TNNLS},
  author       = {Thomas Limbacher and Ozan Özdenizci and Robert Legenstein},
  doi          = {10.1109/TNNLS.2023.3341446},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2551-2562},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Memory-dependent computation and learning in spiking neural networks through hebbian plasticity},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Source-free active domain adaptation via augmentation-based
sample query and progressive model adaptation. <em>TNNLS</em>,
<em>36</em>(2), 2538–2550. (<a
href="https://doi.org/10.1109/TNNLS.2023.3338294">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Active domain adaptation (ADA), which enormously improves the performance of unsupervised domain adaptation (UDA) at the expense of annotating limited target data, has attracted a surge of interest. However, in real-world applications, the source data in conventional ADA are not always accessible due to data privacy and security issues. To alleviate this dilemma, we introduce a more practical and challenging setting, dubbed as source-free ADA (SFADA), where one can select a small quota of target samples for label query to assist the model learning, but labeled source data are unavailable. Therefore, how to query the most informative target samples and mitigate the domain gap without the aid of source data are two key challenges in SFADA. To address SFADA, we propose a unified method SQAdapt via augmentation-based ${S}$ ample ${Q}$ uery and progressive model Adapt ation. In specific, an active selection module (ASM) is built for target label query, which exploits data augmentation to select the most informative target samples with high predictive sensitivity and uncertainty. Then, we further introduce a classifier adaptation module (CAM) to leverage both the labeled and unlabeled target data for progressively calibrating the classifier weights. Meanwhile, the source-like target samples with low selection scores are taken as source surrogates to realize the distribution alignment in the source-free scenario by the proposed distribution alignment module (DAM). Moreover, as a general active label query method, SQAdapt can be easily integrated into other source-free UDA (SFUDA) methods, and improve their performance. Comprehensive experiments on multiple benchmarks have shown that SQAdapt can achieve superior performance and even surpass most of the ADA methods.},
  archive      = {J_TNNLS},
  author       = {Shuang Li and Rui Zhang and Kaixiong Gong and Mixue Xie and Wenxuan Ma and Guangyu Gao},
  doi          = {10.1109/TNNLS.2023.3338294},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2538-2550},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Source-free active domain adaptation via augmentation-based sample query and progressive model adaptation},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIT: Mutual information topic model for diverse topic
extraction. <em>TNNLS</em>, <em>36</em>(2), 2523–2537. (<a
href="https://doi.org/10.1109/TNNLS.2024.3357698">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To automatically mine structured semantic topics from text, neural topic modeling has arisen and made some progress. However, most existing work focuses on designing a mechanism to enhance topic coherence but sacrificing the diversity of the extracted topics. To address this limitation, we propose the first neural-based topic modeling approach purely based on mutual information maximization, called the mutual information topic (MIT) model, in this article. The proposed MIT significantly improves topic diversity by maximizing the mutual information between word distribution and topic distribution. Meanwhile, MIT also utilizes Dirichlet prior in latent topic space to ensure the quality of mined topics. The experimental results on three publicly benchmark text corpora show that MIT could extract topics with higher coherence values (considering four topic coherence metrics) than competitive approaches and has a significant improvement on topic diversity metric. Besides, our experiments prove that the proposed MIT converges faster and more stable than adversarial-neural topic models.},
  archive      = {J_TNNLS},
  author       = {Rui Wang and Deyu Zhou and Haiping Huang and Yongquan Zhou},
  doi          = {10.1109/TNNLS.2024.3357698},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2523-2537},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MIT: Mutual information topic model for diverse topic extraction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AdaptCL: Adaptive continual learning for tackling
heterogeneity in sequential datasets. <em>TNNLS</em>, <em>36</em>(2),
2509–2522. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341841">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Managing heterogeneous datasets that vary in complexity, size, and similarity in continual learning presents a significant challenge. Task-agnostic continual learning is necessary to address this challenge, as datasets with varying similarity pose difficulties in distinguishing task boundaries. Conventional task-agnostic continual learning practices typically rely on rehearsal or regularization techniques. However, rehearsal methods may struggle with varying dataset sizes and regulating the importance of old and new data due to rigid buffer sizes. Meanwhile, regularization methods apply generic constraints to promote generalization but can hinder performance when dealing with dissimilar datasets lacking shared features, necessitating a more adaptive approach. In this article, we propose a novel adaptive continual learning (AdaptCL) method to tackle heterogeneity in sequential datasets. AdaptCL employs fine-grained data-driven pruning to adapt to variations in data complexity and dataset size. It also utilizes task-agnostic parameter isolation to mitigate the impact of varying degrees of catastrophic forgetting caused by differences in data similarity. Through a two-pronged case study approach, we evaluate AdaptCL on both datasets of MNIST variants and DomainNet, as well as datasets from different domains. The latter include both large-scale, diverse binary-class datasets and few-shot, multiclass datasets. Across all these scenarios, AdaptCL consistently exhibits robust performance, demonstrating its flexibility and general applicability in handling heterogeneous datasets.},
  archive      = {J_TNNLS},
  author       = {Yuqing Zhao and Divya Saxena and Jiannong Cao},
  doi          = {10.1109/TNNLS.2023.3341841},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2509-2522},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {AdaptCL: Adaptive continual learning for tackling heterogeneity in sequential datasets},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analytical uncertainty propagation in neural networks.
<em>TNNLS</em>, <em>36</em>(2), 2495–2508. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347156">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The usage of machine-learning techniques, such as neural networks, is common in a large variety of domains. Estimating the certainty of a predicted value is important when precise information is gained. Nevertheless, the forward propagation of uncertainty in machine-learning models is hardly understood. In general, providing error bars for measurements (measurement uncertainty) is crucial when high precision is needed for decision-making. The objective of this work is the development of an analytical method for aleatoric uncertainty forward propagation in neural networks, based on analytical uncertainty propagation well known from physics and engineering. With that, the method gives provable correct results. A benefit is that the method does not require a different training procedure, but only needs the weights and biases of the neural network and is computationally inexpensive. The analytical method is applied to real-world examples from the semiconductor industry (regression and image classification). Its usefulness is demonstrated by the provided examples, which show how meaningful error bars are when machine learning may be used for decision-making.},
  archive      = {J_TNNLS},
  author       = {Paul Jungmann and Julia Poray and Akash Kumar},
  doi          = {10.1109/TNNLS.2023.3347156},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2495-2508},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Analytical uncertainty propagation in neural networks},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid gromov–wasserstein embedding for capsule learning.
<em>TNNLS</em>, <em>36</em>(2), 2480–2494. (<a
href="https://doi.org/10.1109/TNNLS.2023.3348657">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Capsule networks (CapsNets) aim to parse images into a hierarchy of objects, parts, and their relationships using a two-step process involving part–whole transformation and hierarchical component routing. However, this hierarchical relationship modeling is computationally expensive, which has limited the wider use of CapsNet despite its potential advantages. The current state of CapsNet models primarily focuses on comparing their performance with capsule baselines, falling short of achieving the same level of proficiency as deep convolutional neural network (CNN) variants in intricate tasks. To address this limitation, we present an efficient approach for learning capsules that surpasses canonical baseline models and even demonstrates superior performance compared with high-performing convolution models. Our contribution can be outlined in two aspects: first, we introduce a group of subcapsules onto which an input vector is projected. Subsequently, we present the hybrid Gromov–Wasserstein (HGW) framework, which initially quantifies the dissimilarity between the input and the components modeled by the subcapsules, followed by determining their alignment degree through optimal transport (OT). This innovative mechanism capitalizes on new insights into defining alignment between the input and subcapsules, based on the similarity of their respective component distributions. This approach enhances CapsNets’ capacity to learn from intricate, high-dimensional data while retaining their interpretability and hierarchical structure. Our proposed model offers two distinct advantages: 1) its lightweight nature facilitates the application of capsules to more intricate vision tasks, including object detection; and 2) it outperforms baseline approaches in these demanding tasks. Our empirical findings illustrate that HGW capsules (HGWCapsules) exhibit enhanced robustness against affine transformations, scale effectively to larger datasets, and surpass CNN and CapsNet models across various vision tasks.},
  archive      = {J_TNNLS},
  author       = {Pourya Shamsolmoali and Masoumeh Zareapoor and Swagatam Das and Eric Granger and Salvador García},
  doi          = {10.1109/TNNLS.2023.3348657},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2480-2494},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hybrid Gromov–Wasserstein embedding for capsule learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SASAN: Shape-adaptive set abstraction network for
point-voxel 3D object detection. <em>TNNLS</em>, <em>36</em>(2),
2465–2479. (<a
href="https://doi.org/10.1109/TNNLS.2023.3339889">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Point-voxel 3D object detectors have achieved impressive performance in complex traffic scenes. However, they utilize the 3D sparse convolution (spconv) layers with fixed receptive fields, such as voxel-based detectors, and inherit the fixed sphere radius from point-based methods for generating the features of keypoints, which make them weak in adaptively modeling various geometrical deformations and sizes of real objects. To tackle this issue, we propose a shape-adaptive set abstraction network (SASAN) for point-voxel 3D object detection. First, the proposal and offset generation module is adopted to learn the coordinates and confidences of 3D proposals and shape-adaptive offsets of the certain number of offset points for each voxel. Meanwhile, an extra offset supervision task is employed to guide the learning of shifting values of offset points, aiming at motivating the predicted offsets to preferably adapt to the various shapes of objects. Then, the shape-adaptive set abstraction module is proposed to extract multiscale keypoints features by grouping the neighboring offset points’ features, as well as features learned from adjacent raw points and the 2-D bird-view map. Finally, the region of interest (RoI)-grid proposal refinement module is used to aggregate the keypoints features for further proposal refinement and confidence prediction. Extensive experiments on the competitive KITTI 3D detection benchmark demonstrate that the proposed SASAN gains superior performance as compared with state-of-the-art methods.},
  archive      = {J_TNNLS},
  author       = {Hui Zhang and Guiyang Luo and Xiao Wang and Yidong Li and Weiping Ding and Fei-Yue Wang},
  doi          = {10.1109/TNNLS.2023.3339889},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2465-2479},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {SASAN: Shape-adaptive set abstraction network for point-voxel 3D object detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deeply supervised block-wise neural architecture search.
<em>TNNLS</em>, <em>36</em>(2), 2451–2464. (<a
href="https://doi.org/10.1109/TNNLS.2023.3347542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) has shown great promise in automatically designing neural network models. Recently, block-wise NAS has been proposed to alleviate deep coupling problem between architectures and weights existed in the well-known weight-sharing NAS, by training the huge weight-sharing supernet block-wisely. However, the existing block-wise NAS methods, which resort to either supervised distillation or self-supervised contrastive learning scheme to enable block-wise optimization, take massive computational cost. To be specific, the former introduces an external high-capacity teacher model, while the latter involves supernet-scale momentum model and requires a long training schedule. Considering this, in this work, we propose a resource-friendly deeply supervised block-wise NAS (DBNAS) method. In the proposed DBNAS, we construct a lightweight deeply-supervised module after each block to enable a simple supervised learning scheme and leverage ground-truth labels to indirectly supervise optimization of each block progressively. Besides, the deeply-supervised module is specifically designed as structural and functional condensation of the supernet, which establishes global awareness for progressive block-wise optimization and helps search for promising architectures. Experimental results show that the DBNAS method only takes less than 1 GPU day to search out promising architectures on the ImageNet dataset with less GPU memory footprint than the other block-wise NAS works. The best-performing model among the searched DBNAS family achieves 75.6% Top-1 accuracy on ImageNet, which is competitive with the state-of-the-art NAS models. Moreover, our DBNAS family models also achieve good transfer performance on CIFAR-10/100, as well as two downstream tasks: object detection and semantic segmentation.},
  archive      = {J_TNNLS},
  author       = {An Yang and Ying Liu and Chunguang Li and Qinyuan Ren},
  doi          = {10.1109/TNNLS.2023.3347542},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2451-2464},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deeply supervised block-wise neural architecture search},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSFlow: Multiscale flow-based framework for unsupervised
anomaly detection. <em>TNNLS</em>, <em>36</em>(2), 2437–2450. (<a
href="https://doi.org/10.1109/TNNLS.2023.3344118">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Unsupervised anomaly detection (UAD) attracts a lot of research interest and drives widespread applications, where only anomaly-free samples are available for training. Some UAD applications intend to locate the anomalous regions further even without any anomaly information. Although the absence of anomalous samples and annotations deteriorates the UAD performance, an inconspicuous, yet powerful statistics model, the normalizing flows, is appropriate for anomaly detection (AD) and localization in an unsupervised fashion. The flow-based probabilistic models, only trained on anomaly-free data, can efficiently distinguish unpredictable anomalies by assigning them much lower likelihoods than normal data. Nevertheless, the size variation of unpredictable anomalies introduces another inconvenience to the flow-based methods for high-precision AD and localization. To generalize the anomaly size variation, we propose a novel multiscale flow-based framework (MSFlow) composed of asymmetrical parallel flows followed by a fusion flow to exchange multiscale perceptions. Moreover, different multiscale aggregation strategies are adopted for image-wise AD and pixel-wise anomaly localization according to the discrepancy between them. The proposed MSFlow is evaluated on three AD datasets, significantly outperforming existing methods. Notably, on the challenging MVTec AD benchmark, our MSFlow achieves a new state-of-the-art (SOTA) with a detection AUORC score of up to 99.7%, localization AUCROC score of 98.8% and PRO score of 97.1%.},
  archive      = {J_TNNLS},
  author       = {Yixuan Zhou and Xing Xu and Jingkuan Song and Fumin Shen and Heng Tao Shen},
  doi          = {10.1109/TNNLS.2023.3344118},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2437-2450},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MSFlow: Multiscale flow-based framework for unsupervised anomaly detection},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Transferability-guided cross-domain cross-task transfer
learning. <em>TNNLS</em>, <em>36</em>(2), 2423–2436. (<a
href="https://doi.org/10.1109/TNNLS.2024.3358094">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose two novel transferability metrics fast optimal transport-based conditional entropy (F-OTCE) and joint correspondence OTCE (JC-OTCE) to evaluate how much the source model (task) can benefit the learning of the target task and to learn more generalizable representations for cross-domain cross-task transfer learning. Unlike the original OTCE metric that requires evaluating the empirical transferability on auxiliary tasks, our metrics are auxiliary-free such that they can be computed much more efficiently. Specifically, F-OTCE estimates transferability by first solving an optimal transport (OT) problem between source and target distributions and then uses the optimal coupling to compute the negative conditional entropy (NCE) between the source and target labels. It can also serve as an objective function to enhance downstream transfer learning tasks including model finetuning and domain generalization (DG). Meanwhile, JC-OTCE improves the transferability accuracy of F-OTCE by including label distances in the OT problem, though it incurs additional computation costs. Extensive experiments demonstrate that F-OTCE and JC-OTCE outperform state-of-the-art auxiliary-free metrics by 21.1% and 25.8%, respectively, in correlation coefficient with the ground-truth transfer accuracy. By eliminating the training cost of auxiliary tasks, the two metrics reduce the total computation time of the previous method from 43 min to 9.32 and 10.78 s, respectively, for a pair of tasks. When applied in the model finetuning and DG tasks, F-OTCE shows significant improvements in the transfer accuracy in few-shot classification experiments, with up to 4.41% and 2.34% accuracy gains, respectively.},
  archive      = {J_TNNLS},
  author       = {Yang Tan and Enming Zhang and Yang Li and Shao-Lun Huang and Xiao-Ping Zhang},
  doi          = {10.1109/TNNLS.2024.3358094},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2423-2436},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Transferability-guided cross-domain cross-task transfer learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MDEformer: Mixed difference equation inspired transformer
for compressed video quality enhancement. <em>TNNLS</em>,
<em>36</em>(2), 2410–2422. (<a
href="https://doi.org/10.1109/TNNLS.2024.3354982">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning methods have achieved impressive performance in compressed video quality enhancement tasks. However, these methods rely excessively on practical experience by manually designing the network structure and do not fully exploit the potential of the feature information contained in the video sequences, i.e., not taking full advantage of the multiscale similarity of the compressed artifact information and not seriously considering the impact of the partition boundaries in the compressed video on the overall video quality. In this article, we propose a novel Mixed Difference Equation inspired Transformer (MDEformer) for compressed video quality enhancement, which provides a relatively reliable principle to guide the network design and yields a new insight into the interpretable transformer. Specifically, drawing on the graphical concept of the mixed difference equation (MDE), we utilize multiple cross-layer cross-attention aggregation (CCA) modules to establish long-range dependencies between encoders and decoders of the transformer, where partition boundary smoothing (PBS) modules are inserted as feedforward networks. The CCA module can make full use of the multiscale similarity of compression artifacts to effectively remove compression artifacts, and recover the texture and detail information of the frame. The PBS module leverages the sensitivity of smoothing convolution to partition boundaries to eliminate the impact of partition boundaries on the quality of compressed video and improve its overall quality, while not having too much impacts on non-boundary pixels. Extensive experiments on the MFQE 2.0 dataset demonstrate that the proposed MDEformer can eliminate compression artifacts for improving the quality of the compressed video, and surpasses the state-of-the-arts (SOTAs) in terms of both objective metrics and visual quality.},
  archive      = {J_TNNLS},
  author       = {Mingjin Zhang and Haichen Bai and Wenteng Shang and Jie Guo and Yunsong Li and Xinbo Gao},
  doi          = {10.1109/TNNLS.2024.3354982},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2410-2422},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {MDEformer: Mixed difference equation inspired transformer for compressed video quality enhancement},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multiview large margin distribution machine. <em>TNNLS</em>,
<em>36</em>(2), 2395–2409. (<a
href="https://doi.org/10.1109/TNNLS.2023.3349142">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Margin distribution has been proven to play a crucial role in improving generalization ability. In recent studies, many methods are designed using large margin distribution machine (LDM), which combines margin distribution with support vector machine (SVM), such that a better performance can be achieved. However, these methods are usually proposed based on single-view data and ignore the connection between different views. In this article, we propose a new multiview margin distribution model, called MVLDM, which constructs both multiview margin mean and variance. Besides, a framework is proposed to achieve multiview learning (MVL). MVLDM provides a new way to explore the utilization of complementary information in MVL from the perspective of margin distribution and satisfies both the consistency principle and the complementarity principle. In the theoretical analysis, we used Rademacher complexity theory to analyze the consistency error bound and generalization error bound of the MVLDM. In the experiments, we constructed a new performance metric, the view consistency rate (VCR), for the characteristics of multiview data. The effectiveness of MVLDM was evaluated using both VCR and other traditional performance metrics. The experimental results show that MVLDM is superior to other benchmark methods.},
  archive      = {J_TNNLS},
  author       = {Kun Hu and Yingyuan Xiao and Wenguang Zheng and Wenxin Zhu and Ching-Hsien Hsu},
  doi          = {10.1109/TNNLS.2023.3349142},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2395-2409},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Multiview large margin distribution machine},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interleaved periodic event-triggered communications-based
distributed formation control for cooperative unmanned surface vessels.
<em>TNNLS</em>, <em>36</em>(2), 2382–2394. (<a
href="https://doi.org/10.1109/TNNLS.2024.3351218">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article addresses the distributed formation control issue of cooperative unmanned surface vessels (USVs) under interleaved periodic event-triggered communications. First, an adaptive event-based control protocol is designed, where the event-based neural network (NN) scheme is developed to compensate for uncertain model dynamics. Upon the designed control protocol, an interleaved periodic event-triggered mechanism (IPETM) is subsequently proposed to achieve the communication objective. Unlike the common continuous event-triggered methods and periodic event-triggered methods, in which multiple nodes are allowed to trigger their events at the same time, the proposed IPETM ensures that USVs detect their events at different times to avoid the simultaneous event triggering of different nodes. By this virtue, traffic jamming in common wireless environments can be prevented, such that potential communication delays and faults are naturally avoided. In addition, the event detecting instants of the presented IPETM are also discrete and periodic, such that it can be performed under low-computational frequencies. Through Lyapunov-based analysis, it is verified that all closed-loop signals can converge to an arbitrary small compact set with exponential convergence rates. Simulation results demonstrate the effectiveness and superiority of the proposed control scheme.},
  archive      = {J_TNNLS},
  author       = {Bin Zhou and Bing Huang and Yumin Su and Cheng Zhu},
  doi          = {10.1109/TNNLS.2024.3351218},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2382-2394},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Interleaved periodic event-triggered communications-based distributed formation control for cooperative unmanned surface vessels},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Compact goal representation learning via information
bottleneck in goal-conditioned reinforcement learning. <em>TNNLS</em>,
<em>36</em>(2), 2368–2381. (<a
href="https://doi.org/10.1109/TNNLS.2023.3344880">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose an Information bottleneck (IB) for Goal representation learning (InfoGoal), a self-supervised method for generalizable goal-conditioned reinforcement learning (RL). Goal-conditioned RL learns a policy from reward signals to predict actions for reaching desired goals. However, the policy would overfit the task-irrelevant information contained in the goal and may be falsely or ineffectively generalized to reach other goals. A goal representation containing sufficient task-relevant information and minimum task-irrelevant information is guaranteed to reduce generalization errors. However, in goal-conditioned RL, it is difficult to balance the tradeoff between task-relevant information and task-irrelevant information because of the sparse and delayed learning signals, i.e., reward signals, and the inevitable task-relevant information sacrifice caused by information compression. Our InfoGoal learns a minimum and sufficient goal representation with dense and immediate self-supervised learning signals. Meanwhile, InfoGoal adaptively adjusts the weight of information minimization to achieve maximum information compression with a reasonable sacrifice of task-relevant information. Consequently, InfoGoal enables policy to generate a targeted trajectory toward states where the desired goal can be found with high probability and broadly explores those states. We conduct experiments on both simulated and real-world tasks, and our method significantly outperforms baseline methods in terms of policy optimality and the success rate of reaching unseen test goals. Video demos are available at infogoal.github.io.},
  archive      = {J_TNNLS},
  author       = {Qiming Zou and Einoshin Suzuki},
  doi          = {10.1109/TNNLS.2023.3344880},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2368-2381},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Compact goal representation learning via information bottleneck in goal-conditioned reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Advancing spiking neural networks toward deep residual
learning. <em>TNNLS</em>, <em>36</em>(2), 2353–2367. (<a
href="https://doi.org/10.1109/TNNLS.2024.3355393">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the rapid progress of neuromorphic computing, inadequate capacity and insufficient representation power of spiking neural networks (SNNs) severely restrict their application scope in practice. Residual learning and shortcuts have been evidenced as an important approach for training deep neural networks, but rarely did previous work assessed their applicability to the specifics of SNNs. In this article, we first identify that this negligence leads to impeded information flow and the accompanying degradation problem in a spiking version of vanilla ResNet. To address this issue, we propose a novel SNN-oriented residual architecture termed MS-ResNet, which establishes membrane-based shortcut pathways, and further proves that the gradient norm equality can be achieved in MS-ResNet by introducing block dynamical isometry theory, which ensures the network can be well-behaved in a depth-insensitive way. Thus, we are able to significantly extend the depth of directly trained SNNs, e.g., up to 482 layers on CIFAR-10 and 104 layers on ImageNet, without observing any slight degradation problem. To validate the effectiveness of MS-ResNet, experiments on both frame-based and neuromorphic datasets are conducted. MS-ResNet104 achieves a superior result of 76.02% accuracy on ImageNet, which is the highest to the best of our knowledge in the domain of directly trained SNNs. Great energy efficiency is also observed, with an average of only one spike per neuron needed to classify an input sample. We believe our powerful and scalable models will provide strong support for further exploration of SNNs.},
  archive      = {J_TNNLS},
  author       = {Yifan Hu and Lei Deng and Yujie Wu and Man Yao and Guoqi Li},
  doi          = {10.1109/TNNLS.2024.3355393},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2353-2367},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Advancing spiking neural networks toward deep residual learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). KL-DNAS: Knowledge distillation-based latency
aware-differentiable architecture search for video motion magnification.
<em>TNNLS</em>, <em>36</em>(2), 2342–2352. (<a
href="https://doi.org/10.1109/TNNLS.2023.3346169">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Video motion magnification is the task of making subtle minute motions visible. Many times subtle motion occurs while being invisible to the naked eye, e.g., slight deformations in muscles of an athlete, small vibrations in the objects, microexpression, and chest movement while breathing. Magnification of such small motions has resulted in various applications like posture deformities detection, microexpression recognition, and studying the structural properties. State-of-the-art (SOTA) methods have fixed computational complexity, which makes them less suitable for applications requiring different time constraints, e.g., real-time respiratory rate measurement and microexpression classification. To solve this problem, we propose a knowledge distillation-based latency aware-differentiable architecture search (KL-DNAS) method for video motion magnification. To reduce memory requirements and to improve denoising characteristics, we use a teacher network to search the network by parts using knowledge distillation (KD). Furthermore, search among different receptive fields and multifeature connections are applied for individual layers. Also, a novel latency loss is proposed to jointly optimize the target latency constraint and output quality. We are able to find $2.8 \times $ smaller model than the SOTA method and better motion magnification with lesser distortions. https://github.com/jasdeep-singh-007/KL-DNAS.},
  archive      = {J_TNNLS},
  author       = {Jasdeep Singh and Subrahmanyam Murala and G. Sankara Raju Kosuru},
  doi          = {10.1109/TNNLS.2023.3346169},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2342-2352},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {KL-DNAS: Knowledge distillation-based latency aware-differentiable architecture search for video motion magnification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learn zero-constraint-violation safe policy in model-free
constrained reinforcement learning. <em>TNNLS</em>, <em>36</em>(2),
2327–2341. (<a
href="https://doi.org/10.1109/TNNLS.2023.3348422">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We focus on learning the zero-constraint-violation safe policy in model-free reinforcement learning (RL). Existing model-free RL studies mostly use the posterior penalty to penalize dangerous actions, which means they must experience the danger to learn from the danger. Therefore, they cannot learn a zero-violation safe policy even after convergence. To handle this problem, we leverage the safety-oriented energy functions to learn zero-constraint-violation safe policies and propose the safe set actor-critic (SSAC) algorithm. The energy function is designed to increase rapidly for potentially dangerous actions, locating the safe set on the action space. Therefore, we can identify the dangerous actions prior to taking them and achieve zero-constraint violation. Our major contributions are twofold. First, we use the data-driven methods to learn the energy function, which releases the requirement of known dynamics. Second, we formulate a constrained RL problem to solve the zero-violation policies. We prove that our Lagrangian-based constrained RL solutions converge to the constrained optimal zero-violation policies theoretically. The proposed algorithm is evaluated on the complex simulation environments and a hardware-in-loop (HIL) experiment with a real autonomous vehicle controller. Experimental results suggest that the converged policies in all environments achieve zero-constraint violation and comparable performance with model-based baseline.},
  archive      = {J_TNNLS},
  author       = {Haitong Ma and Changliu Liu and Shengbo Eben Li and Sifa Zheng and Wenchao Sun and Jianyu Chen},
  doi          = {10.1109/TNNLS.2023.3348422},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2327-2341},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Learn zero-constraint-violation safe policy in model-free constrained reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep progressive reinforcement learning-based flexible
resource scheduling framework for IRS and UAV-assisted MEC system.
<em>TNNLS</em>, <em>36</em>(2), 2314–2326. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341067">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The intelligent reflecting surface (IRS) and unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) system is widely used in temporary and emergency scenarios. Our goal is to minimize the energy consumption of the MEC system by jointly optimizing UAV locations, IRS phase shift, task offloading, and resource allocation with a variable number of UAVs. To this end, we propose a flexible resource scheduling (FRES) framework by employing a novel deep progressive reinforcement learning that includes the following innovations. First, a novel multitask agent is presented to deal with the mixed integer nonlinear programming (MINLP) problem. The multitask agent has two output heads designed for different tasks, in which a classified head is employed to make offloading decisions with integer variables while a fitting head is applied to solve resource allocation with continuous variables. Second, a progressive scheduler is introduced to adapt the agent to the varying number of UAVs by progressively adjusting a part of neurons in the agent. This structure can naturally accumulate experiences and be immune to catastrophic forgetting. Finally, a light taboo search (LTS) is introduced to enhance the global search of the FRES. The numerical results demonstrate the superiority of the FRES framework, which can make real-time and optimal resource scheduling even in dynamic MEC systems.},
  archive      = {J_TNNLS},
  author       = {Li Dong and Feibo Jiang and Minjie Wang and Yubo Peng and Xiaolong Li},
  doi          = {10.1109/TNNLS.2023.3341067},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2314-2326},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sampled-data state estimation for LSTM. <em>TNNLS</em>,
<em>36</em>(2), 2300–2313. (<a
href="https://doi.org/10.1109/TNNLS.2024.3359211">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article first introduces a sampled-data state estimator design method for continuous-time long short-term memory (LSTM) neural networks with irregularly sampled output. To this end, the structure of the LSTM is addressed to obtain its dynamic equation. As a result, the LSTM neural network is modeled as a continuous-time linear parameter-varying system that is dependent on the gate units. For this system, the sampled-data Luenberger- and Arcak-type state estimator design methods are presented in terms of linear matrix inequalities (LMIs) by using the properties of the gate units. Lastly, the proposed method not only provides a numerical example for analyzing absolute stability but also demonstrates it in practice by applying a pre-trained behavior generation model of a robot manipulator.},
  archive      = {J_TNNLS},
  author       = {Yongsik Jin and S. M. Lee},
  doi          = {10.1109/TNNLS.2024.3359211},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2300-2313},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Sampled-data state estimation for LSTM},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Approximate policy iteration with deep minimax average
bellman error minimization. <em>TNNLS</em>, <em>36</em>(2), 2288–2299.
(<a href="https://doi.org/10.1109/TNNLS.2023.3346992">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we investigate the utilization of deep approximate policy iteration (DAPI) in estimating the optimal action-value function $Q^{\ast}$ within the context of reinforcement learning, employing rectified linear unit (ReLU) ResNet as the underlying framework. The iterative process of DAPI incorporates the minimax average Bellman error minimization principle. It employs ReLU ResNet to estimate the fixed point of the Bellman equation, which is aligned with the estimated greedy policy. Through error propagation, we derive nonasymptotic error bounds between $Q^{\ast}$ and the estimated $Q$ function induced by the output greedy policy in DAPI. To effectively control the Bellman residual error, we address both the statistical and approximation errors associated with the $\alpha $ -mixing dependent data derived from Markov decision processes, using the techniques of empirical process and deep approximation theory, respectively. Furthermore, we present a novel generalization bound for ReLU ResNet in the presence of dependent data, as well as an approximation bound for ReLU ResNet within the Hölder class. Notably, this approximation bound contributes to a significant improvement in the dependence on the ambient dimension, transitioning from an exponential relationship to a polynomial one. The derived nonasymptotic error bounds explicitly depend on factors such as the sample size, the ambient dimension (in polynomial terms), and the width and depth of the neural networks. Consequently, these bounds serve as valuable theoretical guidelines for appropriately setting the hyperparameters, thereby enabling the achievement of the desired convergence rate during the training process of DAPI.},
  archive      = {J_TNNLS},
  author       = {Lican Kang and Yuhui Liu and Yuan Luo and Jerry Zhijian Yang and Han Yuan and Chang Zhu},
  doi          = {10.1109/TNNLS.2023.3346992},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2288-2299},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Approximate policy iteration with deep minimax average bellman error minimization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CDNA-SNN: A new spiking neural network for pattern
classification using neuronal assemblies. <em>TNNLS</em>,
<em>36</em>(2), 2274–2287. (<a
href="https://doi.org/10.1109/TNNLS.2024.3353571">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) mimic their biological counterparts more closely than their predecessors and are considered the third generation of artificial neural networks. It has been proven that networks of spiking neurons have a higher computational capacity and lower power requirements than sigmoidal neural networks. This article introduces a new type of SNN that draws inspiration and incorporates concepts from neuronal assemblies in the human brain. The proposed network, termed as class-dependent neuronal activation-based SNN (CDNA-SNN), assigns each neuron learnable values known as CDNAs which indicate the neuron’s average relative spiking activity in response to samples from different classes. A new learning algorithm that categorizes the neurons into different class assemblies based on their CDNAs is also presented. These neuronal assemblies are trained via a novel training method based on spike-timing-dependent plasticity (STDP) to have high activity for their associated class and low firing rate for other classes. Also, using CDNAs, a new type of STDP that controls the amount of plasticity based on the assemblies of pre- and postsynaptic neurons is proposed. The performance of CDNA-SNN is evaluated on five datasets from the University of California, Irvine (UCI) machine learning repository, as well as Modified National Institute of Standards and Technology (MNIST) and Fashion MNIST, using nested cross-validation (N-CV) for hyperparameter optimization. Our results show that CDNA-SNN significantly outperforms synaptic weight association training (SWAT) ( $p &amp;lt; 0.0005$ ) and SpikeProp ( $p &amp;lt; 0.05$ ) on 3/5 and self-regulating evolving spiking neural (SRESN) ( $p &amp;lt; 0.05$ ) on 2/5 UCI datasets while using the significantly lower number of trainable parameters. Furthermore, compared to other supervised, fully connected SNNs, the proposed SNN reaches the best performance for Fashion MNIST and comparable performance for MNIST and neuromorphic-MNIST (N-MNIST), also utilizing much less (1%–35%) parameters.},
  archive      = {J_TNNLS},
  author       = {Vahid Saranirad and Shirin Dora and Thomas Martin McGinnity and Damien Coyle},
  doi          = {10.1109/TNNLS.2024.3353571},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2274-2287},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {CDNA-SNN: A new spiking neural network for pattern classification using neuronal assemblies},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analysis and application of matrix-form neural networks for
fast matrix-variable convex optimization. <em>TNNLS</em>,
<em>36</em>(2), 2259–2273. (<a
href="https://doi.org/10.1109/TNNLS.2023.3340730">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Matrix-variable optimization is a generalization of vector-variable optimization and has been found to have many important applications. To reduce computation time and storage requirement, this article presents two matrix-form recurrent neural networks (RNNs), one continuous-time model and another discrete-time model, for solving matrix-variable optimization problems with linear constraints. The two proposed matrix-form RNNs have low complexity and are suitable for parallel implementation in terms of matrix state space. The proposed continuous-time matrix-form RNN can significantly generalize existing continuous-time vector-form RNN. The proposed discrete-time matrix-form RNN can be effectively used in blind image restoration, where the storage requirement and computational cost are largely reduced. Theoretically, the two proposed matrix-form RNNs are guaranteed to be globally convergent to the optimal solution under mild conditions. Computed results show that the proposed matrix-form RNN-based algorithm is superior to related vector-form RNN and matrix-form RNN-based algorithms, in terms of computation time.},
  archive      = {J_TNNLS},
  author       = {Youshen Xia and Tiantian Ye and Liqing Huang},
  doi          = {10.1109/TNNLS.2023.3340730},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2259-2273},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Analysis and application of matrix-form neural networks for fast matrix-variable convex optimization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Norest-net: Normal estimation neural network for 3-d noisy
point clouds. <em>TNNLS</em>, <em>36</em>(2), 2246–2258. (<a
href="https://doi.org/10.1109/TNNLS.2024.3352974">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The widely deployed ways to capture a set of unorganized points, e.g., merged laser scans, fusion of depth images, and structure-from- $x$ , usually yield a 3-D noisy point cloud. Accurate normal estimation for the noisy point cloud makes a crucial contribution to the success of various applications. However, the existing normal estimation wisdoms strive to meet a conflicting goal of simultaneously performing normal filtering and preserving surface features, which inevitably leads to inaccurate estimation results. We propose a normal estimation neural network (Norest-Net), which regards normal filtering and feature preservation as two separate tasks, so that each one is specialized rather than traded off. For full noise removal, we present a normal filtering network (NF-Net) branch by learning from the noisy height map descriptor (HMD) of each point to the ground-truth (GT) point normal; for surface feature recovery, we construct a normal refinement network (NR-Net) branch by learning from the bilaterally defiltered point normal descriptor (B-DPND) to the GT point normal. Moreover, NR-Net is detachable to be incorporated into the existing normal estimation methods to boost their performances. Norest-Net shows clear improvements over the state of the arts in both feature preservation and noise robustness on synthetic and real-world captured point clouds.},
  archive      = {J_TNNLS},
  author       = {Yingkui Zhang and Mingqiang Wei and Lei Zhu and Guibao Shen and Fu Lee Wang and Jing Qin and Qiong Wang},
  doi          = {10.1109/TNNLS.2024.3352974},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2246-2258},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Norest-net: Normal estimation neural network for 3-D noisy point clouds},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive intermittent pinning control for synchronization of
delayed nonlinear memristive neural networks with reaction–diffusion
items. <em>TNNLS</em>, <em>36</em>(2), 2234–2245. (<a
href="https://doi.org/10.1109/TNNLS.2023.3344515">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the global exponential synchronization problem is investigated for a class of delayed nonlinear memristive neural networks (MNNs) with reaction–diffusion items. First, using the Green formula, Lyapunov theory, and proposing a new fuzzy adaptive pinning control scheme, some novel algebraic criteria are obtained to ensure the exponential synchronization of the concerned networks. Furthermore, the corresponding control gains can be promptly adjusted based on the current states of partial nodes of the networks. Besides, a fuzzy adaptive aperiodically intermittent pinning control law is also designed to synchronize the fuzzy MNNs (FMNNs). The controller with intermittent mechanism can obtain appropriate rest time and save energy consumption. Finally, some numerical examples are provided to confirm the effectiveness of the results in this article.},
  archive      = {J_TNNLS},
  author       = {Qiwei Liu and Huaicheng Yan and Hao Zhang and Lu Zeng and Chaoyang Chen},
  doi          = {10.1109/TNNLS.2023.3344515},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2234-2245},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Adaptive intermittent pinning control for synchronization of delayed nonlinear memristive neural networks with Reaction–Diffusion items},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cooperative active learning-based dual control for
exploration and exploitation in autonomous search. <em>TNNLS</em>,
<em>36</em>(2), 2221–2233. (<a
href="https://doi.org/10.1109/TNNLS.2024.3349467">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, a multi-estimator based computationally efficient algorithm is developed for autonomous search in an unknown environment with an unknown source. Different from the existing approaches that require massive computational power to support nonlinear Bayesian estimation and complex decision-making process, an efficient cooperative active-learning-based dual control for exploration and exploitation (COAL-DCEE) is developed for source estimation and path planning. Multiple cooperative estimators are deployed for environment learning process, which is helpful to improving the search performance and robustness against noisy measurements. The number of estimators used in COAL-DCEE is much smaller than that of the particles required for Bayesian estimation in information-theoretic approaches. Consequently, the computational load is significantly reduced. As an important feature of this study, the convergence and performance of COAL-DCEE are established in relation to the characteristics of sensor noises and turbulence disturbances. Numerical and experimental studies have been carried out to verify the effectiveness of the proposed framework. Compared with the existing approaches, COAL-DCEE not only provides convergence guarantee but also yields comparable search performance using much less computational power.},
  archive      = {J_TNNLS},
  author       = {Zhongguo Li and Wen-Hua Chen and Jun Yang and Cunjia Liu},
  doi          = {10.1109/TNNLS.2024.3349467},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2221-2233},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Cooperative active learning-based dual control for exploration and exploitation in autonomous search},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid reinforced medical report generation with m-linear
attention and repetition penalty. <em>TNNLS</em>, <em>36</em>(2),
2206–2220. (<a
href="https://doi.org/10.1109/TNNLS.2023.3343391">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To reduce doctors’ workload, deep-learning-based automatic medical report generation has recently attracted more and more research efforts, where deep convolutional neural networks (CNNs) are employed to encode the input images, and recurrent neural networks (RNNs) are used to decode the visual features into medical reports automatically. However, these state-of-the-art methods mainly suffer from three shortcomings: 1) incomprehensive optimization; 2) low-order and unidimensional attention; and 3) repeated generation. In this article, we propose a hybrid reinforced medical report generation method with m-linear attention and repetition penalty mechanism (HReMRG-MR) to overcome these problems. Specifically, a hybrid reward with different weights is employed to remedy the limitations of single-metric-based rewards, and a local optimal weight search algorithm is proposed to significantly reduce the complexity of searching the weights of the rewards from exponential to linear. Furthermore, we use m-linear attention modules to learn multidimensional high-order feature interactions and to achieve multimodal reasoning, while a new repetition penalty is proposed to apply penalties to repeated terms adaptively during the model’s training process. Extensive experimental studies on two public benchmark datasets show that HReMRG-MR greatly outperforms the state-of-the-art baselines in terms of all metrics. The effectiveness and necessity of all components in HReMRG-MR are also proved by ablation studies. Additional experiments are further conducted and the results demonstrate that our proposed local optimal weight search algorithm can significantly reduce the search time while maintaining superior medical report generation performances.},
  archive      = {J_TNNLS},
  author       = {Zhenghua Xu and Wenting Xu and Ruizhi Wang and Junyang Chen and Chang Qi and Thomas Lukasiewicz},
  doi          = {10.1109/TNNLS.2023.3343391},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2206-2220},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Hybrid reinforced medical report generation with M-linear attention and repetition penalty},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Daily schedule recommendation in urban life based on deep
reinforcement learning. <em>TNNLS</em>, <em>36</em>(2), 2196–2205. (<a
href="https://doi.org/10.1109/TNNLS.2024.3353215">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In our daily lives, people frequently consider daily schedule to meet their needs, such as going to a barbershop for a haircut, then eating in a restaurant, and finally shopping in a supermarket. Reasonable activity location [or point-of-interest (POI)] and activity sequencing will help people save a lot of time and get better services. In this article, we propose a reinforcement learning-based deep activity factor balancing model to recommend a reasonable daily schedule according to user’s current location and needs. The proposed model consists of a deep activity factor balancing network (DAFB) and a reinforcement learning framework. First, the DAFB is proposed to fuse multiple factors that affect daily schedule recommendation (DSR). Then, a reinforcement learning framework based on policy gradient is used to learn the parameters of the DAFB. Further, on the feature storage based on the matrix method, we compress the feature storage space of the candidate POIs. Finally, the proposed method is compared with seven benchmark methods using two real-world datasets. Experimental results show that the proposed method is adaptive and effective.},
  archive      = {J_TNNLS},
  author       = {Jia Liu and Donghai Zhai and Wei Huang and Shenggong Ji and Junbo Zhang and Tianrui Li},
  doi          = {10.1109/TNNLS.2024.3353215},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2196-2205},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Daily schedule recommendation in urban life based on deep reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Biphasic face photo-sketch synthesis via semantic-driven
generative adversarial network with graph representation learning.
<em>TNNLS</em>, <em>36</em>(2), 2182–2195. (<a
href="https://doi.org/10.1109/TNNLS.2023.3341246">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Biphasic face photo-sketch synthesis has significant practical value in wide-ranging fields such as digital entertainment and law enforcement. Previous approaches directly generate the photo-sketch in a global view, they always suffer from the low quality of sketches and complex photograph variations, leading to unnatural and low-fidelity results. In this article, we propose a novel semantic-driven generative adversarial network to address the above issues, cooperating with graph representation learning. Considering that human faces have distinct spatial structures, we first inject class-wise semantic layouts into the generator to provide style-based spatial information for synthesized face photographs and sketches. In addition, to enhance the authenticity of details in generated faces, we construct two types of representational graphs via semantic parsing maps upon input faces, dubbed the intraclass semantic graph (IASG) and the interclass structure graph (IRSG). Specifically, the IASG effectively models the intraclass semantic correlations of each facial semantic component, thus producing realistic facial details. To preserve the generated faces being more structure-coordinated, the IRSG models interclass structural relations among every facial component by graph representation learning. To further enhance the perceptual quality of synthesized images, we present a biphasic interactive cycle training strategy by fully taking advantage of the multilevel feature consistency between the photograph and sketch. Extensive experiments demonstrate that our method outperforms the state-of-the-art competitors on the CUHK Face Sketch (CUFS) and CUHK Face Sketch FERET (CUFSF) datasets.},
  archive      = {J_TNNLS},
  author       = {Xingqun Qi and Muyi Sun and Zijian Wang and Jiaming Liu and Qi Li and Fang Zhao and Shanghang Zhang and Caifeng Shan},
  doi          = {10.1109/TNNLS.2023.3341246},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2182-2195},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Biphasic face photo-sketch synthesis via semantic-driven generative adversarial network with graph representation learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A calibrator fuzzy ensemble for highly-accurate robot arm
calibration. <em>TNNLS</em>, <em>36</em>(2), 2169–2181. (<a
href="https://doi.org/10.1109/TNNLS.2024.3354080">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The absolute positioning accuracy of an industrial robot arm is vital for advancing manufacturing-related applications like automatic assembly, which can be improved via the data-driven approaches to robot arm calibration. Existing data-driven calibrators have illustrated their efficiency in addressing the issue of robot arm calibration. However, they mostly are single learning models that can be easily affected by the insufficient representation of the solution space, therefore, suffering from the calibration accuracy loss. To address this issue, this study proposes a calibrator fuzzy ensemble (CFE) with twofold ideas: 1) implementing eight data-driven calibrators relying on different sophisticated machine learning algorithms for an industrial robot arm, which guarantees the accuracy of individual base models and 2) innovatively developing a fuzzy ensemble of the obtained eight diversified calibrators to obtain impressively high calibration accuracy for an industrial robot arm. Extensive experiments on an ABB IRB120 industrial robot implemented with MATLAB demonstrate that compared with state-of-the-art calibrators, CFE decreases the maximum error at 8.59%. Hence, it has great potential for real applications.},
  archive      = {J_TNNLS},
  author       = {Xin Luo and Zhibin Li and Wenbin Yue and Shuai Li},
  doi          = {10.1109/TNNLS.2024.3354080},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2169-2181},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A calibrator fuzzy ensemble for highly-accurate robot arm calibration},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global model selection for semi-supervised support vector
machine via solution paths. <em>TNNLS</em>, <em>36</em>(2), 2154–2168.
(<a href="https://doi.org/10.1109/TNNLS.2024.3354978">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised support vector machine (S3VM) is important because it can use plentiful unlabeled data to improve the generalization accuracy of traditional SVMs. In order to achieve good performance, it is necessary for S3VM to take some effective measures to select hyperparameters. However, model selection for semi-supervised models is still a key open problem. Existing methods for semi-supervised models to search for the optimal parameter values are usually computationally demanding, especially those ones with grid search. To address this challenging problem, in this article, we first propose solution paths of S3VM (SPS3VM), which can track the solutions of the nonconvex S3VM with respect to the hyperparameters. Specifically, we apply incremental and decremental learning methods to update the solution and let it satisfy the Karush–Kuhn–Tucker (KKT) conditions. Based on the SPS3VM and the piecewise linearity of model function, we can find the model with the minimum cross-validation (CV) error for the entire range of candidate hyperparameters by computing the error path of S3VM. Our SPS3VM is the first solution path algorithm for nonconvex optimization problem of semi-supervised learning models. We also provide the finite convergence analysis and computational complexity of SPS3VM. Experimental results on a variety of benchmark datasets not only verify that our SPS3VM can globally search the hyperparameters (regularization and ramp loss parameters) but also show a huge reduction of computational time while retaining similar or slightly better generalization performance compared with the grid search approach.},
  archive      = {J_TNNLS},
  author       = {Yajing Fan and Shuyang Yu and Bin Gu and Ziran Xiong and Zhou Zhai and Heng Huang and Yi Chang},
  doi          = {10.1109/TNNLS.2024.3354978},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2154-2168},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Global model selection for semi-supervised support vector machine via solution paths},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Knowledge-augmented deep learning and its applications: A
survey. <em>TNNLS</em>, <em>36</em>(2), 2133–2153. (<a
href="https://doi.org/10.1109/TNNLS.2023.3338619">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models, though having achieved great success in many different fields over the past years, are usually data-hungry, fail to perform well on unseen samples, and lack interpretability. Different kinds of prior knowledge often exists in the target domain, and their use can alleviate the deficiencies with deep learning. To better mimic the behavior of human brains, different advanced methods have been proposed to identify domain knowledge and integrate it into deep models for data-efficient, generalizable, and interpretable deep learning, which we refer to as knowledge-augmented deep learning (KADL). In this survey, we define the concept of KADL and introduce its three major tasks, i.e., knowledge identification, knowledge representation, and knowledge integration. Different from existing surveys that are focused on a specific type of knowledge, we provide a broad and complete taxonomy of domain knowledge and its representations. Based on our taxonomy, we provide a systematic review of existing techniques, different from existing works that survey integration approaches agnostic to the taxonomy of knowledge. This survey subsumes existing works and offers a bird’s-eye view of research in the general area of KADL. The thorough and critical reviews of numerous papers help not only understand current progress but also identify future directions for the research on KADL.},
  archive      = {J_TNNLS},
  author       = {Zijun Cui and Tian Gao and Kartik Talamadupula and Qiang Ji},
  doi          = {10.1109/TNNLS.2023.3338619},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2133-2153},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Knowledge-augmented deep learning and its applications: A survey},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A statistical physics perspective: Understanding the
causality behind convolutional neural network adversarial vulnerability.
<em>TNNLS</em>, <em>36</em>(2), 2118–2132. (<a
href="https://doi.org/10.1109/TNNLS.2024.3359269">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adversarial vulnerability of convolutional neural networks (CNNs) refers to the performance degradation of CNNs under adversarial attacks, leading to incorrect decisions. However, the causes of adversarial vulnerability in CNNs remain unknown. To address this issue, we propose a unique cross-scale analytical approach from a statistical physics perspective. It reveals that the huge amount of nonlinear effects inherent in CNNs is the fundamental cause for the formation and evolution of system vulnerability. Vulnerability is spontaneously formed on the macroscopic level after the symmetry of the system is broken through the nonlinear interaction between microscopic state order parameters. We develop a cascade failure algorithm, visualizing how micro perturbations on neurons’ activation can cascade and influence macro decision paths. Our empirical results demonstrate the interplay between microlevel activation maps and macrolevel decision-making and provide a statistical physics perspective to understand the causality behind CNN vulnerability. Our work will help subsequent research to improve the adversarial robustness of CNNs.},
  archive      = {J_TNNLS},
  author       = {Ke Wang and Mingjia Zhu and Zicong Chen and Jian Weng and Ming Li and Siu-Ming Yiu and Weiping Ding and Tianlong Gu},
  doi          = {10.1109/TNNLS.2024.3359269},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2118-2132},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {A statistical physics perspective: Understanding the causality behind convolutional neural network adversarial vulnerability},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Estimating counterfactual treatment outcomes over time in
complex multiagent scenarios. <em>TNNLS</em>, <em>36</em>(2), 2103–2117.
(<a href="https://doi.org/10.1109/TNNLS.2024.3361166">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Evaluation of intervention in a multiagent system, for example, when humans should intervene in autonomous driving systems and when a player should pass to teammates for a good shot, is challenging in various engineering and scientific fields. Estimating the individual treatment effect (ITE) using counterfactual long-term prediction is practical to evaluate such interventions. However, most of the conventional frameworks did not consider the time-varying complex structure of multiagent relationships and covariate counterfactual prediction. This may lead to erroneous assessments of ITE and difficulty in interpretation. Here, we propose an interpretable, counterfactual recurrent network in multiagent systems to estimate the effect of the intervention. Our model leverages graph variational recurrent neural networks (GVRNNs) and theory-based computation with domain knowledge for the ITE estimation framework based on long-term prediction of multiagent covariates and outcomes, which can confirm the circumstances under which the intervention is effective. On simulated models of an automated vehicle and biological agents with time-varying confounders, we show that our methods achieved lower estimation errors in counterfactual covariates and the most effective treatment timing than the baselines. Furthermore, using real basketball data, our methods performed realistic counterfactual predictions and evaluated the counterfactual passes in shot scenarios.},
  archive      = {J_TNNLS},
  author       = {Keisuke Fujii and Koh Takeuchi and Atsushi Kuribayashi and Naoya Takeishi and Yoshinobu Kawahara and Kazuya Takeda},
  doi          = {10.1109/TNNLS.2024.3361166},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2103-2117},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Estimating counterfactual treatment outcomes over time in complex multiagent scenarios},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Deep ensemble transformers for dimensionality reduction.
<em>TNNLS</em>, <em>36</em>(2), 2091–2102. (<a
href="https://doi.org/10.1109/TNNLS.2024.3357621">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We propose deep ensemble transformers (DETs), a fast, scalable approach for dimensionality reduction problems. This method leverages the power of deep neural networks and employs cascade ensemble techniques as its fundamental feature extraction tool. To handle high-dimensional data, our approach employs a flexible number of intermediate layers sequentially. These layers progressively transform the input data into decision tree predictions. To further enhance prediction performance, the output from the final intermediate layer is fed through a feed-forward neural network architecture for final prediction. We derive an upper bound of the disparity between the generalization error and the empirical error and demonstrate that it converges to zero. This highlights the generalizability of our method to parameter estimation and feature selection problems. In our experimental evaluations, DETs outperform existing models in terms of prediction accuracy, representation learning ability, and computational time. Specifically, the method achieves over 95% accuracy in gene expression data and can be trained on average 50% faster than traditional artificial neural networks (ANNs).},
  archive      = {J_TNNLS},
  author       = {Maria Nareklishvili and Marius Geitle},
  doi          = {10.1109/TNNLS.2024.3357621},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2091-2102},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Deep ensemble transformers for dimensionality reduction},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust few-shot learning without using any adversarial
samples. <em>TNNLS</em>, <em>36</em>(2), 2080–2090. (<a
href="https://doi.org/10.1109/TNNLS.2023.3336996">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The high cost of acquiring and annotating samples has made the “few-shot” learning problem of prime importance. Existing works mainly focus on improving performance on clean data and overlook robustness concerns on the data perturbed with adversarial noise. Recently, a few efforts have been made to combine the few-shot problem with the robustness objective using sophisticated meta-learning techniques. These methods rely on the generation of adversarial samples in every episode of training, which further adds to the computational burden. To avoid such time-consuming and complicated procedures, we propose a simple but effective alternative that does not require any adversarial samples. Inspired by the cognitive decision-making process in humans, we enforce high-level feature matching between the base class data and their corresponding low-frequency samples in the pretraining stage via self distillation. The model is then fine-tuned on the samples of novel classes where we additionally improve the discriminability of low-frequency query set features via cosine similarity. On a one-shot setting of the CIFAR-FS dataset, our method yields a massive improvement of 60.55% and 62.05% in adversarial accuracy on the projected gradient descent (PGD) and state-of-the-art auto attack, respectively, with a minor drop in clean accuracy compared to the baseline. Moreover, our method only takes $1.69\times $ of the standard training time while being $\approx 5\times $ faster than thestate-of-the-art adversarial meta-learning methods. The code is available at https://github.com/vcl-iisc/robust-few-shot-learning.},
  archive      = {J_TNNLS},
  author       = {Gaurav Kumar Nayak and Ruchit Rawal and Inder Khatri and Anirban Chakraborty},
  doi          = {10.1109/TNNLS.2023.3336996},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2080-2090},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Robust few-shot learning without using any adversarial samples},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information theoretic learning-enhanced dual-generative
adversarial networks with causal representation for robust OOD
generalization. <em>TNNLS</em>, <em>36</em>(2), 2066–2079. (<a
href="https://doi.org/10.1109/TNNLS.2023.3330864">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, machine/deep learning techniques are achieving remarkable success in a variety of intelligent control and management systems, promising to change the future of artificial intelligence (AI) scenarios. However, they still suffer from some intractable difficulty or limitations for model training, such as the out-of-distribution (OOD) issue, in modern smart manufacturing or intelligent transportation systems (ITSs). In this study, we newly design and introduce a deep generative model framework, which seamlessly incorporates the information theoretic learning (ITL) and causal representation learning (CRL) in a dual-generative adversarial network (Dual-GAN) architecture, aiming to enhance the robust OOD generalization in modern machine learning (ML) paradigms. In particular, an ITL- and CRL-enhanced Dual-GAN (ITCRL-DGAN) model is presented, which includes an autoencoder with CRL (AE-CRL) structure to aid the dual-adversarial training with causality-inspired feature representations and a Dual-GAN structure to improve the data augmentation in both feature and data levels. Following a newly designed feature separation strategy, a causal graph is built and improved based on the information theory, which can enhance the causally related factors among the separated core features and further enrich the feature representation with the counterfactual features via interventions based on the refined causal relationships. The ITL is incorporated to improve the extraction of low-dimensional feature representations and learn the optimized causal representations based on the idea of “information flow.” A dual-adversarial training mechanism is then developed, which not only enables the generator to expand the boundary of feature distribution in accordance with the optimized feature representation from AE-CRL, but also allows the discriminator to further verify and improve the quality of the augmented data for OOD generalization. Experiment and evaluation results based on an open-source dataset demonstrate the outstanding learning efficiency and classification performance of our proposed model for robust OOD generalization in modern smart applications compared with three baseline methods.},
  archive      = {J_TNNLS},
  author       = {Xiaokang Zhou and Xuzhe Zheng and Tian Shu and Wei Liang and Kevin I-Kai Wang and Lianyong Qi and Shohei Shimizu and Qun Jin},
  doi          = {10.1109/TNNLS.2023.3330864},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2066-2079},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Information theoretic learning-enhanced dual-generative adversarial networks with causal representation for robust OOD generalization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Celebrating diversity with subtask specialization in shared
multiagent reinforcement learning. <em>TNNLS</em>, <em>36</em>(2),
2051–2065. (<a
href="https://doi.org/10.1109/TNNLS.2023.3326744">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subtask decomposition offers a promising approach for achieving and comprehending complex cooperative behaviors in multiagent systems. Nonetheless, existing methods often depend on intricate high-level strategies, which can hinder interpretability and learning efficiency. To tackle these challenges, we propose a novel approach that specializes subtasks for subgroups by employing diverse observation representation encoders within information bottlenecks. Moreover, to enhance the efficiency of subtask specialization while promoting sophisticated cooperation, we introduce diversity in both optimization and neural network architectures. These advancements enable our method to achieve state-of-the-art performance and offer interpretable subtask factorization across various scenarios in Google Research Football (GRF).},
  archive      = {J_TNNLS},
  author       = {Chenghao Li and Tonghan Wang and Chengjie Wu and Qianchuan Zhao and Jun Yang and Chongjie Zhang},
  doi          = {10.1109/TNNLS.2023.3326744},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2051-2065},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Celebrating diversity with subtask specialization in shared multiagent reinforcement learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient approximations for matrix-based rényi’s entropy on
sequential data. <em>TNNLS</em>, <em>36</em>(2), 2040–2050. (<a
href="https://doi.org/10.1109/TNNLS.2023.3314089">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The matrix-based Rényi’s entropy (MBRE) has recently been introduced as a substitute for the original Rényi’s entropy that could be directly obtained from data samples, avoiding the expensive intermediate step of density estimation. Despite its remarkable success in a broad of information-related tasks, the computational cost of MBRE, however, becomes a bottleneck for large-scale applications. The challenge, when facing sequential data, is further amplified due to the requirement of large-scale eigenvalue decomposition on multiple dense kernel matrices constructed by sliding windows in the region of interest, resulting in $O(mn^{3})$ overall time complexity, where $m$ and $n$ denote the number and the size of windows, respectively. To overcome this issue, we adopt the static MBRE estimator together with a variance reduction criterion to develop randomized approximations for the target entropy, leading to high accuracy with substantially lower query complexity by utilizing the historical estimation results. Specifically, assuming that the changes of adjacent sliding windows are bounded by $\beta \ll 1$ , which is a trivial case in domains, e.g., time-series analysis, we lower the complexity by a factor of $\sqrt {\beta }$ . Polynomial approximation techniques are further adopted to support arbitrary $\alpha $ orders. In general, our algorithms achieve $O(mn^{2}\sqrt {\beta }st)$ total computational complexity, where $s, t \ll n$ denote the number of vector queries and the polynomial degrees, respectively. Theoretical upper and lower bounds are established in terms of the convergence rate for both $s$ and $t$ , and large-scale experiments on both simulation and real-world data are conducted to validate the effectiveness of our algorithms. The results show that our methods achieve promising speedup with only a trivial loss in performance.},
  archive      = {J_TNNLS},
  author       = {Yuxin Dong and Tieliang Gong and Hong Chen and Chen Li},
  doi          = {10.1109/TNNLS.2023.3314089},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2040-2050},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Efficient approximations for matrix-based rényi’s entropy on sequential data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable classification of benign-malignant pulmonary
nodules with neural networks and information bottleneck. <em>TNNLS</em>,
<em>36</em>(2), 2028–2039. (<a
href="https://doi.org/10.1109/TNNLS.2023.3303395">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computerized tomography (CT) is a clinically primary technique to differentiate benign-malignant pulmonary nodules for lung cancer diagnosis. Early classification of pulmonary nodules is essential to slow down the degenerative process and reduce mortality. The interactive paradigm assisted by neural networks is considered to be an effective means for early lung cancer screening in large populations. However, some inherent characteristics of pulmonary nodules in high-resolution CT images, e.g., diverse shapes and sparse distribution over the lung fields, have been inducing inaccurate results. On the other hand, most existing methods with neural networks are dissatisfactory from a lack of transparency. In order to overcome these obstacles, a united framework is proposed, including the classification and feature visualization stages, to learn distinctive features and provide visual results. Specifically, a bilateral scheme is employed to synchronously extract and aggregate global-local features in the classification stage, where the global branch is constructed to perceive deep-level features and the local branch is built to focus on the refined details. Furthermore, an encoder is built to generate some features, and a decoder is constructed to simulate decision behavior, followed by the information bottleneck viewpoint to optimize the objective. Extensive experiments are performed to evaluate our framework on two publicly available datasets, namely, 1) the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) and 2) the Lung and Colon Histopathological Image Dataset (LC25000). For instance, our framework achieves 92.98% accuracy and presents additional visualizations on the LIDC. The experiment results show that our framework can obtain outstanding performance and is effective to facilitate explainability. It also demonstrates that this united framework is a serviceable tool and further has the scalability to be introduced into clinical research.},
  archive      = {J_TNNLS},
  author       = {Haixing Zhu and Weipeng Liu and Zhifan Gao and Heye Zhang},
  doi          = {10.1109/TNNLS.2023.3303395},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2028-2039},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Explainable classification of benign-malignant pulmonary nodules with neural networks and information bottleneck},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constrained maximum cross-domain likelihood for domain
generalization. <em>TNNLS</em>, <em>36</em>(2), 2013–2027. (<a
href="https://doi.org/10.1109/TNNLS.2023.3292242">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a recent noticeable topic, domain generalization aims to learn a generalizable model on multiple source domains, which is expected to perform well on unseen test domains. Great efforts have been made to learn domain-invariant features by aligning distributions across domains. However, existing works are often designed based on some relaxed conditions which are generally hard to satisfy and fail to realize the desired joint distribution alignment. In this article, we propose a novel domain generalization method, which originates from an intuitive idea that a domain-invariant classifier can be learned by minimizing the Kullback–Leibler (KL)-divergence between posterior distributions from different domains. To enhance the generalizability of the learned classifier, we formalize the optimization objective as an expectation computed on the ground-truth marginal distribution. Nevertheless, it also presents two obvious deficiencies, one of which is the side-effect of entropy increase in KL-divergence and the other is the unavailability of ground-truth marginal distributions. For the former, we introduce a term named maximum in-domain likelihood to maintain the discrimination of the learned domain-invariant representation space. For the latter, we approximate the ground-truth marginal distribution with source domains under a reasonable convex hull assumption. Finally, a constrained maximum cross-domain likelihood (CMCL) optimization problem is deduced, by solving which the joint distributions are naturally aligned. An alternating optimization strategy is carefully designed to approximately solve this optimization problem. Extensive experiments on four standard benchmark datasets, i.e., Digits-DG, PACS, Office-Home, and miniDomainNet, highlight the superior performance of our method.},
  archive      = {J_TNNLS},
  author       = {Jianxin Lin and Yongqiang Tang and Junping Wang and Wensheng Zhang},
  doi          = {10.1109/TNNLS.2023.3292242},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2013-2027},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Constrained maximum cross-domain likelihood for domain generalization},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Asymptotic behavior of adversarial training in binary linear
classification. <em>TNNLS</em>, <em>36</em>(2), 2004–2012. (<a
href="https://doi.org/10.1109/TNNLS.2023.3290592">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training using empirical risk minimization (ERM) is the state-of-the-art method for defense against adversarial attacks, that is, against small additive adversarial perturbations applied to test data leading to misclassification. Despite being successful in practice, understanding the generalization properties of adversarial training in classification remains widely open. In this article, we take the first step in this direction by precisely characterizing the robustness of adversarial training in binary linear classification. Specifically, we consider the high-dimensional regime where the model dimension grows with the size of the training set at a constant ratio. Our results provide exact asymptotics for both standard and adversarial test errors under general $\ell _{q}$ -norm bounded perturbations ( $q \ge 1$ ) in both discriminative binary models and generative Gaussian-mixture models with correlated features. We use our sharp error formulae to explain how the adversarial and standard errors depend upon the over-parameterization ratio, the data model, and the attack budget. Finally, by comparing with the robust Bayes estimator, our sharp asymptotics allow us to study the fundamental limits of adversarial training.},
  archive      = {J_TNNLS},
  author       = {Hossein Taheri and Ramtin Pedarsani and Christos Thrampoulidis},
  doi          = {10.1109/TNNLS.2023.3290592},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {2004-2012},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Asymptotic behavior of adversarial training in binary linear classification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Sparse additive machine with the correntropy-induced loss.
<em>TNNLS</em>, <em>36</em>(2), 1989–2003. (<a
href="https://doi.org/10.1109/TNNLS.2023.3280349">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Sparse additive machines (SAMs) have shown competitive performance on variable selection and classification in high-dimensional data due to their representation flexibility and interpretability. However, the existing methods often employ the unbounded or nonsmooth functions as the surrogates of 0–1 classification loss, which may encounter the degraded performance for data with outliers. To alleviate this problem, we propose a robust classification method, named SAM with the correntropy-induced loss (CSAM), by integrating the correntropy-induced loss (C-loss), the data-dependent hypothesis space, and the weighted $\ell _{q,1}$ -norm regularizer ( $q\geq 1$ ) into additive machines. In theory, the generalization error bound is estimated via a novel error decomposition and the concentration estimation techniques, which shows that the convergence rate $\mathcal {O}(n^{-1/4})$ can be achieved under proper parameter conditions. In addition, the theoretical guarantee on variable selection consistency is analyzed. Experimental evaluations on both synthetic and real-world datasets consistently validate the effectiveness and robustness of the proposed approach.},
  archive      = {J_TNNLS},
  author       = {Peipei Yuan and Xinge You and Hong Chen and Yingjie Wang and Qinmu Peng and Bin Zou},
  doi          = {10.1109/TNNLS.2023.3280349},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {1989-2003},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Sparse additive machine with the correntropy-induced loss},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RSS-bagging: Improving generalization through the fisher
information of training data. <em>TNNLS</em>, <em>36</em>(2), 1974–1988.
(<a href="https://doi.org/10.1109/TNNLS.2023.3270559">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The bagging method has received much application and attention in recent years due to its good performance and simple framework. It has facilitated the advanced random forest method and accuracy-diversity ensemble theory. Bagging is an ensemble method based on simple random sampling (SRS) method with replacement. However, SRS is the most foundation sampling method in the field of statistics, where exists some other advanced sampling methods for probability density estimation. In imbalanced ensemble learning, down-sampling, over-sampling, and SMOTE methods have been proposed for generating base training set. However, these methods aim at changing the underlying distribution of data rather than simulating it better. The ranked set sampling (RSS) method uses auxiliary information to get more effective samples. The purpose of this article is to propose a bagging ensemble method based on RSS, which uses the ordering of objects related to the class to obtain more effective training sets. To explain its performance, we give a generalization bound of ensemble from the perspective of posterior probability estimation and Fisher information. On the basis of RSS sample having a higher Fisher information than SRS sample, the presented bound theoretically explains the better performance of RSS-Bagging. The experiments on 12 benchmark datasets demonstrate that RSS-Bagging statistically performs better than SRS-Bagging when the base classifiers are multinomial logistic regression (MLR) and support vector machine (SVM).},
  archive      = {J_TNNLS},
  author       = {Jieting Wang and Feijiang Li and Jue Li and Chenping Hou and Yuhua Qian and Jiye Liang},
  doi          = {10.1109/TNNLS.2023.3270559},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {1974-1988},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {RSS-bagging: Improving generalization through the fisher information of training data},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Community graph convolution neural network for alzheimer’s
disease classification and pathogenetic factors identification.
<em>TNNLS</em>, <em>36</em>(2), 1959–1973. (<a
href="https://doi.org/10.1109/TNNLS.2023.3269446">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a complex neural network system, the brain regions and genes collaborate to effectively store and transmit information. We abstract the collaboration correlations as the brain region gene community network (BG-CN) and present a new deep learning approach, such as the community graph convolutional neural network (Com-GCN), for investigating the transmission of information within and between communities. The results can be used for diagnosing and extracting causal factors for Alzheimer’s disease (AD). First, an affinity aggregation model for BG-CN is developed to describe intercommunity and intracommunity information transmission. Second, we design the Com-GCN architecture with intercommunity convolution and intracommunity convolution operations based on the affinity aggregation model. Through sufficient experimental validation on the AD neuroimaging initiative (ADNI) dataset, the design of Com-GCN matches the physiological mechanism better and improves the interpretability and classification performance. Furthermore, Com-GCN can identify lesioned brain regions and disease-causing genes, which may assist precision medicine and drug design in AD and serve as a valuable reference for other neurological disorders.},
  archive      = {J_TNNLS},
  author       = {Xia-An Bi and Ke Chen and Siyu Jiang and Sheng Luo and Wenyan Zhou and Zhaoxu Xing and Luyun Xu and Zhengliang Liu and Tianming Liu},
  doi          = {10.1109/TNNLS.2023.3269446},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {1959-1973},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Community graph convolution neural network for alzheimer’s disease classification and pathogenetic factors identification},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Guest editorial: Special issue on information theoretic
methods for the generalization, robustness, and interpretability of
machine learning. <em>TNNLS</em>, <em>36</em>(2), 1957–1958. (<a
href="https://doi.org/10.1109/TNNLS.2025.3525991">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_TNNLS},
  author       = {Badong Chen and Shujian Yu and Robert Jenssen and Jose C. Principe and Klaus-Robert Müller},
  doi          = {10.1109/TNNLS.2025.3525991},
  journal      = {IEEE Transactions on Neural Networks and Learning Systems},
  month        = {2},
  number       = {2},
  pages        = {1957-1958},
  shortjournal = {IEEE Trans. Neural Netw. Learn. Syst.},
  title        = {Guest editorial: Special issue on information theoretic methods for the generalization, robustness, and interpretability of machine learning},
  volume       = {36},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
