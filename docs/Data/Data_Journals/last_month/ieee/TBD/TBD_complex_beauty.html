<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TBD_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tbd---22">TBD - 22</h2>
<ul>
<li><details>
<summary>
(2025). Robust privacy-preserving federated item ranking in online
marketplaces: Exploiting platform reputation for effective aggregation.
<em>IEEE Transactions on Big Data</em>, <em>11</em>(1), 303–309. (<a
href="https://doi.org/10.1109/TBDATA.2024.3505055">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Online marketplaces often collect products to sell from several other platforms (and sellers) and produce a unique ranking/score of these products to users. Keeping as private the user preferences provided in each (individual) platform is a need and a challenge at the same time. We are currently used to rating items in the marketplace itself which, in turn, can produce more effective rankings. Hence, the shaping of an effective item ranking would require a sharing of the user ratings between the individual platforms and the marketplace, thus impacting users’ privacy. In this paper, we propose the initial steps towards a change of paradigm, where the ratings are kept as private in each platform. Under this paradigm, each platform produces its rankings, then aggregated by the marketplace, in a federated fashion. To ensure that the marketplace’s rankings maintain their effectiveness, we exploit the concept of reputation of the individual platform, so that the final marketplace ranking is weighted by the reputation of each platform providing its ranking. Experiments on three datasets, covering different use cases, show that our approach can produce effective rankings, improving robustness to attacks, while keeping user preference data private within each seller platform.},
  archive  = {J},
  author   = {Guilherme Ramos and Ludovico Boratto and Mirko Marras},
  doi      = {10.1109/TBDATA.2024.3505055},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {303-309},
  title    = {Robust privacy-preserving federated item ranking in online marketplaces: Exploiting platform reputation for effective aggregation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-modality and equity-aware graph pooling fusion: A bike
mobility prediction study. <em>IEEE Transactions on Big Data</em>,
<em>11</em>(1), 286–302. (<a
href="https://doi.org/10.1109/TBDATA.2024.3414280">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {We propose an equity-aware GRAph-fusion differentiable Pooling neural network to accurately predict the spatio-temporal urban mobility (e.g., station-level bike usage in terms of departures and arrivals) with Equity (GRAPE). GRAPE consists of two independent hierarchical graph neural networks for two mobility systems—one as a target graph (i.e., a bike sharing system) and the other as an auxiliary graph (e.g., a taxi system). We have designed a convolutional fusion mechanism to jointly fuse the target and auxiliary graph embeddings and extract the shared spatial and temporal mobility patterns within the embeddings to enhance prediction accuracy. To further improve the equity of bike sharing systems for diverse communities, we focus on the bike resource allocation and model prediction performance, and propose to regularize the predicted bike resource as well as the accuracy across advantaged and disadvantaged communities, and thus mitigate the potential unfairness in the predicted bike sharing usage. Our evaluation of over 23 million bike rides and 100 million taxi trips in New York City and Chicago has demonstrated GRAPE to outperform all of the baseline approaches in terms of prediction accuracy (by 15.80% for NYC and 50.55% for Chicago on average) and social equity awareness (by 32.44% and 24.43% in terms of resource fairness for NYC and Chicago, and 13.36% and 16.52% in terms of performance fairness).},
  archive  = {J},
  author   = {Xi Yang and Suining He and Kang G. Shin and Mahan Tabatabaie and Jing Dai},
  doi      = {10.1109/TBDATA.2024.3414280},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {286-302},
  title    = {Cross-modality and equity-aware graph pooling fusion: A bike mobility prediction study},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficiently transfer user profile across networks. <em>IEEE
Transactions on Big Data</em>, <em>11</em>(1), 271–285. (<a
href="https://doi.org/10.1109/TBDATA.2024.3414321">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {User profiling has very important applications for many downstream tasks. Most existing methods only focus on modeling user profiles of one social network with plenty of data. However, user profiles are difficult to acquire, especially when the data is scarce. Fortunately, we observed that similar users have similar behavior patterns in different social networks. Motivated by such observations, in this paper, we for the first time propose to study the user profiling problem from the transfer learning perspective. We design two efficient frameworks for User Profile transferring acrOss Networks, i.e., UPON and E-UPON. In UPON, we first design a novel graph convolutional networks based characteristic-aware domain attention model to find user dependencies within and between domains (i.e., social networks). We then design a dual-domain weighted adversarial learning method to address the domain shift problem existing in the transferring procedure. In E-UPON, we optimize UPON in terms of computational complexity and memory. Specifically, we design a mini-cluster gradient descent based graph representation algorithm to shrink the searching space and ensure parallel computation. Then we use an adaptive cluster matching method to adjust the clusters of users. Experimental results on Twitter-Foursquare dataset demonstrate that UPON and E-UPON outperform the state-of-the-art models.},
  archive  = {J},
  author   = {Mengting Diao and Zhongbao Zhang and Sen Su and Shuai Gao and Huafeng Cao and Junda Ye},
  doi      = {10.1109/TBDATA.2024.3414321},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {271-285},
  title    = {Efficiently transfer user profile across networks},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic recognition of cyberbullying in the web of things
and social media using deep learning framework. <em>IEEE Transactions on
Big Data</em>, <em>11</em>(1), 259–270. (<a
href="https://doi.org/10.1109/TBDATA.2024.3409939">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The Web of Things (WoT) is a network that facilitates the formation and distribution of information its users make. Young people nowadays, digital natives, have no trouble relating to others or joining groups online since they have grown up in a world where new technology has pushed communications to a nearly real-time level. Shared private messages, rumours, and sexual comments are all examples of online harassment that have led to several recent cases worldwide. Therefore, academics have been more interested in finding ways to recognise bullying conduct on these platforms. The effects of cyberbullying, a terrible form of online misbehaviour, are distressing. It takes several documents, but the text is predominant on social networks. Intelligent systems are required for the automatic detection of such occurrences. Most previous research has used standard machine-learning techniques to tackle this issue. The increasing pervasiveness of cyberbullying in WoT and other social media platforms is a significant cause for worry that calls for robust responses to prevent further harm. This study offers a unique method of leveraging the deep learning (DL) model binary coyote optimization-based Convolutional Neural Network (BCNN) in social networks to identify and classify cyberbullying. An essential part of this method is the combination of DL-based abuse detection and feature subset selection. To efficiently detect and address cases of cyberbullying via social media, the proposed system incorporates many crucial steps, including preprocessing, feature selection, and classification. A binary coyote optimization (BCO)-based feature subset selection method is presented to enhance classification efficiency. To improve the accuracy of cyberbullying categorization, the BCO algorithm efficiently chooses a selection of key characteristics. Cyberbullying must be tracked and classified across all internet channels, and Convolutional Neural Network (CNN) is constructed. With a best-case accuracy of 99.5% on Formspring, 99.7% on Twitter, and 99.3% on Wikipedia, the suggested algorithm successfully identified the vast majority of cyberbullying content.},
  archive  = {J},
  author   = {Fahd N. Al-Wesabi and Marwa Obayya and Jamal Alsamri and Rana Alabdan and Nojood O Aljehane and Sana Alazwari and Fahad F. Alruwaili and Manar Ahmed Hamza and A Swathi},
  doi      = {10.1109/TBDATA.2024.3409939},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {259-270},
  title    = {Automatic recognition of cyberbullying in the web of things and social media using deep learning framework},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CompanyKG: A large-scale heterogeneous graph for company
similarity quantification. <em>IEEE Transactions on Big Data</em>,
<em>11</em>(1), 247–258. (<a
href="https://doi.org/10.1109/TBDATA.2024.3407573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {In the investment industry, it is often essential to carry out fine-grained company similarity quantification for a range of purposes, including market mapping, competitor analysis, and mergers and acquisitions. We propose and publish a knowledge graph, named CompanyKG, to represent and learn diverse company features and relations. Specifically, 1.17 million companies are represented as nodes enriched with company description embeddings; and 15 different inter-company relations result in 51.06 million weighted edges. To enable a comprehensive assessment of methods for company similarity quantification, we have devised and compiled three evaluation tasks with annotated test sets: similarity prediction, competitor retrieval and similarity ranking. We present extensive benchmarking results for 11 reproducible predictive methods categorized into three groups: node-only, edge-only, and node+edge. To the best of our knowledge, CompanyKG is the first large-scale heterogeneous graph dataset originating from a real-world investment platform, tailored for quantifying inter-company similarity.},
  archive  = {J},
  author   = {Lele Cao and Vilhelm von Ehrenheim and Mark Granroth-Wilding and Richard Anselmo Stahl and Andrew McCornack and Armin Catovic and Dhiana Deva Cavalcanti Rocha},
  doi      = {10.1109/TBDATA.2024.3407573},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {247-258},
  title    = {CompanyKG: A large-scale heterogeneous graph for company similarity quantification},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Communication-efficient distributed learning via sparse and
adaptive stochastic gradient. <em>IEEE Transactions on Big Data</em>,
<em>11</em>(1), 234–246. (<a
href="https://doi.org/10.1109/TBDATA.2024.3407510">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Gradient-based optimization methods implemented on distributed computing architectures are increasingly used to tackle large-scale machine learning applications. A key bottleneck in such distributed systems is the high communication overhead for exchanging information, such as stochastic gradients, between workers. The inherent causes of this bottleneck are the frequent communication rounds and the full model gradient transmission in every round. In this study, we present SASG, a communication-efficient distributed algorithm that enjoys the advantages of sparse communication and adaptive aggregated stochastic gradients. By dynamically determining the workers who need to communicate through an adaptive aggregation rule and sparsifying the transmitted information, the SASG algorithm reduces both the overhead of communication rounds and the number of communication bits in the distributed system. For the theoretical analysis, we introduce an important auxiliary variable and define a new Lyapunov function to prove that the communication-efficient algorithm is convergent. The convergence result is identical to the sublinear rate of stochastic gradient descent, and our result also reveals that SASG scales well with the number of distributed workers. Finally, experiments on training deep neural networks demonstrate that the proposed algorithm can significantly reduce communication overhead compared to previous methods.},
  archive  = {J},
  author   = {Xiaoge Deng and Dongsheng Li and Tao Sun and Xicheng Lu},
  doi      = {10.1109/TBDATA.2024.3407510},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {234-246},
  title    = {Communication-efficient distributed learning via sparse and adaptive stochastic gradient},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Training large-scale graph neural networks via graph partial
pooling. <em>IEEE Transactions on Big Data</em>, <em>11</em>(1),
221–233. (<a href="https://doi.org/10.1109/TBDATA.2024.3403380">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Graph Neural Networks (GNNs) are powerful tools for graph representation learning, but they face challenges when applied to large-scale graphs due to substantial computational costs and memory requirements. To address scalability limitations, various methods have been proposed, including sampling-based and decoupling-based methods. However, these methods have their limitations: sampling-based methods inevitably discard some link information during the sampling process, while decoupling-based methods require alterations to the model&#39;s structure, reducing their adaptability to various GNNs. This paper proposes a novel graph pooling method, Graph Partial Pooling (GPPool), for scaling GNNs to large-scale graphs. GPPool is a versatile and straightforward technique that enhances training efficiency while simultaneously reducing memory requirements. GPPool constructs small-scale pooled graphs by pooling partial nodes into supernodes. Each pooled graph consists of supernodes and unpooled nodes, preserving valuable local and global information. Training GNNs on these graphs reduces memory demands and enhances their performance. Additionally, this paper provides a theoretical analysis of training GNNs using GPPool-constructed graphs from a graph diffusion perspective. It shows that a GNN can be transformed from a large-scale graph into pooled graphs with minimal approximation error. A series of experiments on datasets of varying scales demonstrates the effectiveness of GPPool.},
  archive  = {J},
  author   = {Qi Zhang and Yanfeng Sun and Shaofan Wang and Junbin Gao and Yongli Hu and Baocai Yin},
  doi      = {10.1109/TBDATA.2024.3403380},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {221-233},
  title    = {Training large-scale graph neural networks via graph partial pooling},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TAMT: Privacy-preserving task assignment with
multi-threshold range search for spatial crowdsourcing applications.
<em>IEEE Transactions on Big Data</em>, <em>11</em>(1), 208–220. (<a
href="https://doi.org/10.1109/TBDATA.2024.3403374">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Spatial crowdsourcing is a distributed computing paradigm that utilizes the collective intelligence of workers to perform complex tasks. How to achieve privacy-preserving task assignment in spatial crowdsourcing applications has been a popular research area. However, most of the existing task assignment schemes may reveal private and sensitive information of tasks or workers. Few schemes can support task assignment based on different attributes simultaneously, such as spatial, interest, etc. To study the above themes, in this paper, we propose one privacy-preserving task assignment scheme with multi-threshold range search for spatial crowdsourcing applications (TAMT). Specifically, we first define euclidean distance-based location search and Hamming distance-based interest search, which map the demands of the tasks and the interests of the workers into the binary vectors. Second, we deploy PKD-tree to index the task data leveraging the pivoting techniques and the triangular inequality of euclidean distance, and propose an efficient multi-threshold range search algorithm based on matrix encryption and decomposition technology. Furthermore, based on DT-PKC, we introduce a ciphertext-based secure comparison protocol to support multi-threshold range search for spatial crowdsourcing applications. Finally, comprehensive security analysis proves that our proposed TAMT is privacy-preserving. Meanwhile, theoretical analysis and experimental evaluation demonstrate that TAMT is practical and efficient.},
  archive  = {J},
  author   = {Haiyong Bao and Zhehong Wang and Rongxing Lu and Cheng Huang and Beibei Li},
  doi      = {10.1109/TBDATA.2024.3403374},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {208-220},
  title    = {TAMT: Privacy-preserving task assignment with multi-threshold range search for spatial crowdsourcing applications},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A universal and efficient multi-modal smart contract
vulnerability detection framework for big data. <em>IEEE Transactions on
Big Data</em>, <em>11</em>(1), 190–207. (<a
href="https://doi.org/10.1109/TBDATA.2024.3403376">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {A vulnerability or error in a smart contract will lead to serious consequences including loss of assets and leakage of user privacy. Established smart contract vulnerability detection tools define vulnerabilities through symbolic execution, fuzz testing, and other methods requiring extremely specialized security knowledge. Even so, with the development of vulnerability exploitation techniques, vulnerability detection tools customized by experts cannot cope with the deformation of existing vulnerabilities or unknown vulnerabilities. The vulnerability detection based on machine learning developed in recent years studies vulnerabilities from different dimensions and designs corresponding models to achieve a high detection rate. However, these methods usually only focus on some features of smart contracts, or the model itself does not have universality. Experimental results on the publicly large-scale dataset SmartBugs-Wild demonstrate that this paper&#39;s method not only outperforms existing methods in several metrics, but also is scalable, general, and requires less domain knowledge, providing a new idea for the development of smart contract vulnerability detection.},
  archive  = {J},
  author   = {Wenjuan Lian and Zikang Bao and Xinze Zhang and Bin Jia and Yang Zhang},
  doi      = {10.1109/TBDATA.2024.3403376},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {190-207},
  title    = {A universal and efficient multi-modal smart contract vulnerability detection framework for big data},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Parallelly running and privacy-preserving agglomerative
hierarchical clustering in outsourced cloud computing environments.
<em>IEEE Transactions on Big Data</em>, <em>11</em>(1), 174–189. (<a
href="https://doi.org/10.1109/TBDATA.2024.3403375">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {As a Big Data analysis technique, hierarchical clustering is helpful in summarizing data since it returns the clusters of the data and their clustering history. Cloud computing is the most suitable option to efficiently perform hierarchical clustering over numerous data. However, since compromised cloud service providers can cause serious privacy problems by revealing data, it is necessary to solve the problems prior to using the external cloud computing service. Privacy-preserving hierarchical clustering protocol in an outsourced computing environment has never been proposed in existing works. Existing protocols have several problems that limit the number of participating data owners or disclose the information of data. In this article, we propose a parallelly running and privacy-preserving agglomerative hierarchical clustering (ppAHC) over the union of datasets of multiple data owners in an outsourced computing environment, which is the first protocol to the best of our knowledge. The proposed ppAHC does not disclose any information about input and output, including the data access patterns. The proposed ppAHC is highly efficient and suitable for Big Data analysis to handle numerous data since its cost for one round is independent of the amount of data. It allows data owners without sufficient computing capability to participate in a collaborative hierarchical clustering.},
  archive  = {J},
  author   = {Jeongsu Park and Dong Hoon Lee},
  doi      = {10.1109/TBDATA.2024.3403375},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {174-189},
  title    = {Parallelly running and privacy-preserving agglomerative hierarchical clustering in outsourced cloud computing environments},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Towards real-time network intrusion detection with
image-based sequential packets representation. <em>IEEE Transactions on
Big Data</em>, <em>11</em>(1), 157–173. (<a
href="https://doi.org/10.1109/TBDATA.2024.3403394">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Machine learning (ML) and deep learning (DL) advancements have greatly enhanced anomaly detection of network intrusion detection systems (NIDS) by empowering them to analyze Big Data and extract patterns. ML/DL-based NIDS are trained using either flow-based or packet-based features. Flow-based NIDS are suitable for offline traffic analysis, while packet-based NIDS can analyze traffic and detect attacks in real-time. Current packet-based approaches analyze packets independently, overlooking the sequential nature of network communication. This results in biased models that exhibit increased false negatives and positives. Additionally, most literature-proposed packet-based NIDS capture only payload data, neglecting crucial information from packet headers. This oversight can impair the ability to identify header-level attacks, such as denial-of-service attacks. To address these limitations, we propose a novel artificial intelligence-enabled methodological framework for packet-based NIDS that effectively analyzes header and payload data and considers temporal connections among packets. Our framework transforms sequential packets into two-dimensional images. It then develops a convolutional neural network-based intrusion detection model to process these images and detect malicious activities. Through experiments using publicly available big datasets, we demonstrate that our framework is able to achieve high detection rates of 97.7% to 99% across different attack types and displays promising resilience against adversarial examples.},
  archive  = {J},
  author   = {Jalal Ghadermazi and Ankit Shah and Nathaniel D. Bastian},
  doi      = {10.1109/TBDATA.2024.3403394},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {157-173},
  title    = {Towards real-time network intrusion detection with image-based sequential packets representation},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-enabled secure collaborative model learning using
differential privacy for IoT-based big data analytics. <em>IEEE
Transactions on Big Data</em>, <em>11</em>(1), 141–156. (<a
href="https://doi.org/10.1109/TBDATA.2024.3394700">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {With the rise of Big data generated by Internet of Things (IoT) smart devices, there is an increasing need to leverage its potential while protecting privacy and maintaining confidentiality. Privacy and confidentiality in Big Data aims to enable data analysis and machine learning on large-scale datasets without compromising the dataset sensitive information. Usually current Big Data analytics models either efficiently achieves privacy or confidentiality. In this article, we aim to design a novel blockchain-enabled secured collaborative machine learning approach that provides privacy and confidentially on large scale datasets generated by IoT devices. Blockchain is used as secured platform to store and access data as well as to provide immutability and traceability. We also propose an efficient approach to obtain robust machine learning model through use of cryptographic techniques and differential privacy in which the data among involved parties is shared in a secured way while maintaining privacy and confidentiality of the data. The experimental evaluation along with security and performance analysis show that the proposed approach provides accuracy and scalability without compromising the privacy and security.},
  archive  = {J},
  author   = {Prakash Tekchandani and Abhishek Bisht and Ashok Kumar Das and Neeraj Kumar and Marimuthu Karuppiah and Pandi Vijayakumar and Youngho Park},
  doi      = {10.1109/TBDATA.2024.3394700},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {141-156},
  title    = {Blockchain-enabled secure collaborative model learning using differential privacy for IoT-based big data analytics},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). 3A multi-classification division-aggregation framework for
fake news detection. <em>IEEE Transactions on Big Data</em>,
<em>11</em>(1), 130–140. (<a
href="https://doi.org/10.1109/TBDATA.2024.3378098">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Nowadays, as human activities are shifting to social media, fake news detection has been a crucial problem. Existing methods ignore the classification difference in online news and cannot take full advantage of multi-classification knowledges. For example, when coping with a post “A mouse is frightened by a cat,” a model that learns “computer” knowledge tends to misunderstand “mouse” and give a fake label, but a model that learns “animal” knowledge tends to give a true label. Therefore, this research proposes a multi-classification division-aggregation framework to detect fake news, named $CKA$, which innovatively learns classification knowledges during training stages and aggregates them during prediction stages. It consists of three main components: a news characterizer, an ensemble coordinator, and a truth predictor. The news characterizer is responsible for extracting news features and obtaining news classifications. Cooperating with the news characterizer, the ensemble coordinator generates classification-specifical models for the maximum reservation of classification knowledges during the training stage, where each classification-specifical model maximizes the detection performance of fake news on corresponding news classifications. Further, to aggregate the classification knowledges during the prediction stage, the truth predictor uses the truth discovery technology to aggregate the predictions from different classification-specifical models based on reliability evaluation of classification-specifical models. Extensive experiments prove that our proposed $CKA$ outperforms state-of-the-art baselines in fake news detection.},
  archive  = {J},
  author   = {Wen Zhang and Haitao Fu and Huan Wang and Zhiguo Gong and Pan Zhou and Di Wang},
  doi      = {10.1109/TBDATA.2024.3378098},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {130-140},
  title    = {3A multi-classification division-aggregation framework for fake news detection},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous social event detection via hyperbolic graph
representations. <em>IEEE Transactions on Big Data</em>, <em>11</em>(1),
115–129. (<a href="https://doi.org/10.1109/TBDATA.2024.3381017">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Social events reflect the dynamics of society and, here, natural disasters and emergencies receive significant attention. The timely detection of these events can provide organisations and individuals with valuable information to reduce or avoid losses. However, due to the complex heterogeneities of the content and structure of social media, existing models can only learn limited information; large amounts of semantic and structural information are ignored. In addition, due to high labour costs, it is rare for social media datasets to include high-quality labels, which also makes it challenging for models to learn information from social media. In this study, we propose two hyperbolic graph representation-based methods for detecting social events from heterogeneous social media environments. For cases where a dataset has labels, we design a Hyperbolic Social Event Detection (HSED) model that converts complex social information into a unified social message graph. This model addresses the heterogeneity of social media, and, with this graph, the information in social media can be used to capture structural information based on the properties of hyperbolic space. For cases where the dataset is unlabelled, we design an Unsupervised Hyperbolic Social Event Detection (UHSED). This model is based on the HSED model but includes graph contrastive learning to make it work in unlabelled scenarios. Extensive experiments demonstrate the superiority of the proposed approaches.},
  archive  = {J},
  author   = {Zitai Qiu and Jia Wu and Jian Yang and Xing Su and Charu Aggarwal},
  doi      = {10.1109/TBDATA.2024.3381017},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {115-129},
  title    = {Heterogeneous social event detection via hyperbolic graph representations},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Feature subspace learning-based binary differential
evolution algorithm for unsupervised feature selection. <em>IEEE
Transactions on Big Data</em>, <em>11</em>(1), 99–114. (<a
href="https://doi.org/10.1109/TBDATA.2024.3378090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {It is a challenging task to select the informative features that can maintain the manifold structure in the original feature space. Many unsupervised feature selection methods still suffer the poor cluster performance in the selected feature subset. To tackle this problem, a feature subspace learning-based binary differential evolution algorithm is proposed for unsupervised feature selection. First, a new unsupervised feature selection framework based on evolutionary computation is designed, in which the feature subspace learning and the population search mechanism are combined into a unified unsupervised feature selection. Second, a local manifold structure learning strategy and a sample pseudo-label learning strategy are presented to calculate the importance of the selected feature subspace. Third, the binary differential evolution algorithm is developed to optimize the selected feature subspace, in which the binary information migration mutation operator and the adaptive crossover operator are designed to promote the searching for the global optimal feature subspace. Experimental results on various types of real-world datasets demonstrate that the proposed algorithm can obtain more informative feature subset and competitive cluster performance compared with eight state-of-the-art unsupervised feature selection methods.},
  archive  = {J},
  author   = {Tao Li and Yuhua Qian and Feijiang Li and Xinyan Liang and Zhi-Hui Zhan},
  doi      = {10.1109/TBDATA.2024.3378090},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {99-114},
  title    = {Feature subspace learning-based binary differential evolution algorithm for unsupervised feature selection},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning from crowds using graph neural networks with
attention mechanism. <em>IEEE Transactions on Big Data</em>,
<em>11</em>(1), 86–98. (<a
href="https://doi.org/10.1109/TBDATA.2024.3378100">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Crowdsourcing has been playing an essential role in machine learning since it can obtain a large number of labels in an economical and fast manner for training increasingly complex learning models. However, the application of crowdsourcing learning still faces several challenges such as the low quality of crowd labels and the urgent requirement for learning models adapting to the label noises. There have been many studies focusing on truth inference algorithms to improve the quality of labels obtained by crowdsourcing. Comparably, end-to-end predictive model learning in crowdsourcing scenarios, especially using cutting-edge deep learning techniques, is still in its infant stage. In this paper, we propose a novel graph convolutional network-based framework, namely CGNNAT, which models the correlation of instances by combining the GCN model with an attention mechanism to learn more representative node embeddings for a better understanding of the bias tendency of crowd workers. Furthermore, a specific projection processing layer is employed in CGNNAT to model the reliability of each crowd worker, which makes the model an end-to-end neural network directly trained by noisy crowd labels. Experimental results on several real-world and synthetic datasets show that the proposed CGNNAT outperforms state-of-the-art and classical methods in terms of label prediction.},
  archive  = {J},
  author   = {Jing Zhang and Ming Wu and Zeyi Sun and Cangqi Zhou},
  doi      = {10.1109/TBDATA.2024.3378100},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {86-98},
  title    = {Learning from crowds using graph neural networks with attention mechanism},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A distributed generative adversarial network for data
augmentation under vertical federated learning. <em>IEEE Transactions on
Big Data</em>, <em>11</em>(1), 74–85. (<a
href="https://doi.org/10.1109/TBDATA.2024.3375150">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Vertical federated learning can aggregate participant data features. To address the issue of insufficient overlapping data in vertical federated learning, this study presents a generative adversarial network model that allows distributed data augmentation. First, this study proposes a distributed generative adversarial network FeCGAN for multiple participants with insufficient overlapping data, considering the fact that the generative adversarial network can generate simulation samples. This network is suitable for multiple data sources and can augment participants’ local data. Second, to address the problem of learning divergence caused by different local distributions of multiple data sources, this study proposes the aggregation algorithm FedKL. It aggregates the feedback of the local discriminator to interact with the generator and learns the local data distribution more accurately. Finally, given the problem of data waste caused by the unavailability of nonoverlapping data, this study proposes a data augmentation method called VFeDA. It uses FeCGAN to generate pseudo features and expands more overlapping data, thereby improving the data use. Experiments showed that the proposed model is suitable for multiple data sources and can generate high-quality data.},
  archive  = {J},
  author   = {Yunpeng Xiao and Xufeng Li and Tun Li and Rong Wang and Yucai Pang and Guoyin Wang},
  doi      = {10.1109/TBDATA.2024.3375150},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {74-85},
  title    = {A distributed generative adversarial network for data augmentation under vertical federated learning},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PR3: Reversible and usability-enhanced visual privacy
protection via thumbnail preservation and data hiding. <em>IEEE
Transactions on Big Data</em>, <em>11</em>(1), 59–73. (<a
href="https://doi.org/10.1109/TBDATA.2024.3375155">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The image hosting platform is becoming increasingly popular due to its user-friendly features, but it is prone to causing privacy concerns. Only protecting privacy, in fact, can be easy to come true, but usability is frequently sacrificed. Visual privacy protection schemes aim to make a balance between privacy and usability, whereas they are often irreversible. Recently, some reversible visual privacy protection schemes have been proposed by preserving thumbnails (known as TPE). However, they either have excessive states in the Markov chain modeled by the scheme or cannot reverse losslessly. Meanwhile, images encrypted by existing TPE schemes can not embed additional information and thus the usability is limited to visual observation. In view of this, we pertinently propose a reversible and usability-enhanced visual privacy protection scheme (called PR3) based on thumbnail preservation and data hiding. In this scheme, we utilize the sum-preserving data embedding algorithm to substitute the the lowest seven bits of the image without changing the sum. Any data overflow resulting from the above process is stored in the vacated space of the most significant bits. The remaining space serves two purposes: embedding additional information and adjusting the image to approximate the thumbnail. Compared with existing TPE works, PR3 has fewer states in the Markov chain and supports lossless recovery of images. In addition, additional information can be embedded in the encrypted image to enhance usability.},
  archive  = {J},
  author   = {Ruoyu Zhao and Yushu Zhang and Wenying Wen and Xinpeng Zhang and Xiaochun Cao and Yong Xiang},
  doi      = {10.1109/TBDATA.2024.3375155},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {59-73},
  title    = {PR3: Reversible and usability-enhanced visual privacy protection via thumbnail preservation and data hiding},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FuzzyPPI: Large-scale interaction of human proteome at fuzzy
semantic space. <em>IEEE Transactions on Big Data</em>, <em>11</em>(1),
47–58. (<a href="https://doi.org/10.1109/TBDATA.2024.3375149">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {Large-scale protein-protein interaction (PPI) network of an organism provides key insights into its cellular and molecular functionalities, signaling pathways and underlying disease mechanisms. For any organism, the total unexplored protein interactions significantly outnumbers all known positive and negative interactions. For Human, all known PPI datasets contain only $\sim\!\! 5.61$ million positive and $\sim\!\! 0.76$ million negative interactions, which is $\sim\!\! 3.1$% of potential interactions. We have implemented a distributed algorithm in Apache Spark that evaluates a Human PPI network of $\sim \!\! 180$ million potential interactions resulting from 18 994 reviewed proteins for which Gene Ontology (GO) annotations are available. The computed scores have been validated against state-of-the-art methods on benchmark datasets. FuzzyPPI performed significantly better with an average F1 score of 0.62 compared to GOntoSim (0.39), GOGO (0.38), and Wang (0.38) when tested with the Gold Standard PPI Dataset. The resulting scores are published with a web server for non-commercial use at http://fuzzyppi.mimuw.edu.pl/. Moreover, conventional PPI prediction methods produce binary results, but in fact this is just a simplification as PPIs have strengths or probabilities and recent studies show that protein binding affinities may prove to be effective in detecting protein complexes, disease association analysis, signaling network reconstruction, etc. Keeping these in mind, our algorithm is based on a fuzzy semantic scoring function and produces probabilities of interaction.},
  archive  = {J},
  author   = {Anup Kumar Halder and Soumyendu Sekhar Bandyopadhyay and Witold Jedrzejewski and Subhadip Basu and Jacek Sroka},
  doi      = {10.1109/TBDATA.2024.3375149},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {47-58},
  title    = {FuzzyPPI: Large-scale interaction of human proteome at fuzzy semantic space},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hybrid optimization algorithm for detection of security
attacks in IoT-enabled cyber-physical systems. <em>IEEE Transactions on
Big Data</em>, <em>11</em>(1), 35–46. (<a
href="https://doi.org/10.1109/TBDATA.2024.3372368">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The Internet of Things (IoT) is being prominently used in smart cities and a wide range of applications in society. The benefits of IoT are evident, but cyber terrorism and security concerns inhibit many organizations and users from deploying it. Cyber-physical systems that are IoT-enabled might be difficult to secure since security solutions designed for general information/operational technology systems may not work as well in an environment. Thus, deep learning (DL) can assist as a powerful tool for building IoT-enabled cyber-physical systems with automatic anomaly detection. In this paper, two distinct DL models have been employed i.e., Deep Belief Network (DBN) and Convolutional Neural Network (CNN), considered hybrid classifiers, to create a framework for detecting attacks in IoT-enabled cyber-physical systems. However, DL models need to be trained in such a way that will increase their classification accuracy. Therefore, this paper also aims to present a new hybrid optimization algorithm called “Seagull Adapted Elephant Herding Optimization” (SAEHO) to tune the weights of the hybrid classifier. The “Hybrid Classifier + SAEHO” framework takes the feature extracted dataset as an input and classifies the network as either attack or benign. Using sensitivity, precision, accuracy, and specificity, two datasets were compared. In every performance metric, the proposed framework outperforms conventional methods.},
  archive  = {J},
  author   = {Amit Sagu and Nasib Singh Gill and Preeti Gulia and Ishaani Priyadarshini and Jyotir Moy Chatterjee},
  doi      = {10.1109/TBDATA.2024.3372368},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {35-46},
  title    = {Hybrid optimization algorithm for detection of security attacks in IoT-enabled cyber-physical systems},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge-DPSDG: An edge-based differential privacy protection
model for smart healthcare. <em>IEEE Transactions on Big Data</em>,
<em>11</em>(1), 21–34. (<a
href="https://doi.org/10.1109/TBDATA.2024.3366071">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The edge computing paradigm has revolutionized the healthcare sector, providing more real-time medical data processing and analysis, which also poses more serious privacy and security risks that must be carefully considered and addressed. Based on differential privacy, we presented an innovative privacy-preserving model named Edge-DPSDG (Edge-Differentially Private Synthetic Data Generator) for smart healthcare under edge computing. It also develops and evolves a privacy budget allocation mechanism. In a distributed environment, the privacy budget for local medical data is personalized by computing the Shapley value and the information entropy value of each attribute in the dataset, which takes into account the trade-off between data privacy and utility. Extensive experiments on three public medical datasets are performed to evaluate the performance of Edge-DPSDG on two metrics. For utility evaluation, Edge-DPSDG shows a best 21.29% accuracy improvement compared to the state-of-the-art; our privacy budget allocation mechanism improved existing models’ accuracy by up to 6.05%. For privacy evaluation, Edge-DPSDG shows that can effectively ensure the privacy of the original datasets. In addition, Edge-DPSDG helps smooth the data, and results in a 3.99% accuracy loss decrease over the non-private model.},
  archive  = {J},
  author   = {Moli Lyu and Zhiwei Ni and Qian Chen and Fenggang Li},
  doi      = {10.1109/TBDATA.2024.3366071},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {21-34},
  title    = {Edge-DPSDG: An edge-based differential privacy protection model for smart healthcare},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-centric graph learning: A survey. <em>IEEE Transactions
on Big Data</em>, <em>11</em>(1), 1–20. (<a
href="https://doi.org/10.1109/TBDATA.2024.3489412">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract = {The history of artificial intelligence (AI) has witnessed the significant impact of high-quality data on various deep learning models, such as ImageNet for AlexNet and ResNet. Recently, instead of designing more complex neural architectures as model-centric approaches, the attention of AI community has shifted to data-centric ones, which focuses on better processing data to strengthen the ability of neural models. Graph learning, which operates on ubiquitous topological data, also plays an important role in the era of deep learning. In this survey, we comprehensively review graph learning approaches from the data-centric perspective, and aim to answer three crucial questions: (1) when to modify graph data, (2) what part of the graph data needs modification to unlock the potential of various graph models, and (3) how to safeguard graph models from problematic data influence. Accordingly, we propose a novel taxonomy based on the stages in the graph learning pipeline, and highlight the processing methods for different data structures in the graph data, i.e., topology, feature and label. Furthermore, we analyze some potential problems embedded in graph data and discuss how to solve them in a data-centric manner. Finally, we provide some promising future directions for data-centric graph learning.},
  archive  = {J},
  author   = {Yuxin Guo and Deyu Bo and Cheng Yang and Zhiyuan Lu and Zhongjian Zhang and Jixi Liu and Yufei Peng and Chuan Shi},
  doi      = {10.1109/TBDATA.2024.3489412},
  journal  = {IEEE Transactions on Big Data},
  month    = {2},
  number   = {1},
  pages    = {1-20},
  title    = {Data-centric graph learning: A survey},
  volume   = {11},
  year     = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
