<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIFS_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tifs---80">TIFS - 80</h2>
<ul>
<li><details>
<summary>
(2025). Reconnaissance-strike complex: A network-layer solution to
the natural forking in blockchain. <em>TIFS</em>, <em>20</em>,
2022–2034. (<a href="https://doi.org/10.1109/TIFS.2024.3523767">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The natural forking severely compromises the security and wastes resources of Blockchain. Current analyses of the natural forking are carried out from microscale and macroscale perspectives, each facing challenges in generality and accuracy respectively. This results in dire straits that the forking arising from the network layer cannot be solved within the same layer, and existing defense schemes concentrate on the consensus layer, unfortunately coming at the expense of diminishing decentralized trust. Hence, to overcome these shortcomings, we propose the first reconnaissance-strike solution to the natural forking where the issue is recognized at the network layer and further struck on-site. Specifically, our endeavors encompass 1) analyzing the spatial-temporal transmission dynamics of the main chain. We exert mesoscale perspective by transforming the behavioral analysis of the transmitters (i.e., the nodes) into the movement analysis of the transmitted object (i.e., the main chain) which mitigates following Lévy mobility. Based on this, we quantify the dynamics of long-range leaping and short-range diffusion of the main chain transmission; 2) proposing a cost-effective anti-forking mechanism. This mechanism combats the forking with low cost by configuring logical connections at the network management level, based on the quantitative relationship between Blockchain network topology and the natural forking rate we have derived. Both theoretical analysis and extensive experiments verify that our scheme can maintain the natural forking rate not more than the given threshold in most cases.},
  archive      = {J_TIFS},
  author       = {Anlin Chen and Shengling Wang and Hongwei Shi and Yu Guo and Xiuzhen Cheng},
  doi          = {10.1109/TIFS.2024.3523767},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {2022-2034},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Reconnaissance-strike complex: A network-layer solution to the natural forking in blockchain},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Entire space counterfactual learning for reliable content
recommendations. <em>TIFS</em>, <em>20</em>, 1755–1764. (<a
href="https://doi.org/10.1109/TIFS.2024.3516584">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Post-click conversion rate (CVR) estimation is a fundamental task in developing effective recommender systems, yet it faces challenges from data sparsity and sample selection bias. To handle both challenges, the entire space multitask models are employed to decompose the user behavior track into a sequence of exposure $\rightarrow $ click $\rightarrow $ conversion, constructing surrogate learning tasks for CVR estimation. However, these methods suffer from two significant defects: (1) intrinsic estimation bias (IEB), where the CVR estimates are higher than the actual values; (2) false independence prior (FIP), where the causal relationship between clicks and subsequent conversions is potentially overlooked. To overcome these limitations, we develop a model-agnostic framework, namely Entire Space Counterfactual Multitask Model (ESCM2), which incorporates a counterfactual risk minimizer within the entire space multitask framework to regularize CVR estimation. Experiments conducted on large-scale industrial recommendation datasets and an online industrial recommendation service demonstrate that ESCM2 effectively mitigates IEB and FIP defects and substantially enhances recommendation performance.},
  archive      = {J_TIFS},
  author       = {Hao Wang and Zhichao Chen and Zhaoran Liu and Haozhe Li and Degui Yang and Xinggao Liu and Haoxuan Li},
  doi          = {10.1109/TIFS.2024.3516584},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1755-1764},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Entire space counterfactual learning for reliable content recommendations},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outer bounds on the CEO problem with privacy constraints.
<em>TIFS</em>, <em>20</em>, 1566–1581. (<a
href="https://doi.org/10.1109/TIFS.2024.3522775">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the rate-distortion-leakage region of the Chief Executive Officer (CEO) problem, considering the presence of a passive eavesdropper and privacy constraints. We start by examining the region where a general distortion measure quantifies the distortion. While the inner bound of the region is derived from previous work, this paper newly develops an outer bound. To derive the outer bound, we introduce a new lemma tailored for analyzing privacy constraints. Next, as a specific instance of the general distortion measure, we demonstrate that the tight bound for discrete and Gaussian sources is obtained when the eavesdropper has no side information, and the distortion is quantified by the log-loss distortion measure. We further investigate the rate-distortion-leakage region for a scenario where the eavesdropper has side information, and the distortion is quantified by the log-loss distortion measure and provide an outer bound for this case. The derived outer bound differs from the inner bound by only a minor quantity that appears in the constraints associated with the privacy-leakage rates, and these bounds match when the distortion is large.},
  archive      = {J_TIFS},
  author       = {Vamoua Yachongka and Hideki Yagi and Hideki Ochiai},
  doi          = {10.1109/TIFS.2024.3522775},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1566-1581},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Outer bounds on the CEO problem with privacy constraints},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Local differential privacy is not enough: A sample
reconstruction attack against federated learning with local differential
privacy. <em>TIFS</em>, <em>20</em>, 1519–1534. (<a
href="https://doi.org/10.1109/TIFS.2024.3515793">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Reconstruction attacks against federated learning (FL) aim to reconstruct users’ samples through users’ uploaded gradients. Local differential privacy (LDP) is regarded as an effective defense against various attacks, including sample reconstruction in FL, where gradients are clipped and perturbed. Existing attacks are ineffective in FL with LDP since clipped and perturbed gradients obliterate most sample information for reconstruction. Besides, existing attacks embed additional sample information into gradients to improve the attack effect and cause gradient expansion, leading to a more severe gradient clipping in FL with LDP. In this paper, we propose a sample reconstruction attack against LDP-based FL with any target models to reconstruct victims’ sensitive samples to illustrate that FL with LDP is not flawless. Considering gradient expansion in reconstruction attacks and noise in LDP, the core of the proposed attack is gradient compression and reconstructed sample denoising. For gradient compression, an inference structure based on sample characteristics is presented to reduce redundant gradients against LDP. For reconstructed sample denoising, we artificially introduce zero gradients to observe noise distribution and scale confidence interval to filter the noise. Theoretical proof guarantees the effectiveness of the proposed attack. Evaluations show that the proposed attack is the only attack that reconstructs victims’ training samples in LDP-based FL and has little impact on the target model’s accuracy. We conclude that LDP-based FL needs further improvements to defend against sample reconstruction attacks effectively.},
  archive      = {J_TIFS},
  author       = {Zhichao You and Xuewen Dong and Shujun Li and Ximeng Liu and Siqi Ma and Yulong Shen},
  doi          = {10.1109/TIFS.2024.3515793},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1519-1534},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Local differential privacy is not enough: A sample reconstruction attack against federated learning with local differential privacy},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). B-AVIBench: Toward evaluating the robustness of large
vision-language model on black-box adversarial visual-instructions.
<em>TIFS</em>, <em>20</em>, 1434–1446. (<a
href="https://doi.org/10.1109/TIFS.2024.3520306">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large Vision-Language Models (LVLMs) have shown significant progress in responding well to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent attacks. Despite the critical importance of LVLMs’ robustness against such threats, current research in this area remains limited. To bridge this gap, we introduce B-AVIBench, a framework designed to analyze the robustness of LVLMs when facing various Black-box Adversarial Visual-Instructions (B-AVIs), including four types of image-based B-AVIs, ten types of text-based B-AVIs, and nine types of content bias B-AVIs (such as gender, violence, cultural, and racial biases, among others). We generate 316K B-AVIs encompassing five categories of multimodal capabilities (ten tasks) and content bias. We then conduct a comprehensive evaluation involving 14 open-source LVLMs to assess their performance. B-AVIBench also serves as a convenient tool for practitioners to evaluate the robustness of LVLMs against B-AVIs. Our findings and extensive experimental results shed light on the vulnerabilities of LVLMs, and highlight that inherent biases exist even in advanced closed-source LVLMs like GeminiProVision and GPT-4V. This underscores the importance of enhancing the robustness, security, and fairness of LVLMs. The source code and benchmark are available at https://github.com/zhanghao5201/B-AVIBench.},
  archive      = {J_TIFS},
  author       = {Hao Zhang and Wenqi Shao and Hong Liu and Yongqiang Ma and Ping Luo and Yu Qiao and Nanning Zheng and Kaipeng Zhang},
  doi          = {10.1109/TIFS.2024.3520306},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1434-1446},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {B-AVIBench: Toward evaluating the robustness of large vision-language model on black-box adversarial visual-instructions},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient privacy-preserving scheme for weak password
collection in internet of things against perpetual leakage.
<em>TIFS</em>, <em>20</em>, 1405–1420. (<a
href="https://doi.org/10.1109/TIFS.2024.3523202">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Password-based authentication is widely applied in Internet of Things (IoT). It allows IoT devices to identify users with passwords to resist unauthorized access. However, choices of weak passwords, especially popular ones, might violate users’ privacy and lead to large-scale network attacks. Collection of popular passwords among IoT devices to establish blocklists via a service provider can prevent use of weak passwords. To protect unpopular passwords during collection, existing privacy-preserving schemes rely on expensive cryptographic primitives (e.g., garbled circuits and zero-knowledge proofs), which would impose heavy communication and computation burdens on constrained devices and hinder wide deployment of these schemes. In this paper, we propose EAGER+, an efficient privacy-preserving scheme for weak password collection in IoT against perpetual leakage. EAGER+ is mainly built on secret sharing and symmetric encryption, thereby enabling lightweight computation and communication on IoT devices. In EAGER+, we conceive a password-locked encryption with conditional decryption mechanism to efficiently identify popular passwords, where a password is essentially locked under itself in the encryption to guarantee its security, and the password can be revealed from the ciphertext by the service provider only if a sufficient number of devices exploit it. The mechanism is integrated with a servers-aided password-hardening mechanism to resist offline dictionary guessing attacks. Moreover, EAGER+ uses a key renewal mechanism to periodically update secrets for password hardening on key servers to thwart perpetual leakage towards the secrets. We formally analyze the security of EAGER+, and conduct experimental evaluations to show that EAGER+ is more efficient than existing schemes.},
  archive      = {J_TIFS},
  author       = {Changsong Jiang and Chunxiang Xu and Xinfeng Dong and Kefei Chen and Guomin Yang},
  doi          = {10.1109/TIFS.2024.3523202},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1405-1420},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {An efficient privacy-preserving scheme for weak password collection in internet of things against perpetual leakage},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Blockchain-empowered keyword searchable provable data
possession for large similar data. <em>TIFS</em>, <em>20</em>,
1374–1389. (<a href="https://doi.org/10.1109/TIFS.2024.3516563">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Provable Data Possession (PDP) is an alternative technique that guarantees the integrity of remote data. However, most current PDP schemes are inapplicable to similarity-like data checking with the same attribute, i.e., when there are numerous similar files to be checked by Data Owners (DOs). Some traditional models cannot resist the corrupt auditors who always generate biased challenge information. Besides, a copy-summation attack exists in some schemes, which means the Cloud Server (CS) can bypass the verification by storing the median value instead of initial data via summation operation. To address the issues above, in this work, we propose a keyword searchable PDP scheme for large similar data checking. To achieve searchability, we introduce the notion of a keyword in PDP and design a specific index structure to match the authenticator. The scheme enables all matched files to be auditable and verifiable, while guaranteeing privacy protections. Unlike existing methods, our Third Party Auditor (TPA) checks all similar data containing the same keyword simultaneously. We utilize unpredictable yet verifiable public information on the blockchain to generate challenge information, rather than relying on a centralized TPA. The proposed scheme can resist copy-summation attacks. Theoretical analysis demonstrates that the proposed scheme satisfies the security requirements, and our evaluations demonstrate its efficiency.},
  archive      = {J_TIFS},
  author       = {Ying Miao and Keke Gai and Jing Yu and Yu-an Tan and Liehuang Zhu and Weizhi Meng},
  doi          = {10.1109/TIFS.2024.3516563},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1374-1389},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Blockchain-empowered keyword searchable provable data possession for large similar data},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EvalComp: Bootstrapping based on homomorphic comparison
function for CKKS. <em>TIFS</em>, <em>20</em>, 1349–1361. (<a
href="https://doi.org/10.1109/TIFS.2024.3516553">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Approximate Homomorphic Encryption scheme CKKS offers a distinctive and effective approach to privacy-preserving computation, with significant potential applications in IoT and machine learning domains. Recent advancements have introduced bootstrapping techniques tailored for CKKS, including the EvalMod and EvalRound bootstrapping techniques. These bootstrapping techniques mainly focus on approximate computation of modular reduction functions. However, the approximation of modular functions encounters challenges related to computational efficiency and bootstrapping precision, thus emerging as a major bottleneck in the advancement of bootstrapping techniques. Motivated by these concerns, in this paper, we introduce a novel bootstrapping scheme named EvalComp, which eliminates the need to fit modular functions. Unlike existing approaches, EvalComp constructs a homomorphic rounding function using the Homomorphic Comparison Function (HCF) and thus removes the integer multiples of the modulus $\boldsymbol {q}$ from the ciphertext. For $\boldsymbol {N = {2^{9}}}$ , EvalComp enhances bootstrapping precision by over 11 bits and computational efficiency by 16.7% compared with the latest EvalMod scheme (JM22). Additionally, compared with the EvalRound scheme (KPK22+), our scheme improves bootstrapping precision by 2-3 bits and computational efficiency by 20.2%. According to the bootstrapping performance comparison criterion, the performance of EvalComp achieves 1.80 times that of JM22 and 1.69 times that of KPK22+.},
  archive      = {J_TIFS},
  author       = {Huixian Li and Wenyu Mo and Chun Shen and Liaojun Pang},
  doi          = {10.1109/TIFS.2024.3516553},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1349-1361},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {EvalComp: Bootstrapping based on homomorphic comparison function for CKKS},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient generation of targeted and transferable
adversarial examples for vision-language models via diffusion models.
<em>TIFS</em>, <em>20</em>, 1333–1348. (<a
href="https://doi.org/10.1109/TIFS.2024.3518072">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial attacks, particularly targeted transfer-based attacks, can be used to assess the adversarial robustness of large visual-language models (VLMs), allowing for a more thorough examination of potential security flaws before deployment. However, previous transfer-based adversarial attacks incur high costs due to high iteration counts and complex method structure. Furthermore, due to the unnaturalness of adversarial semantics, the generated adversarial examples have low transferability. These issues limit the utility of existing methods for assessing robustness. To address these issues, we propose AdvDiffVLM, which uses diffusion models to generate natural, unrestricted and targeted adversarial examples via score matching. Specifically, AdvDiffVLM uses Adaptive Ensemble Gradient Estimation (AEGE) to modify the score during the diffusion model’s reverse generation process, ensuring that the produced adversarial examples have natural adversarial targeted semantics, which improves their transferability. Simultaneously, to improve the quality of adversarial examples, we use the GradCAM-guided Mask Generation (GCMG) to disperse adversarial semantics throughout the image rather than concentrating them in a single area. Finally, AdvDiffVLM embeds more target semantics into adversarial examples after multiple iterations. Experimental results show that our method generates adversarial examples 5x to 10x faster than state-of-the-art (SOTA) transfer-based adversarial attacks while maintaining higher quality adversarial examples. Furthermore, compared to previous transfer-based adversarial attacks, the adversarial examples generated by our method have better transferability. Notably, AdvDiffVLM can successfully attack a variety of commercial VLMs in a black-box environment, including GPT-4V. The code is available at https://github.com/gq-max/AdvDiffVLM},
  archive      = {J_TIFS},
  author       = {Qi Guo and Shanmin Pang and Xiaojun Jia and Yang Liu and Qing Guo},
  doi          = {10.1109/TIFS.2024.3518072},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1333-1348},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Efficient generation of targeted and transferable adversarial examples for vision-language models via diffusion models},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fed-UGI: Federated undersampling learning framework with
gini impurity for imbalanced network intrusion detection. <em>TIFS</em>,
<em>20</em>, 1262–1277. (<a
href="https://doi.org/10.1109/TIFS.2024.3516547">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the modern interconnected world, the popularization of networks and the rapid development of information technology led to the increasing security risks and threats in network systems. The existing intrusion detection system is constantly challenged by various malicious intrusion attacks. Machine learning algorithms have been widely used in intrusion detection. However, the model training requires the support of a sufficient high-quality samples, especially attack traffic data. Network intrusion detection datasets may not be shared between organizations due to data security and some privacy policy concerns. The federated learning framework is an optimal approach to address this issue, in which organizations collaborate to train a global model shared by multiple parties while keeping the data local to the client, guaranteeing the data privacy and security of all parties. However, there is a problem of class imbalance in the network traffic data owned by the organizations, which seriously affects the detection performance of the model and leads to a high consumption of model training time. Therefore, this study proposed a novel federated undersampling learning framework with Gini impurity, namely Fed-UGI. The framework is based on the hash-based block undersampling method to rebalance the client, which can solve the influence of imbalanced training data on the model detection performance and improve the model training efficiency. Moreover, the client weighted aggregation strategy based on Local Gini impurity can further optimize the effect of global model aggregation and reduce the impact of the dispersion degree and information difference in client data on model aggregation. In addition, extensive experiments on intrusion detection datasets show that compared to SOTA methods, the proposed Fed-UGI method has a good detection effect on the three metrics of F1-score, G-mean and AUC, the training time of the model is reduced by 51.76%-92.58%, especially in highly class imbalance situation.},
  archive      = {J_TIFS},
  author       = {Ming Zheng and Xiaowen Hu and Ying Hu and Xiaoyao Zheng and Yonglong Luo},
  doi          = {10.1109/TIFS.2024.3516547},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1262-1277},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Fed-UGI: Federated undersampling learning framework with gini impurity for imbalanced network intrusion detection},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AuditPCH: Auditable payment channel hub with privacy
protection. <em>TIFS</em>, <em>20</em>, 1251–1261. (<a
href="https://doi.org/10.1109/TIFS.2024.3515820">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anonymous Payment Channel Hub (PCH), one of the most promising layer-two solutions, settles the scalability issue in blockchain while guaranteeing the unlinkability of transacting parties. However, such developments bring conflicting requirements, i.e., hiding the sender-to-receiver relationships from any third party but opening the relationship to the auditor. Existing works do not support these requirements simultaneously since off-chain transactions are not recorded in the blockchain. Further, the privacy protection strategies hinder auditors from capturing the payment relationships. Thus, it is still a challenge to audit the finance activities of PCH transacting parties. This paper proposes a novel anonymous PCH solution called AuditPCH to achieve privacy and auditability. Concretely, we design a Linkable Randomizable Puzzle scheme for constructing conditional transactions, allowing a sender to pay for a receiver via the hub. As such, AuditPCH, with the new LRP scheme, ensures that 1) payment relationships can be protected from the hub and 2) an auditor with necessary trapdoors can associate the sender and receiver of a payment. We prove the security of AuditPCH under the Global Universal Composability framework. The extensive experimental evaluations on AuditPCH are established to demonstrate its functionality and flexibility.},
  archive      = {J_TIFS},
  author       = {Yuxian Li and Jian Weng and Junzuo Lai and Yingjiu Li and Jiahe Wu and Ming Li and Jianfei Sun and Pengfei Wu and Robert H. Deng},
  doi          = {10.1109/TIFS.2024.3515820},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1251-1261},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {AuditPCH: Auditable payment channel hub with privacy protection},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Security-enhanced data transmission with fine-grained and
flexible revocation for DTWNs. <em>TIFS</em>, <em>20</em>, 1237–1250.
(<a href="https://doi.org/10.1109/TIFS.2024.3523765">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The diverse properties of wireless networks are fulfilled with the assistance of digital twin (DT), which utilizes a virtual model of the physical object (PO) to provide predictions and control decisions. However, the open wireless channels and key leakage of compromised entities (including DT and PO) pose significant security issues, highlighting the need for secure data transmission schemes. Meanwhile, it is impractical to directly apply the existing works and cryptographic primitives to DT-empowered wireless networks (DTWNs) due to the absence of a solution to capture the security requirements comprehensively. Moreover, the essential characteristics for protecting historical data cannot be met. Therefore, this paper proposes a security-enhanced data transmission scheme with fine-grained and flexible revocation by customizing a novel cryptographic primitive named forward-secure puncturable signed encryption (FS-PSE). Our scheme enables confidential data dissemination/acquisition between the physical and virtual space while ensuring authentication of the real-time information and feedback results. In addition, three revocation modes are defined. Based on these modes, the entities can flexibly revoke any decryption-&amp;-signature, decryption, and signature capability in a fine-grained approach, thereby providing security protections for the historically transmitted data even though the entity is compromised. Moreover, our scheme is instantiated with a concrete FS-PSE construction and extended to support outsourced computing to improve efficiency. Finally, the formal security proof and performance evaluation demonstrate the security and practicality of our scheme.},
  archive      = {J_TIFS},
  author       = {Chenhao Wang and Yang Ming and Hang Liu and Yutong Deng and Yi Zhao and Songnian Zhang},
  doi          = {10.1109/TIFS.2024.3523765},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1237-1250},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Security-enhanced data transmission with fine-grained and flexible revocation for DTWNs},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving coded schemes for multi-server federated
learning with straggling links. <em>TIFS</em>, <em>20</em>, 1222–1236.
(<a href="https://doi.org/10.1109/TIFS.2024.3524160">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated Learning (FL) has emerged as an unparalleled machine learning paradigm where multiple edge clients jointly train a global model without sharing the raw data. However, sharing local models or gradients still compromises clients’ privacy and could be susceptible to delivery failures due to unreliable communication links. To address these issues, this paper considers a multi-server FL where E edge clients wish to jointly train the global model with the help of H servers while guaranteeing data privacy and meanwhile combating $s\leq H$ unreliable links per client. We first propose a hybrid coding scheme based on repetition coding and MDS Coding, such that any $T_{s}$ colluding servers cannot deduce any client data besides the aggregated model, and any $T_{e}$ colluding clients remain unaware of honest clients’ data. Furthermore, we propose a Lagrange coding with mask (LCM) to ensure more stringent privacy protection that additionally demands that colluding servers possess no knowledge about either the local or global models. Furthermore, we establish lower bounds for both the uplink and downlink communication loads and theoretically prove that the hybrid scheme and LCM scheme can achieve the optimal uplink communication loads under the first and second threat models, respectively. For the second threat model with no straggling link, the LCM scheme is optimal. These demonstrate the communication efficiency, robustness, and privacy guarantee of our schemes.},
  archive      = {J_TIFS},
  author       = {Kai Liang and Songze Li and Ming Ding and Feng Tian and Youlong Wu},
  doi          = {10.1109/TIFS.2024.3524160},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1222-1236},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Privacy-preserving coded schemes for multi-server federated learning with straggling links},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). RRMAC: A multi-data owner access control scheme with robust
revocation for co-owned data sharing. <em>TIFS</em>, <em>20</em>,
1206–1221. (<a href="https://doi.org/10.1109/TIFS.2024.3515853">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the rising requirement for data sharing, multi-data owner access control schemes have emerged, where a single data file is jointly owned by multiple data owners. Since the shared files contain information from multiple data owners, it is crucial to revoke malicious users to minimize harm when data leakage occurs. However, current multi-data owner solutions typically rely on a single data owner to encrypt and share data and fail to provide robust user revocation. When revocation is managed by a single entity, it may fail to protect the rights of all data owners and can introduce a single point of failure in multi-data owner settings. On the other hand, if revocation requires the participation of all data owners, user access may fail if some owners are offline or compromised. To address these issues, we propose a robust multi-data owner access control scheme with efficient user revocation. We construct a secret resharing protocol based on secret sharing technology and proposed a multi-data owner access control scheme. Only users who obtain a sufficient number of private keys can decrypt the ciphertext. To achieve multi-owner controlled revocation, we use key splitting to divide the user’s private key into an authorization key and an update key and embed a period into the update keys. During user revocation, the cloud updates the ciphertext and the data user can decrypt the ciphertext without obtaining the update keys of all data owners. The thorough performance analysis shows that the overhead of the proposed scheme is acceptable. Specifically, the proposed scheme takes approximately 0.5 seconds to encrypt, and with preprocessing, this time is reduced to 0.06 seconds, while decryption requires around 0.15 seconds on the Raspberry Pi.},
  archive      = {J_TIFS},
  author       = {Bei Li and Hong Zhong and Jie Cui and Chengjie Gu and Debiao He},
  doi          = {10.1109/TIFS.2024.3515853},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1206-1221},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {RRMAC: A multi-data owner access control scheme with robust revocation for co-owned data sharing},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Cross-optical property image translation for face
anti-spoofing: From visible to polarization. <em>TIFS</em>, <em>20</em>,
1192–1205. (<a href="https://doi.org/10.1109/TIFS.2024.3521323">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the development of spectral sensors and spectral data-driven learning methods which have led to significant advances in face anti-spoofing (FAS), the singular dimensionality of spectral information often results in poor robustness and weak generalization. Polarization, another fundamental property of light, can reveal intrinsic differences between genuine and fake faces with advantaged performance in precision, robustness, and generalizability. In this paper, we propose a facial image translation method from visible light (VIS) to polarization (VPT), capable of generating valuable polarimetric optical characteristics for facial presentation attack detection using VIS spectrum information input only. Specifically, the VPT method adopts a multi-stream network structure, comprising a main network and two branch networks, to translate VIS images into degree of polarization (DoP) images and Stokes polarization parameters ${S}_{1}$ and ${S}_{2}$ . To further improve image translation quality, we introduce a frequency-domain consistency loss as a complement to the existing spatial losses to narrow the gap in the frequency domain. The physical mapping relations for the DoP and Stokes parameters are employed, and the Stokes loss is designed to ensure that the generated polarization modalities conform to objective physical laws. Extensive experiments on the CASIA-Polar and CASIA-SURF datasets demonstrate the superiority of VPT over other baseline methods in terms of polarization image quality and its remarkable performance in the FAS task. This work leverages the inherent physical advantages of polarization information in material discrimination tasks while addressing hardware limitations in polarization image collection, proposing a novel solution for face recognition system security control.},
  archive      = {J_TIFS},
  author       = {Yu Tian and Kunbo Zhang and Yalin Huang and Leyuan Wang and Yue Liu and Zhenan Sun},
  doi          = {10.1109/TIFS.2024.3521323},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1192-1205},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Cross-optical property image translation for face anti-spoofing: From visible to polarization},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Resilient and redactable blockchain with two-level rewriting
and version detection. <em>TIFS</em>, <em>20</em>, 1163–1175. (<a
href="https://doi.org/10.1109/TIFS.2024.3520830">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The immutability of blockchain has exposed its limitations in adapting to rapidly evolving legal requirements and preventing malicious misuse. To address these issues, transaction-level redactable blockchain solutions based on the policy-based chameleon hash (PCH) have been introduced. These solutions allow users to create transactions and encrypt trapdoors under specific attribute policies. However, current transaction-level rewriting schemes face two security challenges: Firstly, transactions encrypted with the invalid trapdoor are difficult to rewrite; Secondly, due to lacking version detection on transactions, malicious modifiers may rollback the version of the transaction to launch a reversion attack. In this paper, we present a resilient and redactable blockchain (RRB) with 2-level rewriting and transaction version detection. Specifically, we propose a new redactable blockchain structure that supports both transaction-level and block-level rewriting. To tackle the invalid trapdoor problem, we propose two protocols: a fine-grained, controllable transaction-level rewriting protocol and a centrally controlled block-level rewriting protocol. Moreover, for the transaction reversion attack, we design a version detection mechanism for RRB by using an accumulator. Through security analysis and performance evaluation, we demonstrate the security and practicality of our RRB scheme.},
  archive      = {J_TIFS},
  author       = {Wei Wang and Haipeng Peng and Junke Duan and Licheng Wang and Xiaoya Hu and Zilin Zhao},
  doi          = {10.1109/TIFS.2024.3520830},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1163-1175},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Resilient and redactable blockchain with two-level rewriting and version detection},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A soft-contrastive pseudo learning approach toward
open-world forged speech attribution. <em>TIFS</em>, <em>20</em>,
1135–1148. (<a href="https://doi.org/10.1109/TIFS.2024.3515815">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Anti-spoofing of deepfake or forged speech is an important technique for the security usage of generative artificial intelligence. Beyond binary classification of real and forged speech, method attribution of forged speech is becoming a practical solution of interpretable anti-spoofing strategies. However, existing related methods have poor performance on analyzing speech forgery methods unseen in their training data, which is inefficient in open-world scenarios with emerging new forgery methods. In this paper, Open-World Forged Speech Attribution (OW-FSA) is firstly defined towards the attribution of forged speech on the methods generating it, where the recognized methods are not limited to the seen ones in training data and the properties of the unseen methods should also be depicted adequately. A novel algorithm, Soft-contrastive Pseudo Learning (SPL), is proposed to address the challenges outlined in OW-FSA, which introduces two key innovations: 1) Based on similarities between features at different scales, the proposed similarity-based soft filtering module filters and matches utterances from the same forgery class to enhance the intra-class compactness of features through contrastive learning. 2) The proposed similarity-based soft pseudo-labeling module integrates label-smoothing-like and similarity weighting techniques to mitigate possible errors in pseudo-labeling. Besides, an iterative algorithm based on SPL is proposed to predict the number of unseen classes. Extensive experiments have validated the superiority of the proposed algorithm over other recently proposed methods on the task of OW-FSA with or without the knowledge of the number of unseen classes. Intuitive visualization and ablation studies have also been conducted to illustrate the advantages of the proposed algorithm. The newly defined task OW-FSA and the proposed algorithm SPL in this paper will help advance the research in speech anti-spoofing.},
  archive      = {J_TIFS},
  author       = {Qiang Zhang and Xiongwei Zhang and Meng Sun and Jibin Yang},
  doi          = {10.1109/TIFS.2024.3515815},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1135-1148},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {A soft-contrastive pseudo learning approach toward open-world forged speech attribution},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient and secure post-quantum certificateless
signcryption with linkability for IoMT. <em>TIFS</em>, <em>20</em>,
1119–1134. (<a href="https://doi.org/10.1109/TIFS.2024.3520007">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The Internet of Medical Things (IoMT) has gained significant research focus in both academic and medical institutions. Nevertheless, the sensitive data involved in IoMT raises concerns regarding user validation and data privacy. To address these concerns, certificateless signcryption (CLSC) has emerged as a promising solution, offering authenticity, confidentiality, and unforgeability. Unfortunately, most existing CLSC schemes are impractical for IoMT due to their heavy computational and storage requirements. Additionally, these schemes are vulnerable to quantum computing attacks. Therefore, research focusing on designing an efficient post-quantum CLSC scheme is still far-reaching. In this work, we propose PQ-CLSCL, a novel post-quantum CLSC scheme with linkability for IoMT. Our proposed design facilitates secure transmission of medical data between physicians and patients, effectively validating user legitimacy and minimizing the risk of private information leakage. To achieve this, we leverage lattice sampling algorithms and hash functions to generate the partial secret key, then employ the sign-then-encrypt method and design a link label. We also formalize and prove the security of our design, including indistinguishability against chosen-ciphertext attacks (IND-CCA2), existential unforgeability against chosen-message attacks (EU-CMA), and linkability. Finally, through comprehensive performance evaluation, our computation overhead is just 5% of other existing schemes. The evaluation results demonstrate that our solution is practical and efficient.},
  archive      = {J_TIFS},
  author       = {Shiyuan Xu and Xue Chen and Yu Guo and Siu-Ming Yiu and Shang Gao and Bin Xiao},
  doi          = {10.1109/TIFS.2024.3520007},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1119-1134},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Efficient and secure post-quantum certificateless signcryption with linkability for IoMT},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dualistic disentangled meta-learning model for generalizable
person re-identification. <em>TIFS</em>, <em>20</em>, 1106–1118. (<a
href="https://doi.org/10.1109/TIFS.2024.3516540">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (re-ID) is a research hotspot in the field of intelligent monitoring and security. Domain generalizable (DG) person re-identification transfers the trained model directly to the unseen target domain for testing, which is closer to the practical application than supervised or unsupervised person re-ID. Meta-learning strategy is an effective way to solve the DG problem, nevertheless, existing meta-learning-based DG re-ID methods mainly simulates the test process in a single aspect such as identity or style, while ignoring the completely different person identities and styles in the unseen target domain. As to this problem, we consider a double disentangling from two levels of training strategy and feature learning, and propose a novel dualistic disentangled meta-learning (D $^{\mathbf {2}}$ ML) model. D $^{\mathbf {2}}$ ML is composed of two disentangling stages, one is for learning strategy, which spreads one-stage meta-test into two-stage, including an identity meta-test stage and a style meta-test stage. The other is for feature representation, which decouples the shallow layer features into identity-related features and style-related features. Specifically, we first conduct identity meta-test stage on different person identities of the images, and then employ a feature-level style perturbation module (SPM) based on Fourier spectrum transformation to conduct the style meta-test stage on the image with diversified styles. With these two stages, abundant changes in the unseen domain can be simulated during the meta-test phase. Besides, to learn more identity-related features, a feature disentangling module (FDM) is inserted at each stage of meta-learning and a disentangled triplet loss is developed. Through constraining the relationship between identity-related features and style-related features, the generalization ability of the model can be further improved. Experimental results on four public datasets show that our D $^{\mathbf {2}}$ ML model achieves superior generalization performance compared to the state-of-the-art methods.},
  archive      = {J_TIFS},
  author       = {Jia Sun and Yanfeng Li and Luyifu Chen and Houjin Chen and Minjun Wang},
  doi          = {10.1109/TIFS.2024.3516540},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1106-1118},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Dualistic disentangled meta-learning model for generalizable person re-identification},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing specific emitter identification: A semi-supervised
approach with deep cloud and broad edge integration. <em>TIFS</em>,
<em>20</em>, 1092–1105. (<a
href="https://doi.org/10.1109/TIFS.2024.3524157">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Specific emitter identification (SEI) is crucial in the Internet of Everything (IoE). Over the past decade, deep learning (DL) and broad learning (BL)-enabled SEI technologies have emerged. Both DL- and BL-based SEI methods rely on extensive radio frequency (RF) signal samples and corresponding labels, but labeling unknown signals is a considerable overhead and costly task. Consequently, many researchers have begun exploring semi-supervised learning techniques to address the semi-supervised SEI (SS-SEI) problem with limited labeled RF signals. However, existing SS-SEI solutions often prioritize identification performance, leading to high computational overheads and lacking iterability and scalability. To overcome these challenges, this paper proposes a novel SS-SEI solution, termed deep cloud and broad edge (DCBE). This approach integrates a DL-based SEI method at the cloud server with an updatable BL-based SEI method at the edge node. Initially, several DL-based SEI models are trained using labeled historical data at the cloud server. Meanwhile, an updatable BL-based SEI method is deployed locally on the edge node to identify unlabelled signals. When the DCBE solution is operational, edge nodes capture real-time unlabelled RF signals. The pre-trained DL-based SEI method and the locally BL-based SEI method jointly identify these RF signals. The identification results, along with the new real-time RF signals, are then used to update the weights of the BL-based SEI method at the edge nodes. The DCBE SS-SEI solution is validated using an open-source, large-scale, real-world automatic dependent surveillance-broadcast (ADS-B) dataset. Experimental results demonstrate that the proposed DCBE solution offers significant advantages in terms of SS-SEI performance, reduced computational overhead without GPU dependency, and system robustness in complex environments.},
  archive      = {J_TIFS},
  author       = {Yibin Zhang and Yuchao Liu and Juzhen Wang and Qi Xuan and Yun Lin and Guan Gui},
  doi          = {10.1109/TIFS.2024.3524157},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1092-1105},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Enhancing specific emitter identification: A semi-supervised approach with deep cloud and broad edge integration},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reducing internal collateral damage from DDoS attacks
through micro-service cloud architecture. <em>TIFS</em>, <em>20</em>,
1081–1091. (<a href="https://doi.org/10.1109/TIFS.2024.3516560">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Mitigating DDoS attacks poses a significant challenge for cyber security teams within victim organizations, as these attacks directly target service availability. Most DDoS mitigation solutions focus address the direct effects of DDoS attacks, such as service unavailability and network congestion, while the indirect effects, including collateral damage to legitimate users, receive substantially less attention in the present state-of-the-art. To address this gap, we propose a novel defense architecture designed to mitigate collateral damage and ensure service availability for legitimate users even under attack conditions. The proposed approach employs containerization, micro-services architecture, and traffic segmentation to enhance system resilience and fortify security. We send requests for two distinct services, namely an HTTP-based service and an SSH service, in order to analyze the collateral damage caused by the DDoS attack. The proposed architecture classifies incoming HTTP traffic into two categories: “benign traffic” and “suspicious traffic,” determined by the number of requests originating from the same source address. We tested this approach in three different scenarios (S-1, S-2, and S-3). Experimental results demonstrate that the proposed architecture effectively isolates suspicious traffic, mitigating its impact on benign services. This ensures the availability of critical services during a DDoS attack while minimizing collateral damage. In scenarios S-1, S-2, and S-3, it maintains service availability at 3%, 67%, and 98%, respectively, highlighting its efficacy in the face of varying levels of DDoS attack intensity. Furthermore, the architecture is extremely effective in reducing the collateral effects on SSH requests during a DDoS attack. In the S-1 scenario, SSH login time was reduced by 25%, 46%, and 27%, respectively. In the S-2 scenario, the reductions were 99%, 53%, and 29%. In the same vein, the system achieved reductions of 4%, 17%, and 99% in the S-3 scenario.},
  archive      = {J_TIFS},
  author       = {Anmol Kumar and Mayank Agarwal},
  doi          = {10.1109/TIFS.2024.3516560},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1081-1091},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Reducing internal collateral damage from DDoS attacks through micro-service cloud architecture},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Information leakage measures for imperfect statistical
information: Application to non-bayesian framework. <em>TIFS</em>,
<em>20</em>, 1065–1080. (<a
href="https://doi.org/10.1109/TIFS.2024.3516585">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper analyzes the problem of estimating information leakage when the complete statistics of the privacy mechanism are not known, and the only available information consists of several input-output pairs obtained through interaction with the system or through some side channel. Several metrics, such as subjective leakage, objective leakage, and confidence boost, were introduced before for this purpose, but by design only work in a Bayesian framework. However, it is known that Bayesian inference can quickly become intractable if the domains of the involved variables are large. In this paper, we focus on this exact problem and propose a novel approach to perform an estimation of the leakage measures when the true knowledge of the privacy mechanism is beyond the reach of the user for a non-Bayesian framework using machine learning. Initially, we adapt the definition of leakage metrics to a non-Bayesian framework and derive their statistical bounds, and afterward, we evaluate the performance of those metrics via various experiments using Neural Networks, Random Forest Classifiers, and Support Vector Machines. We have also evaluated their performance on an image dataset to demonstrate the versatility of the metrics. Finally, we provide a comparative analysis between our proposed metrics and the metrics of the Bayesian framework.},
  archive      = {J_TIFS},
  author       = {Shahnewaz Karim Sakib and George T. Amariucai and Yong Guan},
  doi          = {10.1109/TIFS.2024.3516585},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1065-1080},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Information leakage measures for imperfect statistical information: Application to non-bayesian framework},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Test-time image reconstruction for cross-device OCT
fingerprint extraction. <em>TIFS</em>, <em>20</em>, 1049–1064. (<a
href="https://doi.org/10.1109/TIFS.2024.3515810">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optical coherence tomography (OCT) technology enables imaging of 3D fingerprint structures. Extracting surface and internal fingerprints for identity recognition is possible by processing OCT images with layer segmentation and contour extraction. However, due to domain shift effects, OCT fingerprint extraction models often struggle to perform well across different devices. In this paper, a cross-device OCT fingerprint extraction method based on test-time image reconstruction is proposed. This method simultaneously trains layer segmentation and image reconstruction tasks during training. Additionally, a contour classification task is integrated to ensure the continuity and robustness of the contour extraction results. During the testing phase, image reconstruction is performed on test images, and the shared modules are updated to adapt the layer segmentation and contour classification network to the test domain. The result with the minimum inconsistency during the testing phase is selected as the final prediction. Experiments and comparisons are performed in terms of the distance between the ground truth and the extracted contours.},
  archive      = {J_TIFS},
  author       = {Yi-Peng Liu and Zhanqing Li and Xuan Yang and Xiao Lu and Jing Li and Peng Chen and Ronghua Liang},
  doi          = {10.1109/TIFS.2024.3515810},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1049-1064},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Test-time image reconstruction for cross-device OCT fingerprint extraction},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Toward robust radio frequency fingerprint identification via
adaptive semantic augmentation. <em>TIFS</em>, <em>20</em>, 1037–1048.
(<a href="https://doi.org/10.1109/TIFS.2024.3522758">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Radio frequency fingerprint identification (RFFI) is regarded as one of the most promising techniques for managing and regulating Internet of Things (IoT) devices. This technology analyzes the unique electromagnetic signals emitted by wireless devices to enable precise identification and authentication. Most existing RFFI methods focus on RF signals collected in specific scenarios. However, in real-world applications, signals are often collected at different times or from varying deployment locations, leading to differences between the training and testing distributions. The study of RFFI methods under these conditions remains underexplored. To address this gap, this paper introduces a cross-domain RFFI framework centered on adaptive semantic augmentation (ASA). The framework integrates a computationally efficient multi-resolution spectrogram decomposition strategy with a feature-sensitive multi-scale network. The ASA method enhances RFFI accuracy in cross-domain settings by linearly interpolating between two distinct semantic features to create new semantics for further identification. The proposed approach leverages two-dimensional discrete wavelet transform (2D-DWT) to decompose the raw spectrogram into four sub-bands, followed by a multi-scale network to extract critical semantic features for the ASA method. Simulation results show that the proposed ASA method significantly improves Unmanned Aerial Vehicle (UAV) identification performance, achieving accuracies of 93.05% and 98.90% on two different cross-domain datasets, respectively, outperforming existing data augmentation (DA) methods. Furthermore, generalizability validation demonstrates that the proposed method performs outstandingly across other Internet of Things (IoT) applications.},
  archive      = {J_TIFS},
  author       = {Zhenxin Cai and Yu Wang and Guan Gui and Jin Sha},
  doi          = {10.1109/TIFS.2024.3522758},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1037-1048},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Toward robust radio frequency fingerprint identification via adaptive semantic augmentation},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Query-efficient model inversion attacks: An information flow
view. <em>TIFS</em>, <em>20</em>, 1023–1036. (<a
href="https://doi.org/10.1109/TIFS.2024.3518779">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Model Inversion Attacks (MIAs) pose a certain threat to the data privacy of learning-based systems, as they enable adversaries to reconstruct identifiable features of the training distribution with only query access to the victim model. In the context of deep learning, the primary challenges associated with MIAs are suboptimal attack success rates and the corresponding high computational costs. Prior efforts assumed that the expansive search space caused these limitations, employing generative models to constrain the dimensions of the search space. Despite the initial success of these generative-based solutions, recent experiments have cast doubt on this fundamental assumption, leaving two open questions about the influential factors determining MIA performance and how to manipulate these factors to improve MIAs. To answer these questions, we reframe MIAs from the perspective of information flow. This new formulation allows us to establish a lower bound for the error probability of MIAs, determined by two critical factors: (1) the size of the search space and (2) the mutual information between input and output random variables. Through a detailed analysis of generative-based MIAs within this theoretical framework, we uncover a trade-off between the size of the search space and the generation capability of generative models. Based on the theoretical conclusions, we introduce the Query-Efficient Model Inversion Approach (QE-MIA). By strategically selecting an appropriate search space and introducing additional mutual information, QE-MIA achieves a reduction of $60\%\sim 70\%$ in query overhead while concurrently enhancing the attack success rate by $5\%\sim 25\%$ .},
  archive      = {J_TIFS},
  author       = {Yixiao Xu and Binxing Fang and Mohan Li and Xiaolei Liu and Zhihong Tian},
  doi          = {10.1109/TIFS.2024.3518779},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1023-1036},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Query-efficient model inversion attacks: An information flow view},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving generative modeling with sliced
wasserstein distance. <em>TIFS</em>, <em>20</em>, 1011–1022. (<a
href="https://doi.org/10.1109/TIFS.2024.3516549">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large models require larger datasets. While people gain from using massive amounts of data to train large models, they must be concerned about privacy issues. To address this issue, we propose a novel approach for private generative modeling using the Sliced Wasserstein Distance (SWD) metric in a Differential Private (DP) manner. We propose Normalized Clipping, a parameter-free clipping technique that generates higher-quality images. We demonstrate the advantages of Normalized Clipping over the traditional clipping method in parameter tuning and model performance through experiments. Moreover, experimental results indicate that our model outperforms previous methods in differentially private image generation tasks.},
  archive      = {J_TIFS},
  author       = {Ziniu Liu and Han Yu and Kai Chen and Aiping Li},
  doi          = {10.1109/TIFS.2024.3516549},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {1011-1022},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Privacy-preserving generative modeling with sliced wasserstein distance},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient revocable cross-domain anonymous authentication
scheme for IIoT. <em>TIFS</em>, <em>20</em>, 996–1010. (<a
href="https://doi.org/10.1109/TIFS.2024.3523198">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid evolution of the Industrial Internet of Things (IIoT) has necessitated increased device interactions across various management domains. This entails devices from different domains collaborating on the same production task. This poses significant challenges for the dynamics of cross-domain authentication schemes. Traditional cross-domain authentication schemes struggle to support seamless switching between domains and face difficulties when accommodating devices that join and leave the same domain. Moreover, these schemes suffer from intricate interactions and suboptimal efficiency. To address these issues, we propose a dynamic group signature scheme based on a dynamic accumulator and a non-interactive zero-knowledge proof. We integrated this scheme with blockchain technology to construct an efficient revocation cross-domain authentication scheme. The proposed scheme enables cross-domain anonymous authentication with simple interactions and provides an efficient revocation function for illegal devices. This approach ensures conditional privacy-preserving and enables efficient member joining and exiting through a dynamic accumulator. It effectively addresses the dynamic requirements of devices involved in IIoT production and manufacturing processes. We prove the security of the proposed scheme using a random Oracle model and conduct thorough analyses to verify its resistance against various attacks. Furthermore, the experimental results demonstrate that the proposed scheme achieves better performance in terms of computational and communication costs.},
  archive      = {J_TIFS},
  author       = {Mingwei Zeng and Jie Cui and Qingyang Zhang and Hong Zhong and Debiao He},
  doi          = {10.1109/TIFS.2024.3523198},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {996-1010},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Efficient revocable cross-domain anonymous authentication scheme for IIoT},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DRFormer: A discriminable and reliable feature transformer
for person re-identification. <em>TIFS</em>, <em>20</em>, 980–995. (<a
href="https://doi.org/10.1109/TIFS.2024.3520304">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As person image variations are likely to cause a part misalignment problem, most previous person Re-Identification (ReID) works may adopt local feature partition or additional landmark annotations to acquire aligned person features and boost ReID performance. However, such approaches either only achieve coarse-grained part alignments without considering detailed image variations within each part, or require extra annotated landmarks to train an available pose estimation model. In this work, we propose an effective Discriminable and Reliable Transformer (DRFormer) framework to learn part-aligned person representations with only person identity labels. Specifically, the DRFormer framework consists of Discriminable Feature Transformer (DFT) and Reliable Feature Transformer (RFT) modules, which generate discriminable and reliable high-order features, respectively. For reducing the dimension of high-order features, the DFT module utilizes a Self-Attentive Kronecker Product (SAKP) algorithm to promote the representational capabilities of compressed features via a self-attention strategy. For eliminating the background noise, the RFT module mines the foreground regions to adaptively aggregate foreground features via a Gumbel-Softmax strategy. Moreover, the proposed framework derives from an interpretable motivation and elegantly solves part misalignments without using feature partition or pose estimation. This paper theoretically and experimentally demonstrates the superiority of the proposed DRFormer framework, achieving state-of-the-art performance on various person ReID datasets.},
  archive      = {J_TIFS},
  author       = {Pingyu Wang and Xingjian Zheng and Linbo Qing and Bonan Li and Fei Su and Zhicheng Zhao and Honggang Chen},
  doi          = {10.1109/TIFS.2024.3520304},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {980-995},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {DRFormer: A discriminable and reliable feature transformer for person re-identification},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Secure tracking control and attack detection for power
cyber-physical systems based on integrated control decision.
<em>TIFS</em>, <em>20</em>, 968–979. (<a
href="https://doi.org/10.1109/TIFS.2024.3516557">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, the problems of attack detection and secure tracking control for the power cyber-physical system are investigated. Considering the critical role of cyber networks in influencing decision-making for power grid optimization, a multiobjective optimization problem is introduced to determine the output power of generators. This optimization problem is solved based on the improved particle swarm optimization algorithm. The power system is modelled with dynamic characteristics taken into account. Furthermore, a resilient state-feedback tracking control strategy, that exploits a sliding mode observer, is introduced to ensure the reference value generated by the cyber network is tracked even under attacks. In addition, by using the reconstructed attack signals, an attack detection scheme is proposed. Some sufficient conditions are then obtained for the solvability of the tracking control problem. Finally, a simulation example and the experimental validation built into the StarSim hardware-in-the-loop simulation platform are introduced to illustrate the effectiveness of the proposed method.},
  archive      = {J_TIFS},
  author       = {Chaowei Sun and Qingyu Su and Jian Li},
  doi          = {10.1109/TIFS.2024.3516557},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {968-979},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Secure tracking control and attack detection for power cyber-physical systems based on integrated control decision},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSR-ABE: Traceable and server-aided revocable
ciphertext-policy attribute-based encryption under static assumptions.
<em>TIFS</em>, <em>20</em>, 955–967. (<a
href="https://doi.org/10.1109/TIFS.2024.3516542">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The cloud server is a versatile platform for data storage, with users increasingly uploading personal data to public servers to circumvent costly local storage. However, the server is not entirely honest, as it may potentially compromise user data privacy. Ciphertext-policy attribute-based encryption (CP-ABE) is a highly flexible cryptographic technique for ensuring access control over encrypted data in cloud storage applications. To prevent unauthorized access, traceability and revocability are two necessary requirements for CP-ABE system. Nevertheless, existing white-box traceable and revocable CP-ABE schemes suffer from several imitations: 1) Whether direct revocation or indirect revocation is applied, neither type of the revocation mode is well compatible with the trace function. 2) Moreover, all of the previous white-box traceable CP-ABE schemes rely on non-static assumptions to prove traceability. Ideally, a scheme provably secure under static complexity assumptions is preferable. To deal with these issues, we propose a novel traceable and server-aided revocable CP-ABE (TSR-ABE) scheme based on static assumptions. Specifically, our revocation mode works well with the trace function, and we prove the adaptive chosen-plaintext attack security and traceability of our scheme via the well-known dual system encryption methodology. Compared with many previous traceable CP-ABE schemes, regardless of whether they support revocation or not, we remove the need to introduce an additional l-SDH assumption to prove the traceability of the scheme. In addition, our scheme is more practical due to its lower private key size, lower decryption costs and lower tracing costs. As a result, we strengthen current research from the perspective of both security and efficiency.},
  archive      = {J_TIFS},
  author       = {Fei Meng and Leixiao Cheng},
  doi          = {10.1109/TIFS.2024.3516542},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {955-967},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {TSR-ABE: Traceable and server-aided revocable ciphertext-policy attribute-based encryption under static assumptions},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Data-importance-aware attack strategy design and secure
control countermeasure. <em>TIFS</em>, <em>20</em>, 944–954. (<a
href="https://doi.org/10.1109/TIFS.2024.3522770">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper is concerned with the security issues related to integrated attack-defense strategy for a category of multi-sensor networked control systems with state saturation constraints. In general, existing denial-of-service (DoS) attack models typically conduct indiscriminate attacks on data packets, disregarding the significance of the attacked data packets to the system. Note that the measurement data from different sensor nodes possesses varying levels of importance. In light of this, we first propose a novel form of attack from the perspective of attack design, known as a data-importance-aware attack. The importance of data refers to the quantitative impact of the measured values at each sensor node on the stable and safe operation of the entire system. As such, the proposed attack has the awareness to launch attacks against critical sensor nodes, rendering data unable to be transmitted. Then, an attack-node-dependent security controller is devised from the defender’s perspective against the constructed attack, which can effectively resist the impact of attacks and stabilize the system. By employing the Lyapunov functional method, sufficient conditions are derived to ensure the asymptotic stability of the closed-loop system. Finally, the reliability and effectiveness of the node importance-aware attack strategy and control countermeasure are validated by numerical simulation.},
  archive      = {J_TIFS},
  author       = {Jiancun Wu and Engang Tian and Chen Peng and Zhiru Cao},
  doi          = {10.1109/TIFS.2024.3522770},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {944-954},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Data-importance-aware attack strategy design and secure control countermeasure},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gradient inversion of text-modal data in distributed
learning. <em>TIFS</em>, <em>20</em>, 928–943. (<a
href="https://doi.org/10.1109/TIFS.2024.3522792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Gradient inversion attacks (GIAs) pose significant challenges to the privacy-preserving paradigm of distributed learning. These attacks employ carefully designed strategies to reconstruct victim’s private training data from their shared gradients. However, existing work mainly focuses on attacks and defenses for image-modal data, while the study for text-modal data remains scarce. Furthermore, the performance of the limited attack researches on text-modal data is also unsatisfactory, which can be partially attributed to the finer granularity of text data compared to image. To bridge the existing research gap, we propose a high-fidelity attack method tailored for Transformer-based language models (LMs). In our method, we initially reconstruct the label space of the victim’s training data by leveraging the characteristics of the Transformer architecture. After that, we propose a shallow-to-deep paradigm to facilitate gradient matching, which can significantly improve the attack performance. Furthermore, we develop a weighted surrogate loss that resolves the consistent deviation issue present in current attack researches. A substantial number of experiments on Transformer-based LMs (e.g., Bert and GPT) demonstrate that our attack is competitive and significantly outperforms existing methods. In the final part of this paper, we investigate the influence of the inherent position embedding module within the Transformer architecture on attack performance, and based on the analysis results, we propose a countermeasure to alleviate part of the privacy leakage issue in distributed learning.},
  archive      = {J_TIFS},
  author       = {Zipeng Ye and Wenjian Luo and Qi Zhou and Yubo Tang and Zhenqian Zhu and Yuhui Shi and Yan Jia},
  doi          = {10.1109/TIFS.2024.3522792},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {928-943},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Gradient inversion of text-modal data in distributed learning},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ZkDL: Efficient zero-knowledge proofs of deep learning
training. <em>TIFS</em>, <em>20</em>, 914–927. (<a
href="https://doi.org/10.1109/TIFS.2024.3520863">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The recent advancements in deep learning have brought about significant changes in various aspects of people’s lives. Meanwhile, these rapid developments have raised concerns about the legitimacy of the training process of deep neural networks. To protect the intellectual properties of AI developers, directly examining the training process by accessing the model parameters and training data is often prohibited for verifiers. In response to this challenge, we present zero-knowledge deep learning (zkDL), an efficient zero-knowledge proof for deep learning training. To address the long-standing challenge of verifiable computations of non-linearities in deep learning training, we introduce zkReLU, a specialized proof for the ReLU activation and its backpropagation. zkReLU turns the disadvantage of non-arithmetic relations into an advantage, leading to the creation of FAC4DNN, our specialized arithmetic circuit design for modelling neural networks. This design aggregates the proofs over different layers and training steps, without being constrained by their sequential order in the training process. With our new CUDA implementation that achieves full compatibility with the tensor structures and the aggregated proof design, zkDL enables the generation of complete and sound proofs in less than a second per batch update for an 8-layer neural network with 10M parameters and a batch size of 64, while provably ensuring the privacy of data and model parameters. To our best knowledge, we are not aware of any existing work on zero-knowledge proof of deep learning training that is scalable to million-size networks.},
  archive      = {J_TIFS},
  author       = {Haochen Sun and Tonghe Bai and Jason Li and Hongyang Zhang},
  doi          = {10.1109/TIFS.2024.3520863},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {914-927},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {ZkDL: Efficient zero-knowledge proofs of deep learning training},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stealthiness assessment of adversarial perturbation: From a
visual perspective. <em>TIFS</em>, <em>20</em>, 898–913. (<a
href="https://doi.org/10.1109/TIFS.2024.3520016">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Assessing the stealthiness of adversarial perturbations is challenging due to the lack of appropriate evaluation metrics. Existing evaluation metrics, e.g., $L_{p}$ norms or Image Quality Assessment (IQA), fall short of assessing the pixel-level stealthiness of subtle adversarial perturbations since these metrics are primarily designed for traditional distortions. To bridge this gap, we present the first comprehensive study on the subjective and objective assessment of the stealthiness of adversarial perturbations from a visual perspective at a pixel level. Specifically, we propose new subjective assessment criteria for human observers to score adversarial stealthiness in a fine-grained manner. Then, we create a large-scale adversarial example dataset comprising 10586 pairs of clean and adversarial samples encompassing twelve state-of-the-art adversarial attacks. To obtain the subjective scores according to the proposed criterion, we recruit 60 human observers, and each adversarial example is evaluated by at least 15 observers. The mean opinion score of each adversarial example is utilized for labeling. Finally, we develop a three-stage objective scoring model that mimics human scoring habits to predict adversarial perturbation’s stealthiness. Experimental results demonstrate that our objective model exhibits superior consistency with the human visual system, surpassing commonly employed metrics like PSNR and SSIM.},
  archive      = {J_TIFS},
  author       = {Hangcheng Liu and Yuan Zhou and Ying Yang and Qingchuan Zhao and Tianwei Zhang and Tao Xiang},
  doi          = {10.1109/TIFS.2024.3520016},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {898-913},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Stealthiness assessment of adversarial perturbation: From a visual perspective},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learnability of optical physical unclonable functions
through the lens of learning with errors. <em>TIFS</em>, <em>20</em>,
886–897. (<a href="https://doi.org/10.1109/TIFS.2024.3518065">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We show that a class of optical physical unclonable functions (PUFs) can be efficiently PAC-learned to arbitrary precision with arbitrarily high probability, even in the presence of intentionally injected noise, given access to polynomially many challenge-response pairs, under mild and practical assumptions about the distributions of the noise and challenge vectors. We motivate our analysis by identifying similarities between the integrated version of Pappu’s original optical PUF design and the post-quantum Learning with Errors (LWE) cryptosystem. We derive polynomial bounds for the required number of samples and the computational complexity of a linear regression algorithm, based on size parameters of the PUF, the distributions of the challenge and noise vectors, and the desired accuracy and probability of success of the regression algorithm. We use a similar analysis to that done by Bootle et al. [“LWE without modular reduction and improved side-channel attacks against BLISS,” in Advances in Cryptology – ASIACRYPT 2018], who demonstrated a learning attack on poorly implemented versions of LWE cryptosystems. This extends the results of Rührmair et al. [“Optical PUFs reloaded,” Cryptology ePrint Archive, 2013], who presented a theoretical framework showing that a subset of this class of PUFs is learnable in polynomial time in the absence of injected noise, under the assumption that the optics of the PUF were either linear or had negligible nonlinear effects. (Rührmair et al. also included an experimental validation of this technique, which of course included measurement uncertainty, demonstrating robustness to the presence of natural noise.) We recommend that the design of strong PUFs should be treated as a cryptographic engineering problem in physics, as PUF designs would benefit greatly from basing their physics and security on standard cryptographic assumptions. Finally, we identify future research directions, including suggestions for how to modify an LWE-based optical PUF design to better defend against cryptanalytic attacks.},
  archive      = {J_TIFS},
  author       = {Apollo Albright and Boris Gelfand and Michael Dixon},
  doi          = {10.1109/TIFS.2024.3518065},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {886-897},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Learnability of optical physical unclonable functions through the lens of learning with errors},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust AI-synthesized speech detection using feature
decomposition learning and synthesizer feature augmentation.
<em>TIFS</em>, <em>20</em>, 871–885. (<a
href="https://doi.org/10.1109/TIFS.2024.3520001">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {AI-synthesized speech, also known as deepfake speech, has recently raised significant concerns due to the rapid advancement of speech synthesis and speech conversion techniques. Previous works often rely on distinguishing synthesizer artifacts to identify deepfake speech. However, excessive reliance on these specific synthesizer artifacts may result in unsatisfactory performance when addressing speech signals created by unseen synthesizers. In this paper, we propose a robust deepfake speech detection method that employs feature decomposition to learn synthesizer-independent content features as complementary for detection. Specifically, we propose a dual-stream feature decomposition learning strategy that decomposes the learned speech representation using a synthesizer stream and a content stream. The synthesizer stream specializes in learning synthesizer features through supervised training with synthesizer labels. Meanwhile, the content stream focuses on learning synthesizer-independent content features, enabled by a pseudo-labeling-based supervised learning method. This method randomly transforms speech to generate speed and compression labels for training. Additionally, we employ an adversarial learning technique to reduce the synthesizer-related components in the content stream. The final classification is determined by concatenating the synthesizer and content features. To enhance the model’s robustness to different synthesizer characteristics, we further propose a synthesizer feature augmentation strategy that randomly blends the characteristic styles within real and fake audio features and randomly shuffles the synthesizer features with the content features. This strategy effectively enhances the feature diversity and simulates more feature combinations. Experimental results on four deepfake speech benchmark datasets demonstrate that our model achieves state-of-the-art robust detection performance across various evaluation scenarios, including cross-method, cross-dataset, and cross-language evaluations.},
  archive      = {J_TIFS},
  author       = {Kuiyuan Zhang and Zhongyun Hua and Yushu Zhang and Yifang Guo and Tao Xiang},
  doi          = {10.1109/TIFS.2024.3520001},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {871-885},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Robust AI-synthesized speech detection using feature decomposition learning and synthesizer feature augmentation},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepReg: A trustworthy and privacy-friendly ownership
regulatory framework for deep learning models. <em>TIFS</em>,
<em>20</em>, 854–870. (<a
href="https://doi.org/10.1109/TIFS.2024.3518061">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Well-trained deep learning (DL) models are widely recognized as valuable intellectual property (IP) and have been extensively adopted. However, concerns regarding IP infringement emerge when these models are either privately sold to end-users or publicly released online. Unauthorized activities, such as redistributing privately purchased models or exploiting restricted open-source models for commercial gain, pose a significant threat to the interests of model owners. In this paper, we introduce DeepReg, a trustworthy and privacy-friendly regulatory framework designed to address IP infringement within the realm of DL models, thereby nurturing a healthier development ecosystem. DeepReg enables a designated third-party regulator to extract the fingerprint of the original model within a Trusted Execution Environment, as well as to verify suspect models utilizing solely the predicted label without probability. Specifically, we leverage the uniqueness of feature extractors in DL models to craft multiple synthetic inputs for a selected real input. The real input, along with its synthetic inputs, establishes a one-to-many relationship, thereby creating a unique fingerprint for the original model. Furthermore, we propose two distinct methods for suspect detection and piracy judgment. These methods analyze the responses from the model API upon feeding the fingerprint, ensuring a high level of confidence while preventing malicious accusations. Experimental results demonstrate that DeepReg achieves 100% detection accuracy for pirated models, with zero false positives for irrelevant models.},
  archive      = {J_TIFS},
  author       = {Xirong Zhuang and Lan Zhang and Chen Tang and Yaliang Li},
  doi          = {10.1109/TIFS.2024.3518061},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {854-870},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {DeepReg: A trustworthy and privacy-friendly ownership regulatory framework for deep learning models},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing ethereum fraud detection via generative and
contrastive self-supervision. <em>TIFS</em>, <em>20</em>, 839–853. (<a
href="https://doi.org/10.1109/TIFS.2024.3521611">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rampant fraudulent activities on Ethereum hinder the healthy development of the blockchain ecosystem, necessitating the reinforcement of regulations. However, multiple imbalances involving account interaction frequencies and interaction types in the Ethereum transaction environment pose significant challenges to data mining-based fraud detection research. To address this, we first propose the concept of meta-interactions to refine interaction behaviors in Ethereum, and based on this, we present a dual self-supervision enhanced Ethereum fraud detection framework, named Meta-IFD. This framework initially introduces a generative self-supervision mechanism to augment the interaction features of accounts, followed by a contrastive self-supervision mechanism to differentiate various behavior patterns, and ultimately characterizes the behavioral representations of accounts and mines potential fraud risks through multi-view interaction feature learning. Extensive experiments on real Ethereum datasets demonstrate the effectiveness and superiority of our framework in detecting common Ethereum fraud behaviors such as Ponzi schemes and phishing scams. Additionally, the generative module can effectively alleviate the interaction distribution imbalance in Ethereum data, while the contrastive module significantly enhances the framework’s ability to distinguish different behavior patterns. The source code will be available in https://github.com/GISec-Team/Meta-IFD.},
  archive      = {J_TIFS},
  author       = {Chengxiang Jin and Jiajun Zhou and Chenxuan Xie and Shanqing Yu and Qi Xuan and Xiaoniu Yang},
  doi          = {10.1109/TIFS.2024.3521611},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {839-853},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Enhancing ethereum fraud detection via generative and contrastive self-supervision},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Provable privacy advantages of decentralized federated
learning via distributed optimization. <em>TIFS</em>, <em>20</em>,
822–838. (<a href="https://doi.org/10.1109/TIFS.2024.3516564">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) emerged as a paradigm designed to improve data privacy by enabling data to reside at its source, thus embedding privacy as a core consideration in FL architectures, whether centralized or decentralized. Contrasting with recent findings by Pasquini et al., which suggest that decentralized FL does not empirically offer any additional privacy or security benefits over centralized models, our study provides compelling evidence to the contrary. We demonstrate that decentralized FL, when deploying distributed optimization, provides enhanced privacy protection - both theoretically and empirically - compared to centralized approaches. The challenge of quantifying privacy loss through iterative processes has traditionally constrained the theoretical exploration of FL protocols. We overcome this by conducting a pioneering in-depth information-theoretical privacy analysis for both frameworks. Our analysis, considering both eavesdropping and passive adversary models, successfully establishes bounds on privacy leakage. In particular, we show information theoretically that the privacy loss in decentralized FL is upper bounded by the loss in centralized FL. Compared to the centralized case where local gradients of individual participants are directly revealed, a key distinction of optimization-based decentralized FL is that the relevant information includes differences of local gradients over successive iterations and the aggregated sum of different nodes’ gradients over the network. This information complicates the adversary’s attempt to infer private data. To bridge our theoretical insights with practical applications, we present detailed case studies involving logistic regression and deep neural networks. These examples demonstrate that while privacy leakage remains comparable in simpler models, complex models like deep neural networks exhibit lower privacy risks under decentralized FL. Extensive numerical tests further validate that decentralized FL is more resistant to privacy attacks, aligning with our theoretical findings.},
  archive      = {J_TIFS},
  author       = {Wenrui Yu and Qiongxiu Li and Milan Lopuhaä-Zwakenberg and Mads Græsbøll Christensen and Richard Heusdens},
  doi          = {10.1109/TIFS.2024.3516564},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {822-838},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Provable privacy advantages of decentralized federated learning via distributed optimization},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Analyze and improve differentially private federated
learning: A model robustness perspective. <em>TIFS</em>, <em>20</em>,
807–821. (<a href="https://doi.org/10.1109/TIFS.2024.3518058">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differentially Private Federated learning (DPFL) applies differential privacy (DP) techniques to preserve clients’ privacy in Federated Learning (FL). Existing methods based on Gaussian Mechanism require the operations of model updates clipping and noise injection, which lead to a serious degradation in model accuracies. Several improved methods are proposed to mitigate the accuracy degradation by decreasing the scale of the injected noise. Different from previous methods, we firstly propose to enhance the model robustness against the DP noise for the accuracy improvement. In this paper, we develop a novel FL scheme with improved model robustness, called FedIMR, which can provide the client-level DP guarantee while maintaining a high model accuracy. We find that the injected noise leads to the fluctuation of loss values in the local training, hindering the model convergence seriously. This motivates us to improve the model robustness for narrowing down the bias of model outputs caused by the noise. The model robustness is evaluated with the signal-to-noise ratio (SNR) of each layer’s outputs. Two techniques are proposed to improve the output SNR, including the logit vector normalization (LVN) and dynamic clipping threshold (DCT). Specifically, LVN normalizes the logit vertor to make the optimization algorithm keep increasing the model output, which is the signal item of the output SNR. DCT dynamically adjusts the clipping threshold to reduce the noise item of the output SNR. We also provide the privacy analysis and convergence results. Experiments are conducted over three famous datasets to evaluate the effectiveness of our method. Both the theoretical results and empirical experiments confirm that our FedIMR can achieve a better accuracy-privacy tradeoff than previous methods.},
  archive      = {J_TIFS},
  author       = {Shuaishuai Zhang and Jie Huang and Peihao Li},
  doi          = {10.1109/TIFS.2024.3518058},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {807-821},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Analyze and improve differentially private federated learning: A model robustness perspective},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EASNs: Efficient anonymous social networks with enhanced
security and high scalability. <em>TIFS</em>, <em>20</em>, 796–806. (<a
href="https://doi.org/10.1109/TIFS.2024.3516568">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Privacy concerns have been persistently afflicting individuals within online social networks (OSNs), rendering privacy-preserving communications over the Internet with authentication especially important. Unfortunately, the guarantees of privacy and authenticity are not always provided in OSNs. Individuals are still facing the challenges of being deceived or exploited. To mitigate these issues, anonymous social networks (ASNs) have emerged as a remedy for OSNs, facilitating individuals to connect with others anonymously and authentically. Despite the existence of numerous and remarkable cryptographic primitives, there are no formal solutions for ASNs except for matchmaking encryption (ME), since ME can simultaneously provide various key functionalities, i.e. bilateral access control, identity anonymity, and message authentication, to address the requirements of ASNs. In this paper, we design a system for ASNs by adopting fuzzy identity-based matchmaking encryption (fuzzy IB-ME), and the proposed scheme in this work is highly efficient. The scheme also realizes adaptive security in generic group model (GGM), which is generally adopted in pairing-based cryptography. The proposed ASNs system offers various advantages compared to the previous solutions, including 1) bilateral access control, 2) enhanced security, 3) high scalability, and 4) high efficiency. In addition to theoretical evaluations, we conduct extensive experiments to evaluate our scheme’s computational and storage efficiency. These evaluations indicate that our solution outperforms previous solutions and as well as preserves many desired functionalities.},
  archive      = {J_TIFS},
  author       = {Wenfeng Huang and Axin Wu and Shengmin Xu and Guowen Xu and Wei Wu},
  doi          = {10.1109/TIFS.2024.3516568},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {796-806},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {EASNs: Efficient anonymous social networks with enhanced security and high scalability},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Online two-stage channel-based lightweight authentication
method for time-varying scenarios. <em>TIFS</em>, <em>20</em>, 781–795.
(<a href="https://doi.org/10.1109/TIFS.2024.3516575">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Physical Layer Authentication (PLA) emerges as a promising security solution, offering efficient identity verification for the Internet of Things (IoT). The advent of 5G/6G technologies has ushered in an era of extensive device connectivity, diverse networks, and complex application scenarios within IoT ecosystems. These advancements necessitate PLA systems that are highly secure, robust, capable of online processing, and adaptable to unknown channel conditions. In this paper, we introduce a novel two-stage PLA framework that synergizes channel prediction with power-delay attributes, ensuring superior performance in mobile and time-varying channel environments. Specifically, our approach employs Sparse Variational Gaussian Processes (SVGP) to accurately model and track real-time channel variations, leveraging historical data for online predictions without incurring significant computational or storage overhead. The second stage of our framework enhances the robustness of the authentication process by incorporating power-delay features, which are inherently resistant to temporal fluctuations, thereby eliminating the need for additional feature extraction in noisy settings. Moreover, our authentication scheme is designed to be distribution-agnostic, utilizing Kernel Density Estimation (KDE) for non-parametric threshold determination in hypothesis testing. Theoretical analysis underpins the generalization capabilities of our proposed method. Simulation results in mobile scenarios reveal that our two-stage PLA framework reduces complexity and significantly improves identity authentication performance, particularly in scenarios with low signal-to-noise ratios.},
  archive      = {J_TIFS},
  author       = {Yuhong Xue and Zhutian Yang and Zhilu Wu and Hu Wang and Guan Gui},
  doi          = {10.1109/TIFS.2024.3516575},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {781-795},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Online two-stage channel-based lightweight authentication method for time-varying scenarios},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). X-DFS: Explainable artificial intelligence guided
design-for-security solution space exploration. <em>TIFS</em>,
<em>20</em>, 753–766. (<a
href="https://doi.org/10.1109/TIFS.2024.3515855">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Design and manufacturing of integrated circuits predominantly use a globally distributed semiconductor supply chain involving diverse entities. The modern semiconductor supply chain has been designed to boost production efficiency, but is filled with major security concerns such as malicious modifications (hardware Trojans), reverse engineering (RE), and cloning. While being deployed, digital systems are also subject to a plethora of threats such as power, timing, and electromagnetic (EM) side channel attacks. Many Design-for-Security (DFS) solutions have been proposed to deal with these vulnerabilities, and such solutions (DFS) relays on strategic modifications (e.g., logic locking, side channel resilient masking, and dummy logic insertion) of the digital designs for ensuring a higher level of security. However, most of these DFS strategies lack robust formalism, are often not human-understandable, and require an extensive amount of human expert effort during their development/use. All of these factors make it difficult to keep up with the ever growing number of microelectronic vulnerabilities. In this work, we propose X-DFS, an explainable Artificial Intelligence (AI) guided DFS isolution-space exploration approach that can dramatically cut down the mitigation strategy development/use time while enriching our understanding of the vulnerability by providing human-understandable decision rationale. We implement X-DFS and comprehensively evaluate it for reverse engineering threats (SAIL, SWEEP, and OMLA) and formalize a generalized mechanism for applying X-DFS to defend against other threats such as hardware Trojans, fault attacks, and side channel attacks for seamless future extensions.},
  archive      = {J_TIFS},
  author       = {Tanzim Mahfuz and Swarup Bhunia and Prabuddha Chakraborty},
  doi          = {10.1109/TIFS.2024.3515855},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {753-766},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {X-DFS: Explainable artificial intelligence guided design-for-security solution space exploration},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy-preserving localization for underwater acoustic
sensor networks: A differential privacy-based deep learning approach.
<em>TIFS</em>, <em>20</em>, 737–752. (<a
href="https://doi.org/10.1109/TIFS.2024.3518069">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Localization is a key premise for implementing the applications of underwater acoustic sensor networks (UASNs). However, the inhomogeneous medium and the open feature of underwater environment make it challenging to accomplish the above task. This paper studies the privacy-preserving localization issue of UASNs with consideration of direct and indirect data threats. To handle the direct data threat, a privacy-preserving localization protocol is designed for sensor nodes, where the mutual information is adopted to acquire the optimal noises added on anchor nodes. With the collected range information from anchor nodes, a ray tracing model is employed for sensor nodes to compensate the range bias caused by straight-line propagation. Then, a differential privacy (DP) based deep learning localization estimator is designed to calculate the positions of sensor nodes, and the perturbations are added to the forward propagation of deep learning framework, such that the indirect data leakage can be avoided. Besides that, the theory analyses including the Cramer-Rao Lower Bound (CRLB), the privacy budget and the complexity are provided. Main innovations of this paper include: 1) the mutual information-based localization protocol can acquire the optimal noise over the traditional noise-adding mechanisms; 2) the DP-based deep learning estimator can avoid the leakage of training data caused by overfitting in traditional deep learning-based solutions. Finally, simulation and experimental results are both conducted to verify the effectiveness of our approach.},
  archive      = {J_TIFS},
  author       = {Jing Yan and Yuhan Zheng and Xian Yang and Cailian Chen and Xinping Guan},
  doi          = {10.1109/TIFS.2024.3518069},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {737-752},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Privacy-preserving localization for underwater acoustic sensor networks: A differential privacy-based deep learning approach},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differentially private decentralized optimization with relay
communication. <em>TIFS</em>, <em>20</em>, 724–736. (<a
href="https://doi.org/10.1109/TIFS.2024.3515803">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Security concerns in large-scale networked environments are becoming increasingly critical. To further improve the algorithm security from the design perspective of decentralized optimization algorithms, we introduce a new measure: Privacy Leakage Frequency (PLF), which reveals the relationship between communication and privacy leakage of algorithms, showing that lower PLF corresponds to lower privacy budgets. Based on such assertion, a novel differentially private decentralized primal-dual algorithm named DP-RECAL is proposed to take advantage of operator splitting method and relay communication mechanism to experience less PLF so as to reduce the overall privacy budget. To the best of our knowledge, compared with existing differentially private algorithms, DP-RECAL presents superior privacy performance and communication complexity. In addition, with uncoordinated network-independent stepsizes, we prove the convergence of DP-RECAL for general convex problems and establish a linear convergence rate under the metric subregularity. Evaluation analysis on least squares problem and numerical experiments on real-world datasets verify our theoretical results and demonstrate that DP-RECAL can defend some classical gradient leakage attacks.},
  archive      = {J_TIFS},
  author       = {Luqing Wang and Luyao Guo and Shaofu Yang and Xinli Shi},
  doi          = {10.1109/TIFS.2024.3515803},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {724-736},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Differentially private decentralized optimization with relay communication},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detection of false data injection attacks in smart grids: An
optimal transport-based reliable self-training approach. <em>TIFS</em>,
<em>20</em>, 709–723. (<a
href="https://doi.org/10.1109/TIFS.2024.3515809">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite the success of data-driven methods in detecting false data injection (FDI) attacks, the remarkable progress is inseparable from massive labeled and class-balanced measurements. However, the collected measurement datasets in smart grids typically exhibit skewed class distributions and are partially labeled due to the expensive labeling costs. Learning from such non-ideal datasets undoubtedly results in the degenerated detection performance of the data-driven methods. To cope with this issue, we propose an optimal transport (OT)-based framework named DeSSW to promote the utilization of plentiful unlabeled measurements through the self-training technique, which improves the ability to identify FDI attacks by producing distinguishable representations for normal and attacked measurements in the feature space. Specifically, DeSSW consists of a novel re-weighting algorithm and a debiased self-training strategy. The re-weighting algorithm ensures high-confidence unlabeled measurements dominate the self-training procedure, and the debiased self-training strategy mitigates bias accumulation in the iterative self-training procedure. Extensive experiments demonstrate that DeSSW achieves superior detection performance when facing the combinatorial challenge of partially labeled and class-imbalanced measurements, even if the measurements are noisy.},
  archive      = {J_TIFS},
  author       = {Kaiyao Miao and Meng Zhang and Fanghong Guo and Rongxing Lu and Xiaohong Guan},
  doi          = {10.1109/TIFS.2024.3515809},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {709-723},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Detection of false data injection attacks in smart grids: An optimal transport-based reliable self-training approach},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-level resource-coherented graph learning for website
fingerprinting attacks. <em>TIFS</em>, <em>20</em>, 693–708. (<a
href="https://doi.org/10.1109/TIFS.2024.3520014">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning-based website fingerprinting (WF) attacks dominate website traffic classification. In the real world, the main challenges limiting their effectiveness are, on the one hand, the difficulty in countering the effect of content updates on the basis of accurate descriptions of page features in traffic representations. On the other hand, the model’s accuracy relies on training numerous samples, requiring constant manual labeling. The key to solving the problem is to find a website traffic representation that can stably and accurately display page features, as well as to perform self-supervised learning that is not reliant on manual labeling. This study introduces the multi-level resource-coherented graph convolutional neural network (MRCGCN), a self-supervised learning-based WF attack. It analyzes website traffic using resources as the basic unit, which are coarser than packets, ensuring the page’s unique resource layout while improving the robustness of the representations. Then, we utilized an echelon-ordered graph kernel function to extract the graph topology as the label for website traffic. Finally, a two-channel graph convolutional neural network is designed for constructing a self-supervised learning-based traffic classifier. We evaluated the WF attacks using real data in both closed- and open-world scenarios. The results demonstrate that the proposed WF attack has superior and more comprehensive performance compared to state-of-the-art methods.},
  archive      = {J_TIFS},
  author       = {Bo Gao and Weiwei Liu and Guangjie Liu and Fengyuan Nie and Jianan Huang},
  doi          = {10.1109/TIFS.2024.3520014},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {693-708},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Multi-level resource-coherented graph learning for website fingerprinting attacks},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ReTrial: Robust encrypted malicious traffic detection via
discriminative relation incorporation and misleading relation
correction. <em>TIFS</em>, <em>20</em>, 677–692. (<a
href="https://doi.org/10.1109/TIFS.2024.3515821">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Encryption techniques greatly ensure the confidentiality and integrity of network communications. However, they also allow attackers to conceal malicious activities within encrypted traffic, posing severe cybersecurity challenges. Current detection methods primarily rely on statistics and correlation analysis. However, both statistical features and inter-entity relations can be easily obfuscated. Moreover, issues with low-quality data and fixed feature sets limit the generalizability and adaptability to defend against various evasion techniques. Robustifying encrypted malicious traffic detection in adverse conditions is still an open problem. In this paper, we propose R e T rial , a robust encrypted malicious traffic detection system via discriminative relation incorporation and misleading relation correction. The key motivations behind R e T rial are to accurately leverage the rich relations among flows for contextual analysis, and correct misleading ones for robust threat detection. Specifically, we construct a relational multigraph and develop a tailored Graph Attention Network (GAT) to selectively incorporate contextual information. Then we retrieve multi-order neighborhood similarity graphs as observations for adaptive relation correction. Following an iterative scheme, both detector performance and graph topology mutually optimize. To validate the robustness of R e T rial , we simulate various adverse conditions by randomly dropping packets and greedily injecting perturbation edges. The experimental results show that R e T rial is competitive in ideal condition. Under adverse conditions, though the performances of other state-of-the-art methods degrade significantly, R e T rial consistently exhibits superior performance with a maximum reduction of only 5.88% in F1, highlighting its robustness in threat detection.},
  archive      = {J_TIFS},
  author       = {Jianjin Zhao and Qi Li and Zewei Han and Junsong Fu and Guoshun Nan and Meng Shen and Bharat K. Bhargava},
  doi          = {10.1109/TIFS.2024.3515821},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {677-692},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {ReTrial: Robust encrypted malicious traffic detection via discriminative relation incorporation and misleading relation correction},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust image hashing with weighted saliency map and
laplacian eigenmaps. <em>TIFS</em>, <em>20</em>, 665–676. (<a
href="https://doi.org/10.1109/TIFS.2024.3516552">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Copy detection is crucial for protecting image copyright. This paper proposes a robust image hashing approach via Weighted Saliency Map (WSM) and Laplacian Eigenmaps (LE) (hereafter WSM-LE approach). An important contribution is the WSM construction via the edge map and the saliency map. As the WSM can indicate the interest regions of image, hash calculation based on WSM can provide robustness of our WSM-LE approach. Another contribution is the low-dimensional feature learning by the LE technique. As the LE technique can effectively learn the internal geometric relationships of image, the extracted low-dimensional features can improve discrimination of our WSM-LE approach. In addition, the low-dimensional features are treated as vectors and the vector distances are used to create a compact and encrypted hash. Numerous experiments and comparisons are conducted to confirm the effectiveness and superiority of our WSM-LE approach. The results indicate that our WSM-LE approach has excellent classification and copy detection performances than some baseline approaches.},
  archive      = {J_TIFS},
  author       = {Xiaoping Liang and Zhenjun Tang and Xianquan Zhang and Xinpeng Zhang and Ching-Nung Yang},
  doi          = {10.1109/TIFS.2024.3516552},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {665-676},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Robust image hashing with weighted saliency map and laplacian eigenmaps},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Signed latent factors for spamming activity detection.
<em>TIFS</em>, <em>20</em>, 651–664. (<a
href="https://doi.org/10.1109/TIFS.2024.3516573">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the increasing trend of performing spamming activities (e.g., Web spam, deceptive reviews, fake followers, etc.) on various online platforms to gain undeserved benefits, spam detection has emerged as a hot research issue. Previous attempts to combat spam mainly employ features related to metadata, user behaviors, or relational ties. These studies have made considerable progress in understanding and filtering spamming campaigns. However, this problem remains far from fully solved. Almost all the proposed features focus on a limited number of observed attributes or explainable phenomena, making it difficult for existing methods to achieve further improvement. To broaden the vision about solving the spam problem and address long-standing challenges (class imbalance and graph incompleteness) in the spam detection area, we propose a new attempt of utilizing signed latent factors to filter fraudulent activities. The spam-contaminated relational datasets of multiple online applications in this scenario are interpreted by the unified signed network. Two competitive and highly dissimilar algorithms of latent factors mining (LFM) models are designed based on multi-relational likelihoods estimation (LFM-MRLE) and signed pairwise ranking (LFM-SPR), respectively. We then explore how to apply the mined latent factors to spam detection tasks. Experiments on real-world datasets of different kinds of Web applications (social media and Web forum) indicate that LFM models outperform state-of-the-art baselines in detecting spamming activities. By specifically manipulating experimental data, the effectiveness of our methods in dealing with incomplete and imbalanced challenges is validated.},
  archive      = {J_TIFS},
  author       = {Yuli Liu},
  doi          = {10.1109/TIFS.2024.3516573},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {651-664},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Signed latent factors for spamming activity detection},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Privacy passport: Privacy-preserving cross-domain data
sharing. <em>TIFS</em>, <em>20</em>, 636–650. (<a
href="https://doi.org/10.1109/TIFS.2024.3515797">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Data sharing facilitates the integration and in-depth exploration of cross-domain data, thereby fostering innovative research and model development. However, privacy leakage emerges as a critical barrier to the sharing and circulating of such data. Existing privacy-preserving technologies face challenges in handling complex scenarios involving multiple participants due to the following reasons: 1) Divergent privacy permission. Data sharing is constrained by various privacy limitations, necessitating the consideration of privacy permissions across different domains, akin to a cross-border process. 2) High collaboration cost. Collaboration among multiple domains to determine the privacy constraint and sharing ways incur additional costs. 3) Large noise magnitude. Traditional privacy techniques to protect the privacy of a single domain using local differential privacy (LDP) may introduce excessive noise, thereby reducing data utility. Drawing inspiration from the cross-border visa issuance process, we present an innovative framework called PriVisa for enabling privacy-preserving data sharing across different domains. It consists of four key modules to overcome the mentioned challenges: the hybrid pattern, optimized sharing path construction, personalized grouping, and LDP-based perturbation. 1) The hybrid pattern for coordination among organizations, considering authentication, privacy constraints, and sharing methods. 2) The optimized sharing path construction using a privacy constraint hierarchy tree to maximize data utility while adhering to privacy requirements. 3) The feature similarity grouping and perturbing mechanism satisfying LDP to protect privacy and optimize data utility. The theoretical and experimental validation confirms PriVisa’s effectiveness in addressing divergent privacy constraints and promoting data utility in cross-domain data sharing.},
  archive      = {J_TIFS},
  author       = {Xue Chen and Cheng Wang and Qing Yang and Hu Teng and Changjun Jiang},
  doi          = {10.1109/TIFS.2024.3515797},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {636-650},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Privacy passport: Privacy-preserving cross-domain data sharing},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Accountable decryption made formal and practical.
<em>TIFS</em>, <em>20</em>, 620–635. (<a
href="https://doi.org/10.1109/TIFS.2024.3515808">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing scale and complexity of online activities, accountability, as an after-the-fact mechanism, has become an effective complementary approach to ensure system security. Decades of research have delved into the connotation of accountability. They fail, however, to achieve practical accountability of decryption. This paper seeks to address this gap. We consider the scenario where a client (called encryptor, her) encrypts her data and then chooses a delegate (a.k.a. decryptor, him) that stores data for her. If the decryptor initiates an illegitimate decryption on the encrypted data, there is a non-negligible probability that this behavior will be detected, thereby holding the decryptor accountable for his decryption. We make three contributions. First, we review key definitions of accountability known so far. Based on extensive investigations, we formalize new definitions of accountability specifically targeting the decryption process, denoted as accountable decryption, and discuss the (im)possibilities when capturing this concept. We also define the security goals in correspondence. Second, we present a novel Trusted Execution Environment(TEE)-assisted solution aligning with definitions. Instead of fully trusting TEE, we take a further step, making TEE work in the “trust, but verify” model where we trust TEE and use its service, but empower users (i.e., decryptors) to detect the potentially compromised state of TEEs. Third, we implement a full-fledged system and conduct a series of evaluations. The results demonstrate that our solution is efficient. Even in a scenario involving $300,000$ log entries, the decryption process concludes in approximately 5.5ms, and malicious decryptors can be identified within 69ms.},
  archive      = {J_TIFS},
  author       = {Rujia Li and Yuanzhao Li and Qin Wang and Sisi Duan and Qi Wang and Mark Ryan},
  doi          = {10.1109/TIFS.2024.3515808},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {620-635},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Accountable decryption made formal and practical},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). GroupFace: Imbalanced age estimation based on multi-hop
attention graph convolutional network and group-aware margin
optimization. <em>TIFS</em>, <em>20</em>, 605–619. (<a
href="https://doi.org/10.1109/TIFS.2024.3520020">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the recent advances in computer vision, age estimation has significantly improved in overall accuracy. However, owing to the most common methods do not take into account the class imbalance problem in age estimation datasets, they suffer from a large bias in recognizing long-tailed groups. To achieve high-quality imbalanced learning in long-tailed groups, the dominant solution lies in that the feature extractor learns the discriminative features of different groups and the classifier is able to provide appropriate and unbiased margins for different groups by the discriminative features. Therefore, in this novel, we propose an innovative collaborative learning framework (GroupFace) that integrates a multi-hop attention graph convolutional network and a dynamic group-aware margin strategy based on reinforcement learning. Specifically, to extract the discriminative features of different groups, we design an enhanced multi-hop attention graph convolutional network. This network is capable of capturing the interactions of neighboring nodes at different distances, fusing local and global information to model facial deep aging, and exploring diverse representations of different groups. In addition, to further address the class imbalance problem, we design a dynamic group-aware margin strategy based on reinforcement learning to provide appropriate and unbiased margins for different groups. The strategy divides the sample into four age groups and considers identifying the optimum margins for various age groups by employing a Markov decision process. Under the guidance of the agent, the feature representation bias and the classification margin deviation between different groups can be reduced simultaneously, balancing inter-class separability and intra-class proximity. After joint optimization, our architecture achieves excellent performance on several age estimation benchmark datasets. It not only achieves large improvements in overall estimation accuracy but also gains balanced performance in long-tailed group estimation.},
  archive      = {J_TIFS},
  author       = {Yiping Zhang and Yuntao Shou and Wei Ai and Tao Meng and Keqin Li},
  doi          = {10.1109/TIFS.2024.3520020},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {605-619},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {GroupFace: Imbalanced age estimation based on multi-hop attention graph convolutional network and group-aware margin optimization},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective node injection approach for attacking social
network alignment. <em>TIFS</em>, <em>20</em>, 589–604. (<a
href="https://doi.org/10.1109/TIFS.2024.3515842">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The importance of social network alignment (SNA) for various downstream applications, such as social network information fusion and e-commerce recommendation, has prompted numerous professionals to develop and share SNA tools. However, malicious actors can exploit these tools to integrate sensitive user information, thereby posing cybersecurity risks. Although many researchers have explored attacking SNA (ASNA) through network modification attacks to protect users, practical feasibility remains challenging. In this study, we propose an effective node injection attack via a dynamic programming framework (DPNIA) to address the problem of modeling and solving ASNA within a limited time and balancing the costs and benefits. DPNIA models ASNA as a problem of maximizing the number of confirmed incorrect correspondent node pairs with greater similarity scores than the pairs between existing nodes, thereby making ASNA solvable. A cross-network evaluation method is employed directly to identify node vulnerabilities, facilitating progressive attacking from easy to difficult. In addition, an optimal injection strategy searching method based on dynamic programming is used to determine which links should be added between the injected and existing nodes, thereby enhancing the effectiveness of the attack at a low cost. Experiments on four real-world datasets demonstrated that DPNIA consistently and significantly surpasses various baselines when attacking both multiple networks simultaneously and a single network.},
  archive      = {J_TIFS},
  author       = {Shuyu Jiang and Yunxiang Qiu and Xian Mo and Rui Tang and Wei Wang},
  doi          = {10.1109/TIFS.2024.3515842},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {589-604},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {An effective node injection approach for attacking social network alignment},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bilevel optimized collusion attacks against gait recognizer.
<em>TIFS</em>, <em>20</em>, 574–588. (<a
href="https://doi.org/10.1109/TIFS.2024.3515806">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extensive investigations have revealed that the gait recognition system is always vulnerable to impersonation attacks, which pose significant threats to the identity access security. Previous impersonation strategies have primarily focused on mimicking the victim’s walking style or probing the similar gait features to merely manipulate the input samples, without concurrently undermining the built-in model of the gait recognizer, thereby failing to achieve cost-effective attacks. In contrast to these existing heuristic approaches, we propose an optimal adversarial complicity strategy, called collusion attack, which leverages the tight collaboration between an external attacker and an internal spy to tie up into the close colluder, simultaneously enabling the input-&amp;model-corrupted tampering modes and misleading the gait recognizer more powerfully and stealthily for misidentifying the illegitimate Alice as legitimate Bob. Specifically, we formulate a bilevel optimization problem to model such a leader-follower Stackelberg game with sequentially adversarial interaction process between the colluders and gait recognizer. Further, to solve this challenging bilevel problem efficiently, we absorb the Lagrangian dual theory and linearization representation method to reformulate a tractable mixed integer program. Finally, we perform comparison and ablation experiments with the state-of-the-art attack modes on single-&amp;multi-source gait datasets to verify the validity of our collusion strategy in inducing the mistaken identity with great success rate, high confidence, and low cost. Empirical results also shed light on key insights in mitigating the collusion attacks and enhancing the gait recognition robustness to safeguard the identity access applications.},
  archive      = {J_TIFS},
  author       = {Jianmin Dong and Da-Tian Peng and Zhongmin Cai and Bo Zeng},
  doi          = {10.1109/TIFS.2024.3515806},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {574-588},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Bilevel optimized collusion attacks against gait recognizer},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IFViT: Interpretable fixed-length representation for
fingerprint matching via vision transformer. <em>TIFS</em>, <em>20</em>,
559–573. (<a href="https://doi.org/10.1109/TIFS.2024.3520015">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Determining dense feature points on fingerprints used in constructing deep fixed-length representations for accurate matching, particularly at the pixel level, is of significant interest. To explore the interpretability of fingerprint matching, we propose a multi-stage interpretable fingerprint matching network, namely Interpretable Fixed-length Representation for Fingerprint Matching via Vision Transformer (IFViT), which consists of two primary modules. The first module, an interpretable dense registration module, establishes a Vision Transformer (ViT)-based Siamese Network to capture long-range dependencies and the global context in fingerprint pairs. It provides interpretable dense pixel-wise correspondences of feature points for fingerprint alignment and enhances the interpretability in the subsequent matching stage. The second module takes into account both local and global representations of the aligned fingerprint pair to achieve an interpretable fixed-length representation extraction and matching. It employs the ViTs trained in the first module with the additional fully connected layer and retrains them to simultaneously produce the discriminative fixed-length representation and interpretable dense pixel-wise correspondences of feature points. Extensive experimental results on diverse publicly available fingerprint databases demonstrate that the proposed framework not only exhibits superior performance on dense registration and matching but also significantly promotes the interpretability in deep fixed-length representations-based fingerprint matching.},
  archive      = {J_TIFS},
  author       = {Yuhang Qiu and Honghui Chen and Xingbo Dong and Zheng Lin and Iman Yi Liao and Massimo Tistarelli and Zhe Jin},
  doi          = {10.1109/TIFS.2024.3520015},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {559-573},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {IFViT: Interpretable fixed-length representation for fingerprint matching via vision transformer},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SCU: An efficient machine unlearning scheme for deep
learning enabled semantic communications. <em>TIFS</em>, <em>20</em>,
547–558. (<a href="https://doi.org/10.1109/TIFS.2024.3516576">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning (DL) enabled semantic communications leverage DL to train encoders and decoders (codecs) to extract and recover semantic information. However, most semantic training datasets contain personal private information. Such concerns call for enormous requirements for specified data erasure from semantic codecs when previous users hope to move their data from the semantic system. Existing machine unlearning solutions remove data contribution from trained models, yet usually in supervised sole model scenarios. These methods are infeasible in semantic communications that often need to jointly train unsupervised encoders and decoders. In this paper, we investigate the unlearning problem in DL-enabled semantic communications and propose a semantic communication unlearning (SCU) scheme to tackle the problem. SCU includes two key components. Firstly, we customize the joint unlearning method for semantic codecs, including the encoder and decoder, by minimizing mutual information between the learned semantic representation and the erased samples. Secondly, to compensate for semantic model utility degradation caused by unlearning, we propose a contrastive compensation method, which considers the erased data as the negative samples and the remaining data as the positive samples to retrain the unlearned semantic models contrastively. Theoretical analysis and extensive experimental results on three representative datasets demonstrate the effectiveness and efficiency of our proposed methods.},
  archive      = {J_TIFS},
  author       = {Weiqi Wang and Zhiyi Tian and Chenhan Zhang and Shui Yu},
  doi          = {10.1109/TIFS.2024.3516576},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {547-558},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {SCU: An efficient machine unlearning scheme for deep learning enabled semantic communications},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmenting model extraction attacks against disruption-based
defenses. <em>TIFS</em>, <em>20</em>, 531–546. (<a
href="https://doi.org/10.1109/TIFS.2024.3515792">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Existing research has demonstrated that deep neural networks are susceptible to model extraction attacks, where an attacker can construct a substitute model with similar functionality to the victim model by querying the black-box victim model. To counter such attacks, various disruption-based defenses have been proposed. These defenses disrupt the output results of queries before returning them to potential attackers. In this paper, we propose the first defense-penetrating model extraction attack framework, aimed at breaking disruption-based defense methods. Our proposed attack framework comprises two key modules: disruption detection and disruption recovery, which can be integrated into generic model extraction attacks. Specifically, the disruption detection module uses a novel meta-learning-based algorithm to infer the defense strategy employed by the defender, by learning the key differences between the distributions of disrupted and undisrupted query results. Once the defense method is inferred, the disruption recovery module is designed to restore clean query results from the disrupted query results, using a carefully-designed generative model. We conducted extensive experiments on 5 commonly-used datasets to evaluate the effectiveness of our proposed framework. The results demonstrate that the substitute model accuracy of current model extraction attacks can be significantly improved by up to 82.42%, even when faced with four state-of-the-art model extraction defenses. Moreover, our attack approach shows promising results in penetrating unknown defenses in real-world cloud service APIs hosted by Microsoft Azure and Face++.},
  archive      = {J_TIFS},
  author       = {Xueluan Gong and Shuaike Li and Yanjiao Chen and Mingzhe Li and Rubin Wei and Qian Wang and Kwok-Yan Lam},
  doi          = {10.1109/TIFS.2024.3515792},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {531-546},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Augmenting model extraction attacks against disruption-based defenses},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Game-theoretic neyman-pearson detection to combat strategic
evasion. <em>TIFS</em>, <em>20</em>, 516–530. (<a
href="https://doi.org/10.1109/TIFS.2024.3515834">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The security in networked systems depends greatly on recognizing and identifying adversarial behaviors. Traditional detection methods target specific categories of attacks and have become inadequate against increasingly stealthy and deceptive attacks that are designed to bypass detection strategically. This work proposes game-theoretical frameworks to recognize and combat such evasive attacks. We focus on extending a fundamental class of statistical-based detection methods based on Neyman-Pearson’s (NP) hypothesis testing formulation. We capture the conflicting relationship between a strategic evasive attacker and an evasion-aware NP detector. By analyzing both the equilibrium behaviors of the attacker and the NP detector, we characterize their performance using Equilibrium Receiver-Operational-Characteristic (EROC) curves. We show that the evasion-aware NP detectors outperform the non-strategic ones by allowing them to take advantage of the attacker’s messages to adaptively modify their decision rules to enhance their success rate in detecting anomalies. In addition, we extend our framework to a sequential setting where the user sends out identically distributed messages. We corroborate the analytical results with a case study of an intrusion detection evasion problem.},
  archive      = {J_TIFS},
  author       = {Yinan Hu and Juntao Chen and Quanyan Zhu},
  doi          = {10.1109/TIFS.2024.3515834},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {516-530},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Game-theoretic neyman-pearson detection to combat strategic evasion},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attention consistency refined masked frequency forgery
representation for generalizing face forgery detection. <em>TIFS</em>,
<em>20</em>, 504–515. (<a
href="https://doi.org/10.1109/TIFS.2024.3516561">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the successful development of deep image generation technology, visual data forgery detection would play a more important role in social and economic security. Existing forgery detection methods suffer from unsatisfactory generalization ability to determine the authenticity in the unseen domain. In this paper, we propose a novel Attention Consistency Refined masked frequency forgery representation model toward a generalizing face forgery detection algorithm (ACMF). Most forgery technologies always bring in high-frequency aware cues, which make it easy to distinguish source authenticity but difficult to generalize to unseen artifact types. The masked frequency forgery representation module is designed to explore robust forgery cues by randomly discarding high-frequency information. In addition, we find that the forgery saliency map inconsistency through the detection network could affect the generalizability. Thus, the forgery attention consistency is introduced to force detectors to focus on similar attention regions for better generalization ability. Experiment results on several public face forgery datasets (FaceForensic++, DFD, Celeb-DF, WDF and DFDC datasets) demonstrate the superior performance of the proposed method compared with the state-of-the-art methods. The source code and models are publicly available at https://github.com/chenboluo/ACMF .},
  archive      = {J_TIFS},
  author       = {Decheng Liu and Tao Chen and Chunlei Peng and Nannan Wang and Ruimin Hu and Xinbo Gao},
  doi          = {10.1109/TIFS.2024.3516561},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {504-515},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Attention consistency refined masked frequency forgery representation for generalizing face forgery detection},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HEVC video adversarial samples detection via joint features
of compression and pixel domains. <em>TIFS</em>, <em>20</em>, 488–503.
(<a href="https://doi.org/10.1109/TIFS.2024.3516569">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning models are currently under significant threat from adversarial attacks, while adversarial detection represents an effective means of countering such assaults. However, existing adversarial detection techniques are deficient in localizing video adversarial frames, leading to poor performance on sparse video adversarial attacks. This paper presents an approach for detecting adversarial perturbations in videos based on fusion features derived from the video compression and RGB domain. Our research begins by examining how the introduction of extensive non-natural noise during video adversarial attacks severely disrupts the spatial structure of individual frames and the motion information between frames. This disruption culminates in unnatural variations in the Coding Tree Units (CTU) partitioning during the HEVC video encoding process. Then meticulously mapping the positions and partitioning information of coding units (CU), predictive units (PU), and transformation units (TU) onto specific values and sizes, constituting the video’s Compression Domain Units (CDU) features. Finally, a dual-path network utilizing both the video’s CDU features and the decoded frames RGB features is employed for detecting video adversarial samples. Extensive experiments are conducted to verify the performance. The results show that the proposed scheme outperforms or rivals the state-of-the-art methods in video adversarial detection.},
  archive      = {J_TIFS},
  author       = {Zeyu Zhao and Yueneng Wang and Ke Xu and Tanfeng Sun and Xinghao Jiang},
  doi          = {10.1109/TIFS.2024.3516569},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {488-503},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {HEVC video adversarial samples detection via joint features of compression and pixel domains},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Federated learning minimal model replacement attack using
optimal transport: An attacker perspective. <em>TIFS</em>, <em>20</em>,
478–487. (<a href="https://doi.org/10.1109/TIFS.2024.3516555">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Federated learning (FL) has emerged as a powerful collaborative learning approach that enables client devices to train a joint machine learning model without sharing private data. However, the decentralized nature of FL makes it highly vulnerable to adversarial attacks from multiple sources. There are diverse FL data poisoning and model poisoning attack methods in the literature. Nevertheless, most of them focus only on the attack’s impact and do not consider the attack budget and attack visibility. These factors are essential to effectively comprehend the adversary’s rationale in designing an attack. Hence, our work highlights the significance of considering these factors by providing an attacker perspective in designing an attack with a low budget, low visibility, and high impact. Also, existing attacks that use total neuron replacement and randomly selected neuron replacement approaches only cater to these factors partially. Therefore, we propose a novel federated learning minimal model replacement attack (FL-MMR) that uses optimal transport (OT) for minimal neural alignment between a surrogate poisoned model and the benign model. Later, we optimize the attack budget in a three-fold adaptive fashion by considering critical learning periods and introducing the replacement map. In addition, we comprehensively evaluate our attack under three threat scenarios using three large-scale datasets: GTSRB, CIFAR10, and EMNIST. We observed that our FL-MMR attack drops global accuracy to $\approx 35\%$ less with merely 0.54% total attack budget and lower attack visibility than other attacks. The results confirm that our method aligns closely with the attacker’s viewpoint compared to other methods.},
  archive      = {J_TIFS},
  author       = {K. Naveen Kumar and C. Krishna Mohan and Linga Reddy Cenkeramaddi},
  doi          = {10.1109/TIFS.2024.3516555},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {478-487},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Federated learning minimal model replacement attack using optimal transport: An attacker perspective},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Reinforcement learning-based personalized differentially
private federated learning. <em>TIFS</em>, <em>20</em>, 465–477. (<a
href="https://doi.org/10.1109/TIFS.2024.3515814">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to the different privacy and local model quality requirements for each participant, federated learning (FL) is vulnerable to membership inference attacks. To solve this issue, we propose a risk-aware reinforcement learning (RL)-based personalized differentially private FL framework. This framework uses local model accuracy and privacy loss as the constraints to satisfy the user’s personalized requirements. By designing a multi-agent RL, this framework optimizes perturbation policy including perturbation mechanisms and parameters (such as privacy budget and probabilistic relaxation). The goal of each participant is to improve global accuracy and reduce privacy loss, attack success rate, and short-term risk value. Firstly, the framework designs a two-level hierarchical policy selection module to choose the perturbation policy to accelerate learning speed. Secondly, our proposed framework designs a punishment function to evaluate short-term risk and an R-network to estimate long-term risk, which guarantees safe exploration. Thirdly, this framework formulates an improved Boltzmann policy distribution to increase the impact of risk, thus avoiding risky policies that may cause severe privacy leakage or local task failure. We also analyze the convergence performance and provide privacy analysis for both Gaussian and Laplace mechanisms. Experimental results based on the MNIST dataset demonstrate the effectiveness of our framework compared with benchmarks.},
  archive      = {J_TIFS},
  author       = {Xiaozhen Lu and Zihan Liu and Liang Xiao and Huaiyu Dai},
  doi          = {10.1109/TIFS.2024.3515814},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {465-477},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Reinforcement learning-based personalized differentially private federated learning},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Selfish mining time-averaged analysis in bitcoin: Is orphan
reporting an effective countermeasure? <em>TIFS</em>, <em>20</em>,
449–464. (<a href="https://doi.org/10.1109/TIFS.2024.3518090">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A Bitcoin miner who owns a sufficient amount of mining power can perform selfish mining to increase its relative revenue. Studies have demonstrated that the time-averaged profit of a selfish miner starts to rise once the mining difficulty level gets adjusted in favor of the attacker. Selfish mining profitability lies in the fact that orphan blocks are not incorporated into the current version of Bitcoin’s difficulty adjustment mechanism (DAM). Therefore, it is believed that considering the count of orphan blocks in the DAM can result in complete unprofitability for selfish mining. In this paper, we disprove this belief by providing a formal analysis of the selfish mining time-averaged profit. We present a precise definition of the orphan blocks that can be incorporated into calculating the next epoch’s target and then introduce two modified versions of DAM in which both main-chain blocks and orphan blocks are incorporated. We propose two versions of smart intermittent selfish mining, where the first one dominates the normal intermittent selfish mining, and the second one results in selfish mining profitability under the modified DAMs. Moreover, we present the orphan exclusion attack with the help of which the attacker can stop honest miners from reporting the orphan blocks. Using combinatorial tools, we analyze the profitability of selfish mining accompanied by the orphan exclusion attack under the modified DAMs. Our results show that even when considering orphan blocks in the DAM, selfish mining can still be profitable. However, the level of profitability under the modified DAMs is significantly lower than that observed under the current version of Bitcoin DAM, suggesting that orphan reporting can be an effective countermeasure against a payoff-maximizing selfish miner.},
  archive      = {J_TIFS},
  author       = {Roozbeh Sarenche and Ren Zhang and Svetla Nikova and Bart Preneel},
  doi          = {10.1109/TIFS.2024.3518090},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {449-464},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Selfish mining time-averaged analysis in bitcoin: Is orphan reporting an effective countermeasure?},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Physical adversarial patch attack for optical fine-grained
aircraft recognition. <em>TIFS</em>, <em>20</em>, 436–448. (<a
href="https://doi.org/10.1109/TIFS.2024.3516577">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) have been widely used in remote sensing but demonstrated to be sensitive with adversarial examples. By introducing carefully designed perturbations to clean images, DNNs can be led to incorrect predictions. Adversarial patch is commonly used to conduct adversarial attack, where traditional methods optimize its content and position separately, neglecting the coupling relation of two factors. In this paper, we propose a black-box attack framework targeting fine-grained aircraft recognition, named PatchGen, simultaneously optimizing both content and position of physical adversarial patches. For the requirements of physical attack, we further constrain the patch in object region and utilize elaborate criteria to evaluate its naturalness to alleviate the distortion when applying the patch in real world. We comprehensively validate our method in fine-grained aircraft classification, extending to object detection subsequently. Extensive experiments demonstrate that the proposed method achieves superior attack performance efficiently for classification and detection tasks in digital domain. Moreover, we validate the effectiveness of the adversarial patch under diverse circumstances in the physical world and prove that our method can be applied to different models as well as various domains.},
  archive      = {J_TIFS},
  author       = {Ke Li and Di Wang and Wenxuan Zhu and Shaofeng Li and Quan Wang and Xinbo Gao},
  doi          = {10.1109/TIFS.2024.3516577},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {436-448},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Physical adversarial patch attack for optical fine-grained aircraft recognition},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint finger valley points-free ROI detection and recurrent
layer aggregation for palmprint recognition in open environment.
<em>TIFS</em>, <em>20</em>, 421–435. (<a
href="https://doi.org/10.1109/TIFS.2024.3516539">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cooperative palmprint recognition, pivotal for civilian and commercial uses, stands as the most essential and broadly demanded branch in biometrics. These applications, often tied to financial transactions, require high accuracy in recognition. Currently, research in palmprint recognition primarily aims to enhance accuracy, with relatively few studies addressing the automatic and flexible palm region of interest (ROI) extraction (PROIE) suitable for complex scenes. Particularly, the intricate conditions of open environment, alongside the constraint of human finger skeletal extension limiting the visibility of Finger Valley Points (FVPs), render conventional FVPs-based PROIE methods ineffective. In response to this challenge, we propose an FVPs-Free Adaptive ROI Detection (FFARD) approach, which utilizes cross-dataset hand shape semantic transfer (CHSST) combined with the constrained palm inscribed circle search, delivering exceptional hand segmentation and precise PROIE. Furthermore, a Recurrent Layer Aggregation-based Neural Network (RLANN) is proposed to learn discriminative feature representation for high recognition accuracy in both open-set and closed-set modes. The Angular Center Proximity Loss (ACPLoss) is designed to enhance intra-class compactness and inter-class discrepancy between learned palmprint features. Overall, the combined FFARD and RLANN methods are proposed to address the challenges of palmprint recognition in open environment, collectively referred to as RDRLA. Experimental results on four palmprint benchmarks HIT-NIST-V1, IITD, MPD and BJTU_PalmV2 show the superiority of the proposed method RDRLA over the state-of-the-art (SOTA) competitors. The code of the proposed method is available at https://github.com/godfatherwang2/ RDRLA.},
  archive      = {J_TIFS},
  author       = {Tingting Chai and Xin Wang and Ru Li and Wei Jia and Xiangqian Wu},
  doi          = {10.1109/TIFS.2024.3516539},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {421-435},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Joint finger valley points-free ROI detection and recurrent layer aggregation for palmprint recognition in open environment},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Decaf: Data distribution decompose attack against federated
learning. <em>TIFS</em>, <em>20</em>, 405–420. (<a
href="https://doi.org/10.1109/TIFS.2024.3516545">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In contrast to prevalent Federated Learning (FL) privacy inference techniques such as generative adversarial networks attacks, membership inference attacks, property inference attacks, and model inversion attacks, we devise an innovative privacy threat: the Data Distribution Decompose Attack on FL, termed Decaf . This attack enables an honest-but-curious FL server to meticulously profile the proportion of each class owned by the victim FL user, divulging sensitive information like local market item distribution and business competitiveness. The crux of Decaf lies in the profound observation that the magnitude of local model gradient changes closely mirrors the underlying data distribution, including the proportion of each class. Decaf addresses two crucial challenges: accurately identify the missing/null class(es) given by any victim user as a premise and then quantify the precise relationship between gradient changes and each remaining non-null class. Notably, Decaf operates stealthily, rendering it entirely passive and undetectable to victim users regarding the infringement of their data distribution privacy. Experimental validation on five benchmark datasets (MNIST, FASHION-MNIST, CIFAR-10, FER-2013, and SkinCancer) employing diverse model architectures, including customized convolutional networks, standardized VGG16, and ResNet18, demonstrates Decaf ’s efficacy. Results indicate its ability to accurately decompose local user data distribution, regardless of whether it is IID or non-IID distributed. Specifically, the dissimilarity measured using $L_{\infty }$ distance between the distribution decomposed by Decaf and ground truth is consistently below 5% when no null classes exist. Moreover, Decaf achieves 100% accuracy in determining any victim user’s null classes, validated through formal proof.},
  archive      = {J_TIFS},
  author       = {Zhiyang Dai and Yansong Gao and Chunyi Zhou and Anmin Fu and Zhi Zhang and Minhui Xue and Yifeng Zheng and Yuqing Zhang},
  doi          = {10.1109/TIFS.2024.3516545},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {405-420},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Decaf: Data distribution decompose attack against federated learning},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Illicit social accounts? Anti-money laundering for
transactional blockchains. <em>TIFS</em>, <em>20</em>, 391–404. (<a
href="https://doi.org/10.1109/TIFS.2024.3518068">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, blockchain anonymity has led to more illicit accounts participating in various money laundering transactions. Existing studies typically detect money laundering transactions, known as AML (Anti-money Laundering), through learning transaction features on transaction graphs of transactional blockchains. However, transaction graphs fail to represent the accounts’ social features within transactional organizations. Account graphs reveal such features well, and detecting illicit accounts on account graphs provides a new perspective on AML. For example, it helps uncover illegal transactions whose transaction features are not distinct in transaction graphs, with a loose assumption that illicit accounts are likely involved in illegal transactions. In this paper, we propose a Social Attention Graph Neural Network ( $\textsf {SGNN}$ ) on account graphs converted from transaction graphs. To detect illicit accounts, $\textsf {SGNN}$ learns the social features on two sub-graphs, a heterogeneous graph and a hypergraph, extracted from the account graph, and fuses these features into account attribute vectors through attention. The experimental results on the Elliptic++ dataset demonstrate $\textsf {SGNN}$ ’s advances. It outperforms the best baseline by 14.18% in precision, 7.37% in F1 score, 0.96% in accuracy, and 0.64% in recall when detecting illicit accounts on account graphs, as well as detects 20.3% more recall of illegal transactions through these illicit accounts than state-of-the-art methods based on transaction graphs when the mappings between illegal transactions and illicit accounts are provided. Moreover, thanks to social features, $\textsf {SGNN}$ has a novel capability that works under many account scales and activity degrees. We release our code on https://github.com/CloudLab-NEU/SGNN .},
  archive      = {J_TIFS},
  author       = {Jie Song and Sijia Zhang and Pengyi Zhang and Junghoon Park and Yu Gu and Ge Yu},
  doi          = {10.1109/TIFS.2024.3518068},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {391-404},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Illicit social accounts? anti-money laundering for transactional blockchains},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). LCMA: A novel lightweight continuous message authentication
for cyber-physical system. <em>TIFS</em>, <em>20</em>, 375–390. (<a
href="https://doi.org/10.1109/TIFS.2024.3516580">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cyber-Physical Systems (CPS) consist of various physical devices and have a significant impact on both industry and the economy. In CPS, controllers or control centers typically send continuous commands to actuators. Due to the limited computational and storage resources of CPS devices, existing Message Authentication Code and digital signature algorithms face challenges in terms of being non-interactive, lightweight, and continuous on the actuator side. To address this issue, we propose a lightweight continuous message authentication (LCMA) scheme that ensures the continuity of signatures through a mechanism involving random numbers and incrementing sub-private keys. The multidimensional Bloom filters is designed and used togather with precomputed verification points generated by Key Generation Center to enable non-interactive verification. Additionally, we design a redundancy-free hash tree for CPS to reduce information redundancy. The proposed solution requires only hash operations and Bloom filter queries for verification, achieving sufficient lightweight performance. Finally, we provide a formal security proof for the proposed scheme and simulate it on the ESP32 platform. The results show that the implementation times for signature generation and verification are 0.779 milliseconds and 0.792 milliseconds, respectively. Compared to other non-interactive lightweight message authentication schemes, the proposed LCMA is more suitable for CPS devices.},
  archive      = {J_TIFS},
  author       = {Shouxu Han and Jie Liu and Yi Luo and Hongping Gan},
  doi          = {10.1109/TIFS.2024.3516580},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {375-390},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {LCMA: A novel lightweight continuous message authentication for cyber-physical system},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NMFAD: Neighbor-aware mask-filling attributed network
anomaly detection. <em>TIFS</em>, <em>20</em>, 364–374. (<a
href="https://doi.org/10.1109/TIFS.2024.3516570">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a widely adopted protocol for anomaly detection in attributed networks, reconstruction error prioritizes comprehensive feature extraction to detect anomalies over interrogating the differential representation between normal and abnormal nodes. Intuitively, in attributed networks, normal nodes and their neighbors often exhibit similarities, whereas abnormal nodes demonstrate behaviors distinct from their neighbors. Hence, normal nodes can be accurately represented through their neighbors and effectively reconstructed. As opposed to normal nodes, abnormal nodes represented by their neighbors may be erroneously reconstructed as normal, resulting in increased reconstruction error. Leveraging from this observation, we propose a novel anomaly detection protocol called Neighbor-aware Mask-Filling Anomaly Detection (NMFAD) for attributed networks, aiming to maximize the variability between original and reconstructed features of abnormal nodes filled with information from their neighbors. Specifically, we utilize random-mask on nodes and integrate them into the backbone Graph Neural Networks (GNNs) to map nodes into a latent space. Subsequently, we fill the masked nodes with embeddings from their neighbors and smooth the abnormal nodes closer to the distribution of normal nodes. This optimization improves the likelihood of the decoder to reconstructing abnormal nodes as normal, thereby maximizing the reconstruction error of abnormal nodes. Experimental results demonstrate that, compared to the existing models, NMFAD exhibits superior performance.in attributed networks.},
  archive      = {J_TIFS},
  author       = {Liang Xi and Runze Li and Menghan Li and Dehua Miao and Ruidong Wang and Zygmunt J. Haas},
  doi          = {10.1109/TIFS.2024.3516570},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {364-374},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {NMFAD: Neighbor-aware mask-filling attributed network anomaly detection},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hard adversarial example mining for improving robust
fairness. <em>TIFS</em>, <em>20</em>, 350–363. (<a
href="https://doi.org/10.1109/TIFS.2024.3516554">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AEs). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems. Recent works in this field usually apply class-wise regularization methods to enhance the fairness of AT. However, this paper discovers that these paradigms can be sub-optimal in improving robust fairness. Specifically, we empirically observe that the AEs that are already robust (referred to as “easy AEs” in this paper) are useless and even harmful in improving robust fairness. To this end, we propose the hard adversarial example mining (HAM) technique which concentrates on mining hard AEs while discarding the easy AEs in AT. Specifically, HAM identifies the easy AEs and hard AEs with a fast adversarial attack method. By discarding the easy AEs and reweighting the hard AEs, the robust fairness of the model can be efficiently and effectively improved. Extensive experimental results on four image classification datasets demonstrate the improvement of HAM in robust fairness and training efficiency compared to several state-of-the-art fair adversarial training methods. Our code is available at https://github.com/yyl-github-1896/HAM .},
  archive      = {J_TIFS},
  author       = {Chenhao Lin and Xiang Ji and Yulong Yang and Qian Li and Zhengyu Zhao and Zhe Peng and Run Wang and Liming Fang and Chao Shen},
  doi          = {10.1109/TIFS.2024.3516554},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {350-363},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Hard adversarial example mining for improving robust fairness},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Synchronous byzantine agreement with o(n) messages and o(1)
expected time. <em>TIFS</em>, <em>20</em>, 338–349. (<a
href="https://doi.org/10.1109/TIFS.2024.3515854">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Byzantine agreement is the most fundamental primitive in distributed computing. All known Byzantine agreement protocols achieve quadratic or sub-quadratic messages and communication. We show that surprisingly, by directly assuming a random leader election oracle (that can be built from the verifiable random function), threshold signatures, and the $1/3$ corruption bound, we can build Linear-BA, a binary agreement (BA) that has linear message complexity, constant expected time complexity, and a normal case that has linear communication. We extend Linear-BA to construct Linear-MBA, a multi-valued Byzantine agreement (MBA) protocol also with $O(n)$ messages and $O(1)$ expected time. Finally, we present Linear-MBA-SV, an MBA protocol with the strong validity property via a no-cost transformation from Linear-MBA. All the protocols above are secure under a static adversary, where a static adversary corrupts a set of replicas at the beginning of the protocol. We go on and show an impossibility result that in the adaptive adversary model (in which the adversary can selectively corrupt the replicas while the protocol is running), one cannot build a Byzantine agreement protocol with $O(n)$ messages and $O(1)$ expected time. Accordingly, we revise our protocol to obtain Byzantine agreement protocols with $O(n)$ messages per round and $O(n)$ time. Our results offer a fresh view of what is needed for linear Byzantine agreement: by examining the “needed” assumptions, one can identify the performance bottlenecks for Byzantine agreement. Meanwhile, all our protocols are efficient, as all the building blocks have efficient instantiations.},
  archive      = {J_TIFS},
  author       = {Haochen Wang and Qidi You and Sisi Duan},
  doi          = {10.1109/TIFS.2024.3515854},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {338-349},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Synchronous byzantine agreement with o(n) messages and o(1) expected time},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-authority attribute-based encryption scheme with
access delegation for cross blockchain data sharing. <em>TIFS</em>,
<em>20</em>, 323–337. (<a
href="https://doi.org/10.1109/TIFS.2024.3515812">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To achieve fine-grained access control and address the data silos challenge in data sharing, the integration of blockchain with attribute-based encryption emerges as a promising solution. Nowadays, the growing interconnectedness among diverse blockchain applications has spurred the need for efficient cross-chain data sharing. However, existing single-authority attribute-based data sharing schemes are not suitable for such cross-chain scenarios involving multiple attribute authorities. Moreover, the frequent requirement for data owners to process cross-chain data requests significantly hampers practicality. In this context, we introduce a novel multi-authority attribute-based proxy re-encryption scheme that enables ciphertext policy updating and supports secure and efficient cross-chain data sharing. By introducing a proxy, the data owner is empowered to delegate access without leaking any valid information and flexibly sells data across blockchains through cross-chain access policies. Besides, our scheme leverages the relay chain to foster a decentralized and trustworthy ecosystem. The adoption of smart contracts automates the cross-chain data sharing process and ensures equitable distribution of benefits among participants. Additionally, our scheme integrates hybrid encryption with the decentralized data hosting platform, substantially mitigating the on-chain storage burden. Security analysis affirms that our scheme is semantically secure and resistant to collusion attack. Performance analysis and simulation experiments demonstrate the excellent efficiency and practicality of our scheme when conducting cross-chain data sharing.},
  archive      = {J_TIFS},
  author       = {Pengfei Duan and Zhaofeng Ma and Hongmin Gao and Tian Tian and Yuqing Zhang},
  doi          = {10.1109/TIFS.2024.3515812},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {323-337},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Multi-authority attribute-based encryption scheme with access delegation for cross blockchain data sharing},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Byzantine fault tolerance with non-determinism, revisited.
<em>TIFS</em>, <em>20</em>, 309–322. (<a
href="https://doi.org/10.1109/TIFS.2024.3516541">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Conventional Byzantine fault tolerance (BFT) requires replicated state machines to execute deterministic operations only. In practice, numerous applications and scenarios, especially in the era of blockchains, contain various sources of non-determinism. Meanwhile, it is even sometimes desirable to support non-determinism, and replicas still agree on the execution results. Despite decades of research on BFT, we still lack an efficient and easy-to-deploy solution for BFT with non-determinism—BFT-ND, especially in the asynchronous setting. We revisit the problem of BFT-ND and provide a formal and asynchronous treatment of BFT-ND. In particular, we design and implement Block-ND that insightfully separates the task of agreeing on the order of transactions from the task of agreement on the state: Block-ND allows reusing existing BFT implementations; on top of BFT, we reduce the agreement on the state to multivalued Byzantine agreement (MBA), a somewhat neglected primitive by practical systems. Block-ND is completely asynchronous as long as the underlying BFT is asynchronous. We provide a new MBA construction that is significantly faster than existing MBA constructions. We instantiate Block-ND in both the partially synchronous setting (with PBFT, OSDI 1999) and the purely asynchronous setting (with PACE, CCS 2022). Via a 91-instance WAN deployment on Amazon EC2, we show that Block-ND has only marginal performance degradation compared to conventional BFT.},
  archive      = {J_TIFS},
  author       = {Yue Huang and Huizhong Li and Yi Sun and Sisi Duan},
  doi          = {10.1109/TIFS.2024.3516541},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {309-322},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Byzantine fault tolerance with non-determinism, revisited},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A multiscale discriminative attack method for automatic
modulation classification. <em>TIFS</em>, <em>20</em>, 294–308. (<a
href="https://doi.org/10.1109/TIFS.2024.3515802">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic Modulation Classification (AMC)-oriented Deep Neural Networks (ADNNs) have received much attention in recent years for their wide range of applications. However, they are vulnerable to attacks. Adversarial Examples (AEs) of modulation signals with added weak perturbations can easily fool ADNNs. The study of AEs on AMC, on one side, can enhance the security of wireless communication systems; on the other side, it can provide an effective defence against potential attacks. Nevertheless, most existing attack methods generate AEs with low transferability. In this paper, we propose a Multiscale Discriminative Attack Method (MDAM) for modulated signals. The method strives to alleviate such transferability issue by destroying discriminative features in multi-layer. Specifically, we utilize interpretable class activation maps to distinguish the discriminative regions, ignoring the noise and focusing on the interference of the discriminative features. Beyond that, we propose a multi-layer activation disruption loss to constrain activations in the middle layers. In so doing, the AEs do not erroneously retain deep features of the original signal. We conduct extensive experiments on RadioML datasets and the local area network (LAN) communication dataset we collected to evaluate the effectiveness of MDAM in both white-box and black-box attack scenarios. The results show that MDAM outperforms existing methods.},
  archive      = {J_TIFS},
  author       = {Jing Bai and Chang Ge and Zhu Xiao and Hongbo Jiang and Tong Li and Huaji Zhou and Licheng Jiao},
  doi          = {10.1109/TIFS.2024.3515802},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {294-308},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {A multiscale discriminative attack method for automatic modulation classification},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Global or local adaptation? Client-sampled federated
meta-learning for personalized IoT intrusion detection. <em>TIFS</em>,
<em>20</em>, 279–293. (<a
href="https://doi.org/10.1109/TIFS.2024.3516548">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the increasing size of Internet of Things (IoT) devices, cyber threats to IoT systems have increased. Federated learning (FL) has been implemented in an anomaly-based intrusion detection system (NIDS) to detect malicious traffic in IoT devices and counter the threat. However, current FL-based NIDS mainly focuses on global model performance and lacks personalized performance improvement for local data. To address this issue, we propose a novel personalized federated meta-learning intrusion detection approach (PerFLID), which allows multiple participants to personalize their local detection models for local adaptation. PerFLID shifts the goal of the personalized detection task to training a local model suitable for the client’s specific data, rather than a global model. To meet the real-time requirements of NIDS, PerFLID further refines the client selection strategy by clustering the local gradient similarities to find the nodes that contribute the most to the global model per global round. PerFLID can select the nodes that accelerate the convergence of the model, and we theoretically analyze the improvement in the convergence speed of this strategy over the personalized federated learning algorithm. We experimentally evaluate six existing FL-NIDS approaches on three real network traffic datasets and show that our PerFLID approach outperforms all baselines in detecting local adaptation accuracy by 10.11% over the state-of-the-art scheme, accelerating the convergence speed under various parameter combinations.},
  archive      = {J_TIFS},
  author       = {Haorui Yan and Xi Lin and Shenghong Li and Hao Peng and Bo Zhang},
  doi          = {10.1109/TIFS.2024.3516548},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {279-293},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Global or local adaptation? client-sampled federated meta-learning for personalized IoT intrusion detection},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepCRF: Deep learning-enhanced CSI-based RF fingerprinting
for channel-resilient WiFi device identification. <em>TIFS</em>,
<em>20</em>, 264–278. (<a
href="https://doi.org/10.1109/TIFS.2024.3515796">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents DeepCRF, a new framework that harnesses deep learning to extract subtle micro-signals from channel state information (CSI) measurements, enabling robust and resilient radio-frequency fingerprinting (RFF) of commercial-off-the-shelf (COTS) WiFi devices across diverse channel conditions. Building on our previous research, which demonstrated that micro-signals in CSI, termed micro-CSI, most likely originate from RF circuitry imperfections and can serve as unique RF fingerprints, we develop a new approach to overcome the limitations of our prior signal space-based method. While the signal space-based method is effective in strong line-of-sight (LoS) conditions, we show that it struggles with the complexities of non-line-of-sight (NLoS) scenarios, compromising the robustness of CSI-based RFF. To address this challenge, DeepCRF incorporates a carefully trained convolutional neural network (CNN) with model-inspired data augmentation, supervised contrastive learning, and decision fusion techniques, enhancing its generalization capabilities across unseen channel conditions and resilience against noise. Our evaluations demonstrate that DeepCRF significantly improves device identification accuracy across diverse channels, outperforming both the signal space-based baseline and state-of-the-art neural network-based benchmarks. Notably, it achieves an average identification accuracy of 99.53% among 19 COTS WiFi network interface cards in real-world unseen scenarios using 4 CSI measurements per identification procedure.},
  archive      = {J_TIFS},
  author       = {Ruiqi Kong and He Chen},
  doi          = {10.1109/TIFS.2024.3515796},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {264-278},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {DeepCRF: Deep learning-enhanced CSI-based RF fingerprinting for channel-resilient WiFi device identification},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Joint identity verification and pose alignment for partial
fingerprints. <em>TIFS</em>, <em>20</em>, 249–263. (<a
href="https://doi.org/10.1109/TIFS.2024.3516566">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Currently, portable electronic devices are becoming more and more popular. For lightweight considerations, their fingerprint recognition modules usually use limited-size sensors. However, partial fingerprints have few matchable features, especially when there are differences in finger pressing posture or image quality, which makes partial fingerprint verification challenging. Most existing methods regard fingerprint position rectification and identity verification as independent tasks, ignoring the coupling relationship between them—relative pose estimation typically relies on paired features as anchors, and authentication accuracy tends to improve with more precise pose alignment. In this paper, we propose a novel framework for joint identity verification and pose alignment of partial fingerprint pairs, aiming to leverage their inherent correlation to improve each other. To achieve this, we present a multi-task CNN (Convolutional Neural Network)-Transformer hybrid network, and design a pre-training task to enhance the feature extraction capability. Experiments on multiple public datasets (NIST SD14, FVC2002 DB1_A &amp; DB3_A, FVC2004 DB1_A &amp; DB2_A, FVC2006 DB1_A) and an in-house dataset demonstrate that our method achieves state-of-the-art performance in both partial fingerprint verification and relative pose estimation, while being more efficient than previous methods. Code is available at: https://github.com/XiongjunGuan/JIPNet .},
  archive      = {J_TIFS},
  author       = {Xiongjun Guan and Zhiyu Pan and Jianjiang Feng and Jie Zhou},
  doi          = {10.1109/TIFS.2024.3516566},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {249-263},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Joint identity verification and pose alignment for partial fingerprints},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmentation matters: A mix-paste method for x-ray
prohibited item detection under noisy annotations. <em>TIFS</em>,
<em>20</em>, 234–248. (<a
href="https://doi.org/10.1109/TIFS.2024.3516546">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automatic X-ray prohibited item detection is vital for public safety. Existing deep learning-based methods all assume that the annotations of training X-ray images are correct. However, obtaining correct annotations is extremely hard if not impossible for large-scale X-ray images, where item overlapping is ubiquitous. As a result, X-ray images are easily contaminated with noisy annotations, leading to performance deterioration of existing methods. In this paper, we address the challenging problem of training a robust prohibited item detector under noisy annotations (including both category noise and bounding box noise) from a novel perspective of data augmentation, and propose an effective label-aware mixed patch paste augmentation method (Mix-Paste). Specifically, for each item patch, we mix several item patches with the same category label from different images and replace the original patch in the image with the mixed patch. In this way, the probability of containing the correct prohibited item within the generated image is increased. Meanwhile, the mixing process mimics item overlapping, enabling the model to learn the characteristics of X-ray images. Moreover, we design an item-based large-loss suppression (LLS) strategy to suppress the large losses corresponding to potentially positive predictions of additional items due to the mixing operation. We show the superiority of our method on X-ray datasets under noisy annotations. In addition, we evaluate our method on the noisy MS-COCO dataset to showcase its generalization ability. These results clearly indicate the great potential of data augmentation to handle noise annotations. The source code is released at https://github.com/wscds/Mix-Paste .},
  archive      = {J_TIFS},
  author       = {Ruikang Chen and Yan Yan and Jing-Hao Xue and Yang Lu and Hanzi Wang},
  doi          = {10.1109/TIFS.2024.3516546},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {234-248},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Augmentation matters: A mix-paste method for X-ray prohibited item detection under noisy annotations},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balancing differential privacy and utility: A
relevance-based adaptive private fine-tuning framework for language
models. <em>TIFS</em>, <em>20</em>, 207–220. (<a
href="https://doi.org/10.1109/TIFS.2024.3516579">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Differential privacy (DP) has been proven to be an effective universal solution for privacy protection in language models. Nevertheless, the introduction of DP incurs significant computational overhead. One promising approach to this challenge is to integrate Parameter Efficient Fine-Tuning (PEFT) with DP, leveraging the memory-efficient characteristics of PEFT to reduce the substantial memory consumption of DP. Given that fine-tuning aims to quickly adapt pretrained models to downstream tasks, it is crucial to balance privacy protection with model utility to avoid excessive performance compromise. In this paper, we propose a Relevance-based Adaptive Private Fine-Tuning (Rap-FT) framework, the first approach designed to mitigate model utility loss caused by DP perturbations in the PEFT context, and to achieve a balance between differential privacy and model utility. Specifically, we introduce an enhanced layer-wise relevance propagation process to analyze the relevance of trainable parameters, which can be adapted to the three major categories of PEFT methods. Based on the relevance map generated, we partition the parameter space dimensionally, and develop an adaptive gradient perturbation strategy that adjusts the noise addition to mitigate the adverse impacts of perturbations. Extensive experimental evaluations are conducted to demonstrate that our Rap-FT framework can improve the utility of the fine-tuned model compared to the baseline differentially private fine-tuning methods, while maintaining a comparable level of privacy protection.},
  archive      = {J_TIFS},
  author       = {Naiyu Wang and Shen Wang and Meng Li and Longfei Wu and Zijian Zhang and Zhitao Guan and Liehuang Zhu},
  doi          = {10.1109/TIFS.2024.3516579},
  journal      = {IEEE Transactions on Information Forensics and Security},
  month        = {12},
  pages        = {207-220},
  shortjournal = {IEEE Trans. Inf. Forensics Security},
  title        = {Balancing differential privacy and utility: A relevance-based adaptive private fine-tuning framework for language models},
  volume       = {20},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
