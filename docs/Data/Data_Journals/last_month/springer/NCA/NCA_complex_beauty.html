<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>NCA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="nca---89">NCA - 89</h2>
<ul>
<li><details>
<summary>
(2025). Real-time arabic sign language recognition system using
sensory glove and machine learning. <em>NCA</em>, <em>37</em>(9),
6977–6993. (<a
href="https://doi.org/10.1007/s00521-025-11010-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article aims to present a novel Arabic sign language recognition (SLR) strategy using sensory glove and machine learning. The article focuses on hand gesture recognition through the development of a glove-computer system designed for real-time hand posture detection and gesture-to-text translation. Gesture recognition plays a crucial role in enhancing interactions between humans and machines, making technology more intuitive and efficient. This technology has potential applications in various fields such as smart homes, gaming, automotive systems, and virtual reality. The primary goal of this article is then to create a supportive communication environment for individuals with speaking difficulties. The article began with the development of a sensory glove equipped with sensors to detect hand orientation and finger flexing, with data processed and transmitted wirelessly to a computer for machine learning prediction. A dynamic dataset, which included signs for letters and movement-based signs for words, was created and used to build two machine learning models: Support Vector Machine (SVM) model with feature extraction (SVM-FE model) and Long Short-Term Memory (LSTM) model. The proposed deep learning LSTM model demonstrated superior performance with accuracy of 99.6%. Based on these findings, a real-time recognition application was developed using the LSTM model, effectively showcasing the system&#39;s practical applicability in real-world scenarios.},
  archive      = {J_NCA},
  author       = {Halabi, Mohamad and Harkouss, Youssef},
  doi          = {10.1007/s00521-025-11010-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6977-6993},
  shortjournal = {Neural Comput. Appl.},
  title        = {Real-time arabic sign language recognition system using sensory glove and machine learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved transfer learning model for detection of
insulator defects in power transmission lines. <em>NCA</em>,
<em>37</em>(9), 6951–6976. (<a
href="https://doi.org/10.1007/s00521-025-11011-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Insulators are critical components of transmission lines but are prone to failures that can jeopardize the safe operation of electrical power systems. Accurate detection of insulator defects is essential for timely maintenance. With advancements in object detection algorithm and artificial intelligence, insulator defect detection has garnered significant attention. However, detection accuracy remains an issue. To address this, we propose an improved transfer learning model. Our approach incorporates the Mish activation function and a global context network module to enhance the model&#39;s performance. The improved YOLOv9 model is trained and tested using two public datasets: the insulator defect image dataset and the China power line insulator dataset. Experimental results demonstrate that our model achieves optimal detection precision and recall rates of 99.84 and 99.92%, respectively—improvements of 1.06 and 1.09% over the actual YOLOv9. Additionally, our model outperforms other algorithms, such as RTDETR and SSD, particularly in adapting to complex backgrounds and detecting small targets.},
  archive      = {J_NCA},
  author       = {Pradeep, V. and Baskaran, K. and Evangeline, S. Ida},
  doi          = {10.1007/s00521-025-11011-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6951-6976},
  shortjournal = {Neural Comput. Appl.},
  title        = {An improved transfer learning model for detection of insulator defects in power transmission lines},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PDC-ViT: Source camera identification using pixel difference
convolution and vision transformer. <em>NCA</em>, <em>37</em>(9),
6933–6949. (<a
href="https://doi.org/10.1007/s00521-025-11004-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Source camera identification has emerged as a vital solution to unlock incidents involving critical cases like terrorism, violence, and other criminal activities. The ability to trace the origin of an image/video can aid law enforcement agencies in gathering evidence and constructing the timeline of events. Moreover, identifying the owner of a certain device narrows down the area of search in a criminal investigation where smartphone devices are involved. This paper proposes a new pixel-based method for source camera identification, integrating Pixel Difference Convolution (PDC) with a Vision Transformer network (ViT), and named PDC-ViT. While the PDC acts as the backbone for feature extraction by exploiting Angular PDC (APDC) and Radial PDC (RPDC). These techniques enhance the capability to capture subtle variations in pixel information, which are crucial for distinguishing between different source cameras. The second part of the methodology focuses on classification, which is based on a Vision Transformer network. Unlike traditional methods that utilize image patches directly for training the classification network, the proposed approach uniquely inputs PDC features into the Vision Transformer network. To demonstrate the effectiveness of the PDC-ViT approach, it has been assessed on five different datasets, which include various image contents and video scenes. The method has also been compared with state-of-the-art source camera identification methods. Experimental results demonstrate the effectiveness and superiority of the proposed system in terms of accuracy and robustness when compared to its competitors. For example, our proposed PDC-ViT has achieved an accuracy of 94.30%, 84%, 94.22% and 92.29% using the Vision dataset, Daxing dataset, Socrates dataset and QUFVD dataset, respectively.},
  archive      = {J_NCA},
  author       = {Elharrouss, Omar and Akbari, Younes and Almadeed, Noor and Al-Maadeed, Somaya and Khelifi, Fouad and Bouridane, Ahmed},
  doi          = {10.1007/s00521-025-11004-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6933-6949},
  shortjournal = {Neural Comput. Appl.},
  title        = {PDC-ViT: Source camera identification using pixel difference convolution and vision transformer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An effective deep learning-based automatic prediction and
classification of alzheimer’s disease using EGELU-SZN technique.
<em>NCA</em>, <em>37</em>(9), 6915–6932. (<a
href="https://doi.org/10.1007/s00521-025-10994-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recently, Alzheimer’s disease (AD) has become a serious hazard to human health. Therefore, an optimal strategy for formulating the treatment plan is the AD’s early diagnosis. In spite of this, no effective treatment or accurate diagnosis exists currently. Also, the pre-selection of brain regions is a complicated task. Therefore, an efficient AD classification is needed. Hence, by utilizing the Exponential Gaussian Error Linear Unit–Squeeze Net (EGELU-SZN) technique, an early prediction as well as classification of AD is proposed. Primarily, from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset, the input brain Magnetic Resonance Imaging (MRI) images are gathered. For the brain MRI images, a skull stripping process is executed. Here, by utilizing the Adaptive Median Otsu’s Thresholding (AMOT) technique, the skull along with cerebral tissues like fat and skin around the brain are removed. After that, to eliminate the noise, pre-processing is computed. After pre-processing, to segment the brain region accurately, segmentation is evaluated. Therefore, an effectual segmentation algorithm termed Rectilinear Mayfly Optimization-centric Automatic Seeded Region Growing algorithm (RMF-ASRG) has been utilized. Features are extracted as of the segmented brain region. Later, by utilizing the Reflective Correlation Principal Component Analysis (RCPCA) algorithm, the reduction of features is performed. Then, the predicted outcomes are classified as AD, Cognitive Normal (CN), as well as Mild Cognitive Impairment (MCI) by employing the EGELU-SZN Classifier. The proposed EGELU-SZN attained the accuracy, precision, recall, specificity, and sensitivity values of 95.9882%, 94.1661%, 93.2327%, 92.8744%, and 96.2327%, respectively, in the classification process. Experimental outcomes signified that superior performance was attained by the proposed methodology when analyzed with benchmark methodologies.},
  archive      = {J_NCA},
  author       = {Sathyabhama, B. and Kannan, M.},
  doi          = {10.1007/s00521-025-10994-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6915-6932},
  shortjournal = {Neural Comput. Appl.},
  title        = {An effective deep learning-based automatic prediction and classification of alzheimer&#39;s disease using EGELU-SZN technique},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing text understanding of decoder-based model by
leveraging parameter-efficient fine-tuning method. <em>NCA</em>,
<em>37</em>(9), 6899–6913. (<a
href="https://doi.org/10.1007/s00521-025-10975-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machine reading comprehension (MRC) is a fundamental natural language understanding task in natural language processing, which aims to comprehend the text of a given passage and answer questions based on it. Understanding implicit information, deducing the logical structure of information, and connecting context from different pieces of information make the MRC task difficult. Most current state-of-the-art approaches for MRC are using encoder-based models. However, no earlier research proposed a decoder-only model for MRC question-answering datasets, although language models based on this category achieved unprecedented performance in different generative tasks. In this paper, we propose a parameter-efficient fine-tuning framework that effectively increases MRC capabilities on decoder-only large language models. This framework designs the process for MRC and introduces the low-rank adaptation (LoRA) method to effectively fine-tune the large model with many parameters, even with lower hardware resource requirements than the previous methods. In addition, we also integrate a quantized model inference strategy for the fine-tuned model to improve practicability further. We conducted experiments on four types of MRC datasets. After extensive experiments, our results show that our model achieved a significant performance boost over baselines and outperformed other strong models for MRC.},
  archive      = {J_NCA},
  author       = {Feroze, Wasif and Cheng, Shaohuan and Jimale, Elias Lemuye and Jakhro, Abdul Naveed and Qu, Hong},
  doi          = {10.1007/s00521-025-10975-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6899-6913},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing text understanding of decoder-based model by leveraging parameter-efficient fine-tuning method},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An enhanced neuro-adaptive PID sliding mode control for
robot manipulators: Promoting sustainable automation. <em>NCA</em>,
<em>37</em>(9), 6877–6898. (<a
href="https://doi.org/10.1007/s00521-025-10980-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The control of robot manipulators presents significant challenges, primarily due to their complex, nonlinear dynamics. Another major difficulty arises from environmental and operational disturbances. Numerous control frameworks and approaches have been proposed in the literature to address these issues. However, many of these approaches are discontinuous or non-adaptive, which negatively affects their performance and makes them unsuitable for real-time applications. This paper proposes a novel integrated control scheme that combines adaptive control with an improved continuous second-order sliding mode control (CSOS), utilizing generalized artificial neural networks (GANN) for enhanced performance in robot manipulators. The proposed control method consists of two key components: An adaptive proportional-integral-derivative (PID) controller and an adaptive CSOS-based control module (CSOSSD-APID), designed to deliver superior transient and steady-state performance. In this approach, the adaptive CSOS benefits from GANN’s strong noise handling capabilities and its ability to estimate uncertainties effectively. This integration significantly enhances the robustness of robot manipulator control across various tracking tasks, using a single pre-trained GANN model with fine-tuned weights tailored to each task. Numerical simulations demonstrate the effectiveness and versatility of the proposed control scheme, particularly in managing highly time-varying trajectories while contributing to more sustainable and efficient automation practices.},
  archive      = {J_NCA},
  author       = {Elmogy, Ahmed and Alhemaly, Nagah and El-Ghaish, Hany and Elawady, Wael},
  doi          = {10.1007/s00521-025-10980-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6877-6898},
  shortjournal = {Neural Comput. Appl.},
  title        = {An enhanced neuro-adaptive PID sliding mode control for robot manipulators: Promoting sustainable automation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An active learning framework for adversarial training of
deep neural networks. <em>NCA</em>, <em>37</em>(9), 6849–6876. (<a
href="https://doi.org/10.1007/s00521-024-10851-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces a novel approach to bolster the robustness of Deep Neural Network (DNN) models against adversarial attacks named “Targeted Adversarial Resilience Learning (TARL)”. The initial evaluation of a baseline DNN model reveals a significant accuracy decline when subjected to adversarial examples generated through techniques like FGSM, PGD, Carlini Wagner, and DeepFool attacks. To address this vulnerability, the article proposes an active learning framework, wherein the model iteratively identifies and learns from the most uncertain and misclassified instances. The key components of this approach include uncertainty estimation score in predicting the class of the input sample, selecting challenging samples based on this uncertainty score, labeling these challenging examples and augmenting them into the training set, and thereafter retraining the model with the expanded training set. The iterative active learning process, governed by parameters such as the number of iterations and batch size, demonstrates the potential to systematically enhance the resilience of DNN against adversarial threats. The proposed methodology has been investigated on several popular datasets such as the SARS-CoV-2 CT scan, MNIST, CIFAR-10, and Caltech-101, and demonstrated to be effective. Experiments illustrate that the learning framework improves the adversarial accuracies from 17.4% to 98.71% for the SARS-CoV-2 dataset, from 8.4% to 99.89% for the MNIST dataset, 1.6% to 78.84% for the CIFAR-10, and 12% to 92.92% for Caltech-101. Further, comparative analysis with several state-of-the-art methods suggests that the proposed framework offers superior defense against various attack methods and offers promising defensive mechanisms to deep neural networks.},
  archive      = {J_NCA},
  author       = {Ghosh, Susmita and Chatterjee, Abhiroop and Fiondella, Lance},
  doi          = {10.1007/s00521-024-10851-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6849-6876},
  shortjournal = {Neural Comput. Appl.},
  title        = {An active learning framework for adversarial training of deep neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced segmentation of optic disc and cup using
attention-based u-net with dense dilated series convolutions.
<em>NCA</em>, <em>37</em>(9), 6831–6847. (<a
href="https://doi.org/10.1007/s00521-025-10989-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Delineating the boundaries of the optic disc and cup regions is a critical pre-requisite for glaucoma screening because it allows for precise measurement of key parameters, such as cup-to-disc ratio, which is a critical indicator of optic nerve head damage, a hallmark of glaucoma progression. Accurate segmentation enables early detection and monitoring of the disease, aiding in timely intervention to prevent vision loss. The main contribution of this research work is to develop an automated process to isolate and demarcate the optic disc and cup from retinal fundus images. To prevent the blood vessels from interfering with the segmentation process, a novel method is used for vessel mask generation and vessel inpainting. Most of the research works have used based encoder–decoder models like U-Net architecture or handcrafted feature extraction techniques such as hough transform, fuzzy clustering, etc. The proposed model has made significant modifications to the U-Net model. (1) Dual attention mechanism at every layer of decoder and (2) dense dilated series convolutions as skip connections to generate higher level feature map. The proposed model achieved benchmark accuracies - Dice score of 95.95% and IoU score of 92.22% for optic disc segmentation averaged over fivefold. For the task of outlining the optic cup region, it attained a Dice score of 88.7% and IoU of 79.72%.},
  archive      = {J_NCA},
  author       = {Kumar, G. Bharadwaja and Kumar, Soham},
  doi          = {10.1007/s00521-025-10989-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6831-6847},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhanced segmentation of optic disc and cup using attention-based U-net with dense dilated series convolutions},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Differential analysis of alternative splicing events in gene
regions using residual neural networks. <em>NCA</em>, <em>37</em>(9),
6819–6829. (<a
href="https://doi.org/10.1007/s00521-025-10992-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Several computational methods for the differential analysis of alternative splicing (AS) events among RNA-Seq samples typically rely on estimating isoform-level gene expression. However, these approaches are often error-prone due to the interplay of individual AS events, which results in different isoforms with locally similar sequences. Moreover, methods based on isoform-level quantification usually need annotated transcripts. In this work, we leverage the ability of deep learning networks to learn features from images and propose deepSpecas, a novel method for event-based AS differential analysis between two RNA-Seq samples. Our method does not rely on isoform abundance estimation, neither on a specific annotation. deepSpecas employs an image embedding scheme to represent the alignments of the two samples on the same region and utilizes a residual neural network to predict the AS events possibly expressed within that region. To our knowledge, deepSpecas is the first deep learning approach for performing an event-based AS analysis of RNA-Seq samples. To validate deepSpecas, we also address the lack of high quality AS benchmark datasets. For this purpose, we manually curated a set of regions exhibiting AS events. These regions were used for training our model and for assessing the predictions of our method. Our results highlight that deepSpecas achieves higher precision at the expense of a small reduction in sensitivity. The tool and the manually curated regions are available at https://github.com/sciccolella/deepSpecas .},
  archive      = {J_NCA},
  author       = {Ciccolella, Simone and Denti, Luca and Avila Cartes, Jorge and Della Vedova, Gianluca and Pirola, Yuri and Rizzi, Raffaella and Bonizzoni, Paola},
  doi          = {10.1007/s00521-025-10992-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6819-6829},
  shortjournal = {Neural Comput. Appl.},
  title        = {Differential analysis of alternative splicing events in gene regions using residual neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CTMBIDS: Convolutional tsetlin machine-based intrusion
detection system for DDoS attacks in an SDN environment. <em>NCA</em>,
<em>37</em>(9), 6795–6818. (<a
href="https://doi.org/10.1007/s00521-025-10976-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Software Defined Networks (SDN) face many security challenges today. A great deal of research has been done within the field of Intrusion Detection Systems (IDS) in these networks. Yet, numerous approaches still rely on deep learning algorithms, but these algorithms suffer from complexity in implementation, the need for high processing power, and high memory consumption. In addition to security issues, firstly, the number of datasets that are based on SDN protocols are very small. Secondly, the ones that are available encompass a variety of attacks in the network and do not focus on a single attack. For this reason, to introduce an SDN-based IDS with a focus on Distributed Denial of Service (DDoS) attacks, it is necessary to generate a DDoS-oriented dataset whose features can train a high-quality IDS. In this work, in order to address two important challenges in SDNs, in the first step, we generate three DDoS attack datasets based on three common and different network topologies. Then, in the second step, using the Convolutional Tsetlin Machine (CTM) algorithm, we introduce a lightweight IDS for DDoS attack dubbed &quot;CTMBIDS,&quot; with which we implement an anomaly-based IDS. The lightweight nature of the CTMBIDS stems from its low memory consumption and also its interpretability compared to the existing complex deep learning models. The low usage of system resources for the CTMBIDS makes it an ideal choice for an optimal software that consumes the SDN controller’s least amount of memory. Also, in order to ascertain the quality of the generated datasets, we compare the empirical results of our work with the DDoS attacks of the KDDCup99 benchmark dataset as well. Since the main focus of this work is on a lightweight IDS, the results of this work show that the CTMBIDS performs much more efficiently than traditional and deep learning based machine learning algorithms. Furthermore, the results also show that in most datasets, the proposed method has relatively equal or better accuracy and also consumes much less memory than the existing methods.},
  archive      = {J_NCA},
  author       = {Jafari Gohari, Rasoul and Aliahmadipour, Laya and Kuchaki Rafsanjani, Marjan},
  doi          = {10.1007/s00521-025-10976-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6795-6818},
  shortjournal = {Neural Comput. Appl.},
  title        = {CTMBIDS: Convolutional tsetlin machine-based intrusion detection system for DDoS attacks in an SDN environment},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A self-supervised graph convolutional model for
recommendation with exponential moving average. <em>NCA</em>,
<em>37</em>(9), 6777–6793. (<a
href="https://doi.org/10.1007/s00521-024-10933-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recommendation algorithms based on graph convolutional networks can integrate user and item node information along with their interaction topology, better capturing the intricate relationships between users and items, thereby enhancing the accuracy of recommender systems. However, existing methods often overlook the impact of noise in user behavior data on recommendation performance. Additionally, when there are too many convolutional layers in the graph, the node representations tend to smoothing, resulting in an inability to accurately distinguish user preferences. To address these issues, we propose a self-supervised graph convolutional model for recommendation with exponential moving average (SGCERec). Specifically, we first employ exponential moving average (EMA) techniques from the field of time-series analysis to denoise the raw user interaction data. Then, by applying layer filtering technique to update the propagation of information and the representation of nodes within the graph convolutional network, we effectively deepen the model hierarchy, enabling the model to gain a deeper understanding of the features and structures of the graph data, thereby improving the performance and effectiveness of the recommender systems. Finally, experimental results on three real datasets show that SGCERec outperforms state-of-the-art recommendation methods across various common evaluation metrics.},
  archive      = {J_NCA},
  author       = {Chen, Rui and Pang, Kangning and Wang, Zonglin and Liu, Qingfang and Tang, Cundong and Chang, Yanshuo and Huang, Min},
  doi          = {10.1007/s00521-024-10933-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6777-6793},
  shortjournal = {Neural Comput. Appl.},
  title        = {A self-supervised graph convolutional model for recommendation with exponential moving average},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Automatic channel selection using multi-objective
prioritized jellyfish search (MPJS) algorithm for motor imagery
classification using modified DB-EEGNET. <em>NCA</em>, <em>37</em>(9),
6749–6776. (<a
href="https://doi.org/10.1007/s00521-025-10979-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain–computer interface (BCI) enables the device to communicate directly with the brain by decoding neural signals, particularly electroencephalograms (EEGs). EEG signals are used in a variety of applications, especially motor imagery detection, due to their noninvasive nature, real-time monitoring capabilities, and cost-effectiveness. Often, EEG data consists of multi-channel signals; the presence of multiple channels leads to computational complexity and the presence of redundant channel signals. To avoid these, the channel selection algorithm is currently being used, particularly optimization-based channel selection. However, the optimization-based channel selection method may have limitations, such as eliminating the most important channel due to poor initialization and failing to achieve optimal performance due to the lack of an efficient multi-objective fitness function. To address these limitations, we proposed a new channel selection mechanism called the multi-objective prioritized jellyfish search algorithm (MPJS), which has two significant improvements. First, domain-specific initialization is employed to select the most important channels at the initialization stage, which ensures that no important channels are omitted. Second, using a multi-objective fitness function instead of a single objective one to select the most relevant and informative channels ensures that the selected channels meet the number criteria and include candidates’ channels. Prior work primarily focused on two-class MI classification, with only a few studies examining four-class MI classification; however, these four-class classification methods fail to achieve optimal performance. To address these research gaps and achieve optimal performance in four-class MI detection, we proposed an improved double-branch EEGNET (DB-EEGNET). This proposed work performance was evaluated by using benchmark datasets, including BCI Competition IV-2008-2A, BCI Competition III-2008-A, and the High Gamma dataset (HGD). Our proposed MJPS channel selection and DB-EEGNET classification method outperformed the baseline algorithm on the BCI IV-IIA, IIIA, and HGD datasets, with an average accuracy of 83.9%, 84.46%, and 94.78%, respectively.},
  archive      = {J_NCA},
  author       = {Vadivelan, D. Senthil and Sethuramalingam, Prabhu},
  doi          = {10.1007/s00521-025-10979-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6749-6776},
  shortjournal = {Neural Comput. Appl.},
  title        = {Automatic channel selection using multi-objective prioritized jellyfish search (MPJS) algorithm for motor imagery classification using modified DB-EEGNET},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). AFuNet: An attention-based fusion network to classify texts
in a resource-constrained language. <em>NCA</em>, <em>37</em>(9),
6725–6748. (<a
href="https://doi.org/10.1007/s00521-024-10953-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the era of widespread Internet use and extensive social media interaction, the digital realm is accumulating vast amounts of unstructured text data. This unstructured data often contain undesirable information, necessitating time-consuming manual classification efforts. An intelligent text classification system capable of automatically categorizing digitized texts based on semantic meaning is crucial. However, this task is particularly challenging for low-resource languages like Bengali due to a shortage of annotated corpora, issues with out-of-vocabulary words, lack of domain-specific hyperparameter tuning, limited ability to extract generalized text features, and class imbalances within the corpus. AFuNet: an attention-based fusion network to classify texts in a resource-constrained language. AFuNet undergoes a comprehensive four-phase experimental process, including baseline model evaluation and hyperparameter tuning, late fusion and model selection, attention-based early fusion and model identification, and an ablation study with impact analysis. Fine-tuned based on five Bengali text classification corpora, AFuNet achieves impressive accuracies: 96.60 ± 0.2 (BTCC11), 85.37 ± 0.2 (OSBC), 97.35 ± 0.2 (BARD), 93.74 ± 0.2 (IndicNLP), and 96.51 ± 0.2 (ProthomAlo). In comparison with previous state-of-the-art models on these corpora, AFuNet demonstrates significant accuracy improvements ranging from 0.54% to 4.49%, showcasing its effectiveness in advancing text classification capabilities for the Bengali language.},
  archive      = {J_NCA},
  author       = {Hossain, Md. Rajib and Hoque, Mohammed Moshiul and Dewan, M. Ali Akber and Hoque, Enamul and Siddique, Nazmul},
  doi          = {10.1007/s00521-024-10953-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6725-6748},
  shortjournal = {Neural Comput. Appl.},
  title        = {AFuNet: An attention-based fusion network to classify texts in a resource-constrained language},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Metamorphic testing of deep neural network-based autonomous
driving systems using behavioural domain adequacy. <em>NCA</em>,
<em>37</em>(9), 6677–6724. (<a
href="https://doi.org/10.1007/s00521-024-10794-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep neural networks (DNNs) are crucial in autonomous driving systems (ADSs) for tasks like steering control, but model inaccuracies, biased training data, and incorrect runtime parameters can compromise their reliability. Metamorphic testing (MT) enhances reliability by generating follow-up tests from mutated DNN source inputs, identifying inconsistencies as defects. Various MT techniques for ADSs include generative/transfer models, neuron-based coverage maximization, and adaptive test selection. Despite these efforts, significant challenges remain, including the ambiguity of neuron coverage’s correlation with misbehaviour detection, a lack of focus on DNN critical pathways, inadequate use of search-based methods, and the absence of an integrated method that effectively selects sources and generates follow-ups. This paper addresses such challenges by introducing DeepDomain, a grey-box multi-objective test generation approach for DNN models. It involves adaptively selecting diverse source inputs and generating domain-oriented follow-up tests. Such follow-ups explore critical pathways, extracted by neuron contribution, with broader coverage compared to their source tests (inter-behavioural domain) and attaining high neural boundary coverage of the misbehaviour regions detected in previous follow-ups (intra-behavioural domain). An empirical evaluation of the proposed approach on three DNN models used in the Udacity self-driving car challenge, and 18 different MRs demonstrates that relying on behavioural domain adequacy is a more reliable indicator than coverage criteria for effectively guiding the testing of DNNs. Additionally, DeepDomain significantly outperforms selected baselines in misbehaviour detection by up to 94 times, fault-revealing capability by up to 79%, output diversity by 71%, corner-case detection by up to 187 times, identification of robustness subdomains of MRs by up to 33 percentage points, and naturalness by two times. The results confirm that state-of-the-art coverage metrics are inadequate in misbehaviour-inducing test generation. Furthermore, black-box diversity-based test generation is less effective than the grey-box approach.},
  archive      = {J_NCA},
  author       = {Kalaee, Akram and Parsa, Saeed},
  doi          = {10.1007/s00521-024-10794-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6677-6724},
  shortjournal = {Neural Comput. Appl.},
  title        = {Metamorphic testing of deep neural network-based autonomous driving systems using behavioural domain adequacy},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel augmentation strategy for credit scoring modeling.
<em>NCA</em>, <em>37</em>(9), 6663–6675. (<a
href="https://doi.org/10.1007/s00521-024-10452-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In last years, social lending platforms have been increasingly used as virtual environments where borrowers can directly interact with lenders without any intermediary. As a result, a reliable credit scoring strategy, i.e., assessing whether a client is able to fully repay a loan, became of utmost importance to reduce the risk of not repaying the lenders. In this context, machine learning tools are being increasingly adopted to design automatic credit scoring systems but the data imbalance problem still penalizes their predictive performance, i.e., the greatest majority of clients can afford the repayment and learning to classify ”bad” borrowers depends on few instances where the loan was not paid back. In this paper, we target the data imbalance problem and propose a novel data augmentation strategy to improve the predictive performance of credit scoring models. The proposed methodology performs data augmentation by injecting synthetic instances in the dataset generated along the decision boundary of the decision model. We assessed the effectiveness of the proposed augmentation strategy on a million-scale dataset from Lending Club, the largest Social Lending platform, and found that it improves the performance of several classification models, also in comparison to other state-of-the-art approaches.},
  archive      = {J_NCA},
  author       = {La Gatta, Valerio and Postiglione, Marco and Sperlì, Giancarlo},
  doi          = {10.1007/s00521-024-10452-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6663-6675},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel augmentation strategy for credit scoring modeling},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ViF-SD2E: A robust weakly-supervised framework for neural
decoding. <em>NCA</em>, <em>37</em>(9), 6645–6661. (<a
href="https://doi.org/10.1007/s00521-024-10958-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural decoding plays a vital role in the interaction between the brain and the outside world. Our task in this paper is to decode the movement track of a finger directly based on the neural data. Existing neural decoding solutions primarily perform some preprocessing operations on neural data before feeding them into existing models (such as LSTM) for decoding. However, these solutions either are prone to overfitting or cannot well exploit the spatial and temporal information. In our previous observations, there is a symmetrical phenomenon between the unsupervised decoded trajectory and the ground truth trajectory within the activity space. This precisely motivates us to propose (or derive) a robust weakly-supervised framework (or model structure), called ViF-SD2E, for neural decoding. In particular, it consists of a space-division (SD) module and an exploration–exploitation (2E) strategy, to effectively exploit both the spatial information of the outside world and the temporal information of neural activity, where the SD2E output is analogized with the weak 0/1 vision feedback (ViF) label for training. Extensive experiments demonstrate the effectiveness of our method, which can sometimes be comparable to supervised counterparts. Therefore, we redirect our attention to the information (hidden in data) ViF-SD2E conveys to us. In other words, we believe that the advantage of ViF-SD2E lies in the fact that its processing steps are objectively determined by the inherent attributes (i.e., symmetry) of the neural data, or rather, the model structure is fixed.},
  archive      = {J_NCA},
  author       = {Feng, Jingyi and Luo, Yong and Song, Shuang and Hu, Han},
  doi          = {10.1007/s00521-024-10958-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6645-6661},
  shortjournal = {Neural Comput. Appl.},
  title        = {ViF-SD2E: A robust weakly-supervised framework for neural decoding},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fixed/preassigned-time synchronization of complex networks
under aperiodically intermittent event-triggered control. <em>NCA</em>,
<em>37</em>(9), 6633–6643. (<a
href="https://doi.org/10.1007/s00521-024-10918-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper considers the fixed-/preassigned-time synchronization of complex networks via aperiodically intermittent event-triggered control. A novel intermittent control lemma is developed to ensure fixed-time synchronization with the help of an event-triggered method. Some criteria are proposed to achieve the synchronization goal for complex networks within a fixed/preassigned time via two types of aperiodically intermittent event-triggered controllers. A numerical example is given to illustrate the validity of the new theoretical results.},
  archive      = {J_NCA},
  author       = {Dong, Ziyu and Hu, Yuanfa and Liu, Xiaoyang and Cao, Jinde},
  doi          = {10.1007/s00521-024-10918-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6633-6643},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fixed/preassigned-time synchronization of complex networks under aperiodically intermittent event-triggered control},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust entropy regularized k-means clustering algorithm
for processing noise in datasets. <em>NCA</em>, <em>37</em>(9),
6617–6632. (<a
href="https://doi.org/10.1007/s00521-024-10899-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {K-means is one of the clustering algorithms. Due to its simple implementation and powerful functionality, it is widely used in fields such as data mining, cluster analysis, data preprocessing, and unsupervised learning. However, the K-means algorithm suffers from the problem of being sensitive to outliers. If there are a certain number of outliers in a low-dimensional sample set, the resulting cluster centers will be greatly disturbed, affecting the clustering results. We can certainly detect outliers before clustering, but this phased approach has an impact on the accuracy of clustering results. To address this issue, we propose an improved robust Entropy Regularized K-Means clustering algorithm. Our method is based on the Entropy Regularized K-Means clustering algorithm and adds a weight value to the optimization function to ignore out-of-bounds data, and obtain a more accurate number of clusters in the dataset, thereby achieving synchronous clustering and detection. The advantages of this algorithm are strong anti-interference ability, the ability to ignore the influence of outliers on cluster centers, and synchronous clustering and detection. We tested our improved algorithm on artificial and real datasets, demonstrating that it can better determine cluster centers and find some outlier data.},
  archive      = {J_NCA},
  author       = {Jiang, Peilin and Cao, Junnan and Yu, Weizhong and Nie, Feiping},
  doi          = {10.1007/s00521-024-10899-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6617-6632},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust entropy regularized K-means clustering algorithm for processing noise in datasets},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing intra-aural disease classification with
attention-based deep learning models. <em>NCA</em>, <em>37</em>(9),
6601–6616. (<a
href="https://doi.org/10.1007/s00521-025-10990-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ear diseases are defined as pathological conditions that indicate dysfunction or abnormal function of the ear organ, which is part of the auditory system of living organisms that regulates hearing and balance functions. These diseases usually manifest as conditions that affect the internal components of the ear structure and can manifest themselves with symptoms such as hearing loss, ear pain, balance problems, and fluid accumulation in the ear. The accuracy of the diagnosis depends on expert knowledge and subjective opinion. This method is prone to human error. This study presents a novel computer-aided diagnosis system for otoscope images of ear diseases, utilizing a vision transformer-based feature extractor combined with machine learning classifiers to provide accurate second opinions for ENT specialists. For this purpose, a new model based on state-of-the-art vision transformer feature extractor and machine learning models is proposed. In the experimental study, the dataset, comprising 880 eardrum images categorized into four classes (CSOM, earwax, myringosclerosis, and normal), was split into training (70%), validation (10%), and testing (20%) subsets. Each image was preprocessed to 420 × 380 pixels to fit the input dimensions of the models. The vision transformer architecture was utilized for feature extraction, followed by classification using various machine learning algorithms including kNN, SVM, and random forest. As a result, the model using vision transformer feature extractor and k-nearest neighbors (kNN) algorithm achieved 99.00% accuracy. In this study, a deep learning-based and computer-aided diagnosis system, in other words, a computational model, was developed instead of the current human error-prone disease diagnosis method used by ear nose throat (ENT) specialists. The main purpose of the deep learning-based decision support system is to support the diagnosis process where expert knowledge is difficult to access and to provide an alternative opinion to the expert diagnosis.},
  archive      = {J_NCA},
  author       = {Demircan, Furkancan and Ekinci, Murat and Cömert, Zafer},
  doi          = {10.1007/s00521-025-10990-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6601-6616},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing intra-aural disease classification with attention-based deep learning models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ViT-SENet-tom: Machine learning-based novel hybrid
squeeze–excitation network and vision transformer framework for tomato
fruits classification. <em>NCA</em>, <em>37</em>(9), 6583–6600. (<a
href="https://doi.org/10.1007/s00521-025-10973-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Tomatoes are essential fruits in numerous nations for their vast demand. It is very important to maintain the freshness of tomatoes. One of the primary challenges in the recent culinary landscape is accurately identifying healthy tomatoes while effectively eliminating damaged or rejected ones. Existing approaches employ various strategies for categorizing tomato fruit, but they often suffer from inaccuracies, slow detection, and suboptimal performance. Thus, motivated by this gap, in this paper, we propose a novel machine learning (ML) framework, ViT-SENet-Tom, which is a hybrid vision transformer (ViT) model with squeeze and excitation (SENet) block network for fast, accurate, and efficient tomato fruit classification. The framework works on three tomato classes, respectively, the ripe, unripe, and reject. In developing the proposed model, we utilized advanced and newly designed layers and functions. This integration created a more complex and sophisticated neural network, significantly enhancing efficiency and contributing to the model’s novelty. Our chosen dataset was small initially, but we implemented augmentation techniques to increase its size. This approach made our system more reliable, efficient, and effective. The hybrid ViT-SENet framework employs encoders and self-attention networks with squeeze and excitation channel functions to allow precise, robust, fast, and efficient tomato classification. In simulation, the framework achieves a training accuracy of 99.87% and validation accuracy of 93.87%, indicating the precise classification of tomatoes. Besides, this work tests accuracy using fivefold cross-validation. The highest accuracy seen at fold-5 is 99.90%. These testing results demonstrate the efficacy of the proposed framework in real-deployment scenarios. The implementation has the potential to provide enhanced and more sustainable food security and safety in future.},
  archive      = {J_NCA},
  author       = {Swapno, S M Masfequier Rahman and Nobel, S. M. Nuruzzaman and Islam, Md Babul and Bhattacharya, Pronaya and Mattar, Ebrahim A.},
  doi          = {10.1007/s00521-025-10973-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6583-6600},
  shortjournal = {Neural Comput. Appl.},
  title        = {ViT-SENet-tom: Machine learning-based novel hybrid squeeze–excitation network and vision transformer framework for tomato fruits classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Structure-to-word dynamic interaction model for abstractive
sentence summarization. <em>NCA</em>, <em>37</em>(9), 6567–6581. (<a
href="https://doi.org/10.1007/s00521-024-10970-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Abstractive text summarization aims to capture important information from text and integrate contextual information to guide the summary generation. However, effective integration of important and relevant information remains a challenging problem. Existing graph-based methods only consider either word relations or structure information, but neglect the correlation between them. To simultaneously capture the word relations and structure information from sentences, we propose a novel Structure-to-Word dynamic interaction model for Abstractive Sentence Summarization (SWSum). Specifically, we first represent structure and word relation information of sentences by constructing semantic scenario graph and semantic word relation graph based on FrameNet. We subsequently stack multiple graph-based dynamic interaction layers that iteratively enhance their correlation to learn node representations. Finally, a graph fusion module is designed to obtain better overall graph representations, which provide an attention-based context vector for the decoder to generate summary. Experimental results demonstrate our model outperforms existing state-of-the-art methods on two popular benchmark datasets, i.e., Gigaword and DUC 2004.},
  archive      = {J_NCA},
  author       = {Guan, Yong and Guo, Shaoru and Li, Ru},
  doi          = {10.1007/s00521-024-10970-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6567-6581},
  shortjournal = {Neural Comput. Appl.},
  title        = {Structure-to-word dynamic interaction model for abstractive sentence summarization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). R-WhONet: Recalibrated wheel odometry neural network for
vehicular positioning using transfer learning. <em>NCA</em>,
<em>37</em>(9), 6547–6565. (<a
href="https://doi.org/10.1007/s00521-024-10046-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a transfer learning approach to recalibrate our previously developed Wheel Odometry Neural Network (WhONet) for vehicle positioning in environments where Global Navigation Satellite Systems (GNSS) are unavailable. The WhONet has been shown to possess the capability to learn the uncertainties in the wheel speed measurements needed for correction and accurate positioning of vehicles. These uncertainties may be manifested as tyre pressure changes from driving on muddy and uneven terrains or wheel slips. However, a common cause for concern for data-driven approaches, such as the WhONet model, is usually the inability to generalise the models to a new vehicle. In scenarios where machine learning models are trained in a specific domain but deployed in another domain, the model’s performance degrades. In real-life scenarios, several factors are influential to this degradation, from changes to the dynamics of the vehicle to new pattern distributions of the sensor’s noise, and bias will make the test sensor data vary from training data. Therefore, the challenge is to explore techniques that allow the trained machine learning models to spontaneously adjust to new vehicle domains. As such, we propose the Recalibrated-Wheel Odometry neural Network, based on transfer learning, that adapts the WhONet model from its source domain (a vehicle and environment on which the model is initially trained) to the target domain (a new vehicle on which the trained model is to be deployed). Through a performance evaluation on several GNSS outage scenarios—short-term complex driving scenarios such as on roundabouts, sharp cornering, hard-brake and wet roads (drifts), and on longer-term GNSS outage scenarios of 30s, 60s, 120s and 180s duration—we demonstrate that a model trained in the source domain does not generalise well to a new vehicle in the target domain. However, we show that our new proposed framework improves the generalisation of the WhONet model to new vehicles in the target domains by an average of 32% (i.e. 32% reduction in the vehicle position error estimation across the scenarios investigated).},
  archive      = {J_NCA},
  author       = {Onyekpe, Uche and Szkolnik, Alicja and Palade, Vasile and Kanarachos, Stratis and Fitzpatrick, Michael E.},
  doi          = {10.1007/s00521-024-10046-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6547-6565},
  shortjournal = {Neural Comput. Appl.},
  title        = {R-WhONet: Recalibrated wheel odometry neural network for vehicular positioning using transfer learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing financial time series forecasting through
topological data analysis. <em>NCA</em>, <em>37</em>(9), 6527–6545. (<a
href="https://doi.org/10.1007/s00521-024-10787-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Topological data analysis (TDA) is increasingly acknowledged within financial markets for its capacity to manage complexity and discern nuanced patterns and structures. It has been applied effectively to uncover intricate relationships and capture non-linear dependencies inherent in market data. This manuscript presents a groundbreaking study that delves into integrating features derived from TDA to improve the performance of forecasting models for univariate time series prediction. The research specifically examines whether incorporating features extracted from TDA-such as entropy, amplitude, and the number of points obtained from persistent diagrams can provide valuable supplementary information to the baseline forecasting model. Thus, the aim is to determine if these TDA-derived features can boost forecasting accuracy by offering additional insights that existing models might overlook. The N-BEATS model serves as the baseline forecasting model due to its robust generalization capabilities and flexibility in incorporating additional features into the model. The proposed methodology is compared against a univariate N-BEATS model without additional features and other strategies incorporating supplementary features such as temporal decomposition and time delay embeddings. The evaluation includes forecasting for six cryptocurrencies across four distinct time scenarios and four traditional financial instruments across two scenarios each, resulting in 32 datasets. The results obtained were promising, as the proposed method, $$\texttt {N-BEATS}_\mathrm {+TDA}$$ , achieved the best results in mean performance and mean ranking for the three metrics considered (MAPE, MAE, and RMSE). Significant differences were observed with the rest of the proposed methods using a significance level of $$\alpha = 0.10$$ , highlighting the effectiveness of integrating TDA features to enhance forecasting models.},
  archive      = {J_NCA},
  author       = {de Jesus, Luiz Carlos and Fernández-Navarro, Francisco and Carbonero-Ruz, Mariano},
  doi          = {10.1007/s00521-024-10787-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6527-6545},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing financial time series forecasting through topological data analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness-driven federated learning-based spam email
detection using clustering techniques. <em>NCA</em>, <em>37</em>(9),
6515–6526. (<a
href="https://doi.org/10.1007/s00521-024-10969-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the world of emails, spam messages present a significant challenge, leading to inconveniences and potential security risks. Addressing this issue, the task of spotting spam in emails is critical for ensuring secure and trustworthy communication. However, two prevalent approaches have their challenges. The centralized model, gathering data in one place, raises privacy issues. Conversely, the federated learning model, which focuses on privacy, can lead to a compromise in accuracy. This research paper presents a novel federated learning-based fair clustering technique for spam email detection. By addressing privacy concerns and aiming for accurate classification, the proposed approach Fair Clustering model combines the strengths of federated learning and data clustering. Through experimental evaluation, the Fair Clustering model is evaluated against both a centralized and federated learning model. Different metrics, such as accuracy, recall, precision, and F1-score, are used to evaluate and compare the performance of these models. The results demonstrate that the Fair Clustering model outperforms the federated learning model, showcasing the effectiveness of fair clustering in selecting representative clients and improving classification performance.},
  archive      = {J_NCA},
  author       = {Kaushal, Vishal and Sharma, Sangeeta},
  doi          = {10.1007/s00521-024-10969-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6515-6526},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fairness-driven federated learning-based spam email detection using clustering techniques},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stylometry-driven framework for urdu intrinsic plagiarism
detection: A comprehensive analysis using machine learning, deep
learning, and large language models. <em>NCA</em>, <em>37</em>(9),
6479–6513. (<a
href="https://doi.org/10.1007/s00521-024-10966-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Detecting plagiarism in documents is a well-established task in natural language processing (NLP). Broadly, plagiarism detection is categorized into two types (1) intrinsic: to check the whole document or all the passages have been written by a single author; (2) extrinsic: where a suspicious document is compared with a given set of source documents to figure out sentences or phrases which appear in both documents. In the pursuit of advancing intrinsic plagiarism detection, this study addresses the critical challenge of intrinsic plagiarism detection in Urdu texts, a language with limited resources for comprehensive language models. Acknowledging the absence of sophisticated large language models (LLMs) tailored for Urdu language, this study explores the application of various machine learning, deep learning, and language models in a novel framework. A set of 43 stylometry features at six granularity levels was meticulously curated, capturing linguistic patterns indicative of plagiarism. The selected models include traditional machine learning approaches such as logistic regression, decision trees, SVM, KNN, Naive Bayes, gradient boosting and voting classifier, deep learning approaches: GRU, BiLSTM, CNN, LSTM, MLP, and large language models: BERT and GPT-2. This research systematically categorizes these features and evaluates their effectiveness, addressing the inherent challenges posed by the limited availability of Urdu-specific language models. Two distinct experiments were conducted to evaluate the impact of the proposed features on classification accuracy. In experiment one, the entire dataset was utilized for classification into intrinsic plagiarized and non-plagiarized documents. Experiment two categorized the dataset into three types based on topics: moral lessons, national celebrities, and national events. Both experiments are thoroughly evaluated through, a fivefold cross-validation analysis. The results show that the random forest classifier achieved an exceptional accuracy of 98.81% in experiment 1. On the other hand, in experiment 2, the extreme gradient boosting classifier attained an overall accuracy of 99.00% highlighting its superior capability in distinguishing nuanced stylistic features across different topics. Overall, machine learning models showcasing superior performance utilizing the proposed set of stylometry features over deep learning approaches and LLMs.},
  archive      = {J_NCA},
  author       = {Manzoor, Muhammad Faraz and Farooq, Muhammad Shoaib and Abid, Adnan},
  doi          = {10.1007/s00521-024-10966-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6479-6513},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stylometry-driven framework for urdu intrinsic plagiarism detection: A comprehensive analysis using machine learning, deep learning, and large language models},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Constructing a smoothed leaky ReLU using a linear
combination of the smoothed ReLU and identity function. <em>NCA</em>,
<em>37</em>(9), 6465–6478. (<a
href="https://doi.org/10.1007/s00521-024-10935-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Convolutional neural networks (CNNs) have made tremendous progress in solving many challenging problems. Good activation functions can improve the performance of CNNs. The existing activation functions exhibit inconsistent performance gains across different training settings, models, datasets and tasks. To solve this problem, we propose a general smoothed approximation for the maximum function $$\max (x_i, \alpha x_i)$$ using the linear combination of the smoothed rectified linear unit and the identity function. And we use exponential moving average to training the negative slope in this smoothed approximation. To validate the effectiveness of our approach, we also present a smoothed approximation case named leaky power function linear unit (LPFLU) to compare with the current state-of-the-art activation functions. Experimental results demonstrate that our LPFLU outperforms the existing state-of-the-art activation functions in improved robustness across different training settings, models, datasets and tasks.},
  archive      = {J_NCA},
  author       = {Zhu, Meng and Min, Weidong and Li, Jiahao and Liu, Mengxue and Deng, Ziyang and Zhang, Yao},
  doi          = {10.1007/s00521-024-10935-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6465-6478},
  shortjournal = {Neural Comput. Appl.},
  title        = {Constructing a smoothed leaky ReLU using a linear combination of the smoothed ReLU and identity function},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge AI-powered marine pollution classification with
customized CNN model. <em>NCA</em>, <em>37</em>(9), 6449–6463. (<a
href="https://doi.org/10.1007/s00521-024-10959-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The increasing production of disposable plastic products contributes greatly to marine pollution and its impact on the marine ecosystem and organisms consuming ocean-derived food. To address this issue, this paper proposes a new customized convolutional neural network (CNN) model for categorizing the level of marine pollution in underwater ocean regions using image classification. The customized CNN model is developed and compared with five preexisting models, including DenseNet121, Inception-ResNetV2, InceptionV3, VGG-19, and VGG-16. The results show that the customized model achieves an accuracy of 99.5% and performs optimally according to various performance metrics. The model is implemented on an edge AI device, such as Raspberry Pi, to bring it to practical use.},
  archive      = {J_NCA},
  author       = {Palanisamy, Sanjai and Bonny, Talal and Nasir, Nida and Al Shabi, Mohammad and Al Shammaa, Ahmed},
  doi          = {10.1007/s00521-024-10959-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6449-6463},
  shortjournal = {Neural Comput. Appl.},
  title        = {Edge AI-powered marine pollution classification with customized CNN model},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Personalized medical recommendation system with machine
learning. <em>NCA</em>, <em>37</em>(9), 6431–6447. (<a
href="https://doi.org/10.1007/s00521-024-10916-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a machine learning-based healthcare recommendation system designed to provide personalized medical advice by accurately predicting diseases from patient symptoms. The system utilizes a comprehensive symptom–disease dataset, leveraging support vector classifier (SVC) and random forest (RF) models, achieving outstanding accuracies of 97.75% in disease prediction. These results surpass those of similar studies, such as one employing hybrid CNN and fuzzy logic techniques, which achieved 99% accuracy but relied on smaller datasets with limited diversity. The proposed system not only excels in diagnosis but also integrates tailored recommendations, including medication, dietary plans, and exercise regimens, to address the specific needs of patients. These personalized recommendations enhance practical utility, offering a patient-centered approach that promotes proactive health management. By focusing on diseases with high and moderate predictive performance, the system addresses both common and complex conditions effectively. The study demonstrates the transformative potential of machine learning in developing scalable and efficient healthcare systems, bridging the gap between accurate prediction and actionable treatment strategies. Future research will aim to incorporate larger and more diverse datasets, address underrepresented diseases, and refine feature engineering to enhance model generalizability and the system&#39;s overall effectiveness.},
  archive      = {J_NCA},
  author       = {Hassan, Basma M. and Elagamy, Shahd Mohamed},
  doi          = {10.1007/s00521-024-10916-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6431-6447},
  shortjournal = {Neural Comput. Appl.},
  title        = {Personalized medical recommendation system with machine learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Collision avoidance and routing based on location access
(CARLA) of mobile robots. <em>NCA</em>, <em>37</em>(9), 6401–6430. (<a
href="https://doi.org/10.1007/s00521-024-10914-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The paper introduces a new path-planning robotic system methodology called Collision Avoidance and Routing based on Location Access (CARLA) for use in critical environments such as hospitals and crises where quick action and saving human lives are vital. The main focus of our framework is on accuracy and fast responses, such as delivering tools or items in a specific area while avoiding collisions with other robots and obstacles. CARLA is designed to provide quick responses during emergencies, unlike most existing algorithms that are integrated into site control units or distributed among mobile robots on-site. By being loaded onto a remote server node rather than individual robots, CARLA helps to conserve the robots&#39; capabilities, hardware resources, and power consumption. Additionally, our system utilizes cloud computing and Fog servers technology to improve data transmission times between the cloud and smart devices, especially for applications with strict timing requirements like emergency response. The Fog platform is also leveraged to enhance on-site access to real-time interaction and location-based services by bringing processing power closer to the robots from far-off Cloud servers. CARLA has various applications, such as in factories and warehouses, where mobile robots need to be selected and directed by a central control system remotely. The proposed framework consists of three main modules: Robot Knowledge Module, Robot Selection Module, and Route Reservation Module, which will all be discussed in detail in this paper. The results of simulations using this framework show that the robots have improved flexibility and efficiency in terms of computing paths and successfully fulfiling requests without colliding, compared to traditional methods used in similar scenarios.},
  archive      = {J_NCA},
  author       = {ElSayyad, Shimaa Ezzat and Saleh, Ahmed I. and Ali, Hesham A. and Saraya, M. S. and Rabie, Asmaa H. and Abdelsalam, Mohamed M.},
  doi          = {10.1007/s00521-024-10914-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {9},
  pages        = {6401-6430},
  shortjournal = {Neural Comput. Appl.},
  title        = {Collision avoidance and routing based on location access (CARLA) of mobile robots},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exponential synchronization of bi-directional associative
memory neural networks with delay on arbitrary time domains.
<em>NCA</em>, <em>37</em>(8), 6383–6400. (<a
href="https://doi.org/10.1007/s00521-024-10820-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {We investigate the exponential synchronization of bi-directional associative memory neural networks with delays on a family of different time domains. By utilizing the theory of time scales, we provide stabilization results that are applicable to continuous-time, discrete-time, and general nonuniform hybrid time domains. Our approach employs a unified matrix-measure theory, a recent alternative to traditional Lyapunov functions, to establish exponential synchronization and design effective feedback laws. Notably, our methodology does not require symmetry or diagonality in the control gain matrix, distinguishing it from prior works. Furthermore, we explore various special cases of the considered systems and provide a detailed discussion highlighting the advantages of our findings over existing results. The effectiveness of our proposed criteria is demonstrated through small-scale and medium-scale simulated numerical examples across different time domains. Additionally, we apply our results to an example from the literature, showcasing the broad applicability and improved performance of our method in comparison to previous approaches.},
  archive      = {J_NCA},
  author       = {Kumar, Vipin and Heiland, Jan and Benner, Peter},
  doi          = {10.1007/s00521-024-10820-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6383-6400},
  shortjournal = {Neural Comput. Appl.},
  title        = {Exponential synchronization of bi-directional associative memory neural networks with delay on arbitrary time domains},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Composite neural learning-based adaptive actuator failure
compensation control for full-state constrained autonomous surface
vehicle. <em>NCA</em>, <em>37</em>(8), 6369–6381. (<a
href="https://doi.org/10.1007/s00521-024-10651-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article studies composite neural learning-based adaptive failure compensation control issues for the autonomous surface vehicle with full-state constraints. Initially, the control strategy solve the problems of computational complexity and state constraints and eliminate the negative effect of filter error on tracking performance by integrating with the command-filtered backstepping technique and barrier Lyapunov functions. Then, a composite neural learning framework is established, where the effect caused by approximation error on tracking accuracy can be efficiently reduced by constructing the serial-parallel estimation model to obtain the estimations of the system states. Furthermore, an adaptive resilient trajectory tracking controller is designed, which can ensure that all the signals of the closed-loop system are semi-globally uniformly ultimately bounded satisfying the preset constraints even if the expected actuator faults occur suddenly. Finally, the feasibility and superiority of the designed control strategy are clarified by simulation results.},
  archive      = {J_NCA},
  author       = {Song, Shuai and Jiang, Yu and Song, Xiaona and Stojanovic, Vladimir},
  doi          = {10.1007/s00521-024-10651-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6369-6381},
  shortjournal = {Neural Comput. Appl.},
  title        = {Composite neural learning-based adaptive actuator failure compensation control for full-state constrained autonomous surface vehicle},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Correlation-based pruning algorithm with weight compensation
for feedforward neural networks. <em>NCA</em>, <em>37</em>(8),
6351–6367. (<a
href="https://doi.org/10.1007/s00521-024-10932-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Optimizing neural network architectures through effective pruning techniques has become essential to balancing model complexity and accuracy. This study introduces a novel correlation-based approach to systematically reduce network size by identifying and removing redundant neurons based on their activation correlations. By selectively pruning neurons while compensating for their contributions, the method maintains model fidelity across diverse datasets. Results demonstrate substantial architecture reductions with minimal performance impact: For the MNIST dataset, the number of neurons in hidden layers was reduced from 128-128 to 118-93, while maintaining a high accuracy of 97.59%. Comparative analysis indicates that this pruning approach achieves competitive or superior results compared to state-of-the-art methods while reducing computational complexity and memory requirements by up to 25%. The findings highlight the potential of correlation-driven pruning strategies to optimize neural networks, making them more efficient and adaptable to resource-constrained environments.},
  archive      = {J_NCA},
  author       = {Ebid, Shaimaa E. K. and El-Tantawy, Samah and Shawky, Doaa and Abdel-Malek, Hany L.},
  doi          = {10.1007/s00521-024-10932-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6351-6367},
  shortjournal = {Neural Comput. Appl.},
  title        = {Correlation-based pruning algorithm with weight compensation for feedforward neural networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Polyp image segmentation based on improved planet
optimization algorithm using reptile search algorithm. <em>NCA</em>,
<em>37</em>(8), 6327–6349. (<a
href="https://doi.org/10.1007/s00521-024-10667-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {To recognize the potential for colon polyps to develop into cancer over time, early diagnosis is crucial for preventative healthcare. Timely identification significantly improves the prognosis and treatment outcomes for colorectal cancer patients. Image segmentation is crucial in medical image analysis for accurate diagnosis and treatment planning. Therefore, in this study, we present an alternative multilevel thresholding polyp segmentation method (MPOA) to enhance the segmentation of polyp images. The proposed method is based on enhancing the planet optimization algorithm (POA) by integrating operators from the reptile search algorithm (RSA). The evaluation of the developed MPOA is tested with different polyp images and compared with other image segmentation approaches. The results highlight the superior capability of MPOA, as evidenced by various performance measures in effectively segmenting polyp images. Furthermore, metrics such as peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and fitness values demonstrate that MPOA outperforms the basic version of POA and other methods. The evaluation outcomes underscore the significant impact of RSA in enhancing the performance of POA for the segmentation of polyp images.},
  archive      = {J_NCA},
  author       = {Abd Elaziz, Mohamed and Al-qaness, Mohammed A. A. and Al-Betar, Mohammed Azmi and Ewees, Ahmed A.},
  doi          = {10.1007/s00521-024-10667-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6327-6349},
  shortjournal = {Neural Comput. Appl.},
  title        = {Polyp image segmentation based on improved planet optimization algorithm using reptile search algorithm},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ResdenseNet: A lightweight dense ResNet enhanced with
depthwise separable convolutions and its applications for early plant
disease classification. <em>NCA</em>, <em>37</em>(8), 6305–6326. (<a
href="https://doi.org/10.1007/s00521-024-10972-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, artificial intelligence has undergone robust development, leading to the emergence of numerous autonomous AI applications. However, a crucial challenge lies in optimizing computational efficiency and reducing training time while maintaining high accuracy with limited hardware resources. This paper introduces ResdenseNet, a model built upon the MobileNet, DenseNet, and ResNet architectures. ResdenseNet combines dense blocks and residual blocks from the DenseNet and ResNet architectures. In these dense blocks, the standard convolutional units are replaced by depthwise separable convolutional units, a significant part of the MobileNet architecture. The experimental outcomes are contrasted with established models and their iterations, including ResNet-50, ResNet-101, MobileNet-V1, MobileNet-V2, DenseNet-121, and DenseNet-169. The proposed model is tested on benchmark and proposed datasets, showcasing its efficiency in reducing computations and accelerating the training process. Emphasizing hyperparameter importance, ResdenseNet, optimized with a growth rate of 64, 6 layers, and ReLU activation, achieves an accuracy of (98.73%) and a F1-score of (98.20%) on the wheat and barley dataset. The results indicate that ResdenseNet significantly decreases the number of parameters to 0.72M and efficiently shortens training time to 5983.54 s. Particularly noteworthy is ResdenseNet’s superiority over other models in terms of having the fewest parameters, the shortest training time, and the highest accuracy, especially when dealing with wheat, barley, and maize datasets.},
  archive      = {J_NCA},
  author       = {Nagpal, Jyoti and Goel, Lavika},
  doi          = {10.1007/s00521-024-10972-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6305-6326},
  shortjournal = {Neural Comput. Appl.},
  title        = {ResdenseNet: A lightweight dense ResNet enhanced with depthwise separable convolutions and its applications for early plant disease classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A deep learning framework for automatic assessment of
presence in virtual reality using multimodal behavioral cues.
<em>NCA</em>, <em>37</em>(8), 6283–6303. (<a
href="https://doi.org/10.1007/s00521-024-10943-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Effective development of virtual reality (VR) applications is heavily reliant on the evaluation of user experience (UX). However, traditional methods such as questionnaires have inherent limitations which hinder their ability to capture nuanced behavioral responses and impede the agility of VR content creation: They are time-consuming, burdensome for users, and require significant human effort for interpretation. This study introduces an automated framework aimed at addressing the limitations of questionnaire-based evaluations to assess UX in VR. Our primary focus is to validate the concept of this framework through assessment of the sense of presence (SOP), a crucial psychological perception with significant impact on VR UX. Our proposed framework utilizes a deep neural network (DNN) to analyze patterns in multimodal behavioral cues, including facial expressions, head movements, and hand movements, to predict scores from the Igroup Presence Questionnaire (IPQ). Additionally, we introduce two statistical profiles: the Visual Entropy Profile (VEP), which offers insights into visual complexity by depicting scene entropy, and the Experiential Presence Profile (EPP), which is designed to capture users’ historical SOP levels to enable personalized baseline and sensitivity estimation. The proposed framework achieves a significant correlation between actual and predicted IPQ scores, with a Spearman’s rank correlation coefficient of 0.7303, showcasing the potential of DNNs in analyzing complex behavioral signals and automating SOP assessment. This study represents a pioneering effort in leveraging DNNs for the automatic assessment of SOP and paves the way for future advances in automatically assessing VR UX and unlocking new opportunities in the field.},
  archive      = {J_NCA},
  author       = {Pannattee, Peerawat and Shimada, Shogo and Yem, Vibol and Nishiuchi, Nobuyuki},
  doi          = {10.1007/s00521-024-10943-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6283-6303},
  shortjournal = {Neural Comput. Appl.},
  title        = {A deep learning framework for automatic assessment of presence in virtual reality using multimodal behavioral cues},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing link prediction in graph data augmentation through
graphon mixup. <em>NCA</em>, <em>37</em>(8), 6267–6282. (<a
href="https://doi.org/10.1007/s00521-024-10923-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Link prediction in complex networks is a fundamental problem with applications in diverse domains, from social networks to biological systems. Traditional approaches often struggle to capture intricate relationships in graphs, leading to suboptimal predictions. To address this, we introduce a novel method called graphon mixup (GM), which leverages the power of graphons to enhance link prediction. The augmentation strategy involves generating a synthetic graph by combining the original graph with a graphon-based synthetic graph. This process, expressed as a weighted combination of adjacency matrices, strategically blends real and synthetic information, enriching the training dataset. GM formulates link prediction as a joint optimization problem, aligning the characteristics of the synthetic graph with the true underlying structure. The objective is to minimize cross-entropy loss between predicted and true edge probabilities. A detailed computational complexity analysis evaluates the time and space requirements, aiding in understanding the efficiency and scalability of GM across different datasets and network sizes. Empirical validation on benchmark datasets demonstrates GM’s effectiveness in consistently improving average precision across diverse network types. The proposed method enhances the generalization capabilities of link prediction models, providing a more robust framework capable of accurate predictions even in the presence of noise or unseen patterns.},
  archive      = {J_NCA},
  author       = {Sultana, Tangina and Hossain, Md. Delowar and Morshed, Md. Golam and Lee, Young-Koo},
  doi          = {10.1007/s00521-024-10923-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6267-6282},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing link prediction in graph data augmentation through graphon mixup},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Outlier-resistant state estimation for memristor-based BAM
neural networks with probabilistic time-varying delays. <em>NCA</em>,
<em>37</em>(8), 6251–6265. (<a
href="https://doi.org/10.1007/s00521-024-10890-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study considers the issue of nonfragile state estimation (SE) for memristor-based bidirectional associative memory (MBAM) neural networks with probabilistic time-varying delays. The primary objective is to develop an effective estimator for accurately assessing neuron states, which are crucial in various engineering applications. Furthermore, we consider a scenario in which the measurement outputs of the neural networks may be influenced by abnormal disturbances, which could have a negative impact on the performance of the estimator. In this case, a factitious saturation constraint is introduced to mitigate the adverse effects on the designed outlier-resistant estimator, thereby improving the reliability of the estimator. Through constructing sensible Lyapunov–Krasovskii functional (LKF), a delay-dependent criterion is derived to guarantee the exponential stability of the augmented system. Finally, the effectiveness of the desired estimation scheme is demonstrated via two simulation examples.},
  archive      = {J_NCA},
  author       = {Shao, Xiaoguang and Zhang, Jie and Lyu, Ming and Lu, Yanjuan},
  doi          = {10.1007/s00521-024-10890-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6251-6265},
  shortjournal = {Neural Comput. Appl.},
  title        = {Outlier-resistant state estimation for memristor-based BAM neural networks with probabilistic time-varying delays},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Explainable energy consumption and speed prediction in
sustainable cities using deep learning. <em>NCA</em>, <em>37</em>(8),
6233–6249. (<a
href="https://doi.org/10.1007/s00521-024-10850-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The idea of sustainable cities has drawn a lot of attention due to the quick expansion of metropolitan areas as well as the growing problems brought on by resource scarcity and climate change. Cities that prioritize sustainable practices are those that minimize their negative effects on the environment, maximize resource efficiency, and improve the standard of living for their citizens. Therefore, for sustainable cities, this paper uses the vehicle energy dataset (VED) to estimate travel times and calculate vehicle energy consumption. The dataset contains 12,609,170 road elevation tracks, 12,203,044 speed limit tracks, and 12,281,719 speed limit records with direction. An open-source routing engine called Valhalla is utilized to do a variety of tasks, including finding paths, matching maps, and creating maneuvers based on paths. The three primary stages of the suggested model are data pre-processing, feature extraction, and result interpretation. In the data pre-processing stage, null values are first eliminated and data normalization is implemented. Then, three techniques known as the gated recurrent unit (GRU), recurrent neural network (RNN), and long short-term memory (LSTM) are used to optimize the model. Finally, the results are interpreted through the use of SHAP (SHapley Additive explanations) in explainable artificial intelligence (XAI) techniques. The LSTM model yields the best prediction results, achieving 15.2662 RMSE, 11.7266 MAE, and 0.6696 R2 at 8 batch size, according to the evaluation results. Additional experiments are carried out in batch sizes of 8, 16, 32, and 64.The lowest metrics are produced by batch sizes of 64, while the best metrics are produced by batch sizes of 8.},
  archive      = {J_NCA},
  author       = {Abd El-Latif, Eman I. and El-dosuky, Mohamed},
  doi          = {10.1007/s00521-024-10850-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6233-6249},
  shortjournal = {Neural Comput. Appl.},
  title        = {Explainable energy consumption and speed prediction in sustainable cities using deep learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Distance-based mutual congestion feature selection with
genetic algorithm for high-dimensional medical datasets. <em>NCA</em>,
<em>37</em>(8), 6217–6232. (<a
href="https://doi.org/10.1007/s00521-024-10837-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection poses a challenge in high-dimensional datasets, where the number of features exceeds the number of observations, as seen in microarray, gene expression, and medical datasets. There is not a universally optimal feature selection method applicable to any data distribution, and as a result, the literature consistently endeavors to address this issue. One recent approach in feature selection is termed frequency-based feature selection. However, existing methods in this domain tend to overlook feature values, focusing solely on the distribution in the response variable. In response,this paper introduces the Distance-based Mutual Congestion (DMC) as a filter method that considers both the feature values and the distribution of observations in the response variable. DMC sorts the features of datasets, and the top 5% are retained and clustered by KMeans to mitigate multicollinearity. This is achieved by randomly selecting one feature from each cluster. The selected features form the feature space, and the search space for the Genetic Algorithm with Adaptive Rates (GAwAR) will be approximated using this feature space. GAwAR approximates the combination of the top 10 features that maximizes prediction accuracy within a wrapper scheme. To prevent premature convergence, GAwAR adaptively updates the crossover and mutation rates. The hybrid DMC-GAwAR is applicable to binary classification datasets, and experimental results demonstrate its superiority over some recent works.},
  archive      = {J_NCA},
  author       = {Nematzadeh, Hossein and Mani, Joseph and Nematzadeh, Zahra and Akbari, Ebrahim and Mohamad, Radziah},
  doi          = {10.1007/s00521-024-10837-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6217-6232},
  shortjournal = {Neural Comput. Appl.},
  title        = {Distance-based mutual congestion feature selection with genetic algorithm for high-dimensional medical datasets},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive loss optimization for enhanced learning
performance: Application to image-based rock classification.
<em>NCA</em>, <em>37</em>(8), 6199–6215. (<a
href="https://doi.org/10.1007/s00521-024-10965-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the geoscience domain, mainly within the oil and gas industry, getting the correct category of rock samples is crucial. Machine learning models deployed for rock classification often use the categorical cross-entropy loss function. This loss function may struggle when the rocks are either very similar or have too much intraclass variability. Furthermore, categorical cross-entropy loss may ignore subtle but significant differences between classes. This results in the ignoring of hard-to-classify samples and fails to prioritize learning from these challenging patterns. This can lead to models biased toward more common classes or mislabeling of underrepresented rock types, especially when dealing with noisy or inconsistent data. To bridge those gaps, we propose a new hybrid loss function. It combines the traditional categorical cross-entropy loss function with Online Hard Example Mining (OHEM), a method originally formulated for object detection tasks focusing on hard-to-classify samples. We designed this function to be adjustable, making it adaptable to various challenges inherent to the rock classification. We evaluated this technique on a diverse, highly heterogeneous, and challenging dataset provided by Shell Brazil. The available techniques were tested and encountered problems with challenging classes. However, our new technique improved classification accuracy for both challenging and easier samples. In addition to rock classification, this technique may serve as a blueprint for addressing complicated classification problems in other fields.},
  archive      = {J_NCA},
  author       = {Salavati, Soroor and Mendes Júnior, Pedro Ribeiro and Rocha, Anderson and Ferreira, Alexandre},
  doi          = {10.1007/s00521-024-10965-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6199-6215},
  shortjournal = {Neural Comput. Appl.},
  title        = {Adaptive loss optimization for enhanced learning performance: Application to image-based rock classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). FLAME: Fire detection in videos combining a deep neural
network with a model-based motion analysis. <em>NCA</em>,
<em>37</em>(8), 6181–6197. (<a
href="https://doi.org/10.1007/s00521-024-10963-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the catastrophic natural events posing hazards to human lives and infrastructures, fire is the phenomenon causing more frequent damages. Thanks to the spread of smart cameras, video fire detection is gaining more attention as a solution to monitor wide outdoor areas where no specific sensors for smoke detection are available. However, state-of-the-art fire detectors assure a satisfactory Recall but exhibit a high false-positive rate that renders the application practically unusable. In this paper, we propose FLAME, an efficient and adaptive classification framework to address fire detection from videos. The framework integrates a state-of-the-art deep neural network for frame-wise object detection, in an automatic video analysis tool. The advantages of our approach are twofold. On the one side, we exploit advances in image detector technology to ensure a high Recall. On the other side, we design a model-based motion analysis that improves the system’s Precision by filtering out fire candidates occurring in the scene’s background or whose movements differ from those of the fire. The proposed technique, able to be executed in real-time on embedded systems, has proven to surpass the methods considered for comparison on a recent literature dataset representing several scenarios. The code and the dataset used for designing the system have been made publicly available by the authors at ( https://mivia.unisa.it/large-fire-dataset-with-negative-samples-lfdn/ ).},
  archive      = {J_NCA},
  author       = {Gragnaniello, Diego and Greco, Antonio and Sansone, Carlo and Vento, Bruno},
  doi          = {10.1007/s00521-024-10963-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6181-6197},
  shortjournal = {Neural Comput. Appl.},
  title        = {FLAME: Fire detection in videos combining a deep neural network with a model-based motion analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Leveraging ChatGPT for enhanced stock selection and
portfolio optimization. <em>NCA</em>, <em>37</em>(8), 6163–6179. (<a
href="https://doi.org/10.1007/s00521-024-10928-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The public release of ChatGPT represents a significant milestone in generative AI technology, enabling the autonomous generation of content based on pre-training. This breakthrough presents new opportunities for advancements in the field of portfolio selection. This paper aims to introduce a comprehensive portfolio selection method by applying ChatGPT for stock selection and combining it with optimization algorithms to jointly optimize portfolio selection. Compared to randomly selected stocks, the portfolios optimized using ChatGPT-selected stocks and solved with the egret swarm optimization algorithm (ESOA) demonstrate higher diversification and lower volatility, leading to superior portfolio optimization results. Additionally, to validate ESOA’s superiority, its performance is compared against genetic algorithm (GA) and particle swarm optimization (PSO) on five metrics: risk, expected return, Sharpe ratio, objective value, and penalty term. Under equivalent experimental setting, ESOA exhibits a better ability to balance the relationship between risk and return.},
  archive      = {J_NCA},
  author       = {Huang, Zhendai and Liao, Bolin and Hua, Cheng and Cao, Xinwei and Li, Shuai},
  doi          = {10.1007/s00521-024-10928-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6163-6179},
  shortjournal = {Neural Comput. Appl.},
  title        = {Leveraging ChatGPT for enhanced stock selection and portfolio optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Image quality assessment by enabling inter-patch message
passing via graph convolutional networks. <em>NCA</em>, <em>37</em>(8),
6145–6161. (<a
href="https://doi.org/10.1007/s00521-024-10893-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There is a crucial problem posing great challenges to the image quality assessment (IQA), that is, how to accurately regress the visual quality score of an entire image from its patches. The vast majority of existing patch-based IQA methods treat each patch independently. In this paper, we innovatively enable inter-patch message passing (MP) for the proposed IQA via graph convolutional networks (IQG). The patches are embedded into the graph by treating the low-dimensional vector representation of each patch as a node and the inter-patch intrinsic correlation as an edge. Since the intrinsic correlation is not directly available, an adaptive edge generator is proposed to adaptively construct the directed weighted edges by separately obtaining the patch-connected mask and the edge weights. To mitigate the overfitting that may occur when adaptive MP is enabled, we attach an embedding approach that creates the undirected unweighted edge between any two patches to enable each node in the graph to connect to every other node, thus passing the information that otherwise would be neglected. Extensive experiments demonstrate the state-of-the-art performance of our proposed IQG in complete scenarios, including full-reference and no-reference IQA tasks on benchmark IQA databases.},
  archive      = {J_NCA},
  author       = {Liu, Yufan and Guo, Jiefeng},
  doi          = {10.1007/s00521-024-10893-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6145-6161},
  shortjournal = {Neural Comput. Appl.},
  title        = {Image quality assessment by enabling inter-patch message passing via graph convolutional networks},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Revolutionizing online shopping with FITMI: A realistic
virtual try-on solution. <em>NCA</em>, <em>37</em>(8), 6125–6144. (<a
href="https://doi.org/10.1007/s00521-024-10843-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In today’s digital age, consumers increasingly rely on online shopping for convenience and accessibility. However, a significant drawback of online shopping is the inability to physically try on clothing before purchasing. This limitation often leads to uncertainty regarding fit and style, resulting in customer post-purchase dissatisfaction and higher return rates. Research indicates that online items are three times more likely to be returned than in-store ones, especially during the pandemic. To address this challenge, we propose a virtual try-on method called FITMI, an enhanced Latent Diffusion Textual Inversion model for virtual try-on purposes. The proposed architecture aims to bridge the gap between traditional in-store try-ons and online shopping by offering users a realistic and interactive virtual try-on experience. Although virtual try-on solutions already exist, recent advancements in artificial intelligence have significantly enhanced their capabilities, enabling more sophisticated and realistic virtual try-on experiences than ever before. Building on these advancements, FITMI surpasses ordinary virtual try-ons relying on generative adversarial networks, often producing unrealistic outputs. Instead, FITMI utilizes latent diffusion models to generate high-quality images with detailed textures. As a web application, FITMI facilitates virtual try-ons by seamlessly integrating images of users with garments from catalogs, providing a true-to-life representation of how the items would look. This approach differentiates us from competitors. FITMI is validated using two widely recognized benchmarks: the Dress-Code and Viton-HD datasets. Additionally, FITMI acts as a trusted style advisor, enhancing the shopping experience by recommending complementary items to elevate the chosen garment and suggesting similar options based on user preferences.},
  archive      = {J_NCA},
  author       = {Samy, Tassneam M. and Asham, Beshoy I. and Slim, Salwa O. and Abohany, Amr A.},
  doi          = {10.1007/s00521-024-10843-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6125-6144},
  shortjournal = {Neural Comput. Appl.},
  title        = {Revolutionizing online shopping with FITMI: A realistic virtual try-on solution},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-orthogonal-oppositional enhanced african vultures
optimization for combined heat and power economic dispatch under
uncertainty. <em>NCA</em>, <em>37</em>(8), 6097–6123. (<a
href="https://doi.org/10.1007/s00521-024-10715-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper attempts to conceptualize a potent methodology by combining the African vultures optimization algorithm (AVOA) with a multi-orthogonal-oppositional strategy (M2OS), named AVO-M2OS, to address the nonconvexity and multidimensional nature of the combined heat and power economic dispatch (CHPED) problem under both crisp and uncertainty aspects. The AVO-M2OS uses the M2OS to simultaneously explore the search region, improving solutions’ diversity as well as solution quality. Therefore, AVO-M2OS can perform deeper exploration and exploitation features and thus mitigate the trapping at local optima, especially when tackling the more complicated nature of the CHPED problem. A three-stage analysis is conducted to assess the effectiveness of the proposed AVO-M2OS algorithm. During the first stage, the algorithm’s performance is evaluated on benchmark problems such as CEC 2005 and CEC 2019, employing statistical verifications and convergence characteristics. In the second stage, the significance of the results is evaluated using the nonparametric Friedman test to demonstrate that the results did not occur by chance. The results indicate that the AVO-M2OS algorithm outperforms the best existing algorithm (AVOA) by an average rank of the Friedman test exceeding 26% for the CEC 2005 suite while outperforming the gray wolf optimization (GWO) by 60% for the CEC 2019 suite. Moreover, the AVO-M2OS demonstrates exceptional performance compared to existing state-of-the-art algorithms, surpassing the best algorithm available by an average rank of the Friedman test that exceeds 41%. Finally, the AVO-M2OS’s applicability is achieved by minimizing the operational costs by finding the optimal power and heat generation scheduling for the CHPED problem. The recorded results realize that the AVO-M2OS algorithm offers accurate performance compared to competing optimizers, where it saves the operational cost of the 48-unit system by 24% on the original AVO variant. Furthermore, the uncertainty aspect of CHPED, called UCHPED, is investigated using intuitionistic fuzzy numbers (IFN) to simulate the fluctuation based on customers’ varying energy demands across different time periods, posing a significant challenge for timely and equitable energy allocation. The optimization results show that the suggested AVO-M2OS algorithm provides more robust and reliable optimal solutions compared to other methods in most of the studied benchmark functions, including the CHPED problem, addressing both crisp and uncertain aspects. Therefore, it is a potential alternative for both real-world operations and modeling situations.},
  archive      = {J_NCA},
  author       = {Rizk-Allah, Rizk M. and Snášel, Václav and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-024-10715-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6097-6123},
  shortjournal = {Neural Comput. Appl.},
  title        = {Multi-orthogonal-oppositional enhanced african vultures optimization for combined heat and power economic dispatch under uncertainty},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MIG-DARTS: Towards effective differentiable architecture
search by gradually mitigating the initial-channel gap between search
and evaluation. <em>NCA</em>, <em>37</em>(8), 6085–6096. (<a
href="https://doi.org/10.1007/s00521-024-10681-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Neural architecture search (NAS) based on differentiable methods has made significant progress in both search cost (GPU-days and GPU memory consumption) and network performance. However, there still exists a large gap between the search and evaluation due to the unaffordable search cost, which will cause the searched architecture to be suboptimal in the evaluation. Based on the observation of the large initial-channel gap between search and evaluation, this paper is the first to propose to gradually mitigate the initial-channel gap as the search stage proceeds to elevate the performance of evaluation architecture; meanwhile, we remove poorly performing candidate operations after each search stage to keep an acceptable search cost. To further alleviate the excessive growth of search cost brought by the progressive increase of initial-channels, this paper proposes to separate the search space, by which an individual search space with reduced candidate operations is built for normal cell and reduction cell, respectively. Moreover, this paper proposes a stability-aware stopping strategy to alleviate the problem of invalid search to reduce the search cost in GPU-days. By conducting experiments on CIFAR10 and CIFAR100 datasets, the results show that the proposed method can achieve state-of-the-art performance with a small search cost.},
  archive      = {J_NCA},
  author       = {Hao, Debei and Pei, Songwei},
  doi          = {10.1007/s00521-024-10681-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6085-6096},
  shortjournal = {Neural Comput. Appl.},
  title        = {MIG-DARTS: Towards effective differentiable architecture search by gradually mitigating the initial-channel gap between search and evaluation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Time-variant quadratic programming solving by using
finitely-activated RNN models with exact settling time. <em>NCA</em>,
<em>37</em>(8), 6067–6084. (<a
href="https://doi.org/10.1007/s00521-024-10922-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recurrent neural networks (RNNs) are well established with comprehensive models capable of solving zero finding problems. Most of the conventional designs apply the infinite activation, but may not be practical for implementation. This paper presents model designs of finitely-activated zeroing neural networks (structure-like RNNs), possessing the finite-time convergence property as well, for solving time-variant convex quadratic programming. Two techniques for realizing finite activation are provided, based on which novel activation functions (AFs) are constructed, including the conic AFs and the finitely-valued power-rate AFs. Theoretical analyses of finite-time convergence are presented in detail and settling time is exactly established for each model. It is shown that finitely-valued AFs can approximate or even outperform the original power-rate AFs. The proposed neural network models are applied to solve an example of time-variant quadratic programming, and the repetitive motion planning of redundant robots with joint angle and joint velocity constraints, where the anti-disturbance capability of the finitely-activated integral neural network models has been examined and verified. The obtained numerical results demonstrate effectiveness of the computing schemes.},
  archive      = {J_NCA},
  author       = {Sun, Mingxuan and Zhang, Yu and Wang, Liming and Wu, Yuxin and Zhong, Guomin},
  doi          = {10.1007/s00521-024-10922-8},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6067-6084},
  shortjournal = {Neural Comput. Appl.},
  title        = {Time-variant quadratic programming solving by using finitely-activated RNN models with exact settling time},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PartialST: Partial spatial–temporal learning for urban flow
prediction. <em>NCA</em>, <em>37</em>(8), 6053–6066. (<a
href="https://doi.org/10.1007/s00521-024-10888-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate urban flow prediction plays a crucial role in transportation management, as it enables optimized resource allocation and improved traffic efficiency. Although current methods have made advances, they still encounter challenges such as high computational overhead and the risk of overfitting complex models. To tackle these issues, we introduce the partial channel connection to urban flow prediction, aiming to reduce complexity while keeping competitive performance. The partial channel connection selectively engages a specific subset of channels for operations in a single step, while preserving the identity mapping for the remaining channels. This approach ensures comprehensive training of all channels throughout the entirety of the training process and mitigates computational overheads at each step. In this paper, we apply the partial channel connection across various spatial and temporal encoders, undertaking a thorough investigation into their predictive accuracy. Based on these insights, we design a model named PartialST for urban flow prediction, which effectively captures the temporal and spatial correlations. We evaluate PartialST through comparative experiments against other state-of-the-art methods on two real-world datasets. The results demonstrate not only the superior performance of our model over other comparative models but also the effectiveness of the partial channel connection approach.},
  archive      = {J_NCA},
  author       = {Wang, Yong and Li, Xiaoyu and Zhang, Xinxin and Liu, Rui and Gong, Yongshun},
  doi          = {10.1007/s00521-024-10888-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6053-6066},
  shortjournal = {Neural Comput. Appl.},
  title        = {PartialST: Partial spatial–temporal learning for urban flow prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An integrated decision-making process for risk analysis of
decentralized finance. <em>NCA</em>, <em>37</em>(8), 6021–6051. (<a
href="https://doi.org/10.1007/s00521-024-10839-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decentralized finance is upending the financial system through innovative, open, and interoperable financial solutions. Decentralized finance is a rapidly emerging field based on distributed ledger technology. Decentralized banking protocols are witnessing a perfect storm in terms of growth. However, because these financial innovations pose specific risks to consumers, creators, regulators, and other stakeholders, this emerging subject demands careful investigation. The current study tries to categorize and rate the risks connected with decentralized finance. The current study seeks to identify the multiple risks associated with decentralized finance through a thorough literature analysis. Data gathered from specialists in prior research were incorporated into the study used for empirical analysis. As MCDM techniques, IVFF-based DEMATEL, AHP, and TOPSIS are first used, and then the IVFF-ARAS method and sensitivity analysis are used for performance evaluation and verification. The findings of this study have several ramifications for legislators, businesspeople, technologists, and practitioners. These stakeholders can concentrate on these weaknesses in the future and provide longer-lasting solutions.},
  archive      = {J_NCA},
  author       = {Kirişci, Murat},
  doi          = {10.1007/s00521-024-10839-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6021-6051},
  shortjournal = {Neural Comput. Appl.},
  title        = {An integrated decision-making process for risk analysis of decentralized finance},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Machine learning-based gait cycle segmentation using
instantaneous knee and hip-extension angles for biomechanical analysis.
<em>NCA</em>, <em>37</em>(8), 6009–6019. (<a
href="https://doi.org/10.1007/s00521-024-10720-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The biomechanical analysis of human movement, particularly gait, is crucial in fields such as clinical medicine, sports, and rehabilitation. While traditional motion capture (Mocap) systems are effective, they are often limited by their complexity, high cost, and the unnatural settings they require in terms of the gesture and motion environment. Emerging tools like inertial sensors and markerless video-based systems offer greater flexibility but encounter challenges in motion cycle segmentation, as they present kinematic data as time series, adding new difficulties to the analysis. This paper introduces a novel machine learning-based system for automatic gait cycle segmentation using features extracted from two easily measurable lower limb kinematic variables: hip and knee extension angles. The proposed method leverages instantaneous information from these angles for segmentation, ensuring versatility and independence from specific data collection methods. This allows for rapid segmentation and potential implementation on lower-performance processors. Experimental results demonstrate the high accuracy and efficiency of the proposed algorithm segmenting the gait cycle. The F1-score was 0.997. By using readily available hip and knee kinematic data and identifying crucial biomechanical relationships, our method offers a versatile and practical solution for motion analysis across various clinical and sports applications.},
  archive      = {J_NCA},
  author       = {Solórzano, Brayan David and Chavez, Susana and Giraldo, Luis Felipe and De la Portilla, Christian Cifuentes},
  doi          = {10.1007/s00521-024-10720-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {6009-6019},
  shortjournal = {Neural Comput. Appl.},
  title        = {Machine learning-based gait cycle segmentation using instantaneous knee and hip-extension angles for biomechanical analysis},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Integrating contextual intelligence with mixture of experts
for signature and anomaly-based intrusion detection in CPS security.
<em>NCA</em>, <em>37</em>(8), 5991–6007. (<a
href="https://doi.org/10.1007/s00521-024-10967-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The adoption of IoT and cyber-physical systems (CPSs) in smart homes and critical infrastructures has led to the possibility of physical damage from system compromises. Security failures in sectors like power, transport, and public safety can have more severe physical impacts than just information loss. Intrusion detection systems (IDSs) are crucial in a defense-in-depth approach. We propose a detection engine to prevent CPS from transitioning into unsafe states beyond critical limits, thresholds, and behavioral normalicies. A novel host-based IDS using a mixture-of-experts (MoE) model is introduced in the CPS security paradigm. For signature-based protection, we developed a context-aware CPS-SNORT ruleset for deep packet inspection (DPI) of Gcode instructions (NIST RS-274/ISO 6983-1:2009) used in numerical control of machines like CNCs and 3D printers. A new Gcode dataset was developed on a CPS test bed. In a supervised learning approach, we achieved over 99% accuracy with random tree for known attack detection. In a semi-supervised approach, logistic regression achieved 85% accuracy. For behavioral anomaly detection, LSTM achieved 99.9% accuracy, outperforming isolation forest and local outlier factor.},
  archive      = {J_NCA},
  author       = {Rahim, Kashif and Nasir, Zia Ul Islam and Ikram, Nassar and Qureshi, Hassaan Khaliq},
  doi          = {10.1007/s00521-024-10967-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5991-6007},
  shortjournal = {Neural Comput. Appl.},
  title        = {Integrating contextual intelligence with mixture of experts for signature and anomaly-based intrusion detection in CPS security},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Taking class imbalance into account in open set recognition
evaluation. <em>NCA</em>, <em>37</em>(8), 5975–5989. (<a
href="https://doi.org/10.1007/s00521-024-10960-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, deep neural networks have been employed increasingly often, which correlates with them receiving growing user trust. However, such systems cannot identify samples from unknown classes and often induce an incorrect decision with high confidence. This is aimed to be solved by open set recognition methods. The presented work looks at the evaluation protocols of existing approaches in the field. A particular focus is being placed on the impact of class imbalance, especially in the dichotomy between known and unknown samples, which is a rarely considered factor in the experimental environment. The work analyzes current evaluation strategies—regarding dataset construction and metric selection—noting that the class imbalance can significantly impact the obtained results. We analyze the effect of using the popular baseline metrics (accuracy, balanced accuracy, and F1-score) for method quality assessment and introduce a protocol extension to four recognition quality measures that can be built upon those baselines. The analysis of base measures revealed that the choice of baseline metric could significantly impact the computed criterion values when the class imbalance of the recognized problem appears. The proposed experimental environment was used in an example experiment on commonly used computer vision datasets. As an outcome of problem analysis, we present a set of guidelines for evaluating open set recognition methods.},
  archive      = {J_NCA},
  author       = {Komorniczak, Joanna and Ksieniewicz, Paweł},
  doi          = {10.1007/s00521-024-10960-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5975-5989},
  shortjournal = {Neural Comput. Appl.},
  title        = {Taking class imbalance into account in open set recognition evaluation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A momentum accelerated stochastic method and its application
on policy search problems. <em>NCA</em>, <em>37</em>(8), 5957–5973. (<a
href="https://doi.org/10.1007/s00521-024-10883-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the dramatic increase in model complexity and problem scales in the machine learning area, researches on the first-order stochastic methods and its accelerated variants for non-convex problems have attracted wide research interest. However, most works on convergence analysis of accelerated methods focus on general convex or strongly convex objective functions. In this paper, we consider an accelerated scheme coming from dynamic systems and ordinary differential equations, which has a simpler and more direct form than the traditional scheme. We construct auxiliary sequences of iteration points as analysis tools, which can be interpreted as extension of Nesterov’s estimate sequence in non-convex case. We analyze the convergence property under different cases when momentum parameters are fixed or varying over iterations. For non-smooth and general convex objective functions, we give a relaxed step-size requirement to ensure convergence. For the non-convex policy search problem in classical reinforcement learning, we propose an accelerated stochastic policy gradient method with restart technique and construct numerical experiments to verify its effectiveness.},
  archive      = {J_NCA},
  author       = {Jiang, Boou and Yuan, Ya-xiang},
  doi          = {10.1007/s00521-024-10883-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5957-5973},
  shortjournal = {Neural Comput. Appl.},
  title        = {A momentum accelerated stochastic method and its application on policy search problems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Do as you teach: A multi-teacher approach to self-play in
deep reinforcement learning. <em>NCA</em>, <em>37</em>(8), 5945–5956.
(<a href="https://doi.org/10.1007/s00521-024-10829-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A long-running challenge in the reinforcement learning (RL) community has been to train a goal-conditioned agent in sparse reward environment such that it also generalizes to unseen goals. We propose a novel goal-conditioned RL algorithm; Multi-Teacher Asymmetric Self-Play, which allows multiple agents (i.e., the teachers) to create a successful curriculum for another agent (i.e., the student) and empirically demonstrate its effectiveness on complex domains like FetchReach and a novel driving simulator designed for goal-conditioned RL. Our results show a 30-40% improvement over the baseline while also improving the learning speed of the student. We attribute this improvement in performance to the better exploration and coverage of the state space by multiple teacher agents. In addition, the results show that completely new students can learn offline from the goals generated by teachers trained with a previous student, reducing the computational cost by around 95%. This is crucial in the context of application domains where repeatedly training a teacher agent is expensive or even infeasible.},
  archive      = {J_NCA},
  author       = {Kharyal, Chaitanya and Gottipati, Sai Krishna and Sinha, Tanmay Kumar and Abdollahi, Fatemeh and Das, Srijita and Taylor, Matthew E.},
  doi          = {10.1007/s00521-024-10829-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5945-5956},
  shortjournal = {Neural Comput. Appl.},
  title        = {Do as you teach: A multi-teacher approach to self-play in deep reinforcement learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). TSUBF-net: Trans-spatial UNet-like network with bi-direction
fusion for segmentation of adenoid hypertrophy in CT. <em>NCA</em>,
<em>37</em>(8), 5927–5943. (<a
href="https://doi.org/10.1007/s00521-024-10824-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adenoid hypertrophy stands as a common cause of obstructive sleep apnea–hypopnea syndrome in children. It is characterized by snoring, nasal congestion, and growth disorders. Computed tomography (CT) emerges as a pivotal medical imaging modality, utilizing X-rays and advanced computational techniques to generate detailed cross-sectional images. Within the realm of pediatric airway assessments, CT imaging provides an insightful perspective on the shape and volume of enlarged adenoids. Despite the advances of deep learning methods for medical imaging analysis, there remains an emptiness in the segmentation of adenoid hypertrophy in CT scans. To address this research gap, we introduce TSUBF-Net (Trans-Spatial UNet-like Network based on Bi-direction Fusion), a 3D medical image segmentation framework. TSUBF-Net is engineered to effectively discern intricate 3D spatial interlayer features in CT scans and enhance the extraction of boundary-blurring features. Notably, we propose two innovative modules within the U-shaped network architecture: the Trans-Spatial Perception (TSP) module and the Bi-directional Sampling Collaborated Fusion (BSCF) module. These two modules are in charge of operating during the sampling process and strategically fusing down-sampled and up-sampled features, respectively. Furthermore, we introduce the Sobel loss term, which optimizes the smoothness of the segmentation results and enhances model accuracy. Extensive 3D segmentation experiments are conducted on several datasets. TSUBF-Net is superior to the state-of-the-art methods with the lowest HD95: 7.03, IoU: 85.63, and DSC: 92.26 on our own AHSD dataset. The results in the other two public datasets also demonstrate that our methods can robustly and effectively address the challenges of 3D segmentation in CT scans.},
  archive      = {J_NCA},
  author       = {Zhou, Rulin and Feng, Yingjie and Wang, Guankun and Zhong, Xiaopin and Wu, Zongze and Wu, Qiang and Zhang, Xi},
  doi          = {10.1007/s00521-024-10824-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5927-5943},
  shortjournal = {Neural Comput. Appl.},
  title        = {TSUBF-net: Trans-spatial UNet-like network with bi-direction fusion for segmentation of adenoid hypertrophy in CT},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SE-GCL: An event-based simple and effective graph
contrastive learning for text representation. <em>NCA</em>,
<em>37</em>(8), 5913–5926. (<a
href="https://doi.org/10.1007/s00521-024-10686-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Text representation learning is significant as the cornerstone of natural language processing. In recent years, graph contrastive learning (GCL) has been widely used in text representation learning due to its ability to represent and capture complex text information in a self-supervised setting. However, the current mainstream graph contrastive learning methods often require the incorporation of domain knowledge or cumbersome computations to guide the data augmentation process, which significantly limits the application efficiency and scope of GCL. Additionally, many methods learn text representations only by constructing word-document relationships, which overlooks the rich contextual semantic information in the text. To address these issues and exploit representative textual semantics, we present an event-based, simple, and effective graph contrastive learning (SE-GCL) for text representation. Precisely, we extract event blocks from text and construct internal relation graphs to represent inter-semantic interconnections, which can ensure that the most critical semantic information is preserved. Then, we devise a streamlined, unsupervised graph contrastive learning framework to leverage the complementary nature of the event semantic and structural information for intricate feature data capture. In particular, we introduce the concept of an event skeleton for core representation semantics and simplify the typically complex data augmentation techniques found in existing graph contrastive learning to boost algorithmic efficiency. We employ multiple loss functions to prompt diverse embeddings to converge or diverge within a confined distance in the vector space, ultimately achieving a harmonious equilibrium. We conducted experiments on the proposed SE-GCL on four standard data sets (AG News, 20NG, SougouNews, and THUCNews) to verify its effectiveness in text representation learning. The accuracy achieved on the respective datasets is 91.56, 86.76, 98.03, and 97.79%, demonstrating superior performance on most datasets compared to baseline methods.},
  archive      = {J_NCA},
  author       = {Meng, Tao and Ai, Wei and Li, Jianbin and Wang, Ze and Li, Keqin},
  doi          = {10.1007/s00521-024-10686-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5913-5926},
  shortjournal = {Neural Comput. Appl.},
  title        = {SE-GCL: An event-based simple and effective graph contrastive learning for text representation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Masked hybrid attention with laplacian query fusion and
tripartite sequence matching for medical image segmentation.
<em>NCA</em>, <em>37</em>(8), 5891–5911. (<a
href="https://doi.org/10.1007/s00521-024-10934-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation is pivotal in computer-aided diagnosis systems, demanding high precision and contextual understanding. Vision Transformer-based approaches have gained much attention recently due to their excellent performance and ability to capture long-range dependencies in medical images. However, research shows they suffer from inadequate multi-scale feature integration, poor object localization, and inconsistent mask predictions, leading to sub-optimal segmentation performance. This paper addresses these challenges by redefining semantic medical image segmentation through learnable object queries within an enhanced transformer framework with a masked hybrid attention querying mechanism, optimizing multi-scale feature fusion, object localization, and instance-specific segmentation. First, this study presents a novel transformer-based masked hybrid attention mechanism using Laplacian query fusion on learnable query features and incorporating a novel tripartite sequence matching technique as part of the enhanced decoder block to improve the consistency of mask predictions and optimize decoder queries. The designed hybrid multi-head self- and cross-attention mechanisms aim to selectively integrate multi-scale features, ensuring optimal feature combinations for precise segmentation. Secondly, multiple class tokens are incorporated to improve object localization and capture class-specific characteristics within the transformer framework, leveraging the transformer decoders’ ability to learn distinct instance representations. Experimental results and extensive ablation studies demonstrate the effectiveness of the proposed approach on three publicly available datasets, obtaining better segmentation results compared to various state-of-the-art approaches using various evaluation metrics. Specifically, the proposed model achieves a Dice Score of 95.25%, 92.75%, and 85.25% on LUNA, ISIC, and DRIVE datasets, respectively.},
  archive      = {J_NCA},
  author       = {Ekong, Favour and Yu, Yongbin and Patamia, Rutherford Agbeshi and Sarpong, Kwabena and Ukwuoma, Chiagoziem C. and Wang, Xiangxiang and Ukot, Akpanika Robert and Cai, Jingye},
  doi          = {10.1007/s00521-024-10934-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5891-5911},
  shortjournal = {Neural Comput. Appl.},
  title        = {Masked hybrid attention with laplacian query fusion and tripartite sequence matching for medical image segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DMVL4AVD: A deep multi-view learning model for automated
vulnerability detection. <em>NCA</em>, <em>37</em>(8), 5873–5889. (<a
href="https://doi.org/10.1007/s00521-024-10892-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Automated vulnerability detection is crucial to protect software systems. However, state-of-the-art approaches mainly focus on a single view of the source code, which often leads to incomplete code representation and low detection accuracy. To solve these problems, this paper proposes a novel automatic vulnerability detection model, DMVL4AVD, based on deep multi-view learning that represents source codes from three distinct views: code sequences, code property graphs, and code metrics. Different deep models are employed to extract features from each view. Firstly, the [CLS] vectors derived from encoder layers 1 to 12 of GraphCodeBERT are used as code sequence features which contain rich semantic information. Next, the gated graph neural network (GGNN) is exploited to learn the features of nodes in the code property graph, encompassing both syntactic and dependency information of the source code. During the extraction of graph features, node representation is augmented by incorporating the degree centrality of each node, along with its corresponding code and type attributes, resulting in a more comprehensive depiction of the graph&#39;s structure. Statistical metrics generated by the code analysis tool SourceMonitor are then processed through a 1-dimensional (1-D) CNN to produce metric features. Fused features from these three views are learned by a multilayer perceptron (MLP) to yield final classification results. Experimental results demonstrate the superiority of DMVL4AVD over existing approaches. The model performs significantly better than the studied baselines, achieving an average increase in accuracy of 6.79% and an average boost of 6.94% in precision compared to the approaches in the literature.},
  archive      = {J_NCA},
  author       = {Du, Xiaozhi and Zhou, Yanrong and Du, Hongyuan},
  doi          = {10.1007/s00521-024-10892-x},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5873-5889},
  shortjournal = {Neural Comput. Appl.},
  title        = {DMVL4AVD: A deep multi-view learning model for automated vulnerability detection},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhancing affordable EEG to act as a quantitative EEG for
inattention treatment using MATLAB. <em>NCA</em>, <em>37</em>(8),
5849–5871. (<a
href="https://doi.org/10.1007/s00521-024-10835-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lack of attention is a chronic behavior in attention deficit hyperactivity disorder (ADHD), autism spectrum disorder (ASD), and other disorders that harm academic and social performance. ADHD is a disorder whose typical symptoms include inattention, hyperactivity, and impulsivity. They have a major impact on the affected person’s function and development. The electroencephalogram (EEG) device is a diagnostic tool, whereas the quantitative EEG (QEEG) device is a diagnostic and therapeutic tool for most mental disorders. QEEG applies the neurofeedback method in treatment. Neurofeedback is a technique for training brain functions and is an alternative to the traditional oral treatment of inattention disorders due to its numerous side effects. The proposed software can upgrade most EEG devices in hospitals and clinics into QEEGs capable of neurofeedback. The upgrading tools and stages are introduced in this study. The cost of upgrading an EEG device is 25 times less than the purchase price of a QEEG device. The EEG device (Open BCI) has been upgraded with MATLAB to function as a QEEG system, integrating a variety of feature extraction methods for inattention detection such as fractal dimension (FD), wavelet transform (WT), multi-resolution techniques (MR), and empirical mode decomposition (EMD) which signified a notable progress in the field. Furthermore, the implemented software is easily customizable to include any forthcoming superior techniques that may arise. Earlier research distinguished the differences between states of relaxation and concentration using a simple fixed threshold. In this paper, short training has been utilized to calculate adaptive thresholds to optimize individual effects. Different thresholding techniques were employed with the EMD_Dt technique to distinguish between focused and unfocused epochs. The adaptive threshold method results have been more accurate reaching the benchmark of 99.82%, as opposed to the fixed threshold method, which reaches an accuracy of 97.73%. The findings were assessed through a pilot study involving 3483 epochs collected across 24 sessions from male and female children aged between 5 and 16. The proposed QEEG software was evaluated to be Specific, Measurable, Achievable, Realistic, and Timed (SMART) with an effect size of 0.85528336, which is significant.},
  archive      = {J_NCA},
  author       = {Magdy Rady, Radwa and Elsalamawy, Doaa and Rizk, M. R. M. and Abdel Alim, Onsy and Diaa Moussa, Nancy},
  doi          = {10.1007/s00521-024-10835-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {8},
  pages        = {5849-5871},
  shortjournal = {Neural Comput. Appl.},
  title        = {Enhancing affordable EEG to act as a quantitative EEG for inattention treatment using MATLAB},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Historical states modeling for visual tracking.
<em>NCA</em>, <em>37</em>(7), 5831–5848. (<a
href="https://doi.org/10.1007/s00521-024-10921-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Extracting additional spatiotemporal information from video sequences is critical for accurately perceiving target appearance changes during visual tracking. However, most learning-based trackers utilize only a single search image and template from a video for training, resulting in a lack of temporal information and low data utilization. To address these issues, we present an innovative Trajectory Guided Tracking (TGTrack) framework, which leverages the historical states of the target to predict its current location. Specifically, we construct trajectory tokens derived from tracking results in historical frames, integrating the position and scale information of the target. We propose a trajectory prediction module to utilize these trajectory tokens to generate the potential scope of current target. Furthermore, to enhance the inference efficiency of the tracker, we eliminate manually customized heads and post-processing steps. Consequently, we achieve a good balance between inference speed and effectiveness. Extensive experimental results demonstrate that our TGTrack achieves leading performance across multiple benchmarks.},
  archive      = {J_NCA},
  author       = {Shi, Junze and Yu, Yang and Hui, Bin and Shi, Jian and Luo, Haibo},
  doi          = {10.1007/s00521-024-10921-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5831-5848},
  shortjournal = {Neural Comput. Appl.},
  title        = {Historical states modeling for visual tracking},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A surface defect detection instrument for large aperture
spherical optical elements. <em>NCA</em>, <em>37</em>(7), 5815–5829. (<a
href="https://doi.org/10.1007/s00521-024-10889-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spherical optical elements are an important classification of modern optical system components. Surface defects on optical elements can cause serious problems to the optical system. Fast and accurate defect detection for large aperture (200 mm) spherical optical elements is a challenge for industrial applications due to the tiny scale of the defects and the non-flat and super-smooth surface. A surface defect detection instrument for large aperture spherical optical elements is established in this paper, while the main contributions are: (1) A 5-axis motion system with microscopic imaging and multi-angle lighting system is designed for defect detection. (2) To image the spherical element surface clearly and completely, an adaptive path planning method that suits the 5-axis motion system is raised. (3) Aiming at tiny and weak defects of precise optical elements, an effective defect detection algorithm based on reverse attention is proposed for the instrument, which outperforms the baseline methods. Experiments display the instrument’s superior capability to existing instruments that, for a spherical optical element of 200 mm aperture and 200 mm radius of the sphere surface, the instrument can achieve surface defect detection with the precision of 2 μm in less than 10 min.},
  archive      = {J_NCA},
  author       = {Li, Mingwei and Shi, Yali and Zhang, Zhengtao and Tao, Xian and Shang, Xiuqin},
  doi          = {10.1007/s00521-024-10889-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5815-5829},
  shortjournal = {Neural Comput. Appl.},
  title        = {A surface defect detection instrument for large aperture spherical optical elements},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intelligent recognition system of in-service tire damage
driven by strong combination augmentation and contrast fusion.
<em>NCA</em>, <em>37</em>(7), 5795–5813. (<a
href="https://doi.org/10.1007/s00521-024-10898-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the advancement of computer technology, dynamic detection of damage to tire in-service has become feasible. However, current methods often struggle with accuracy limitations when confronted with specific working conditions and external factors. To address this challenge, we propose an intelligent recognition system for in-service tire damage driven by Strong Combination Augmentation and Contrast Fusion. The system uses a key feature learning enhancement method to address the problem. It uses the Hough transform and the Perceptual Hash algorithm to perform secondary feature comparison, enabling tire region detection even in low-resolution and high-interference scenarios. To effectively eliminate interference caused by wear, stains, and similar factors, we also introduce an efficient damage detection network called CA-EffNet. This network employs a strategic approach that combines various augmentation techniques and parameters with contrast fusion within a supervised learning framework. By integrating these elements, CA-EffNet expands the feature exploration space and effectively captures key damage features. The results show that the system efficiently achieves real-time detection within just 0.7 s at speeds of up to 15 km/h, meeting strict detection requirements. These results highlight the potential of the system to significantly advance the field of tire damage detection and ultimately contribute to safer roads.},
  archive      = {J_NCA},
  author       = {Shen, Dagang and Cao, Jinfeng and Liu, Peng and Guo, Jihong},
  doi          = {10.1007/s00521-024-10898-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5795-5813},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intelligent recognition system of in-service tire damage driven by strong combination augmentation and contrast fusion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fake news detection based on multi-modal domain adaptation.
<em>NCA</em>, <em>37</em>(7), 5781–5793. (<a
href="https://doi.org/10.1007/s00521-024-10896-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid development of social media has led to the unguaranteed authenticity of news, and the role of fake news detection in cybersecurity governance has become increasingly prominent. In this paper, we mine information from multiple modalities, such as the text and images of news, and propose a multi-modal fake news detection model based on the multi-stage domain adaptation for the differences existing between source and task domains and between different modalities. The multi-modal feature extraction network of BERT combined with EfficientNet is used to deeply analyze the features of social media data, and the multi-modal domain adaptation network is used to reduce the domain shift of different domains and different modalities of news data and to capture the correlation between events by adversarial ideas. Experimental results on public datasets of Weibo and Twitter show that the model significantly improves the effectiveness of the fake news detection task.},
  archive      = {J_NCA},
  author       = {Wang, Xiaopei and Meng, Jiana and Zhao, Di and Meng, Xuan and Sun, Hewen},
  doi          = {10.1007/s00521-024-10896-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5781-5793},
  shortjournal = {Neural Comput. Appl.},
  title        = {Fake news detection based on multi-modal domain adaptation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comprehensive study of fisheye image compression and
perception for autonomous driving. <em>NCA</em>, <em>37</em>(7),
5765–5780. (<a
href="https://doi.org/10.1007/s00521-024-10831-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Fisheye cameras are widely used in various fields, including automotive contexts for $$360^{\circ }$$ near-field vision around vehicles, as well as in photography, robotics, underwater imaging, and virtual reality. However, conventional image compression techniques do not take into account the specific characteristics of fisheye images, such as radial distortion and wide-angle field of view, especially when operating at low bit rates. This can lead to degradation of image quality and distortion of geometric features that are essential for computer vision (CV) applications such as object detection, semantic segmentation, and motion estimation. Recent studies have highlighted the impact of various noise factors on automotive camera sensors, the challenges of correcting radial lens distortion, and the effects of image compression artifacts on fisheye camera visual perception tasks. In this work, a comprehensive study of fisheye image compression and perception using deep learning-based techniques is conducted. It is demonstrated that deep learning-based techniques achieve better compression performance and perceptual quality than conventional techniques, particularly at low bitrates crucial for automotive applications.},
  archive      = {J_NCA},
  author       = {Barakat, Basem and Sobh, Ibrahim and Wong, Chup-Chung and Islam, Muahmmad},
  doi          = {10.1007/s00521-024-10831-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5765-5780},
  shortjournal = {Neural Comput. Appl.},
  title        = {A comprehensive study of fisheye image compression and perception for autonomous driving},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Detecting and assessing weak adhesion in structural single
lap joints using a machine learning pipeline with lamb waves data.
<em>NCA</em>, <em>37</em>(7), 5751–5764. (<a
href="https://doi.org/10.1007/s00521-024-10819-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adhesive joints are widely used in industries such as aerospace and automotive due to their lightweight and high mechanical performance. However, weak adhesion remains a significant issue affecting the structural integrity of these joints. Current detection methods of weak adhesion rely on destructive testing, which limits the widespread use of adhesive primary structures. This study proposes a novel nondestructive testing (NDT) technique to detect, evaluate the intensity, and localize weak adhesion in single lap joints (SLJs) using lamb waves (LWs) and machine learning (ML). The aim is to develop a ML-based pipeline capable of identifying weak adhesion with high accuracy and sensitivity, based on data from simulated and experimental SLJ samples. The proposed technique integrates LW data with convolutional neural networks (CNNs) in a ML pipeline for weak adhesion detection in SLJs. The use of a large simulated dataset combined with transfer learning allows for effective adaptation to experimental conditions, improving both the detection and localization of damage. This approach offers a significant advancement over traditional destructive testing techniques. The pipeline begins with the generation of simulated LW time-series data for SLJs with varying adhesion levels, damage locations, and sizes. After preprocessing, the data are input into a CNN, which is initially trained on synthetic data. Transfer learning is employed to fine-tune the model using a small experimental dataset. The final trained model is then applied to detect weak adhesion, estimate its intensity, and localize the damage. The proposed pipeline demonstrated high performance in both simulated and experimental datasets: regarding detection, the algorithm achieved over 95.3% accuracy in identifying damage from simulated data and near 100% detection of damaged cases in experimental data; for intensity estimation, the algorithm showed an average loss of approximately 45 MPa for weak adhesion intensity in experimental validation, with an average error of about 140 MPa and a best-case error of just near 3.6 MPa; in terms of localization, the average localization error was approximately 8 mm in the synthetic validation dataset; with respect to flexibility, the methodology is adaptable to different damage characteristics, such as existence, intensity, and localization, without requiring substantial modifications. Summing up, this study presents a novel NDT approach using ML and LW data that significantly improves the detection, evaluation, and localization of weak adhesion in adhesive joints. Its high accuracy and adaptability have the potential to enhance structural health monitoring, ensuring the safety and durability of bonded structures in critical industries.},
  archive      = {J_NCA},
  author       = {Ramalho, Gabriel M. F. and Lopes, António M. and da Silva, Lucas F. M.},
  doi          = {10.1007/s00521-024-10819-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5751-5764},
  shortjournal = {Neural Comput. Appl.},
  title        = {Detecting and assessing weak adhesion in structural single lap joints using a machine learning pipeline with lamb waves data},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid meta-heuristic algorithm for optimization of
capuchin search algorithm for high-dimensional biological data
classification. <em>NCA</em>, <em>37</em>(7), 5719–5750. (<a
href="https://doi.org/10.1007/s00521-024-10815-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Feature selection (FS) is a preprocessing technique that diminishes redundant and non-informative features to enhance data classification methods. This technique has gained global significance with the expansion of real-world data, particularly high-dimensional biological datasets. This study introduces a distinctive wrapper-based FS model, built upon the capuchin search algorithm (CapSA). CapSA is a recent swarm intelligence algorithm inspired by the foraging behaviors of Capuchin monkeys. Despite the strengths of the standard CapSA, it has notable limitations that this paper aims to address through purposeful modifications to the algorithm. These modifications include incorporating genetic algorithm operators (crossover and mutation), a dynamic mechanism for determining the number of leaders, and incorporating adaptive inertia weight. The proposed enhanced variant, named CapSA-CM, aims to achieve a more effective balance between the exploration and exploitation phases of the algorithm. The proposed methods are assessed using high-dimensional, low-sample biological datasets. The CapSA-CM approach is validated by comparing its efficacy with basic and hybrid meta-heuristic algorithms. Statistical analysis demonstrates the superiority of the CapSA-CM in terms of feature reduction, accuracy rates, and fitness values compared to the original CapSA and other comparable algorithms.},
  archive      = {J_NCA},
  author       = {Jaber, Iyad and Hassouneh, Yousef and Khemaja, Maha},
  doi          = {10.1007/s00521-024-10815-w},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5719-5750},
  shortjournal = {Neural Comput. Appl.},
  title        = {A hybrid meta-heuristic algorithm for optimization of capuchin search algorithm for high-dimensional biological data classification},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMU-trans: Imputing missing motion capture data with
unsupervised transformers. <em>NCA</em>, <em>37</em>(7), 5699–5717. (<a
href="https://doi.org/10.1007/s00521-024-10946-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Motion capture (mocap) systems are extensively utilized in healthcare for monitoring rehabilitation programs, facilitating clinical gait assessments for early Alzheimer’s diagnosis, managing walking disorders, and developing exoskeleton suits. However, like many other healthcare technologies, mocap systems have some flaws, like missing markers and occlusions. Given mocap data’s sequential and temporal nature, understanding marker relationships and capturing global dependencies are crucial for effective human motion recovery applications. To address these challenges, we proposed an unsupervised transformers framework for human motion recovery, called IMU-Trans. We evaluated our framework’s generalizability across two clinical datasets and tested its robustness by adjusting the missing marker rates, comparing its performance against low-dimensional Kalman filtering, long short-term memory (LSTM), and gated recurrent unit (GRU) models. Our experimental results demonstrated that IMU-Trans outperforms state-of-the-art models by training in an unsupervised manner. The closest competitor, GRU, demonstrated an RMSE of 1.35 ± 0.82, 2.36 ± 1.26, 3.43 ± 1.73, and 4.39 ± 2.18 cm for 20%, 30%, 40%, and 50% missing rates, respectively. IMU-Trans outperformed GRU with an RMSE of 1.26 ± 0.60, 2.06 ± 0.88, 2.68 ± 1.04, and 3.05 ± 1.22 for the same rates. Notably, our framework performs well even with higher missing data rates, creating opportunities for advancements in data analytics and indicating a promising future for motion capture in healthcare.},
  archive      = {J_NCA},
  author       = {Avdan, Goksu and Onal, Sinan and Lu, Chao},
  doi          = {10.1007/s00521-024-10946-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5699-5717},
  shortjournal = {Neural Comput. Appl.},
  title        = {IMU-trans: Imputing missing motion capture data with unsupervised transformers},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Navigation variable-based multi-objective particle swarm
optimization for UAV path planning with kinematic constraints.
<em>NCA</em>, <em>37</em>(7), 5683–5697. (<a
href="https://doi.org/10.1007/s00521-024-10945-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Path planning is essential for unmanned aerial vehicles (UAVs) as it determines the path that the UAV needs to follow to complete a task. This work addresses this problem by introducing a new algorithm called navigation variable-based multi-objective particle swarm optimization (NMOPSO). It first models path planning as an optimization problem via the definition of a set of objective functions that include optimality and safety requirements for UAV operation. The NMOPSO is then used to minimize those functions through Pareto optimal solutions. The algorithm features a new path representation based on navigation variables to include kinematic constraints and exploit the maneuverable characteristics of the UAV. It also includes an adaptive mutation mechanism to enhance the diversity of the swarm for better solutions. Comparisons with various algorithms have been carried out to benchmark the proposed approach. The results indicate that the NMOPSO performs better than not only other particle swarm optimization variants but also other state-of-the-art multi-objective and meta-heuristic optimization algorithms. Experiments have also been conducted with real UAVs to confirm the validity of the approach for practical flights. The source code of the algorithm is available at https://github.com/ngandng/NMOPSO .},
  archive      = {J_NCA},
  author       = {Duong, Thi Thuy Ngan and Bui, Duy-Nam and Phung, Manh Duong},
  doi          = {10.1007/s00521-024-10945-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5683-5697},
  shortjournal = {Neural Comput. Appl.},
  title        = {Navigation variable-based multi-objective particle swarm optimization for UAV path planning with kinematic constraints},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Velocity control of a stephenson III six-bar linkage-based
gait rehabilitation robot using deep reinforcement learning.
<em>NCA</em>, <em>37</em>(7), 5671–5682. (<a
href="https://doi.org/10.1007/s00521-024-10944-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Lower limb rehabilitation robots can help to improve the locomotor capabilities of patients experiencing gait impairments and help medical workers by reducing strain on them. However, since commercially available exoskeletons are expensive and there is a lack of number of physiotherapists many patients are still not able to get proper rehabilitation training. The closed-loop linkage mechanisms have recently drawn much attention in the realization of gait rehabilitation robots. Such mechanisms are affordable and capable of providing suitable trajectories for gait training therapy. In this work, we have proposed a fully operational one degree-of-freedom mechanism which can generate complex naturalistic lower limb trajectories. Although in theory, it is assumed that the constant speed applied at the input crank is sufficient to control the system, in reality, the external forces exerted by human legs and the inertia of the links can greatly alter the rotational velocity at the crank, which may negatively affect the training process. Therefore, we have explored the performance of a deep reinforcement learning-based control algorithm designed to regulate the speed of the input crank to reach satisfactory performance needed for gait rehabilitation training. Experimental evaluations with healthy human subjects were conducted to demonstrate that the mechanism is capable of directing lower limbs on naturalistic gait trajectories with a required walking speed.},
  archive      = {J_NCA},
  author       = {Kapsalyamov, Akim and Brown, Nicholas A. T. and Goecke, Roland and Jamwal, Prashant K. and Hussain, Shahid},
  doi          = {10.1007/s00521-024-10944-2},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5671-5682},
  shortjournal = {Neural Comput. Appl.},
  title        = {Velocity control of a stephenson III six-bar linkage-based gait rehabilitation robot using deep reinforcement learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Intrusion detection system model: A white-box decision tree
with feature selection optimization. <em>NCA</em>, <em>37</em>(7),
5655–5670. (<a
href="https://doi.org/10.1007/s00521-024-10942-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Intrusion detection has been an active development area due to its importance in highly digitally connected ecosystems. Most of the existing developments have focused on the use of complex machine learning models that are black-box in nature. There is an urgent need to investigate a more transparent model approach for determining the features associated with intrusion detection. In this paper, a feature selection is proposed for a decision tree (DT)-based classifier. In particular, a stochastic optimization technique based on differential evolution (DE) is used to create the DT for optimizing feature selection. The contribution of this paper is twofold. First, a white-box machine learning model using DT is implemented. Second, an optimal feature reduction approach is embedded in the process of building the DT. The results demonstrate an improvement over the non-feature selection approach and the black-box neural network and are comparable to other state-of-the-art models. This shows that it is possible to achieve high performance despite using a minimal transparent model by eliminating non-contributing features. This is the essence of Occam’s razor principle, which states that a more condensed model contributes to better generalization. There is an evident improvement in the generalization of the DT model after optimization of features. Despite often being associated with a weaker machine learning model, the results show comparative results on independent datasets, indicating the suitability for such a task. It is worth mentioning that the final model only utilizes a fraction of the full feature set. Although the generalization performance only improved less than 1% in comparison with the non-feature selection counterpart, the proposed approach suggests that a condensed model yielding a similar performing model should be considered.},
  archive      = {J_NCA},
  author       = {Wong, W. K. and Juwono, Filbert H. and Eswaran, Sivaraman and Motelebi, Foad},
  doi          = {10.1007/s00521-024-10942-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5655-5670},
  shortjournal = {Neural Comput. Appl.},
  title        = {Intrusion detection system model: A white-box decision tree with feature selection optimization},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Course time scheduling problem for distance education
considering server load balancing: A case of an engineering faculty.
<em>NCA</em>, <em>37</em>(7), 5635–5653. (<a
href="https://doi.org/10.1007/s00521-024-10941-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {During the Covid-19 pandemic and mass disaster, universities have had to continue their courses with distance education. Internet servers in educational institutions slowed down for some periods, and courses could not be processed. The interruptions are due to the intensity of users on the servers and the internet congestion in the country during some time periods. For these reasons, the course time scheduling problem for distance education is discussed in this study. This study aims to balance the number of users in the system to prevent internet congestion. To solve the problem, two different mathematical models are developed. The first model obtains the balanced course scheduling for any time period. The second model is provided by the course assignment, considering internet congestion that occurred during any period. The proposed models were tested in a real case study dealing with the charting of courses offered in all departments of the engineering faculty of a university in Turkey. A problem-specific heuristic model is developed to solve the problem since a solution could not be obtained from the mathematical models in polynomial time due to the large size of the actual data set. The comparative results obtained from mathematical models and problem-specific heuristics are reported, and their performance is discussed. According to the comparative results, problem-specific heuristic outperforms mathematical models in obtaining a balanced schedule and solution time.},
  archive      = {J_NCA},
  author       = {Alakaş, Hacı Mehmet and Pınarbaşı, Mehmet and Sarımehmet, Bedirhan and Eren, Tamer},
  doi          = {10.1007/s00521-024-10941-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5635-5653},
  shortjournal = {Neural Comput. Appl.},
  title        = {Course time scheduling problem for distance education considering server load balancing: A case of an engineering faculty},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Radial basis function network-based optimization of the hard
self-propelled rotary turning titanium. <em>NCA</em>, <em>37</em>(7),
5607–5634. (<a
href="https://doi.org/10.1007/s00521-024-10940-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Machining of difficult-to-cut materials such as high-temperature metals is challenging due to their low machinability resulting in reduced productivity and high manufacturing cost. This investigation develops and optimizes the hard self-propelled rotary turning (HSPRT) operation, in which an efficient self-propelled rotary tool is proposed and fabricated. The HSPRT responses (total carbon emission—TC, machined roughness—MR, and noise emission—EN) are minimized using optimal process variables (inclination angle—A, turning depth—D, turning speed—V, and rake angle—R). The TC, MR, and EN models are developed in terms of the HSPRT inputs using the radial basis function network and response surface method, while the weights were computed using the removal effects of criteria, EQUAL, and rank order centroid methods. The improved quantum-behaved particle swarm optimization algorithm and method based on the multi-attributive border approximation area comparison were applied to produce feasible solutions and select the best optimal point. The optimization findings of the V, D, f, and R were 32 deg., 0.2 mm, 137 m/min, and 20 deg., while the TC, MR, and EN were saved by 42.8%, 24.1%, and 20.0%, respectively. The HSPRT performances were primarily affected by the turning depth and speed, respectively. The valuable outcomes could be applied to the practice to boost HSPRT performances, while the developed HSPRT operation could be utilized for machining alloys and hardened steels. The technique could be applied to treat optimization problems for other rotary turning processes.},
  archive      = {J_NCA},
  author       = {Nguyen, Trung-Thanh and Dang, Xuan-Ba},
  doi          = {10.1007/s00521-024-10940-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5607-5634},
  shortjournal = {Neural Comput. Appl.},
  title        = {Radial basis function network-based optimization of the hard self-propelled rotary turning titanium},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Finite-time fault-tolerant control of attitude control
system of quadrotor UAV based on neural network disturbance observer.
<em>NCA</em>, <em>37</em>(7), 5597–5606. (<a
href="https://doi.org/10.1007/s00521-024-10927-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper investigates a new finite-time fault-tolerant control scheme for a quadrotor unmanned aerial vehicle (UAV). Firstly, a novel neural network disturbance observer with an auxiliary system is designed to compensate for actuator faults and external disturbances. In addition, in order to ensure the system’s rapidity, the finite-time theory is incorporated into the observer design and the controller design. The hyperbolic tangent function is also introduced to process the input signals, which ensures that the UAV receives relatively the smooth input signals. The design scheme takes into account the rapidity and robustness of the system, which makes the performance of the UAV better. Finally, the advantages of the proposed scheme are demonstrated through comparative experiments and the feasibility of the scheme is further verified through actual physical experiments.},
  archive      = {J_NCA},
  author       = {Li, Boning and Chen, Ming and Qi, Shuchang and Peng, Kaixiang},
  doi          = {10.1007/s00521-024-10927-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5597-5606},
  shortjournal = {Neural Comput. Appl.},
  title        = {Finite-time fault-tolerant control of attitude control system of quadrotor UAV based on neural network disturbance observer},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DeepCancer: Deep learning for brain tumor detection-based
application system. <em>NCA</em>, <em>37</em>(7), 5577–5596. (<a
href="https://doi.org/10.1007/s00521-024-10926-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A brain tumor is the abnormal cells that growth in the brain, and it is considered as one of the most dangerous diseases that lead to the cause of death. Diagnosis at early is important for increasing the survival rate from the brain tumors. Specialists can identify the tumors manually, but it is very time and effort consuming, and are subject to human error, especially when dealing with large amounts of images. The automatic identification algorithms-based applications can facilitate the process. This study aimed to investigate the possibility of detecting brain cancer based on images using Deep Learning (DL) techniques and statistical operations. The features were extracted using two models of Convolutional Neural Network (CNN), (VGG-19 and AlexNet), then they were used to generate new datasets for statistical operations. CNN is used to extract features with distinct details from brain MRI images. The data were trained in three different training–testing data splitting ratios. Then, the features were classified based on the KNN, RF, and SVM to find the best accuracy of brain MRI image. At the end, the obtained classification accuracy was in favor of statistical operations especially for Large-Value, and Merge between features using KNN (99.1) and SVM (99.1). The features that extracted used in this study can provide high influence on the classification accuracy. The results across all three training–testing data splitting ratios were almost similar, and this approves that the brain cancer can be identified with high accuracy even if the training dataset sizes were minimal.},
  archive      = {J_NCA},
  author       = {AlShowarah, Suleyman A.},
  doi          = {10.1007/s00521-024-10926-4},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5577-5596},
  shortjournal = {Neural Comput. Appl.},
  title        = {DeepCancer: Deep learning for brain tumor detection-based application system},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Hmltnet: Multi-modal fake news detection via hierarchical
multi-grained features fused with global latent topic. <em>NCA</em>,
<em>37</em>(7), 5559–5575. (<a
href="https://doi.org/10.1007/s00521-024-10924-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Since the adverse impact of fake news, especially multi-modal fake news, on public decision-making and social governance, multi-modal fake news detection has lately attracted increasing attention. However, many existing methods ultimately exploit multi-modal features without detail fusion to complete detection and insufficiently consider the intrinsic features in news content, resulting in poor performance. To tackle these issues, we propose a network for multi-modal fake news detection that uses hierarchical multi-grained features fused with global latent topic (HMLTNet). Specifically, we first construct Hierarchical Multi-grained Encoding Module to capture convolutional and hierarchical textual features. Then, Cross-modal Shared Attention Module completes detail compensation in the multi-modal features by fusing textual and visual features and jointly modeling inter- and intra-modality correlations. Finally, the global latent topic features are excavated and stocked from multi-modal features by utilizing Latent Topic Memory Module. Furthermore, we design an Enhanced Similarity Module and introduce a dense-like strategy together to alleviate the adverse effects of cross-modal semantic gap. Extensive experiments on three public datasets indicate that the presented network reaches the best accuracy compared to state-of-the-art methods.},
  archive      = {J_NCA},
  author       = {Cui, Shaoguo and Gong, Linfeng and Li, Tiansong},
  doi          = {10.1007/s00521-024-10924-6},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5559-5575},
  shortjournal = {Neural Comput. Appl.},
  title        = {Hmltnet: Multi-modal fake news detection via hierarchical multi-grained features fused with global latent topic},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Modified u-net with attention gate for enhanced automated
brain tumor segmentation. <em>NCA</em>, <em>37</em>(7), 5521–5558. (<a
href="https://doi.org/10.1007/s00521-024-10919-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study addresses the formidable challenges encountered in automated brain tumor segmentation, including the complexities of irregular shapes, ambiguous boundaries, and intensity variations across MRI modalities. Manual segmentation, plagued by subjectivity and time constraints, further exacerbates the problem. To address these issues, we propose a modified U-Net architecture with an integrated attention gate. The proposed model demonstrates high performance, with notable Dice Similarity Coefficient (DSC) and Jaccard Index (JI) values across various tumor classes, consistently exceeding 0.93 and 0.87, respectively. Incorporating Contrast-Limited Adaptive Histogram Equalization and Histogram Equalization improves segmentation accuracy, particularly in cases of Meningioma. Comparative analyses against established models reveal a DSC of 0.9521 and a JI of 0.9093, underscoring the superiority of our method. Validation in the BraTS 2021 dataset underscores the robustness of the method, achieving high DSC and JI scores in four MRI modalities, with the T2 modality demonstrating the highest performance (DSC: 0.9216, JI: 0.8556). While acknowledging these achievements, we recognize challenges related to dataset specificity and computational intensity associated with the attention gate. Future research efforts should address these issues to improve the generalizability and applicability of the method in real-world scenarios. In addition to presenting a novel automated brain tumor segmentation method, this study contributes comprehensive result values and comparative analyses with previous research, providing valuable insights into the evolving landscape of medical image analysis.},
  archive      = {J_NCA},
  author       = {Saifullah, Shoffan and Dreżewski, Rafał and Yudhana, Anton and Wielgosz, Maciej and Caesarendra, Wahyu},
  doi          = {10.1007/s00521-024-10919-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5521-5558},
  shortjournal = {Neural Comput. Appl.},
  title        = {Modified U-net with attention gate for enhanced automated brain tumor segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DNA sequence design model for multi-scene fusion.
<em>NCA</em>, <em>37</em>(7), 5499–5520. (<a
href="https://doi.org/10.1007/s00521-024-10905-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Due to its unique properties and excellent sequence design methods, DNA finds wide applications in computing, information storage, molecular circuits, and biological diagnosis. Previous efforts to enhance the efficiency and precision of DNA sequence design have led to the proposal of various universal DNA sequence design methods. These methods optimize the arrangement of the four bases to reduce sequence similarity and meet specific criteria. However, prior investigations have predominantly focused on sequence design within single-scene frameworks, overlooking the complexities associated with designing for multi-scene fusion, such as ion-bridge mismatch, tri-base sequence design, and others. To address this gap, we fused four common scenes and introduced two novel constraint models to facilitate DNA sequence design for multi-scene fusion. Additionally, we developed a dynamic virus spread algorithm as the core for optimizing DNA sequences and evaluated it using 23 well-known benchmark functions. Furthermore, our algorithm outperformed eight popular swarm evolutionary algorithms in eight dominant results. Finally, we simulated the optimization of four distinct scenes, demonstrating that our sequences met expected performance levels in their respective areas. Thus, our work provides a practical tool for designing DNA sequences tailored to various specific applications.},
  archive      = {J_NCA},
  author       = {Yao, Yao and Zheng, Yanfen and Cui, Shuang and Hou, Yaqing and Zhang, Qiang and Wei, Xiaopeng},
  doi          = {10.1007/s00521-024-10905-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5499-5520},
  shortjournal = {Neural Comput. Appl.},
  title        = {DNA sequence design model for multi-scene fusion},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An efficient and scalable semi-supervised framework for
semantic segmentation. <em>NCA</em>, <em>37</em>(7), 5481–5497. (<a
href="https://doi.org/10.1007/s00521-024-10891-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation has succeeded remarkably in various applications, such as autonomous vehicles and robotic systems. However, the training process for such techniques necessitates a significant amount of labeled data. Although semi-supervised frameworks can alleviate this issue, advanced approaches typically require multiple baseline models to form a dual model, which is costly in space computation complexity. To relieve the undesired computational cost for systems with precious computation and memory resources, we propose an efficient and scalable semi-supervised learning framework to significantly improve the performance with a few additional parameters concerning the baseline models. This framework includes a pseudo-dual module and a self-rectification module. The overall structure comprises three parts: an encoder, a shallow decoder, and a deep decoder. The deep decoder is connected to a deep layer of the encoder, and the shallow decoder is connected to a shallow layer. As knowledge distillation transfers knowledge from one model to another, the pseudo-dual module can distill knowledge from the ensemble of two decoders to improve the encoder, which can implicitly form a pseudo-dual model. The self-rectification module calculates class-wise likelihoods according to the similarity between features and class prototypes learned from different decoders and rectifies low-confidence pseudo-labels. The effectiveness of such rectification is justified theoretically and numerically. In our experiments with DeepLabV2, our methods outperform others in mIoU by over 1.21% with 1/8 labeled data using the Cityscapes dataset and by 0.38% with 1/8 labeled data using PASCAL VOC 2012 datasets. In most cases, our approach can also save more than 30% of memory costs during training. Nevertheless, the effectiveness of the proposed approach also depends on the quality of pseudo-labels generated by backbone models and may encounter challenges when handling data with highly imbalanced classes.},
  archive      = {J_NCA},
  author       = {Hao, Huazheng and Xiao, Hui and Xiong, Junjie and Dong, Li and Yan, Diqun and Liang, Dongtai and Zhuang, Jiayan and Peng, Chengbin},
  doi          = {10.1007/s00521-024-10891-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5481-5497},
  shortjournal = {Neural Comput. Appl.},
  title        = {An efficient and scalable semi-supervised framework for semantic segmentation},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MGAN-CRCM: A novel multiple generative adversarial network
and coarse refinement-based cognizant method for image inpainting.
<em>NCA</em>, <em>37</em>(7), 5459–5480. (<a
href="https://doi.org/10.1007/s00521-024-10886-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image inpainting is a recognized method for restoring the properties of pixels in damaged or incomplete images in computer vision technology. Some recent techniques based on generative adversarial network (GAN) image inpainting have outperformed traditional approaches due to their excellent deep learning capability and adaptability to various image domains. Since residual networks (ResNet) also gained popularity over time due to their property as a generative model, offering better feature representation and compatibility with other architectures, how could we leverage both of these models to result in even greater success in image inpainting? This paper proposes a novel architecture for image inpainting based on GAN and residual networks. Our proposed architecture consists of three models: Transpose Convolution-based GAN, Fast ResNet-Convolutional Neural Network, and Co-Modulation GAN. Transpose Convolution-based GAN is our newly designed architecture. It produces guided and blind image inpainting, and FR-CNN performs the object removal case. Co-Mod GAN acts as a refinement layer because it refines the results from Transpose Convolution-based GAN and FR-CNN. To train and evaluate our proposed architecture on publicly available benchmark datasets: CelebA, Places2, and ImageNet are used. Our approach proves our hypothesis, and our proposed model acquires the highest accuracy of 96.59% in the ImageNet dataset, FR-CNN acquires the highest accuracy of 96.70% in the Places2 dataset, and Co-Mod GAN acquires the highest accuracy of 96.16% in the CelebA dataset. Through an analysis of both qualitative and quantitative comparisons, it is evident that our proposed model exceeds existing architectures in performance.},
  archive      = {J_NCA},
  author       = {Asad, Nafiz Al and Pranto, Md. Appel Mahmud and Shiam, Shbiruzzaman and Akand, Musaddeq Mahmud and Yousuf, Mohammad Abu and Hasan, Khondokar Fida and Moni, Mohammad Ali},
  doi          = {10.1007/s00521-024-10886-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5459-5480},
  shortjournal = {Neural Comput. Appl.},
  title        = {MGAN-CRCM: A novel multiple generative adversarial network and coarse refinement-based cognizant method for image inpainting},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Develop a novel, faster mask region-based convolutional
neural network model with leave-one-subject-out to predict freezing of
gait abnormalities of parkinson’s disease. <em>NCA</em>, <em>37</em>(7),
5441–5457. (<a
href="https://doi.org/10.1007/s00521-024-10832-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A common symptom of severe Parkinson’s disease (PD) is Freezing of Gait (FoG), a gait disorder that causes sudden difficulty in initiating or maintaining walking. FoG frequently leads to falls and has a detrimental impact on a patient’s regular life. Real-time detection algorithms identify FoG occurrences using wearable sensors. Anticipating FoG in advance allows for pre-emptive cueing, which may prevent the episodes or reduce their severity and duration. This research proposes a Faster Mask Region-based Convolutional Neural Network (FMRCNN) signal processing approach for FoG identification. The model captured gyroscope, magnetometer, and tri-axial accelerometer signals using an inertial measurement device on the left side of the abdomen. The experimental results demonstrate a reduction in the equal error rate to 1.9% in the Leave-One-Subject-Out (LOSO) Cross-Validation (CV) with Long Short Term Memory (LSTM) assessment. Additionally, the tenfold CV evaluation enhances specificity and sensitivity by 0.045 and 0.017, respectively, compared to previous best results. It takes only 0.52 ms to detect a 256-data section. The proposed work uses the LOSO-CV-LSTM to evaluate various machine learning (ML) and deep learning (DL) techniques for FoG detection. The proposed system not only detects FoG but also enhances the automation of PD detection and therapy at an earlier stage. The results demonstrate that the proposed system improves performance measures compared to existing systems.},
  archive      = {J_NCA},
  author       = {Ezhilarasi, J. and Senthil Kumar, T.},
  doi          = {10.1007/s00521-024-10832-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5441-5457},
  shortjournal = {Neural Comput. Appl.},
  title        = {Develop a novel, faster mask region-based convolutional neural network model with leave-one-subject-out to predict freezing of gait abnormalities of parkinson’s disease},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event-triggered adaptive fuzzy inverse optimal control of
steer-by-wire vehicle systems. <em>NCA</em>, <em>37</em>(7), 5429–5439.
(<a href="https://doi.org/10.1007/s00521-024-10768-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, an event-triggered adaptive fuzzy inverse optimal control issue is investigated for the steer-by-wire vehicle (SBWV) systems. Firstly, fuzzy logic systems are adopted to model the unknown nonlinear dynamics and an auxiliary nonlinear system is established. Then, an event-triggered mechanism (ETM) is established to reduce the numbers of controller execution times. Subsequently, based on designed auxiliary nonlinear system and ETM, an event-triggered adaptive fuzzy inverse optimal control algorithm is proposed by employing the backstepping control technique. It is proved that the developed control method can ensure the stability of SBWV systems and the tracking error converges to the neighborhood of zero. Finally, the simulation results are provided to demonstrate the effectiveness of presented control approach.},
  archive      = {J_NCA},
  author       = {Zhang, Jiaming and Zuo, Yi and Tong, Shaocheng},
  doi          = {10.1007/s00521-024-10768-0},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5429-5439},
  shortjournal = {Neural Comput. Appl.},
  title        = {Event-triggered adaptive fuzzy inverse optimal control of steer-by-wire vehicle systems},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel w13 deep CNN structure for improved semantic
segmentation of multiple objects in remote sensing imagery.
<em>NCA</em>, <em>37</em>(7), 5397–5427. (<a
href="https://doi.org/10.1007/s00521-024-10765-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper proposes a novel convolutional neural network (CNN) architecture designed for semantic segmentation in remote sensing images. The proposed W13 Net model addresses the inherent challenges of segmentation tasks through a carefully crafted architecture, combining the strengths of multistage encoding–decoding, skip connections, combined weighted output, and concatenation techniques. Compared with different segmentation models, the suggested model performs better. A comprehensive analysis of different segmentation models has been carried out, resulting in an extensive comparison between the proposed W13 Net and five existing state-of-the-art segmentation architectures. Utilizing two standardized datasets, the Dense Labeling Remote Sensing Dataset Termed (DLRSD), and the Mohammad Bin Rashid Space Center (MBRSC) Dubai Aerial Imagery Dataset, the evaluation entails training, testing, and validation across different classes. The W13 Net demonstrates adaptability, generalization capabilities, and superior results in key metrics, all while displaying robustness across a variety of datasets. A number of metrics, including accuracy, precision, recall, F1 score, and IOU, were used to evaluate the system’s performance. According to the experimental results, the W13 Net model obtained an accuracy of 87.8%, precision of 0.88, recall of 0.88, F1 score of 0.88, and IOU of 0.74. The suggested model showed a significant improvement in segmentation IOU, with an increase of up to 18%, when compared to other with the recent segmentation models taking into consideration the model’s comparatively low number of parameter (2.2 million) in comparison with the recent models.},
  archive      = {J_NCA},
  author       = {Elgamily, Khaled Mohammed and Mohamed, M. A. and Abou-Taleb, Ahmed Mohamed and Ata, Mohamed Maher},
  doi          = {10.1007/s00521-024-10765-3},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5397-5427},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel w13 deep CNN structure for improved semantic segmentation of multiple objects in remote sensing imagery},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stress detection based EEG under varying cognitive tasks
using convolution neural network. <em>NCA</em>, <em>37</em>(7),
5381–5395. (<a
href="https://doi.org/10.1007/s00521-024-10737-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {One tool for promoting mental health is human stress detection through multitasks of electroencephalography (EEG) recordings. This study proposed a short-term stress detection approach using VGGish as a feature extraction and convolution neural network (CNN) as a classifier based on EEG signals from the SAM 40 dataset. This database was recently available and was collected from 40 patients using 32 channels to identify performance on four tasks including Stroop color-word test (SCWT), answering arithmetic problems, finding mirror-identical images, and relaxing. Each task took 25 s to complete and was then repeated three times to record three trials. This means that the total EEG data contain 480 signals for four tasks recorded using 120 trials per task. The primary objective of this research was to track the amount of short-term stress that patients experienced while they engaged in the four mental tasks. Moreover, the VGGish-CNN model is applied to the SAM 40 dataset using five stages including signal preprocessing, segmentation, filtration, spectrogram, and classification process. We compared the VGGish-CNN model and the VGGish model for stress-based EEG classification to determine the best classification accuracy. The proposed approach for stress detection is the preliminary study that achieved an accuracy of 99.25% using the VGGish-CNN model on the SAM 40 dataset. Next, k-fold cross validation is performed to verify the efficiency of the VGGish-CNN model. This study can advance the application of brain–computer interface (BCI) and its use to identify patterns in EEG data that invoke stress-related inferences to aid in the diagnosis of mental disorders. In the future, investigation of human stress using EEG data will be useful in neurorehabilitation.},
  archive      = {J_NCA},
  author       = {Afify, Heba M. and Mohammed, Kamel K. and Hassanien, Aboul Ella},
  doi          = {10.1007/s00521-024-10737-7},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5381-5395},
  shortjournal = {Neural Comput. Appl.},
  title        = {Stress detection based EEG under varying cognitive tasks using convolution neural network},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust pointer meter reading method for inspection robots
in real industrial scenarios. <em>NCA</em>, <em>37</em>(7), 5369–5379.
(<a href="https://doi.org/10.1007/s00521-024-10682-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In real industrial scenarios, inspection robots can replace humans to automatically read pointer meters, which greatly improves productivity and safety. However, existing automatic reading methods perform poorly in complex robot operating environments. To this end, we propose an automatic reading method for pointer meters, which can be better applied to inspection robot working conditions. Firstly, we propose a meter detection network, Yolo_Meter, which combines an attention mechanism and an adaptive feature fusion module. This network can accurately locate the meter from the perspective of robots and crop out images that are suitable for automatic meter readings. Secondly, we propose an oriented pointer detection network (OPDNet) to fit the tip position of the pointer precisely. Thirdly, we design a deep neural network OCR_Meter to obtain the scale and unit information of the meter by text detection and a filtering algorithm, which is adaptable to multiple types of meters. Finally, we propose a polar pixel method for locating the main scale lines and design the local angle method to calculate the readings of the pointer meters. Adequate experiments demonstrate the high accuracy and robustness of our method in real-world scenarios, with an average global error of only 0.73%.},
  archive      = {J_NCA},
  author       = {Huang, Zhiqing and Wang, Yuchao and Zhang, Yanxin and Zhang, Chenguang},
  doi          = {10.1007/s00521-024-10682-5},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5369-5379},
  shortjournal = {Neural Comput. Appl.},
  title        = {A robust pointer meter reading method for inspection robots in real industrial scenarios},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel approach to predict the traffic accident assistance
based on deep learning. <em>NCA</em>, <em>37</em>(7), 5343–5368. (<a
href="https://doi.org/10.1007/s00521-024-10939-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {According to the World Health Organization, thousands of people die every year in road traffic accidents. A crucial problem is the prediction of medical assistance in these accidents. For this purpose, we propose a new deep learning model whose goal is to distinguish whether a traffic accident requires medical assistance. The proposed perspective is general, so the model is valid for any dataset from any city. For this purpose, we present a model divided into three differentiated stages. In the first pre-processing stage, a general data treatment is performed, from data collection and cleaning to balancing. Secondly, the post-processing stage employs genetic and boosting algorithms to obtain the importance of all the data set variables used in the prediction. In the last stage, Model Training, a new model based on two-dimensional convolutional neural networks is applied to obtain a prediction of the need for medical assistance in traffic accidents. Finally, we test the effectiveness and accuracy of the proposed model by applying it to traffic accident datasets in six different cities. The obtained experimental results show that our framework achieves higher accuracy in all cities compared to six state-of-the-art models, confirming its suitability and applicability, even in real time.},
  archive      = {J_NCA},
  author       = {Vicent, José F. and Curado, Manuel and Oliver, José L. and Pérez-Sala, Luis},
  doi          = {10.1007/s00521-024-10939-z},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5343-5368},
  shortjournal = {Neural Comput. Appl.},
  title        = {A novel approach to predict the traffic accident assistance based on deep learning},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Numerical prediction of ureter stone size using an
integrated CFD-ML approach. <em>NCA</em>, <em>37</em>(7), 5325–5341. (<a
href="https://doi.org/10.1007/s00521-024-10880-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Ureteral flow parameters provide significant details about its physical attributes. Ureter is a single transport medium for urine transmission from kidney to ureter and its health is very important for a healthy human body. Understanding the fluid flow behavior can contribute toward the ureter health monitoring including estimation of any kind of blockage in the flow. Using ANSYS Fluent, Computational Fluid Dynamics (CFD) analysis and the grid independence study are carried out through iterative simulation process to achieve the solution independence. The CFD modeling provides tools and techniques to observe varying fluid parameters such as pressure, velocity and effect of the flow on smooth walls. Fluid Structure Interaction (FSI), an effective technique to analyze the effects of such flows on the ureter walls is also employed. Although the exact modeling of the ureter wall is not possible due to its complex physical parameters, some of its available physiological properties can be used to visualize the model of the ureter numerically. The present study is intended to predict the ureter stone size by using the FSI analysis. The simulations are carried out by increasing the stone size gradually from 1.7 to 3.4 mm and the input flow parameters are compared with the output flow parameters within the same solution setup and boundary conditions via artificial neural network in MATLAB. The output results obtained from the FSI simulations are then utilized to generate a prediction model for the ureter stone size. It is observed that the increasing stone size has a significant effect on the ureter wall, causing high stress regions in the point of interaction. The findings also revealed that the predicted size of the ureter stone is the closest to the actual size and with the least mean squared error at 80 optimal neurons.},
  archive      = {J_NCA},
  author       = {Ashraf, Muhammad Mubashar and Kamal, Khurram and Fahad, Muhammad and Noor, N. F. M. and Ratlamwala, Tahir Abdul Hussain},
  doi          = {10.1007/s00521-024-10880-1},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5325-5341},
  shortjournal = {Neural Comput. Appl.},
  title        = {Numerical prediction of ureter stone size using an integrated CFD-ML approach},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Single-pass end-to-end neural decompilation using copying
mechanism. <em>NCA</em>, <em>37</em>(7), 5309–5323. (<a
href="https://doi.org/10.1007/s00521-024-10735-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traditional decompilers utilize countless hardcoded rules written by subject matter experts, making them inflexible. Some recent systems address this using deep learning. The current consensus is that these systems have to include considerable domain knowledge and iterative heuristic components to solve parts of the decompilation problem, particularly the problem of predicting identifiers and literals. In this paper, we present a single-pass end-to-end neural decompilation system that utilizes copying mechanism. The copying mechanism is able to copy the literals and (offsets of) variables directly from the assembly code, in a single step, as part of the single forward pass through the model. Additionally, we take a further step toward decompiling real-world code by addressing important programming constructs like switch statements, function definitions, and function calls. We compile a dataset of real-world programming competition code and evaluate our model on it. The method achieves a program accuracy of 73% on the hardest complexity level of our generated dataset and 51% on the real-world examples without any additional error correction (EC) techniques, which surpasses the results of previous works without EC.},
  archive      = {J_NCA},
  author       = {Szalay, Gergő and Poór, Máté Bálint and Pintér, Balázs and Gregorics, Tibor},
  doi          = {10.1007/s00521-024-10735-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5309-5323},
  shortjournal = {Neural Comput. Appl.},
  title        = {Single-pass end-to-end neural decompilation using copying mechanism},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Driving behaviors analysis for public transport drivers in
kuwait: A machine learning approach to drivers safety. <em>NCA</em>,
<em>37</em>(7), 5289–5307. (<a
href="https://doi.org/10.1007/s00521-024-10964-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This research paper addresses the critical concern of evaluating driving behaviors among bus drivers in Kuwait to enhance road safety and prevent accidents. Real driving data from 73 bus drivers working in Kuwait Public Transport Company (KPTC), collected through Teltonika devices, forms the basis of the quantitative analysis. The OPTICS (Ordering Points to Identify the Clustering Structure) algorithm and Expectation–Maximization (EM) clustering were employed using Gaussian Mixture Models (EM-GMM) to classify drivers into distinct behavioral categories. Correlation analyses were then conducted to pinpoint factors influencing risky driving. It was revealed that over speeding is the predominant contributor, accounting for 84.89% of unsafe behaviors. Predictive modeling is undertaken using Gradient Boosted Trees (GBT) and discriminant analysis, with GBT emerging as the most effective, achieving the highest accuracy. Risk indices for each driver cluster are calculated, showing that 28% of drivers exhibit unsafe practices. The probability of accidents for drivers with hazardous tendencies was determined to be 0.772, while the general likelihood of accidents among bus drivers in Kuwait is calculated at 0.318. Surprisingly, no significant correlation is found between age and driving behavior, highlighting the influence of factors such as psychological conditions, fatigue, weather, and road conditions on driving conduct. The findings contribute valuable insights for developing targeted interventions to mitigate risky driving behaviors and enhance overall road safety in the region.},
  archive      = {J_NCA},
  author       = {AlKheder, Sharaf and Al-Saleh, Hanaa},
  doi          = {10.1007/s00521-024-10964-y},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5289-5307},
  shortjournal = {Neural Comput. Appl.},
  title        = {Driving behaviors analysis for public transport drivers in kuwait: A machine learning approach to drivers safety},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Chicken moth flame optimization and region-based convolution
neural network for water quality prediction. <em>NCA</em>,
<em>37</em>(7), 5271–5288. (<a
href="https://doi.org/10.1007/s00521-024-10878-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Water is an important source for the sustenance of life, and its quality has a direct impact on the environment and public health. Water is utilized for various practices, such as agriculture, industry, and drinking. Geo-environmental pollution caused by various types of waste such as municipal, industrial, medical, solid, and agricultural fields makes the water unsuitable for usage. Water quality is primarily impacted by the discharge of agricultural and industrial effluents into the environment, which disrupts biological systems. Predicting water quality is crucial for environmental monitoring, ecosystem sustainability, and aquaculture. Accurate water quality prediction is essential for sustainable water management. Hence, the quality of the water should be maximized by managing water resources. In this research, an optimization-enabled deep learning model named chicken moth flame–region-based convolution neural network (CMF-RCNN) is introduced to predict water quality. Here, hidden properties of water are analyzed and utilized to predict the water quality characteristics. Moreover, input data are normalized using Z-score normalization and optimal features are selected via correlation analysis. Later, the water quality is predicted from the selected features using RCNN. The prediction performance of RCNN is enhanced by fine-tuning its weights by utilizing CMF. Moreover, the performance of CMF-RCNN is analyzed with respect to existing water quality prediction models, and the CMF-RCNN attained superior performance with precision of 0.927, recall of 0.946, and F1-score of 0.936, respectively.},
  archive      = {J_NCA},
  author       = {Jose, D. Justin and Sulochana, C. Helen},
  doi          = {10.1007/s00521-024-10878-9},
  journal      = {Neural Computing and Applications},
  month        = {3},
  number       = {7},
  pages        = {5271-5288},
  shortjournal = {Neural Comput. Appl.},
  title        = {Chicken moth flame optimization and region-based convolution neural network for water quality prediction},
  volume       = {37},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
