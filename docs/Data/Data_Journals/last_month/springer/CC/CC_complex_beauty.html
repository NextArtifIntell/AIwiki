<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>CC_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="cc---66">CC - 66</h2>
<ul>
<li><details>
<summary>
(2025). Cognitive-inspired spectral spatiotemporal analysis for
emotion recognition utilizing electroencephalography signals.
<em>CC</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s12559-024-10361-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The rapid advancement of computer technologies, along with the significant role of emotions in daily life, has driven interest in intelligent emotion recognition systems. Electroencephalography (EEG) serves as a prominent objective tool in affective computing. However, effectively integrating multichannel EEG spatial and temporal information remains a critical challenge. This study introduces a novel emotion recognition model grounded in cognitive and biological principles, emphasizing the importance of spatiotemporal dynamics in emotional processing. In this research, brain frequency bands were extracted through wavelet analysis, and the signals within predefined time windows were quantified. These features were then concatenated across distinct brain channels to create a comprehensive matrix representing spatiotemporal brain information. The matrix was characterized using both the summation of matrix cells and the highest singular value to optimize computational costs during classification. The resulting attributes were input into a classification module for emotion detection. Experimental results on the Database for Emotion Analysis using Physiological Signals (DEAP) achieved a maximum accuracy of 89.55%. This work introduces a novel approach to analyzing and classifying EEG signals elicited by various emotional stimuli, demonstrating that the proposed model is competitive with the state-of-the-art classification schemes, thereby paving the way for future development of a robust spatiotemporal-based EEG emotion recognition system.},
  archive      = {J_CC},
  author       = {Goshvarpour, Atefeh and Goshvarpour, Ateke},
  doi          = {10.1007/s12559-024-10361-6},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {Cognitive-inspired spectral spatiotemporal analysis for emotion recognition utilizing electroencephalography signals},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A levitated controlled attention for named entity
recognition. <em>CC</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s12559-024-10381-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Controlled attention is a mechanism developed in cognitive neuroscience. It has been successfully applied to support named entity recognition, where the start and end boundaries of a possible named entity are marked by two specific tokens to indicate its position in a sentence. Then, it is fed into a deep network for classification. The entity boundary markers enable a deep neural network to be aware of entity boundaries and build the contextual dependency of a sentence relevant to entity boundaries. The problem with this strategy is that every possible named entity must be evaluated independently. This leads to very high computational complexity and cannot construct the semantic dependency between different named entities. In this paper, a levitated controlled attention mechanism is presented for named entity recognition. In this method, all possible named entities are fed together into a deep network for one-pass classification, which can establish the semantic dependency between contextual features and possible named entities. In the experiments, the levitated controlled attention is evaluated on four public datasets. The results show that it not only considerably reduces the computational complexity but also improves the performance of named entity recognition.},
  archive      = {J_CC},
  author       = {Huang, Rong and Chen, Yanping and Huang, Ruizhang},
  doi          = {10.1007/s12559-024-10381-2},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {A levitated controlled attention for named entity recognition},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A graph neural network with spatial attention for emotion
analysis. <em>CC</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s12559-024-10358-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Emotion recognition plays a crucial role in the diagnosis and treatment of various mental disorders. Research studies revealed the close relationship between brain regions and their functional roles in emotions. Propose a learning method that extends graph neural networks and takes into account the spatial relationship between EEG channels and their contributions of different regions of the brain to human emotions. Our method uses the adjacency matrix to model the spatial topological relationships in multi-channel EEG signals and learns weights to adjust their contributions to the classification. Extensive evaluation is conducted using public data sets, including comparison studies with state-of-the-art methods and performance analysis. In our comparison studies, our method demonstrates superior performance in terms of average accuracy. It is demonstrated that the proposed method improves the accuracy of emotion recognition and analyzes the brain at a fine granularity to decide the part that is most related to the triggering of the emotion.},
  archive      = {J_CC},
  author       = {Chen, Tian and Li, Lubao and Yuan, Xiaohui},
  doi          = {10.1007/s12559-024-10358-1},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {A graph neural network with spatial attention for emotion analysis},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Combining interpretable embedded multicriteria feature
cross-selection engineering and machine learning to mimic the brain for
stock trading signal prediction. <em>CC</em>, <em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s12559-024-10365-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Stock trading signal prediction is very important for investors’ trading decisions. However, since the stock market is a complex and nonlinear system, stock trading is frequent and complex. Human beings cannot integrate all the relevant information in time and make the right decisions by their brains alone. Machine learning can mimic the brain, learn from experience, and discover the connection between different things, thus realizing correct prediction and decision-making. Therefore, this study innovatively proposes a fusion of interpretable embedded multicriteria feature cross-selection engineering to capture effective features. Meanwhile, an optimized neural network prediction model is proposed where the Bayesian (BO) algorithm assumes the task of searching for hyperparameter combinations. The methods are as follow: (1) Daily stock prices are categorized into four types of key points for stock trading signals based on the time series extreme point algorithm. (2) A more comprehensive range of impact factors is constructed. Starting from the stock’s historical trading data, based on the stock’s trend, volatility, and turnover flow, five categories of technical indicators are constructed: Overlap Study, Momentum Indicator, Momentum Indicator, Volatility Indicator, and Price Conversion. (3) To construct a feature cross-selection method with multiple feature screening criteria to find the optimal feature influencing factors from different evaluation dimensions. (4) The hyper-parameters of the Artificial Neural Network (ANN) are optimized using Bayesian optimization algorithm. The optimized ANN is then used to model the data and obtain predictions. Twenty stocks were randomly selected from Shanghai Stock Exchange and Shenzhen Stock Exchange as experimental data to verify the validity of the model. The accuracy of the model proposed in this paper is 54.83%, 55.46%, and 54.70% for stocks with upward, steady, and downward trends respectively. The accuracy is on average 7.93%, 8.09%, and 8.09% higher than the comparison model. The return on investment through the predicted results of the model is 21.87%, 7.76%, and −3.51% respectively, which is better than the other comparative models. It can be seen from the experiments that the feature cross-selection method with multi-feature screening criterion can help the model to better find the optimal feature influencing factor, which helps to improve the accuracy of prediction. The Bayesian optimization algorithm contributes to the performance improvement of the ANN. After modeling the features using the Bayesian optimized ANN, the stock trading signal prediction model proposed in this paper is significantly better than other prediction models.},
  archive      = {J_CC},
  author       = {Wang, Jujie and Dong, Ying},
  doi          = {10.1007/s12559-024-10365-2},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Cogn. Comput.},
  title        = {Combining interpretable embedded multicriteria feature cross-selection engineering and machine learning to mimic the brain for stock trading signal prediction},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Density estimation-based stein variational gradient descent.
<em>CC</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s12559-024-10370-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Approximating a target distribution, such as a Bayesian posterior, is important in many areas, including cognitive computation. We introduce a variant of Stein variational gradient descent (SVGD) (Liu and Wang Adv Neural Inf Process Syst 29, 2016), called the density estimation-based Stein variational gradient descent (DESVGD). SVGD has proven to be promising as a sampling method for approximating target distributions. SVGD, however, suffers from discontinuity inherent in the empirical measure, making it difficult to closely monitor the convergence of the sampling-based approximation to the target. DESVGD utilizes kernel density estimation to replace the empirical measure in SVGD with its continuous counterpart. This allows direct computation of the KL divergence between the current approximation and the target distribution, thereby helping to monitor the numerical convergence of the iterative optimization process. DESVGD also offers derivatives of the KL divergence, which can be used to better design learning rates and thus to achieve faster convergence. By simply replacing the kernel used in SVGD with its weighted average, one can easily implement DESVGD based on existing SVGD algorithms. Our numerical experiments demonstrate that DESVGD approximates the target distribution well and outperforms the original SVGD in terms of approximation quality.},
  archive      = {J_CC},
  author       = {Kim, Jeongho and Lee, Byungjoon and Min, Chohong and Park, Jaewoo and Ryu, Keunkwan},
  doi          = {10.1007/s12559-024-10370-5},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {Density estimation-based stein variational gradient descent},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HC3: A three-way clustering method based on hierarchical
clustering. <em>CC</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s12559-024-10379-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Three-way decision is a field of research pertaining to human-inspired computation. Guided by the principle of three-way decision, three-way clustering addresses the information uncertainty problem by using the core region and the fringe region to characterize a cluster. The universe is split into three parts by these two regions, which capture three kinds of relationships between objects and a cluster, namely, belonging to, partially belonging to, and not belonging to. In recent years, there have been considerable three-way clustering algorithms. However, the generalization and scalability of current three-way cluster algorithms remain relatively weak, with most algorithms adhering to a fixed allocation strategy or fixed threshold parameters. In order to overcome this problem, this paper proposes a multilevel three-way clustering algorithm based on a hierarchical strategy (HC3 for short). The proposed algorithm uses kernel density estimation information of data to adaptively construct a multilevel structure of data, where the higher levels (or the internal layers) with the high-density objects are closer to core regions of clusters, and the lower levels (or the external layers) with the low-density objects are closer to fringe regions of clusters. Under the multilevel structure, we establish a three-way allocation strategy based on the stability of subclass clusters, obtaining the correct attribution of data after fully considering neighboring information. The experiments are conducted on 13 data sets with different dimensions. By comparing to other 8 clustering algorithms, the effectiveness of the proposed HC3 is verified through accuracy (ACC), adjusted Rand index (ARI), and adjusted mutual information (AMI).},
  archive      = {J_CC},
  author       = {Guan, Wenrui and Wang, Pingxin and Jiang, Wengang and Zhang, Ying},
  doi          = {10.1007/s12559-024-10379-w},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {HC3: A three-way clustering method based on hierarchical clustering},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-head attention and long short-term network for
enhanced inpainting of occluded handwriting. <em>CC</em>,
<em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s12559-024-10382-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the domain of handwritten character recognition, inpainting occluded offline characters is essential. Relying on the remarkable achievements of transformers in various tasks, we present a novel framework called “Enhanced Inpainting with Multi-head Attention and stacked long short-term memory (LSTM) Network” (E-Inpaint). This framework aims to restore occluded offline handwriting while capturing its online signal counterpart, enriched with dynamic characteristics. The proposed approach employs Convolutional Neural Network (CNN) and Multi-Layer Perceptron (MLP) in order to extract essential hidden features from the handwriting image. These features are then decoded by stacked LSTM with Multi-head Attention, achieving the inpainting process and generating the online signal corresponding to the uncorrupted version. To validate our work, we utilize the recognition system Beta-GRU on Latin, Indian, and Arabic On/Off dual datasets. The obtained results show the efficiency of using stacked-LSTM network with multi-head attention, enhancing the quality of the restored image and significantly improving the recognition rate using the innovative Beta-GRU system. Our research mainly highlights the potential of E-Inpaint in enhancing handwritten character recognition systems.},
  archive      = {J_CC},
  author       = {Rabhi, Besma and Elbaati, Abdelkarim and Hamdi, Yahia and Dhahri, Habib and Pal, Umapada and Chabchoub, Habib and Ouahada, Khmaies and Alimi, Adel M.},
  doi          = {10.1007/s12559-024-10382-1},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {A novel multi-head attention and long short-term network for enhanced inpainting of occluded handwriting},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A survey of artificial neural network computing systems.
<em>CC</em>, <em>17</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s12559-024-10383-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An artificial neural network (ANN) is currently used in multiple different applications such as bio-medicine, finance, Internet, and mobile networks. Since their inception, many advances have taken place introducing new models and features. Such progress resulted in different ANN models and most importantly different types of implementation, which vary from software (SW) to hardware (HW) following specific development principles. Researchers have been working significantly the last decade in this area tackling with different aspects of ANN’s implementations. In this survey, we present the progress of ANN in terms of implementation as part of computing platforms. Thus, we present the ANN-enabled computing platforms in terms of algorithmic models, computing architectures, and SW/HW implementations. This work concludes with open challenges and lessons learned in order to summarize what is potentially useful for further research in the area of ANN computing platforms with a wide spectrum of applications. An artificial neural network (ANN) is considered the key element of future computing systems applied to different domains. While the algorithmic design of an ANN is one of the major engineering elements, the implementation of ANN is equally important with many difficulties that should be overcome by future engineers. This survey aims to provide a comprehensive tutorial about the ANN-enabled computing systems, i.e., computing architectures with embedded artificial intelligence (AI). Starting with the ANN models and their applications, the survey provides a taxonomy of the types of ANN computing systems. Both SW and HW implementations are provided for each of those types, which highlight the key architectural elements as well as the performance of the ANN-enabled computing systems. Open challenges and lessons learned follow to provide a discussion for future research in the area of AI computing systems.},
  archive      = {J_CC},
  author       = {Foukalas, Fotis},
  doi          = {10.1007/s12559-024-10383-0},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Cogn. Comput.},
  title        = {A survey of artificial neural network computing systems},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-type image coding method acting on supervised
hierarchical deep spiking convolutional neural networks for image
classification. <em>CC</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s12559-024-10355-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Spiking neural networks (SNNs) have gained significant momentum in recent times as they transmit information via discrete spikes, similar to neuromorphic low-power systems. However, existing spike coding methods are often limited to a single scale of time or rate, and typically suffer from drawbacks such as reduced accuracy or long classification latency. In this paper, we propose a pixel-based multi-type image coding (PMIC) method inspired by the functional organization of primate visual systems to address the issues at hand. The encoded information comprises both spatial and temporal details, represented by spiking firing time and intensity, respectively. Subsequently, we combine the spiking firing time and intensity as inputs of a hierarchical spiking convolutional neural network (SCNN) including several convolutional and pooling layers. During the training phase, we use error backpropagation to optimize parameters. Comparison of experimental results with some state-of-the-art approaches on MNIST dataset, Fashion-MNIST dataset as well as ETH-80 dataset of image classification demonstrates that SCNN using PMIC can achieve the best test accuracy, which is 99.13%, 90.31%, and 94.29%, respectively. The proposed PMIC utilizes multiple filters and coding strategies to extract multi-type information and is more beneficial to the performance of SNNs compared to methods that extract single-scale or single-type information.},
  archive      = {J_CC},
  author       = {Liu, Fang and Xu, Jialin and Yang, Jie and Wu, Wei},
  doi          = {10.1007/s12559-024-10355-4},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {A novel multi-type image coding method acting on supervised hierarchical deep spiking convolutional neural networks for image classification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). CRCFusionAICADx: Integrative CNN-LSTM approach for accurate
colorectal cancer diagnosis in colonoscopy images. <em>CC</em>,
<em>17</em>(1), 1–37. (<a
href="https://doi.org/10.1007/s12559-024-10357-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Colorectal cancer (CRC) is a critical health issue worldwide and is very treatable if diagnosed on time. This paper proposes an innovative CADx system, namely CRCFusionAICADx, that enhances the efficiency of diagnosis by fusing CNNs with LSTM networks and feature integration techniques. Using data from the CKHK-22 colonoscopy image dataset, we preprocess the images into grayscale first and then apply LBP analysis for emphasizing textural features. These are further analyzed using three different pre-trained CNN models: VGG16, DenseNet-201, and ResNet50. These were chosen because of their complementary feature extraction capabilities. The resultant features from grayscale, LBP, and raw images will be fused to create an integrated dataset. To increase variability in the dataset and reduce overfitting for the network, we decided to apply a series of data augmentation techniques, which included zooming in, rotation, and horizontal flipping. By doing so, we expanded the dataset into 57,148 images. This augmented dataset is then used to train a model, RDV-22, which includes an integration of the architectures of VGG16, DenseNet-201, and ResNet50, with CNN and CNN + LSTM layers. The LSTM network learns the temporal dependencies of frames in a sequence and hence allows for more sensitive and specific detection of CRC. CRCFusionAICADx produces very impressive results, where the RDV-22 model produces a testing accuracy of 90.81%, precision of 91.00%, recall of 90.00%, and an F1 score of 90.49% in its results. This gives the model an ROC AUC of 0.98, reflecting very strong discriminatory power. This integrative approach thus shows tremendous promise for early CRC detection by offering a strong diagnostic tool that integrates both spatial and temporal features into a new standard in clinical diagnostics.},
  archive      = {J_CC},
  author       = {Raju, Akella S. Narasimha and Jayavel, Kayalvizhi and Rajalakshmi, Thulasi and Rajababu, M.},
  doi          = {10.1007/s12559-024-10357-2},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-37},
  shortjournal = {Cogn. Comput.},
  title        = {CRCFusionAICADx: Integrative CNN-LSTM approach for accurate colorectal cancer diagnosis in colonoscopy images},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Computer-aided diagnosis of graphomotor difficulties
utilizing direction-based fractional order derivatives. <em>CC</em>,
<em>17</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s12559-024-10360-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Children who do not sufficiently develop graphomotor skills essential for handwriting often develop graphomotor disabilities (GD), impacting the self-esteem and academic performance of the individual. Current examination methods of GD consist of scales and questionaries, which lack objectivity, rely on the perceptual abilities of the examiner, and may lead to inadequately targeted remediation. Nowadays, one way to address the factor of subjectivity is to incorporate supportive machine learning (ML) based assessment. However, even with the increasing popularity of decision-support systems facilitating the diagnosis and assessment of GD, this field still lacks an understanding of deficient kinematics concerning the direction of pen movement. This study aims to explore the impact of movement direction on the manifestations of graphomotor difficulties in school-aged. We introduced a new fractional-order derivative-based approach enabling quantification of kinematic aspects of handwriting concerning the direction of movement using polar plot representation. We validated the novel features in a barrage of machine learning scenarios, testing various training methods based on extreme gradient boosting trees (XGBboost), Bayesian, and random search hyperparameter tuning methods. Results show that our novel features outperformed the baseline and provided a balanced accuracy of 87 % (sensitivity = 82 %, specificity = 92 %), performing binary classification (children with/without graphomotor difficulties). The final model peaked when using only 43 out of 250 novel features, showing that XGBoost can benefit from feature selection methods. Proposed features provide additional information to an automated classifier with the potential of human interpretability thanks to the possibility of easy visualization using polar plots.},
  archive      = {J_CC},
  author       = {Gavenciak, Michal and Mucha, Jan and Mekyska, Jiri and Galaz, Zoltan and Zvoncakova, Katarina and Faundez-Zanuy, Marcos},
  doi          = {10.1007/s12559-024-10360-7},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Cogn. Comput.},
  title        = {Computer-aided diagnosis of graphomotor difficulties utilizing direction-based fractional order derivatives},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A fixed-time control algorithm for multiagent systems with
input delay via event-triggered strategy. <em>CC</em>, <em>17</em>(1),
1–12. (<a href="https://doi.org/10.1007/s12559-024-10366-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multiagent systems have become increasingly relevant in numerous fields due to their potential for cooperative control and distributed networks. Developing effective adaptive algorithms for these systems is crucial, as adaptive techniques can enhance the ability of multiple agents to collaboratively complete specific tasks. In this paper, we propose an event-triggered adaptive fixed-time containment algorithm for multiagent systems with input delay. Firstly, our methodology employs Fuzzy Logic Systems to approximate uncertain terms in system dynamics and addresses the algebraic loop problem inherent in non-strict feedback functions. Additionally, an integral term is introduced to mitigate the adverse effects of time delay on system performance. Under the fixed-time stability framework, the proposed algorithm achieves containment within an exact time constant, independent of initial conditions. Furthermore, a dynamic event-triggered mechanism is incorporated to optimize the number of triggers, thereby conserving communication resources. As a result, the designed control algorithm guarantees that the closed-loop systems signals meet the criteria for semi-global practical fixed-time stability, allowing the outputs of followers to converge to the convex hull of leaders within a finite time. Finally, the feasibility and effectiveness of the algorithm are demonstrated through simulations involving underwater vehicle systems.},
  archive      = {J_CC},
  author       = {Liu, Guijiang and Wang, Xin and Guang, Weiwei and Chen, Hongyu},
  doi          = {10.1007/s12559-024-10366-1},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {A fixed-time control algorithm for multiagent systems with input delay via event-triggered strategy},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A hybrid semantics and syntax-based graph convolutional
network for aspect-level sentiment classification. <em>CC</em>,
<em>17</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s12559-024-10367-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aspect-level sentiment classification seeks to ascertain the sentiment polarities of individual aspects within a sentence. Most existing research in this field focuses on individually assessing the importance of contexts on individual aspects, disregarding the negative impact of imbalanced relations between aspects due to their mutual influence. This paper presents a hybrid semantics and syntax-based graph convolutional network (SS-GCN) for aspect-level sentiment classification. This model addresses the imbalanced limitation by creating aspects-based balance relations between the strengths and weaknesses of different aspects through an auxiliary task. Furthermore, the multi-head self-attention mechanism utilizes position-enhanced encoding to identify the most relevant aspects of the current word. Extensive experiments demonstrate that SS-GCN outperforms other baselines in terms of classification performance. Compared to state-of-the-art methods, SS-GCN significantly improves 0.39–1.66% in accuracy and 0.43–1.92% in Macro-F1 on the SemEval 14-15 and MAMS datasets.},
  archive      = {J_CC},
  author       = {Huang, Chen and Li, Xianyong and Du, Yajun and Dong, Zhicheng and Huang, Dong and Kumar Jain, Deepak and Hussain, Amir},
  doi          = {10.1007/s12559-024-10367-0},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Cogn. Comput.},
  title        = {A hybrid semantics and syntax-based graph convolutional network for aspect-level sentiment classification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DmrNet: Dual-stream mutual information contraction and
re-discrimination network for semi-supervised temporal action detection.
<em>CC</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s12559-024-10374-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semi-supervised temporal action detection only requires a small number of labeled samples from the dataset and utilizes the remaining unlabeled samples for model training, effectively alleviating the significant time and manpower costs associated with annotating large-scale temporal action detection datasets. However, previous semi-supervised temporal action detection methods relied on sequential action localization and classification, which leads to erroneous localization predictions that can easily affect subsequent classification predictions, resulting in error propagation problem. To overcome error propagation, we propose a dual-stream mutual information contraction and re-discrimination network (DmrNet). Specifically, the traditional two-step strategy of temporal action detection has been changed to a four-step parallel strategy by us. Firstly, this paper designs the first-step classification prediction and the second-step localization prediction as a parallel structure to prevent error propagation from localization to classification. Then, in the third step, the dual-stream mutual information contraction part maps the dual-stream features to a new vector space to ensure the cross-correlation between classification and action localization. Finally, the fourth step of classification re-discrimination part captures the consistency information of the dual-stream structure to enhance internal representation. Compared with existing methods, DmrNet achieved an average accuracy improvement of 10.7% on ActivityNet v1.3 and 5.2% on THUMOS14 using only 10% annotation data. The experimental results show that the proposed DmrNet not only achieves good detection performance in semi-supervised learning but also achieves performance comparable to state-of-the-art methods in fully supervised learning.},
  archive      = {J_CC},
  author       = {Zhang, Qiming and Hu, Zhengping and Wang, Yulu and Bi, Shuai and Zhang, Hehao and Di, Jirui},
  doi          = {10.1007/s12559-024-10374-1},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {DmrNet: Dual-stream mutual information contraction and re-discrimination network for semi-supervised temporal action detection},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Event classification on subsea pipeline inspection data
using an ensemble of deep learning classifiers. <em>CC</em>,
<em>17</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s12559-024-10377-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Subsea pipelines are the backbone of the modern oil and gas industry, transporting a total of 28% of global oil production. Due to several factors, such as corrosion or deformations, the pipelines might degrade over time, which might lead to serious economic and environmental damages if not addressed promptly. Therefore, it is crucial to detect any serious damage to subsea pipelines before they cause dangerous catastrophes. Inspections of subsea pipelines are usually made using a Remote Operating Vehicle and the inspection data is usually processed manually, which is subject to human errors, and requires experienced Remote Operating Vehicle operators. It is thus necessary to automate the inspection process to enable more efficiency as well as reduce costs. Besides, it is recognised that specific challenges of noisy and low-quality inspection data arising from the underwater environment prevent the industry from taking full advantage of the recent development in the Artificial Intelligence field to the problem of subsea pipeline inspection. In this paper, we developed an ensemble of deep learning classifiers to further improve the performance of single deep learning models in classifying anomalous events on the subsea pipeline inspection data. The output of the proposed ensemble was combined based on a weighted combining method. The weights of base classifiers were found by minimising the difference between the weighted combining result and the given associated ground truth annotation information. Three inspection datasets, gathered from different oil and gas companies in the United Kingdom, were analysed. These datasets were recorded under varying conditions and include a range of anomalies. The results showed that the proposed ensemble achieves around 78% accuracy on two datasets and more than 99% accuracy on one dataset, which is better compared to base classifiers and two popular ensembles.},
  archive      = {J_CC},
  author       = {Dang, Truong and Nguyen, Tien Thanh and Liew, Alan Wee-Chung and Elyan, Eyad},
  doi          = {10.1007/s12559-024-10377-y},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Cogn. Comput.},
  title        = {Event classification on subsea pipeline inspection data using an ensemble of deep learning classifiers},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DisTrack: A new tool for semi-automatic misinformation
tracking in online social networks. <em>CC</em>, <em>17</em>(1), 1–18.
(<a href="https://doi.org/10.1007/s12559-024-10378-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article introduces DisTrack, a methodology and a tool developed for tracking and analyzing misinformation within online social networks (OSNs). DisTrack is designed to combat the spread of misinformation through a combination of natural language processing (NLP) social network analysis (SNA) and graph visualization. The primary goal is to detect misinformation, track its propagation, identify its sources, and assess the influence of various actors within the network. DisTrack’s architecture incorporates a variety of methodologies including keyword search, semantic similarity assessments, and graph generation techniques. These methods collectively facilitate the monitoring of misinformation, the categorization of content based on alignment with known false claims, and the visualization of dissemination cascades through detailed graphs. The tool is tailored to capture and analyze the dynamic nature of misinformation spread in digital environments. The effectiveness of DisTrack is demonstrated through three case studies focused on different themes: discredit/hate speech, anti-vaccine misinformation, and false narratives about the Russia-Ukraine conflict. These studies show DisTrack’s capabilities in distinguishing posts that propagate falsehoods from those that counteract them, and tracing the evolution of misinformation from its inception. The research confirms that DisTrack is a valuable tool in the field of misinformation analysis. It effectively distinguishes between different types of misinformation and traces their development over time. By providing a comprehensive approach to understanding and combating misinformation in digital spaces, DisTrack proves to be an essential asset for researchers and practitioners working to mitigate the impact of false information in online social environments.},
  archive      = {J_CC},
  author       = {Villar-Rodríguez, Guillermo and Huertas-García, Álvaro and Martín, Alejandro and Huertas-Tato, Javier and Camacho, David},
  doi          = {10.1007/s12559-024-10378-x},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {DisTrack: A new tool for semi-automatic misinformation tracking in online social networks},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Robust synchronization of stochastic markovian jumping CVNs
with randomly occurring nonlinearities and generally uncertain
transition rates. <em>CC</em>, <em>17</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s12559-024-10362-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This article intents to the robust synchronization issue for Markovian jumping complex-valued networks (CVNs) subject to the stochastic noises and randomly occurring nonlinearities, where the considered transition rates are generally uncertain, which expands the existed relevant results. Meanwhile, two random variables with pre-given statistical characteristics are proposed to explain the involved randomly occurring nonlinearities phenomenon, and random variables are mutually independent. By designing the appropriate mode-dependent controller, combined with generalized complex It $$\hat{o}$$ ’s formula, Lyapunov stability theory, and the properties of the transition rate matrix, some sufficient conditions are achieved to ensure error system realizes stochastically asymptotically mean-square stable. Furthermore, sufficient mode/delay-dependent criteria of globally exponential synchronization for considered CVNs are also investigated. In the end, two illustrative examples with simulations are proposed to verify the effectiveness and feasibility of the designed control schemes.},
  archive      = {J_CC},
  author       = {Li, Qiang and Wei, Hanqing and Hua, Dingli and Wang, Jinling and Zheng, Yuanshi},
  doi          = {10.1007/s12559-024-10362-5},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Cogn. Comput.},
  title        = {Robust synchronization of stochastic markovian jumping CVNs with randomly occurring nonlinearities and generally uncertain transition rates},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extensions and detailed analysis of synergy between
traditional classification and classification based on negative features
in deep convolutional neural networks. <em>CC</em>, <em>17</em>(1),
1–16. (<a href="https://doi.org/10.1007/s12559-024-10369-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent times, deep convolutional neural networks became an irreplaceable tool for pattern recognition in many different machine learning applications, especially in image classification. On the other hand, these models are often used in critical systems which are the reason for new and recent research regarding their robustness and reliability. One of the most important issues for these models is their susceptibility to different adversarial attacks. In our previous work Milošević and Racković (Neural Network World. 2019;29(4):221–34), and Milošević and Racković (Neural Comput Applic. 2021;33:7593–602), the new type of learning applicable to all the convolutional neural networks was introduced: the classification based on the negative features and the synergy of traditional and those newly introduced network models. In the case of partial inputs/image occlusion, it was shown that our new method creates models that are more robust and perform better when compared to traditional models of the same architecture. In this paper, some extensions of the earlier proposed synergy are given by introducing negatively trained features and additional synergy between four independent neural network models. A detailed analysis of the robustness of the newly proposed model is performed on EMNIST and CIFAR-10 image classification data sets in the case of the selected input occlusions and adversarial attacks. The newly proposed neural network architecture improves the robustness of the neural network and increases its resistance to various types of input damage and adversarial attacks.},
  archive      = {J_CC},
  author       = {Racković, Miloš and Vidaković, Jovana and Milošević, Nemanja},
  doi          = {10.1007/s12559-024-10369-y},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {Extensions and detailed analysis of synergy between traditional classification and classification based on negative features in deep convolutional neural networks},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EXplainable AI for word embeddings: A survey. <em>CC</em>,
<em>17</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s12559-024-10373-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, word embeddings have become integral to natural language processing (NLP), offering sophisticated machine understanding and manipulation of human language. Yet, the complexity of these models often obscures their inner workings, posing significant challenges in scenarios requiring transparency and explainability. This survey conducts a comprehensive review of eXplainable artificial intelligence (XAI) strategies focused on enhancing the interpretability of word embeddings. By classifying the existing body of work into six broad categories based on their methodological approaches—a classification that, to our knowledge, does not exist in the literature—we provide a structured overview of current techniques and their characteristics. Additionally, we uncover a noteworthy oversight: a predominant emphasis on interpreting model outputs at the expense of exploring the models’ internal mechanics. This finding underscores the necessity of shifting research efforts toward not only clarifying the results these models produce but also demystifying the models themselves. Such a shift is crucial for uncovering and addressing biases inherent in word embeddings, thus ensuring the development of fair and trustworthy AI systems. Through this analysis, we identify key research questions for future studies and advocate for a holistic approach to transparency in word embeddings, encouraging the research community to explore both the outcomes and the underlying algorithms of these models.},
  archive      = {J_CC},
  author       = {Boselli, Roberto and D’Amico, Simone and Nobani, Navid},
  doi          = {10.1007/s12559-024-10373-2},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Cogn. Comput.},
  title        = {EXplainable AI for word embeddings: A survey},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Artificial intelligence inspired task offloading and
resource orchestration in intelligent transportation systems.
<em>CC</em>, <em>17</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s12559-024-10380-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Internet of Vehicles (IoV) applications require the support of communication, caching, and computation (3C) resources to offload the computation-intensive tasks and for uplifting the traffic conditions in the development of sustainable smart cities. Intelligent Transportation Systems (ITS) lack the integrated ecosystems of addressing the low-latency task handovers, resource management issues, and centralized incentivization strategies. Digital Twin (DT) aids in capturing the real-time varying resource needs of the vehicles and the communication infrastructure that will regulate the task offloading process and facilitates in incentivizing the vehicular instances. In this manuscript, we establish a digital twin counterpart ( $$DT_{PIoV}$$ ) of the physical IoV (PIoV) to meet the QoS requirements during dynamic offloading and the time-varying resource supply–demand of computationally intensive applications. We formulate a response delay minimization function which is solved by the proposed DT-driven context-aware dynamic offloading method (CADOM). Furthermore, we use M/M/1/N/FCFS queueing method that combats the drawbacks of handling the simultaneous deadline-based tasks in a volatile environment of PIoV. In addition, we also maximize the utilities of vehicle and RSU service satisfaction by employing a reward-based mechanism for on-demand allocation of resources based on the Stackelberg game, where the DT of vehicle is deemed as a leader and service provider RSUs as a follower. The simulation results establish that the proposed system outpaces the conventional traffic management system by emphasizing the role of $$DT_{PIoV}$$ in jointly optimizing the overall response latency for different task sizes and also ensure a better utility satisfaction by catering on-demand resource allocation.},
  archive      = {J_CC},
  author       = {Rawlley, Oshin and Gupta, Shashank and Chandrakar, Jyotsana and Johnson, Manisha K. and Kalra, Chahat},
  doi          = {10.1007/s12559-024-10380-3},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Cogn. Comput.},
  title        = {Artificial intelligence inspired task offloading and resource orchestration in intelligent transportation systems},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fine-tuned BERT algorithm-based automatic query expansion
for enhancing document retrieval system. <em>CC</em>, <em>17</em>(1),
1–16. (<a href="https://doi.org/10.1007/s12559-024-10354-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Online retrieval systems are mostly web-based, which makes document collecting more dynamic or fluid than in traditional information retrieval systems. With the web growing in size every day, finding meaningful information on it using a search query consisting of only a few keywords which has become increasingly difficult. One important factor in making Internet searches better is query expansion, or QE. Manual query expansion method involves the user adding terms to the query, which takes a long time but produces good results. However, the automatic query expansion (AQE) method determines the best statements with minimal time consumption. Therefore, to improve document retrieval system, a fine-tuned BERT algorithm is developed for automatic query expansion. Initially, the input text was augmented using embedding augmentation (EA) approach. The augmented text was pre-processed using tokenization, normalization, splitting, stemming, stop word removal, as well as lemmatization. Then extracting the technical keywords from the pre-processed text using co-occurrence statistical information. After extracting the keywords, a fine-tuned BERT model is utilized for expanding the query to improve document retrieval system. The hyper parameters present in the BERT was tuned using frilled lizard optimization to enhance the performance of the BERT model. Proposed model provides 92% accuracy, 95% precision, and 95.6% recall. Thus, a fine-tuned BERT model minimizing query-document mismatch and thereby improving retrieval performance.},
  archive      = {J_CC},
  author       = {Vishwakarma, Deepak and Kumar, Suresh},
  doi          = {10.1007/s12559-024-10354-5},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {Fine-tuned BERT algorithm-based automatic query expansion for enhancing document retrieval system},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic neighborhood selection for context aware temporal
evolution using graph neural networks. <em>CC</em>, <em>17</em>(1),
1–19. (<a href="https://doi.org/10.1007/s12559-024-10359-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Graph neural networks (GNN) have seen significant growth recently for modeling temporal evolution in dynamic networks. Representation of complex networks in the form of graph data structures has enabled researchers to study how entities within these networks interact with each other. These interactions evolve over time. Developing a generic methodology for modeling this temporal evolution in complex networks for tracking evolving relationships has been a significant challenge. Most of the existing methods fail to extract contextual representations of historical neighborhood interactions for future link prediction. To address these challenges, this paper presents a novel method for modeling temporal evolution in complex networks using GNNs. A Context-Aware Graph Temporal Neural Network (CATGNN) method that uses dynamic neighborhood selection based on common neighbors for a given node is presented. The method uses dynamic neighborhood selection using contextual embeddings extracted from the historical interactions of the down-sampled set of neighbors of a central node based on a common neighborhood. Fixed-sized contextual memory modules are constructed for each node that store the historical interactions of its neighbors and are updated based on the recency and significance of interactions. The proposed method has been evaluated using six real-world datasets and has comparable performance against state-of-the-art methods, both in terms of accuracy and efficiency. It shows an improvement of 7.52 to 0.05% over the baselines in terms of average precision. The results demonstrate that the proposed CATGNN model can capture complex patterns of change that are difficult to identify using traditional techniques by propagating information over the graph structure. The model can be applied in various fields involving complex systems.},
  archive      = {J_CC},
  author       = {Zeb, Muhammad Ali and Uddin, M. Irfan and Alarood, Ala Abdulsalam and Shafiq, Muhammad and Habibullah, Safa and Alsulami, Abdulkream A.},
  doi          = {10.1007/s12559-024-10359-0},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Cogn. Comput.},
  title        = {Dynamic neighborhood selection for context aware temporal evolution using graph neural networks},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). NeuroInteract: An innovative deep learning strategy for
effective drug repositioning in schizophrenia therapy. <em>CC</em>,
<em>17</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s12559-024-10384-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Schizophrenia (SCZ) is a serious physiological and neurological disorder that affects an individual’s perception of factuality. It expresses different symptoms such as thinking, aberrant behavior, delusions, and hallucinations. An efficient approach for inferring potential indications for drugs is through drug repositioning. In this context, drug repositioning imparts a valuable strategy to gain safer, faster, and potentially efficient treatment options to improve schizophrenia therapy. Current treatments are insufficient and existing drug repositioning methods are unsuccessful in solving the drug-disease interactions’ difficulties, including long-term efficacy, drug synergy, and capturing genetic variations. Also, existing methods are restrained because of the incapacity to efficiently integrate heterogeneous biomedical data, which results in suboptimal predictions. This research introduces a NeuroInteract model using deep learning in order to predict candidate drugs for SCZ therapy. The proposed model enhances the accuracy of drug repositioning through the collection of various data sources such as genetic information and drug-disease associations. The novelty of the proposed model is the utilization of the heterogeneous data network that is integrated with the progressive optimization model for the purpose of improving prediction accuracy. The developed method imparts effective learning from various data characteristics through the integration of various types of neural network layers such as fully connected layers, convolutional layers, recurrent layers, and graph convolutional layers. The collected data from DrugBank 5.0 and repoDB undergoes a process of data integration, which aids in generating precise predictions for candidate drugs for repositioning. A data pre-processing technique is employed to improve the data quality. After data pre-processing, the proposed method effectively extracts the meaningful features and finds the spatial dependencies to predict the potential candidate drugs for SCZ treatment. Also, it efficiently handles sequential dependencies and genetic information. The oppositional crossover boosted meerkat optimization (OCMO) algorithm is deployed to optimize the performance of the model. The OCMO optimizes the learning process and enhances the model accuracy by dynamically adjusting its search strategy. Ultimately, comprehensive experimental analyses are conducted using several estimation parameters. The proposed method gains greater effectiveness and outperforms existing methods in drug repositioning. The developed method reaches an accuracy of 98.84% and a hit rate of 98.76%. These experimental findings ascertain the ability of NeuroInteract to find promising drugs for repurposing, furnishing a robust and more cost-effective model for SCZ treatment.},
  archive      = {J_CC},
  author       = {J., Sherine Glory and P., Durgadevi and P., Ezhumalai},
  doi          = {10.1007/s12559-024-10384-z},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Cogn. Comput.},
  title        = {NeuroInteract: An innovative deep learning strategy for effective drug repositioning in schizophrenia therapy},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel interpretable graph convolutional neural network for
multimodal brain tumor segmentation. <em>CC</em>, <em>17</em>(1), 1–25.
(<a href="https://doi.org/10.1007/s12559-024-10387-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep convolutional neural networks (CNNs) have revolutionized computer vision, demonstrating remarkable performance in various tasks. However, their end-to-end learning strategy poses challenges to explainability. In this work, we explore the application of explainability techniques in brain tumor segmentation using magnetic resonance imaging (MRI) data. Our adaptive learning class activation map (AL-CAM) employs a unique multiple-pop-out training strategy and contrastive learning to enhance internal outputs, improving interpretability. Additionally, we introduce a novel approach to explainability in graph convolutional neural networks (GCNNs). The usage of traditional CNN interpretability tools such as saliency maps, CAM, and EB are often unable to handle the complexity of graph-structured data. Our work brim this gap by adapting and improving these techniques for graph convolutional neural networks (GCNN). We present two innovative tools: adaptive CAM for differentiated interpretability and contrastive EB for deeper insights into functions. Using a novel feature fusion approach, we further push the boundaries and combine the feature strengths of GNN and CNN for a holistic understanding of GCNN decision-making. Our proposed framework enables interpretability in various areas, not just medical imaging. Our work demonstrates the versatility of explainability methods and demonstrates their power in unlocking the secrets of GCNNs and ultimately solving real-world challenges, particularly in the field of medical image analysis.},
  archive      = {J_CC},
  author       = {Arshad Choudhry, Imran and Iqbal, Saeed and Alhussein, Musaed and Aurangzeb, Khursheed and Qureshi, Adnan N. and Hussain, Amir},
  doi          = {10.1007/s12559-024-10387-w},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Cogn. Comput.},
  title        = {A novel interpretable graph convolutional neural network for multimodal brain tumor segmentation},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive decision-making system for behavior analysis
among young adults. <em>CC</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s12559-024-10372-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The global spread of the pandemic, secure isolation regulations, logistical limitations, and delays in reopening educational institutions such as colleges and universities have all had a severe psychological impact. Students, in particular, are regarded as a vulnerable population, experiencing higher levels of fear, stress, depression, and unhealthy eating compared to the general population. To reduce these psychological consequences, the study provides a multi-dimensional evaluation approach to bridge the gap between governments and health institutions in preventing and controlling biological hazards, such as mental illness among students. In the aftermath of the pandemic, this study presents a comprehensive evaluation approach designed to mitigate the psychological impact on students by connecting governments and health institutions in preventing and controlling biological hazards, particularly mental illness. To establish complex and vague data concerning the discussed communities, psychological details were obtained in the complex spherical fuzzy $$ \mathscr {N}$$ -soft context. An enhanced group decision-making methodology was then established in two phases. Initially, weight analytics were defined using the Reyni entropy technique. In the subsequent phase, the Combined Compromise Solution (CoCoSo) approach was applied to examine the possibilities. Students attending schools and colleges experience significant psychological impacts. To evaluate these effects, an analytical study was conducted, suggesting that improved educational amenities are necessary to mitigate these psychological consequences. Furthermore, the study validates the significance of the proposed decision system through its analysis. A unique score function is suggested for analyzing the psychological consequences among adults because it effectively addresses the ambiguity in periodic data, resulting in accurate and consistent judgments within a two-dimensional framework. Experts thoroughly analyzed the data using the complex spherical fuzzy $$ \mathscr {N}$$ -soft set-integrated CoCoSo method, and its limitations were also addressed.},
  archive      = {J_CC},
  author       = {Pragathi, Subramaniam and Narayanamoorthy, Samayan and Pamucar, Dragan and Kang, Daekook},
  doi          = {10.1007/s12559-024-10372-3},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {An adaptive decision-making system for behavior analysis among young adults},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Enhanced self-attention-based rapid CNN for detecting dense
objects in varying illumination. <em>CC</em>, <em>17</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s12559-024-10376-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper addresses the challenge of efficient detection of densely arranged unordered items under varying illumination. Specifically, a novel convolutional neural network-based method is proposed for item vector detection, recognition, and classification, termed Self-Attention and Concatenation-Based Detector (ACDet). In a benchmark pharmaceutical case study, rapid and accurate detection of pharmaceutical package contours is achieved, enabling the automatic and fast verification of both the quantity and types of pharmaceuticals during distribution. At the input stage, a combined image augmentation method is applied to improve the detection model’s ability to learn the appearance features of items from multiple angles. Based on YOLOv8 model, integrating computational module C2F with Attention (C2F-A), multidimensional self-attention reinforcement is applied to the outputs of multiple gradient streams. The designed Weighted Concatenation (WConcat) module self-learns to weight and concatenate multi-level feature maps, enhancing the model’s cognitive capability. Finally, simulation experiments are conducted to determine the optimal timing for utilizing each module. Simulation experiments compared the proposed ACDet with several state-of-the-art YOLO architecture models utilizing the benchmark Comprehensive Pharmaceutical Package Dataset (CPPD). ACDet achieved 81.0% mAP and 79.5% Smooth mAP on the CPPD dataset, outperforming other models by an average of 5.5% to 16.6%. On public datasets, the results were 52.2% and 51.0%, respectively. The impact of utilizing C2F-A at different stages on performance was also tested, concluding that the WConcat module does not necessitate spatial attention. Finally, in zero-shot testing, the verification success rate reached 99.91%. Our work shows that the proposed ACDet can overcome many challenges in complex object detection scenarios, enhancing robustness while maintaining a lightweight design. The proposed model can serve as a new benchmark.},
  archive      = {J_CC},
  author       = {Chen, Lu and Yang, Li and Jie, Tan and Haoyuan, Ma and Yu, Liu and Shenbing, Fu and Wang, Junkang and Wu, Hao and Li, Gun},
  doi          = {10.1007/s12559-024-10376-z},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Cogn. Comput.},
  title        = {Enhanced self-attention-based rapid CNN for detecting dense objects in varying illumination},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Evolutionary multitasking with adaptive tradeoff selection
strategy. <em>CC</em>, <em>17</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s12559-024-10386-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As a new emerging evolutionary framework, evolutionary multitasking aims to optimize multiple tasks simultaneously. Knowledge transfer is an important component of evolutionary multitasking. How to extract and transfer knowledge significantly affects the performance of the algorithm. A serious challenge for evolutionary multitasking is the inappropriate knowledge transfer or insufficient exploration and exploitation. To address this challenge, an evolutionary multitasking with adaptive tradeoff selection strategy (EMT-ATS) is proposed. To enhance global exploration and local exploitation during the evolution, an adaptive tradeoff selection mechanism is developed to select promising offspring during different stages to guide the population toward more promising solution regions. In addition, a Cohen’s d indicator-based is used to adjust knowledge transfer. To verify the effectiveness of the proposed EMT-ATS, a series of experiments are conducted with several popular evolutionary multitasking algorithms on multitasking benchmark problems. In addition, a multitask optimization problem involving two real-world problems is used to validate the practicability of the proposed EMT-ATS. Experimental results demonstrate the effectiveness of the proposed EMT-ATS.},
  archive      = {J_CC},
  author       = {Li, Wei and Zhou, Yinhui and Wang, Lei},
  doi          = {10.1007/s12559-024-10386-x},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Cogn. Comput.},
  title        = {Evolutionary multitasking with adaptive tradeoff selection strategy},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive unsupervised graph convolution network for data
clustering with graph reconstruction. <em>CC</em>, <em>17</em>(1), 1–14.
(<a href="https://doi.org/10.1007/s12559-024-10364-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, graph clustering has emerged as one of the most challenging problems in the field of deep learning. With the increasing complexity of real-world networks, such as social and biological networks, more and more effective methods are needed to organize and understand these structures. Various cognition-based techniques have been explored for classifying nodes within these graphs, and graph convolution networks (GCNs) have attracted great interest. GCNs, a deep semi-supervised learning approach, provide a powerful framework for learning node representations by utilizing both local and global graph information. By iteratively aggregating information from neighboring nodes, GCNs effectively capture the intricate relationships and dependencies within complex networks. We introduce a novel deep unsupervised learning scheme built upon the foundation of GCN architecture. The key contributions are outlined below. First, the entire architecture is trained with three unsupervised learning losses. The first loss focuses on kernelized features that use node attributes to reflect the information extracted from the data. The second loss leverages spectral smoothness that uses connections between nodes to capture global cluster structure. The third loss is based on graph reconstruction that introduces additional regularization of the representation of nodes by the output of the model. Second, the spectral smoothing loss involves an adaptive approach using an additional graph matrix associated with the node representations. This adaptive integration of additional structural information increases the learning efficiency during the training phase. The adaptive fused graph used for spectral smoothing loss incorporates structural insights derived from both data features and deep node representations. To assess the performance of our approach, we conducted extensive experimental evaluations on four benchmark datasets widely used in the field of graph clustering. These datasets were carefully selected to cover diverse domains and varying degrees of complexity, ensuring a comprehensive evaluation of our method’s efficacy. Our results showcase the remarkable performance of our unsupervised GCN across multiple metrics, surpassing other state-of-the-art graph neural network techniques in terms of clustering accuracy, purity, and other relevant measures. Notably, our method consistently outperforms competing approaches across the used datasets, demonstrating its versatility and effectiveness in handling various real-world scenarios.},
  archive      = {J_CC},
  author       = {Jreidy, M. Al and Constantin, J. and Dornaika, F. and Hamad, D.},
  doi          = {10.1007/s12559-024-10364-3},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {Adaptive unsupervised graph convolution network for data clustering with graph reconstruction},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Disturbance observer-based control: Weighted aggregated
aczel-alsina sum product assessment based on power operators for
managing fuzzy 2-tuple linguistic neural networks. <em>CC</em>,
<em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s12559-024-10371-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Disturbance observer–based control (DOBC) is a valuable strategy for enhancing control system performance by compensating for disturbances. The core idea is to design an observer that accurately estimates external disturbances affecting the system, and then use this estimation to adjust the control input accordingly. This article introduces a novel approach involving fuzzy 2-tuple linguistic (F2-TL) sets, incorporating algebraic and Aczel-Alsina operational laws. Additionally, we propose several operators: the F2-TL Aczel-Alsina power averaging (F2-TLAAPA) operator, the F2-TL Aczel-Alsina power weighted averaging (F2-TLAAPWA) operator, the F2-TL Aczel-Alsina power geometric (F2-TLAAPG) operator, and the F2-TL Aczel-Alsina power weighted geometric (F2-TLAAPWG) operator. These operators are used to aggregate information into a singleton set, and we discuss their fundamental properties, including idempotency, monotonicity, and boundedness. Moreover, we explain the WASPAS (weighted aggregated sum product assessment) technique, applying the proposed methods and illustrating them with relevant examples. The article also explores the application of these techniques to multi-attribute decision-making (MADM) problems, demonstrating their value. Finally, to validate the introduced methods and highlight the superiority of the proposed approach, we compare the ranking results obtained using our methods with those from existing techniques.},
  archive      = {J_CC},
  author       = {Ali, Zeeshan and Hila, Kostaq},
  doi          = {10.1007/s12559-024-10371-4},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {Disturbance observer-based control: Weighted aggregated aczel-alsina sum product assessment based on power operators for managing fuzzy 2-tuple linguistic neural networks},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-view hierarchical graph neural network for
argumentation mining. <em>CC</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s12559-024-10391-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Argumentation mining (AM) aims to detect the arguments and their relations from argumentative texts. Generally, AM contains three key challenging subtasks, including argument component type classification (ACTC), argumentative relation identification (ARI), and argumentative relation type classification (ARTC). Most previous studies solve these three subtasks separately, neglecting the rich interrelation information among the three tasks. In this paper, we propose a multi-view hierarchical graph neural network (MHGNN) for AM, which resolves the three interacted subtasks in a unified multi-task learning framework. Concretely, MHGNN learns graph embeddings from multiple views (i.e., word view and semantic view) that often provide more comprehensive information. Each graph view is equipped with a two-level graph structure: (i) the first level is the argumentation graph with each argumentation component (AC) as a graph node, which learns the inter-AC knowledge from the input text; (ii) the second level is the AC graph with each word or semantic role as graph node respectively, which learn the fine-grained intra-AC knowledge within each AC from the word level or semantic level. The multi-view hierarchical GNN makes our model more effective to utilize the rich information among and within the ACs in the input text. Then, we transform ACTC, ARI, and ARTC into node classification, edge prediction, and edge type classification on the argumentation graph by devising novel graph attention mechanisms to learn comprehensive and relation-aware graph embeddings. These three subtasks are integrated into a unified model through multi-task learning and partial parameters sharing. Extensive experiments on two benchmark datasets demonstrate that the proposed MHGNN framework outperforms the strong baseline methods for all three subtasks.},
  archive      = {J_CC},
  author       = {Sun, Yang and Bao, Jianzhu and Tu, Geng and Liang, Bin and Yang, Min and Xu, Ruifeng},
  doi          = {10.1007/s12559-024-10391-0},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {Multi-view hierarchical graph neural network for argumentation mining},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). On the integration of large-scale time series distance
matrices into deep visual analytic tools. <em>CC</em>, <em>17</em>(1),
1–18. (<a href="https://doi.org/10.1007/s12559-024-10394-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Time series are essential for modeling a lot of activities such as software behavior, heart rate, and business processes. The analysis of the series data can prevent errors, boost profits, and improve the understanding of behaviors. Among the many techniques available, we can find deep learning techniques and data mining techniques. In data mining, distance matrices between subsequences (similarity matrices, recurrence plots) have already shown their potential in fast large-scale time series behavior analysis. In deep learning, there exist different tools for analyzing the models’ embedding space to get insights into the data behavior. DeepVATS is a tool for large time series analysis that allows the visual interaction within the embedding space (latent space) of deep learning models and the original data. The training and analysis of the model may result in a large use of computational resources, resulting in a lack of interactivity. To solve this issue, we integrate distance matrix plots within the tool. The incorporation of these plots with the associated downsampling techniques makes DeepVATS a more efficient and user-friendly tool for a first quick analysis of the data, achieving runtimes reductions of up to $$10^4$$ seconds, allowing fast preliminary analysis of datasets of up to 7 M elements. Also, this incorporation allows us to detect trends, extending its capabilities. The new functionality is tested in three use cases: the M-Toy synthetic dataset for anomaly detection, the S3 synthetic dataset for trend detection, and the real-world dataset pulsus paradoxus for anomaly checking.},
  archive      = {J_CC},
  author       = {Santamaria-Valenzuela, Inmaculada and Rodriguez-Fernandez, Victor and Camacho, David},
  doi          = {10.1007/s12559-024-10394-x},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {On the integration of large-scale time series distance matrices into deep visual analytic tools},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fuzzy soft topological numbers with an operation of vertex
deletion: A comparative study with TOPSIS method and its application in
car import decision-making. <em>CC</em>, <em>17</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s12559-024-10396-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {There are two distinct soft computing models for representing ambiguity and uncertainty: fuzzy and soft sets. A novel mathematical technique for handling uncertainties is the soft set. This set offers a parameterized viewpoint for soft computing and uncertainty modeling. Soft sets have been shown to have potential uses in a number of disciplines, including probability theory, operations research, game theory, measurement theory, and the smoothness of functions. Topological numbers possess significant importance in graph theory. On topological numbers in fuzzy graph theory, there is also a wealth of literature. However, there has not been much research done on fuzzy soft topological numbers up until now. Fuzzy soft graphs are very versatile instruments available for decision-making. Therefore, in fuzzy soft graph theory, it would be very beneficial to introduce and apply topological numbers. Multi-criteria decision-making approaches give decision-makers the required instruments, but their underlying theories and assumptions may differ. Therefore, choosing the best way to make decisions is just as crucial as actually making the decision. The technique for order preference by similarity to ideal solution (TOPSIS) is the most widely used multi-criteria decision-making method. TOPSIS can solve the real-world problems. TOPSIS is a technique for ranking, based on the weights and impacts of the given elements. However, prior to this study, no work has been done on the application of fuzzy soft topological numbers in decision-making systems. The novelty of this research manuscript is to calculate three fuzzy soft topological numbers before and after the deletion of the vertex for a generalized graph and in a fuzzy soft framework and make a comparison in the results obtained before and after deleting the vertex. Subsequently, we demonstrated an application of international automobile importation into the United States by several nations using various graphical networks, employing a parameterized fuzzy soft graph point of view and three different modes of transportation. It is established that if a vertex is removed from a network, the profit made will decrease significantly. Additionally, the optimal network of nations for all purposes is evaluated. By using the TOPSIS approach, the ranking of networks is also generated from a set of alternatives.},
  archive      = {J_CC},
  author       = {Anwar, Shabana and Kamran Jamil, Muhammad and Azeem, Muhammad and Deveci, Muhammet and Antucheviciene, Jurgita},
  doi          = {10.1007/s12559-024-10396-9},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Cogn. Comput.},
  title        = {Fuzzy soft topological numbers with an operation of vertex deletion: A comparative study with TOPSIS method and its application in car import decision-making},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Neural adaptive dynamic event-triggered containment control
for uncertain multi-agent systems under markovian switching dynamics.
<em>CC</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s12559-024-10388-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, we propose the containment control problem for multi-agent systems with Markovian switching dynamics by proposing a novel adaptive dynamic event-triggered sliding mode control scheme based on radial basis function neural networks. First, the unknown nonlinear dynamics of the system were approximated by using radial basis function neural networks. The dynamic event-triggered control scheme designed in the framework of sliding mode control operated at specific event sampling moments, thereby reducing computational and communication burdens. The containment control was achieved through a synergistic approach integrating dynamic event-triggered control with neural network-based adaptive control in a stochastic switching system. Moreover, we proved that Zeno behavior was effectively avoided. The proposed distributed containment control technique was validated through simulations, demonstrating its effectiveness and superiority.},
  archive      = {J_CC},
  author       = {Cai, Jiayi and Wu, Wenjun and Yi, Chengbo and Chen, Yanxian},
  doi          = {10.1007/s12559-024-10388-9},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {Neural adaptive dynamic event-triggered containment control for uncertain multi-agent systems under markovian switching dynamics},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Convolutional cross-modal autoencoder-based few-shot
learning for data augmentation with application to alzheimer dementia
diagnosis. <em>CC</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s12559-024-10390-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a novel deep few-shot learning method for magnetic resonance images-based Alzheimer’s dementia (AD) diagnosis. The proposed method consists of two main phases namely data augmentation and data classification. With regard to data augmentation and, to deal with data scarcity issues, we designed a convolutional cross-modal autoencoder (CCMAE) model for data generation. This model, which consists of two encoders and one decoder, receives two image modalities namely longitudinal and cross-section MRI, and generates a new cross-section image. We opt for a convolutional version of the autoencoder to capture the spatial information more effectively and reduce the number of trainable parameters. Moreover, to make the model able to perform deep analysis of input image, we establish a skip connection strategy between the first encoder and the decoder similar to the UNet mechanism. With regard to classification, we design a convolutional neural network-based model in which both textual and visual features are fused to strengthen the network performance and produce more reliable decisions. A comprehensive experiment on a publicly available dataset has been conducted to demonstrate the effectiveness of the proposed method compared to some related works. The code is publicly available at: https://github.com/Bazine-Othmane/scientific-paper-code .},
  archive      = {J_CC},
  author       = {Bazine, Othmane and Rai, Omar and Aiadi, Oussama and Hedjam, Rachid and Khaldi, Belal and Zhong, Guoqiang},
  doi          = {10.1007/s12559-024-10390-1},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {Convolutional cross-modal autoencoder-based few-shot learning for data augmentation with application to alzheimer dementia diagnosis},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A comparative analysis of metaphorical cognition in ChatGPT
and human minds. <em>CC</em>, <em>17</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s12559-024-10393-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {ChatGPT represents a significant advancement in the field of Artificial Intelligence (AI), showcasing the development of a robust AI system capable of multitasking and generating human-like language. At present, many scholars have done evaluations on ChatGPT in terms of language, reasoning, and scientific knowledge abilities, based on benchmarks or well-crafted questions. However, to the best of our knowledge, there is currently no existing comparative analysis from a cognitive perspective that directly assesses ChatGPT alongside humans. Metaphor, serving as a manifestation of linguistic creativity, provides a valuable avenue for examining cognition. This is due to the mapping relationship it establishes between the target and source conceptual domains, reflecting distinct cognitive patterns. In this paper, we use a metaphor processing tool, MetaPro, to analyze the cognitive differences between ChatGPT and humans through the metaphorical expressions in ChatGPT- and human-generated text. We illustrate the preferences in metaphor usage, concept mapping, and cognitive pattern variances across different domains. The methodology utilized in this study makes a valuable contribution to the task-agnostic evaluation of AI systems and cognitive research. The insights garnered from this research prove instrumental in comprehending the cognitive distinctions between ChatGPT and humans, facilitating the identification of potential cognitive biases within ChatGPT.},
  archive      = {J_CC},
  author       = {Mao, Rui and Chen, Guanyi and Li, Xiao and Ge, Mengshi and Cambria, Erik},
  doi          = {10.1007/s12559-024-10393-y},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {A comparative analysis of metaphorical cognition in ChatGPT and human minds},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel depth-connected region-based convolutional neural
network for small defect detection in additive manufacturing.
<em>CC</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s12559-024-10397-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Defect detection on the computed tomography (CT) images plays an important role in the development of metallic additive manufacturing (AM). Although some deep learning techniques have been adopted in the CT image-based defect detection problem, it is still a challenging task to accurately detect small-size defects in the presence of undesirable noises. In this paper, a novel defect detection method, namely, the depth-connected region-based convolutional neural network (DC-RCNN), is proposed to detect small defects and reduce the influence of noises. In particular, a saliency-guided region proposal method is first developed to generate small-size region proposals with the aim to accommodate the small defects. Then, the main architecture of DC-RCNN is proposed to extract and connect the consistent features across multiple frames, thereby reducing the influence of randomly distributed noises. Moreover, the transfer learning technique is utilized to improve the generalization ability of the proposed DC-RCNN. In order to verify the effectiveness and superiority, the proposed method is applied to the real-world AM data for defect detection. The experimental validations show that the proposed DC-RCNN is able to detect the small-size defects under noises and outperforms the original RCNN method in terms of detection accuracy and running time.},
  archive      = {J_CC},
  author       = {Wang, Yiming and Wang, Zidong and Liu, Weibo and Zeng, Nianyin and Lauria, Stanislao and Prieto, Camilo and Sikström, Fredrik and Yu, Hui and Liu, Xiaohui},
  doi          = {10.1007/s12559-024-10397-8},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {A novel depth-connected region-based convolutional neural network for small defect detection in additive manufacturing},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Interval-valued intuitionistic fuzzy yager power operators
and possibility degree-based group decision-making model. <em>CC</em>,
<em>17</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s12559-024-10368-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {As an extended form of intuitionistic fuzzy set, the theory of interval-valued intuitionistic fuzzy set (IVIFS) can describe fuzziness more flexibly. This study aims to develop a group decision-making model based on the distance measure, Yager power aggregation operators and the possibility measure in the context of IVIFSs. For this purpose, new distance measure is proposed to quantify the dissimilarity between two IVIFSs. In addition, comparison with existing distance measures is performed to illustrate the efficiency of introduced measure. Combining the Yager’s triangular norms with the proposed distance-based power operators, a series of interval-valued intuitionistic fuzzy (IVIF) Yager power aggregation operators are introduced with their desirable properties. Moreover, a possibility measure is developed for pairwise comparisons of IVIFSs, which overcomes the shortcomings of existing IVIF-score function, IVIF-accuracy function, and IVIF-possibility measures. The developed possibility measure is further utilized to compute the weights of criteria. To prove the practicality and effectiveness of introduced model, it is applied to a case study of manufacturing plant location selection problem with IVIF information. Finally, sensitivity and comparative analyses are carried out to test the stability and robustness of the proposed method under the setting of IVIFSs.},
  archive      = {J_CC},
  author       = {Rani, Pratibha and Mishra, Arunodaya Raj and Deveci, Muhammet and Alrasheedi, Adel Fahad and Alshamrani, Ahmad M. and Pedrycz, Witold},
  doi          = {10.1007/s12559-024-10368-z},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Cogn. Comput.},
  title        = {Interval-valued intuitionistic fuzzy yager power operators and possibility degree-based group decision-making model},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unified multi-view data clustering: Simultaneous learning of
consensus coefficient matrix and similarity graph. <em>CC</em>,
<em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s12559-024-10392-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Integrating data from multiple sources or views has become increasingly common in data analysis, particularly in fields like healthcare, finance, and social sciences. However, clustering such multi-view data poses unique challenges due to the heterogeneity and complexity of the data sources. Traditional clustering methods are often unable to effectively leverage the information from different views, leading to suboptimal clustering results. To address this challenge, multi-view clustering techniques have been developed, aiming to integrate information from multiple views to improve clustering performance. These techniques typically involve learning a similarity matrix for each view and then combining these matrices to form a consensus similarity matrix, which is subsequently used for clustering. However, existing approaches often suffer from limitations such as the need for manual tuning of parameters and the inability to effectively capture the underlying structure of the data. In this paper, we propose a novel approach for multi-view clustering that addresses these limitations by jointly learning the consensus coefficient matrix and similarity graph. Unlike existing methods that follow a sequential approach of first learning the coefficient matrix and then constructing the similarity graph, our approach simultaneously learns both matrices, ensuring a more regularized consensus graph. Additionally, our method automatically adjusts the weight of each view, eliminating the need for manual parameter tuning. Our approach involves several key steps. First, we formulate an optimization problem that jointly optimizes the consensus coefficient matrix, unified spectral projection matrix, coefficient matrix, and soft cluster assignment matrix. We then propose an efficient algorithm to solve this optimization problem, which involves iteratively updating the matrices until convergence. To learn the consensus coefficient matrix and similarity graph, we leverage techniques from matrix factorization and graph-based learning. Specifically, we use a self-representation technique to learn the coefficient matrix (regularization graPh) and a graph regularization technique to learn the similarity graph. By jointly optimizing these matrices, we ensure that the resulting consensus graph is more regularized and better captures the underlying structure of the data. We evaluate our approach on several public image datasets, comparing it against state-of-the-art multi-view clustering methods. Our experimental results demonstrate that our approach consistently outperforms existing methods in terms of clustering accuracy and robustness. Additionally, we conduct sensitivity analysis to evaluate the impact of different hyperparameters on the clustering performance. We present a novel approach for multi-view data clustering that jointly learns the consensus coefficient matrix and similarity graph. By simultaneously optimizing these matrices, our approach achieves better clustering performance compared to existing methods. Our results demonstrate the effectiveness and robustness of our approach across different datasets, highlighting its potential for real-world applications in various domains.},
  archive      = {J_CC},
  author       = {Dornaika, F. and El Hajjar, S. and Charafeddine, J. and Barrena, N.},
  doi          = {10.1007/s12559-024-10392-z},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {Unified multi-view data clustering: Simultaneous learning of consensus coefficient matrix and similarity graph},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Optimizing social issues strategies by using bipolar complex
fuzzy muirhead mean decision-making approach. <em>CC</em>,
<em>17</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s12559-024-10353-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive processes that affect people perceptions, comprehension, and interactions with others, such as attribution mistakes and heuristics, are responsible for social issues. These social issues includes polarization, prejudice, and inequality. To address these issues, we must comprehend cognitive mechanisms, and this can be made by using some appropriate multi-attribute decision-making (MADM) approach, that can handle people perceptions of complex and bipolar nature. Thus, in this manuscript, we concentrate on a MADM technique that relies on certain novel aggregation operators in the framework of bipolar complex fuzzy sets. These aggregation operators include Muirhead mean (MM) operator and dual Muirhead mean (DMM) operator of several types. To authenticate the validity of these defined aggregation operators, certain properties of these operators are proved. Furthermore, we consider the interpreted operators to produce a decision-making (DM) technique to deal with bipolar complex fuzzy MADM issues. We then consider a real life example to show the application and need of the interpreted work in daily life. To confirm the viability and potential of the offered technique, we compare our established technique with some other prevailing techniques.},
  archive      = {J_CC},
  author       = {Rehman, Ubaid ur and Mahmood, Tahir and García, Gustavo Santos},
  doi          = {10.1007/s12559-024-10353-6},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Cogn. Comput.},
  title        = {Optimizing social issues strategies by using bipolar complex fuzzy muirhead mean decision-making approach},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A weakly supervised data labeling framework for machine
lexical normalization in vietnamese social media. <em>CC</em>,
<em>17</em>(1), 1–32. (<a
href="https://doi.org/10.1007/s12559-024-10356-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This study introduces an innovative automatic labeling framework to address the challenges of lexical normalization in social media texts for low-resource languages like Vietnamese. Social media data is rich and diverse, but the evolving and varied language used in these contexts makes manual labeling labor-intensive and expensive. To tackle these issues, we propose a framework that integrates semi-supervised learning with weak supervision techniques. This approach enhances the quality of the training dataset and expands its size while minimizing manual labeling efforts. Our framework automatically labels raw data, converting non-standard vocabulary into standardized forms, thereby improving the accuracy and consistency of the training data. Experimental results demonstrate the effectiveness of our weak supervision framework in normalizing Vietnamese text, especially when utilizing pre-trained language models. The proposed framework achieves an impressive F1-score of 82.72% and maintains vocabulary integrity with an accuracy of up to 99.22%. Additionally, it effectively handles undiacritized text under various conditions. This framework significantly enhances natural language normalization quality and improves the accuracy of various NLP tasks, leading to an average accuracy increase of 1–3%.},
  archive      = {J_CC},
  author       = {Nguyen, Dung Ha and Nguyen, Anh Thi Hoang and Van Nguyen, Kiet},
  doi          = {10.1007/s12559-024-10356-3},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-32},
  shortjournal = {Cogn. Comput.},
  title        = {A weakly supervised data labeling framework for machine lexical normalization in vietnamese social media},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). BrainEnsemble: A brain-inspired effective ensemble pruning
algorithm for pattern classification. <em>CC</em>, <em>17</em>(1), 1–21.
(<a href="https://doi.org/10.1007/s12559-024-10363-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The human brain comprises distinct regions, each with specific functions. Interconnected through neural pathways, the brain regions collaborate to process complex information. Similarly, ensemble learning enhances pattern classification by leveraging the collaboration and complementarity between classifiers. The similarity between the two suggests that simulating the brain’s functional network holds the potential for groundbreaking advancements in the design of ensemble learning algorithms. Motivated by this, our paper proposes a brain-inspired ensemble pruning method called BrainEnsemble. This method provides an example of using classifier combinations to emulate the functions of brain regions. Guided by the principles of curriculum learning and the divide-and-conquer strategy, each artificial brain region can specialize in specific functions and tasks. Additionally, BrainEnsemble simulates the brain regions’ responses and connectivity mechanisms through graph connections. In this model, different artificial brain regions can dynamically reorganize and adjust their interactions to adapt to continuously changing environments or data distributions, enabling the model to maintain high performance when confronted with new data. Extensive experimental results demonstrate the superior performance of BrainEnsemble. In summary, drawing inspiration from the information processing mechanism of the human brain can provide new ideas for the design of ensemble learning algorithms, and more research can be conducted in this direction in the future.},
  archive      = {J_CC},
  author       = {Li, Danyang and Huang, Shisong and Wen, Guihua and Zhang, Zhuhong},
  doi          = {10.1007/s12559-024-10363-4},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Cogn. Comput.},
  title        = {BrainEnsemble: A brain-inspired effective ensemble pruning algorithm for pattern classification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting deep contrast feature for image retrieval.
<em>CC</em>, <em>17</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s12559-024-10375-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In the field of content-based image retrieval (CBIR), fused feature-based methods have demonstrated their advanced performance on the popular benchmark datasets. However, it is inevitable increase the vector dimensionality because the fused features have diversity. Therefore, achieving both a low-dimensional representation and high retrieval performance remains challenging. To address this problem, an image retrieval method based on the deep contrast-based layer is proposed, namely the deep contrast feature histogram (DCFH), to image retrieval. There are three highlights as follows: (1) texture features based on the edge orientation are calculated to build contrast-based layer; it can enhance the discriminative power of deep features; (2) a generalized mean aggregation method is introduced to effectively aggregate the representative information in the deep feature maps of convolutional neural network (CNN); (3) a multi-orientational PCA whitening method is proposed to provide a compact yet discriminative representation. Comparative experiments demonstrated that our method can provide outstandingly competitive retrieval performance on popular benchmark datasets. This work captures visual information from both global and local perspectives, presenting an approach in line with human visual cognitive. Experiments demonstrated that our method can efficiently combine the strengths of various features to provide the robust representation, thereby improving the retrieval performance. Moreover, our method is easily to be implemented without requiring to retrain the CNN models and not the use of additional supervision.},
  archive      = {J_CC},
  author       = {Lu, Zhou and Liu, Guang-Hai and Li, Zuoyong and Yang, Lu},
  doi          = {10.1007/s12559-024-10375-0},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Cogn. Comput.},
  title        = {Exploiting deep contrast feature for image retrieval},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Development of a decision support system for performance
measurement of social movements. <em>CC</em>, <em>17</em>(1), 1–27. (<a
href="https://doi.org/10.1007/s12559-024-10385-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Social movements encompass the collective actions of groups gathered under the same goal, operating within a specific organizational structure to reflect their thoughts and views through a series of actions. Social movements are expected to exhibit characteristics of violence, rationality, continuity, and public benefit. The successful performance of social movements is contingent upon their ability to embody these characteristics. The primary motivation of this research is to render the performance of social movements measurable and comparable, aiming to determine their effectiveness. The underlying motivation for this approach is to move beyond subjective evaluations of social movements and instead treat them as structured decision-making processes. The core objective is to develop a decision support system for assessing the performance of social movements and facilitating insights into the performance of movements within a country or region. In this way, the performance evaluation processes of social movements are enhanced, fostering the development of more informed and deliberate social movements. To determine the performance of social movements, the type-2 neutrosophic number (T2NN)–Schweizer Sklar (SS)–symmetry point of criterion (SPC)–evaluation based on relative utility and nonlinear standardization (ERUNS)–(T2NN-SS-SPC-ERUNS) hybrid model is developed and proposed in this research. The T2NN-SS-weighted arithmetic mean aggregation operator is used to combine expert evaluations. The weights of criteria are calculated using the T2NN-SPC method. Performance rankings of social movements are determined using the T2NN-ERUNS method. An algorithm for the three-stage T2NN-SS-SPC-ERUNS hybrid model is developed to evaluate the performance of social movements in Türkiye through a case study. The robustness and consistency of the proposed hybrid method are supported by scenarios. As a result of the research, the “Early Retirement Scheme Victims” social movement is identified as having the highest performance among social movements in Türkiye.},
  archive      = {J_CC},
  author       = {Yalçın, Galip Cihan and Kara, Karahan and Işık, Gülcan and Simic, Vladimir and Pamucar, Dragan},
  doi          = {10.1007/s12559-024-10385-y},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-27},
  shortjournal = {Cogn. Comput.},
  title        = {Development of a decision support system for performance measurement of social movements},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). I2V-CMGAN: Generative adversarial cross-modal network-based
image-to-video person re-identification. <em>CC</em>, <em>17</em>(1),
1–22. (<a href="https://doi.org/10.1007/s12559-024-10389-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Information asymmetry situation amongst image and video features in image-to-video (I2V) person re-identification (Re-ID) refers to the difficulty in extracting consistent and dependable features from both image and video data in order to accurately match and identify a person in both modalities. The problem arises because images and videos have different characteristics and represent different aspects of a person. This difference in representation can result in inconsistent and unreliable features being extracted from image and video data, leading to difficulty in accurately matching and re-identifying a person between modalities. The temporal information provided by videos can also boost the accuracy of person re-identification, especially in crowded and cluttered environments. To address the information asymmetry problem, a generative adversarial cross-modal network–based I2V Person Re-ID (I2V-CMGAN) is proposed, which works by using a generator to transform the features learned from the video network into an image network with an additional loss function to improve the consistency and reliability of features extracted from both image and video data and also preserve identity information. Extensive studies show the efficacy of the proposed approach, and the aggregate results on the MARS dataset outperform the state-of-the-art methods by a substantial margin and achieved rank-1 accuracy of 88.9% (+ 2.9), rank-5 accuracy of 95.5% (+ 2.3), rank-10 accuracy of 97.1% (+ 2.9), and mean average precision of 81.2% (+ 1.1) for I2V Re-ID. On iLIDS-VID and PRID2011 datasets, the proposed method attains outstanding margins with rank-1, rank-5, rank-10, mAP of 64.7%, 89.3%, 92.7%, 74.2%, and 80.9%, 93.3%, 98.9%, and 86.8% respectively.},
  archive      = {J_CC},
  author       = {Joshi, Aditya and Diwakar, Manoj},
  doi          = {10.1007/s12559-024-10389-8},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Cogn. Comput.},
  title        = {I2V-CMGAN: Generative adversarial cross-modal network-based image-to-video person re-identification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Systematic review and thematic analysis of digital games for
cognitive enhancement in children with autism spectrum disorder: Toward
a conceptual framework. <em>CC</em>, <em>17</em>(1), 1–38. (<a
href="https://doi.org/10.1007/s12559-024-10395-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Compared to typically developing people, children with autism spectrum disorder (ASD) have distinct cognitive and intelligence profiles. Some of these children require cognitive rehabilitation. Through the use of cutting-edge therapy and cognitive empowerment methods, some cognitive skills in children with ASD can be strengthened by digital game-based tools. This study’s main purpose is to provide a systematic review and qualitative study about designing digital games for cognitive enhancement in autistic children and to determine the main design components of such digital games. The primary focus of this study is to explore the citations in which the technical and functional elements are provided thoroughly. Furthermore, a conceptual framework is elaborated for designing a digital game for autism. A thorough review of the literature was conducted in the databases of Medline (via PubMed), Web of Science (WOS), Scopus, and IEEE Xplore for English publications published before January 23, 2023. Of 976 papers, 34 studies were found to be eligible in this systematic review. The bulk of the studies were carried out in Asia and Europe. Three (8.8%) studies used games that were built to be multilingual, while 22 (64.7%) studies used games that were only created in English. Creating motivation through narratives, providing incentive systems, raising the complexity level, targeting main skills, and adjusting the choices are the principal components of digital game design. (1) Main cognitive rehabilitation domains in ASD; (2) game designing details: platforms and game genres, motivations, evaluations, game graphics designs, aesthetic mechanisms, incentive systems, and famous game development engines; and (3) mutual interaction between child, therapist, and parents are the crucial categories that are described to devise a conceptual framework in this qualitative study. Of the total number of included studies, 25 studies reported positive effects on autism cases, and in nine, there has not been any evaluation of real cases; however, only usability tests have been conducted. Children with autism may benefit from using appropriate digital game-based interventions to improve mental indices. According to a review, it can be stated that the suitable computerized and digital game-based solutions could enhance cognitive outcomes in children with autism spectrum disorder. However, more research is required to ascertain the true efficacy of these new technologies.},
  archive      = {J_CC},
  author       = {Rezayi, Sorayya and Shahmoradi, Leila and Tehrani-Doost, Mehdi},
  doi          = {10.1007/s12559-024-10395-w},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-38},
  shortjournal = {Cogn. Comput.},
  title        = {Systematic review and thematic analysis of digital games for cognitive enhancement in children with autism spectrum disorder: Toward a conceptual framework},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A non-invasive approach for early alzheimer’s detection
through spontaneous speech analysis using deep visibility graphs.
<em>CC</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s12559-024-10398-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Identifying Alzheimer’s disease (AD) in its early stages is a challenging task for physicians and clinicians. This paper proposes a new algorithm for diagnosing AD, which is based on analyzing spontaneous speech signals. The proposed method uses two visibility graph methods, Natural Visibility Graph (NVG) and Horizontal Visibility Graph (HVG), to derive features from speech windows. These features are then given to a deep BiLSTM-based classifier to decide about segments of the signal. The proposed approach could obtain a sensitivity of 98.33%, specificity of 99.44%, and accuracy of 99.17%. The advantage of converting speech signals into graphs using NVG and HVG is that it allows for the extraction of complex structural features that are not easily captured by traditional methods. This method is highly beneficial due to its non-invasive nature, low cost, and lack of side effects. Patients can undergo the procedure without experiencing any discomfort, while also benefiting from its affordability and accessibility. The method’s safety and practicality make it an ideal choice for those seeking a reliable and effective solution. Moreover, the proposed algorithm has a high accuracy in detecting the early stage of AD, which makes it a promising tool to evaluate Alzheimer’s disease diagnosis in its pre-clinical stage.},
  archive      = {J_CC},
  author       = {Mohammadpoory, Zeynab and Nasrolahzadeh, Mahda and Amiri, Sekineh Asadi and Haddadnia, Javad},
  doi          = {10.1007/s12559-024-10398-7},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {A non-invasive approach for early alzheimer’s detection through spontaneous speech analysis using deep visibility graphs},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Short-term power load forecasting in city based on
ISSA-BiTCN-LSTM. <em>CC</em>, <em>17</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s12559-024-10401-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate short-term power load forecasting is crucial for the stable operation of power systems. In this paper, we propose an advanced forecasting model that combines the Salp Swarm Algorithm (SSA), Bidirectional Temporal Convolutional Network (BiTCN), and Long Short-Term Memory (LSTM). The model first exploits the parallel fusion of BiTCN and LSTM (BiTCN-LSTM), taking full advantage of BiTCN’s strength in parallel processing of local features and the LSTM’s ability to capture long-term dependencies through its gating mechanisms. Subsequently, the Improved Salp Swarm Algorithm (ISSA) is enhanced through adaptive leader ratio adjustment, dual-food design, and food lure follower strategy. Finally, the hyperparameters of the BiTCN-LSTM model are optimized using ISSA to improve the model performance. In the short-term load forecasting experiments, electric load data and weather data from Los Angeles, Tetouan, and Johor were used to compare the proposed model with eight existing models. The evaluation metrics included root mean square error (RMSE), mean absolute error (MAE), normalized root mean square error (NRMSE), and mean absolute percentage error (MAPE). The experimental results showed that the model achieved lower error values than the comparison model in most cases in different seasons, working days, and rest days in different cities. In particular, the error values of RMSE, MAE, NRMSE, and MAPE were 925.11 kW, 732.63 kW, 0.019, and 1.034% for the rest days in the city of Tetouan, respectively. Compared with other algorithms, ISSA demonstrates stronger optimization capability and shorter optimization time. Additionally, model structure analysis was conducted through optimization comparison and ablation experiments, further demonstrating the proposed model’s strong predictive performance.},
  archive      = {J_CC},
  author       = {Fan, Chaodong and Li, Gongrong and Xiao, Leyi and Yi, Lingzhi and Nie, Shanghao},
  doi          = {10.1007/s12559-024-10401-1},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Cogn. Comput.},
  title        = {Short-term power load forecasting in city based on ISSA-BiTCN-LSTM},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Application of metaheuristic algorithms with supervised
machine learning for accurate power consumption prediction. <em>CC</em>,
<em>17</em>(1), 1–35. (<a
href="https://doi.org/10.1007/s12559-025-10402-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate power consumption prediction is a crucial part of energy management. Some of the machine learning models that are the focus of this study for the prediction of power use include Support Vector Regression, Adaptive Boosting, and Decision Tree Regression. These models have been improved with the use of some novel optimizers-namely, the Trochoid Search Optimization, Red-Tailed Hawk, and Giant Armadillo Optimization methods-for hyper-parameter tuning to enhance prediction accuracy. When tested against real data, DTGA outperformed with R2 values of 0.9918, 0.9924, and 0.9934 for three zones. This work extends the study on the forecast of power consumption by integrating machine learning and optimization techniques that provide effective energy management strategies.},
  archive      = {J_CC},
  author       = {Wang, Mengxia and Zhu, Chaoyang and Zhang, Yunxiang and Deng, Jinxin and Cai, Yiwei and Wei, Wei and Guo, Mengxing},
  doi          = {10.1007/s12559-025-10402-8},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-35},
  shortjournal = {Cogn. Comput.},
  title        = {Application of metaheuristic algorithms with supervised machine learning for accurate power consumption prediction},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Context-aware prediction with secure and lightweight
cognitive decision model in smart cities. <em>CC</em>, <em>17</em>(1),
1–12. (<a href="https://doi.org/10.1007/s12559-025-10403-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cognitive networks with the integration of smart and physical devices are rapidly utilized for the development of smart cities. They are explored by many real-time applications such as smart homes, healthcare, safety systems, and other unpredictable environments to gather data and process network requests. However, due to the external conditions and inherent uncertainty of wireless systems, most of the existing approaches cannot cope with routing disturbances and timely delivery performance. Further, due to limited resources, the demand for a secure communication system raises another potential research challenge to protect sensitive data and maintain the integrity of the urban environment. This paper presents a secured decision-making model using reinforcement learning with the combination of blockchain to enhance the degree of trust and data protection. The proposed model increases the network efficiency for resource utilization and the management of communication devices with the alliance of security. It provides a reliable and more adaptive paradigm by exploring learning techniques for dealing with the intrinsic uncertainty and imprecision of cognitive systems. Also, the incorporation of blockchain technology reduces the risk of a single point of failure, malicious vulnerabilities, and data leakage, ultimately fostering trust for urban sensor applications. It validates the incoming routing links and identifies any communication fault incurred due to malicious interference. The proposed model is rigorously tested and verified using simulations and its significance has been proven for network metrics in comparison to existing solutions.},
  archive      = {J_CC},
  author       = {Al-Quayed, Fatima and Humayun, Mamoona and Alnusairi, Thanaa S. and Ullah, Inam and Bashir, Ali Kashif and Hussain, Tariq},
  doi          = {10.1007/s12559-025-10403-7},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Cogn. Comput.},
  title        = {Context-aware prediction with secure and lightweight cognitive decision model in smart cities},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Engaging preference optimization alignment in large language
model for continual radiology report generation: A hybrid approach.
<em>CC</em>, <em>17</em>(1), 1–25. (<a
href="https://doi.org/10.1007/s12559-025-10404-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Large language models (LLMs) remain relatively underutilized in medical imaging, particularly in radiology, which is essential for disease diagnosis and management. Nonetheless, radiology report generation (RRG) is a time-consuming task that can result in delays and inconsistencies. To address these challenges, we present a novel hybrid approach that integrates multi-modal radiology information and preference optimization alignment in LLM for continual RRG. Our method integrates a pre-trained small multi-modal model to analyze radiology images and generate an initial report, which is subsequently refined and aligned by an LLM using odds ratio preference optimization (ORPO) and with historical patient data and assessments to mimic radiologist-like responses, bypassing reinforcement learning from human feedback-based (RLHF) alignment. This two-stage fusion—supervised fine-tuning followed by preference optimization—ensures high accuracy while minimizing hallucinations and errors. We also propose a data field curation strategy extendable to various other RRG modality datasets, focusing on selecting relevant responses for preference alignment. We evaluate our approach on two public datasets, achieving state-of-the-art performance with average Bleu scores of 0.375 and 0.647, Meteor scores of 0.495 and 0.714, Rouge-L scores of 0.483 and 0.732, and average F1-RadGraph scores of 0.488 and 0.487, for chest X-rays and lung CT scan datasets, respectively. We further provide in-depth qualitative analyses and ablation studies to explain the workings of our model and grasp the clinical relevance for RRG. This work presents the first application of preference optimization in continual RRG, representing a significant advancement in automating clinically reliable report generation. By reducing cognitive burdens on radiologists through AI-powered reasoning and alignment in LLMs, the proposed model improves decision-making, perception, and diagnostic precision, streamlining workflows and enhancing patient care. Our code is available at https://github.com/AI-14/r2gpoallm .},
  archive      = {J_CC},
  author       = {Izhar, Amaan and Idris, Norisma and Japar, Nurul},
  doi          = {10.1007/s12559-025-10404-6},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-25},
  shortjournal = {Cogn. Comput.},
  title        = {Engaging preference optimization alignment in large language model for continual radiology report generation: A hybrid approach},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel hyperparameter optimization approach for supervised
classification: Phase prediction of multi-principal element alloys.
<em>CC</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s12559-025-10405-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this paper, a hyperparameter optimization approach is proposed for the phase prediction of multi-principal element alloys (MPEAs) through the introduction of two novel hyperparameters: outlier detection and feature subset selection. To gain a deeper understanding of the connection between alloy phases and their elemental properties, an artificial neural network is employed, with hyperparameter optimization performed using a genetic algorithm to select the optimum hyperparameters. The two novel hyperparameters, outlier detection and feature subset selection, are introduced within the optimization framework, along with new crossover and mutation operators for handling single and multi-valued genes simultaneously. Ablation studies are conducted, illustrating an improvement in prediction accuracy with the inclusion of these new hyperparameters. A comparison with five existing algorithms in multi-class classification is made, demonstrating an improvement in the performance of phase prediction, thereby providing a better perception of the alloy phase space for high-throughput MPEA design.},
  archive      = {J_CC},
  author       = {Fatimi, Syed Hassan and Wang, Zidong and Chang, Isaac T. H. and Liu, Weibo and Liu, Xiaohui},
  doi          = {10.1007/s12559-025-10405-5},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {A novel hyperparameter optimization approach for supervised classification: Phase prediction of multi-principal element alloys},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Augmenting cardiovascular disease prediction through CWCF
integration leveraging harris hawks search in deep belief networks.
<em>CC</em>, <em>17</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s12559-025-10406-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cardiovascular disease (CVD) is a major global health concern, demanding accurate predictive models to aid preventive healthcare strategies. Heart failure, stroke, and coronary artery disease are among the disorders that fall under the umbrella term of cardiovascular disease (CVD). Leveraging the Harris Hawks Optimization (HHO) algorithm in conjunction with deep belief networks (DBNs) aims to improve CVD risk prediction accuracy. Harris Hawks Optimization (HHO) draws inspiration from the cooperative behavior of Harris’s hawks in nature, providing an efficient metaheuristic search algorithm for optimization problems. Integrating HHO into machine learning frameworks enhances the exploration and exploitation of search spaces, leading to improved model performance and convergence rates, particularly in deep learning tasks like feature selection and hyperparameter tuning. Powerful generative models called deep belief networks (DBNs) are made up of several layers of latent, stochastic variables. Restricted Boltzmann machines (RBMs) serve as building blocks in the training process of deep belief networks (DBNs), facilitating the unsupervised pre-training of hidden layers. Leveraging RBMs within DBNs enables the extraction of hierarchical representations, enhancing the network’s ability to learn intricate patterns and improve predictive performance in complex data settings. They leverage unsupervised learning techniques to extract intricate patterns and hierarchical representations from complex data, making them ideal for tasks such as feature learning and classification in machine learning research. This study introduces innovative algorithms, including the correlation-based weighted compound feature generation (CWCFG) technique, to enhance the optimization process of HHO. Comparative analysis against traditional machine learning models and rule-based firefly optimizer (RBFO) and Grey Wolf Optimizer (GWO) with the state-of-the-art deep learning techniques demonstrates the efficacy of the CWCFG-HHO-DBN model. Additionally, an in-depth feature importance analysis identifies key predictors, enriching the model’s interpretability. The research conducts a comprehensive evaluation of the proposed model, employing various performance metrics such as accuracy, precision, recall, and F-measure. With a remarkable accuracy of 97.19%, the HHO-DBN model shows promise in enhancing CVD risk prediction. The findings underscore its potential in personalized medicine, facilitating tailored interventions for high-risk individuals. Future directions include refining the algorithm and expanding its application in healthcare settings.},
  archive      = {J_CC},
  author       = {Savitha, S. and Kannan, A. Rajiv and Logeswaran, K.},
  doi          = {10.1007/s12559-025-10406-4},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Cogn. Comput.},
  title        = {Augmenting cardiovascular disease prediction through CWCF integration leveraging harris hawks search in deep belief networks},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An asymmetric semantic segmentation model via lightweight
attention-guided feature enhancement and fusion. <em>CC</em>,
<em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s12559-025-10407-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Semantic segmentation is widely used in fields such as autonomous driving and unmanned aerial vehicle navigation. However, the huge computational burden and redundant parameters limit its application in edge devices such as mobile phones. In this study, we propose an asymmetric lightweight semantic segmentation model via lightweight attention-guided feature enhancement and fusion. Specifically, the proposed model adopts an encoder-decoder structure. In the encoder, we design an asymmetric feature extraction module to extract image information and use the locally sensitive Hash self-attention to enhance the global information. In the decoder, we first use channel attention to filter out the useless information in shallow layers and adopt the spatial attention to refine local features in deep layers. We then fuse the multi-scale features by the gating mechanism. Additionally, we also design an auxiliary loss to supervise the segmentation of small objects. The results on Cityscapes and CamVid show that the proposed model achieves a good balance between accuracy and the number of parameters. It obtains 70.68% and 72.19% mIoU on the two test datasets with 0.86M parameters, respectively. Code is available on https://github.com/year410/LAANET},
  archive      = {J_CC},
  author       = {Tang, Qingsong and Zhao, Minghui and Ren, Yalei and Shi, Xiaomeng and Jiang, Wuming},
  doi          = {10.1007/s12559-025-10407-3},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {An asymmetric semantic segmentation model via lightweight attention-guided feature enhancement and fusion},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Dynamic behavior of three-layer fractional-order neural
networks with multiple delays. <em>CC</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s12559-025-10411-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Most of the complex network in the real world are not single-layer networks, and networks will be connected with each other. Networks with multi-layer is important because it means cognitive and artificial intelligence. Most current studies of networks consider the case that with n-nodes including ring network, small-word network, scale-free network, etc. This type of network is not enough to describe the complex structure of actual neural networks. However, it is more actual to study the dynamic behavior of multi-layer networks than single-layer networks. In this paper, the stability and bifurcation of a class of three-layer fractional-order neural networks with multiple delays was studied for the first time. By selecting the appropriate bifurcation parameter, the internal dynamic behavior of the given model was discussed by using the theory of Hopf bifurcation, and the critical value and criterion for Hopf bifurcation are derived. The influence of delay, fractional order, and the number of hidden neurons on the bifurcation point were discussed in detail. And the critical value of Hopf bifurcation is accurately calculated. The results show that the stability of the system can be destroyed by increasing the fractional order and the number of hidden neurons. The correctness of the theoretical results is verified by numerical simulation.},
  archive      = {J_CC},
  author       = {Li, Xinyu and Cheng, Zunshui and Xin, Youming and Shang, Yun},
  doi          = {10.1007/s12559-025-10411-7},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {Dynamic behavior of three-layer fractional-order neural networks with multiple delays},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning to calibrate prototypes for few-shot image
classification. <em>CC</em>, <em>17</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s12559-025-10412-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Few-shot learning (FSL) aims to generalise the model to novel classes by using a limited amount of discriminative samples (a.k.a., prototypes). With few labelled samples, there is much uncertainty and randomness in the data, which makes it more difficult for the model to learn the complete underlying patterns. This paper proposes a Discriminative Property Calibration Network (DPCNet) to enable model building in linear space with robust separability. Concretely, the property features of samples are extracted to facilitate filtering out low-informative key points at the instance level, and then the key points are further refined from the perspective of property features to retain those dimensions that contain the most relevant properties. Furthermore, the discriminative key properties are re-weighted by accounting for the correlation between images, thus forcing the model to focus more on the key property information. Moreover, a new margin algorithm is proposed to optimise the data distribution of features by dynamically adjusting the distance between classes. We conduct extensive experiments on four datasets, i.e., miniImageNet, tiredImagenet, CUB-200-2011 and CIFAR-FS, achieving the accuracies of 67.96%, 72.57%, 79.6% and 74.56%, respectively, on the 5-way 1-shot setting, and the same very competitive performance on the 5-way 5-shot setting. The proposed method can well extract the most relevant and discriminative properties, the re-weighted features further emphasise the discrimination and the dynamic margin algorithm enhances the stability and generalisation ability. The proposed method achieves the state-of-the-art performance, and it will have meaningful inspiration for future works.},
  archive      = {J_CC},
  author       = {Liang, Chenchen and Jiang, Chenyi and Wang, Shidong and Zhang, Haofeng},
  doi          = {10.1007/s12559-025-10412-6},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Cogn. Comput.},
  title        = {Learning to calibrate prototypes for few-shot image classification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tweet credibility ranker: A credibility features’ fusion
model. <em>CC</em>, <em>17</em>(1), 1–36. (<a
href="https://doi.org/10.1007/s12559-025-10413-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Misinformation on social media has emerged as a modern weapon of warfare, disrupting societal peace, trust, justice, and democracy. It is quite challenging to address the issue of information credibility for microblogs. It becomes more challenging when the authenticity of the poster is hidden. The concept of information credibility has multi-perspectives. There are many necessary aspects of information credibility which must be considered for effective credibility assessment. It is observed that some important aspects of credibility are not considered in existing studies. The complete credibility assessment solution needs a comprehensive and diverse set of features for such complex identification. Therefore, these features are identified and proposed by exploring the related research studies consisting of the necessary credibility aspects. These features consist of diverse levels provided by microblogs. These levels include the post, poster, poster’s social network, and actual information propagation network. An exploratory study is also conducted to propose the best credibility features that are used in the proposed solution. The attempt is made for a hybrid features fusion model which combines feature-based or machine learning and graph-based approaches. It is a lightweight, high-performing, non-latent features model to avoid their drawbacks. It assesses the levels of credibility of the concerned post. It is designed for high-impact applications to combat low-credibility content during elections, crises, and other critical scenarios. The model is executed over a publicly available dataset extended for credibility assessment. The model provides good results with 95.6% accuracy by XGBoost using platinum features. The performance of the proposed model is compared with state-of-the-art that produced much-appreciating results.},
  archive      = {J_CC},
  author       = {Qureshi, Khubaib Ahmed and Malick, Rauf Ahmed Shams},
  doi          = {10.1007/s12559-025-10413-5},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-36},
  shortjournal = {Cogn. Comput.},
  title        = {Tweet credibility ranker: A credibility features’ fusion model},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An adaptive neural network algorithm with quasi
opposition-based learning for numerical optimization problems.
<em>CC</em>, <em>17</em>(1), 1–29. (<a
href="https://doi.org/10.1007/s12559-025-10415-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The structure of artificial neural networks and the biological nervous systems serve as the foundation for the creation of the neural network algorithm (NNA). The robust global search capability of NNAs makes it an effective tool for solving a wide range of complex optimization problems. Unfortunately, its limited relevance to many optimization problems is due to its poor exploitation, weak convergence, and tendency to fall into local optima. The paper’s goal is to introduce an enhanced version of the NNA known as the adaptive quasi-opposition-based neural network algorithm (AQOBNNA) in order to overcome these issues. The quasi-opposition-based learning (QOBL) and an adaptive strategy are combined in this suggested algorithm, where the adaptive technique is added to determine whether or not to use QOBL. The QOBL technique replaces a random search individual with the best one throughout the position update phase in order to enhance exploitation and increase exploration capabilities. The performance of the suggested AQOBNNA is assessed using a set of 23 traditional benchmark functions and compared with a number of current methods. It is evident from the experimental data that AQOBNNA performs better overall and outperforms all the algorithms that were examined.},
  archive      = {J_CC},
  author       = {Kundu, Tanmay and Garg, Harish},
  doi          = {10.1007/s12559-025-10415-3},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-29},
  shortjournal = {Cogn. Comput.},
  title        = {An adaptive neural network algorithm with quasi opposition-based learning for numerical optimization problems},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploring influence of different emotions on decision-making
by analyzing the temporal, spatial, and spectral domains of EEG.
<em>CC</em>, <em>17</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s12559-025-10416-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Decision-making is a complex cognitive process, in which emotion is one of the most important factors. But insights into the influence of emotion on decision-making are scarce, especially the underlying mechanism of the brain. To reveal the brain’s underlying mechanisms of the influence of emotion on decision-making, an experiment involving emotion elicitation and decision-making tasks was designed. Electroencephalography (EEG), behavioral, and subjective data were collected and conducted. We constructed time-varying weighted directed networks by phase slope index (PSI) in four frequency bands and calculated graph theory metrics. Firstly, the period that the brain processes information most efficiently is 100–300 ms after the appearance of the decision-making task. Secondly, by analyzing the temporal-spatial domains of EEG, the significant differences in global efficiency (GE) and local efficiency (LE) were found among three different emotion groups in the alpha band in the low-difficulty task during 100–300 ms. Thirdly, most activation regions of different emotions were similar and concentrated in the parietal, and occipital lobes but there were still slight differences that were more likely to be found in the prefrontal and left temporal lobes. Graph theory metrics in the decision-making process changed dynamically in the temporal domain and graph theory metrics of different emotions were different.},
  archive      = {J_CC},
  author       = {Wang, Xinyuan and Wang, Danli and Zhao, Yanyan},
  doi          = {10.1007/s12559-025-10416-2},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Cogn. Comput.},
  title        = {Exploring influence of different emotions on decision-making by analyzing the temporal, spatial, and spectral domains of EEG},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). HLAE: Hierarchical local attention encoder for MRI brain
tumor image classification. <em>CC</em>, <em>17</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s12559-025-10419-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {MRI-based brain tumor classification is a challenging neuroimaging task, where the key lies in leveraging ensemble information from brain images. However, current algorithms primarily encode global appearance features of brain images and fail to account for local dependencies inherent in brain tissue adequately. In addition, most existing approaches do not thoroughly investigate the importance coefficients among different regions of brain images. To address these issues, in this work, we propose a novel cognitively-inspired hierarchical local attention encoder (HLAE) framework for capturing local dependency information in MRI images. Based on the characteristics of MRI images, we focus on local information from two perspectives: long-range visual feature dependencies and high-order structural context correlations to fully describe the content association and location relations of brain MRI images. For this purpose, a Swin Transformer is first utilized for encoding the patch-wise content dependencies of a brain MRI image by shifting windows and skipping connections. Meanwhile, a graph structure is also extracted from the MRI image, and a graph attention network is employed to capture the image’s contextual correlations. Finally, the two local information are integrated, and a softmax layer is used to obtain the final brain tumor classification result. This framework naturally contains the attention mechanism, which can effectively quantify the importance among different brain image regions, so as to locate the most discriminative regions in brain tumor classification accurately. Extensive experiments are conducted on two publicly available brain tumor MRI datasets. The results demonstrate its ability to automatically detect brain tumors with superior performance compared to state-of-the-art algorithms.},
  archive      = {J_CC},
  author       = {Dong, Changxu and Sun, Dengdi and Luo, Bin},
  doi          = {10.1007/s12559-025-10419-z},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Cogn. Comput.},
  title        = {HLAE: Hierarchical local attention encoder for MRI brain tumor image classification},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Unleashing the power of generative AI in agriculture 4.0 for
smart and sustainable farming. <em>CC</em>, <em>17</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s12559-025-10420-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Generative artificial intelligence (GAI) represents a pioneering class of artificial intelligence systems renowned for producing diverse media, such as text and images. Agriculture 4.0 (AG-4.0) is a concept that integrates advanced technologies such as the Internet of Things (IoT), data analytics, artificial intelligence, and precision agriculture into the agricultural sector. The integration of GAI and AG-4.0 can generate new and valuable agricultural insights and solutions through pattern recognition and data analysis. This integration enhances farming practices by generating predictive models, simulating optimal growth conditions, diagnosing plant diseases, and optimizing genetic traits. In spite of the tremendous scope of GAI in agriculture, there has been no detailed study concerning the applications and scope of GAI in AG-4.0. Addressing this research gap, we explore various applications, real-world products, and limitations of GAI in agriculture. We explore how GAI models such as ChatGPT and Dall-E can be personalized advisors for farmers, help increase awareness about farmer relief programs, design farm layouts, and many other such applications. Additionally, we cover four real-world GAI products deployed to assist farmers. Since GAI is a growing technology, it poses challenges such as scarcity of data, data privacy, and interpretability. We elaborately discuss these limitations and suggest multiple directions for future research in GAI for agriculture.},
  archive      = {J_CC},
  author       = {Sai, Siva and Kumar, Sanjeev and Gaur, Aanchal and Goyal, Shivam and Chamola, Vinay and Hussain, Amir},
  doi          = {10.1007/s12559-025-10420-6},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Cogn. Comput.},
  title        = {Unleashing the power of generative AI in agriculture 4.0 for smart and sustainable farming},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Innovative deep learning framework for accurate plant
disease detection and crop productivity enhancement. <em>CC</em>,
<em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s12559-025-10421-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In modern agriculture, the detection of plant diseases is crucial for enhancing crop productivity. Predicting disease onset and providing advice to farmers are essential steps to achieve increased yields on a large scale. The research addresses the critical need for timely and accurate plant leaf disease diagnosis to prevent growth issues. Leveraging deep learning advancements, the work confronts challenges like small lesion characteristics, distorted backgrounds, data imbalances, and limited generalization in agricultural datasets. After preprocessing the leaf images with tasks like data augmentation and resizing, a sheaf attention U-net with K-means clustering (SAUKC) is employed for segmentation to identify the region of interest. The segmented features are then input into the Orientation-guided Crystal Edge Deep Network (OCEDN) for infection detection. Fine-tuning with the improved kookaburra optimization algorithm (IKOA) addresses training challenges. The proposed method accurately identifies plant leaf diseases, achieving a remarkable accuracy rate of 98%. The validity of the statistical analysis is confirmed to substantiate the outcomes regarding accuracy, specificity, and recall.},
  archive      = {J_CC},
  author       = {M., Mohan and Anandamurugan, S.},
  doi          = {10.1007/s12559-025-10421-5},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {Innovative deep learning framework for accurate plant disease detection and crop productivity enhancement},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Verifying technical indicator effectiveness in
cryptocurrency price forecasting: A deep-learning time series model
based on sparrow search algorithm. <em>CC</em>, <em>17</em>(1), 1–21.
(<a href="https://doi.org/10.1007/s12559-025-10422-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Forecasting cryptocurrency prices is challenging due to market volatility and dynamic behavior. This study aims to enhance prediction accuracy for Bitcoin (BTC), Ethereum (ETH), and Litecoin (LTC) by proposing a novel deep learning framework. The framework integrates the Sparrow Search Algorithm (SSA) for selecting optimal technical indicators with Bidirectional Long Short-Term Memory (Bi-LSTM) networks. Technical indicators derived from historical market data, including prices and trading volume, are analyzed to improve forecasting. The results demonstrate that the proposed framework effectively enhances prediction accuracy for BTC and LTC. For ETH, the best performance is achieved using all 34 indicators with the Bi-LSTM model. These findings highlight the importance of selecting relevant indicators and demonstrate the potential of advanced deep learning models in addressing the complexities of cryptocurrency markets. This research provides valuable insights and a reliable framework for improving cryptocurrency price predictions.},
  archive      = {J_CC},
  author       = {Cheng, Ching-Hsue and Yang, Jun-He and Dai, Jia-Pei},
  doi          = {10.1007/s12559-025-10422-4},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Cogn. Comput.},
  title        = {Verifying technical indicator effectiveness in cryptocurrency price forecasting: A deep-learning time series model based on sparrow search algorithm},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Functional connectivity imbalance between positive and
negative networks in mild cognitive impairment via feature selection.
<em>CC</em>, <em>17</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s12559-024-10399-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  archive      = {J_CC},
  author       = {Wu, Haifeng and Pu, Changlin},
  doi          = {10.1007/s12559-024-10399-6},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Cogn. Comput.},
  title        = {Functional connectivity imbalance between positive and negative networks in mild cognitive impairment via feature selection},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Attribute reduction in a hybrid decision information system
based on fuzzy conditional information entropy using iterative model and
matrix operation. <em>CC</em>, <em>17</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s12559-024-10400-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Attribute reduction of hybrid decision information systems (HDISs) is a significant research area within the field of machine learning. Due to the presence of nominal attributes, it is difficult to accurately measure the distance between objects in HDISs, which often results in poor attribute reduction for these systems. Rough set theory (RST) is a crucial tool for attribute reduction, but it requires computation of upper and lower approximations, which often leads to computational difficulties. In response to the aforementioned issues, this paper proposes a fast attribute reduction algorithm for HDISs based on fuzzy conditional information entropy that utilizes an iterative model and matrix operations. Firstly, a novel measurement of the distance between nominal attribute values is defined using decision attributes. Subsequently, fuzzy conditional information entropy is calculated from the perspective of “the attribute values is fed back to the attribute set” and its properties are provided. Additionally, an iterative attribute reduction model and difference matrix are established, and two new matrix operations are introduced. Finally, an iterative attribute reduction algorithm is provided. The results of experiments and statistical tests on fifteen UCI datasets, including three large datasets, demonstrate that the proposed algorithm is more effective and efficient than nine state-of-the-art algorithms. This paper not only addresses the issue of difficulty in measuring the distance between nominal attribute values but also significantly improves the computational efficiency of attribute reduction algorithms based on RST, making it possible for them to be applied to large datasets.},
  archive      = {J_CC},
  author       = {Ma, Xiaoqin and Peng, Yichun and Yu, Wenchang and Xu, Yi and Zhang, Qinli and Li, Zhaowen},
  doi          = {10.1007/s12559-024-10400-2},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Cogn. Comput.},
  title        = {Attribute reduction in a hybrid decision information system based on fuzzy conditional information entropy using iterative model and matrix operation},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A novel multi-attribute group decision-making method under
linguistic q-rung orthopair fuzzy environment based on archimedean
copula and extended power average operator. <em>CC</em>, <em>17</em>(1),
1–28. (<a href="https://doi.org/10.1007/s12559-025-10409-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-attribute group decision-making (MAGDM) refers to a series of decision-making problems that rank all possible alternatives based on decision makers’ cognition and evaluations over alternatives from multiple attributes. Hence, the precondition of MAGDM is felicitously describing decision makers’ fuzzy and uncertain cognitive information in complicated decision-making issues. The recently proposed linguistic q-rung orthopair fuzzy set (Lq-ROFS), which uses two linguistic terms to denote membership and non-membership degrees, has been proved to be an effective and promising tool to depict decision makers’ complex cognition in real MAGDM problems. Considering the drawbacks of existing Lq-ROFS-based decision-making methods, this paper focuses on MAGDM approaches where decision makers’ cognitive information is denoted by Lq-ROFSs. The main contribution of this paper is to propose a novel MAGDM method based on Lq-ROFSs. This paper introduces a new MAGDM method under Lq-ROFSs. In order to do this, this study first puts forward some new operational rules for linguistic q-rung orthopair fuzzy numbers (Lq-ROFNs) based on Archimedean copula. These new operational rules are more flexible than existing ones and some other operations can be derived by using different generators. Second, to effectively aggregate Lq-ROFNs, the extended power average operator is applied in linguistic q-rung orthopair fuzzy environment and based on the new operational rules, some novel aggregation operators are generated. Afterward, the developed aggregation operators are used in decision-making problems and a novel MAGDM method which concentrates on linguistic q-rung orthopair fuzzy decision environment is introduced. Specific steps of the new method are illustrated in detail and it is then applied in some illustrative examples to verify its effectiveness. Our proposed method is effective for handling MAGDM problems under Lq-ROFSs. Numerical examples have shown the effectiveness in handling realistic MAGDM problems. In addition, comparison with some existing methods illustrates the advantages and superiorities of our method. This paper introduces a new MAGDM method under Lq-ROFSs. This method is based on Archimedean copula, extended power average operator, and Lq-ROFSs, and is powerful and flexible to cope with MAGDM problems in reality.},
  archive      = {J_CC},
  author       = {Tang, Fangcheng and Zhang, Yushu and Wang, Jun},
  doi          = {10.1007/s12559-025-10409-1},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-28},
  shortjournal = {Cogn. Comput.},
  title        = {A novel multi-attribute group decision-making method under linguistic q-rung orthopair fuzzy environment based on archimedean copula and extended power average operator},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Discovering the cognitive bias of toxic language through
metaphorical concept mappings. <em>CC</em>, <em>17</em>(1), 1–21. (<a
href="https://doi.org/10.1007/s12559-025-10423-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {With the prosperity of social media, toxic language spreading over social media has become an unignorable challenge for individual mental health and social harmony. Many researchers have studied toxic language identification to control or mitigate it. However, it still leaves a blank in the cognitive patterns of toxic language. Metaphors as a common feature in natural language connect literal and metaphorical meanings, which could be a useful tool to study the underlying cognitive patterns of the text. In this paper, we utilize a metaphor processing tool, MetaPro, to process a public toxic language dataset and analyze the cognitive biases between toxic and non-toxic language, multiple levels and subtypes of toxic language as well as toxic language mentioning different genders, sexual orientations, and races. Our study demonstrates that significant differences exist in cognitive patterns of the above-mentioned categories and analyzes the differences with machine learning methods.},
  archive      = {J_CC},
  author       = {Ge, Mengshi and Mao, Rui and Cambria, Erik},
  doi          = {10.1007/s12559-025-10423-3},
  journal      = {Cognitive Computation},
  month        = {2},
  number       = {1},
  pages        = {1-21},
  shortjournal = {Cogn. Comput.},
  title        = {Discovering the cognitive bias of toxic language through metaphorical concept mappings},
  volume       = {17},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
