<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>PAAA_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="paaa---38">PAAA - 38</h2>
<ul>
<li><details>
<summary>
(2025). Plant leaf image segmentation in natural scenes: A
multi-layer graph queries propagation approach. <em>PAAA</em>,
<em>28</em>(1), 1–23. (<a
href="https://doi.org/10.1007/s10044-024-01380-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Accurate leaf segmentation is crucial for optimizing plant recognition and enhancing leaf identification precision. However, leaf segmentation encounters challenges when working with images captured in natural scenes. These images often contain intricate backgrounds with soil artifacts, overlapping leaves, plant elements, shadows, and variations in lighting. To address these issues, we propose an approach for segmenting leaf images using a multi-layer graph-based propagation method. The process begins with spatial localization of the leaf, aiding in detecting the foreground template, describing the central area of the leaf. Subsequently, a multi-level decomposition of the image into homogeneous regions is accomplished to capture image details at different scales. We then construct a graph based on this structure, connecting each region to its neighbors with weighted edges based on shared areas or edges across different resolutions. This graph is used to rank regional similarities to the leaf by propagating ranking scores from the foreground template to the image boundaries. As a result, we obtain a saliency map, which is used to extract the leaf from its surroundings. Finally, the resulting binary mask is refined using random forests to achieve optimal separation between the leaf and the background. Experiments conducted on a widely used dataset demonstrate that our method outperforms several state-of-the-art segmentation methods.},
  archive      = {J_PAAA},
  author       = {Lyasmine, Adada and Idir, Filali and Samia, Bouzefrane},
  doi          = {10.1007/s10044-024-01380-y},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Plant leaf image segmentation in natural scenes: A multi-layer graph queries propagation approach},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A partitioning incremental algorithm using adaptive
mahalanobis fuzzy clustering and identifying the most appropriate
partition. <em>PAAA</em>, <em>28</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10044-024-01360-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper deals with the problem of determining the most appropriate number of clusters in a fuzzy Mahalanobis partition. First, a new fuzzy Mahalanobis incremental algorithm is constructed to search for an optimal fuzzy Mahalanobis partition with $$2,\,3,\ldots$$ clusters. Among these partitions, selecting the one with the most appropriate number of clusters is based on appropriately modified existing fuzzy indexes. In addition, the Fuzzy Mahalanobis Minimal Distance index is defined as a natural extension of the recently proposed Mahalanobis Minimal Distance index for non-fuzzy clustering. The new fuzzy Mahalanobis incremental algorithm was tested on several artificial data sets and the color image segmentation problems from real-world applications: art images, nature photography images, and medical images. The algorithm includes multiple usage of the global optimization algorithm DIRECT. But unlike previously known fuzzy Mahalanobis indexes, the proposed Fuzzy Mahalanobis Minimal Distance index ensures accurate results even when applied to complex real-world applications. A possible disadvantage could be the need for longer CPU time. Furthermore, besides effective identification of the partition with the most appropriate number of clusters, it is shown how to use the proposed Fuzzy Mahalanobis Minimal Distance index to search for an acceptable partition, which proved particularly useful in the above-mentioned real-world applications.},
  archive      = {J_PAAA},
  author       = {Scitovski, Rudolf and Sabo, Kristian and Grahovac, Danijel and Martínez-Álvarez, Francisco and Ungar, Sime},
  doi          = {10.1007/s10044-024-01360-2},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A partitioning incremental algorithm using adaptive mahalanobis fuzzy clustering and identifying the most appropriate partition},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Adaptive optimization of low rank decomposition and its
application on fabric defect detection. <em>PAAA</em>, <em>28</em>(1),
1–15. (<a href="https://doi.org/10.1007/s10044-024-01363-z">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In practical applications of fabric defect detection, low-rank decomposition is the effective method. Sparse matrices represent defect results, so sparse terms are the focus of this application. Because the characteristics of each observation matrix differ, the weight of sparse term also differ. Therefore, this paper proposes adaptive weight for the model, allowing it to find suitable weight for different observation matrices and thereby improving the accuracy of model. During the matrix separation process of the model, elements that should belong to the sparse matrix may be separated into the noise matrix. To address this, this paper establishes new constraints to achieve a deeper separation between the two. While establishing the corresponding algorithmic framework, this paper also considers the fluctuations in the model’s solution process and proposes a new definition for the penalty factors. This aims to improve algorithm efficiency and reduce CPU time. This paper also provides a convergence analysis of the proposed method. In the dataset of fabric defects, it was shown that the star and dot types had the best results in TPR and F-measure, with TPR of 85.15% and 81.56%, and f-measure of 70.51% and 65.40%, respectively. Indicating that the method proposed in this paper has the fastest calculation speed.},
  archive      = {J_PAAA},
  author       = {Shi, Wenya and Chen, Zhixiang and Liang, Jiuzhen and Jiang, Daihong},
  doi          = {10.1007/s10044-024-01363-z},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Adaptive optimization of low rank decomposition and its application on fabric defect detection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Diverse embeddings learning for multi-view clustering.
<em>PAAA</em>, <em>28</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s10044-024-01364-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-view clustering, which improves clustering performance by exploring complementarity and consistency among multiple distinct feature sets, is attracting more and more researchers due to its wide applications in various fields e.g., pattern recognition and data mining. Traditional approaches usually explore above characteristics by mapping different views to a unified embedding through view-specific mapping matrices or neural networks. Then the unified embedding is fed into conventional single view clustering algorithms for final clustering results. However, a unified embedding is not enough to model distinct or even conflict multiple view characteristics due to their diverse representation abilities. Moreover, clustering and embedding learning are divided into two separate parts, which may bring in a gap between the class label and the learned embedding. To alleviate above problems, both unified and view-specific embeddings are learned, and a shared operator tensor and view-specific latent variables are introduced for their relationship modeling. Besides, a Kullback-Liebler divergence based objective is developed as a clustering oriented constraint, which leads to more clustering friendly embedding learned. Extensive experiments are conducted on six widely used datasets, achieving better results compared with several state-of-the-art approaches.},
  archive      = {J_PAAA},
  author       = {Li, Yongzhen and Liao, Husheng},
  doi          = {10.1007/s10044-024-01364-y},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Diverse embeddings learning for multi-view clustering},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). SA-DETR: Saliency attention-based DETR for salient object
detection. <em>PAAA</em>, <em>28</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s10044-024-01379-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Researches on the Salient Object Detection (SOD) task have made many advances based on deep learning methods. However, most methods have focused on predicting a fine mask rather than finding the most salient objects. Most datasets for the SOD task also focus on evaluating pixel-wise accuracy rather than “saliency”. In this study, we used the Salient Objects in Clutter (SOC) dataset to conduct research that focuses more on the saliency of objects. We propose a architecture that extends the cross-attention mechanism of Transformer to the DETR architecture to learn the relationship between the global image semantics and the objects. We extended module with Saliency Attention (SA) to the network, namely SA-DETR, to detect salient objects based on object-level saliency. Our proposed method with cross- and saliency-attentions shows superior results in detecting salient objects among multiple objects compared to other methods. We demonstrate the effectiveness of our proposed method by showing that it outperforms the state-of-the-art performance of the existing SOD method by 4.7% and 0.2% in MAE and mean E-measure, respectively.},
  archive      = {J_PAAA},
  author       = {Nam, Kwangwoon and Kim, Jeeheon and Kim, Heeyeon and Chung, Minyoung},
  doi          = {10.1007/s10044-024-01379-5},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Pattern Anal. Appl.},
  title        = {SA-DETR: Saliency attention-based DETR for salient object detection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Stgcn-pad: A spatial-temporal graph convolutional network
for detecting abnormal pedestrian motion patterns at grade crossings.
<em>PAAA</em>, <em>28</em>(1), 1–17. (<a
href="https://doi.org/10.1007/s10044-024-01382-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {This paper presents a Spatial-Temporal Graph Convolutional Network-based Pedestrians’ behaviors Anomaly Detection system (STGCN-PAD) for grade crossings. The behaviors of pedestrians are represented in a structured manner by skeleton trajectories that are generated using a pose estimation model. The ST-GCN components are sequentially applied to capture the spatial dependencies between skeleton key points within a single video frame and the temporal relationships for each of them. Based on these features, the system reconstructs input trajectories with a constant sliding window size, and the reconstruction error is used to distinguish abnormal behaviors from those normal. To accelerate the processing of extracted multi-dimensional feature maps, an MLP-Mixer model-based reconstruction network is developed as an alternative to the traditional convolution neural network. Only trajectories of normal walking behavior are included for model training. Anomalies, such as lingering and squatting activities, can be identified as outliers by observing the magnitude of reconstruction errors. The case studies demonstrate the salient feasibility and efficiency of the proposed system, which achieves at least comparable performance (approximately 88% in the AUC evaluation metric) with several state-of-the-art approaches while using the MLP-Mixer model accelerates model inference by 10× relative to our previous effort (Song et al. in Appl Intell 53:21676–21691, 2023).},
  archive      = {J_PAAA},
  author       = {Song, Ge and Qian, Yu and Wang, Yi},
  doi          = {10.1007/s10044-024-01382-w},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Stgcn-pad: A spatial-temporal graph convolutional network for detecting abnormal pedestrian motion patterns at grade crossings},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Appropriateness of distances in nearest neighbour
classification: A monometric perspective. <em>PAAA</em>, <em>28</em>(1),
1–23. (<a href="https://doi.org/10.1007/s10044-024-01373-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Among the non-parametric classification methods, the nearest neighbour classifier (NNC) holds a pre-eminent position. Given a training or sample set $${\mathcal {S}}$$ the choice one needs to make is on the value of k and the distance function d to be employed. Towards improving the efficacy of an NNC, there are many works—both theoretical and empirical—that help in choosing a suitable value of k. However, works that deal with the appropriateness of a distance d for a given $${\mathcal {S}}$$ are largely empirical. In this work, we address the following two posers for a given $${\mathcal {S}}$$ : (1) How to identify a potentially appropriate distance d? (2) What qualities should an appropriate d possess? Our investigations show that every distance function d determines a landscape on the underlying data space and only if the class boundaries align with this landscape can this d be appropriate. In view of this, we construct a relational graph $${\mathcal {G}}_{{\mathcal {S}},d}$$ , in fact, a poset, on the given $${\mathcal {S}}$$ using d. With the help of $${\mathcal {G}}_{{\mathcal {S}},d}$$ , we choose a $${\mathcal {T}} \subset {\mathcal {S}}$$ to be used in a condensed-NN algorithm. Terming it the NEN algorithm, firstly, we show empirically that the training error of this NEN algorithm is reflective of the appropriateness of d. Towards providing a theoretical justification to our claims based on empiricism, we investigate the problem of classification in the setting of monometric spaces, wherein it emerges that the suitability of d is essentially related to the embeddability of $${\mathcal {G}}_{{\mathcal {S}},d}$$ in the monometric space ( $${\mathcal {X}}, \preceq _d,d$$ ).},
  archive      = {J_PAAA},
  author       = {Gupta, Megha and Jayaram, Balasubramaniam},
  doi          = {10.1007/s10044-024-01373-x},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-23},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Appropriateness of distances in nearest neighbour classification: A monometric perspective},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Class preserving projections and data augmentation for
appearance-based face recognition. <em>PAAA</em>, <em>28</em>(1), 1–12.
(<a href="https://doi.org/10.1007/s10044-024-01388-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Computer Vision and Biometrics benefit from the recent advances in Pattern Recognition and Artificial Intelligence, which tends to make model-based face recognition more efficient. Also, deep learning combined with data augmentation tends to enrich the training sets used for learning tasks. Nevertheless, face recognition still is challenging, especially because of imaging issues that occur in practice, such as changes in lighting, appearance, head posture and facial expression. In order to increase the reliability of face recognition, we propose a novel supervised appearance-based face recognition method which creates a low-dimensional orthogonal subspace that enforces the face class separability. The proposed approach uses data augmentation to mitigate the problem of training sample scarcity. Unlike most face recognition approaches, the proposed approach is capable of handling efficiently grayscale and color face images, as well as low and high-resolution face images. Moreover, proposed supervised method presents better class structure preservation than typical unsupervised approaches, and also provides better data preservation than typical supervised approaches as it obtains an orthogonal discriminating subspace that is not affected by the singularity problem that is common in such cases. Furthermore, a soft margins Support Vector Machine classifier is learnt in the low-dimensional subspace and tends to be robust to noise and outliers commonly found in practical face recognition. To validate the proposed method, an extensive set of face identification experiments was conducted on three challenging public face databases, comparing the proposed method with methods representative of the state-of-the-art. The proposed method tends to present higher recognition rates in all databases. In addition, the experiments suggest that data augmentation also plays an essential role in the appearance-based face recognition, and that the CIELAB color space (L*a*b) is generally more efficient than RGB for face recognition as it attenuates lighting variations.},
  archive      = {J_PAAA},
  author       = {Soldera, John and Scharcanski, Jacob},
  doi          = {10.1007/s10044-024-01388-4},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Class preserving projections and data augmentation for appearance-based face recognition},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). EdgeFormer: Local patch-based edge detection transformer on
point clouds. <em>PAAA</em>, <em>28</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10044-024-01386-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Edge points on 3D point clouds can clearly convey 3D geometry and surface characteristics, therefore, edge detection is widely used in many vision applications with high industrial and commercial demands. However, the fine-grained edge features are difficult to detect effectively as they are generally densely distributed or exhibit small-scale surface gradients. To address this issue, we present a learning-based edge detection network, named EdgeFormer, which mainly consists of two stages. Based on the observation that spatially neighboring points tend to exhibit high correlation, forming the local underlying surface, we convert the edge detection of the entire point cloud into a point classification based on local patches. Therefore, in the first stage, we construct local patch feature descriptors that describe the local neighborhood around each point. In the second stage, we classify each point by analyzing the local patch feature descriptors generated in the first stage. Due to the conversion of the point cloud into local patches, the proposed method can effectively extract the finer details. The experimental results show that our model demonstrates competitive performance compared to six baselines.},
  archive      = {J_PAAA},
  author       = {Xie, Yifei and Tu, Zhikun and Yang, Tong and Zhang, Yuhe and Zhou, Xinyu},
  doi          = {10.1007/s10044-024-01386-6},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {EdgeFormer: Local patch-based edge detection transformer on point clouds},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Contrastive dual-branch network for long-tailed visual
recognition. <em>PAAA</em>, <em>28</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10044-024-01387-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Over the past decade, deep learning techniques have been widely applied to visual tasks, leading to remarkable breakthroughs. However, data in real-world scenarios often exhibit a long-tailed distribution, where head classes contain significantly more samples than tail classes. Models trained on such imbalanced data tend to bias the head classes, resulting in poor performance on tail classes. Moreover, due to the scarcity of samples in the tail classes, it is challenging for models to learn robust representations for those classes. Inspired by the success of contrastive learning in representation learning, we propose a Contrastive Dual-Branch Network (CDBN) for long-tailed visual recognition. CDBN integrates an imbalance learning branch and a contrastive learning branch to address the challenges of imbalanced data. The imbalance learning branch leverages traditional methods to address data imbalance, while the contrastive learning branch follows the principles of contrastive learning. Specifically, it uses two distinct data augmentation techniques to process the same batch of samples, generating positive sample pairs for enhanced learning. A contrastive auxiliary loss is then introduced to minimize the distance between these pairs in the normalized embedding space. Furthermore, we propose a Cumulative Fusion Strategy (CFS) to guide the model in progressively prioritizing tail classes throughout training. We conducted extensive experiments on the CIFAR10-LT, CIFAR100-LT, and ImageNet-LT datasets and compared our method with various advanced algorithms. The results demonstrate that our method substantially enhances performance across all datasets, achieving state-of-the-art results on several benchmarks. Our code is available at https://github.com/mmzbyxx/CDBN .},
  archive      = {J_PAAA},
  author       = {Miao, Jie and Zhai, Junhai and Han, Ling},
  doi          = {10.1007/s10044-024-01387-5},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Contrastive dual-branch network for long-tailed visual recognition},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Exploiting optimized forgery representation space for
general fake face detection. <em>PAAA</em>, <em>28</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10044-024-01391-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Face forgery has become more realistic with deep learning in computer vision, posing a significant challenge to trustworthy face identification. Existing works have achieved considerable accuracy within the dataset by formulating the detection as a binary classification problem. These methods attempt to amplify the category differences between real and fake faces but ignore the optimization of representation space for learning the specific forgery information within samples, which results in the intra-class distribution collapse and poor generalization in unseen domains. To mitigate this issue, we propose a novel forgery detection framework that combines contrastive learning with supervised learning, named Contrastive Learning Against face Forgery (CLAF). Specifically, a dual branch learning framework is involved in extracting the consistent forgery feature distribution first. Then, we consider the similarity, variance, and covariance constraint term for the representation space, which can better preserve the specific forgery information within each sample for generalization detection. The generalization performance is confirmed on FaceForensics++, Celeb-DF, and DFDC. Extensive experiment results demonstrate the effectiveness of our framework in improving generalization.},
  archive      = {J_PAAA},
  author       = {Yang, Gaoming and Zuo, Bang and Fang, Xianjin and Zhang, Ji},
  doi          = {10.1007/s10044-024-01391-9},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Exploiting optimized forgery representation space for general fake face detection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Improving distantly supervised named entity recognition by
emphasizing uncertain examples. <em>PAAA</em>, <em>28</em>(1), 1–12. (<a
href="https://doi.org/10.1007/s10044-024-01392-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Distantly supervised named entity recognition (DS-NER) aims to acquire knowledge from noisy labels. Recently, label re-weighting and label correction based frameworks have been recognized as promising approaches for DS-NER. These methods mainly handle easy or hard examples, yet neglect the impact of uncertain examples that are predicted correctly sometimes and incorrectly some other times during optimization. In this paper, we propose UE-NER, an Uncertainty Estimation method for DS-NER, which estimates the uncertainty of training examples and emphasizes uncertain ones, thus leads to more accurate and robust performance. To enable uncertainty reasoning, we formulate DS-NER as a span-level classification problem and the variance in predicted probability of the correct class across iterations of minibatch SGD is taken as the uncertainty measure. We further design an enhanced encoder to combine the power of the named entity and other spans in the sentence to boost recognition performance. Experimental results on two benchmark datasets demonstrate the superiority of the proposed UE-NER over existing DS-NER methods.},
  archive      = {J_PAAA},
  author       = {Nie, Binling and Shao, Yiming and Wang, Yigang},
  doi          = {10.1007/s10044-024-01392-8},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-12},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Improving distantly supervised named entity recognition by emphasizing uncertain examples},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Efficient multi-target vehicle trajectory prediction based
on multi-scale graph convolution. <em>PAAA</em>, <em>28</em>(1), 1–17.
(<a href="https://doi.org/10.1007/s10044-024-01396-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Multi-target vehicle trajectory prediction holds significant importance in the field of autonomous driving. Accurate trajectory prediction can enhance the safety and efficiency of autonomous vehicles, reducing traffic accidents and congestion. However, existing methods often fall short when dealing with complex traffic scenarios. Traditional approaches typically rely on single-scale spatiotemporal feature extraction, which struggles to fully capture the complex dynamics of traffic across different temporal and spatial scales, especially in high-density traffic environments. To address these challenges, this thesis proposes a multi-target vehicle trajectory prediction method based on a Multi-Scale Graph Convolutional Network (MSGCN). This method integrates high-definition semantic maps and employs a spatiotemporal multi-head attention mechanism alongside an adaptive dynamic weighting module to achieve efficient multi-target vehicle trajectory prediction. Specifically, this thesis constructs a dynamic feature repository using vehicle subgraphs and lane subgraphs to stabilize model weight fluctuations, thereby more accurately reflecting actual traffic conditions. Experimental results on the Argoverse dataset demonstrate the effectiveness of our method. Specifically, our approach reduces the average displacement error (mADE) by 7% and enhances the final displacement error (mFDE) by 19% when compared to existing state-of-the-art models. Our code is made available at https://github.com/Garegreen/EfficientMSGCN .},
  archive      = {J_PAAA},
  author       = {Gu, Xiang and Wang, Jing and Cheng, Dengyang and Li, Chao and Huang, Qiwei},
  doi          = {10.1007/s10044-024-01396-4},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-17},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Efficient multi-target vehicle trajectory prediction based on multi-scale graph convolution},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Learning learning curves. <em>PAAA</em>, <em>28</em>(1),
1–13. (<a href="https://doi.org/10.1007/s10044-024-01394-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Learning curves depict how a model’s expected performance changes with varying training set sizes, unlike training curves, showing a gradient-based model’s performance with respect to training epochs. Extrapolating learning curves can be useful for determining the performance gain with additional data. Parametric functions, that assume monotone behaviour of the curves, are a prevalent methodology to model and extrapolate learning curves. However, learning curves do not necessarily follow a specific parametric shape: they can have peaks, dips, and zigzag patterns. These unconventional shapes can hinder the extrapolation performance of commonly used parametric curve-fitting models. In addition, the objective functions for fitting such parametric models are non-convex, making them initialization-dependent and brittle. In response to these challenges, we propose a convex, data-driven approach that extracts information from available learning curves to guide the extrapolation of another targeted learning curve. Our method achieves this through using a learning curve database. Using the initial segment of the observed curve, we determine a group of similar curves from the database and reduce the dimensionality via Functional Principle Component Analysis FPCA. These principal components are used in a semi-parametric kernel ridge regression (SPKR) model to extrapolate targeted curves. The solution of the SPKR can be obtained analytically and does not suffer from initialization issues. To evaluate our method, we create a new database of diverse learning curves that do not always adhere to typical parametric shapes. Our method performs better than parametric non-parametric learning curve-fitting methods on this database for the learning curve extrapolation task.},
  archive      = {J_PAAA},
  author       = {Turan, O. Taylan and Tax, David M. J. and Viering, Tom J. and Loog, Marco},
  doi          = {10.1007/s10044-024-01394-6},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Learning learning curves},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Semi-supervised learning with deep laplacian support vector
machine. <em>PAAA</em>, <em>28</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10044-024-01395-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Deep learning is a rapidly growing field that can effectively extract latent features from data and use them to make predictions based on the learned features, but most models just sum the loss of each sample without considering the relationship between samples. On the other hand, the traditional Laplacian Support Vector Machine (LapSVM) can effectively utilize samples and the relationship between samples by constructing a Laplacian graph, and performs well on semi-supervised data. In this paper, we combine LapSVM and deep learning and propose Deep Laplacian Support Vector Machine. Our approach is to first use a Deep Neural Network to extract the latent features from the image, then based on the extracted feature information and a small amount of original label information, we use LapSVM for classification, build a loss function, and finally iteratively update the two parts together. We evaluate our method on several benchmark datasets and demonstrate that it outperforms other semi-supervised learning methods.},
  archive      = {J_PAAA},
  author       = {Chen, Hangyu and Xie, Xijiong and Li, Di},
  doi          = {10.1007/s10044-024-01395-5},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Semi-supervised learning with deep laplacian support vector machine},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A robust approach for outlier detection based on the ratio
of number of reverse neighbors to neighbors. <em>PAAA</em>,
<em>28</em>(1), 1–30. (<a
href="https://doi.org/10.1007/s10044-024-01372-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Outlier detection is an important issue in data mining, which has a wide range of applications in medicine, economics, video search, and credit card fraud detection. Many outlier detection methods have recently been developed. Most of the existing methods act based on the distance or density. Since each of these methods has its inherent disadvantage, we proposed a method which has the advantages of both distance-based and density-based methods. The proposed method is inspired by the basic idea that outliers are usually more distant neighbors to their nearest neighbors. The proposed method consists of three different parts. Each of these parts considers the distance, density, or location of objects, and finally we reach an optimal and efficient algorithm by combining these parts. Our algorithm is based on k nearest neighbor; in addition, we also use another kind of adaptive and extended neighborhood in order to provide more accurate results. Furthermore, the proposed method is robust and has little sensitivity to changes in parameter k. Numerical experiments and comparing with well-known algorithms are performed on both synthetic and real datasets in order to prove the efficiency and robustness of the proposed method.},
  archive      = {J_PAAA},
  author       = {Heydari-Gharaei, Reza and Sharifi, Rasoul and Kashef, Shima and Nezamabadi-pour, Hossein},
  doi          = {10.1007/s10044-024-01372-y},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-30},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A robust approach for outlier detection based on the ratio of number of reverse neighbors to neighbors},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSFM-UNET: Enhancing medical image segmentation with
multi-scale and multi-view frequency fusion. <em>PAAA</em>,
<em>28</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10044-024-01384-8">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Medical image segmentation benefits greatly from accurate and efficient models. Although CNNs and Transformer-based models are widely regarded as foundational methods in the realm of medical image segmentation, each has inherent drawbacks: Convolutional Neural Networks (CNNs) frequently face challenges when it comes to accurately capturing long-range relationships because of their limited receptive fields. Conversely, Transformers excel at capturing long-range relationships but come with a high computational cost. To address these challenges, State Space Models (SSMs) like Mamba have emerged as a promising alternative, providing an effective method to represent long-range interactions while maintaining a linear complexity. In this study, we present the Multi-Scale and Multi-View Frequency Mamba UNet (MSFM-UNet), a model specifically designed to leverage Mamba’s unique strengths for improving medical image segmentation. Additionally, the Multi-Scale Feature Aggregation (MSFA) effectively merges the feature outputs generated by each encoder block with those from the decoder. Furthermore, the Multi-View Frequency Enhancement (MVFA) is employed to simultaneously capture global and local perspectives, combining frequency domain attributes to improve the representation of features across multiple scales. We performed a comprehensive evaluation of MSFM-UNet on four widely recognized public datasets: ISIC17, ISIC18, Synapse, and ACDC. The experimental results clearly demonstrate that MSFM-UNet outperforms the current leading models in medical image segmentation. The code is made publicly available at https://github.com/qczggaoqiang/MSFM-UNet .},
  archive      = {J_PAAA},
  author       = {Gao, Qiang and Wang, Yi and Zhou, Feiyan and Wen, Jing and Li, Yong and Fang, Bin and Chen, Peng and Du, Lan and Chen, Cunjian},
  doi          = {10.1007/s10044-024-01384-8},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MSFM-UNET: Enhancing medical image segmentation with multi-scale and multi-view frequency fusion},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Latent sparse subspace learning and visual domain
classification via balanced distribution alignment and hilbert–schmidt
metric. <em>PAAA</em>, <em>28</em>(1), 1–20. (<a
href="https://doi.org/10.1007/s10044-024-01390-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Getting machine learning (ML) to perform accurate prediction needs a sufficient number of labeled samples. However, due to the either lack or small number of labeled samples in most domains, it is often beneficial to use domain adaptation (DA) and transfer learning (TL) to leverage a related auxiliary source domain to optimize the performance on target domain. In fact, the purpose of TL and DA is to use the labeled sample information (i.e., samples and the corresponding labels) for training the classifier to categorize the unlabeled samples. In this paper, we aim to propose a novel semi-supervised transfer learning method entitled “Latent Sparse subspace learning and visual domain classification via Balanced distribution alignment and Hilbert–Schmidt metric (LSBH)”. LSBH uses the latent sparse domain transfer learning for visual adaptation (LSDT) to adapt the samples with different distributions or feature spaces across domains and prevent the creation of local common subspace for source and target domains via the simultaneous learning of latent space and sparse reconstruction. LSBH proposes a novel robust classifier which maintains performance and accuracy even when faced with variations across the source and target domains. To this end, it utilizes the following two criteria in the optimization problem: maximum mean discrepancy and Hilbert–Schmidt independence criterion to reduce the marginal and conditional distribution disparities of domains and increase the dependency between samples and labels at the classification step. LSBH obtains the optimal coefficients for the classifier, which results in the minimum error in the loss function by solving the optimization problem. Thus, the error minimizing of the loss function is a part of the optimization problem. Also, to maintain the geometric structure of data in the classification step, the neighborhood graph of samples is used. The efficiency of the proposed method has been evaluated on different visual datasets and has been compared with new and prominent methods of domain adaptation and transfer learning. The results induce the superior performance of LSBH compared to the other state-of-the-art methods in label prediction.},
  archive      = {J_PAAA},
  author       = {Noori Saray, Shiva and Balafar, Mohammad-Ali and Tahmoresnezhad, Jafar},
  doi          = {10.1007/s10044-024-01390-w},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-20},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Latent sparse subspace learning and visual domain classification via balanced distribution alignment and Hilbert–Schmidt metric},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Gated normalization unit for image restoration.
<em>PAAA</em>, <em>28</em>(1), 1–19. (<a
href="https://doi.org/10.1007/s10044-024-01393-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Image restoration has been an integral part of image processing research with the goal of converting degraded images into clear ones. While some networks have achieved state-of-the-art results through architecture and module design, little attention has been paid to the adaptation of normalization methods in image restoration tasks. Normalization methods are crucial in deep learning. In this work, we attempt to combine gating mechanisms with normalization methods. Gated mechanisms are popular in feature extraction and information filtering, and combining them with normalization methods has potential for designing image restoration algorithms. Firstly, we propose a Simple Gated Attention Unit (SGAU), a block using a simple gating mechanism to validate the potential of gating mechanisms. Then, we propose a new normalization block, Gated Instance Normalization (GIN), and introduce a new normalization method, Global Response Normalization (GRN), for image restoration tasks. Both GIN and GRN combine gating mechanisms with normalization methods for feature extraction, fusion, and integration. Finally, we propose a two-stage network, Gated Normalization Network (GNNet), utilizing GIN and GRN as blocks to effectively extract and filter information. Deep separable convolutions are used in the deep layers to reduce parameters while preserving spatial information, improving local feature perception. An improved cross-stage feature fusion (ICSFF) block is used for feature information transfer between stages, and a supervised attention module (SAM) is used as input to the second stage network from the first stage output. Through various image restoration tasks, we achieve 32.93 dB PSNR on GoPro, 30.42 dB PSNR on HIDE for image deblurring, 39.94 dB PSNR on SIDD for real-world denoising, and good performance in Gaussian white noise denoising and image deraining tasks. Moreover, the GIN and GRN only generated a small number of gated weight and bias parameters, and compared to other multi-stage networks, the model size is reduced, and computational complexity is well balanced.},
  archive      = {J_PAAA},
  author       = {Wang, Qingyu and Wang, Haitao and Zang, Luyang and Jiang, Yi and Wang, Xinyao and Liu, Qiang and Huang, Dehai and Hu, Binding},
  doi          = {10.1007/s10044-024-01393-7},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Gated normalization unit for image restoration},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-state perception consistency constraints network for
person re-identification. <em>PAAA</em>, <em>28</em>(1), 1–15. (<a
href="https://doi.org/10.1007/s10044-024-01398-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (Re-ID) remains challenging due to pose variations and scale changes across non-overlapping camera views. In this work, we propose a Multi-state Perception Consistency Constraints Network (MPCC-Net) that extracts discriminative and robust features for person Re-ID. MPCC-Net consists of three primary components. First, a multi-state fused backbone network processes multi-scale and multi-view information. Second, perception consistency constraints enhance feature stability. Third, partition attention modules focus on different body parts to improve local discrimination. Comprehensive experiments on benchmark datasets demonstrate MPCC-Net’s competitive performance, effectively addressing pose and scale variations for accurate person Re-ID. Our source code will also be publicly available at: https://github.com/sesamecandy/MPCC-Net},
  archive      = {J_PAAA},
  author       = {Zhou, Mengting and Lian, Guoyun and Ouyang, Xinyu and Du, Jingyu and Song, Qiqi and Yang, Jinfeng},
  doi          = {10.1007/s10044-024-01398-2},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-state perception consistency constraints network for person re-identification},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Self-weighted subspace clustering via adaptive rank
constrained graph embedding. <em>PAAA</em>, <em>28</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s10044-024-01405-6">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Recent years, subspace clustering methods have attracted wide attention in partitioning high-dimensional data from a union of underlying subspaces, in which the data distribution is mainly explored to compensate for the absence of label information. However, for practical applications, subspace clustering still suffers from redundant and noisy features, which brings about disturbed reconstruction loss and restricts trustworthy graph learning. In this paper, we propose a robust subspace clustering framework via Self-weighted feature learning and adaptive rank constrained graph embedding (SWARG) to address the limitations of existing graph-based subspace clustering models. Specifically, a feature self-weighted learning term is introduced to the sparse subspace clustering framework to alleviate the disturbed contributions from the noisy and redundant features. As such, a few discriminative features will act as remarkable contributions in representing data samples. Meanwhile, the profile-based graph embedding term further preserving the contribution behavior information of data samples that distributed around the same subspace. Moreover, the adaptive rank-constraint graph embedding method is considered to guarantee discriminative structure for different components of representation matrix with flexible entropy-based similarity preserving. To solve the proposed model, we then develop an efficient alternative direction updating algorithm, together with convergence and complexity analysis. Finally, experimental results on toy databases and benchmark databases demonstrate the effectiveness of the proposed SWARG model compared to a series of state-of-the-art models. Our code is available at http://github.com/ty-kj/SAWRG .},
  archive      = {J_PAAA},
  author       = {Jiang, Kun and Yang, Zhihai and Sun, Qindong},
  doi          = {10.1007/s10044-024-01405-6},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Self-weighted subspace clustering via adaptive rank constrained graph embedding},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). ST-HViT: Spatial-temporal hierarchical vision transformer
for action recognition. <em>PAAA</em>, <em>28</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10044-024-01407-4">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Human action recognition (HAR) is an important task in the field of computer vision, and its primary goal is to analyze and understand human activities in videos. In addition to containing the spatial information of static images, videos also contain unique temporal information, which makes the information contained in the videos even richer. However, the training cost required to fully learn the spatial-temporal information of the videos is quite expensive for a model. In light of this, we propose a novel two-stream network structure to effectively capture the spatial-temporal information in video data. We perform masked autoencoders (MAE) pre-training, aiming to reduce the training burden of the model through this asymmetric encoder-decoder pre-training method. In addition, we propose a new multi-scale decoder component that combines transposed convolutional upsampling and convolutional downsampling. It fully utilizes the multi-scale features of the encoder to achieve excellent performance. On two challenging video datasets, Kinetics 400 (K400) and Something-Something-v2 (SSv2), we achieve state-of-the-art performance with 85.9 $$\%$$ and 75.3 $$\%$$ Top-1 accuracy, respectively.},
  archive      = {J_PAAA},
  author       = {Xia, Limin and Fu, Weiye},
  doi          = {10.1007/s10044-024-01407-4},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {ST-HViT: Spatial-temporal hierarchical vision transformer for action recognition},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Bidirectional spatio-temporal generative adversarial network
for video super-resolution. <em>PAAA</em>, <em>28</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s10044-024-01409-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Adversarial and periodic training method plays an essential role in video super-resolution, which can generate spatial high frequency detail and temporal consistency relation. However, this approach is based on unidirectional loop whose first frame can only use its own feature information, while the last frame can use all feature information of whole sequence. The biggest problem caused by this information imbalance is that early video frames are poorly reconstructed. To address these issues, we propose a novel video super-resolution model, called Bidirectional Spatio-Temporal Generative Adversarial Network (Bi-STGAN), to generate fine detail and temporal consistency video by explicitly introducing the backward branch. Specifically, Bi-STGAN adopts an elaborately designed bidirectional branch structure so that the high-resolution frames estimated from front to back can be used as input for subsequent iterations from back to front. The advantage of Bi-STGAN is to enhance information gathering by utilizing information from past and future frames which can be cyclically passed through the time series. The experimental results show that compared with the baselines, Bi-STGAN achieves competitive improvement of 15.20% for LPIPS and 2.87dB for PSNR on the REDS4 dataset, thereby demonstrating the superiority of our state-of-the-art model on video super-resolution.},
  archive      = {J_PAAA},
  author       = {Yang, Peng and Chen, Zhangquan and Sun, Yuankang and Hu, Zhongjian and Li, Bing},
  doi          = {10.1007/s10044-024-01409-2},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Bidirectional spatio-temporal generative adversarial network for video super-resolution},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Balanced clustering contrastive learning for long-tailed
visual recognition. <em>PAAA</em>, <em>28</em>(1), 1–11. (<a
href="https://doi.org/10.1007/s10044-025-01410-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Real-world deep learning training data often follow a long-tailed (LT) distribution, where a few classes (head classes) have the most samples and many classes (tail classes) have very few samples. Models trained on LT datasets typically achieve high accuracy on head classes, but suffer from poor performance on tail classes. To address this challenge, strategies based on supervised contrastive learning have been explored. However, existing methods often focus on either reducing the dominance of head class features or expanding the feature space of tail classes, but rarely achieve a balanced feature distribution across both. In this paper, we propose Balanced clustering contrastive learning (BCCL) to balance the feature space between the head and tail classes more effectively. The proposed approach introduces two main components. First, we employ queue-based clustering to extract multiple centroids. This addresses the intra-minibatch class absence issue and maintains intra-class balance. Second, we expand the feature space of tail classes based on class frequency to enhance their expressiveness. An evaluation of four LT datasets, CIFAR-10-LT, CIFAR-100-LT, ImageNet-LT, and iNaturalist 2018, demonstrates that BCCL consistently outperforms the existing methods. These results establish the ability of BCCL to maintain a balanced feature space in diverse environments. Our code is available at https://github.com/GGTINE/BCCL .},
  archive      = {J_PAAA},
  author       = {Kim, Byeong-il and Ko, Byoung Chul},
  doi          = {10.1007/s10044-025-01410-3},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-11},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Balanced clustering contrastive learning for long-tailed visual recognition},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Separability and scatteredness (s&amp;s) ratio-based
efficient SVM regularization parameter, kernel, and kernel parameter
selection. <em>PAAA</em>, <em>28</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10044-025-01411-2">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Support Vector Machine (SVM) is a robust machine learning algorithm with broad applications in classification, regression, and outlier detection. SVM requires tuning a regularization parameter (RP) which controls the model capacity and the generalization performance. Conventionally, the optimum RP is found by comparison of a range of values through the Cross-Validation (CV) procedure. In addition, for non-linearly separable data, the SVM uses kernels. In this case a set of kernels, each with a set of parameters, denoted as a grid of kernels, are considered. The optimal choice of RP and the grid of kernels is through various forms of deterministic or probabilistic grid-search. The existing methods rely heavily on exhaustive searches and provide very limited insight into the underlying data characteristics, resulting in excessive computational complexity. This work addresses this issue by proposing a statistical framework that directly relates the dataset’s separability and scatteredness to the choice of optimal hyperparameters. By stochastically analyzing the behavior of the regularization parameter, the method shows that the SVM performance can be modeled as a function of the newly defined separability and scatteredness (S&amp;S) ratio of the data. The Separability is a measure of the distance between classes, and the scatteredness is the ratio of the spread of data points. In particular, for the hinge loss cost function, an S&amp;S ratio-based table provides the optimum RP. The data S&amp;S ratio is a powerful value that can automatically evaluate linear or non-linear separability before using the SVM algorithm. The provided lookup S&amp;S ratio-based table can also provide the optimum kernel and its parameters before using the SVM algorithm. Consequently, the computational complexity of the CV grid-search is reduced to only the computational complexity of one-time use of the SVM. The simulation results on the real dataset confirm the superiority of the proposed approach in the sense of efficiency and computational complexity over the grid-search methods. The method performs better or comparable to the existing state of-the-art methods with a significantly reduced computational cost.},
  archive      = {J_PAAA},
  author       = {Shamsi, Mahdi and Beheshti, Soosan},
  doi          = {10.1007/s10044-025-01411-2},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Separability and scatteredness (S&amp;S) ratio-based efficient SVM regularization parameter, kernel, and kernel parameter selection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Ultra-fast computation of fractal dimension for RGB images.
<em>PAAA</em>, <em>28</em>(1), 1–22. (<a
href="https://doi.org/10.1007/s10044-025-01415-y">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The fractal dimension (FD) is a quantitative parameter widely used to analyze digital images in many application fields such as image segmentation, feature extraction, object recognition, texture analysis, and image compression and denoising, among many others. A variety of algorithms have been previously proposed for estimating the FD, however most of them are limited to binary or gray-scale images only. In recent years, several authors have proposed algorithms for computing the FD of color images. Nevertheless, almost all these methods are computationally inefficient when analyzing large images. Nowadays, color images can be very large in size, and there is a growing trend toward even larger datasets. This implies that the time required to calculate the FD of such datasets can become extremely long. In this paper we present a very efficient GPU algorithm, implemented in CUDA, for computing the FD of RGB color images. Our solution is an extension to RGB of the differential box-counting (DBC) algorithm for gray-scale images. Our implementation simplifies the box-counting computation to very simple operations which are easily combined across iterations. We evaluated our algorithm on two distinct hardware/software platforms using a set of images of increasing size. The performance of our method was compared against two recent FD algorithms for RGB images: a fast box-merging GPU algorithm, and the most advanced approach based on extending the DBC method. The results showed that our GPU algorithm performed very well and achieved speedups of up to 7.9× and 6172.6× regarding these algorithms, respectively. In addition, our algorithm achieved average error rates similar to those obtained by the two reference algorithms when estimating the FD for synthetic images with known FD values, and even outperformed them when processing large images. These results suggest that our GPU algorithm offers a highly reliable and ultra-fast solution for estimating the FD of color images.},
  archive      = {J_PAAA},
  author       = {Ruiz de Miras, Juan and Li, Yurong and León, Alejandro and Arroyo, Germán and López, Luis and Torres, Juan Carlos and Martín, Domingo},
  doi          = {10.1007/s10044-025-01415-y},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-22},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Ultra-fast computation of fractal dimension for RGB images},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). DE-NAF: Decoupled neural attenuation fields for sparse-view
CBCT reconstruction. <em>PAAA</em>, <em>28</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10044-025-01416-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Cone-beam computed tomography (CBCT) acquires three-dimensional internal images, particularly effective for high-mineral density structures like bones. However, especially in sparse view scenarios, its ability to visualize low-density soft tissues is limited, restricting its clinical applications. To address this problem, this study proposes a method called Decoupled Neural Attenuation Fields (DE-NAF). Specifically, DE-NAF utilizes an Adaptive Hybrid Encoder that includes both hash encoding and 3D feature grid encoding methods. This approach decouples the CBCT reconstruction into two components. Hash encoding is used for high-mineral density structures, such as bones, owing to its superior encoding quality and ability to retain features of high-mineral density structures during hash conflict resolution. The 3D feature grid is employed for low-density soft tissues, such as muscles, as it effectively preserves the feature information of low-density soft tissues. The Adaptive Hybrid Encoder extracts these features, which are then decoded by a multilayer perceptron (MLP) decoder to predict X-ray attenuation values for precise reconstruction. In addition, a loss of structural perception was introduced to enhance tissue contrast and detail, further aiding CBCT reconstruction. Extensive experiments demonstrated that DE-NAF effectively addresses the limitations of CBCT in imaging low-density soft tissues, maintaining complete structural integrity and exceeding other methods in reconstruction quality.},
  archive      = {J_PAAA},
  author       = {Zhao, Tianning and Ding, Guoping and Liu, Zhenyang and Hu, Peng and Wei, Hangping and Tan, Min and Ding, Jiajun},
  doi          = {10.1007/s10044-025-01416-x},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {DE-NAF: Decoupled neural attenuation fields for sparse-view CBCT reconstruction},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Multi-task model with attribute-specific heads for person
re-identification. <em>PAAA</em>, <em>28</em>(1), 1–13. (<a
href="https://doi.org/10.1007/s10044-025-01421-0">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Person re-identification (ReID) has become an important task in digital surveillance for enhancing security, efficient monitoring, and enabling various applications in smart cities and public safety systems. Person ReID with attributes is a challenging task due to different camera views create significant difficulties in capturing each person’s unique identity and detailed attributes. In this work, we propose a multi-task model that not only performs unique person ReID but also simultaneously predicts attributes. Our model jointly utilizes a shared backbone network, which can be either ResNet50 or EfficientNet, along with generalized mean (GeM) pooling to achieve efficient feature extraction. It also applies attribute-specific heads to predict various characteristics such as gender, age, type of clothes, color, and alongside the ReID classification. This multi-task approach utilizes the shared features across tasks, gives comprehensive attribute predictions, and may further contribute to identification in surveillance scenarios. We evaluate our model on two commonly used publicly available datasets, Market1501 and DukeMTMC-reID, demonstrating how our approach can improve both in ReID accuracy and give reliable attribute predictions. These results reveal that our multi-task model can be competitive, providing a holistic solution for practical applications in surveillance where both identification and attributes are important. The approach has shown the potential of unifying ReID with attribute prediction to develop more robust and advanced surveillance systems. The code of this experiment is publicly accessible at https://github.com/TripleTheGreatDali/ReIDMTMASH .},
  archive      = {J_PAAA},
  author       = {Ahmed, Md Foysal and Oyshee, Adiba An Nur},
  doi          = {10.1007/s10044-025-01421-0},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-13},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Multi-task model with attribute-specific heads for person re-identification},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A new method for tuning the CNN pre-trained models as a
feature extractor for malware detection. <em>PAAA</em>, <em>28</em>(1),
1–19. (<a href="https://doi.org/10.1007/s10044-024-01381-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Despite significant advancements in Android malware detection, current approaches face notable challenges, particularly in handling obfuscation techniques, achieving high detection accuracy, and maintaining computational efficiency. Traditional static and dynamic analysis methods often struggle with evolving malware tactics and providing lightweight execution, which necessitates models that can dynamically adapt to these challenges. To address these needs, this study presents TuneDroid, a novel approach that optimizes CNN model configurations for both improved detection rates and resilience to obfuscation. By leveraging image-based visualization of code, TuneDroid enables CNNs to recognize high-level visual patterns that remain consistent even with code modifications, thereby enhancing robustness against common evasion tactics. TuneDroid utilizes Bayesian optimization for dynamically tuning pre-trained Convolutional Neural Network (CNN) models. This optimization process selects optimal pre-trained models, layer configurations, and positions, significantly enhancing detection performance. Using a dataset of 3000 benign and 3000 malicious apps, where DEX code is converted into images, TuneDroid achieved accuracy rates of 99.44% on the validation set and 98.00% on the testing set. In comparison, static end-to-end models without hyperparameter tuning yielded lower accuracies, not exceeding 90.50% and 91.17%. The robustness of TuneDroid’s performance is demonstrated through extensive experiments, including precision, recall, F1-score, and comparisons with baseline models. These results highlight the importance of dynamic tuning in maximizing the effectiveness of CNN-based malware detection. This work stands out by focusing on the dynamic tuning of deep learning models for Android app security, demonstrating substantial improvements in detection accuracy and showcasing the potential of Bayesian optimization in this context.},
  archive      = {J_PAAA},
  author       = {Bakır, Halit},
  doi          = {10.1007/s10044-024-01381-x},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-19},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A new method for tuning the CNN pre-trained models as a feature extractor for malware detection},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). MSFFNet: Multi-scale feature fusion network with semantic
optimization for crowd counting. <em>PAAA</em>, <em>28</em>(1), 1–16.
(<a href="https://doi.org/10.1007/s10044-024-01385-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In recent years, the crowd-counting system has strong strength to ensure safety in public places with the practical necessity of dense crowd analysis. However, until now, it has been difficult to obtain high-quality density maps due to complex background interference, congested crowd and large-scale variations. To address this issue, this paper presents a multi-scale feature fusion network (MSFFNet) based on CNN (convolution neural network), which is capable of detecting enough semantic features to understand crowds in sparse and highly congested scenes. In this method, a large majority of encoded features are fused adaptively rather than separated extraction components. Therefore, it enhances the ability to extend the range of receptive field sizes and reduce computation cost. MSSFNet is consists of three modules: grouped feature extractor, fusion block and decoder. The feature extractor is based on first 13 convolution layers of VGG16, which extract low-level features from crowd images. The fusion block computes the weights in each group from the contrast features and average them from convolutional layers later concatenated pooling layer with a feature map. The decoder capably extracts relevant information while enduring spatial resolution. Additionally, we designed two-stream module and semantic optimization module (SOM) with decoder which instantaneously enhance the crowd head positions and reduce background noises by re-weighting features. Extensive experiments on four public datasets (ShanghaiTech Part_A and Part_B, UCF_CC_50, UCF_QNRF and JHU-Crowd++), validate that MSFFNet can perform efficiently in complex background noises and capture head sizes in sparse, congested and various weather situation.},
  archive      = {J_PAAA},
  author       = {Rohra, Avinash and Yin, Baoqun and Bilal, Hazrat and Kumar, Aakash and Ali, Munawar and Li, Yang},
  doi          = {10.1007/s10044-024-01385-7},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {MSFFNet: Multi-scale feature fusion network with semantic optimization for crowd counting},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A lightweight multidimensional feature network for small
object detection on UAVs. <em>PAAA</em>, <em>28</em>(1), 1–24. (<a
href="https://doi.org/10.1007/s10044-024-01389-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {UAV small object detection has essential applications in the military, search and rescue, and smart cities, providing critical support for target recognition in complex environments. However, the existing UAV small object detection models usually have many parameters and high computational complexity, limiting their deployment and application in practical scenarios to some extent. In this study, we propose a UAV detector with Lightweight Multidimensional Feature Network (LMF-UAV), aiming to reduce the number of parameters and computation of the model while guaranteeing accuracy, which constructs the Lightweight Multidimensional Feature Network (LMF-Net) for lightweight feature extraction, and Efficient Expressive Network (EENet) for efficient feature fusion. Neural architecture search utilizes the Dual-branch Cross-stage Universal Inverted Bottleneck to enable the network to select the most suitable structure at different layers according to requirements, thereby improving the computational efficiency of LMF-Net while maintaining performance. EENet uses the Channel-wise Partial Convolution Stage to reduce redundant computation and memory access and fuse spatial features more effectively. First, LMF-Net extracts features from the images collected by UAV and obtains three multi-scale feature maps. Second, EENet performs feature fusion on three feature maps of different scales to obtain three feature representatives. Finally, the decoupled head detects the feature map and outputs the final result. The bounding box regression loss function uses Wasserstein distance to evaluate box similarity and enhance the model’s sensitivity to small targets. The experimental results demonstrate that on the VisDrone dataset, mAP50-95 of LMF-UAV reaches 24.6%, while parameters are only 14.7M, FLOPs are only 61.8G, showing a good balance between performance and efficiency.},
  archive      = {J_PAAA},
  author       = {Yang, Wenyuan and He, Qihan and Li, Zhongxu},
  doi          = {10.1007/s10044-024-01389-3},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-24},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A lightweight multidimensional feature network for small object detection on UAVs},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Utilize trajectory information for small target
classification. <em>PAAA</em>, <em>28</em>(1), 1–9. (<a
href="https://doi.org/10.1007/s10044-024-01397-3">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Small target recognition has always been challenging in image processing systems. When targets are far from the camera, target features tend to have low quality, limiting the amount of useful information for detection systems. Consequently, classic Detection Before Tracking (DBT) algorithms find great difficulty in separating targets from their background based on their visual properties. In this study, we proposed a Track Before Detect (TBD) approach that tracks potential targets in multiple frames, reducing the false alarm rate and enhancing the detection robustness to clutter. Then, we utilize target trajectory information to distinguish actual targets from any background noise. The proposed approach reframes the classic target image classification challenge to a multivariate time series classification problem, using target trajectory coordinates (x, y) as features. The proposed approach achieved a remarkable 97% accuracy in classifying targets from noise using only ten data points (half a second of tracking). Furthermore, it successfully classified targets into specific categories (airplane, drone, bird) with a 96% accuracy rate over a 1.5 s window (30 data points).},
  archive      = {J_PAAA},
  author       = {Alkentar, Saad and Assalem, Abdulkarim and Alsahwa, Bassem},
  doi          = {10.1007/s10044-024-01397-3},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-9},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Utilize trajectory information for small target classification},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). An improved nearest neighbour classifier. <em>PAAA</em>,
<em>28</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10044-024-01399-1">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {A windowed version of the Nearest Neighbour (WNN) classifier for images is described. While its construction is inspired by the architecture of Artificial Neural Networks, the underlying theoretical framework is based on approximation theory. We illustrate WNN on the datasets MNIST and EMNIST of images of handwritten digits. In order to calibrate the parameters of WNN, we first study it on MNIST. We then apply WNN with these parameters to EMNIST resulting in an error rate of 0.76% which significantly outperforms traditional classification methods like Support Vector Machines. By expansions of the training set, an error rate down to 0.42% is achieved.},
  archive      = {J_PAAA},
  author       = {Setterqvist, Eric and Kruglyak, Natan and Forchheimer, Robert},
  doi          = {10.1007/s10044-024-01399-1},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {An improved nearest neighbour classifier},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Texture discrimination via hilbert curve path based
information quantifiers. <em>PAAA</em>, <em>28</em>(1), 1–18. (<a
href="https://doi.org/10.1007/s10044-024-01400-x">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {The analysis of the spatial arrangement of colors and roughness/smoothness of figures is relevant due to its wide range of applications. This paper proposes a texture characterization method that extracts data from images using the Hilbert curve. Three information theory quantifiers are then computed: permutation entropy, permutation complexity, and Fisher information measure. The proposal exhibits some important properties: (i) it allows discrimination between figures according to varying degrees of correlations (as measured by the Hurst exponent), (ii) it is invariant to rotation and symmetry transformations, (iii) it is invariant to image scaling, (iv) it can be used for both black and white and color images. Validations have been performed not only using synthetic images but also using the well-known Brodatz image database.},
  archive      = {J_PAAA},
  author       = {Bariviera, Aurelio F. and Hansen, Roberta and Pastor, Verónica E.},
  doi          = {10.1007/s10044-024-01400-x},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-18},
  shortjournal = {Pattern Anal. Appl.},
  title        = {Texture discrimination via hilbert curve path based information quantifiers},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). A light-weight backbone to adapt with extracting grouped
dilation features. <em>PAAA</em>, <em>28</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10044-024-01401-w">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Addressing grouped dilation features (GDFs) improved the learning ability of MobileNetV1 in image representation. However, the computational complexity is still at a high level, while the performance is a modest degree. This expensive cost is principally caused by the backbone of MobileNetV1 taking deep feature maps in several latest layers. To mitigate these issues, we propose a light-weight network (called CGDF-Net) with an adaptative architecture to effectively extract grouped dilation features. CGDF-Net is structured by two main contributions: (i) Its backbone is improved by simply replacing several latest layers of MobileNetV1 with a pointwise convolutional layer for reducing the computational complexity; (ii) Embedding an attention mechanism into the GDF block to form a completed GDF perceptron (CGDF) that directs the learning process into the significant properties of objects in images instead of the trivial ones. Experimental results on benchmark datasets for image recognition have validated that the proposed CGDF-Net network obtained good performance with a small computational cost in comparison with MobileNets and other light-weight models. For instance, CGDF-Net obtained 60.86% with 3.53M learnable parameters on Stanford Dogs, up to 6% better than MoblieNetV1-GDF (54.9%, 3.39M) and 9% versus MoblieNetV1 (51.6%, 3.33M). Meantime, the performance of CGDF-Net on ImageNet-100 is 85.22%, about 6% $$\sim$$ 8% higher than MobileNetV1-GDF’s (79.14%) and MobileNetV1’s (77.01%), respectively. The code of CGDF-Net is available at https://github.com/nttbdrk25/CGDFNet .},
  archive      = {J_PAAA},
  author       = {Nguyen, Thanh Tuan and Pham, Hoang Anh and Nguyen, Thanh Phuong},
  doi          = {10.1007/s10044-024-01401-w},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {A light-weight backbone to adapt with extracting grouped dilation features},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). IMIHCT: Improved multi-stage image inpainting with hybrid
CNN and transformer. <em>PAAA</em>, <em>28</em>(1), 1–14. (<a
href="https://doi.org/10.1007/s10044-024-01402-9">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Aiming at problems such as the poor effect of large-hole image inpainting, the limitation of local information reconstruction of the convolutional neural network, and a surge in parameters caused by stacking a large number of convolutional modules in the network model. We make full use of the advantages of convolutional neural network and transformer and propose an improved multi-stage inpainting method with hybrid CNN and transformer. The method achieves a balance between performance and parameters. Specifically, rough results are first generated using a coarse inpainting network with skip connections and lightweight Taylor transformer modules. Then, a local refinement network with coordinate attention is used to perform local refinement, optimizing local details while weakening the influence of unreasonable content in the distance. Finally, to compensate for the inability of local refinement networks to refine the overall pattern over long distances, global refinement is performed using a network that is consistent with the structure of the coarse inpainting network to make the reconstructed image more realistic and natural. Results show that the method outperforms the state of the arts on three publicly available datasets. The code is made available at https://github.com/Sheeran2000/IMIHCT .},
  archive      = {J_PAAA},
  author       = {Ning, Tao and Wang, Xingfang and Ding, Hongwei},
  doi          = {10.1007/s10044-024-01402-9},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-14},
  shortjournal = {Pattern Anal. Appl.},
  title        = {IMIHCT: Improved multi-stage image inpainting with hybrid CNN and transformer},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). UMAM-NET: Ultrasound thyroid nodule malignancy grading
network based on multi-subnet attention mechanism. <em>PAAA</em>,
<em>28</em>(1), 1–16. (<a
href="https://doi.org/10.1007/s10044-024-01404-7">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Background and Objectives: Thyroid nodules are one of the most common thyroid diseases, and their incidence has been on the rise in recent years. Ultrasound imaging, due to its low cost and no ionizing radiation, has become the preferred method for imaging thyroid nodules. Accurate assessment of the malignancy grade of thyroid nodules is crucial to ensure the accuracy of subsequent examination and treatment. Texture and shape are key features for determining the nature of thyroid nodules. Despite the excellent performance of convolutional neural networks (CNNs) in image feature extraction and aggregation, the low resolution and high noise characteristics of ultrasound images still pose challenges for existing CNN models in identifying texture and shape. Methods: To address this challenge, we propose a thyroid nodule malignancy grading network based on a multi-subnet attention mechanism (UMAM-NET). In the feature extraction stage, we innovatively introduce the multi-subnet attention module. The module designs two parallel subnets, aiming to enhance the model’s attention to the texture and shape of thyroid nodules. Results: Compared to other deep learning models, the proposed UMAM-NET performs better in the malignant grading task of thyroid nodules. It demonstrates excellent performance on public datasets, achieving the best results in Recall (93.1%), F1-score (95.4%), and Accuracy (98.4%). Similarly, it also shows outstanding performance on the sub-collected dataset, with Recall (91.8%), F1-score (92.0%), and Accuracy (94.4%). Conclusion: Our proposed UMAM-NET, based on multi-subnet attention mechanism, provides a promising approach for accurate assessment of thyroid nodule malignancy grade, which can be of great value in clinical practice.},
  archive      = {J_PAAA},
  author       = {Bi, Hui and Wang, Fan and Xiong, YuHao and Dong, ZhaoHui and Jiang, Yibo and Zhao, Tong and Zheng, Yineng},
  doi          = {10.1007/s10044-024-01404-7},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-16},
  shortjournal = {Pattern Anal. Appl.},
  title        = {UMAM-NET: Ultrasound thyroid nodule malignancy grading network based on multi-subnet attention mechanism},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). PSFE-YOLO: A traffic sign detection algorithm with
pixel-wise spatial feature enhancement. <em>PAAA</em>, <em>28</em>(1),
1–15. (<a href="https://doi.org/10.1007/s10044-024-01406-5">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Traffic sign detection is essentially important for intelligent driving. Existing detection algorithms typically incorporate self-attention mechanisms to model the dependencies among image elements, such as patches or pixels. When using a patch as a token, the positional information within the patch could be lost. When using a pixel as a token, an increase in the number of tokens can lead to a significant increase in computational complexity. To balance these two extreme situations, a pixel only needs to focus on pixels from the surrounding area. Therefore, we propose a local attention module termed Pixel-wise Spatial Feature Enhancement (PSFE), which uses pixels as tokens to enhance the spatial information of feature maps, and each pixel’s self-attention only acts on a local region to reduce computational complexity. Furthermore, we design a Bidirectional Res2Net (BR) module that generates multiple feature maps with different channel numbers from an input feature map, and then restores them to one feature map with the original input size through bidirectional fusion, greatly enriching the receptive field information contained in the feature map. We conducted experiments on the GTSDB, TT100K, and CCTSDB 2021 datasets to comprehensively evaluate our method, and the experimental results showed that our method has superior performance.},
  archive      = {J_PAAA},
  author       = {Zhang, Jianming and Wang, Zulou and Yi, Yao and Kuang, Li-Dan and Zhang, Jin},
  doi          = {10.1007/s10044-024-01406-5},
  journal      = {Pattern Analysis and Applications},
  month        = {3},
  number       = {1},
  pages        = {1-15},
  shortjournal = {Pattern Anal. Appl.},
  title        = {PSFE-YOLO: A traffic sign detection algorithm with pixel-wise spatial feature enhancement},
  volume       = {28},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
