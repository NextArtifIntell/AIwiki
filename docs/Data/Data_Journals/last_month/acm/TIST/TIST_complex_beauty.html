<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>TIST_complex_beauty</title>
  <style>
    html {font-size: 22px;}
    body {margin: 0 auto; max-width: 76em;}
    #copyID {font-size: 18px;}
  </style>
  <script>
    function copy(element) {
      if (element.type == "button"){
      element.type="text";
      }
      element.style.color="black";
      element.style.backgroundColor="#C7EDCC";
      element.select();
      element.setSelectionRange(0, 99999);
      navigator.clipboard.writeText(element.value);
      window.getSelection().removeAllRanges();
      element.type="button";
    }
  </script>
</head>
<body>

<h2 id="tist---8">TIST - 8</h2>
<ul>
<li><details>
<summary>
(2025). Explaining neural news recommendation with attributions onto
reading histories. <em>TIST</em>, <em>16</em>(1), 1–25. (<a
href="https://doi.org/10.1145/3673233">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {An important aspect of responsible recommendation systems is the transparency of the prediction mechanisms. This is a general challenge for deep-learning-based systems such as the currently predominant neural news recommender architectures, which are optimized to predict clicks by matching candidate news items against users’ reading histories. Such systems achieve state-of-the-art click-prediction performance, but the rationale for their decisions is difficult to assess. At the same time, the economic and societal impact of these systems makes such insights very much desirable. In this article, we ask the question to what extent the recommendations of current news recommender systems are actually based on content-related evidence from reading histories. We approach this question from an explainability perspective. Building on the concept of integrated gradients, we present a neural news recommender that can accurately attribute individual recommendations to news items and words in input reading histories while maintaining a top scoring click-prediction performance. Using our method as a diagnostic tool, we find that: (a), a substantial number of users’ clicks on news are not explainable from reading histories, and many history-explainable items are actually skipped; (b), while many recommendations are based on content-related evidence in histories, for others the model does not attend to reasonable evidence, and recommendations stem from a spurious bias in user representations. Our code is publicly available at https://github.com/lucasmllr/xnrs .},
  archive      = {J_TIST},
  doi          = {10.1145/3673233},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-25},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Explaining neural news recommendation with attributions onto reading histories},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Aspect-enhanced explainable recommendation with multi-modal
contrastive learning. <em>TIST</em>, <em>16</em>(1), 1–24. (<a
href="https://doi.org/10.1145/3673234">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Explainable recommender systems ( ERS ) aim to enhance users’ trust in the systems by offering personalized recommendations with transparent explanations. This transparency provides users with a clear understanding of the rationale behind the recommendations, fostering a sense of confidence and reliability in the system’s outputs. Generally, the explanations are presented in a familiar and intuitive way, which is in the form of natural language, thus enhancing their accessibility to users. Recently, there has been an increasing focus on leveraging reviews as a valuable source of rich information in both modeling user-item preferences and generating textual interpretations, which can be performed simultaneously in a multi-task framework. Despite the progress made in these review-based recommendation systems, the integration of implicit feedback derived from user-item interactions and user-written text reviews has yet to be fully explored. To fill this gap, we propose a model named SERMON (A s pect-enhanced E xplainable R ecommendation with M ulti-modal C o ntrast Lear n ing). Our model explores the application of multimodal contrastive learning to facilitate reciprocal learning across two modalities, thereby enhancing the modeling of user preferences. Moreover, our model incorporates the aspect information extracted from the review, which provides two significant enhancements to our tasks. Firstly, the quality of the generated explanations is improved by incorporating the aspect characteristics into the explanations generated by a pre-trained model with controlled textual generation ability. Secondly, the commonly used user-item interactions are transformed into user-item-aspect interactions, which we refer to as interaction triple, resulting in a more nuanced representation of user preference. To validate the effectiveness of our model, we conduct extensive experiments on three real-world datasets. The experimental results show that our model outperforms state-of-the-art baselines, with a 2.0% improvement in prediction accuracy and a substantial 24.5% enhancement in explanation quality for the TripAdvisor dataset.},
  archive      = {J_TIST},
  doi          = {10.1145/3673234},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-24},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Aspect-enhanced explainable recommendation with multi-modal contrastive learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fairness and bias in algorithmic hiring: A multidisciplinary
survey. <em>TIST</em>, <em>16</em>(1), 1–54. (<a
href="https://doi.org/10.1145/3696457">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Employers are adopting algorithmic hiring technology throughout the recruitment pipeline. Algorithmic fairness is especially applicable in this domain due to its high stakes and structural inequalities. Unfortunately, most work in this space provides partial treatment, often constrained by two competing narratives, optimistically focused on replacing biased recruiter decisions or pessimistically pointing to the automation of discrimination. Whether, and more importantly what types of , algorithmic hiring can be less biased and more beneficial to society than low-tech alternatives currently remains unanswered, to the detriment of trustworthiness. This multidisciplinary survey caters to practitioners and researchers with a balanced and integrated coverage of systems, biases, measures, mitigation strategies, datasets, and legal aspects of algorithmic hiring and fairness. Our work supports a contextualized understanding and governance of this technology by highlighting current opportunities and limitations, providing recommendations for future work to ensure shared benefits for all stakeholders.},
  archive      = {J_TIST},
  doi          = {10.1145/3696457},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-54},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fairness and bias in algorithmic hiring: A multidisciplinary survey},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Extracting political interest model from interaction data
based on novel word-level bias assignment. <em>TIST</em>,
<em>16</em>(1), 1–21. (<a
href="https://doi.org/10.1145/3702649">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In democratic countries, political interest is deeply involved in people’s daily lives. Research in political consumerism shows that product purchase decision is also influenced by the political orientation of the consumer. In traditional recommendation system design, user interest in an item is provided by a unified model. Recently, interest disentanglement methods have been introduced. It is shown that by disentangling interest factors such as conformity and private interest, recommendation performance can be significantly improved. However, few studies attempt to disentangle political interest in purchase behavior, which is bipolar. In this article, we propose a method to extract political interest model from e-commerce interaction data, which is supported by a novel word-level political bias assignment. For the bias assignment part, we improved a political bias distilling method. For the political interest model extraction part, we extend a one-side bias method to make it support bipolar bias. We compare our method with state-of-the-art baseline methods in several evaluation settings, and the experimental results show that our method can achieve superior performance. Further investigation shows that our method is consistent with theories of political consumerism.},
  archive      = {J_TIST},
  doi          = {10.1145/3702649},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Extracting political interest model from interaction data based on novel word-level bias assignment},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Edge manipulations for the maximum vertex-weighted bipartite
b-matching. <em>TIST</em>, <em>16</em>(1), 1–26. (<a
href="https://doi.org/10.1145/3702650">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this article, we explore the Mechanism Design aspects of the Maximum Vertex-Weighted \(b\) -matching (MVbM) problem on bipartite graphs \((A\cup T,E)\) . The set \(A\) comprises agents, while \(T\) represents tasks. The set \(E\) , which connects \(A\) and \(T\) , is the private information of either agents or tasks. In this framework, we investigate three mechanisms— \(\mathbb{M}_{BFS}\) , \(\mathbb{M}_{DFS}\) , and \(\mathbb{M}_{G}\) . We examine scenarios in which either agents or tasks are strategic and report their adjacent edges to one of the three mechanisms. In both cases, we assume that the strategic entities are bounded by their statements: They can hide edges, but they cannot report edges that do not exist. First, we consider the case in which agents can manipulate. In this framework, \(\mathbb{M}_{BFS}\) and \(\mathbb{M}_{DFS}\) are optimal but not truthful. By characterizing the Nash Equilibria induced by \(\mathbb{M}_{BFS}\) and \(\mathbb{M}_{DFS}\) , we reveal that both mechanisms have a Price of Anarchy ( \(PoA\) ) and Price of Stability ( \(PoS\) ) of \(2\) . These efficiency guarantees are tight; no deterministic mechanism can achieve a lower \(PoA\) or \(PoS\) . In contrast, the third mechanism, \(\mathbb{M}_{G}\) , is not optimal, but truthful and its approximation ratio is \(2\) . We demonstrate that this ratio is optimal; no deterministic and truthful mechanism can outperform it. We then shift our focus to scenarios where tasks can exhibit strategic behavior. In this case, \(\mathbb{M}_{BFS}\) , \(\mathbb{M}_{DFS}\) , and \(\mathbb{M}_{G}\) all maintain truthfulness, making \(\mathbb{M}_{BFS}\) and \(\mathbb{M}_{DFS}\) truthful and optimal mechanisms. In conclusion, we investigate the manipulability of \(\mathbb{M}_{BFS}\) and \(\mathbb{M}_{DFS}\) through experiments on randomly generated graphs. We observe that (i) \(\mathbb{M}_{BFS}\) is less prone to be manipulated by the first agent than \(\mathbb{M}_{DFS}\) , and (ii) \(\mathbb{M}_{BFS}\) is more manipulable on instances in which the total capacity of the agents is equal to the number of tasks. 1},
  archive      = {J_TIST},
  doi          = {10.1145/3702650},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-26},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Edge manipulations for the maximum vertex-weighted bipartite b-matching},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Fast and accurate evacuation planning algorithm with
bayesian optimization. <em>TIST</em>, <em>16</em>(1), 1–21. (<a
href="https://doi.org/10.1145/3704920">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {In this work, we propose a method for generating an evacuation plan at a high speed to realize safe and swift evacuation in the event of a large-scale disaster such as an earthquake and its accompanying tsunami. Existing conventional methods have several problems. Simulation-based methods that use agents and methods that use existing time expansion networks have high computational costs, which makes it difficult for evacuation routes to be immediately changed according to the effects of disasters such as collapsed buildings and roads. Although heuristics with reduced calculation costs are also being researched, they may result in very long evacuation completion times and cannot generate optimal evacuation plans. We guarantee the optimal solution by reducing the number of maximum flow problem calculations, which constitute the bottleneck for methods using the existing time expansion network, through the use of the Bayesian optimization machine learning method. This reduces the calculation cost of the entire algorithm. The performance of our method is evaluated from the two viewpoints of the evacuation completion time, which indicates the quality of the evacuation plan, and the time required for the generation by the solution of the algorithm in computer experiments under multiple scenarios. In addition, the impact of the number of evacuees and the locations of the sinks are analyzed. We show that our method can quickly generate an optimal evacuation plan.},
  archive      = {J_TIST},
  doi          = {10.1145/3704920},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Fast and accurate evacuation planning algorithm with bayesian optimization},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Heterogeneous graph neural networks using self-supervised
reciprocally contrastive learning. <em>TIST</em>, <em>16</em>(1), 1–21.
(<a href="https://doi.org/10.1145/3706115">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Heterogeneous graph neural network (HGNN) is a popular technique for modeling and analyzing heterogeneous graphs. Most existing HGNN-based approaches are supervised or semi-supervised learning methods requiring graphs to be annotated, which is costly and time-consuming. Self-supervised contrastive learning has been proposed to address the problem of requiring annotated data by mining intrinsic properties in the given data. However, the existing contrastive learning methods are not suitable for heterogeneous graphs because they construct contrastive views only based on data perturbation or pre-defined structural properties (e.g., meta-path) in graph data while ignoring noises in node attributes and graph topologies. We develop a robust heterogeneous graph contrastive learning approach, namely HGCL, which introduces two views on respective guidances of node attributes and graph topologies and integrates and enhances them by a reciprocally contrastive mechanism to better model heterogeneous graphs. In this new approach, we adopt distinct but suitable attribute and topology fusion mechanisms in the two views, which are conducive to mining relevant information in attributes and topologies separately. We further use both attribute similarity and topological correlation to construct high-quality contrastive samples. Extensive experiments on four large real-world heterogeneous graphs demonstrate the superiority and robustness of HGCL over several state-of-the-art methods.},
  archive      = {J_TIST},
  doi          = {10.1145/3706115},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-21},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Heterogeneous graph neural networks using self-supervised reciprocally contrastive learning},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
<li><details>
<summary>
(2025). Tucker decomposition-enhanced dynamic graph convolutional
networks for crowd flows prediction. <em>TIST</em>, <em>16</em>(1),
1–19. (<a href="https://doi.org/10.1145/3706116">www</a>)
</summary>
<textarea id="copyID" onclick="copy(this)" rows="16" cols="145">
@article{ ,
  abstract     = {Crowd flows prediction is an important problem for traffic management and public safety. Graph Convolutional Network (GCN), known for its ability to effectively capture and utilize topological information, has demonstrated significant advancements in addressing this problem. However, GCN-based models were often based on predefined crowd-flow graphs via historical movement behaviors of human beings and traffic vehicles, which ignored the abnormal changes in crowd flows. In this study, we propose a multi-scale fusion GCN-based framework with Tucker decomposition named mTDNet to enhance dynamic GCN for crowd flows prediction. Following the paradigm of extant methods, we also employ the predefined crowd-flow graphs as a part of mTDNet to effectively capture the historical movement behaviors of crowd flows. To capture the abnormal changes, we propose a Tucker decomposition-based network with the product of the adjacency matrix of historical movement pattern graphs and an Adaptive Learning Tensor ( ALT ) by reconstructing the crowd flows. Particularly, we utilize the Tucker decomposition scheme to decompose ALT , which enhances the dynamic learning of graph structures, allowing for effective capturing of the dynamic changes in crowd flow, including abnormal changes. Furthermore, a multi-scale 3DGCN is utilized to mine and fuse the multi-scale spatio-temporal information from crowd flows, to further boost the mTDNet prediction performance. Experiments conducted on two real-world datasets showed that the proposed mTDNet surpasses other crowd flow prediction methods.},
  archive      = {J_TIST},
  doi          = {10.1145/3706116},
  journal      = {ACM Transactions on Intelligent Systems and Technology},
  month        = {1},
  number       = {1},
  pages        = {1-19},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  title        = {Tucker decomposition-enhanced dynamic graph convolutional networks for crowd flows prediction},
  volume       = {16},
  year         = {2025},
}
</textarea>
</details></li>
</ul>

</body>
</html>
